{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess \n",
    "import torch as ch\n",
    "from torch import Tensor\n",
    "import torch.linalg as LA\n",
    "from torch.distributions import Uniform\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "from cox.utils import Parameters\n",
    "from cox.store import Store\n",
    "\n",
    "from cox.readers import CollectionReader\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math \n",
    "\n",
    "import sys \n",
    "sys.path.append('../..')\n",
    "from delphi.stats.linear_regression import TruncatedRegression\n",
    "from delphi import oracle\n",
    "from delphi.utils import constants as consts\n",
    "from delphi.utils.helpers import setup_store_with_metadata\n",
    "\n",
    "OUT_DIR = '/home/gridsan/stefanou/Regression/'\n",
    "TABLE_NAME = 'logs'\n",
    "\n",
    "# set environment variable so that stores can create output files\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Parameters({\n",
    "    \"bias\": True,\n",
    "    \"samples\": 1000,\n",
    "    \"c\": 0,\n",
    "    \"batch_size\": 5,\n",
    "    \"lr\": 1e-1,\n",
    "    \"var_lr\": 1e-2,\n",
    "    \"var_\": 1,\n",
    "    \"trials\": 3,\n",
    "    \"norm\": False,\n",
    "    \"workers\": 8,\n",
    "    \"steps\": 1000,\n",
    "    \"x_lower\": -10,\n",
    "    \"x_upper\": 10,\n",
    "    \"lower\": -1,\n",
    "    \"upper\": 1,\n",
    "    \"device\": \"cuda\",\n",
    "    \"num_samples\": 100,\n",
    "})\n",
    "mse_loss = ch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start by generating the ground-truth for our expriment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt weight:  Parameter containing:\n",
      "tensor([[-0.6398]], requires_grad=True)\n",
      "gt bias:  Parameter containing:\n",
      "tensor([[-0.8709]], requires_grad=True)\n",
      "alpha:  tensor([0.3930])\n",
      "gt ols coef:  [[-0.63485026]]\n",
      "gt ols intercept:  [-0.81396824]\n",
      "trunc ols coef:  [[-0.27256936]]\n",
      "trunc ols intercept:  [1.5339618]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution for generating feature vectors\n",
    "d, k = 1, 1\n",
    "w = Uniform(-1, 1)\n",
    "# m = MultivariateNormal(ch.zeros(d), ch.eye(d)/d)\n",
    "m = Uniform(-5, 5)\n",
    "phi = oracle.Left(Tensor([0.0]))\n",
    "# phi = oracle.Identity()\n",
    "\n",
    "# generate ground truth\n",
    "gt = ch.nn.Linear(in_features=k, out_features=1)\n",
    "gt.weight = ch.nn.Parameter(w.sample(ch.Size([k, d])))\n",
    "\n",
    "# gt.bias = ch.nn.Parameter(ch.ones(1, 1)) if args.bias else None\n",
    "gt.bias = ch.nn.Parameter(w.sample(ch.Size([1, 1]))) if args.bias else None\n",
    "\n",
    "print(\"gt weight: \", gt.weight)\n",
    "print(\"gt bias: \", gt.bias)\n",
    "\n",
    "# create base classifier\n",
    "with ch.no_grad():\n",
    "    # generate data\n",
    "    X = m.sample(ch.Size([args.samples, d])) if isinstance(m, Uniform) else m.sample(ch.Size([args.samples]))\n",
    "\n",
    "    y = gt(X)\n",
    "\n",
    "noise_var = Tensor([5.0])[...,None]\n",
    "# remove synthetic data from the computation graph\n",
    "with ch.no_grad():\n",
    "    # add noise to ground-truth pedictions\n",
    "    noised = y + ch.sqrt(noise_var) * ch.randn(X.size(0), 1)\n",
    "    # truncate based off of the standardized data\n",
    "    indices = phi(noised).flatten().nonzero(as_tuple=False).flatten()\n",
    "    y_trunc, x_trunc = noised[indices], X[indices]\n",
    "    alpha = Tensor([y_trunc.size(0) / args.samples])\n",
    "    print(\"alpha: \", alpha)\n",
    "    \n",
    "# ground-truth OLS\n",
    "gt_ols = LinearRegression()\n",
    "gt_ols.fit(X, noised)\n",
    "print(\"gt ols coef: \", gt_ols.coef_)\n",
    "print(\"gt ols intercept: \", gt_ols.intercept_)\n",
    "\n",
    "trunc_ols = LinearRegression()\n",
    "trunc_ols.fit(x_trunc, y_trunc)\n",
    "trunc_ols_pred = trunc_ols.predict(x_trunc)\n",
    "print(\"trunc ols coef: \", trunc_ols.coef_)\n",
    "print(\"trunc ols intercept: \", trunc_ols.intercept_)\n",
    "\n",
    "# data for plotting regressions\n",
    "unnorm_data = np.linspace(-5, 5, 100).reshape(100, 1)\n",
    "norm_data = np.linspace(-1, 1, 100).reshape(100, 1)\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(X, noised)\n",
    "plt.scatter(x_trunc, y_trunc)\n",
    "plt.plot(unnorm_data, gt_ols.predict(unnorm_data), color='green', label='gt ols')\n",
    "plt.plot(unnorm_data, trunc_ols.predict(unnorm_data), color='red', label='trunc ols')\n",
    "plt.legend()\n",
    "plt.title(\"Empirical and Ground Truth Dataset and Model\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to standardize our truncated dataset, so that our empirical estimates are located on the l2 ball. First we will divide all of our covariate features by $B\\sqrt{k}$, so that all of our covariate features $||x_{i}||_{2}^{2} \\leq 1$, and reside on the $\\ell_{2}$ ball. This way the norm of $w$ will be multiplied by $B\\sqrt{k}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max truncated x norm tensor(4.9916)\n",
      "beta:  tensor(4.9916)\n",
      "x max l2:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "max_x_trunc_norm = LA.norm(x_trunc, dim=-1, ord=float('inf')).max()\n",
    "print(\"max truncated x norm\", max_x_trunc_norm)\n",
    "\n",
    "beta = max_x_trunc_norm*math.sqrt(X.size(1))\n",
    "print(\"beta: \", beta)\n",
    "\n",
    "x_trunc_norm = x_trunc / beta\n",
    "print(\"x max l2: \", x_trunc_norm.norm(dim=-1).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now observe that the norm of the truncated x covariates is bounded by 1. So, now we will standardze our dependent variable so that it's ground-truth takes the form of the linear regression latent variable model with noise variance of 1. First, let's calculate the predicted values from our naive ols regression on teh truncated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will standardize our data for the case where we assume that the empirical noise variance is the underlying noise variance of the ground truth regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp noise var:  tensor([2.4027])\n",
      "trunc reg noise var:  tensor([1.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emp_noise_var = (y_trunc - trunc_ols_pred).var(0)\n",
    "print(\"emp noise var: \", emp_noise_var)\n",
    "\n",
    "emp_stand_y_trunc = y_trunc / ch.sqrt(emp_noise_var)\n",
    "trunc_noise_var = (emp_stand_y_trunc - (trunc_ols_pred / ch.sqrt(emp_noise_var))).var(0)\n",
    "print(\"trunc reg noise var: \", trunc_noise_var)\n",
    "\n",
    "new_X, emp_stand_noised = X / beta, noised / ch.sqrt(emp_noise_var)\n",
    "\n",
    "gt_emp_stand = LinearRegression()\n",
    "gt_emp_stand.fit(new_X, emp_stand_noised)\n",
    "\n",
    "trunc_emp_stand_ols = LinearRegression()\n",
    "trunc_emp_stand_ols.fit(x_trunc_norm, emp_stand_y_trunc)\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(new_X, emp_stand_noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc_norm, emp_stand_y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(norm_data, gt_emp_stand.predict(norm_data), color='green', label='gt ols')\n",
    "plt.plot(norm_data, trunc_emp_stand_ols.predict(norm_data), color='red', label='trunc ols')\n",
    "plt.legend()\n",
    "plt.title('Y Scaled by Empirical Noise Variance')\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will standardize our data for the case where we assume that wee know the underlying ground-truth noise variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trunc reg noise var:  tensor([0.4805])\n",
      "reg noise var:  tensor([0.9624])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stand_noised, stand_y_trunc = noised / ch.sqrt(noise_var), y_trunc / ch.sqrt(noise_var)\n",
    "\n",
    "gt_stand = LinearRegression()\n",
    "gt_stand.fit(new_X, stand_noised)\n",
    "\n",
    "trunc_stand_ols = LinearRegression()\n",
    "trunc_stand_ols.fit(x_trunc_norm, stand_y_trunc)\n",
    "\n",
    "trunc_noise_var = (stand_y_trunc - trunc_stand_ols.predict(x_trunc_norm)).var(0)\n",
    "print(\"trunc reg noise var: \", trunc_noise_var)\n",
    "\n",
    "reg_noise_var = (stand_noised - gt_stand.predict(new_X)).var(0)\n",
    "print(\"reg noise var: \", reg_noise_var)\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(new_X, stand_noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc_norm, stand_y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(norm_data, gt_stand.predict(norm_data), color='green', label='gt ols')\n",
    "plt.plot(norm_data, trunc_stand_ols.predict(norm_data), color='red', label='trunc ols')\n",
    "plt.legend()\n",
    "plt.title(\"Y Scaled by Ground-Truth Noise Variance\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncated Regression with Known Empirical Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 steps | score: [0.21396589279174805]\n",
      "100 steps | score: [0.12902069091796875]\n",
      "200 steps | score: [0.08731332421302795]\n",
      "300 steps | score: [0.007806718349456787]\n",
      "400 steps | score: [0.03827406466007233]\n",
      "500 steps | score: [0.05123590677976608]\n",
      "600 steps | score: [0.05245800316333771]\n",
      "700 steps | score: [0.09803733974695206]\n",
      "800 steps | score: [0.06443636119365692]\n",
      "900 steps | score: [0.07019159942865372]\n",
      "1000 steps | score: [0.08759771287441254]\n"
     ]
    }
   ],
   "source": [
    "trunc_reg = TruncatedRegression(phi=phi, alpha=alpha, bias=True, unknown=False, val=100, bs=10, n=100, tol=1e-2)\n",
    "known_emp_res = trunc_reg.fit(x_trunc_norm, emp_stand_y_trunc)\n",
    "known_emp_w_unnorm = (known_emp_res.weight * ch.sqrt(emp_noise_var)) / beta\n",
    "\n",
    "known_emp_bias_unnorm = ch.zeros(1, 1)\n",
    "if args.bias: \n",
    "    known_emp_bias_unnorm = (known_emp_res.bias * ch.sqrt(emp_noise_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(new_X, emp_stand_noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc_norm, emp_stand_y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(norm_data, trunc_emp_stand_ols.predict(norm_data), color='r', label='ols')\n",
    "plt.plot(norm_data, gt_emp_stand.predict(norm_data), color='green', label='gt')\n",
    "plt.plot(norm_data, known_emp_res(Tensor(norm_data)).detach().numpy(), label='known emp', color='blue')\n",
    "plt.legend()\n",
    "plt.title(\"Empirical Known Noise Variance Results - Normalized\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.plot(unnorm_data, trunc_ols.predict(unnorm_data), color='red', label='ols')\n",
    "plt.plot(unnorm_data, (Tensor(unnorm_data)@known_emp_w_unnorm + known_emp_bias_unnorm).detach().numpy(), label='known', color='blue')\n",
    "plt.plot(unnorm_data, gt_ols.predict(unnorm_data), color='green', label='gt')\n",
    "plt.scatter(X, noised, label='entire dataset')\n",
    "plt.scatter(x_trunc, y_trunc, label='truncated dataset')\n",
    "plt.legend()\n",
    "plt.title(\"Empirical Known Noise Variance Results - UnNormalized\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncated Regression with Known Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 steps | score: [0.22792524099349976]\n",
      "1 steps | score: [0.2949662506580353]\n",
      "2 steps | score: [0.2621906101703644]\n",
      "3 steps | score: [0.2080284059047699]\n",
      "4 steps | score: [0.23872174322605133]\n",
      "5 steps | score: [0.18210293352603912]\n",
      "6 steps | score: [0.2085130214691162]\n",
      "7 steps | score: [0.14472460746765137]\n",
      "8 steps | score: [0.2240763157606125]\n",
      "9 steps | score: [0.15688711404800415]\n",
      "10 steps | score: [0.16034062206745148]\n",
      "11 steps | score: [0.14710168540477753]\n",
      "12 steps | score: [0.18119260668754578]\n",
      "13 steps | score: [0.10140843689441681]\n",
      "14 steps | score: [0.10847195237874985]\n",
      "15 steps | score: [0.09841840714216232]\n",
      "16 steps | score: [0.1279100775718689]\n",
      "17 steps | score: [0.12686927616596222]\n",
      "18 steps | score: [0.06960474699735641]\n",
      "19 steps | score: [0.15381039679050446]\n",
      "20 steps | score: [0.12468279153108597]\n",
      "21 steps | score: [0.10570991784334183]\n",
      "22 steps | score: [0.051160745322704315]\n",
      "23 steps | score: [0.05610969290137291]\n",
      "24 steps | score: [0.09964567422866821]\n",
      "25 steps | score: [0.0908287912607193]\n",
      "26 steps | score: [0.13781407475471497]\n",
      "27 steps | score: [0.0996604859828949]\n",
      "28 steps | score: [0.09594499319791794]\n",
      "29 steps | score: [0.034496940672397614]\n",
      "30 steps | score: [0.05671054869890213]\n",
      "31 steps | score: [0.09376480430364609]\n",
      "32 steps | score: [0.07169470191001892]\n",
      "33 steps | score: [0.06671405583620071]\n",
      "34 steps | score: [0.05126481503248215]\n",
      "35 steps | score: [0.08191582560539246]\n",
      "36 steps | score: [0.0685681700706482]\n",
      "37 steps | score: [0.08196662366390228]\n",
      "38 steps | score: [0.06548850238323212]\n",
      "39 steps | score: [0.06472156941890717]\n",
      "40 steps | score: [0.07436861842870712]\n",
      "41 steps | score: [0.03190019726753235]\n",
      "42 steps | score: [0.06774307787418365]\n",
      "43 steps | score: [0.038948118686676025]\n",
      "44 steps | score: [0.09778306633234024]\n",
      "45 steps | score: [0.10535956919193268]\n",
      "46 steps | score: [0.07373832911252975]\n",
      "47 steps | score: [0.05990351364016533]\n",
      "48 steps | score: [0.049999430775642395]\n",
      "49 steps | score: [0.10884112119674683]\n",
      "50 steps | score: [0.07945777475833893]\n",
      "51 steps | score: [0.05868232250213623]\n",
      "52 steps | score: [0.08693044632673264]\n",
      "53 steps | score: [0.01179477572441101]\n",
      "54 steps | score: [0.04095172882080078]\n",
      "55 steps | score: [0.07975287735462189]\n",
      "56 steps | score: [0.06252098083496094]\n",
      "57 steps | score: [0.09374231100082397]\n",
      "58 steps | score: [0.0609673336148262]\n",
      "59 steps | score: [0.06594178080558777]\n",
      "60 steps | score: [0.04719149321317673]\n",
      "61 steps | score: [0.09695431590080261]\n",
      "62 steps | score: [0.030236924067139626]\n",
      "63 steps | score: [0.08373057842254639]\n",
      "64 steps | score: [0.05751125141978264]\n",
      "65 steps | score: [0.06272462755441666]\n",
      "66 steps | score: [0.09626749902963638]\n",
      "67 steps | score: [0.0866536796092987]\n",
      "68 steps | score: [0.03852082043886185]\n",
      "69 steps | score: [0.06340669095516205]\n",
      "70 steps | score: [-0.011530846357345581]\n",
      "71 steps | score: [0.04804756119847298]\n",
      "72 steps | score: [0.01737319491803646]\n",
      "73 steps | score: [0.03538535535335541]\n",
      "74 steps | score: [0.011133871972560883]\n",
      "75 steps | score: [0.030422065407037735]\n",
      "76 steps | score: [0.06510668247938156]\n",
      "77 steps | score: [0.04892720282077789]\n",
      "78 steps | score: [0.05881785601377487]\n",
      "79 steps | score: [0.032266248017549515]\n",
      "80 steps | score: [0.060389213263988495]\n",
      "81 steps | score: [0.06897278130054474]\n",
      "82 steps | score: [0.04110974445939064]\n",
      "83 steps | score: [0.06627797335386276]\n",
      "84 steps | score: [0.07775705307722092]\n",
      "85 steps | score: [0.08026131987571716]\n",
      "86 steps | score: [0.03149797022342682]\n",
      "87 steps | score: [0.022329185158014297]\n",
      "88 steps | score: [0.03131485730409622]\n",
      "89 steps | score: [0.07270734012126923]\n",
      "90 steps | score: [0.05253347381949425]\n",
      "91 steps | score: [0.05144127458333969]\n",
      "92 steps | score: [0.03156886622309685]\n",
      "93 steps | score: [0.07476358115673065]\n",
      "94 steps | score: [0.026630744338035583]\n",
      "95 steps | score: [0.03869267553091049]\n",
      "96 steps | score: [0.06060149520635605]\n",
      "97 steps | score: [0.06448312103748322]\n",
      "98 steps | score: [0.056307002902030945]\n",
      "99 steps | score: [0.04601375758647919]\n",
      "100 steps | score: [0.022613221779465675]\n",
      "101 steps | score: [0.03892005980014801]\n",
      "102 steps | score: [0.0329858735203743]\n",
      "103 steps | score: [0.06395307183265686]\n",
      "104 steps | score: [0.016831018030643463]\n",
      "105 steps | score: [0.05780560523271561]\n",
      "106 steps | score: [0.02306646667420864]\n",
      "107 steps | score: [0.02938542328774929]\n",
      "108 steps | score: [0.06685492396354675]\n",
      "109 steps | score: [0.09369197487831116]\n",
      "110 steps | score: [0.017790842801332474]\n",
      "111 steps | score: [0.07113846391439438]\n",
      "112 steps | score: [0.029156900942325592]\n",
      "113 steps | score: [0.07101115584373474]\n",
      "114 steps | score: [0.027068819850683212]\n",
      "115 steps | score: [0.029941264539957047]\n",
      "116 steps | score: [0.05182518810033798]\n",
      "117 steps | score: [0.031229091808199883]\n",
      "118 steps | score: [0.05190553888678551]\n",
      "119 steps | score: [0.03221893683075905]\n",
      "120 steps | score: [0.011148475110530853]\n",
      "121 steps | score: [0.04648955911397934]\n",
      "122 steps | score: [0.057514291256666183]\n",
      "123 steps | score: [0.04858038201928139]\n",
      "124 steps | score: [0.08272937685251236]\n",
      "125 steps | score: [0.007944125682115555]\n",
      "126 steps | score: [0.06293299049139023]\n",
      "127 steps | score: [0.05492778122425079]\n",
      "128 steps | score: [0.009849950671195984]\n",
      "129 steps | score: [0.0665479525923729]\n",
      "130 steps | score: [0.020905308425426483]\n",
      "131 steps | score: [0.007472831755876541]\n",
      "132 steps | score: [0.07305966317653656]\n",
      "133 steps | score: [0.02398783154785633]\n",
      "134 steps | score: [0.04768814891576767]\n",
      "135 steps | score: [0.06196782737970352]\n",
      "136 steps | score: [-0.003931403160095215]\n",
      "137 steps | score: [0.028271188959479332]\n",
      "138 steps | score: [0.03989794850349426]\n",
      "139 steps | score: [0.064724862575531]\n",
      "140 steps | score: [0.03644092381000519]\n",
      "141 steps | score: [0.0303408894687891]\n",
      "142 steps | score: [0.04403707757592201]\n",
      "143 steps | score: [0.08094008266925812]\n",
      "144 steps | score: [0.056703515350818634]\n",
      "145 steps | score: [0.04987352341413498]\n",
      "146 steps | score: [0.016516361385583878]\n",
      "147 steps | score: [0.02370554767549038]\n",
      "148 steps | score: [0.0348338782787323]\n",
      "149 steps | score: [0.04442299157381058]\n",
      "150 steps | score: [0.04535244405269623]\n",
      "151 steps | score: [0.04006991535425186]\n",
      "152 steps | score: [0.021881986409425735]\n",
      "153 steps | score: [0.03316810354590416]\n",
      "154 steps | score: [0.03377523273229599]\n",
      "155 steps | score: [0.05087006837129593]\n",
      "156 steps | score: [0.0007986985146999359]\n",
      "157 steps | score: [0.029002739116549492]\n",
      "158 steps | score: [0.051418181508779526]\n",
      "159 steps | score: [-0.008234407752752304]\n",
      "160 steps | score: [0.06474640220403671]\n",
      "161 steps | score: [0.06525565683841705]\n",
      "162 steps | score: [0.06268207728862762]\n",
      "163 steps | score: [0.04403652250766754]\n",
      "164 steps | score: [0.050466474145650864]\n",
      "165 steps | score: [0.08403035998344421]\n",
      "166 steps | score: [0.04911009222269058]\n",
      "167 steps | score: [0.006123332306742668]\n",
      "168 steps | score: [0.054058775305747986]\n",
      "169 steps | score: [0.0620557963848114]\n",
      "170 steps | score: [0.022270245477557182]\n",
      "171 steps | score: [0.020080890506505966]\n",
      "172 steps | score: [0.04196386784315109]\n",
      "173 steps | score: [0.011172670871019363]\n",
      "174 steps | score: [0.02704862877726555]\n",
      "175 steps | score: [0.0585087351500988]\n",
      "176 steps | score: [0.049131326377391815]\n",
      "177 steps | score: [0.00977582111954689]\n",
      "178 steps | score: [0.010431675240397453]\n",
      "179 steps | score: [0.016540445387363434]\n",
      "180 steps | score: [0.032255131751298904]\n",
      "181 steps | score: [0.02813897468149662]\n",
      "182 steps | score: [0.004914965480566025]\n",
      "183 steps | score: [0.024892011657357216]\n",
      "184 steps | score: [-0.0030811354517936707]\n",
      "185 steps | score: [0.06455112993717194]\n",
      "186 steps | score: [0.006074313074350357]\n",
      "187 steps | score: [0.05782565847039223]\n",
      "188 steps | score: [0.04011789336800575]\n",
      "189 steps | score: [0.048247575759887695]\n",
      "190 steps | score: [0.03945600986480713]\n",
      "191 steps | score: [0.10158202052116394]\n",
      "192 steps | score: [0.003033522516489029]\n",
      "193 steps | score: [0.02372056059539318]\n",
      "194 steps | score: [0.06329971551895142]\n",
      "195 steps | score: [0.05533286929130554]\n",
      "196 steps | score: [0.01542430929839611]\n",
      "197 steps | score: [0.01648794114589691]\n",
      "198 steps | score: [0.06184124946594238]\n",
      "199 steps | score: [0.030040381476283073]\n",
      "200 steps | score: [0.011048205196857452]\n",
      "201 steps | score: [0.05725990608334541]\n",
      "202 steps | score: [0.004970286041498184]\n",
      "203 steps | score: [0.062833771109581]\n",
      "204 steps | score: [0.0542430616915226]\n",
      "205 steps | score: [0.029755258932709694]\n",
      "206 steps | score: [0.06228768080472946]\n",
      "207 steps | score: [0.03785884380340576]\n",
      "208 steps | score: [-0.010446850210428238]\n",
      "209 steps | score: [0.07493425160646439]\n",
      "210 steps | score: [0.07745768874883652]\n",
      "211 steps | score: [0.036456093192100525]\n",
      "212 steps | score: [0.008197203278541565]\n",
      "213 steps | score: [0.01168747991323471]\n",
      "214 steps | score: [0.016563737764954567]\n",
      "215 steps | score: [0.023465456441044807]\n",
      "216 steps | score: [0.005904454737901688]\n",
      "217 steps | score: [0.0025641657412052155]\n",
      "218 steps | score: [-0.03374335169792175]\n",
      "219 steps | score: [0.010388918220996857]\n",
      "220 steps | score: [-0.003227498382329941]\n",
      "221 steps | score: [0.060544855892658234]\n",
      "222 steps | score: [0.015549585223197937]\n",
      "223 steps | score: [0.0225693229585886]\n",
      "224 steps | score: [0.01865377277135849]\n",
      "225 steps | score: [0.021242598071694374]\n",
      "226 steps | score: [0.05877530947327614]\n",
      "227 steps | score: [0.03236082196235657]\n",
      "228 steps | score: [-0.020422693341970444]\n",
      "229 steps | score: [0.024624096229672432]\n",
      "230 steps | score: [0.11102177202701569]\n",
      "231 steps | score: [0.014500642195343971]\n",
      "232 steps | score: [0.10041119158267975]\n",
      "233 steps | score: [-0.01171882450580597]\n",
      "234 steps | score: [0.03751197084784508]\n",
      "235 steps | score: [0.07980340719223022]\n",
      "236 steps | score: [0.04474616423249245]\n",
      "237 steps | score: [0.046068426221609116]\n",
      "238 steps | score: [0.043878257274627686]\n",
      "239 steps | score: [0.018673524260520935]\n",
      "240 steps | score: [0.13244444131851196]\n",
      "241 steps | score: [0.05610046535730362]\n",
      "242 steps | score: [-0.03280206769704819]\n",
      "243 steps | score: [0.05599335581064224]\n",
      "244 steps | score: [0.025369353592395782]\n",
      "245 steps | score: [0.030776571482419968]\n",
      "246 steps | score: [0.041889991611242294]\n",
      "247 steps | score: [0.06016611307859421]\n",
      "248 steps | score: [0.018099673092365265]\n",
      "249 steps | score: [0.00880257785320282]\n",
      "250 steps | score: [0.03402498736977577]\n",
      "251 steps | score: [0.0172608382999897]\n",
      "252 steps | score: [0.008853793144226074]\n",
      "253 steps | score: [0.043516695499420166]\n",
      "254 steps | score: [0.02083102986216545]\n",
      "255 steps | score: [0.06941904872655869]\n",
      "256 steps | score: [0.04454556480050087]\n",
      "257 steps | score: [0.04407684877514839]\n",
      "258 steps | score: [0.018799541518092155]\n",
      "259 steps | score: [0.05745667964220047]\n",
      "260 steps | score: [0.0474824532866478]\n",
      "261 steps | score: [0.03990662470459938]\n",
      "262 steps | score: [0.03919105604290962]\n",
      "263 steps | score: [-0.00946558266878128]\n",
      "264 steps | score: [0.015828508883714676]\n",
      "265 steps | score: [0.06342092156410217]\n",
      "266 steps | score: [0.0549616739153862]\n",
      "267 steps | score: [0.015179865062236786]\n",
      "268 steps | score: [-0.008357226848602295]\n",
      "269 steps | score: [0.008195668458938599]\n",
      "270 steps | score: [0.02639281377196312]\n",
      "271 steps | score: [0.04824244603514671]\n",
      "272 steps | score: [0.06264284998178482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273 steps | score: [-0.02597793936729431]\n",
      "274 steps | score: [0.024449782446026802]\n",
      "275 steps | score: [0.01679632067680359]\n",
      "276 steps | score: [0.0008333530277013779]\n",
      "277 steps | score: [0.057054903358221054]\n",
      "278 steps | score: [-0.037568531930446625]\n",
      "279 steps | score: [0.05349735915660858]\n",
      "280 steps | score: [0.023959243670105934]\n",
      "281 steps | score: [0.014926321804523468]\n",
      "282 steps | score: [0.03855067119002342]\n",
      "283 steps | score: [0.0671711415052414]\n",
      "284 steps | score: [0.0706542432308197]\n",
      "285 steps | score: [0.02388918586075306]\n",
      "286 steps | score: [0.02325756475329399]\n",
      "287 steps | score: [0.019921734929084778]\n",
      "288 steps | score: [0.05201120302081108]\n",
      "289 steps | score: [0.02606736496090889]\n",
      "290 steps | score: [0.04196438565850258]\n",
      "291 steps | score: [0.04703817516565323]\n",
      "292 steps | score: [0.0074427779763937]\n",
      "293 steps | score: [0.018532728776335716]\n",
      "294 steps | score: [0.03266746550798416]\n",
      "295 steps | score: [0.04913664609193802]\n",
      "296 steps | score: [0.016563888639211655]\n",
      "297 steps | score: [0.020801272243261337]\n",
      "298 steps | score: [0.02212405949831009]\n",
      "299 steps | score: [0.04595984145998955]\n",
      "300 steps | score: [0.033184368163347244]\n",
      "301 steps | score: [0.05651940405368805]\n",
      "302 steps | score: [0.022296780720353127]\n",
      "303 steps | score: [0.011242546141147614]\n",
      "304 steps | score: [0.02692342735826969]\n",
      "305 steps | score: [0.07880360633134842]\n",
      "306 steps | score: [0.039709340780973434]\n",
      "307 steps | score: [0.025480329990386963]\n",
      "308 steps | score: [0.012864194810390472]\n",
      "309 steps | score: [0.021754510700702667]\n",
      "310 steps | score: [0.046334270387887955]\n",
      "311 steps | score: [0.005450502038002014]\n",
      "312 steps | score: [-0.01863555982708931]\n",
      "313 steps | score: [0.03045676089823246]\n",
      "314 steps | score: [0.05730609968304634]\n",
      "315 steps | score: [-0.016186174005270004]\n",
      "316 steps | score: [0.05691422522068024]\n",
      "317 steps | score: [0.030907178297638893]\n",
      "318 steps | score: [0.047809332609176636]\n",
      "319 steps | score: [0.09173861891031265]\n",
      "320 steps | score: [0.07428605109453201]\n",
      "321 steps | score: [0.09004287421703339]\n",
      "322 steps | score: [0.06202319636940956]\n",
      "323 steps | score: [0.048991549760103226]\n",
      "324 steps | score: [0.023858079686760902]\n",
      "325 steps | score: [0.033265989273786545]\n",
      "326 steps | score: [0.039460018277168274]\n",
      "327 steps | score: [0.0024634525179862976]\n",
      "328 steps | score: [0.015298105776309967]\n",
      "329 steps | score: [0.026142148301005363]\n",
      "330 steps | score: [0.007370121777057648]\n",
      "331 steps | score: [0.05836924538016319]\n",
      "332 steps | score: [0.07545886933803558]\n",
      "333 steps | score: [0.029159065335989]\n",
      "334 steps | score: [0.04067773371934891]\n",
      "335 steps | score: [0.015093818306922913]\n",
      "336 steps | score: [0.02972216159105301]\n",
      "337 steps | score: [0.05190166085958481]\n",
      "338 steps | score: [-0.0313892662525177]\n",
      "339 steps | score: [0.03273835778236389]\n",
      "340 steps | score: [0.02788430266082287]\n",
      "341 steps | score: [-0.00930088758468628]\n",
      "342 steps | score: [0.10057759284973145]\n",
      "343 steps | score: [0.002368684858083725]\n",
      "344 steps | score: [-0.026950504630804062]\n",
      "345 steps | score: [0.026828385889530182]\n",
      "346 steps | score: [0.042740415781736374]\n",
      "347 steps | score: [0.02159927785396576]\n",
      "348 steps | score: [-0.023805294185876846]\n",
      "349 steps | score: [0.04818784072995186]\n",
      "350 steps | score: [-0.009018894284963608]\n",
      "351 steps | score: [0.012570850551128387]\n",
      "352 steps | score: [-0.006405748426914215]\n",
      "353 steps | score: [0.06404829770326614]\n",
      "354 steps | score: [0.017689067870378494]\n",
      "355 steps | score: [0.0850137323141098]\n",
      "356 steps | score: [0.00869150459766388]\n",
      "357 steps | score: [0.014794226735830307]\n",
      "358 steps | score: [-0.01350976899266243]\n",
      "359 steps | score: [0.057853031903505325]\n",
      "360 steps | score: [-0.007869549095630646]\n",
      "361 steps | score: [0.06559770554304123]\n",
      "362 steps | score: [0.0354071743786335]\n",
      "363 steps | score: [-0.0007447116076946259]\n",
      "364 steps | score: [0.031779564917087555]\n",
      "365 steps | score: [0.058665938675403595]\n",
      "366 steps | score: [0.02939853072166443]\n",
      "367 steps | score: [-0.019749339669942856]\n",
      "368 steps | score: [0.014059804379940033]\n",
      "369 steps | score: [0.050333499908447266]\n",
      "370 steps | score: [0.03982117772102356]\n",
      "371 steps | score: [0.01547936163842678]\n",
      "372 steps | score: [0.03016652911901474]\n",
      "373 steps | score: [0.0017641764134168625]\n",
      "374 steps | score: [0.03126759082078934]\n",
      "375 steps | score: [0.10462164878845215]\n",
      "376 steps | score: [0.007286384701728821]\n",
      "377 steps | score: [-0.0036647766828536987]\n",
      "378 steps | score: [0.05381636694073677]\n",
      "379 steps | score: [0.05395297333598137]\n",
      "380 steps | score: [0.06316254287958145]\n",
      "381 steps | score: [0.045786529779434204]\n",
      "382 steps | score: [0.07573039829730988]\n",
      "383 steps | score: [0.021733064204454422]\n",
      "384 steps | score: [0.032442107796669006]\n",
      "385 steps | score: [0.08576478064060211]\n",
      "386 steps | score: [0.07770580053329468]\n",
      "387 steps | score: [0.032157085835933685]\n",
      "388 steps | score: [0.029106346890330315]\n",
      "389 steps | score: [0.011328425258398056]\n",
      "390 steps | score: [-0.005620807409286499]\n",
      "391 steps | score: [0.004515204578638077]\n",
      "392 steps | score: [-0.005795042961835861]\n",
      "393 steps | score: [0.07718789577484131]\n",
      "394 steps | score: [0.044883936643600464]\n",
      "395 steps | score: [-0.005444865673780441]\n",
      "396 steps | score: [0.05610772967338562]\n",
      "397 steps | score: [0.051939379423856735]\n",
      "398 steps | score: [-0.0036774948239326477]\n",
      "399 steps | score: [0.004878930747509003]\n",
      "400 steps | score: [0.04274078831076622]\n",
      "401 steps | score: [0.04392656311392784]\n",
      "402 steps | score: [0.01656811684370041]\n",
      "403 steps | score: [0.0723230391740799]\n",
      "404 steps | score: [0.04146670550107956]\n",
      "405 steps | score: [0.013003408908843994]\n",
      "406 steps | score: [0.019230887293815613]\n",
      "407 steps | score: [0.03783674165606499]\n",
      "408 steps | score: [0.05989013984799385]\n",
      "409 steps | score: [0.06446819752454758]\n",
      "410 steps | score: [0.007490672171115875]\n",
      "411 steps | score: [0.09479337930679321]\n",
      "412 steps | score: [0.04477740824222565]\n",
      "413 steps | score: [0.019228637218475342]\n",
      "414 steps | score: [0.0016860850155353546]\n",
      "415 steps | score: [0.02937469072639942]\n",
      "416 steps | score: [0.01377238892018795]\n",
      "417 steps | score: [0.007492907345294952]\n",
      "418 steps | score: [0.0029803551733493805]\n",
      "419 steps | score: [0.014962669461965561]\n",
      "420 steps | score: [0.0009236596524715424]\n",
      "421 steps | score: [0.06563872843980789]\n",
      "422 steps | score: [0.04812048375606537]\n",
      "423 steps | score: [0.015911288559436798]\n",
      "424 steps | score: [0.03885664790868759]\n",
      "425 steps | score: [0.014310486614704132]\n",
      "426 steps | score: [0.03000420331954956]\n",
      "427 steps | score: [0.10955245792865753]\n",
      "428 steps | score: [0.044194918125867844]\n",
      "429 steps | score: [0.03925284743309021]\n",
      "430 steps | score: [0.004487708210945129]\n",
      "431 steps | score: [0.025690028443932533]\n",
      "432 steps | score: [0.08596181869506836]\n",
      "433 steps | score: [-0.002535320818424225]\n",
      "434 steps | score: [0.03184198588132858]\n",
      "435 steps | score: [0.054766248911619186]\n",
      "436 steps | score: [0.002664707601070404]\n",
      "437 steps | score: [0.07228662818670273]\n",
      "438 steps | score: [0.03999992832541466]\n",
      "439 steps | score: [0.09296592324972153]\n",
      "440 steps | score: [0.01159648783504963]\n",
      "441 steps | score: [-0.02980842813849449]\n",
      "442 steps | score: [0.023348724469542503]\n",
      "443 steps | score: [-0.04410881921648979]\n",
      "444 steps | score: [0.058249037712812424]\n",
      "445 steps | score: [0.03881257027387619]\n",
      "446 steps | score: [0.060793664306402206]\n",
      "447 steps | score: [-0.01223253458738327]\n",
      "448 steps | score: [0.031190263107419014]\n",
      "449 steps | score: [0.008489951491355896]\n",
      "450 steps | score: [-0.002198096364736557]\n",
      "451 steps | score: [0.032352931797504425]\n",
      "452 steps | score: [-0.008131418377161026]\n",
      "453 steps | score: [0.016680248081684113]\n",
      "454 steps | score: [0.026722216978669167]\n",
      "455 steps | score: [0.0006018355488777161]\n",
      "456 steps | score: [-0.005501154810190201]\n",
      "457 steps | score: [0.03997361660003662]\n",
      "458 steps | score: [0.05861446261405945]\n",
      "459 steps | score: [0.10871495306491852]\n",
      "460 steps | score: [0.0438736267387867]\n",
      "461 steps | score: [0.008646674454212189]\n",
      "462 steps | score: [0.05141022056341171]\n",
      "463 steps | score: [0.09243320673704147]\n",
      "464 steps | score: [0.014243395999073982]\n",
      "465 steps | score: [-0.017236564308404922]\n",
      "466 steps | score: [0.060787782073020935]\n",
      "467 steps | score: [0.06099940463900566]\n",
      "468 steps | score: [0.04421386495232582]\n",
      "469 steps | score: [0.10312755405902863]\n",
      "470 steps | score: [0.040452610701322556]\n",
      "471 steps | score: [0.026232406497001648]\n",
      "472 steps | score: [0.038814984261989594]\n",
      "473 steps | score: [0.03470110893249512]\n",
      "474 steps | score: [0.04348398745059967]\n",
      "475 steps | score: [0.01825600117444992]\n",
      "476 steps | score: [0.020674413070082664]\n",
      "477 steps | score: [0.029646731913089752]\n",
      "478 steps | score: [0.008308902382850647]\n",
      "479 steps | score: [0.029370982199907303]\n",
      "480 steps | score: [0.02954457700252533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481 steps | score: [0.03362830728292465]\n",
      "482 steps | score: [0.03242761641740799]\n",
      "483 steps | score: [0.05110327526926994]\n",
      "484 steps | score: [0.0020140260457992554]\n",
      "485 steps | score: [0.021153971552848816]\n",
      "486 steps | score: [0.02494627982378006]\n",
      "487 steps | score: [0.023896321654319763]\n",
      "488 steps | score: [-0.011196300387382507]\n",
      "489 steps | score: [0.02521386556327343]\n",
      "490 steps | score: [0.03734341263771057]\n",
      "491 steps | score: [-0.03936251625418663]\n",
      "492 steps | score: [0.002857208251953125]\n",
      "493 steps | score: [0.04861506074666977]\n",
      "494 steps | score: [0.02275863289833069]\n",
      "495 steps | score: [0.00911550223827362]\n",
      "496 steps | score: [0.0574294812977314]\n",
      "497 steps | score: [0.03830121457576752]\n",
      "498 steps | score: [0.02008000575006008]\n",
      "499 steps | score: [-0.004075948148965836]\n",
      "500 steps | score: [0.03017093800008297]\n",
      "501 steps | score: [-0.010363306850194931]\n",
      "502 steps | score: [0.017443668097257614]\n",
      "503 steps | score: [0.007878076285123825]\n",
      "504 steps | score: [-0.006684970110654831]\n",
      "505 steps | score: [0.04113595187664032]\n",
      "506 steps | score: [0.07125679403543472]\n",
      "507 steps | score: [-0.013863541185855865]\n",
      "508 steps | score: [0.04521472007036209]\n",
      "509 steps | score: [-0.02299879863858223]\n",
      "510 steps | score: [0.015034407377243042]\n",
      "511 steps | score: [0.04689454287290573]\n",
      "512 steps | score: [0.011965131387114525]\n",
      "513 steps | score: [0.06541229039430618]\n",
      "514 steps | score: [-0.024898085743188858]\n",
      "515 steps | score: [0.011082060635089874]\n",
      "516 steps | score: [0.0342332124710083]\n",
      "517 steps | score: [0.046287138015031815]\n",
      "518 steps | score: [0.0279310904443264]\n",
      "519 steps | score: [-0.022502049803733826]\n",
      "520 steps | score: [-0.0012699626386165619]\n",
      "521 steps | score: [0.060211777687072754]\n",
      "522 steps | score: [0.02402281016111374]\n",
      "523 steps | score: [0.02095510996878147]\n",
      "524 steps | score: [-0.009000640362501144]\n",
      "525 steps | score: [0.013782963156700134]\n",
      "526 steps | score: [-0.03533697873353958]\n",
      "527 steps | score: [0.01979614794254303]\n",
      "528 steps | score: [0.0545843243598938]\n",
      "529 steps | score: [-0.016083508729934692]\n",
      "530 steps | score: [0.043099015951156616]\n",
      "531 steps | score: [-0.03078782558441162]\n",
      "532 steps | score: [0.04415828734636307]\n",
      "533 steps | score: [0.012882933020591736]\n",
      "534 steps | score: [0.02292799949645996]\n",
      "535 steps | score: [0.020999882370233536]\n",
      "536 steps | score: [-0.012393675744533539]\n",
      "537 steps | score: [0.02808169648051262]\n",
      "538 steps | score: [0.01767073944211006]\n",
      "539 steps | score: [0.03406322002410889]\n",
      "540 steps | score: [-0.012463565915822983]\n",
      "541 steps | score: [0.02300417795777321]\n",
      "542 steps | score: [0.0662304162979126]\n",
      "543 steps | score: [0.03738037124276161]\n",
      "544 steps | score: [-0.00690377876162529]\n",
      "545 steps | score: [0.0730944573879242]\n",
      "546 steps | score: [0.06189925968647003]\n",
      "547 steps | score: [0.061075303703546524]\n",
      "548 steps | score: [0.017229877412319183]\n",
      "549 steps | score: [-0.008156798779964447]\n",
      "550 steps | score: [-0.04560612887144089]\n",
      "551 steps | score: [0.0725887268781662]\n",
      "552 steps | score: [0.03651801869273186]\n",
      "553 steps | score: [0.006883513182401657]\n",
      "554 steps | score: [0.05144172161817551]\n",
      "555 steps | score: [0.04575109854340553]\n",
      "556 steps | score: [0.0005018636584281921]\n",
      "557 steps | score: [0.0683785229921341]\n",
      "558 steps | score: [0.02896900847554207]\n",
      "559 steps | score: [0.056366272270679474]\n",
      "560 steps | score: [0.022423705086112022]\n",
      "561 steps | score: [0.0424104779958725]\n",
      "562 steps | score: [0.02326754853129387]\n",
      "563 steps | score: [0.08769223093986511]\n",
      "564 steps | score: [0.06283736228942871]\n",
      "565 steps | score: [0.03521692007780075]\n",
      "566 steps | score: [0.05082567781209946]\n",
      "567 steps | score: [0.04917047545313835]\n",
      "568 steps | score: [0.029732856899499893]\n",
      "569 steps | score: [0.0816950649023056]\n",
      "570 steps | score: [0.06428754329681396]\n",
      "571 steps | score: [0.01753278821706772]\n",
      "572 steps | score: [0.023472987115383148]\n",
      "573 steps | score: [0.0627397894859314]\n",
      "574 steps | score: [0.048507776111364365]\n",
      "575 steps | score: [0.019602082669734955]\n",
      "576 steps | score: [0.034434568136930466]\n",
      "577 steps | score: [0.04893980920314789]\n",
      "578 steps | score: [0.010149376466870308]\n",
      "579 steps | score: [0.09178872406482697]\n",
      "580 steps | score: [0.058625586330890656]\n",
      "581 steps | score: [0.024020982906222343]\n",
      "582 steps | score: [0.03398382291197777]\n",
      "583 steps | score: [0.04537728428840637]\n",
      "584 steps | score: [0.06365208327770233]\n",
      "585 steps | score: [0.005299467593431473]\n",
      "586 steps | score: [0.05952289700508118]\n",
      "587 steps | score: [-0.020444296300411224]\n",
      "588 steps | score: [-0.010745532810688019]\n",
      "589 steps | score: [0.03274787589907646]\n",
      "590 steps | score: [0.015040256083011627]\n",
      "591 steps | score: [0.021063603460788727]\n",
      "592 steps | score: [0.03115827776491642]\n",
      "593 steps | score: [0.01709805801510811]\n",
      "594 steps | score: [0.025624839588999748]\n",
      "595 steps | score: [0.01955910213291645]\n",
      "596 steps | score: [0.050852399319410324]\n",
      "597 steps | score: [-0.0024414844810962677]\n",
      "598 steps | score: [0.03375570848584175]\n",
      "599 steps | score: [0.022769086062908173]\n",
      "600 steps | score: [0.06587247550487518]\n",
      "601 steps | score: [-0.01302383467555046]\n",
      "602 steps | score: [0.015961773693561554]\n",
      "603 steps | score: [0.0427592433989048]\n",
      "604 steps | score: [0.0013254955410957336]\n",
      "605 steps | score: [0.07114183157682419]\n",
      "606 steps | score: [0.017982732504606247]\n",
      "607 steps | score: [0.053327273577451706]\n",
      "608 steps | score: [0.03452969714999199]\n",
      "609 steps | score: [0.010905127972364426]\n",
      "610 steps | score: [0.026430951431393623]\n",
      "611 steps | score: [0.04242287576198578]\n",
      "612 steps | score: [0.03324068337678909]\n",
      "613 steps | score: [0.04413379728794098]\n",
      "614 steps | score: [0.016408585011959076]\n",
      "615 steps | score: [0.005514331161975861]\n",
      "616 steps | score: [0.04950443655252457]\n",
      "617 steps | score: [0.05903485044836998]\n",
      "618 steps | score: [0.022115236148238182]\n",
      "619 steps | score: [0.01742498204112053]\n",
      "620 steps | score: [0.07241197675466537]\n",
      "621 steps | score: [0.040438223630189896]\n",
      "622 steps | score: [0.07705999910831451]\n",
      "623 steps | score: [0.05496397614479065]\n",
      "624 steps | score: [0.0845644474029541]\n",
      "625 steps | score: [0.042095083743333817]\n",
      "626 steps | score: [0.032918862998485565]\n",
      "627 steps | score: [0.0424739308655262]\n",
      "628 steps | score: [0.0399932786822319]\n",
      "629 steps | score: [0.031122390180826187]\n",
      "630 steps | score: [0.03219108283519745]\n",
      "631 steps | score: [0.040658287703990936]\n",
      "632 steps | score: [0.0647604689002037]\n",
      "633 steps | score: [-0.0047726258635520935]\n",
      "634 steps | score: [0.019367825239896774]\n",
      "635 steps | score: [0.02793867513537407]\n",
      "636 steps | score: [0.06148742884397507]\n",
      "637 steps | score: [0.016069497913122177]\n",
      "638 steps | score: [-0.0068351514637470245]\n",
      "639 steps | score: [0.018838362768292427]\n",
      "640 steps | score: [0.0695890411734581]\n",
      "641 steps | score: [0.03526211902499199]\n",
      "642 steps | score: [0.10034915804862976]\n",
      "643 steps | score: [0.020742490887641907]\n",
      "644 steps | score: [0.03499418869614601]\n",
      "645 steps | score: [0.0044632479548454285]\n",
      "646 steps | score: [0.05052259936928749]\n",
      "647 steps | score: [0.0509735643863678]\n",
      "648 steps | score: [-0.02084360644221306]\n",
      "649 steps | score: [-0.012219421565532684]\n",
      "650 steps | score: [0.0056812576949596405]\n",
      "651 steps | score: [-0.013588044792413712]\n",
      "652 steps | score: [0.024566637352108955]\n",
      "653 steps | score: [0.0022905953228473663]\n",
      "654 steps | score: [0.07452619075775146]\n",
      "655 steps | score: [0.056406378746032715]\n",
      "656 steps | score: [0.007005900144577026]\n",
      "657 steps | score: [0.03231319040060043]\n",
      "658 steps | score: [0.0045595839619636536]\n",
      "659 steps | score: [0.09057709574699402]\n",
      "660 steps | score: [0.01760469749569893]\n",
      "661 steps | score: [0.014979926869273186]\n",
      "662 steps | score: [0.016188915818929672]\n",
      "663 steps | score: [0.03395095467567444]\n",
      "664 steps | score: [-0.005299162119626999]\n",
      "665 steps | score: [0.04826835170388222]\n",
      "666 steps | score: [0.018692869693040848]\n",
      "667 steps | score: [0.011225223541259766]\n",
      "668 steps | score: [0.07691040635108948]\n",
      "669 steps | score: [0.019059371203184128]\n",
      "670 steps | score: [-0.00011339783668518066]\n",
      "671 steps | score: [-0.014973923563957214]\n",
      "672 steps | score: [0.02741524949669838]\n",
      "673 steps | score: [-0.03201163932681084]\n",
      "674 steps | score: [0.05067409574985504]\n",
      "675 steps | score: [0.042726948857307434]\n",
      "676 steps | score: [0.10830894112586975]\n",
      "677 steps | score: [-0.0003119036555290222]\n",
      "678 steps | score: [0.03183098882436752]\n",
      "679 steps | score: [0.03484133630990982]\n",
      "680 steps | score: [0.012790771201252937]\n",
      "681 steps | score: [0.01298530399799347]\n",
      "682 steps | score: [0.006345678120851517]\n",
      "683 steps | score: [0.03816213086247444]\n",
      "684 steps | score: [-0.0049968622624874115]\n",
      "685 steps | score: [0.015595383942127228]\n",
      "686 steps | score: [0.03634806349873543]\n",
      "687 steps | score: [-0.05243830010294914]\n",
      "688 steps | score: [0.0467364527285099]\n",
      "689 steps | score: [0.056339941918849945]\n",
      "690 steps | score: [0.014303244650363922]\n",
      "691 steps | score: [0.03488670662045479]\n",
      "692 steps | score: [0.02162107452750206]\n",
      "693 steps | score: [0.04164205491542816]\n",
      "694 steps | score: [0.04200400039553642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695 steps | score: [0.042436759918928146]\n",
      "696 steps | score: [0.03614497929811478]\n",
      "697 steps | score: [0.02266758307814598]\n",
      "698 steps | score: [-0.016355715692043304]\n",
      "699 steps | score: [-0.0021387040615081787]\n",
      "700 steps | score: [0.07268598675727844]\n",
      "701 steps | score: [0.027193276211619377]\n",
      "702 steps | score: [0.02192355878651142]\n",
      "703 steps | score: [0.058335911482572556]\n",
      "704 steps | score: [0.04199270159006119]\n",
      "705 steps | score: [0.050817206501960754]\n",
      "706 steps | score: [0.050887856632471085]\n",
      "707 steps | score: [0.030434057116508484]\n",
      "708 steps | score: [0.03620852530002594]\n",
      "709 steps | score: [0.02891785278916359]\n",
      "710 steps | score: [0.027724657207727432]\n",
      "711 steps | score: [0.010398704558610916]\n",
      "712 steps | score: [0.09271533042192459]\n",
      "713 steps | score: [0.01701303757727146]\n",
      "714 steps | score: [0.022657616063952446]\n",
      "715 steps | score: [0.038127101957798004]\n",
      "716 steps | score: [0.05423532426357269]\n",
      "717 steps | score: [-0.018958404660224915]\n",
      "718 steps | score: [-0.0036770887672901154]\n",
      "719 steps | score: [0.0340099036693573]\n",
      "720 steps | score: [0.02904011867940426]\n",
      "721 steps | score: [0.005382765084505081]\n",
      "722 steps | score: [0.04133820906281471]\n",
      "723 steps | score: [0.07981845736503601]\n",
      "724 steps | score: [0.04165294021368027]\n",
      "725 steps | score: [0.04640987515449524]\n",
      "726 steps | score: [0.04862309247255325]\n",
      "727 steps | score: [0.019466781988739967]\n",
      "728 steps | score: [0.058240652084350586]\n",
      "729 steps | score: [0.010634053498506546]\n",
      "730 steps | score: [-0.0339752621948719]\n",
      "731 steps | score: [0.028536610305309296]\n",
      "732 steps | score: [0.042922571301460266]\n",
      "733 steps | score: [0.008651291951537132]\n",
      "734 steps | score: [0.0456562265753746]\n",
      "735 steps | score: [0.010709669440984726]\n",
      "736 steps | score: [0.023957904428243637]\n",
      "737 steps | score: [0.038861896842718124]\n",
      "738 steps | score: [0.05855982378125191]\n",
      "739 steps | score: [0.03856710344552994]\n",
      "740 steps | score: [0.06925925612449646]\n",
      "741 steps | score: [0.018182458356022835]\n",
      "742 steps | score: [0.000670943409204483]\n",
      "743 steps | score: [0.0506606325507164]\n",
      "744 steps | score: [-0.007502906024456024]\n",
      "745 steps | score: [0.06292285025119781]\n",
      "746 steps | score: [0.029022106900811195]\n",
      "747 steps | score: [0.08288173377513885]\n",
      "748 steps | score: [0.052706070244312286]\n",
      "749 steps | score: [0.013502759858965874]\n",
      "750 steps | score: [0.030851731076836586]\n",
      "751 steps | score: [0.030893487855792046]\n",
      "752 steps | score: [0.06399339437484741]\n",
      "753 steps | score: [0.01656825840473175]\n",
      "754 steps | score: [0.001309916377067566]\n",
      "755 steps | score: [0.05690687894821167]\n",
      "756 steps | score: [0.010105520486831665]\n",
      "757 steps | score: [0.01998046040534973]\n",
      "758 steps | score: [0.05911720544099808]\n",
      "759 steps | score: [0.05633540451526642]\n",
      "760 steps | score: [0.026125917211174965]\n",
      "761 steps | score: [0.030859850347042084]\n",
      "762 steps | score: [0.03242199867963791]\n",
      "763 steps | score: [0.06633216142654419]\n",
      "764 steps | score: [-0.00820963829755783]\n",
      "765 steps | score: [0.023381423205137253]\n",
      "766 steps | score: [0.047481708228588104]\n",
      "767 steps | score: [0.00665292888879776]\n",
      "768 steps | score: [0.058518219739198685]\n",
      "769 steps | score: [0.01234627515077591]\n",
      "770 steps | score: [0.06528230011463165]\n",
      "771 steps | score: [0.023218568414449692]\n",
      "772 steps | score: [0.019421260803937912]\n",
      "773 steps | score: [0.021781189367175102]\n",
      "774 steps | score: [0.014183573424816132]\n",
      "775 steps | score: [0.04637381434440613]\n",
      "776 steps | score: [-0.007063224911689758]\n",
      "777 steps | score: [0.04108281061053276]\n",
      "778 steps | score: [-0.04947545379400253]\n",
      "779 steps | score: [0.02992713823914528]\n",
      "780 steps | score: [0.015560697764158249]\n",
      "781 steps | score: [0.005489509552717209]\n",
      "782 steps | score: [0.07650984078645706]\n",
      "783 steps | score: [-0.018660716712474823]\n",
      "784 steps | score: [0.045409686863422394]\n",
      "785 steps | score: [0.027286235243082047]\n",
      "786 steps | score: [0.0872669517993927]\n",
      "787 steps | score: [0.07652641087770462]\n",
      "788 steps | score: [0.0684184581041336]\n",
      "789 steps | score: [0.02193167246878147]\n",
      "790 steps | score: [0.035638757050037384]\n",
      "791 steps | score: [0.06653483211994171]\n",
      "792 steps | score: [0.021686013787984848]\n",
      "793 steps | score: [0.023937076330184937]\n",
      "794 steps | score: [-0.024890489876270294]\n",
      "795 steps | score: [0.04821360856294632]\n",
      "796 steps | score: [-0.011552974581718445]\n",
      "797 steps | score: [0.010196760296821594]\n",
      "798 steps | score: [0.056456584483385086]\n",
      "799 steps | score: [0.028376448899507523]\n",
      "800 steps | score: [0.03959997743368149]\n",
      "801 steps | score: [0.06208718195557594]\n",
      "802 steps | score: [-0.010290931910276413]\n",
      "803 steps | score: [-0.011735856533050537]\n",
      "804 steps | score: [-0.006406038999557495]\n",
      "805 steps | score: [0.0475541353225708]\n",
      "806 steps | score: [0.04338286072015762]\n",
      "807 steps | score: [0.06804484128952026]\n",
      "808 steps | score: [0.03730153664946556]\n",
      "809 steps | score: [0.041486285626888275]\n",
      "810 steps | score: [0.01033322885632515]\n",
      "811 steps | score: [-0.01812736876308918]\n",
      "812 steps | score: [0.07026451826095581]\n",
      "813 steps | score: [-0.010244134813547134]\n",
      "814 steps | score: [-0.0416928306221962]\n",
      "815 steps | score: [0.03448818251490593]\n",
      "816 steps | score: [-0.0024620220065116882]\n",
      "817 steps | score: [0.06383690983057022]\n",
      "818 steps | score: [-0.012925751507282257]\n",
      "819 steps | score: [-0.003989402204751968]\n",
      "820 steps | score: [0.005360383540391922]\n",
      "821 steps | score: [-0.005288396030664444]\n",
      "822 steps | score: [0.009780511260032654]\n",
      "823 steps | score: [0.024725724011659622]\n",
      "824 steps | score: [0.019330177456140518]\n",
      "825 steps | score: [0.00689571350812912]\n",
      "826 steps | score: [0.016247129067778587]\n",
      "827 steps | score: [0.052729327231645584]\n",
      "828 steps | score: [0.027836203575134277]\n",
      "829 steps | score: [0.005345731973648071]\n",
      "830 steps | score: [0.0273739006370306]\n",
      "831 steps | score: [0.018678918480873108]\n",
      "832 steps | score: [0.02484617941081524]\n",
      "833 steps | score: [0.060620568692684174]\n",
      "834 steps | score: [0.0829600915312767]\n",
      "835 steps | score: [0.029463892802596092]\n",
      "836 steps | score: [0.02276056632399559]\n",
      "837 steps | score: [0.031151562929153442]\n",
      "838 steps | score: [0.06548544764518738]\n",
      "839 steps | score: [-0.008147232234477997]\n",
      "840 steps | score: [0.03772563114762306]\n",
      "841 steps | score: [0.05014549940824509]\n",
      "842 steps | score: [0.014414962381124496]\n",
      "843 steps | score: [0.01298825815320015]\n",
      "844 steps | score: [0.027546560391783714]\n",
      "845 steps | score: [0.012591086328029633]\n",
      "846 steps | score: [0.027929086238145828]\n",
      "847 steps | score: [0.011810850352048874]\n",
      "848 steps | score: [0.02649134211242199]\n",
      "849 steps | score: [0.04356694221496582]\n",
      "850 steps | score: [0.04665644094347954]\n",
      "851 steps | score: [-0.002548854798078537]\n",
      "852 steps | score: [-0.0050038546323776245]\n",
      "853 steps | score: [0.00965820625424385]\n",
      "854 steps | score: [0.02933342382311821]\n",
      "855 steps | score: [0.0296767670661211]\n",
      "856 steps | score: [0.04527838155627251]\n",
      "857 steps | score: [0.01717602275311947]\n",
      "858 steps | score: [0.03218211606144905]\n",
      "859 steps | score: [0.03568824380636215]\n",
      "860 steps | score: [0.013975769281387329]\n",
      "861 steps | score: [0.013711337000131607]\n",
      "862 steps | score: [0.010587427765130997]\n",
      "863 steps | score: [0.0035004429519176483]\n",
      "864 steps | score: [0.05717482417821884]\n",
      "865 steps | score: [0.018765561282634735]\n",
      "866 steps | score: [0.003775138407945633]\n",
      "867 steps | score: [0.032421186566352844]\n",
      "868 steps | score: [-0.01956634223461151]\n",
      "869 steps | score: [0.08601564168930054]\n",
      "870 steps | score: [0.039766497910022736]\n",
      "871 steps | score: [0.0013310834765434265]\n",
      "872 steps | score: [-0.00519818440079689]\n",
      "873 steps | score: [0.02962527424097061]\n",
      "874 steps | score: [0.07506107538938522]\n",
      "875 steps | score: [0.02376316487789154]\n",
      "876 steps | score: [0.058768875896930695]\n",
      "877 steps | score: [0.02185974270105362]\n",
      "878 steps | score: [0.049856580793857574]\n",
      "879 steps | score: [-0.005773436278104782]\n",
      "880 steps | score: [0.07544717937707901]\n",
      "881 steps | score: [0.05382419377565384]\n",
      "882 steps | score: [0.03333747386932373]\n",
      "883 steps | score: [-0.0019367001950740814]\n",
      "884 steps | score: [0.011492226272821426]\n",
      "885 steps | score: [0.06746460497379303]\n",
      "886 steps | score: [0.05080558359622955]\n",
      "887 steps | score: [-0.004308659583330154]\n",
      "888 steps | score: [0.058875299990177155]\n",
      "889 steps | score: [0.0380915030837059]\n",
      "890 steps | score: [0.01085193082690239]\n",
      "891 steps | score: [0.01928834617137909]\n",
      "892 steps | score: [0.0028743185102939606]\n",
      "893 steps | score: [0.027425222098827362]\n",
      "894 steps | score: [-0.07424885034561157]\n",
      "895 steps | score: [0.028350042179226875]\n",
      "896 steps | score: [0.05150303989648819]\n",
      "897 steps | score: [0.02895932085812092]\n",
      "898 steps | score: [0.02792648784816265]\n",
      "899 steps | score: [0.04892158880829811]\n",
      "900 steps | score: [-0.0006891041994094849]\n",
      "901 steps | score: [0.037662990391254425]\n",
      "902 steps | score: [0.06523620337247849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903 steps | score: [0.04355330765247345]\n",
      "904 steps | score: [0.01662503182888031]\n",
      "905 steps | score: [0.02281426079571247]\n",
      "906 steps | score: [-0.012518681585788727]\n",
      "907 steps | score: [0.03886164724826813]\n",
      "908 steps | score: [0.03609493374824524]\n",
      "909 steps | score: [0.05443263053894043]\n",
      "910 steps | score: [-0.003424406051635742]\n",
      "911 steps | score: [-0.017703909426927567]\n",
      "912 steps | score: [0.05033386871218681]\n",
      "913 steps | score: [0.039386823773384094]\n",
      "914 steps | score: [0.006775885820388794]\n",
      "915 steps | score: [0.057025518268346786]\n",
      "916 steps | score: [-0.0023002997040748596]\n",
      "917 steps | score: [0.037724047899246216]\n",
      "918 steps | score: [0.008647460490465164]\n",
      "919 steps | score: [0.050553034991025925]\n",
      "920 steps | score: [0.06465011090040207]\n",
      "921 steps | score: [0.03931897506117821]\n",
      "922 steps | score: [0.030704814940690994]\n",
      "923 steps | score: [0.023311646655201912]\n",
      "924 steps | score: [0.07336388528347015]\n",
      "925 steps | score: [0.0414448082447052]\n",
      "926 steps | score: [0.023537738248705864]\n",
      "927 steps | score: [0.07910522818565369]\n",
      "928 steps | score: [0.05233002081513405]\n",
      "929 steps | score: [0.027451839298009872]\n",
      "930 steps | score: [0.037897177040576935]\n",
      "931 steps | score: [0.04696325585246086]\n",
      "932 steps | score: [0.016797814518213272]\n",
      "933 steps | score: [0.009321961551904678]\n",
      "934 steps | score: [0.01853960193693638]\n",
      "935 steps | score: [0.04223916679620743]\n",
      "936 steps | score: [-0.0070657432079315186]\n",
      "937 steps | score: [0.0018940344452857971]\n",
      "938 steps | score: [0.0022292248904705048]\n",
      "939 steps | score: [0.00260007381439209]\n",
      "940 steps | score: [0.02807142585515976]\n",
      "941 steps | score: [-0.030183427035808563]\n",
      "942 steps | score: [0.011266961693763733]\n",
      "943 steps | score: [0.017115261405706406]\n",
      "944 steps | score: [0.02171720191836357]\n",
      "945 steps | score: [0.032253921031951904]\n",
      "946 steps | score: [-0.03792988508939743]\n",
      "947 steps | score: [0.038350921124219894]\n",
      "948 steps | score: [0.01952524483203888]\n",
      "949 steps | score: [0.018556753173470497]\n",
      "950 steps | score: [-0.01448061689734459]\n",
      "951 steps | score: [0.0005047395825386047]\n",
      "952 steps | score: [0.09798789769411087]\n",
      "953 steps | score: [0.03008906915783882]\n",
      "954 steps | score: [0.03743062540888786]\n",
      "955 steps | score: [0.019073987379670143]\n",
      "956 steps | score: [0.03472784906625748]\n",
      "957 steps | score: [-0.013535924255847931]\n",
      "958 steps | score: [0.04099614545702934]\n",
      "959 steps | score: [0.008763067424297333]\n",
      "960 steps | score: [0.027440955862402916]\n",
      "961 steps | score: [-0.01619984582066536]\n",
      "962 steps | score: [0.023304585367441177]\n",
      "963 steps | score: [0.002194385975599289]\n",
      "964 steps | score: [-0.0066253431141376495]\n",
      "965 steps | score: [0.011658791452646255]\n",
      "966 steps | score: [0.009297490119934082]\n",
      "967 steps | score: [-0.022384800016880035]\n",
      "968 steps | score: [0.019252527505159378]\n",
      "969 steps | score: [0.03881620243191719]\n",
      "970 steps | score: [0.05924190208315849]\n",
      "971 steps | score: [0.06881950795650482]\n",
      "972 steps | score: [0.020061716437339783]\n",
      "973 steps | score: [0.04329945892095566]\n",
      "974 steps | score: [0.011237125843763351]\n",
      "975 steps | score: [0.07066001743078232]\n",
      "976 steps | score: [0.05941128730773926]\n",
      "977 steps | score: [0.006284352391958237]\n",
      "978 steps | score: [0.009754665195941925]\n",
      "979 steps | score: [0.024770479649305344]\n",
      "980 steps | score: [0.04153852164745331]\n",
      "981 steps | score: [0.01613859087228775]\n",
      "982 steps | score: [0.032239049673080444]\n",
      "983 steps | score: [-0.015617694705724716]\n",
      "984 steps | score: [0.03551459684967995]\n",
      "985 steps | score: [0.03590957447886467]\n",
      "986 steps | score: [-0.002752058207988739]\n",
      "987 steps | score: [0.043862178921699524]\n",
      "988 steps | score: [0.017422527074813843]\n",
      "989 steps | score: [0.023670360445976257]\n",
      "990 steps | score: [0.04287780821323395]\n",
      "991 steps | score: [-0.009283596649765968]\n",
      "992 steps | score: [0.008888322860002518]\n",
      "993 steps | score: [0.030229946598410606]\n",
      "994 steps | score: [0.08478522300720215]\n",
      "995 steps | score: [0.0179756972938776]\n",
      "996 steps | score: [0.004114408046007156]\n",
      "997 steps | score: [0.0120757557451725]\n",
      "998 steps | score: [-0.009046729654073715]\n",
      "999 steps | score: [0.023238908499479294]\n",
      "1000 steps | score: [0.06449675559997559]\n",
      "1001 steps | score: [0.004301615059375763]\n",
      "1002 steps | score: [0.04076123610138893]\n"
     ]
    }
   ],
   "source": [
    "trunc_reg = TruncatedRegression(phi=phi, alpha=alpha, bias=args.bias, unknown=False, val=10, bs=100, n=1, tol=1e-2)\n",
    "known_res = trunc_reg.fit(x_trunc_norm, stand_y_trunc)\n",
    "known_weight_unnorm = (known_res.weight * ch.sqrt(noise_var)) / beta\n",
    "\n",
    "known_bias_unnorm = ch.zeros(1, 1)\n",
    "if args.bias:  \n",
    "    known_bias_unnorm = known_res.bias * ch.sqrt(noise_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(new_X, stand_noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc_norm, stand_y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(norm_data, trunc_stand_ols.predict(norm_data), color='r', label='ols')\n",
    "plt.plot(norm_data, gt_stand.predict(norm_data), color='green', label='gt')\n",
    "plt.plot(norm_data, known_res(Tensor(norm_data)).detach().numpy(), label='known', color='blue')\n",
    "plt.legend()\n",
    "plt.title(\"Known Noise Variance - Normalized\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(X, noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc, y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(unnorm_data, trunc_ols.predict(unnorm_data), color='r', label='ols')\n",
    "plt.plot(unnorm_data, gt_ols.predict(unnorm_data), color='green', label='gt')\n",
    "plt.plot(unnorm_data, (Tensor(unnorm_data)@known_weight_unnorm + known_bias_unnorm).detach().numpy(), label='known', color='blue')\n",
    "plt.legend()\n",
    "plt.title(\"Known Noise Variance - UnNormalized\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncated Regression with Unknown Noise Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 steps | score: [0.07770762592554092, -0.111968033015728]\n",
      "10 steps | score: [-0.015211671590805054, 0.10884328186511993]\n",
      "20 steps | score: [-0.03479945659637451, 0.15274977684020996]\n",
      "30 steps | score: [-0.0038830898702144623, 0.03264313191175461]\n",
      "40 steps | score: [-0.043718915432691574, 0.1272171437740326]\n",
      "50 steps | score: [-0.04175432771444321, 0.10144871473312378]\n",
      "60 steps | score: [0.05597959831357002, -0.12434219568967819]\n",
      "70 steps | score: [-0.026684921234846115, 0.10233378410339355]\n",
      "80 steps | score: [-0.03361361473798752, 0.07169242948293686]\n",
      "90 steps | score: [0.05024251714348793, -0.10881216824054718]\n",
      "100 steps | score: [-0.09872782230377197, 0.19719107449054718]\n",
      "110 steps | score: [-0.07058897614479065, 0.17554223537445068]\n",
      "120 steps | score: [-0.014901414513587952, 0.018000751733779907]\n",
      "130 steps | score: [-0.07098206877708435, 0.1597038209438324]\n",
      "140 steps | score: [-0.008060965687036514, -0.021449148654937744]\n",
      "150 steps | score: [0.01843872293829918, -0.06233038753271103]\n",
      "160 steps | score: [-0.04895247146487236, 0.10068373382091522]\n",
      "170 steps | score: [-0.013795435428619385, -0.003680497407913208]\n",
      "180 steps | score: [0.013341695070266724, -0.07309997081756592]\n",
      "190 steps | score: [-0.10985228419303894, 0.216348797082901]\n",
      "200 steps | score: [-0.007866725325584412, -0.03125286102294922]\n",
      "210 steps | score: [0.014380890876054764, -0.09335078299045563]\n",
      "220 steps | score: [-0.09875296801328659, 0.21226567029953003]\n",
      "230 steps | score: [-0.0838228315114975, 0.12711217999458313]\n",
      "240 steps | score: [0.0217190720140934, -0.1040637195110321]\n",
      "250 steps | score: [-0.10322952270507812, 0.24968090653419495]\n",
      "260 steps | score: [-0.05098176747560501, 0.07341562211513519]\n",
      "270 steps | score: [-0.01967857964336872, -0.0028767362236976624]\n",
      "280 steps | score: [-0.0795978307723999, 0.1813851147890091]\n",
      "290 steps | score: [-0.08867921680212021, 0.21073192358016968]\n",
      "300 steps | score: [-0.018095090985298157, -0.032751694321632385]\n",
      "310 steps | score: [-0.1225493773818016, 0.3209547996520996]\n",
      "320 steps | score: [-0.055330611765384674, 0.06004374101758003]\n",
      "330 steps | score: [-0.006670929491519928, -0.08937616646289825]\n",
      "340 steps | score: [-0.06298801302909851, 0.13955268263816833]\n",
      "350 steps | score: [-0.035291001200675964, 0.06973134726285934]\n",
      "360 steps | score: [-0.018689017742872238, -0.034045420587062836]\n",
      "370 steps | score: [-0.08418116718530655, 0.15627729892730713]\n",
      "380 steps | score: [-0.05262574553489685, 0.09933891892433167]\n",
      "390 steps | score: [-0.03955487906932831, 0.03456266224384308]\n",
      "400 steps | score: [-0.10429492592811584, 0.2378442883491516]\n",
      "410 steps | score: [-0.056831322610378265, 0.12334395945072174]\n",
      "420 steps | score: [-0.057145923376083374, 0.11161138117313385]\n",
      "430 steps | score: [-0.08688832819461823, 0.19038891792297363]\n",
      "440 steps | score: [-0.023679083213210106, -0.05460614711046219]\n",
      "450 steps | score: [-0.030015356838703156, -0.017014488577842712]\n",
      "460 steps | score: [-0.09797780960798264, 0.2354314774274826]\n",
      "470 steps | score: [-0.05021439120173454, 0.08107039332389832]\n",
      "480 steps | score: [-0.028026895597577095, 0.041255202144384384]\n",
      "490 steps | score: [-0.09143656492233276, 0.23057258129119873]\n",
      "500 steps | score: [-0.05675698071718216, 0.0984235629439354]\n",
      "510 steps | score: [-0.047313444316387177, 0.059824131429195404]\n",
      "520 steps | score: [-0.08814527094364166, 0.1853559911251068]\n",
      "530 steps | score: [-0.015055209398269653, -0.01805482804775238]\n",
      "540 steps | score: [-0.0041277483105659485, -0.12233083695173264]\n",
      "550 steps | score: [-0.024835992604494095, 0.01302500069141388]\n",
      "560 steps | score: [-0.04941484332084656, 0.03392284736037254]\n",
      "570 steps | score: [-0.07660456001758575, 0.11334890127182007]\n",
      "580 steps | score: [-0.0911368578672409, 0.2019517570734024]\n",
      "590 steps | score: [-0.07269230484962463, 0.13489659130573273]\n",
      "600 steps | score: [-0.005126208066940308, -0.09008079767227173]\n",
      "610 steps | score: [-0.09112212061882019, 0.203960120677948]\n",
      "620 steps | score: [-0.06822974979877472, 0.1663704514503479]\n",
      "630 steps | score: [0.013755302876234055, -0.16628500819206238]\n",
      "640 steps | score: [-0.07322843372821808, 0.13034015893936157]\n",
      "650 steps | score: [0.001806691288948059, -0.06690209358930588]\n",
      "660 steps | score: [-0.028042281046509743, 0.02744004875421524]\n",
      "670 steps | score: [-0.0982012078166008, 0.22673776745796204]\n",
      "680 steps | score: [-0.02521044760942459, -0.013288542628288269]\n",
      "690 steps | score: [0.02412702515721321, -0.22507941722869873]\n",
      "700 steps | score: [-0.06384878605604172, 0.14965376257896423]\n",
      "710 steps | score: [-0.02215200662612915, -0.009798988699913025]\n",
      "720 steps | score: [-0.04275977239012718, 0.08549147844314575]\n",
      "730 steps | score: [-0.05009744316339493, 0.052277885377407074]\n",
      "740 steps | score: [-0.019972123205661774, -0.008367523550987244]\n",
      "750 steps | score: [-0.05078564211726189, 0.10366546362638474]\n",
      "760 steps | score: [-0.06712835282087326, 0.10207457840442657]\n",
      "770 steps | score: [-0.03534384071826935, 0.02037063241004944]\n",
      "780 steps | score: [-0.002250123769044876, -0.07384398579597473]\n",
      "790 steps | score: [-0.04851025342941284, 0.047511808574199677]\n",
      "800 steps | score: [-0.02487998455762863, -0.05187632888555527]\n",
      "810 steps | score: [-0.037773240357637405, 0.04930813983082771]\n",
      "820 steps | score: [-0.06507986783981323, 0.17424041032791138]\n",
      "830 steps | score: [-0.07538963854312897, 0.09307172894477844]\n",
      "840 steps | score: [-0.00622066855430603, -0.10641564428806305]\n",
      "850 steps | score: [-0.08714039623737335, 0.18473657965660095]\n",
      "860 steps | score: [-0.05343995988368988, 0.06798780709505081]\n",
      "870 steps | score: [-0.012705227360129356, -0.03779983893036842]\n",
      "880 steps | score: [-0.09235821664333344, 0.21190601587295532]\n",
      "890 steps | score: [-0.06408943980932236, 0.1047029048204422]\n",
      "900 steps | score: [-0.06196032837033272, 0.11695599555969238]\n",
      "910 steps | score: [-0.10138392448425293, 0.1573125123977661]\n",
      "920 steps | score: [-0.022676972672343254, -0.047995634377002716]\n",
      "930 steps | score: [-0.03194694221019745, 0.007983379065990448]\n",
      "940 steps | score: [-0.06971318274736404, 0.16517315804958344]\n",
      "950 steps | score: [-0.042371757328510284, 0.055688802152872086]\n",
      "960 steps | score: [-0.04629889875650406, 0.07214899361133575]\n",
      "970 steps | score: [-0.05310743302106857, 0.10810751467943192]\n",
      "980 steps | score: [-0.028563376516103745, 0.07298441231250763]\n",
      "990 steps | score: [-0.057661984115839005, 0.08357267081737518]\n",
      "1000 steps | score: [-0.04188273102045059, 0.021954935044050217]\n",
      "1010 steps | score: [-0.07254461199045181, 0.11653328686952591]\n",
      "1020 steps | score: [-0.026229435577988625, 0.012644089758396149]\n",
      "1030 steps | score: [-0.056118663400411606, 0.09369262307882309]\n",
      "1040 steps | score: [-0.053385764360427856, 0.071950264275074]\n",
      "1050 steps | score: [-0.011414863169193268, -0.03779630362987518]\n",
      "1060 steps | score: [-0.03886167332530022, 0.030665602535009384]\n",
      "1070 steps | score: [-0.04899020493030548, 0.10108999907970428]\n",
      "1080 steps | score: [-0.02419879101216793, -0.026650190353393555]\n",
      "1090 steps | score: [-0.05875026434659958, 0.09668974578380585]\n",
      "1100 steps | score: [-0.05122814700007439, 0.06281882524490356]\n",
      "1110 steps | score: [-0.036285899579524994, 0.04371748864650726]\n",
      "1120 steps | score: [-0.05587826296687126, 0.0765102431178093]\n",
      "1130 steps | score: [-0.04132897034287453, 0.060515183955430984]\n",
      "1140 steps | score: [-0.07906800508499146, 0.17717725038528442]\n",
      "1150 steps | score: [-0.026073994114995003, 0.012282103300094604]\n",
      "1160 steps | score: [-0.02938184142112732, -0.0012682676315307617]\n",
      "1170 steps | score: [-0.012225611135363579, -0.04553934186697006]\n",
      "1180 steps | score: [-0.06222670525312424, 0.1344817727804184]\n",
      "1190 steps | score: [-0.025894004851579666, -0.004117652773857117]\n",
      "1200 steps | score: [-0.015872783958911896, -0.003952555358409882]\n",
      "1210 steps | score: [-0.07954463362693787, 0.1641388088464737]\n",
      "1220 steps | score: [-0.03286709636449814, 0.011004440486431122]\n",
      "1230 steps | score: [-0.08384141325950623, 0.13990278542041779]\n",
      "1240 steps | score: [-0.09048240631818771, 0.2349064201116562]\n",
      "1250 steps | score: [-0.08161601424217224, 0.17016708850860596]\n",
      "1260 steps | score: [-0.02534736692905426, -0.0024881511926651]\n",
      "1270 steps | score: [-0.0978676825761795, 0.18326160311698914]\n",
      "1280 steps | score: [-0.01666335016489029, -0.03347121179103851]\n",
      "1290 steps | score: [-0.049957871437072754, 0.06369839608669281]\n",
      "1300 steps | score: [-0.05825561657547951, 0.06871697306632996]\n",
      "1310 steps | score: [-0.018521208316087723, -0.006696715950965881]\n",
      "1320 steps | score: [-0.058990005403757095, 0.12347877025604248]\n",
      "1330 steps | score: [-0.10140611231327057, 0.21241122484207153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340 steps | score: [-0.01400713436305523, -0.0558122843503952]\n",
      "1350 steps | score: [-0.08481942117214203, 0.15662620961666107]\n",
      "1360 steps | score: [-0.0764402449131012, 0.14082351326942444]\n",
      "1370 steps | score: [-0.021166086196899414, 0.022645816206932068]\n",
      "1380 steps | score: [0.0054030641913414, -0.07436034083366394]\n",
      "1390 steps | score: [-0.049138426780700684, 0.050974342972040176]\n",
      "1400 steps | score: [-0.07839575409889221, 0.13464291393756866]\n",
      "1410 steps | score: [-0.03305252268910408, 0.026697207242250443]\n",
      "1420 steps | score: [-0.07760383188724518, 0.10051722824573517]\n",
      "1430 steps | score: [-0.015680477023124695, -0.060201071202754974]\n",
      "1440 steps | score: [-0.04532398283481598, 0.05143383517861366]\n",
      "1450 steps | score: [-0.05975762754678726, 0.15153823792934418]\n",
      "1460 steps | score: [-0.03191012889146805, 0.0001558065414428711]\n",
      "1470 steps | score: [-0.014606371521949768, -0.019187040627002716]\n",
      "1480 steps | score: [-0.06064256280660629, 0.13444608449935913]\n",
      "1490 steps | score: [-0.05573276802897453, 0.1114293560385704]\n",
      "1500 steps | score: [-0.03885091096162796, 0.005774244666099548]\n",
      "1510 steps | score: [-0.07829970121383667, 0.17329561710357666]\n",
      "1520 steps | score: [-0.005838222801685333, -0.0568803995847702]\n",
      "1530 steps | score: [-0.027244944125413895, 0.011787660419940948]\n",
      "1540 steps | score: [-0.05697242543101311, 0.10489846765995026]\n",
      "1550 steps | score: [0.012978889048099518, -0.10104718804359436]\n",
      "1560 steps | score: [-0.04813824221491814, 0.05936266481876373]\n",
      "1570 steps | score: [-0.09060600399971008, 0.2217627763748169]\n",
      "1580 steps | score: [-0.04277198016643524, 0.05090866982936859]\n",
      "1590 steps | score: [-0.005301032215356827, -0.10281171649694443]\n",
      "1600 steps | score: [0.004734192043542862, -0.06841934472322464]\n",
      "1610 steps | score: [-0.02539670653641224, 0.00559968501329422]\n",
      "1620 steps | score: [-0.039537735283374786, 0.06138752028346062]\n",
      "1630 steps | score: [-0.08586634695529938, 0.16667494177818298]\n",
      "1640 steps | score: [-0.042034950107336044, 0.05116657167673111]\n",
      "1650 steps | score: [-0.04888775199651718, 0.03460061177611351]\n",
      "1660 steps | score: [-0.06852405518293381, 0.15523578226566315]\n",
      "1670 steps | score: [-0.057829584926366806, 0.13076776266098022]\n",
      "1680 steps | score: [-0.02190243825316429, 0.012069657444953918]\n",
      "1690 steps | score: [-0.07498319447040558, 0.14119045436382294]\n",
      "1700 steps | score: [-0.06593506038188934, 0.12329986691474915]\n",
      "1710 steps | score: [-0.04074563831090927, 0.018406279385089874]\n",
      "1720 steps | score: [-0.05498029291629791, 0.10170171409845352]\n",
      "1730 steps | score: [-0.03301380202174187, 0.0032504498958587646]\n",
      "1740 steps | score: [-0.02926081232726574, -0.017789535224437714]\n",
      "1750 steps | score: [-0.053019989281892776, 0.06525833904743195]\n",
      "1760 steps | score: [-0.02492159605026245, 0.0043307021260261536]\n",
      "1770 steps | score: [-0.02827286161482334, -0.0111050084233284]\n",
      "1780 steps | score: [-0.045760639011859894, 0.04309789463877678]\n",
      "1790 steps | score: [-0.09093159437179565, 0.18600478768348694]\n",
      "1800 steps | score: [-0.08043652772903442, 0.16842666268348694]\n",
      "1810 steps | score: [-0.07509783655405045, 0.11157989501953125]\n",
      "1820 steps | score: [-0.04919613525271416, 0.11228135228157043]\n",
      "1830 steps | score: [-0.07284677028656006, 0.11089301854372025]\n",
      "1840 steps | score: [-0.03932465240359306, 0.03952283412218094]\n",
      "1850 steps | score: [-0.007200397551059723, -0.03690128028392792]\n",
      "1860 steps | score: [-0.01399599015712738, -0.0411311537027359]\n",
      "1870 steps | score: [-0.05412609875202179, 0.1315488964319229]\n",
      "1880 steps | score: [-0.05369121953845024, 0.07782259583473206]\n",
      "1890 steps | score: [-0.044800832867622375, 0.001935616135597229]\n",
      "1900 steps | score: [-0.023151002824306488, -0.02242060750722885]\n",
      "1910 steps | score: [-0.03366450220346451, 0.015608690679073334]\n",
      "1920 steps | score: [-0.03846516087651253, 0.03735654801130295]\n",
      "1930 steps | score: [-0.0715981125831604, 0.16009874641895294]\n",
      "1940 steps | score: [-0.06581094861030579, 0.13896381855010986]\n",
      "1950 steps | score: [-0.00651979073882103, -0.0603802427649498]\n",
      "1960 steps | score: [-0.07123027741909027, 0.15111488103866577]\n",
      "1970 steps | score: [-0.0554109551012516, 0.07561567425727844]\n",
      "1980 steps | score: [-0.031972486525774, 0.014462996274232864]\n",
      "1990 steps | score: [-0.11047538369894028, 0.23696905374526978]\n",
      "2000 steps | score: [-0.06430412083864212, 0.16255804896354675]\n"
     ]
    }
   ],
   "source": [
    "trunc_reg = TruncatedRegression(phi=phi, alpha=alpha, bias=True, unknown=True, bs=100, n=10, tol=1e-2, val=10, steps=2000)\n",
    "unknown_res = trunc_reg.fit(x_trunc_norm, emp_stand_y_trunc)\n",
    "unknown_var = unknown_res.lambda_.inverse()\n",
    "unknown_weight_unnorm, unknown_bias_unnorm = (((unknown_res.weight * unknown_var) * ch.sqrt(emp_noise_var)) / beta).detach().numpy(), ((unknown_res.bias * unknown_var) * ch.sqrt(emp_noise_var)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEWCAYAAABv+EDhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAADGAUlEQVR4nOz9d7xcZ3Xvj7/XbjNzzpk5varLktxUjBuYYhyTOEDCRencm1ATnIQvJPcX+IbcxEmA2PcLlzRSHC4Egklyk3BTnJAQTGIjDEYgV0kuktXL6f3Mmbbb8/vj2XufmdN01CwJz+f1sjVnZs+eZz/72WutZ5XPEqUUddRRRx11vPxgXOoB1FFHHXXUcWlQVwB11FFHHS9T1BVAHXXUUcfLFHUFUEcdddTxMkVdAdRRRx11vExRVwB11FFHHS9T1BXA9wBE5Asicu+lHsdLARF5nYgcvNTjWA4i8tMi8rVLPY7vJYjILhH5uej1BZ9fEVkvIkpErAt53ssddQVwGSBaeJvmvfcREfmrSzWmiwUReVd0vb867/3TInLHmb6vlPqmUurqCzieVSLii8hVi3z2TyLyu2d7TqXUXyul7rowI3xpICLHRWRERBqr3vs5Edl1CYe1KK7E+b1cUVcAdVwKTAC/KiLZSz0QpVQ/8DDw9ur3RaQNeDPwwNmc7wq3IE3gl8/3JKJRly1XAOo36QqAiNwRWcgfjKy0QRF59xLHZkXk6yLyR9GD+AUR+VMR+TcRyYvId6utXRF5tYg8LiLT0b+vjt7/PhHZX3Xcf4jI41V/f1NEdkavj4vIh0RkX3SevxOR9DKX9AKwG/iVJa4hJSJ/KCID0X9/KCKp6rmoOvbDItIfXdtBEXlD9L4hIr8mIkdEZFxEvhQJ9cXwAPMUAPA24Hml1P6q8+RF5HkR+ZGq33+XiDwmIn8gIuPAR6L3vlV1zKdE5JSIzIjIkyLyuqrPPhKN7YvR+Z8TkZurPl8jIv8oIqPRdfxJ1WfvEZEXRGRSRB4SkXXLzPlK8EngQyLSstiHS62V6LNdInKfiDwGFIGN0U7vfSJyKLq23xGRq0Tk29FcfElEnOj7rSLyr9F1TkavVy8xjmR+ReRXRWS26j9PRL4QfdYsIp+Lnpd+EblXRMzoM1NEfldExkTkKPBD5zl3VyTqCuDKQQ/QDKwCfhb4UxFprT5ARNrR1uxjSqlfUnM8H28DPgq0AoeB+6Lj24B/A/4IaAd+H/i36DzfATaLSIeI2MB2oE+0gskANwPfrPr5nwTeCGyIjn3XGa7nN4H/voRQ/g3gVcANwA7gVuCe+QeJyNXA+4FblFJZ4AeB49HHHwB2Aq8H+oBJ4E+XGMs/AR0i8tqq997OnPV/BHgdev4/CvyViPRWHftK4CjQTTS38/B4dC1twP8B/u88BflfgL8FWoB/Af4kuj4T+FfgBLAefe//NvrsrcCvAz8KdKLvxd8scX0rxRPALuBD8z84w1qJ8XbgbiAbjRn0PbkJfT9/FfgM8DPAGmAr8F+j4wzgL4B1wFqgRDQPy0Ep9b+UUk1KqSbgWmAU+Lvo4y8APrAJeAVwF/Bz0WfvBX44ev9m4MfP9Fvfk1BK1f+7xP8BCtg0772PAH8Vvb4D/UBYVZ+PAK+KXn8B+DzwLPD/zjvPF4A/r/r7zcCB6PXbgT3zjt8NvCt6/U20gHkV8DXgS2gh/33AvqrvHAd+purv/wV8eolrfRfwrej1l4BPRK9PA3dEr48Ab676zg8Cx6vm4nT0elM0D98P2PN+5wXgDVV/9wJe9RzOO/7Pgc9ErzcDLtC1xLHPAG+tup6TS13jEt+fBHZU3ef/rPrsOqAUvb4NLdAWjBn4d+Bnq/420Jb3unNcg8ejedwKTKOVys8Bu1a4VnYBH1tkXb+m6u8ngQ9X/f17wB8uMZ4bgMmqv3cBP7fU/AKZ6vOjlXEFyFQd81+Br0evHwF+oeqzu6LxLro+vlf/q+8ALg8EgD3vPRstsGKMK6X8qr+LQFPV3z+Efgg+vcj5h5b4Xh9zllqME2hLE+AbaIF7e/R6F9qifn3090p+Yzn8FvCLItI97/354zoRvVcDpdRh4L+jheiIiPytiMTHrQP+SUSmRGQKrRACtGBYDA8APxFZ5m8HHlJKjQCIyDtE5Jmqc20FOqq+e2q5ixTtHnshcp1MoXcS1d+fP3dp0bGENcCJefc9xjrgU1VjmgCEuXtX/fufrnKR/PpyY1VKPYvedfzavI/OtFZg8XkYrnpdWuTvpmiMDSLyv0XkhIjMAI8CLbHLZgX4HHBQKfWJ6O916GdosGqO/jfQVXU91eOdf20vC9QVwOWBk+gtfjU2cHaL8rPAV4GvSFUmxxkwgH5QqrEW6I9ez1cA32BpBXDWUEodAP4R7fJZblxro/cWO8f/UUq9NjpeAbEAOAW8SSnVUvVfWumg72L4FlqIvhXtongAIPKrfxbtampXSrWgd1pSPYylrjHy9/8q2kXWGn1/et73l8IpYK0sHlg+Bfz8vOvLKKW+Pf9ApdQvqMhNopT6nyv43d9Gu0iqhfuZ1gosMw8rwAeBq4FXKqVy6DUHK5gnEfk1YAvaNRrjFHoH0FE1Pzml1PXR54NoBRtj7XmM/YpFXQFcHvg74B4RWS06ePn9wFuAvz/L87wfOAh8OfLTnwlfAbaIyH8TEUtEfgrtgvjX6PNvox/KW9Hb/+fQQuCVaAvtQuCjwLvR/u8Yf4Oej04R6UDvFBakxIrI1SJyp+gAcRltUYbRx58G7osDo9G53rrUIJT2A3wRrUBagC9HHzWiBdtodJ53o3cAK0UW7YceBSwR+S0gt8Lv7kELqo+LSKOIpEXkNdFnnwb+h4hcH42rWUR+4izGtSSindXfAb9U9faZ1sr5Iou+f1NRvOG3V/IlEXlTNM4fUUqVqq5hEO22/D0RyUXP1VUi8vrokC8BvxQ9c60s3PG8LFBXAJcHPoYWtt9C+4f/F/DT0XZ8xYiE2N1of/o/y/KZOCilxtGBsA8C42hL9YeVUmPR5wXgKeA5pZQbfW032i0xcjZjW2YMx4C/RAvaGPeiA5L7gP3RGBYrdEsBHwfG0G6ULuB/RJ99Ch1Q/ZqI5NFB7VeeYThfRFuCf6eUqkTjex7tq96Ndl9sAx47i0t8CL0zexG9oytzBpdRDKVUgDYENqF3iaeBn4o++ye0svrbyGXyLPCmsxjXmfAxqu7JmdbKBcAfol2YY+h79dUVfu+n0PGKF6rcXLEb9B2AAzyPfq7+Hh0LAr2rewjYi15f/3gBruGKg0QBkDrqqKOOOl5mqO8A6qijjjpepqgrgDrqqKOOlynqCqCOOuqo42WKugKoo4466niZ4ooiruro6FDr16+/1MOoo4466rii8OSTT44ppTrnv39FKYD169fzxBNPXOph1FFHHXVcURCRRYtK6y6gOuqoo46XKeoKoI466qjjZYq6AqijjjrqeJmirgDqqKOOOl6mqCuAOuqoo46XKS5pFpDo1nN/jmZXVMB7lFK7L+WY6qijjjrOBvsffZBw9/20VAaYSvVh3PY+tt2+81IPa0W41GmgnwK+qpT68ag3aMMlHk8dddRRx4qx/9EHye66B1dSzJotZNxxnF33sB+uCCVwyVxAItKMbvrwOQCllKuUmrpU46mjjjrqOFuEu+/HlRSe2QAieGYDrqQId99/qYe2IlzKGMAGdJOMvxCRp0XkzxfrZCUid4vIEyLyxOjo6Es/yjrqqKOOJdBSGcAzansveUaG5sqiDewuO1xKBWABNwJ/ppR6BVBgka48SqnPKKVuVkrd3Nm5oJK5jjrqqOOSYSrVhx2Wat6zwxLTqQUtrC9LXEoFcBo4rZT6bvT336MVQh111FHHFQHjtvfhqAp2UASlsIMijqpg3Pa+Sz20FeGSKQCl1BBwSkSujt56A7p1Wx111FHHFYFtt+8kf8e9lJx2GoMpSk47+TvuvSICwHDps4A+APx1lAF0FN0cvI466qjjisG223fCFSLw5+OSKgCl1DPAzZdyDHXUUUcdL1fUK4HrqKOOOl6mqCuAOuqoo46XKeoKoI466qjjZYpLHQSuo4466viexeXOE1TfAdRRRx11XATEPEEZdzzhCcruuof9jz54qYeWoK4A6qijjjouAq4EnqC6AqijjjrquAi4EniC6gqgjjrqqOMi4ErgCaorgDrqqKOOi4ArgSeongVURx11XNa43DNplsK223eyHx0LaK4MMJ3qo3KZjb2uAOqoo47LFld6x61z4Ql6KRVe3QVURx11XLa4EjJpLiRe6tTRugKoo446LltcCZk0FxIvtcKrK4A66qjjssWVkElzIfFSK7y6AqijjjouW1wJmTQXEi+1wqsHgeuoo47LFuebSbNUQPVyzSwybnsfzq57INCWvx2WcFSFykVSeKKUuignvhi4+eab1RNPPHGph1FHHXVcAajOIKoWpoPrdrLu2N/QpArYBHiYzEoj43f+3oqUwMVWHvH5Y4V3Ic4vIk8qpRY036orgDrquMxxuVqrlzv2fuIuMu64DqhGsIMi3X4/KXx8TEIEA4VFwHFzA9f81uPLnnMppXK59wFeSgHUYwB11HEZ40pglLxcsVRAtYmyFv5igAihGPiYrAlOnPGc32tpqfUYQB11XMaoETig/w30+1dqI/KXClOpPlpLJ8mRJ6VcKuIwQxaFAPM9HyvzhLRUBpg1W2reu5LTUusKoI46LmN8rwmclxLFnlu55uiTBBh4mDjKpZtRRqWVFjUDSlv/hgoxCTlpbeDqM5xzKtW30K20giydy9WNV1cAddRxGeNcBU4d0DC0hynJ0aqmSePhYzApzcyY7RAYNDKLpTx8scjTgvv63wCWF9bnkqVzLnQWL5XCqMcA6qjjMkZ1HnzanWJN5RDr/OOk3ckVxwH2P/ogez9xFyc+tpW9n7jrZRM/6CodIatmcbGZlQwuNlk1Sy6YYOzO3+VYZjsjZg/HMtsZu/N3k/TQ5WIu227fSf6Oeyk57TQGU5Sc9jMGgM82bvBSxn0u+Q5AREzgCaBfKfXDl3o8ddRxOSHOg7d33cc6NUBFbE7LKoRQCwWWJ0W70snUzgcOLoAO9kb/GirEwV2SpG0lMZezJXg7WzfeSxn3ueQKAPhl4AUgd6kHUkcdlyO23b6Tvbvv54S7vsYVtBKhcCGEyeXqvz4TXGwylDFUmKR7xu/PR3yN1xafpChpxlUHZUuLpOWE9UrmZiVuvOrzbAkG8bGw/JCKOIwbHZTN7EWJ+1xSF5CIrAZ+CPjzSzmOOuq43HGuHDHnyy1zId0RL7UraiSziTFpxxcLiwBfLMaknZHMpgXjiq+xKCkc5dIbDJL2Z4ClYy4rnZsz0VlUn8cPBYeABsqEgKV8eoNBst7YRYn7XOoYwB8CvwqESx0gIneLyBMi8sTo6OhLNrA66riccK4cMefLLXOh8t4vRT2Dcdv7CA1L+/mdqxkxewgNawGPUPU1jhtdEKWJtodjy3IPrXRuzhQ3qD5POxO4WICQwo/cV4o2NXFR+I8umQtIRH4YGFFKPSkidyx1nFLqM8BnQFcCvzSjq6OOywvnyhFzvtwyFyoN9VLUM6yUR6j6GstWlkH6aA9HyKgyJad9Se6hs5mb5eIG1edJKRcPixCDFC6W8nHFpkTmorjdLmUM4DXAfxGRNwNpICcif6WU+plLOKY66rgsca6kaOdLpnah0lAvVT3DSgK286+xbGUZCUxKTjs7Pvy1FX8PlvftLxUjKEuGNd5hLBVgEmCg6xIAXHGYkSyT6bX0nt2lrwiXTAEopf4H8D8Aoh3Ah+rCv446lsa5tBc8n+/BhWOnvJzrGS7W7molGVj7H32Q9mACR2luIoWPQ4ACSji6eE2N0t/z4xfl2i+HLKA66qjjMsWFamx+MWmOzzdL6WLtrua7vUwV0BaO0f3wzzL+yAdwcejDpUAj/eYq2sMxMqpCiI5CNOCigAombScfAu4967k5E+psoHXU8TLEpUjt3P3APWw59gBNqsisNPDihndy2zvPT6hdzuycJz62Vbu9REj7eXqDAYSAFD5lHACdnYTJoNlH2cqxqfICFh4GECCAIISEmBx4w+fP+ZqWYgOt7wDqqONlhotdHLaYcgHoPfEg42YXQ5Gg7j3xIPsfvfm8fnO54HJsnV9M3n57130Ji+hpax3u638jqSjuC6fpCgapSBpLBYQIKUICDHyxMFQIBAC0h2P0k0MIq6jqBCAhr/teLQSro446XkJczIycpZRLRTIX5TeXCi53lY5QuchKrv2RD9KmpvExAcVa/xhTj3yI3U9+iW1T/4mDh4FCVBkHnwo2JopSVIgWioFSWsinVQXUnNhXgEmIil77GBclYF5XAHXU8TLDfKGZ9vM67bF4nL2fuOu8LOWFfm+ftmCMRsrkpXFBhW1X6TB7P3HXOVvpSwWXHVw8ZdMVTuL4bpJNs5zCqd65lMggAmlVWnRc4e77aVIFFJDCwyBEIbSoSW6Z+ndcLMqksPGx8VFod0+BVGTXg6FCSpJmRrI0qoKuEcDBorZuQ4AA46IEzOsKoI7vGVyplAUvNaqFZuybBkVJ0udtKVcrl7Q/Q28wSIigUEmF7SBQtnJkvTFyqkC+qjjsbH97qeAyQEc4Thi5Wyzl06VG6CyOceJjWxesj+qdix8K69UxFDBg6J4CbQ/fzfgjHwA0lcQmNYuNj0mA0nY+oEhHwl4BGSoYKEIEFwsTxaS00qHGI/cPWimJxcD3/THbbt/Jwd+5hbR/FIsgSgTVMQAjutYLjboCqOOKwnJNvl+upGdni2qh2R6OoMWVMEsDXcEQaVUh+8gHzmnuSmRY4x7GRue0BxiASYk0ZiQa28MxRgKLNjXBuNF2Rv/9YtY40eddpSM0qiI2LiEmp6115O+4l2wkrGMiOEFhExCiFl0f1TuXrmAocutAVziMicIgIK3yCb+Q4GMnBAb63+p0mjRe9LfCRGERUsCmZGaZDlwcPFwcJtNraxRRWpU4bayiOxwhTRlQFEkxK9nvuUKwOuo4Kywn5C+WX/t7cVdRnb6YKR6nJGlmaaBNTSfWaoMqnpFtdP7cFHtuZX04iY0PUZ9dLXQ9BqWbitFQU2GbD6bIWx0155zvv59vjWfccZoe+SCC4IlFs9J8PQqDcWkjpUq4LCSCc/AA0Zk1EW1D9fpYWI1rgggNqhS5crSN74uFrTycRTqISc1fCkESrh2tYoWUKjF25+8nczq/uCvenZ2wNyfv2UGRktN+UQrBLjUXUB11rBjLca+cL+nZYriSidDOhG2372THh7/GgYabGDF7aKJISNQhC0VF0ivmrPeVwYbSPm49+ifk1DSz0phYx9rmF9rUFAAjZi8HGm5ix4e/xkjmqkV5ihzcGm4c7WgxaVfabdWsZuhQ4/SFQzj4CCE2Pn1qiLZgDHvXfYxkNpGXRhw8mihhEuIjlGVujcTrY/+jD9IUTnOVe4BV7lF89BwYSmfkaCbRMMrP0b78+NqqoQAPQdAKSJI9ALhY+v0z8CjV9H/wplnj6v4PqcrK+z+cDeoKoI4rBssJ+fMlPVsMF4sIrbV0kg0P383gR6665MogFjhpVdGCToUYKMaNzhVx1psqoDccwogyWFJ4tKoZPExKpCLLVztJOsOhGmK1pVgyXezkPqeUmygmR7mk/RkyuBiROBZC0vjR39obvyE4StHpoEXl8TGZJUOIYBMyS2NyDXZYokyG7K57KEij3ikolxQuGcoRI6fgRAVZfuQwqVYGCh2gDRBU5BhyMfHESj6PM3oCzDMaJTFxnMJgddgPCk5LH4aEF4U8r64A6rhisJyQPxPl7rngQu0qqhVJOsjToSYwUGQovSSsmMshFjgFyWCj2yPqoqTssgo0npv2cDQR0CESiUHt8w7ExMUmiCxqU4U1BVpLsWSOZDYl97kiTmKNu+LQHo7p38MgxEhSJrWSMaPv2GyZ/ibD0okrDhYBJVL4mOSYAaXIuqP0+adYFxyjLRjDkxSD5ioCDKxIwBdJJ4pjRhp0Jo/yUZErKcTAw4qcPYoAgzGjnWPmVRRoImRuB2SgsPHI+memdd52+07KTisnrPWcSm2m7LScs/FxJtRjAHVcMViOTuBCURZU42IQoSUCTEwc5V3wHPzFCrDOlNoYz11NRW2kQJeiaojnxlEufmTt+pjYkcizCGhURRTCkHRSNHOaXG3eNca/PR2Pe/f9FHtupfnEgxDAOG2sYhAFDEs3q8IBfASizBsr4s0RSFw3w9LN6rCfIWcdXpCiPRwjpVwq2NjKo80bIKcKjBttdIRjGCidnWT2EohFUaUxCDmR2gJA1hulURWYlgwOLkVSZJTHtDSQVbORQ8hkTNoJxcK74zeY3nUfuWCaDB4hQgUTQWgPJ5m+7eNnvHddpcNM2LXr7GKQ59UVQB1XDM4k5M+H9GwxXAwitDjAGFu0cGEe7MUC5NlHPoSKsl4WC6ZWZ8GcrQKN58YXE0MFEDlgJiRHu5oBVJIa2adGqPiTPNN09YKcf2DBuJtPPMhgdjtbpr9JkypSxmbKaMOUkIJkKEgjnmjB7igfiVItK5Ji3OgkEJNZ1UDWG6NDTRAieJhRaqXFjNlOnlY8s4Gcm8dSPiGSKIoASe4NQN7qIAws1v/WszXzHe6+n7B0RMcssJnMzGX0nNh1D8edq0kH+WicuhbBRwh338+JXfcsOwc5VcDzxsg7nclvXgzyvDoXUB11sHx6abVQXC4LaCUpql3BEI5yAZlztURZHstRD58Jez9x14Ldyhr3ECg4ldrMKvcolvKByG8tFmlVoSAZBu7843PaKe1/9EFyX/91VodaeRVJYRBgAjPSQJuaiSoAtAA2gGHpJG93zClTySCENePucE/Triaj7HetSnwc9m18L00bbq7ZqWS9MbrVKMNGJ3lr7ryD63ay7ehnsCKOTQOFAsalhSZV5LizpYajJ0TvKfQuxmfAXE3ZygKc0/1Z7H5k3VHa1ST91upag2KROch6o7SFEwxYay4Ix1GdC6iOOpbA7gfuiYRFSFlSSMknrE6BXMEDd6Y6hNi6LpV0muSsaP95unIaH4P9a990XtewGCWCFvg6WBnvPEwCGnApqvSK0z2Xul571330hMOUcXT7wojKeFA6aEKnT8Z5+A2qhItNjjx56VyyQjjt52lXk5GDJ4j866Dw2Hb0M+wHHMmw2tf8O6fMdTy17sdpGNpTs3O57fadjH/kAdLKjXYIBj4mWVXQNQFhCc9sSBrAdIZDiAoZMNfQHE4SiKljSee466vePZqBS6capYkSCuEq/zAKoUSKSWlltTqhFVIV8lYHtudRctovmEtzMdQVQB0va+x/9EG2H/0sgsJFV4x2MMFY2HZWfvmV1iG4RgOjoUO3GgMUZUkxI7nzJkZbLF7hi5XkKlbEwVI+KXzdckQMbOVhEbA6OA0Pv5uD37ivhsxsqfqHWNm1BWN4kQgxUQyYa+gJBuhW41HWi4Gr4gx6HSOIM3mWqhBuD8eq0ifndgDaivfYfvSz9FurOe5swQ5LpFWJpg03s20JVlEXO4lRgFaKLpauFo5ce4GYTBgdiXU9f9dXqdrJLUX+Nh+x0rd33ccG1Q9J1pK+thBFA2Ua1CACrPEOM2r0zO06whIjmavOa1e4EtQVQB0va4S778fAx4t8viECKiRHnvAs/PLLdbyavztYExwGYMBcU+NmOJ9A8GLxigJNKNEZUXEw1SCkhIOtPFJ4yTUL4RyZ2bEn6D3x4JK7mVjZxRw4cYXvhuBYEpANMKIUTd3isEQKi6AmkwdYUCGcUuUkdiCJ0NRKQGcT+Ssu9nNxaGSWhihOoNM0oSg58nfce1axpOXI3/ZHxyymMA9+4z58jCQ4HmPuujQfqKN8+oLTDKg+bFw6wzHwj1P67XY8cSjQwEjmqgteiFhXAHVc8Tifat2WygAVSWm63shdESKkVeWsAm7LZgzN2x3YEUVCezhKP1oBnG8gePEg7m/q64neO84G+sLT2MrFjAKnGjqlMcCkkVm2HHuAgjQuSaTWUhnAVwZmkv0+hzjt0cMkTUgIeBhMGq10h6PMkKVTjRNEVbKDpp7juEJ4VhrwMelQkxhQIzZNQsoRk2aM5eZt2mijPZiMRL+K0jGFaaPtrBMGYvI3HzNZJyihkVlmvnGfrkCOFGbMHTT4yAe5Sk3gYSaWf4za9FWbfnMVncEwfVE8xSAgwCSFj6OKmtyufLLWNXkBUK8DqOOKxvlW606l+piRXJJrDnGTDuOsagiWq0OYX09QEQeioqMY1RkeZ1s1HB+f23UPAIPrdgKQ23WP3uHc9j7W/9azXPNbj3Pizj9j2OwliHzrQOL+CsXAUj45VaAjHMdSfkKk1hGO01U6ksxZpxrBi6pbq4W0roK1cCXFMXM9s9KIQ8Bkei1PbfxFJjNrk7qBOAhetrJJhfDAnX9MyWiK8uvn6BV0o3RZILCWy4wR0TuRCg5lHAR9b/vC02ddd9FSGYhoLebUXTxfq/0TUVGcz1r3EKvVIGlcmtUUBiHpiBZ6MYQIJUlRtnKccjYltQUhZvI9AWx8cip/wWsB6juAOq5onC8HkHHb+wh33cOY0UZOzZBSFUIs9m98L7dVfb96l1GWDEpBhtp8+qXSKPfuvr9mdzBudLAq6McVa0Gg8WxJ7eYf3106SOfRPQQYFCWNlGsD2knO/yMfwFF5FEIFm0B0aqovFmakmJIdkRgYKsTBTeYs9fDPRkLaS9wZMFf16yiXspVjJLAWZNDEY54faB3vuZWG3feTCotYhPgYEO0xYr6iTjWBHRQXpOUutgvMqRIDRh9d4TANuJEyMGlQJbY8/LNJzCNeR8vtIKdSfbQWxxJ2T6BqvkLMwKVXDWNHef+CIoOftHecj1hpepiMGzrVMy5+c3CxaxrDaEs9rUoXvBagrgDquKIJz5bzvS+Gxa419geHVame84V/QhWsDNYGxxBgTFrYVHya9MPvovSwhW1uwLvjN1g/b+7m++cDsZiQZvJmG43BVK2y+MRdZ9XhqqbK2J+hQ01DXI2rAjrUBGNG24Lvj5k9qECRU0UcPMyIQjlUBgHaBWEoI6qE1Zz2tgqSfgHHzI30BaeY89DPCboMHgXSSxaTLaYsx3tuTeIOE3YfjW5x0XTMY6qFitNao2RhYR69s+seypJBJCRQFhVlY+OTjpqseAi9wSkKVbUS1d/dfewJGob21BDdzR47omMACjTLZ0ieFqbNVvqCUwln0HyFuBg0P5DNqNFB2WxK5uqUuY6rgsOJgshXmtg/ch17h7fxtm1/j21d2FqAeh3AyxyXc0/VlWCxfOul8rbP9VqrfyPOpzcJcCLWS9Bb+QAt2Mfv/L0F51tpPUF1H9kEStHmDVIxMgvGngpLTNi9IMIq9yjZqEmJAAXJRFaqpmOuGA01328LRsmqPFaUca8LpvR12AS6cjZySPiYlCXFiNmb5Nn3nniQ7mCAdFQLWw0P4YWGW1dsTMy/j2l/JtklnbI3LXuvlloDqaBEhxonQzl5PyZ3A83tU4kypU6l5tg3l8rBH1y3k9YTDy3IAgLY8vDPEgIp/OR3kttX9a9COCFrMA2VGB5dpSPYyuXY9DoeH3klo4Nt7Bveyr7hrRyeuCo5z9ff9SbWbzh1Ts9mvQ6gjkVxMdsDvhQ4m2rdc73W6l1GTH2QVuUaf7QR5XM0qzyji5xvpUHH5Tpc5aVlwdizTCc57TFxWpz3Dtp9k1IVAjHJz7t2J3CpkKIkJilVwSLEJsTCj4K0KnHCWIR42HQFQ6RUmeyxB3hxwztZffRPaqz/OfIzzjoYP2u2kPZnkopcDxNbeQt2SUt9F0i+n1FlLAJGpZmMKifj0/w8eo5MAhqUbsC+yj3KuNFJ2cqSUzP6eufNdcPQHq75rceT3726agwHv3EfG31tuc+PUwigR2Phi0UxbOLZ8RspHd7Jw49v48iTE7wwdDUz5Vx0fMjGpqPsaNzHO9b8JdvNvewI9pLLlei/48/qWUB1XDicrQvlcsPZUBic67VOpfpoLZ8kp/I4eKSUu2j2hEFIhkoSLD0XLKXQqhkyq8fuBnaS014RB1EBDiEVDFAqoT9wcRZ8Py4UM5WHFTHsxByXBjpbCXQgNcSgXU1TwcbDplHppu4+FhZzBWdE3xfOzoiYSunOW4tRN+TvuFfvUOZRKMT3OFaapvKT+gIz4gjKqRI+gkkcTSBJLwVFGF2fpXx6gwEG6SOlKpQlvWCu43WyKOfS63+D8OGfRZPCqYiWDoZmu9g7sJVnTm3lmcFt7B3bzqH8JgKlRW+jdLPVGuNt6m94BU+zg71sYz9NswWYhdCAY6uE3evhhvCaFc3l2aCuAF7muFCEZ5cS863rOCtmfkzjXK+12HMr1xx9Mgoi2mRwFz0udi84S3y+0mtZTKFN776f1tJJcuQ1sZk4zJBlJLMpiQXEVcajkiOFR1pVdJXxxvfSMLRnyUIxG29Rq1UBBdIImuY57msbYFCWFK6kcMXGUV5NdoygKJI+KyPCuO19tD18N6AIo4C0QUiAsOnhnyPAYELayNsdtJZP0v7wzzP4yK8wktmUkMe1BXP1BQZQwolEvoGLETVpX5i1FL+OKatBsJXLxsoBKuIwbnQQiMV0qq826E6O7Ogg6b/+IIXVb2P3rhs5NbyKfZPb2Jffxt7KdobDnuQaV3OKG3iGH+Pv2WHs54bOAVabT+E1p/GzDl7OYbTF5B/a23muyWBPAzxnzDImeoR/IwGvusBpoJdMAYjIGuCLQDf6HnxGKfWpSzWelysuFOHZ5YLlsmjia027BXLk5wTkGWgYGob2MCyd5MjjKDfJKq8WmtWMlO68XPXqsS3H1llj2c57wHcfe4Jrjj4ZuVcCHOWSpUC/c6MOWFdV6c6PNdwWVbEuVSjWqGoptqtdOkDkCgqiPHpNmDxudOAZGQpBJtoTxKRsBj4Wk9K6QLGe6frjWIOl/KiVpM6ed/CpYGsabS+gLQp0N6kCjcV9pI4+yZB0J83XXUlRUHMKWd8vIyot02O0IuXiRWxBgVg4ysVUHq6yaZwtIvkQO1+kaXaKUt7By7Zh/cV7KUzaHJ65jmfL17OPHexlB89xPRX0rsGhwnXW87yx6SF25Pazte1Zru05gNvXysYPfA5W3QqdnZRDl//7yds54A2ylwr71AinoniFABulkderNq43WthmZNlEA25YvqDu2UsWBBaRXqBXKfWUiGSBJ4GdSqnnl/pOPQh8cXA2hGeXO84UFN79wD3ccPTT2FH6YiwcjphX4d2xeFn//MBsHAjOoDNn4iKfAINB6WYys3ZFAehsMJ1koJwpKL33E3fRUzpEu5qMBJtuQuJjcuwNn1nR/VrsPgNc+/C7MZP+trXWcQmHQbOPNcGpqD7C5JS5JmrqrmmSFYoWVdAc+pJhhiyhYTG4bmeSSVOWDNlgouZam4IpBCFvNuMZcS9hnfnTHo4m5HVpKhSjgLbupWsjhGTwKJJC7xp0quqE0Ube7qxpdu9Gu6VV4SB+wcCdtTFnXKxZHzMfYOQD/FmDMA923kMKIaK08jjCVexlB8+wg2fsm9kXXs+pYG0yV+3OONe1Ps/NXU+zas0gN61+nFd3Po1tamUUU1R7GDwHfPW6n2H/zCGeHXyMF1U+ChlDDzZbJccOUtysHNa/7n/S+637Fk0IaAymaphJV4LLLgislBoEBqPXeRF5AVgFLKkA6rjwuJJTQBfDUn7+rtJh9n7iLm4oPoWNT4CFpTvEIgSsCY4zusT2er7rKM7j18VFcwbUmLQTGtaiBWTh7vsxQp8uJkn52oVjqwoBFpNRNexyQemWygApKjUEayiFg79ii3CpQPTBb9zHVf6hRCECka2s+XvKZpahsCth3SybWbLeKN3haMLuWfTGaFMTlEgzmVlLsSqtc9ZsYY13GEf5lFQTXtRdrcnvB4EJU3e7HTW7WRX00xOcJhXFJOJ2inFvX4uAsqTIRLTNoUSxjlmP6dksXTNDOMUSxiwE0y6ZfAkrDw2z4xizFVIhpOZdv2oQSo1Z9jnb2de6g2eadrC/vI39s1sp+E0AGBKwseU423ue5yd7HmRz3wmu7jlCR3acte4hEBg1uukNBjHw6SdkDwF7JOC7hDxJQF4UHPhjskq4Xpp4l6zmFTi8KvRpNLtIqVKNAbb38b+46O7ZyyIGICLrgVcA313ks7uBuwHWrl07/+M6zgNnW3RU/b0zFUVdKizm5896Y+RUgbw7nrgqtLtgjsgghTdXZXkWefy5YGJRPvj56Codplnlo0pPM9pBeLhVljcsHZSeSvXRVRxMOIuAyLI02VR8hhMf27rs/C+n6N3X/wZTj/wSLWo6ceOEmMxII2NGD43BFJOZtfT3zLFuNqqCFv4RX33e6aQcNCY7rfn1DJbSu4f2cIx+dLaLTUC1B6Js5RgLC/SpUf2GUqiStspVvoKahTDvk8lr6z3MQ1N+BpkNkRAamACgh2n99QbBa3JwcynoMpjJtpJqLDNo9fFC+Vr2Fbaxb2o7zwxv48joxsSp15yaZnv3s7x7y1+xvftZdnQ/y9bOFxhLtVIysmSDCZpUAZsAzzXxqfAVaeVweIynxeUJPAYkqipXsB2Tt5FiE518nyqyWZn0V7F/6h1qK1d/eC7DaLF1dzHcs5dcAYhIE/APwH9XSs3M/1wp9RngM6BdQC/x8L6ncS5pkUsVRfVL74oVyMXEYg9Nm5pg3GjT1+fPteiba1qisZTwrQ7MdpUOR24Ih7LTinvbnNuod5lxOTHxWhXfUKgkIkKbw3xKiFhopyUDiKZnwMRAYeFjoCiLs0CBQ20nsI5wkrzZvKSiHzO6aQyK2JGb50RU1LaUMul8+G4aKNNamSIuinLFxi+NsPcTd3Ft8UkqWOBrDh8dPI7oNpTCKAeoMR8n77F59imMfIjkFTIbIHmFyitkNsRaWGKASgsqa6CyBmGHA03CVK4VL5fCa0ph5ALK2Ua80GB6OMezw9fz7eFXcvDUZg4Ob2Gi1Jaca0PrMbb0HOEHX/ENru45xF3tD3FV8zFMUTWusBAhp2YgcNmPx/NS5GlcnsDnAAGKKRDYqExejcMrQ5NXo9iOSRqDE+Z6ylaWTZXnMPFrAsxlM3vGdXexKKEvaSGYiNjAvwIPKaV+/0zHn08M4HvN1XEhMN+3XZ1DfaDhpkWDlGl3krh5RXWTEV8s+p2NixZhvdRzP9/X3VU6khRLra28SAOVxPaPOXGKpBi0Vi/b+GO+Hz/rj9EeTjIjjUk2zlJUyh2PfJBmNaOt68hfHTcrOWZtWBADgLnqVjP06FQjNKgKQkhY1Q4RtJumKJkkW0VhJORk833rMetm3AzmxQ3vTFw184ueqith5ze3aQvHsJUfKTahjI2pfOxKyHChjdaZKVL5MuQhmAXJh5j5AJVXMAuGHy6YX5UCsgY0CX7OQjUZmE1ADlSTyeEf/CTX7HwX+/d8lewjv8YaNUSsxMcLbTwzvI0nhm7gyZEbeXZ4K8dG1+KHOiCfsUpc1/0C27uf5bqeA2ztfo7tXc+SS83ii8W40UlnOJRcU5wmehTFdwnYLfAkHs/gU45shlYstkmWm0OD1ymfG3DoSLKQNHupGTGgjhsddAXDUU8AKGGjIkU+Jm2Lxo0uJJaKAVzKILAADwATSqn/vpLvnKsCuNKrXc8GZ+OeqQ6YxhztOmhmM0OOTjWKhaIkDqPSRWDYrPOPc9pYRdluZkPlQJRKqPPNj6WuWRCkOtPcvxTKYf51rgpOR63KVRRINRiRLmx8po3WFc5XbZBxxOyhKZjCkxR9oRZMAYKLw6w0kjfbyIR5WsNJMlSi4iCHMelgKrN6QQA+/i1TBVHHKi1YLPyITVRhQ+JAcrFRURC6Rw3Tb61JdnYbKwcS3s6YBVRTPHiEWIxLa03rwcU6V6XKRcrXvh/z0b+gcXIce6ZC2/Q4MhtCXsGsgnyIeAvnXzmgsgbSJKicQdBkYjaBnzMxmsDICtIkhI5B3N5RYVAS7a03lH6n8aMj+D786/95mJNf/ipHBtdxcOhq9g1vZXB2bv/Vl+1nS89Rbul+gut6XmBb13NsaTuMZYRJfcGg2ZfUDNjolpDjhHxNchxRozwlLo8TMB6lYGYU7MBmOxk2mz1sNXKsJoWIRJXaA0wb7WwIjlIRm1HpwlYu3WqUKcnSqmaSugogUgJOsrtYaSD/XHHZBYGB1wBvB/aLyDPRe7+ulPrKhf6h5Vwdi/GrXKlK4WzdM9XukvZQNygBYZZGOtSE9tEChlL0qiEGpY8KNp1qhFM040ZNRoCkh+r8INWZ5v5cYhBni+rrLJtZRsJO2tQElUjAuNiUzCxWMIEhIbPG4mOpbe4+mvDoN6kCGf84JgGoOTZ7G93MsE1N4wY2Fh42AeUoc8VEE6wZt71vAX9Q/Ftd3rGEPROlEooGnZEz58CyCKlg0hn5z+ezj8ZZS3EQ2VAhFUmTqpRomZ0kKDtYMy523qVlagQr77GqUMbKe1gzLqYbAO+vGaOy0RZ7VqDXgC0WlawFTZF7psnEzoaYKS3UXaykZaQmoJZE4MdlWkZVYH661MRzw9fx/PC1fHvkVZz4Cjz7LJTLbwDegG24XNd5gB+46hF2dD/L9u5n2db9LO0Nk8xKo56XiLbDjCIbNh4lUkyZjTylchwOh9krFb5LyHEJgElE4Dpl8sM47FBpXqtCtiIYGJgoKv4kQ2aGsqXTPu2wxLTRTiXVykSpGQePBlVgJHMV/T0/zvajn6kR/qDdShlcZqSREpklqUMutly6lFlA32JprqQLiqUzQ45QeQkE0EuFcPf9GMqnK5ykSRUgqqhsZ4J+c+MC/361jzFTPE5JUowbXVXCTT+WWviEtIejjEonq9WAbjIi7fSpAQQYpmtR8q/lqm+nF1EOaa9A3yMfWLTi81wx35c6mVnL9G0frznvyCfuQtyF5f/V81UdYNb1AJCOrEcjssVNYqtc1wpYBFRw6FQTnLbW0RQUsJR2CwxHDcwXi7nEvxVTTwBJADsV0QRXIs4elfy+IoXPMXMjTqWAKlrYMxXKUxbt01MYeR9ntoKRDzBmQ1ReYVZCMkCOkeS3lQVh1oRmcHsc1FUGKhsiWfCbLLycA00GaceN3IdzsRQTVSN8K5CkbpoEWEkVRUyfAYGC41Pr2De0jSeGd/D88DXsH97G8al1yZhamivceBP85H85zGsrf8hNPU9zXcdBUqZX46uPKSxSqsyAsYrV6hQGAfsxeByfp8VlD7Ps90d0CqYBfcrkOqOFH5Us2yTLddJIu1+gJxxiRppoYUbHOLAJ0Yp0dXCK02oVgWHTFozoWoriUSpRh7dQrKQGw//tP13AChq/HjF7KTntNfGjc03OOBdc8iDwS4Gz5Ve5Unhw5qOrdCTxM8ePpYOHEbn5FgtyxqmB1e6NVKUfD7MmSyYUA0e5BJbDMbUxYWQ8aW1AKUhTYtZpXxCkWq76dr5ySPt5OsJxDBRD5rpzykpaSmmciYtnJTQR1TsJV2yaVBFQuDikcRetLo2DzaDpfE/ZmxbkdS8WAIx/yxcTQwXYMfmcr2A2ROVD7LxHmBfMfACzIel8iWDWYHPpBczZwoJzKhOsrEGYtSh3pTE3ogV7E7hNFpIzcbM2dipg1OzEkxS9wSAKCyMKYttQVUNRXQOhha+NYkayeDiJcaAVos68mvayHBy5mn1D17NveCt7h7eyf/h68q7ODDIkYHPbEW7ue5L33PhFru05wMbu41hv/X8RIYk/NKrSAusxViqnCdlNhW+qk+yTEs/g6RRMIKeEmzH4kEqx2ljNtbf9Ou1P/e2CNRoYNofTNwDQWNxHEBlCIQ4oHX/pCYc4bayjUelev77YCxhYuX0ncTMaXcSnkhUhsGhWz0vJz/WyUACLNWhORbzdU4Fbc+OvJB6c+YgpCEIxCJWRWFqCIu3P0BkMYxImlL7VQrJ6jiriaMszSovTjVIUvpiJ/37HChficqlsU/N48ttD7b4oSwqiXPHqhT9f0Bd7bqX1xENsqfK7nqu1tBKaiNrm7lNkKeJiEYiJUrE7o5YMTPvdQ05aGyg7rUv/huvC0BAMDMDAANsGBxk5dA3quV00TE8nvnYp1XbgMgFlQJC18LMWlWt34Le3Eub3kWuYQTUZDLSspvymDxNkm8h+4zcxQp8ONU6AZsPRriilRbwYFEhhK5+WcIoQIRPl5McM9dVUx7EgM6JaWx9oVAVCVeDUTC8Hh69h39A29kbC/vDEVYRKM+VknRm2dT/H23f8Ldu7n+WG7v1c3/UCtu3hYWGgGDT7sFWZxq9/gLSqEIjBDDkaKAOKPIonCPguAY9LwB4CBiJhbyvYgclPkmGryvJ65XIVFmDg4DNEmnyqDZZZo7ld9+h0z4TdBzyxUQpGzS7KTiviH8PDxFQ+TpSZ1ROOYJf08zhLmixz1dZzTW5k0TjkS8nP9bJQANUNmtepASpic1pW0alGWKUG6fcNylaUm3yZ8+Asm8+NTYYyhgpxMUnjEm+MVwX9KGDA6FtUSFYLN780QlPk2qhgYeHhEOIqi4pkFh3XUlgulW0/1Dx4uh+swbjRUcMKGfqn2P3APTWFRa3lk1xz9En8qINSdZxiqXz+5bDSnOvqncTB37mF3uAUlvJ1n92INk0inzNAOYCZYhPm1T9By9gkTd99AGYVRj7EmSlj5ysY5RT82vzyJOiyLOjtpRSWSbdWUGuFsMkkzJoYWaAJJCcEGYsZo4kXN7yTpg03R+6DbkaM9cl1BLmsnnMR+h75AEJIgK17AUSGgokwavRot5QyyAUzUbg4DsxK0qFqrp2hgRdYvDB6NXuHt/Lk0A08PbKDg0NbGC+1J9eyvuUE27v38+PXP8j1Pc/ziu59rGoZJCVlTKASOYc0z5LSrRcRuoLByH+vqAD7lMdTDPIdUeylxAFCVCRRNymD12Nxc2hxKwZbsWlAV0s7VPAw8UQzjJr4rAlOox5+N0esTUnW02LNfOJGMJpoz0+awpTJRMkWKVKqghNRURC5/rrUBAc+dgtl5zq2u08mcxHvDp9seXNN34kYLyU/18uqH8DeT9w1x+qoXEJMbFwqOJxyluccvxxwpoyavZ+4KyEMc5TugGQQkMKnKGlGjZ6a5hrLceanwzxtKp9Uy05KE4P2hguexVOdstkajEWkuSEmAR6WFqliYCpVk62yyj2Ko1wcPIqkQSTp0NRvbzincvmzosTwfV74ly/S/NB9qFmQWchNjdOQLyZZMZIPoVBrsQMogaDJwm1uoNzRTZgqYTVUyLd2ELzyx1h/149Bby90doJhcOJjW2kOJ7GUn9QRmCogQ4VZMjVrtyKZJE03xvx7feJjW/GVwZrw9ILgZAWLfmMVpoRMR4Joox+zmwpTxWb2Dm/jmaFt7BveytPD2zkwugUv1EkAaavEtV0HeUX3XrZ3P8v27ufY0f0szemZyBEiFCSdZJX1+aeYMNroCMfxxYqom7WAfU4snlUFviOKxwnYh0clmsxOZbBVmniNCrhFWdyE0B7xEKVwa9J8fWxSVCKeIpNUXJMRBaFdbKakhbE7f3fRYGz7Ix+kXU1goZJoh4/FhLQybbTSEObpU0PRDM3FNspRNwUjqpFoUqWk09mkNDOU2bxo6ufFyFq8HLOAXnJU+8h90eXlCsHBPyPn+IXC+QjMM/kG4/aGI9KzZNOQGGbgLlpBGlMW5FQp4lxRGITkVJGiN0ITBc0H/8gH2H3siRqr/GzdL9VzUSKDJw6OKupsGjQJmIdJv9HHmuAkPWqEjso4rjhkVJlKZMHGFlkcpzhXa2nb7TvhNW+B0VHtihkchM9+NnHL1Pw3MsK1YW0uuwLCJhM3l8ZvdvBWO6gmodjaypp3f4JDQy/iHv8XmuwxpjKrqugSsnP3q/xP7J+5iW033JCcdyrVh5R8OpiAiBIhhSalGzW7a9xlq/0THI+qTJvdYbqUVqqhf5TdD9zDbe+8l6lUH5uKzyR1BNWwCOhUIxx2buD0qg9x8l++yomBt/Pc8LXsG95Kf35Vcmxv0yDbu5/lTVf9B9t6nuWa7oOs7zhJo5QiIUxE6hb752FSspzOXEtzZUDHjIIRcmqGaSo8rkrsEZ8n8HmckAnRjG4NCq6TBn6aZu4IK9yEwzoU/eb6RDCmH/kAoSpHGU5zbeBBGDR7Ey4jxRwZdJyLFGDSyCwjS/Rx2A80PfyLmBQBoUSaKcmRY4aWYCpKKI6D4JpCI27q2EAZA4Wj/IRDSU/I4rGf6t+8mAVgMV5WCqDaRx7/GyqDkqTP2lo8F5xvdH8532AsTFNhiSw67XAks4nxnlvZcuwBrnIPUJYU40YHAKvUIK5YC8bRUhkgRz4RqPHDZBDSo0Yok0r44Lcd/QwTRhue1arHchbBqvlzERcrjUsbPWok8Tl7EbOmkfBDQkoVIsWkH+gGKgRK5/N7Yi9eLh+GMDY2J9gXE+oDAzA8DMEi5addXZRyjXhmHunzKVy3juCGu1h1+5ugrw/6+jj5mbuYdVoXJe/a3xyQffovUOkUs4aOBVy1wvlL+haHbQmLqQCD0jknUJhL/bTDEg1Bnj41opVS5LS58eifsfsBaLrtfaQfflciBvOVJvYNX88zw9vYO7yNvUPb2D++g3LFAr4fy/C5puMgd6z/Jjf07I/oEfbT0TgOzDWCDzEZNHuxwoCUmguKEx0Vq8vNv/IgTw8+zT9/83McO/QoT+Bx3NCfGgqux2AnFreEJrdg0SNtTNmaBiaOZUFIqSrpYPCRDybuz5DaSu+ylWNIddEWTkSjDJPYWAU7au7uLSuQT+y6h1PmVSCS1IDEzWUmjDb6wmEChAChQrQbinYdAbo/QW8wyCCa8mI5I+WlLJx8WSmAah/53CJhSfreC43zje4v5RusSCYRphN2b2L5xxZmQRrJqDKOcukNBqKNLIwaPQuCrVOpPrqLQ7jR0oi3yRD5fKMc8rKkSKsKOTWD56cSf31FHPzS8KJ8/MvNhR3xzDdRYFYatbsDnW2h01JNTE3/lQgWC4WnhFLJJJV3SeVDCrMp0l07WP93/wF/8EAi2NXgILKYYO/o0O6WVatg27a51319+nVfH/T0sH/3v0Vz3Fq1u/oW+1vfyLZbbtH3p2HV0r7bRe695Yfk1Ax55oqw5iv0lsoAYaov8VHHfYvjiuxq2GGJU+Y60qpEtxpNHBa66MwGBemnH+ZI87383Td+jeeGdSbO0ckNyTnaMhNs7jnCL77PYscO2LEDrr3W4sXvHmLjw78UrQVdj1DdBUw3bwlpD8coYxGrpYCQFwh5Ap/viOK7FHnhfzZFFSawFuFWLO4O07wSnaGTRShhE2Di4GKqGQJvlLzVgR1WMAiZkSypyiTyjfs4sesemnDJSxMpXGylHT8+FmXRvYlDsdi/8W6uP/Y5HDXX/yCFi6csvIjvfylUP3txmjTobLC83cmAC+1qkkrkikxFFdJuFMy2o5lqD8cYCawlOX1eyhRQeJkpgJHMJrwqH3lMEzuZWbssj8uFwpmYKs+k8ZcKVJbJLKpYthx7gHGzC89qxfPTtIejpFQZh4ATxtokHhCPo7kyQP6Oe/EfvjsqNLIW+Ex1ow7FuNER0UYUk4pKD5O0KmETUiyfJG91LLmA589FXKzkKJdBcxW9fj9GOcSfNWmYmcaa1TQCZlRxSl7/a88qnCq53kER+D/Q1pYI8cm2Rqz1s6SbXPysphgwsjCZbWPsroX9exdDrLBMFdDlHYvy800q37gvUd6L3Z+mYArlGmzwj1KUNOOqI7HadfCwXPM78xV6LASaTzxI/o57yQPsvp9cME5OFRgPWyPBOOcn9gD3qz/Pc6PXJr76vcPb2D98HdOVFvgUiPwqm9qOcGPvM7z7hr/UWTg9++nIjnDk+z/HtttvqRlXEhCNunZVoiCtExW3jUsLDhXGVJE9hHxXAvZR5kkCZiNN0azgFizeoHK8RoW8GkUPZtSxSyX0CXq16VTmCinSVGgLJ2jwCmSUq3mdlM364FiS2FCgkV41orOyAB8Hg5ASqWSn0AS4x75Qc136dz0KZDBue1+ieLtKRxKSv+qmMwQ6dTOMaBziHXXe7sD2XGbMdtb7RzVHE1Z0VYohaaOJWTKqXLNzWWqdvVSp6S8rBbCUj3wx+t6LgTMxVZ5J4yeZM9+4j/XuiwCcMtfRHI4zYddaL56RockvMhS5BcpWln6yoBTr3RcJjNpdT2yp7rh9J7uPPcH2o5/FVq4ubKGJdjUd5TrrZiBlK8eMW6GJYpQjbUb8NrrcPqfy5KVz4QJWCqanKU3nyI0PIwUDO+/CVIXMTB41q1gzm8eecZFgYYJCwheTFdQ6i6DJYqy1V3dUyto4jWVW/8+9kJnLVjr5ibvYUExRwUncf4YKaZTCon7fasQC4briE0AYUSnozmC28tnkH2LwIxsTLqC40XdzZYAyGQRdLVyUVLQDm3MDzJClHR87KK5Iodu77iNNKdrp9eF5Y7QGE0zMtPCNyR/kRfunGf6z69mze4bjJweSdMtGe5bt3c/xtq3/wPae/fT2DdN88zVcM/BFmlU+qWHwsHhm4y8umpkCtV27tNunzHfx+S4B32GIPaIYFe1mtRVsw+SnSXFbKNyKySYMgqiK2SMV+eR19+IyKRw83RCGoMoFGVKUBkbMHtqDEU1PEfFQ+VFqZrsaZ9zoIAx03UucPDAtWcbv/L0kZfnAx26hRc0uCMoDeNjYu+5jQ6DPa+ITYpKhjFc6SfOJgWQXpvxTOoVccrSHYziVAXwxGTTXcPVvPs7+Rx+k75EP0KCKVCKeobKVpRhkl+Wagpe+RevLSgG8lMGV+dj/6IOk3UnW+cep+Daj0klgOrVMlaxM46dUSXO9REIjpwp43lgNn4sdlpiVhqRheNqfoSsYpoEyCljjn2A07KixHuMt6W3vvJf9j95cM09Hq/jdPSOjt9WGxXTYpDtUhS6uZxPOQJBXZGZnaC+dxp5xsWYqpGYOwGc3aZdMqcT87qahYxBkdQBVrTaYau3B3/4GvPHHSaenaG+cRLIGytZN/QwUbrTFn3C08rODInmnh9WZ2lTVrtJhGtDZJaKiYC0mgaLmwdr9wD1sOfYAWVUkLw282Pw6evP7MEI/ChfGPWVVlGKrotTFSqK483fcmzzgez9xF/mounhcdbEqOI2Fx7rgBMUwTYEm9kXtGqvXY27XPcwaLTXX4BkZVpWO8s2p1/HcyFYODG7i8MB6Dg5tZqzYkRzX2zLMK7qe5m2v3ccrevazo/tZNrYew4hy4/24ac3kOON3/h6ji3QPWwxu4FLZtJo/fiRkPwWexuWAzLmgtiiD21UjW8zVvCGY5malGDPXsCY4icmcy7WEjU2AhY+LTTriRYpdKto/rxbsNucbNHHTeERwlEt7OIYXWf3HUtck66G6hmRLcDSyxzWqK4e71ASNQREPi3SURVSOUlNz5BmRHhqG9rDjw19j/6MP0vHIh2hXk8T9kh3lkw0m2P/og4mcqcnkWaRKfjFUG4lxKnRM3Bef+0LiZaUA4MwVoRcD1X6904auP1itBjimNpKXLHmro+b45TT+YlvE8bCVtnCCctBYY0nGTI9pt0CXGsWO+g952JiEdIaj2J7HSOaqBYqwZp5mZ2FwkKPTaVK7/46eiePaas8rrLwHeYUxG9DgaoEQM9b3MEvgGARZGzfXALfeOudj7+3l6MgRKqf/nQZngqncmhrXV1N0jhMf28qYuRbPS9OjRpNiq5jFc0b0rmapvP39jz7IRlWI0vPmslHiM8R1DbsfuIcbj/4ZAQZlbDKqzK1TX2FMWkhFVmU66otbHRMpolsJLqa4F1pz+nsGWgspUTRtuJlt77y3Zsx7d99PZcrjudFtHD69hmND63h++BpeGL0aN9D1Ao5V4brOA7xpy0O8onsv27qf54bu/QQNQrOaxqnKdZmPHHns0hFGlgg0KqU4PHGYPf172NO/h+/2f5enh57GDVwQnYJ5Myb/NbR5JSY3Y9IaZdecUFn61BQVSVO2sviBqQv7lEoyYkIMDEICMXGVXos2Hnlp5MUN72TLsQdoVKUkaaFs5bCDYo1BE7sMUZqMLxU1iHGr+iVUP0fh7vupiN61VSOm41ZRXCOMst40V0+FEjaOCmvOte32nRzYdR+NwSwWAa7YDBs9BGIl9/9cjc3qtqUdSgfZQ4SCNJK9CLGAl50CuBSoFtqmyhMqkxCPznCIMbMnWdQxlssQWGyLmLc6sD2PktNes9h0L9ib6XvkA1j4qMh1EYhJoEJCD6b8Xna84Te1Zf6Hf7h4Zkw+D8DG6muyBS+bImgysXsDCtlmis05rAaXXNMsY7l2ptu6MW1vyRxmfb57AFjH4ogtommnm4rfkMQxitLAixveScPQnhp/7XREMhf/Vrj7fsaNVlaFg8k54yKmAIO4DGbLsQcIovRgUwVJemmXmiREB1EDSDKR9C5CU7p5EVfPfMU9P3CoYypWDXW299inebFnJ3v3wjPPwN698MSeBxkenVsPXY0jbOt+jvfd+lm29zxLT98It7Q9QaMUNT0EMZWa9rDFPE6LwSCkQZWw8BK3Y7EyxPNf/2X+4Knf40D+BZ4Pp5iOUkQb7AZu7ruZX7r1l7hl1S0090/xfY99GCvJLYoLwvQYOsMhQixm0PGlasLAEilMVKK8LaXp7Iaki9CwyN9xb7JmF7OeX2x+HdunHsbw/SQ2JYQEyowqkQ2Gjbnnpvo5aqkMMEOWJhZSSMytC0WaOQUhQEOk9Du8foYym5PPMpQ45SxP63EuxmasOOJivYqkExdS9Y7mQqGuAFaA803L6iodIUOJjK9DZ17EC9moSlSCCQQhz8q6/iyVCTSSuWrOt1gu61THxx5j24jPxB4fNe2iZiGVLyL5QDfgqChNAvbJ2+d+IJVK0hrZtg3e+EZttUeW+4F/+02sdIFKYzZZ/HFv2LLRxHSqj0M9t865NZzFLZ+Vzmktk2cTI1V0FHGz88quezSnk5FZEENpqQzgKZuYnK06cyUE1gQn2P/og1ytihGnfUCaSg2dg7YGPSqYOISRAJuz5uNA4HzFXT12R1WYcbO8MHwt3xx5Nc+ObOXg4GYODW+g9Ov6eNOEa66BN/xAA63+V3mj/Vlu6t5Le9MEI9IOCD1qOPn1ROhHAjUWxvObzFSjADyFx3+KxRPqJPv9PANRb2Nj6iRbMdmJzS0qw6swSPubCTf+/5J7s3/8QXRb+Dn3T5wOCWCqkH0b76b3xIMLCAP7pRcbjzY1QUH0+l2sk9p867lMBlEhN049hI8kxV5G9CzpAi+FQ4itypRVk24EFIySLp4k+O0W1lS5fuYjRMc/7IgcYzF0qgmOOh3Jut0UjNAajDFqdl9wFoE47XTIXFejYC5GLKCuAM6A3Q/cw7ajn8FCpz5KySdcouuSiCb8mt9AY4PKJ1wpgoqaaCjKUZZHqIyEXG2preL+Rx9EffNP6B19kaaZPIVCA34xjTNdwMlXwA7hr7Zpi31ioua7bWi+GJU1CLMmYadFsFHT9Y60rWPt3X8wl/LYOi+PfR4yj/3ygkbVeauDMLBWXEtxNqluZ9pKn4luem0wlvCwxEI/Zuz0sQjFILvrHso4Cdd+tTDV39Mi1ybEQyIKBR8fgzFpo2xma3y8SsGpU3B8eicPnbiag3vGODawiqMT64nbDubSea7pOcjOWx7iB37uR9ixA667DtLpufnpDgbxsHGx6VD6ngaYEeWERix8Y/GmkjFDiOIFwhqenGcJCQRglj5ls02aeYdq465whpswMHEiK1jHWLzwNBNV9ybcfT+j0kmfGkoUkHatKUakheHM1QtiSNWEgZOpOSbW/Y8+iPON+9hUfAYevpsDu+7Du+M3kvsa97TIBRM0UYj4eCRiRdUwUPSbqyhbWbKuNkTCwCIVFmlT0zX3cqlVHb9vElLCoSGqF6qGi8n1U19nYtc+XEkxZPTQFw6wKuinPwwJTGfZ1M6zNSBjQ89UOg06zjobNNcs+72zxcuKCmIxLHdz9j/6IBsf/nmEMGnDF3fwKRrZJCPDDFxWqcEkJS0w7MRKDatS51JUqmxQOGGuo2xmaXQnWf9zX11QpDTx1G6sI3vJTM1g5X2ktEhWjCF47W04G66as9z7+jidH8IdeYx0eoZiromW1BiNlJNyKouACWlm/M6VpUHGqGYNjbFcF7D56XTGbe/T9NMrOMdKML+rmZ4U3aCjYjTQGYwssOhBRwBcHAbNPgIxSQUletRw1GZxTmh4mAgqCmQajEobI5mrksyx0qOfZeR0A0+Ov5IX1Y/QP3YV+/bB5OTcb23aBOtX9bPN+Ee29B5hU98p1mSPk6LWNRbP2ZbiUzEJRuK2012qFHHPXheThihhUtutigF096o9EvAE+r9CNC0tCm7G4jpp5jYV8koldEeFW+3hGFk1G+XjULO/8DA5ba1N7k08353eCTqjDq5zfKfCVFTpeyYhFwdSW9RUzZqclTQeaTyxyKkZmlQBiQqsypLGVD7paC5iV5eHiRdlF4UI+zbezS1H/zSh6Ibleec1r4+FFQWr0/iJm2qO7dTAJOSwtSlZt2k/T2c4hKlCDjfcsOg1L0brkA2ml208tNz8nMszC5dhR7BzwYVWACvh1tlSfLK2EXfEN2MrL+m6tGRrRLOV9olTVAppGqan6ZwexcgHMKtQ+RB3NoWdr2AV/AVjU6ZB0GDgZx3MbAhNoJoMpprbKLXkoDFktr2b6z/6CBi14m2pRefi0KHGAJ0+ulTP1/OZs+pjDOXTEY4n3x2TdkLDqqGmSPv5yMKpoDA4ukhnpNhSXO2fWDD2pRRSezDCuNnFOv84VmQxVguBOO2xJGnGpR1TQgbX7eTGo/fjRGVKLjau2LpwUIQn/Nvxb/9S4qvfuxcOHJgrHG5s1F6zuIBqxw7Yvh2amuauYymuoeo5Wx0ORj71avt1zt1TxmZcDParEk/jJtb9UJTp4yjYjs010sqN2FzlrGOLV8EQhWc20OwOR9XWiiBKpTQI8HBw8BJhLijy0phwK+XvuDdJbzSJK8QVcRMXnZWVYsTsPSN3zd5P3MWG0j4MpWpSc1ORsRBnBmUoJ/euem8W03/AXM/euKrXVCr5XnXGz3zEn8X0fU9t/EV6TzzIqqA/yu2JPyeaI5iN4hi6zWMnZbNpWd6p+esz7efpC07jYZ2Rf+zAx26hL6KwiNtKBmKdk6FU5wJaBGcqumipDFCRFJYKapp5p4MyYQHMSkAqP0HDxEzSxDqT99lYmMaacbEKHjJPvyoBGoUwaxHkTPxVWYrbf5DuV33fnAXf28u+L7yDjD+BZzawsXIAL9qBOBIy6rRFFANjC4Q/QO6RX6dPaRZFH5MRaSdvNlNy2ln34ecBFqRhrhTzXTIVyVAmQ27XPezdfX9i4buSoiucpLoHbpxOl2UaOyzVtDsMo8Ki+ZkOOjvnT3GqrLnNwYtMPvJ+9rN0cZyLg2dkEgtuMcSZJH1Kuylue+e97H4Ath7+DMfHNvD08HaeGdrG/qiQarTQCffp765ZowX8zp1www369VVXLXo7auZuqQDe/DkDiLlsKsBzaCG/RzT18YsSJlLtGmVwJzY3qDTXSAtbpBH3+/5njUA58bGtzBotpP08bWoqspi9yGo2mJEm0sqrUjP618eNzpritAKNZChjzXOTeBi44uAob0WpzC2VAd3gXubqUSQiArSoRAVhtcHsudjGXEOZMLrDBiFpXAJlJlxSS935aj5+0AR4p6P7v//Rmxn4+q+zNuxPjlOJwtFdvIqSwVI+vcEAY6qNyfTaRX9n/6MPsqn4DEKIG6QYNzppD0ejGEqwKOV5NVYSaD5fvKwVwIKMmlARFk06B47AV76CsTeESZfUTAHJh8hsOPevgquo9bWHjUKYNfFzDm5vmlJLM4XVV7O2/E2CrImXtbEbfWxDMX2GrXKLN8isqR9YkwAHlxADW+nFvVTAafcD9/BK1U9IVLlLSJ8aYSAAp1JZci7Oxk8ZC7IaX35VG8VUWGTC7sPx57pZheh8bc/I4AbaRdYWjlVZV4phszaVbv+jD3LD0U/XCH99LLSqPGO77uOa33p80RjBdORmIvK6z3/oBWhURcZLrewb3srXR+/g+Tef4PAz/5VDI79JJU63NCts6jzKba8r8X0/OGfZt7XVzl3xH+/n1Hlwt8SJAk2qwIsonsBnT2TZ7yXAjQbeo3RR1dtDm1fgsNboxjFbKFfFkCZ6bqVh9/01XdXCyKcc0xiEYhIonfU0Q5Z2NcmY0UZrOEEjFUKEIdEdy2qK05xW0q6uyI2hqSAUofKSNptnClhOpfroKA7RELF/qqr7FJ81FdF+VLvk5j6ViGMnFtExH1FtjCAeX/x9H6I9j1AgxaS0EhoW7ut17CFe2+MfWUNWFbAiihIX3V8jRVBFJRPSHk4yfdvHF1xf/GxoRl5JFEbMcutWKb6l5uqloIV+eSiAMITxcQ79619jfvOL5CaG8UoZcpMztM+exsgH2HkXK+8hYbQEP/1DxOGWIGNCTqBJCLochtfchGzaij34Fcq5BsJG6GkYRZmyaAxgsLwqoaAuSwMjkmUyvXbZbdxUqo/W8kk6wonE/2hEtnLWGyUUa9GA05ZjDxD3WE0uH+hWYzyfumXB8XDu/CNL7aBiCz9OAQzF0IVb4kQZSzoW0Pnw3Qi6CX2c711t4YS7709qF+ZD0Bk8sLhlHfcaiFMUlRKOTW7gmeGt7BvSFv3e4W2cnJ4LqrU2TnFt9yBvu+0fuab3MFf3HGZL2wH8TPOC+MapqiBlezCBj02OPL3FfoyH38X4IyvzhQ/PDvPFv/wAU/TzOD6PS8BUdOsaFdyEyftJcWNos1naeYWajASidnmMSor8638jqXbd/+iD9EaupJyaoas4SPjwz7Ov5Q00VwZIqTIedk2RVdnMYnsuk+m1hBWL/iihIaVKCW1BXJyW9mdoU3nmN76JO34NGKuB5QXV/kcfpKV8mkwUw4iFvBbQRlXBnUb1b8UKohT1VU5F3cncKBsoHbGkVquS+K9BaWX8zj/U5zwD7ffpzLU1wndT5YWIfFBFbjKhJGlKpJaldBg1uxOqlBCwCbEIGDZ6kmOXmquV9qg4H7w8FMCHPwy/+7tsnvd2mDEIIvre2c4WwiaBrDB72ztY94adsGoVzx76LsETn13SbxsvpONsTB6a6taIJ3bdQ97qIC9zVbor2cYZt72P9od/HlB4zPWEVQjd4QgT0rIg5x0gq4pUsKOipSr6Z8IlKS+qBXl19WH2kQ8sqwTiHdScH9/FlYjES1WYkSwdajzqKAYzZJMFHHPLLGfhtFQGzpi5sdjOZeNNOyk4O/m/M+sZ3PU0zw1fx/6R65h1dW66IQFXtx/ittXf5e6bPs/W7ufY1HuExlyFgtUyb8tt19yrBSym3mHSyo2Ubpjkx7eqGfzSi5SqFOmsO8tTg08lBVZ7+vdwYvpEdH9gKwY/gc2toS6uuhaTYemlW41yWvooOy2c9Js1/YDSzX7m+47jvtAd4YTmZ4qU8Lap/2T/xrvJLlFkFSvl6XgunT7c2+YUS3yv2sOxxEkU5/7H9yPAoGw2JRlR4z23LuC4Al0h26omNJ0Gfk3aqgAT0kyrml5wr+eiITpmAZoB1kJzCMWcVaAVQsxnVZAMA3f+Mdtu30kiZqMdJrvvr3FfxnNZ00Uw1GFmAyjhoCIlNRMZcovxiMXPhifCICT3zMdkUpoJxFq2gBFeGuaC73kFsP/RB8nkd7HmBxsJchYTuU6KLS34WQfL0B2oqrfP862BrWvXwht+YtFzr6TQ41y3cdtu38n4Ix8gqwqk0QtnQnI0qRJCyIS9eGevvDSQUWXKOFH3Ir2NnqVhBYJ8JrFWXCwaVHHZ6sPqXUqI5glylEeIz4sRb4pd8pIsoPn53meycDQz6SCpRXYBITBKB/l//hP2D2/lueEf58XBjRz85CZOTCiUEuAGmlKbua77ef7bji9xY/cz3Nizn+s7XyBtl5MgooFiQnL0p689472av+uxVICgIvtzLhUzQNGvxvmPsMx3H30/R57/bZ4deZYwUobrW9bzqtWv4scKDm92h7heGshGHafibmI+BpOZtRQrWYyIdqFs5egnN5c1VXVfYp9zbAVXovaHuiOWT8PQHgbu/ONFi6zGe26ld5ldYFKhqipUM8SWSOksKlVhVhpp8waiNGfoOPoZJqSNvD1HClgR7UqyVIAnNqEyauggBEWjKjEkXbSqSTIRT1H1jkChe0UMSA+TmbWk3Ul6g1OYSkXuGk3hUJZ0EsBeLjun+np3H3uChqE9c6ndQE84RAUnoqkwzuj+idduvJbm37M4TrYSoX6xmQu+pxVAcpNXpQi7M4QIbUxTMRvxrDSeytAYTHH1hx9f1ho4H5xJyC3le9f1AxV8dCm9oULa1Ez0d3rJANKLG96ZUBqUcLDQ7Qmf2/iz3LbEGKcS//AY1SRcFUkv216xepcSYkSWvjAhbQlvSjXmW0pnsnCKPbdiHH1cZ+T4Di+M6baDzwxt48nhG9g/vJXpUnNyvtVt/VzbfZA3vuJR3vj+d7BjB8yc+A86vv5B2tQ0PmbECaQRt0L0MZHoerKPfIjGoD8KUFoUaKJy228mvzE/bqQDnxVOobtW7ZGAx6MUzGKUb98cmLyy6XreevVb6Z4Mue7Fb7Fxeoyp8gRdXkBGmrBUoDM80Jahg8/BhhsT7pnsGVwBic9ZDOLy5jQeZaWjIGVJ0VwZYP0Sc95whoSIhN/mkQ/QpGYxIWLeNPRcYSfUI3lJ0eefJo3LajVIwZ1kxOzFlVTSsCZ2DzrRrjb248eukhwzjJrdZMNpsmqWmPo6bq5uoGhTE0zf9nFcYGLXPRCOJWswdm8tZWwt5r5MewW2Hf0MA9YaZs2WhM3ViPY68U48zspZyv0Dyz/3l4KOZil8TyuA6ptcCSJ/NLr5eD/ZZHGs1Ad+LgUdy/bEXeZ3w933MyFtdKiJmv4FFgHjxkL++BhxJsuWYw/QpDR/yosb3slt8/hmqlFt3blYVf7hzkX56auvffCRXyFDJaHXjn3KK81UWOxhGB3VKZb//qU1fPL0F3hxaDMHxzbjhzpwlrGKXLW5zJuv+xpbul/kVd17uKFrH+m0m6R0rn/rO/TJ1u/k4KP30RQUsFRtP4A4fGhF5GT2rvtoV+ORIDLwI76eakyl+nArwzxtBDyr8jwrszzHLCPRcSkFr8DkZ3G4KbS4GQfDuAq3X9F1+K/JqnyNVZxVeQrSiENBd/sSAyeqb+0qHebAx27BERY0+qlWlNXskwG66jl2leiuajYzZKlIpsYlk7/j3mQHcWLXPWdkoawmOYtbhqYoESI869zIlmMPJGNooBwJc93nd1VwKiFaW+MdpkKKJopJc5YQifY+hu4LrGCADBUzQ4N/NKoBiHvyBviY5CU7NwdA5Rv3sd4/SgWbYekikKV59xejVMmpGc1mGykFU/m0qWlMAipRamrcqD5Ox1yKRv5SEk+eDS5pHYCIvBH4FNoF+udKqcX3UxHOtg6gukio2r1hEHDaWlcTqD1TYdLZ9Ok8U3FZ/FlTOE2BRjxjrqGKrlA1yeBRlDSzNNBEkYwqJwHRGWmq4Qc5l7zg+ailsK3lH1EYpFRp0Ws/n6Iu34dDh+Zy6uP8+sE52h66cyNs6TnC1b2Huab3EFd3H+Lalue46iP7OPg7t7DWP0YQFWul8DAImaWBE2/4s2TOq9fB5spzUcJp3NvVTCzKIqnEjRM/6CWEZ2yHyTt/hj0De/jmoUc4UZoTihtJcYsyea0KuRWT7RjYUcjSi849Ja3kzWa6gkEcpRuFDJq9lK0cWXeUdjXJuNFKTs3QoCqYBIxKMwVySxYYVqfJbj/6WTKUifvfmsRN6XWu/oD0RPEjpf3SS9S8rPQ+7n7gHm44+mnsyNXjYWKhFU4Zh4aoW0Ccoln9/xIOKfyIEtpMKq9DYFxaaFIliBIGZiRLZzhGCi/J84/972PSxmRmYSLFSvs6xzn2NgGVyHDpC05TkTT9jmapiut7bPxoRvXeMUSYMDsu297hi+GyqwMQERP4U+AHgNPA4yLyL0qp5y/Ub8z3ww0CncEwglHTlGEl1s9KGzUsZ9UDNZ91BYM0UoQgoiWAiIoWCmj++DY8JqQ5yjzQvmbNK9/PmGpfMhvobLEche1S/PRh5Cpzdt1D6ClmQoeUKmPj8kXrTfzIoVFeu1nvVqanYd++WkH/7LOatgjAshW5niLOqjy3vN7lp9+UY8fhn6PPPrZAKM06OoNCqZj7JkgyMxSCiVcTu6heB6rqIY6LqjJUopRCnwPAk+LzFC6Ph8+zDx/fVfDVPWTMdm7qvYW3Ondy/anneZVXRKU1i+nssSe4/uhnEbyojExz1gypNsqSJpAMjvKSXtTt4Rj95JJGIjoDZ4AgMgryTucCzvt+c2PNmtv/6INsO/oZJAqCxjQjLrYWliKYKmQys5ZUZRJDwiXX79lknLSdfAiAMmkCDBopI1GldEx3EvvzY56iOJNnxOyjKxjEiCo/CqSx8QkxaFEz+FiAMEsDHeFEco8cfDK4FEgzJm2EhrVoUsNy7pVvHRrl848do/H0t/hwMBEJdu3CWhX0o5CExA5IGEZLkUEUFywKxksq/ONxn5wosbYtw3tesyF5rs4Xl9IFdCtwWCl1FEBE/hZ4K3DBFMD8RR2IlWju6uDZSgK1SzVqyJX7ec8X9iQ35xcH/oTUUooCKCuHfJgi9APKpMlSQCG4YpCJrMOAmGFFW3FdajzaHlsMSTNNFEmrCo2qwLe3fZx/OtrHgccepuKHOJbBtb3Zc1oki21bD25+J9fuvY9xchhBgGMZWIYkCnL97Tv58liBpmc+yypGOBF282dTP8V3hm7lS/+ZZ73kOH0kxfHjc79jN7p0rCvx1v9q8+Y7GghbJ/jLF56lISNMFlwGZyr8wfOK77Nv5Z7ghWSu5wulDCX6pZc1qh8SgW5iIOQDi4mH/5Dvf6KVV9tv4V3l/w1AkRQZKlgE9KP4Nj77pcxuFE/jMRO5cpqUcCMWP6M6WBd28pfhr7GmYRX2tMlPvOU6Xvv2eXN7+86E/yZX7udE2Mm/pN/K+8qfpaBSKFdbmrbSNANOlEcfp8XGlmyyW2Eh5308D9VpshYhlch4yERVvBYeYDIovRTuvJd872to/KvXL3kPl7r3S7ksVvsnCIi7NMc0e0TVs7HwDxd8r0CKibCBXkKKpLEIOJnaUpV55lKMrPEkHhUVTZ0w1ye0C/OTCVYiIL91aJSPfvl5vCDgt9x/YVxlmZEGemVCVx+LxaS0ocRIGvToHYrPcLQb7ie7aPD9YiIed9o2aG+0Gc1X+OiXn+e333LdBVECl1IBrAJOVf19GnjlhfyBlS7qlVg/85WEHyrEneWo6uTrB0bJOAZj+RItQT9jqhkRH8cySFlG8qAppRgJs4n7YYh2mplNkuBi7hIXC5OAk/TSzRhpXGZVhhFpo2I1M22I5lf3J/mj46vxwwITBS0gii4cHZ0950VSbUF969Aof/Tl5/kN6aZdTVIMMxRdrZ6ajDKnWMfIHvj4l1/NgedeR2mwifJIFuXGRS6KfE+ZH7wd7vrRWfbMHKN9bZG2zoCSFzDuhWy87To+/9gxGjLCVNGlf0pvCQT4hnc9fvgO3md+jd5geMH9i++J75tRXriew7KymFVp+mQEUxRPWzcwYv4028P/ywBlnpMCewgZEO1SMxVcQ4ofklZeF7rchMPVGAgmQ6qN/0+9k7TRyVTJZ02rzecfO7bovMZz954v7GE0X6ExZTEw8C+0hpPMkmFQtbFehjDQhkBYyYPy+IfGt5CPdkvV62w+5z3UGia5cj9FUpEla1ECUpGpMKUauD/1c+zsfQ0frbqHJZWh7AWkbZOM0ueaE6CtrO2+t0aALiZcX8Ec+yfM0U8r4CTdrGKURkoEGByX1XSrUWw8TtONUooKTiR09TWVrRwjgUUQ0Xd4ZoPusoWFEFJWDqN+hlHW0yEz5H/0r2vGdyYB+a1Do/zy3z7DTNkjCBVr7GHGaAaEadVEg2NiCQndRazEj9FHu5qmFApBEJKhfMHz8M+Ezz92jLRt0JjSolr/6y+5Bs8Wl30QWETuBu4GWLt28ZLr5bCSiPtKFEW1kiiRRjydnvm54I0ooOiGFIGTdjcdTFFUGSqeFuhNUmY61cdMyaNFTVIytBLJ00RJ6XRNS/mRVaUDYZ6ymKaRijLok3EGVDtFlQE3IGUZNEmZ06qLtG1warKCaQimIQShYqros6atVlBVP8iNjoGIMFsJlt1Sxovvqw0/wg8N/hN7h67nueHrODp8FYeGN3N8Yj3qowAbEMfD6crTtLWfVNcMdmceu3OGvg6Hv/sfb+A9X3ie1ZFQBKlZyCcnSrQ32rwwGNESRwpOAY/Ldt7PjTz5Wz+wYHzGbe/D+vo9UQu/IHL/KI6qVk4yyZdQ7Jn+OGV5kbI6ARKCAY2qlVuUxTuV0B32MRHeyE+buwmtNLZ4dKpRUng8p9bw+/5P8m11PSIhrh/S4JicnCgtu57i6wH4SuNO3pP/34QKpmlkSNrpYpICKUbDFr6W+xGes29g95ef58duXEW//RbeXvg0KggZpY016BjAsHQv6Cp1WnWhlEePTAEhASYeUMHgQ+r9PF68honoHj5ov4X3Vf6cUEFR0hjuLI7lc3DzO/mjJQQowEe//Dx+GDJRcDk1UeQ7Ryf4O2MNm9QJfLTw9zBJ41HCYTJsxDct2sgzY7RiBQWOqj46ZDraMSgmVROrZEy7W6py4eMsIgKoYCeN1U+qNpRAgypzmi7uqxLwZxKQsYKYrfiEoUIpOKn0M1oiE2WYhWTMStIS9Vu9r+FD0ZxcV3qSNxcepM8bYSrdx9A17+afjvZx8olvXHB3zJnWUoyVrMGV4owKQEQ+APyVUmryTMeeJfqBNVV/r47eq4FS6jPAZ0AHgS/wGBKcSVFUK4nG4mlO0sWf+2/k2+G2muM+F7yRj1hfBIXe5voFHMunctv7+NKjR/kl73OIKlKUDA2qxCQ5lFJMkcOSgPUMYKE4qTpJUyIjLp8N3syPm9/U51RpTL+AZfp8yXoLDY5JxQuxzCinXaDsBzWLpNpKMkVxYGgWgA0dDQssJteFF17QPvqHv9BLeTjLf5x+FZ+Y/aXkGnuaB7G787Rde4R0zyzXbvU5UhoBAYmKqOLkAtfXSnC5hby2LcNovkIQqqQGSwGGCJYpTBZdbvqd/2Cm7JFL27z3dRv4hTs2se32nXzwsWN8X+nPmZYTfAfFtwWeN5+nHLlyDDVERl1NS/AqnGALTrgFk2aOAceYyy0/ojbzXvkqqxjhifAaPh+8kW9V31ulCIB9p6cREd7zhT1LPvzx9TSmLI4338q9UyXeaXyVtTLCCdXDPf67knWzVmXoS1nMVsr8wX8ewra2cCJ4O+/iq6xhhCPmeixDFhQYAnzJegu/5H2OwbCFVinQIBV8DP7I38nj5o5k3k1RPFS+linexTv4CmsY4aTq4vjW9/JPM5tJ25VFBej4bIXTk0XKXqjvi4IK8HHjJ/i49RmaKWJLgK8sxkhzmi7aZYZB1cX/tt/OT/3U2/nIl5+nvdFmw8zjWpCqYU4bffwzb+DOzOEagyvofQ2fH+/mzul/oEFNYovPcNjCDI00RM/Cp3gzadtIBPyZBOQnHzrA0HQJLwgJo5hRzTMqadJhCcfwE8VarVROpF7Jn7W8kkLFxxAoHg9J25XzcsecjU+/ei3FKLracLsQOGMWkIjcC7wNeAr4PPCQugCpQyJiAS8Cb0AL/seB/6aUem6p71wMOuhzwff//jc4PVGk7C/0cwK82tjPz5pfZY2McEp18WDqv1BY/VomCi5X5Z/greV/pk8NMyDd/HP6rUyXPX6Gr7BaDVMgQxAqslLmpOriL4I38m21jdtkP+8xtRA5qbr498adfN27ntmKTxAqLFNwTIMgVNimwZq2DJ3ZFJ9/1601LokDg3m8QI9bKik63S5GjmeojORonO3ghRfAiwoqDTvA6Zwl1TWD2TFDqnsauzOPlQlodMzEerqmp4nnBvIEEY2GaAMey4DOXJpv/9obasYQY3imzExJu8qmSx5lL9CB3Ugqp20T1w/wQ0hbBpYpVIIZChzk5s3jKOcI/37wWwQyBYCthK2k2aDaGAxey4ng+7FUD42ORckNMARCtThJmCl653FNT5bBqRJjBW+Ro7QAubqniYofMjxToTljL4i5VCvcBsfk+YEZ3EDRnNFCQ80735q2DOOzFYqu3mEYhhCGCj9UXNub5cH/57WLjuU9X9hD69C3eXPhwWStfT54I99R27BMg2t6NA3ps/0zhEpfn2MKhghiCLeub00EqFRVPyulODlRYmy2gh8sbKQiwG3RGo/X4+eDN7I7+t0b17ZQqPh0ZrVbbv59jz/7/LtuTd6bP2fPnJrmVezjHfLvrJURTtHFF9Wb+S7b2b46x3jB4z9/5fWLrqv4/O95zQbe/YXHsU0DpRQlb+55fXXV+IeMblru/OVEsX7/739j0TnZ3z/DVZ2NS17L2cQi4ussugFlL1xSiZzt8UvhvOigRc/EXcC7gZuBLwGfU0odWfEIFj/vm4E/RKeBfl4pdd9yx18uCuA9X9jDnuOTzJYX56mZj1duaKXoBozPuohAW6NDg2Mykq8wPFOh7AVk0xZ9LRmaMzYHhvK4XkDZDxNLWCmFiJC2dODNDUJWtaQZntGWsxsoHEswRejOpbBNM9nGv/eBJ6lMNBCONjMz0Ig3kqM8nMPPp5MxOrkKr9ghFLNjhK1TdK0vMmVNUvB9TEMoe0FiQaVtAztSNpYpdGbTNDoGLw7PUvHDuewcU8ilbT71thsA+PA/7GO67OP72qKseCEp20gqPStemGSLOJYQ4pEPDuNZLxKYhyhyEFfizCzh2o5rODW0CifcghNuxlHrEWqtQaLzIWAbgq9IFNV8pG2DG9a08MTxSfwljnEsg6s6Gzk+VkQpRdo2WNPWsOChnO9yG5t1GZou1yggQ+J/Jdn9NFUJFz8IQYTnP/bGRcdSHdjsnywRKK1407ZBa4PD6zZ38M/PDCSGSizOLEO4qqsRP1zcwixUfAamyhRdv0ZozkfGNkjZJtNFD0PAtgzStsk1PVmUUowXPD7ylusSAeYFIaenylS8gOt6s/y/P3hNMl/zBfmBoTxlN8APFSnLSNybtmWwpjVTI3SXEpCff+wYe45PokKFaQgVP6QSzYVlCGvaMliGsUCYLqVUjowW2LYqt0AxzL/O5QT1cgqrWiHOv8/nmwV0XmmgSiklIkPAEJpQrxX4exH5D6XUr57VSGrP+xXgK+f6/ZVg/uTdur6NPccnzmsy3/OaDRwcylOo+KxkLyQieEFIvuxR8UPK0UNV8gK6sg5TRY+yF3J8rMj6jgZ6m9McHS1gGYIbKILoR2xRhJFvPG0Z9DRnSNsmpyZKeEGA6yss3yQotHNTbiOf/E2LXbs98oPfj/KiW22EOO2zpNeO4XTlaVldoHtDia4uoVAJ6Ky2Wn1FV9YhXw7wA4UbaIXkBYqyrxkXu9KpZB5jYTQ8U0nmJZex+Gjk31YKJNIOZU+fSymwTSFQIcrqJ7QOMhUepCQv4soxsLWStVQ7DVxNq7qLtLoa09/E8//Pj7PlN76CGyx/E0Kgo8Gm4AYYQUh1OVg1vUDkRVugIGLhA9q9MDhd1rsJYKbsc2hkFtsQPvnQgWQtvXZzZ826+vSuw3z8qwcXDk6Br3RI1TKk9rN5ndkWEwSxoKv4CtfXCvWaniy3rm/jD/7zEF7VLjVWtKlIgfe1pJL7Bn6N4EpZBqXFN0HJvFX8kE1dTaCUdhMh9DZroyJ2U7x2cye//Zbr+N2vHeTAUIG0ZbCxo4FQUeM+eWEwT8n1KfshacskmzYpuwEiECpF4Ov572qwKXsh73nNhmSe4zmY/0x/5MvPs7olzYnxEoQKx9IxCNdXdGZTbOhoXPT5X2pOtnQ3UXQDGlMWU0WXoekKBVevz/d84XEc22RNawYRHeOarZT55b99htZGJxnXufj056+lC4mVuIB+GXgHMAb8OfCgUsoTEQM4pJS66qKMbBGc7Q5gvnUwPFOmf6rM6tYMXdnUOW+n4nP/1j8/y7GxIrA097ghsKW7iRPjRUT01n5zdxNHRgt0ZR16mjOcnigyEFmHpsDa9gZmSj75skegFEGVEeaYWik02Cad0kK+v4lTh1NUhrOUh3N4U3OprKlGn6a+WZr6ZqnkJmnomUE1zxCaYXIuP9A852lL6GlO09OsfYvPnJrSlnhk0QEcGZlldNZNrssyBaXggz+whV+4Y1OSbTFb8ck4Jr3NaZozdmJRZtMmU0Wfsh8w643hGgfxzEN45ouUOEQoBX1ulSGtNtMgVyPuZhqNq8kYXbh+SBit18aUxf6P/CBv/ZNvsvf0zBnvl2UIbY0Ws5WwSrBoGZuxNRelHypesVbvAIJwzvVhCsQ65treLMfHioAWeoboB9gLFBU/pKc5vcAl9Oldh/mjRw5TdINk7qp1jABdWZupUoBlSPK5Hyqu6Wnin9//urN2Bbz1T77JvmhepOr3BL2LWdvWkHx3McXy+ceO8dhhTadd8ReubscSUpbJLetbefzYBPlKkMxVZzZFNm3zYzeuSoytyYJLNm0m6wtqXTV3/+WThKHCNoVQaaGfy1j4gR5vtXJbqdG280+/xeHRAq6n141hCI5lsKmzcUm3WozFDMevPjfEcwMzWIbgByFiCK6vcEzBCxS2AaZpsr5DP4PHRgso4IY1zcn9akyZBKE6qx3AhcD57ADagB9VSp2oflMpFYrID1+oAV4MzM8QmCr6mCJMFj26c+lFMwbOZqu1vqORkqezQ2bKHn6gEuuq6AYEoSJjmwxNa4vY9XWJ0KnJEq4fMlX0SNsm4wVXuydCRahgeKZCd9ahr0WPcWI64PBBYaY/izeaxRvJURnJ8UJlLt3SaSvSsGqGta8fI90zw4YtHmNqho4m7cs8PJxnvODVCDUv0A9F2hAqgfZpp22TlgaHtGXiBmGSyQRQ8kO97bdMyn5A2jJpabDYc3yCX0BbKq2NDpu6GhERpkseB4byFN08M+GL+O6LuOYhSuZBfGssGrpJmg20cAfibsYJt9Bir8UUkzCEMgGBD8WoOkJfLRQrPq/+/x6mM+tgGyTuj8UUsaCF6Wwl5Jfu3MSe4xMLtuFD0yVG8i6Fik9PLlWTjhoL/1zawjIExxJmSvpeBkpbu7F7rOT6CzJp/uiRw4ShSpT3fO+SbQnjBd2HNwznfs82Dd60tXfRtXymdMBDI4VkAyESNTSJ5qcpZdUojqUszO8cnSAM4xmfgyFgIGTTFreub+Obh8awDSLBrdfv1d1N/MNT/Ul20amJIkXXT9aXtqDLHBjKs/fUNLm0xXTJT2IVga/IlwM+8/abzsn6/dahUUZmKnh+lCCh9Lw2py0+dNfVZ/x+9ZxUK9+rOhs5NDyr73eoSFsGjmUQhD6BAltgcLqcnCdjm8mOAHxUtFuav7uIdzQvNc6oAJRSv73MZy9c2OFcWMzfbpX9QAcSq4RavP06m4KL6mPXtunc+NSsoX2MQYjnhzimUFGKIAwpRJafABnHxPNDglBRcAOGpisYIti2gRkopJymabSD5x6zyeTbmDrdSH4oE7Fbgjg+qa48jdcN4HTNYHfO4HTmcdIhm7qbUEoxNF3mqfGAXNomCLX7ZnxeUDNQYBt6PK6vg69lL+TwSIFNXdDTnOLYWBHb0gG0ohtQ8QI2djTQ2phKzhMHDON5mZgtcmjiCJ75IgV1kIrxIhXrpE7BBKywh1R4PdlwC47aghNuxCSFZUB8W1xfcCxttacs/ZCYkRUbZYhimwYF16ddOWTTdjLHcbZH9XwLJL7jPccnarb4rh8wMFWm7IesbWvAEEg7VpIhVfbDJPNo66pmPvnQAYpuUCMSY4EdpwNXC2fQLiXHFPSmOahxWVmGYBsGygAvCnibhtCYMmlrdPiHp/rZuqp5WdfBp3cd5rPfPFaTJQVgCZrPKNo1xQr0U2+7YUVCNXZFxojnvsExExfKZ795DFMExzaT41w/5NtHJ7imJ5sorIyjXTpD0zrV98R4MTnXbCVyJ+ZSzJT9JDbUmLLO2fXx+ceO0d7kkMtYDE1XKPsBjil0NDlnfc75ytexTESg7AXYUUzOsYzErVmO1och+jmK0eCYSbzgYlX2ni0u+zqA88H8AFfaMilUNGXAM6emEgt2Y2dTcpP9UHFweJaKF2Kawu9+7eCC3cFkwcU0FKN5aizhzmya9qYUJydKNKVMTk0UqQRKk95A8gQqQAVCYbSJ6ZEc/lgOdyRHeShLUJxbMJnWMq1riqy+cYKp9AiZ7jwqVyAdBU4rXkAQCcWUbaKUqnmwchmL05OlBdk5sYvBC8EKQir+XDcmP9Tn6M6laG906MqlGC94rG3LLHBdKKUYLZ0iTB3ip/72b3jo8GPk1SFCO8rnVzky6moa1auxfB2oNWlecJ8Uc8KfaAx+JNAtQ0/bzetbEZEkiylQinyV/72vOcWGziYODOWZKnp4gfZjq8gq7W1OJwIz9ht/8qEDHB0rkrJNrupsjHZuIR9ZQul/8qEDPD+YJ1wiQKzHHjJd8silrUQxZmwDL1CYojOb/FBbulrB6QCnUoqygpRlkHbm3G6FilYkS6UDKqX4vf94EVP0ufJlj0989SBGldsqhqBTf6uvbbFdL2j/fINjcnVPE8fHdSqoYxmsb2/ANo3Ean33Fx4nZdW2hrFMoVzRGU0xepvTHBstUPIChqbLUbaX0NeSYXCqTNkLmCn7NdcdZxGdC+aymyxaGnTBWRywXeq6lxLC85VvyjZwPb0+wyjAbIjoDC4BDCFj6zhG/NtQGxe5VAJ/Pr6nFcD8YI5jwVSJxLosewH9Uz5vu2Utf/9UP5YBJ8ZLiX87CEKe7Z/h+z75CKenyqRsk9UtaaZLXmLVOZbObhieqTBT9mlv0ov21ESJXMamO5dmzwt5SsM5KsNZxka0sHfHmyCIHhAzIN01S8/WSbrWl0h152ldU8Az3QWphEoJhhHxq5gGBGHihjg1Uap5sJozetEeGytqcgkRbFOSNFCYy9NPOyahUjomoCBfDhZYiv/27EHu+co/UywdIB8eYNx9Hjdq3GGOp8iZm9nUuJN0uIWJqXWYYTeWYZAyhbIKCSVhKk4QV5AuBT/UsYo4+Fb2A1DaL21EmT2BgtNTZX5n57ZEWS8Vi4jzp+Miomt6qBGqi7lV4h3f0HQJ2zQohcGS47YNYXC6jGVkkt/yo8A44VzmT3w/jOiNWKcstUONs0zmuw5GZsraAre08RJnL80X/obo3/vJm+dKb5ba9TamTPww5NRkhYoXardNxsYLFH5IEjx+7eZOcmk9r441F7D2A+3Lj+8ZEGWxgeeHTEeuxHUdDTRn7MRwKUUK7UK4Rda2ZTg6OpvEnKqNvbOlV5ivfOOdUcrSmXBxBtf87LuPfvl5CpXLw9WzFL6nFcD8DIEgFHpyKcq+9m2nHZPWBps9xydoSpnsPz1NoKr6xkYW77Hxkha4oc/R0WLy4PsKUiLan+6HTBY8jh0xqAz3cPx5k8pwjmCsmfLUnCVjNJZJdeVp3XicbF+B1ZsqjBrjOCnh+t5sslB+PVpE8dg3djYyNusyXfYJIjdHJXI12SJ4kUupwTFY196QCP+ubIoT40Uc04iyILSLoRRtUxWQsrRCEYTN3Y3k0hYjs7NYmSN86jv/hz0De/ju6e9yZDLO+hUajXWsa3gd/+W627mu/SY++W9FlGuSDrTAlXQZ1wsIgYBoi7xI3YRjGUlq3lIwDEn8pmnLYCZKv01F/tUwCAlDxd1/+SSv2tjGe16zgU+97YaaoGmh4i94AFeakRHvDr0wIkBYJtZgWwaleQ/7R7/8PN25FFNFj5IXYhlCNm1TCUKCINTXoHS8yA8U6SrLeX42zXyrtdoCj5V5vNNLmTqupIBc2q6J11Rf1/y4wguDeZ3Ga+hCPM/XgfO2Jof//JXX11zze1+3gd/7jxdxI1+7H2Wt/egrVvHUySliN9vxcT2nm7ubOD1VxvPDxDXV0uBQ9gLy5SDZbZ6vWySOTZhRMWG1sXe28ZT5hqRlaFdSR5PD6KxLvqSz+0byLlu6de3FctlJlxO+pxUA1AZzlirwODCUT4JEMPdwV1urscXnhSEoCCsm5dEcxYlmCkNZKsM6QHs8TreUEKejQMOaCda+tkQxO06qa4YgXSbjaHfNuvYGWhocmgppTk2WF1388y3R3/3aQZ4b0IU9tgGWaRAqxeauRvonSyiRRPhPFV36J/WOphJl0DiWQRjl7//oK1bxny+MkK+4YJ7CzhzlkHuQsfzzzASHue1zepu7OreaW/pu4b03vpdbV93KTX03kUvlkjF99MvPY4lFYGhFeHysSGfWYdjVflczEuC2aRBEOxbQVmn1bmQxpC2dghk/TKcnS0nAteKHeGir1LG0EK225s70AFZbdtMlj8HpMiU3oCll8a0qJtNqRbFYXrwhsS9fZ4PMD7IuNg4guZdpS1jdmqHih5ye1O6QZ05OYVkGzWmLD7/xmgVrOUa1BR5G6aTxbsKxDBzRQvma3mxNvGb+dcXQGU0hjqldUzCXBltZ5Np/4Y5NAAtiEFtXNXNgaIZDIwXKnqYvWd/RSHNGP39HRwv0T5ZoztgU3QDbNPnU27adUUCu1HWz5/gEq1szTBa9Bcbe2aZiLibMP/zGa2qoJqqzs6p3E5ebwJ+P73kFAHOC8+joLEdGoCFlsratIVl8FS+kryXN8Ex5wdZZKQjyafyRHO5IM5WRLO5wDn+qMTnGSHnYXTNkt5+ioXeWDVd7NHbPcnqmQKhgfXuGE+NFKr6KrLM54Q86qPSqjW011YQf+fLziyqDeNHd/ZdPEipd9duU0plGZU8HEYdnyjimJFbXpq4mJosuo3mXwAtpSM9wx3WTGC3fhM7HODr8JAFFKIEljeSMq/np697Pj227g1tX3Upftrajkh7jnpr0vlWtmSTVVVCM5HUcILbuDRFWtaRxTOHoWBEvUCuqoShHKYiff+wYt65v49REibIXaIUWanoG2wDL0NlX1dbc599167IPYGzZjeYLunYBLcxNQ9U8xGvbMhwbKyT1G/OhlPatx1ZgyjKSAHB8zxYbx/zYUkuDw0zJxwtCvdtQZ56jagu8WvinLUO/VjozDWopBL51aJTJiN8nY5v0NKdoaXAoujoVVUQHr+O4jwjJDnI+tq5qZsea5kQ4AolQ3LYqxzOnpmuuozlj05V1GJgq89TJqURprET4r9R1c3KiRFc2RXdurtgxVoDnQq+w1D282GRtFxvf8wrgW4dG+fA/7GNs1sUS8BQUKgGHh2dZHVUCOpbW3hJauMMNeKPaT18ZyeGNZAnLc4Ecq7WA0zVDbns/mZ48ma4Z7BadZWAbgmUaFC2Dtc1ZPFKMz7pJoHF9Rzqy8koR7UGtv3OlC/y1mzt51cY2RvMVvCDkxHgx8u8bmCZJdbBtGfS2hFTM/ZTTz1PiOaaCFyiHozz7HAgmW9q28sObfoLxybXkZ9Zj+KtImRZ2IUuHuYG+bK2QakqZjMxUaG9yatL71rU3sK69gaHpCkXXxwsU69ozdOfSSRV0c8ZmtqKrQGcrAUdHC4m7YjmYohlOv3N0gu5civUduhLXEP3gBlHeeJxx4QUh3zk6wff//vKEXa/d3Pn/b+/N46wo73z/91N16iy9LzTNIggKgojQoKJGATUYzP0lLjG5Ma8sEsZtolczXo3m58RJMs6NUUcdM5PJmLnIjMaEiUxcs6hxwy2IBI0gO8jWQNNNL+f0Waue+8dTVV3n9Dm90N30Vu/XC7q7Tp2qp+rUeZbv8vly5fyJ3PeHLe55ApqgLWFSFDTdL7ETp56LQPkndF2jNWHSEk9TWxZibGmoxzox3kH9ll9tIJYyiRg6EytVh+w4gQvJBKzd3URZ2KA1kXY76prSIBURw50ATCoLZZnAnOesLBKwt5t80tiuolp0nVPHl9IST+e1n+drQ+4z+8gr2xlbGqS6RH1vIoZOIm1S35KgPGLQEk9zuC1FUVBn1oQy2lOmG+3U1b3qTWfbVSdfKNHrWOzzAy3WNtCM+AFgxVu7aElkbDGvDtddos1g665iAs2VtB0o4cNDpbQfLgJpa5wbGYyaNopm1hMc20qktg1jTCsETUrCAW684GQeeaXBNqvoVBUbNMZSbhhYLJnB0HVOHlviJn60xNMcbU9jWZJPGuPsaYwrATXg6hVrsVB22yljihEiQHEowKHWNr658j2ALCE05yE+2BJ3TVoWJlUVB4lamzkQ/RBpbGNjyyfuNRdpEwmkT+Pk8GmI9MmQPgmtIcQlp09j9oLyrKWs04FdOX9iVjz3xvo2kmmTlngKSyrTgBRwsCXJzPGlVBQF2bi/haAh3KQf50tYVRzk6Rs7kl2ctPijsQ4Z6HxjgSnV8VOmMi+VFxnUlAaVL8COFnJWVC3xNLuOtBPUBdXFBjsbolz3+PtURAxm5qmTsHZ3E4btH3EMg0pRNe1+ic+fXkN5xCBlh+86mjpOpvY5J1UB2Zo3vZkJehUrHSf9J40qwbA8YuTtTLwd77SxxW4n5k2+mjmuxFV99Tpul69ca3ekQcKG7pq+lONfidT94LlNTKoyuu0g83XKzv1zPv+SkE5rIk2i3eLj+lZ3VTjRkzXbk3vVm862q06+P+3zAy3WNtCM+AFgT1Oc6GGD9n1jVfTN4VKSh8uwYh1Lw1BFAn1MC+NnHkZUt2CMbUWWRjECKgrF3c/QqC4O8+Mr53D+9JpOCUUl4QD7j8ZBE26G4/ef20RAg4/2txBLmllZmdL9r4NkRrLjcJRx5WEOtyawEyyJGBqxZIZ/fGkrANcvPplrLyzib57+HXG2kNS3kmA7lp2pq4syqsVpTCr5NNXGaVQFT2XbQSW5QNyOQNFVMtgjr2znlNoS94vspLnH0yb/+NJWTqiMUBxSnasjf5E2lQ6OcrBZyFSmY0WTsTi5pjjruvJ9UZ0vaWVxEJDUtyQ7meAcEhnLjaBJZywa2lJMGVNEZZHBodakK/i196g6x8TKCC3xtLsaOtSaoDGW4t2dTdx80TQ3c/ndnU2kMhYZ0yJk6G4mbjxtURzU3GI/qYxFdYlBa1yJymmaco7qmnA/597MBHPDikvDupsjots6Ewdb1HXl60zydbzRZIKfr9nlSg84sifRZHYbvB1pecRwI3EaY+ku/Rb5Osh8nXLY0FxfSXN7isZYSontCfWspDIWEytCWSGSPZk196az7a6T7y/7fH+uJgaDET8ATK6K8P6GaprfORl0k+CYKJGpDWpWP66NmadZNGaiRBMZV4wrmswASl1Tz5ikncxMTbidP3T+8A1d6fN4l/0lIZ2P69tUAZmcOPp8ONml+5sTWfu2Z44ije20s4U7Xt/G367dSWO8ETTQCFJpzKBGXIZMTUNPT6dIH0eZCFIdDLoPZjLdRlATIITr4DMCglTGYuuhKJOrIvxlXzPtKdXZqhR8SX1zAtOSNLSlssw1ibSFoSkHrJS4TuyOugQpNwnH0AQneQYFpwOMJjM0xVTiz+IZNby6paFglI2hqWgnUFWo9h6NM74s7Gb37mmKY1mSKdURKoqCbK5vQ0rcSJhgQCOdsXjkle0ArF6/H12o2PukaRFPm4Tt3AEpJUeiKSwJ1cUGpqVMd8VBjWjSckP/vlR3gusn6GnnlGs2ccxoY0qCHElbYB87ni7cmeR2vC3xNPXNCSQwbWwxOxuirNl2xJU98ZqketLWnnaQ+Y4VMXTaEhn+vKfZXjFBwJZIKI8YfHSglZZ4hhM8x+nJrLlQZ7tgSlVWVT6nox9oJ6zzDMfsZ9ipxrdgSlVBP95QY8QPAMvPm8of135E5NT9hKqjCL0jFT+gCQ7ENZX9aSfrjCkJETZ0ysJqRhII6ATtpJrcMMauZhnOw7HpQKsr8ZCr9VWIjEyS1naqLFptCyltKxntoHpRCgxrMrXap1i+YDGnVs/jiTUS0xJZImw1pWFS9qzZm8i1+WCUoMeXZ1lqJt+eMtlysKM6mSR71n2gOdFZrAyVwGUgKQkbTK6KsLm+jbZEmjZ7tRPS1f1NmapDfXNbA9DhJHQyqTvs00dImzJvnL2maUwsM2hLmCofwI4OOn96jRva6JiVQHUqKUf6GmypbGW2+fmaXUyoCLvO65CukTKVUF8kqDOxPEJRUHc7ttqyMPGUyeG2pO1sVpm66/c08+a2hk6dk6P0eiSa4rJ/XpNVgKcxmsyavTtZsm0JkyljirKikQplorsOXDvPwZEfcKQHupI96c9Za77rboylGFNikMpIWuIZTAvGVQXd6LQTKsLsaIj1OkY+3/dtwZSqLBNlf5dMLIR3EJ/keYa97dGF5L1dTazZdoTTJpRx22dmDLmBoEdy0EOFY5WDPuf/vMTB1lTWtmBAYFlkS83aOvoHmhPEkmkVqYJKrAoIMAydBVMqO+mYF8qkDBuarRui5JrzdWoSk7TYR0rbSlLbSkrbSkrsBmGLa1ljCMsZSu7YOoWQNQ1DK+bU8aWuGBjgJj4FNNXejCXdWfczNy102+qKbtnhoJaE8kiAg63JTu0T9n3ShCCetrJE0bLupa6c37VlIeptW37SlrIWQHFIZ1JVEQG7atnepnjeJK2a0hCN0SQbD7S6GbzO6TRgxvhStxMpJKDlfDEzlrKjO4O9M3YFdY2woRFLmcyfXGF3lh0rFU0IHv36Ga5Jxxsy/HF9K4m0xbzJFe62fHrwTjby2NIgoYDmOmOnjlFZtJsPtmVJarTE03mFw3I7MW8YcIc0hmpfxh7cHF/Ihr3NBDSBacHcSSr72jHzvHzr4n4tNJ7PnOXY/zfXt6kSlDnZzbomqCoO9vn8xyKv3B8UOu+B5gQTKsJZwRlSSjRdY3xZeMAHpkL0SQ56OPOz17ZzJKrSv52vsgQlnazhhrs5USRFQR2JJJFRHbYQapacAmpKA1l2Sm9n4y2ZV1sapCRsUBwKELbtuppQcspCayTqaORoW0lp25BCHVPIYkLWdMrMLzCp+HQinMKRlhK3zQ6WJdnbFKeiKOCGO1YWBxlTohyG0pKkTYukhA/3tfKz17ZzwwXTOH96DZ+fM56n3t9HImO5yo2tCTVwBDThhl1iX7smNGrLguxvTpAxO8ICNc/NTJuSiZUhjran3dKUSfv4YUMnoKslx46GKO0pVQsgbJtjHAlsRzrh+5+fxXee+pC2RJq0PYgZukbETsA5Gku62j26JrLi9aFjlnjLrzZ0hDA6TZWqjsK48hC6prmZqhVFQTfipqY0VNCkk0hbtnJoB0VBnc0H21i+ci2b69tIZpTsd9DQiQQD1HtWTnuPqkzijCnZ3tDOKZrm2uDHV4RpjWcKJkI5z1p9awJDEwghMDMmuq655sXasg67ejigux0vqEFm71FlInOqmfVXB5kv18ZhXHkob5Zvf3WEgxWFU+i8rYk004LFbDkYR7NNrRKVi+GtZDZUGPEDwM/X7LIVHDVXTligOqaIoYSovHHQsWQGgSBiaLb0gtL6EALqW5OEAumOL9Bbu8hYli3o1mFj3t0Y55RajaCRJFi0iQOtHxLXNxMPbMUUjQAIGSAop1JiXmTP7E8hICciUDPUMlQYXUgks5yjAWELytnyE45U7+SqCO/tanI7OeiQk3/kle3Mnqhmgev3NDOpKuJmpbYmMoQCmitpGzGknTSmOs9ExuRwW4ovzJvIcx/WY9lRME4cfshQNvOxpSEOtiSzSlM6yo7tSZPdR9pJ2vLJAlxTiybIkk44f3oN931xTt5V1f1/2MyOBlWIRROC7Q0x7lj9YZZfBrJVSXccjnIklnZNYwIwdJ1rF05m9fr9FDKDLJhSxSOvbMe0TWRVxUF0TVBRlP2lP9yWpLk9za4jMZpiapWZNiXIDLuPtGNaklBArcgSKYuioMq8TmYkOxti7qogoGldirQ5Tl/TlAR0zV6dKb/T7Ikl7GmKY+i6a1apKAqwvzlDZZFBc3vKlS2fUh0ZUDNJ7sA5EFm+XZ0Pjk8UTqHzloUNOxBC+b0A93syFMNDR/wA0JpIEwpoqr6sPRuypOrkHv36GXnlAkIBjZrSIlcXSKI+XAFMqgy7X6BYMkMspWqFCi1Dgt3E9M20iS3Ut2wh2boPkKBDUE6kWM7h1Kp5fPOsi7n6rAtYt6stbxGV8eUd9vtw0GDxjDLe231UqYw6cg4CTLsICChb7JptRzC9WhaoWX08bXLd4++7AlXjyiPuEt3V6o8EONSqlEkd8wJAkaExtizE+j3NfH7OeJ77sB7TkpTYNvCAplEUVLPpkKG5USyGbVNXyqcWmlACdiFdzV4TaYtk2iQS1DtJJxRy3j3w4hYlT6BpbtnEI9GUK9jn4NjIP2mMqaplAqRdiwHgyvkTueGCacyeWJ6V31AU1Pj+c5vcXAenWE88rQbbz88Zz/o9zRxsibvb06bFmBIja/WTtrOdDQFpKbGkcrRrmuN81ygKqkFyT1Pcla8o1Ck60UquVpOlZDA0oQbo9pTp1iDokA4p4aqzJrN2dxPv7mwiqAsmVkY8kTcZ7v/D5n6XKiiktDpQNvDBisIpdN5rF05l9fr9rkaVkNIVIxyK4aEj3gdwxt+/RFsyjWWpjl8JcEFpyOD9713s2lW3HlKF0qfbWvamLaxV35KgNZ4GqXReIoZOPJNBageJys1E5Rbbbr8DKZSpSZflBK1TKGIGZfpMxkdmURSoKujQKyRc5rVjfupHf6QpllLKg3bnZ1qSqpIgb9/5aUAVwPhgb4ttulGdTcouvxi0o1s0QVYWshM6WRwMkDZNmtvTdt6EqlU7oaJjoHBCWwv5PDKW5foAhMAtAOOVP1arL82tJ2zoavVx8tgS10laqCOadffvQUrXpARKETVjSabWlGQ5BTOW5c56HTRgcnVEqb92UY92Y30b6YzF1DEd98m5/tyVQSxpYtgCbsJW9QQ1gBYFddIZE01TekcRe7WUMpV5rDgUIBIM8M53P13w+fWafqwcDShd19AFlIYNxpaFCt6/fBIoR2NJdh5pZ+a40j7Vmi3UZkc51RFQNHSNxmiqy3b25XyDoblT6LyFrr8/TV+9ZdT6AJacOpZV6/bZYmdgSqUds6RubJZTLRzQmFARxpJw4Gg7UTsAP2xoSNFKSt9Cs9hKSm4joW/BFG0ACBkiaE2j1PwcIXkKETmTAGMI6rqrEX7UFHz9ookFs1G9RVSa21PKcZYx2dEQc23cM8eXsutIzNU2CRkaY4sMpo7pCK287TMzsiorORWoDE0QDuikTZN4WoV8loUNxpWHMPSOKkvOw5wy1QPtdH7e4h1A3i9YR2lCJbQXDGiMLQ0ST8VImR1FGCUd4aNFoQBloYDrh+lRFIenE8tYyrmOoFMWaiaPt9pC1dktJPbmLOdNU5n9DrYk3XvQsXxvyioMvvlgG+3JDBaqQIiT2SwAy7IwAjrTxxaz84jKtDVtv4bzbKTMdCc/Rr62TaqMsPtIO7qmAhfSlsQyLWorwqpsaBf3L5+54oCtbjsQEgb5lFadfIDWZIbTxpf2qxnqWMM9+zpwdCXxkSvz4U3EG0qM+AGgIZpkbKlBUyyDaWt3VxUH2HywlfV7ml2nmiXVcryy2KIh9TEJbQtJsZV2awuZ0CF1MKlhyMkUyXMImjMIyVMo1qaQMTVbhll9+QMBLWuWfahVJeg8tX5/l6Jk3sgBDWU/d74kzpJzUmWk4FL3/Ok13HzRNB55ZbvyX6Dq7WqaUGaNNtM17bTE07Qk0lQVGa6wlZvf4AmlbG5PZdUY6EqeItcM89dPvO+WCvSiRPVglp0X4C2R11WVNl2o0FSBCi1N2prsRYbmZpQ6WajRPOcVQH1LksUzyrK2F9J7T2Q6juEs33P3HV8eZnO9PRmwxyZhS0pomuZWtPrZa9u57w9bVF6CBDIWmqYip7rqdDt07YUbImqmlLjao18/gxVv7eo2AzmvuaKHyXrHSu59OtiSVNF2puxV9u9A0VtJ6GNhOIjB5Vd3GkHsaYpTVRyiJBwgbOiUhANUFYfYdjhGKCBpN3fRqr/EQe0n7NZv4p3EpewN3E6D/u+0i4+JiOlUZb5JbfJHTEqsYkLyn6lO3UKJeQnF4mR0YTBjXCnlRQZB2zThJCJBR4JONJnJetCceHhQX9BE2mL/0Q5ZB4lgUmUkK3Lg7z4/S4VKxtLUlIbyPqw3XDCNR79+BudNqyZs6ITswSiaNF0HLKhOSkjydpROe2LJTKfiHcWhgNumQnRIG3Q+tsP4ijBP33g+0aSZVTgEOldpa2hLUl1sUF0SdCO20paqZRzQYHJ1R0fmZKGajnSzc732T1PSyT7s5CK4bSsP2xXTlEnHq6OTu295xLD9EioUFombfOYU4nlzWwOr1+9HE8KNKktbkjElBmNLQ112ut7zlUcMZo4rZXptCeecVMX502vY0xQveP8c8j07p00ow9Czv/79aaPOvU9OHYeQJ4pqMJ2i3lWfMyB191yPREb8CsDJxNU1kHojjZkt7GnaTEJsYcvR7VgB9QBqspgIp1Ce+RKl2kz0zDSKA2PQNUG7abqFNkDJ4zoOuaJQRyif41ANBjq+kLkJOoVmuNFkhvaUiaapfRxfgFfCt6czCmc/pxj5riPtbqlEIaDIljyQdn5C7izMm3Cz+WAbRUE9q8BMd19cJzoqn3dJs1dJTkx4V1EcuaaZceUR2lMZjraregABTVBd3JFgBEpvSDmzO8JVvdIbQpCl1Ald673ni1zJnU075q6woXeK/XYKrIQNjZJwwHWSm5aqedtdp9udk7OnUTD5VmgD6TztlCVv6yaNL++QYBlMp2hvw0cHy88w0Iz4FYCUkqPaM2zTvsYW8XX26fdwVHsakyRl5hLGm/+bicmfMSn5S07I/APV1jcoss4mKKrcWHdTSnf2LFBhmAEl10I4oPFxfSt/3tPMjoYYS04d686epZTEUyojNrc2aO4Md3JVxC4pJygLB6hvSfDB3hY21rdREtLzXVqXvLmtgcff/UR18pmOOrmq9q9JLGWSsh2T+R7686fXsGLZAk6bUIYpYfeRdjYfbKMlnu72i7unKU5TLJU1A3ewpKp65Q233NEQ4897mvm4vpVDrQm3I8qd3Ta3p2hLqGSt+ZMrmFgRpjGW4lBrwp2pBzSNmy+aRk1pEElO5w9MLA91WoXlmyH/+Mo5PHPTQl6+dXGWrHS+fW++aBqGrhdcwW09FCVtKr2hdlsoUNWKzrCjIcbmepVH4F0Vej+HrlZ+3tVa7mqlK3q6ojxWco9/Uk0xY0qC7sSjp+0cKHJXKNC9dIezEs23ih+ujPgooCUPvs7hzB/ZF38bwzyFcn0mWmYKGVPFUGt2NaakXdB56pgiEmmVzONEVMbTapaHdDIuNXRdUBrUVYUuSxIxNIIBQTRpEQ4om3TI0EimrazMSMiud+qdvTW3p9jRECNjquNhRyNVFwe574tzAApGHeRuf+DFLXxc32bbolVFpHQex2h5WCOgB1wBMe/M5s1tDXznqQ9piCZV1JF9P6qKg13GrC9fuZa3tjfahbM7a+hXFRk88pV5AG4YrBNWqWvCFWvLzbbMl1V6sCVOW8LMEkD7/caDbDzQigA3mxtU3YCTx5ZkJX31VzKUN8s67InmklKyYW8LoFYsEhXF42gJTakuYmxpyJWOKI8YbkhnTzvjQrPTdDrNvn37SCQS/XKNfSWRVoNfxpIENMfs0vvJTX+1pSWetpM91aAkUWa23DY1RpP259UxpXHyg5wSsEOFcDjMCSecgGFkr24KRQENygAghLgf+DyQAnYA35RSNnf3vmMZALydiFP1qbk9TUBT5SGjSZP2VMZOfJJcMKOGBVOq+N1H9W4YV2UkwOE2leQzpTpCMKCTSFsUBVXRDUdBc2dDuzJ9SCgOBygPB/j6OSe62iC54XaO3EBLPO1KEaTsgShkaIQDOiUhnZZ42g2lFLZeg1MtqtDxP2mM2VFP6rq6EqGbOkZ1Qo5uvxOqdzSWQtckR2PpLFmGgCZYsewsoPOABCpe3wlH9Z5XE0rV9KSakrwDIHSWVvCGZ27Y26IKm9cUu2afXHmDfCGTzuzfSdZzSmY67+sJPTEBFJIH2H0kRsqUrtKoJTsmFXWTKmiJp9l9RCW4KW2Zon4JGdy1axelpaVUV1dndV4ObYk0jdEUyYzKfakuCVIaNvIcaWTS0+vfcrDNTXD0kjElM+yJyFBASkljYyNtbW1MnZq9sio0AAyWCeglYLaUcg6wFfjuQJ3IWSIfak2wqyFGLKFi9TOW5EBLAuUHU6sAKWHt7qM8/u4n3L50Jo8tO4uTxxTRGEsrx6NpseVQjL/sb2Xf0XY+OtDG3qZ2mttT7Dsad8sbCgHSTlL6/caDBZfak6siHGpN8EmjstEbmlDhhPbMcFx5iMZYCtPuyJwQy1TGcv0Nj7yyPa8zK22HSDqZz11RWxZGCJXA1BhLsb0hRnWxQTSZ4Ug0ja6p45eEAu55HnhxS6dl8Xee+pA7Vn+IaUlOqAxnZd+GAxqhgM7k6mLXBNadAzPXjFASCjC+Ipxl8/cu273Zso5EgnN+YSf0aULYRWt6bn/uqQmgkDmmJGwwpTqCoavPxbDj950Rtb4loQrc64JExuo3h2Qikeiy869vTpA2VS3ftKlyONrs78dooDRsMGVMMTPGlTJlTHHBwS9k62Z5sSzp1mIeKgghqK6u7tWKb1CuQEr5opQyY//5LmQpw/YrTifSGs+QsewMTV0VQXckjFOmmiWGDc3tuB94UVWJak9Z1Jap2ar3GXAiTdpTqpqSN+LFScLSBWw9FHXt6bn25OXnTeWwLbGs2aGoTru2Hoqy/XDMjSmHjrrEFh0fXHvK7FRXN22qVYhjA+9OgtohN1RP1S7OrtvrqIduPRTtNPC0JVQSWcaSriwCdpt1XbhywE7n2xM7rPfe/dNVdQQ0raC92xlQQoYjdNcx+CkHsOhWZjkfPY0YKWRXP3V8KcGAzszxpdRNqmDm+FKlkWR3IMm05X7+YTuAoL8iZPJ1/gCN0ZRKGLQdXZotd9IYTeXd30tbIs3uIzG2HGxj95HYiB80qkuCSpzQ/iJZlposOhXPhhKFPu9CDIUooOXAqkIvCiGuA64DmDx58jGdwEm2Mi2LtJ3kk9Gla4uFjiLjjhTC1kNR94u/92iyU0SJQ8qU5D4GmoBYysSy7bw/e227q1efq1deETGIpTKkMko3XdeUbowqUq+ykYO61rl0ol17V0ol8SxQ760sCtCa8NY+y6+tn49ExkRDyQyACodsjStfiARXPdSJtMmdvactiWlabD8UdQXKnDYnM1beTrs3kSjdFflwImLGl4fZfaRdJWPh1PlVPpp8Rdu7ozcRI4UitXKvszRsIARuQfdk2soKFhjoCJlkxupk1nA0nrrCWTkIgbty2H80TkBPYNrquiPNlFQaNqCCEWkuG7ABQAjxMjAuz0t3SSmfsfe5C8gAvyh0HCnlo8CjoHwAx9qeyVUR9japUoGg7NgioGSB3Taj7OWmBUEh3S9+Mq06L5GngK3jaFTXozR6MvYMQaJiyf/xpa1MrAhTWxbOSjgB9UVUKpMqUzcU0AjYMhTODDYYEBjoxDyrDDPPtN60JA3RNJqAoqCGKSGVtuj6K40rIJYbqlceUaUXj7SlSGUsVxQtoGlMt8sQeu3dhl0ly7kXQgg0e5CSMr/uTW9L8+VmWXqLbjihh2FD48TqCLsb21XWcUBjSnVR3nT8ntj2+yo4lm/guuOSmYBaXTTGUqRNJR/thBMPdIRMKKCRNi13BQA9M2vkrhxUTpvKeQjbIoX1zQmooMsOsqSkhGg02h+XclwoDRsjosPPZdCigIQQy4DrgU9LKdu72R049noAUFgLP5E2bdtwx75SqvyBs6aqwut7j8ZpSyizQ26/G7CTgIyARmkowKHWhLtacGadSgpWmQBAdbiaUOYlr35OMmNh6Mp8dGJ1EYCraV8WDtDQxfLcab9jRioO6a5ZyrsayKUoqKQKYilVAvFINEVVcTBrRu6tM5uv5oGzb2M0xeG2ZEcSlt2mkK1DVFkc5NTxpT3u7LvSWsk9t7c2Qm7BkHyrL+f4XjnvRE4Ukrcdhc7XWydtV9fU33HmH3/8Maeeemre17wzeUdbSkqVoNdVR5frEE2kTXdOFHHEFm0/x5QxxfkOAQy/AWA4ke9zH2pRQJcADwKLpZQ9DqbtywAAuIlRXonfvXYZQcdJ6ESL1JSFue/KOW4HoZy8ne+VCvlUD//kqiI3+iViaEyuLnb1WzKWpG5SBaC89X/Z3+pqyjjRSS3tavY+vbbEzSR2whyb21NZkThenM4/bChlTQkUB3Xi6Q7pB8dE5DhG1QAlOKEyQkDT3M7z/j9sZtvhGACn1JZ0qeD4s9e28/M1u2hNpN2C9b/7qJ6P9rdiSXV8p9i6aQvxnVxT7HaiTbEUY0qCxFJWwc45X6ebK38Ax1YEZPnKtew6EnPlvJ06v5omXAkHh/7ooPtzIOkJWR3Bt78NGzZkvZ6xJBk7WkoTENC1vFXfvCTsZ0oISM6ew767/w+g/vaGT3ojZB588EFWrFgBwDXXXMO3v/1tdwCor6/ny1/+Mq2trWQyGf71X/+VhQsX9s8NGKX0ZgAYLB/APwMh4CXbafGulPKGrt/Sd3IlgCdXRSgLB2hNZFyRNU1TM5jm9jQr3trlzn5VoY8M0UTG7YQdO2hAEzS3p4kl21THqiuHnrRT32OJNBLBhr3NhANKqx1wbehOJnFze4qth6LsPxpnd2O7Kxp2QmWExlhKhTHqqq5BtjtAuAlfuTgz8aKgzqTKCNsPx8hYkrKI4Zp69h6N81f/sQ5dE9SWhTh9YpmdsFRYysGRN5hQEWZaUJmDVq/fz5XzJ9LQZhcCt9N+nRozteUht9PO2M721niaWRPKOmmx5Ct67mRQ57PJp02LN7cdUYqhdAxekD93AjoS1pzBEHBLRubLju5rJ93VNeWuAoqDWlYZyYHIPFWr197F4Qec58+ZWNhWUa+shNeU9P777/PYY4/xpz/9CSklZ599NosXd4TePvnkkyxdupS77roL0zRpb++RMcCnnxiUAUBKOa37vQaGQinxkyojpM0OCeGaYoO1u4+yZtsRZo0vZeG0MTz3YX1WxxvUlK69aanqYs5sN5mxIAAHWxKEDI1mC4K6XXErbbK/OcPkqqJONvRE2iSoa0j7W5WxJPF4htJw2i3H6DjpvGYdyza5ZOxvZXVxANNSdQCc2HfLUsU5dK2d4pBKpHLizwUqxFWgcbAlSdjQ7VDLwmJd3s7MWcHEUyY/X7PLXQlsOxwDITh1XImtr9+RNFPfkkAXynGcTyKjK8drrk2+JZ5m++GonWUMSMnH9W3c8qsNrsMun+CX6xfy2L0tScHs6L7S1TV5Vwe6kGw+qMwjU8cU9Y9Q2cMP97H1igAQ98bPa7g1nKFzhMybb77JFVdcQXGxMgd94QtfYM2aNe7xzjrrLJYvX046nebyyy+nrq6uX9rp0zOGViDrIOAN3dvTFCeoC8aWKg0YadsyNx1oZdW6fZ1CFpN2nL0KIdVth61GKKBi0WMpk4wJ48pCFIUCpEzpOogPtyZoiqWyQhoPt6UYXxFm9oQy6iZXELI1exrsUFEvjrmqyBbXcub+mlDlLseVhziltsStAxAMiKxarNARf+6Ejhm6cCt0QdehiE7IpTOIpG3/RTSZYfX6/dy+dCabfngJm354CU/feD4zx5dm3b9k2gIh3LDH3PN1FSKaG2+/92gcU6rVkSPKplZlKdoS6YLhm8vPm6oKuGQsUhmVpdqeMklmlD+kv+nqmrwD6qHWlOtbOtiaHHJCZd74+WljSzmhMuKWujR0rVs/gpdFixbxxhtvMHHiRJYtW8Z//ud/DnDrfbyM+gEAOmLNJ1REmDWhjKZYilTGJJ42SaZN8qgZZJEbHmoENAK6xsLpY6gsDnJidRHjy8PoQhAKqJKPqtykMj04MeMVESNrlpxMq1C9uF05K6ccLbpma+todgF3XaALQTyjVjJSSmrLQm4lqgPNCcIBjUOtSaW5Y/sL0qYFUimDJjIWsYRK0egq0sXpzJxBRNcEUirRu3ydVW6nretK5sKrkeQ9X1caN7nx9pYl0e1ENkdUz5JKuiKd47XPTTS7+aJpdoU4tV/QNt8diab6Xeulq2vyJsWp4vR2WKb98A3FcoIOXSVULVy4kKeffpr29nZisRi/+c1vsmz8n3zyCbW1tVx77bVcc801rF+/fjAuYdTiDwAenMzc9lSHjb0nSVTBgGaHj6oawo7io1c+OF9HWV0SpKo46CaI5c6SQ4bmFjbRBESCAYqDOhVFBjNqi12nsEQNLAFdw0IVNMmYqjbxSTUl3HzRNKqLQ0yoCDO9toSxpSqOX6L8FFJK1wyiNH8kB1viXYYiOp2ZI3bnyDSPKw/l7axyO+1pNcVUFwcxdC1vfkB3YmXeBLHpY4sx7QgtJ5Q3kbHQwK3L6pA7qN1wwTQmVRW5g7gpVXH1quJgv8+4u7om7+ogHNBVAp/VIZ88FMsJ9oT58+ezbNkyFixYwNlnn80111zDvHnz3Ndfe+015s6dy7x581i1ahW33HLLILZ29DEUEsGGDMvPm8p1j7/vLTrVOQErB0PX7I5MdBI088oHx1OqdGBXHWWuhG5lkcG+ZIag3rm+aEAThA2d0yeW8cG+FrvQuum22aka5VT6ypVVLg0rHfuth6LomoZhDwApOza8LWHyT1ed3snm7HVUloR0grbTNGLo7mx+04FWpbu/cm2W8zKf/6WryJqeOl6Fnbxn2lnP3o/L0DU3zyFfotmb2xrY09ROKKCh6yo8uKEtNWAz7kLX5P3sa8uC7G5U555UFhp05cy+cuutt3LrrbdmbXNCQK+++mquvvrqwWiWD/4AkIWTmduCpD1luQ7UdMZyI1m8COBvlkzvFFmU25EVBVXSTcpU4ZknVhW5ipS5sgfehKGpY4r58pmTsoTpTqwI285ki1NqS2hPmYQDelY6vio8IggHRMGomaKgTmMsnZWJHA7qTC0vpiwcoDGWztv5e6soKS18nWQmTTxtsrcpTjJjomtaj5yX/VUxKZo0mTa2hF0NUZzAJU04qyZVPD2frj/YzuyA5q4edHspsK85wYIplX1uW0/J/exnjitxo4CGajlBn+GPPwDkMNOuV+oUhE+mLcKhAIaAlkTGNQkZGowtCzN7YnnBjszbYU4fW8zuxo5cgkKzunzHuuGCaXnri4JaXVQUqUgch4CuxO1OqIzkjZqBbJNCvpj6fOaG3JVExpJEbcdyMKDRGs+AgPGlQTeP4XiU/XOuLxI0CJgdBVeMgMr1qC4J8UyB/AB1P8Nqtm/ZBWuAVNrs04w7d6Ukpcyb7+BlOJQQ9BlZjLoBoDuzg1dOYIY9w06kLYpDelbtWlC1fm/51Ya8WvqQ3WE6kSj7j8bzSiJ0h7dz6BwvrnOgOeHWPA7b5hhD16gpDXVbVcr7mqNLfySa6mTCyV1JOKGcFnDq+DI3Ca4t0eHHOB7OS+f64mmvmU2Zyro7vzN4nFhd5EpyG5pg+vjSY+6MvQN/QIOP7ZrBU6ojA1J71sfnWBnxA0BuZ3kkmnLt9Xub2nl3Z1NW6n8hwTFHu9/BqfUrgWlji/N+sXM7zIqioKtD39OM1dwBa8GUKlf/3zHDJFImt158St66AN6omXza/Sve2kUsmaEpZiGRJNIWY0uDnXSLHEeld7WgBMwEYTsJqKti6gOJc323/GoD0WSGiKcgS6HVjEPWgD+uY8C/fenMY26Pd+DffLDNza491Jqy5UAGrxi6j4+XET0A5NqsNx1otZOjNAxdENSVOuQjr2x3TTmQfyme2/l1V+s333ugZx2i0+lvrm+jOZ7O6pAfeWU7Y0uDbqKNc961u5u6FFYrlACnCpCoCJQdDTHGlgbd6mW515S7ktB1FUM/rko5f8eXh9nZECOoq8zk/q4z2xXnT6/hn66qy5Ja6InztDuF0WPBO/A7obxI6Q6MQzmk02d0MaIHgFybddo2DUhpETbUNiMgSGWsbmdkTucXTaoErpa4EnQbY3fEze0pDrYk2HywzTWd5DO9NEaVRMKSB1/P29l4O+ZYKoNlSQ61quzciqIgpi1T4S0x6XQovbEh55Ml6OrY0LmznFZTzOHWpBvK2V0x9YHmWDvz/ra9ewf+kKG5CqlO0lt7yqQkpLN85doRV2TcZ3gxogeAXBNMOKC7tX8dnAIn3c3Izp9ew5XzJ7picgFN6fE32oVPGmMqW7coqGeZTrwdkrLXY9f57SxNANkdcyrToVx6sCVJRVGQsKERz8lMOxYzS77IoJ4cu7tQzjsumTmoHdlQcKR6B/5xZSFXXuSEyqBtblPPSlfPwUhn5cqVfOYzn2HChAmD3ZRRzYgeAHJNMOPKQ7Qk0h2VtewVQcTQORpLFZyVO6zd3ZSl4OnUcT3YmlQDghBMqIhkmU6yKoCtXOvWEIbOJhbI7pid2aMmcM0HTjGWrmLbj+Xe9OTYhRzofe20vCavZMYiGNB6XRh9KOFdiXxc30YwoATU9h5NMH1sMWNKgt0+ByOdlStXMnv2bH8AGGRG9ACQa4IxdI1KuyShU+AkYug0xlJMrAh3Oxvzds7lEYMpY4o40BwnEc9QHFICavUtCXYfaScYEO7qIN/7HXLtwd6O2als5chXx5IZAprGzRdNK6hxf6z3pj1ldnnsXH9Kf81aczX5AdpTsLMhOqxnxd4kwDElHfUV2lNKriJ3xTbQfoFv//7bbDi4oV+PWTeujocvebjb/f7+7/+eJ554gpqaGiZNmsQZZ5zBunXr+OpXv0okEuGdd94hEhl+Wc4jgRE9AHRXiWlPU5yjdudfyPHpJXfWXB4xCNgaO2WRgKsrH9CVhkvaTPPmtoZuncJee3BxUHM7wrJwgHHlIQ61JokEA25I5/nTa+irdnZX9vJ8x+5OyvhY8Zbd1G3NIuWLyDCpyhjWs+JC96wpZnVSgh2uUg/d8d5777F69Wo++OAD0uk08+fP54wzzuDMM8/kgQce4MwzO0nU+xxHRvQAAIVtws62JQ++3uN6r4Xi6a9dOJVHXtmOlNKtriQEjC0N8sCLW7J8AE7n7i2K4rUHt6fMLJG4qWOK+fvLZg9IJ9gb801v6uL2Bm/ZTafSlGPyGu7RMoXuWchQpSl7Wgu5P+jJTH0geOutt7jssssIh8OEw2E+//nPD0o7fPIz6sXgupLozaWQmNcNF0yjPGIQNpT+jqFrnFhdRNjQ2XiglYa2JNXFhh2BlK0AOqZEhXR6JYtzReKGwgy4N/fpWI4bMpSzG5SeTzigD/tZcaF7NnNcaZdCdz4+x4sRvwLIJdfhqKSALWrLQowtDXU7Gys0az7VlpDwLus/OtBKOJBtAogmM+xtilNpa/I3tKWY1M/24IGoL9tdNnFfj1tZZFBvZzMLARVFgWEtgAZd37OhEK10PDjvvPO4/vrr+e53v0smk+H555/nuuuuo7S0lLa2tsFu3qhnVK0AHIfjriMxtxhLIm1SElIa+XuPxo95NpZP6z2ZNplQEXb3cbKHo8mM60htjqc53JbMOlZfZr7ONTqrDsdZ21dt++7kmft63KljiqmyV0IVRUFOqikZ9rPigbpnw4mzzjqLSy+9lDlz5vDZz36W008/nfLycpYtW8YNN9xAXV0d8fjwNfMNdwalKPyx0tei8MtXrqWhTXX0jma/aZtsJlVFel1UPJfcmXdjNJkV7rf5YBuJlEnY0G1JAFX0/XBbKqtYel8KhTvX2NeC6T7Dn3zFwQeDaDRKSUkJ7e3tLFq0iEcffZT58+cPdrNGLMOhKPygMNAOx0JyC44JIJ5SlZ68VbBqy8IkM9ItSdlXk81AOWt9fI6V6667jk2bNpFIJLj66qv9zn8IMaoGACcM00mw0jUxoA7H3FDLklCA0rDukUpW5p5Tx5f22+z8WPWHfHwGiieffHKwm+BTgFE1AAyGwzFXxvkHz23qURbvsTpyB8pZ6+PjM/IYVU7gvjgc39zWwPKVa1ny4OssX7n2mJyqPXUK9sWR6zsefXx8esqgrgCEEP8beACokVIeGYhz5JtJ99bc0p8yCD0J/+tr1m1vQgwHImTUx8dneDBoKwAhxCTgM8CegTpHf4VEejtkJ1krbGiseGvXgLR7T1OcoqCetW0gHLkDFTLq4+MzPBhME9BDwHeAAYtD7U3H3ZWJ53h1yA4DlXWby/Ee2Hx8umPlypXcdNNNg92MUcOgDABCiMuA/VLKD3qw73VCiHVCiHUNDb2bmfa04+5uJny8OmSHfEllA+HIPd4Dm4+Pz9BiwHwAQoiXgXF5XroL+P9R5p9ukVI+CjwKKhGsN23oaUhkdzb34x1ZMxBlCvPhh4yOHr79bdiwoX+PWVcHDz/c9T67d+/mc5/7HB999BEADzzwANFolNdee42zzz6bV199lebmZv7v//2/LFy4MOu9L7zwAvfccw/PPfcct912G2VlZaxbt46DBw9y33338cUvfhEpJd/5znf43e9+hxCCv/3bv+XLX/4yN954I0uXLuXSSy/liiuuoLKykhUrVrBixQp27NjBtddey2c/+1nOP/983n77bSZOnMgzzzwz6mSpB2wFIKVcIqWcnfsP2AlMBT4QQuwGTgDWCyHyDRZ9oqcz6e5mwoMRWXP+9BpWLFswoIJwx2ul4eOTj0wmw9q1a3n44Yf5wQ9+kPXab37zG+69915++9vfMmbMGADq6+t58803ef7557nzzjsB+O///m82bNjABx98wMsvv8ztt99OfX09CxcuZM2aNQDs37+fTZs2AbBmzRoWLVoEwLZt27jxxhvZuHEjFRUVrF69+nhd+pDhuEcBSSn/Aox1/rYHgTMHIgqopzPpnsyEj5d41/GMyumvlYYfSTT06W6mPhh84QtfAOCMM85g9+7d7vZXXnmFdevW8eKLL1JWVuZuv/zyy9E0jVmzZnHo0CEA3nzzTb7yla+g6zq1tbUsXryY9957j4ULF/Lwww+zadMmZs2axdGjR6mvr+edd97hkUceobGxkalTp1JXV5e3DaOFEZ8I1pOOe6gkTw1U1a2u6OvANhht9hk+BAIBLKujznQikXB/D4WUJIqu62QyGXf7ySefzM6dO9m6dWtWwRhnf4DuNMwmTpxIc3Mzv//971m0aBFNTU3813/9FyUlJZSWltLY2Jh1PF3XR6Uo3aAngkkppwxUDkBPGSrJU8MxKmc4ttnn+FFbW8vhw4dpbGwkmUzy/PPPd/ueE088kdWrV/ONb3yDjRs3drnvwoULWbVqFaZp0tDQwBtvvMGCBSrP55xzzuHhhx9m0aJFLFy4kAceeKCTn2G0M+JXAD1lKOizD0cht+HYZp/jh2EY3H333SxYsICJEycyc+bMHr1v5syZ/OIXv+BLX/oSzz33XMH9rrjiCt555x3mzp2LEIL77ruPceOUO3HhwoW8+OKLTJs2jRNPPJGmpiZ/AMhhVMlBD3WGo5TzcGzzaGGoyEH7HF96Iwc96CYgnw6GY1TOcGyzj4+Pwh8AhhBDxRfRG4Zjm318fBS+D2CIMRR8Eb1lOLbZx8fHXwH4+Pj4jFr8AcDHx8dnlOIPAD4+Pj6jFH8A8PHxGTI8/fTTrm4PwN13383LL7/cL8fevXs3s2fP7nafgahh/PDDD9Pe3t7vx+0r/gDg4+MD9E/Z076SOwD88Ic/ZMmSJZ32M02z07b+wB8AfHx8Rh0DVR3uiSeeYMGCBdTV1XH99de7HXdJSQl33XUXc+fO5ZxzzuHQoUO8/fbbPPvss9x+++3U1dWxY8cOli1bxlNPPQXAlClTuOOOO5g/fz6//vWvefHFFzn33HOZP38+X/rSl4hGo53O//777zN37lzmzp3Lv/zLv7jbd+/ezcKFC5k/fz7z58/n7bffBuDOO+9kzZo11NXV8dBDDxXcr76+nkWLFlFXV8fs2bNd5dF8bXrkkUc4cOAAF154IRdeeGGf7md/4w8APj4+A6Lp9PHHH7Nq1SreeustNmzYgK7r/OIXvwAgFotxzjnn8MEHH7Bo0SJ+/vOf86lPfYpLL72U+++/nw0bNnDyySd3OmZ1dTXr169nyZIl3HPPPbz88susX7+eM888kwcffLDT/t/85jf5yU9+wgcfZNeeGjt2LC+99BLr169n1apV3HzzzQDce++9LFy4kA0bNvA3f/M3Bfd78sknWbp0qStFXVdXx5EjR/K26eabb2bChAm8+uqrvPrqq8d8PwcCPw/Ax8dnQDSd/vjHP/L+++9z1llnARCPxxk7VinBB4NBPve5zwFKivmll17q0TG//OUvA/Duu++yadMmzjvvPABSqRTnnntu1r7Nzc00Nze7+v9f//rX+d3vfgdAOp3mpptucgemrVu35j1fof3OOussli9fTjqd5vLLL6euro7XX3+92zYNNfwBwMfHZ0Cqw0kpufrqq/nRj37U6TXDMBBCAJ3loLuiuLjYPfbFF1/ML3/5y2Nq20MPPURtbS0ffPABlmURDod7td+iRYt44403eOGFF1i2bBm33norlZWVfWrTYOCbgHx8fAZE0+nTn/40Tz31FIcPHwagqamJTz75pMv3lJaW0tbW1u2xzznnHN566y22b98OKJNS7iy+oqKCiooK3nzzTQDX/ATQ0tLC+PHj0TSNxx9/3PVN5J6/0H6ffPIJtbW1XHvttVxzzTWsX7++yzb19LqON/4A4OPjMyCaTrNmzeKee+7hM5/5DHPmzOHiiy+mvr6+y/dcddVV3H///cybN48dO3YU3K+mpoaVK1fyla98hTlz5nDuueeyefPmTvs99thj3HjjjdTV1WUVkfnWt77Ff/zHfzB37lw2b97srizmzJmDruvMnTuXhx56qOB+r732GnPnzmXevHmsWrWKW265pcs2XXfddVxyySVDzgnsy0EPEfyyij79jS8HPTrx5aCHGQMVgufj4+PTFf4AMATwyyr6+PgMBv4AMATY0xSnKKhnbfPLKvr4+Aw0/gAwBJhcFaE9lZ3a3tcQPB8fH5/u8AeAIYBfVtHHx2cw8AeAIYBfVtHHx2cwGLQBQAjxv4QQm4UQG4UQ9w1WO4YK50+vYcWyBbx862JWLFvgd/4+w57m5mZ++tOfDmobVq5cyYEDB3r1np7IRgNZQnX9ef7u2LBhA7/97W/75ViDMgAIIS4ELgPmSilPAx4YjHb4+Ph42PEa/OJ/wj8vUD93vNanw3U1APRU+qGvDEQHPNjnH/YDAPDXwL1SyiSAlPLwILXDx8cHVGf/+zsgehiKa9TP39/Rp0HgzjvvZMeOHdTV1XH77bfz2muvsXDhQi699FJmzZrVaab9wAMP8P3vfx+ACy64gDvuuIMFCxZwyimnuHLLpmly2223MXv2bObMmcNPfvITQNUNOOuss5g9ezbXXXcdUkqeeuop1q1bx1e/+lXq6uqIx+O8//77LF68mDPOOIOlS5e6mcmFZKO9SCm56aabmDFjBkuWLHElLnpz/nz7ATzyyCPMmjWLOXPmcNVVVwFKSmL58uUsWLCAefPm8cwzz5BKpbj77rtZtWoVdXV1rFq16pg/H/eijvc/YAPwA+BPwOvAWV3sex2wDlg3efJk6ePj0zM2bdrU852f+JKUP1ss5WP/X8e/ny1W24+RXbt2ydNOO839+9VXX5VFRUVy586deV+///775d/93d9JKaVcvHixvPXWW6WUUr7wwgvy05/+tJRSyp/+9KfyyiuvlOl0WkopZWNjY9ZPKaX82te+Jp999ln3OO+9956UUspUKiXPPfdcefjwYSmllL/61a/kN7/5TSmllKeffrp8/fXXpZRS3nbbbVntcli9erVcsmSJzGQycv/+/bK8vFz++te/7vH5u9pv/PjxMpFISCmlPHr0qJRSyu9+97vy8ccfd7dNnz5dRqNR+dhjj8kbb7wx3y2XUub/3IF1Mk//OmArACHEy0KIj/L8uwylQloFnAPcDvyXcKQBOw9Qj0opz5RSnllT49vFfXwGhKO7IVicvS1YrLb3IwsWLGDq1J5Ft33hC18AlFz07t2qHS+//DLXX389gYBSLa2qqgLg1Vdf5eyzz+b000/nlVdeYePGjZ2Ot2XLFj766CMuvvhi6urquOeee9i3b19e2eh8vPHGG3zlK19B13UmTJjARRdd5L7Wk/N3td+cOXP46le/yhNPPOFe24svvsi9995LXV0dF1xwAYlEgj179vTo3vWUAZODllJ2ruNmI4T4a+C/7ZFprRDCAsYAw1L7wNfx8Rn2VE5RZp9QSce2VExt70ccMTWAQCCAZVnu34lEImvfUCgEdC8XnUgk+Na3vsW6deuYNGkS3//+9zsdC5S147TTTuOdd97J2t7c3Hwsl9Lr83e13wsvvMAbb7zBc889xz/8wz/wl7/8BSklq1evZsaMGVnH+dOf/tSn9noZLB/A08CFAEKIU4AgcGSQ2tInfB0fnxHBOd+CTBySUZBS/czE1fZjpDsJ5NraWg4fPkxjYyPJZJLnn3++22NefPHF/Nu//Zs7IDQ1Nbmd6JgxY4hGo1mROd42zJgxg4aGBncASKfTbNy4sUvZaC+LFi1i1apVmKZJfX29W92rp+cvtJ9lWezdu5cLL7yQH//4x7S0tBCNRlm6dCk/+clPXD/Bn//85x7d194wWAPACuAkIcRHwK+Aq6VzlcMMX8fHZ0Rw8gVwyY+hZCzEGtTPS36sth8j1dXVnHfeecyePZvbb7+90+uGYXD33XezYMECLr74YmbOnNntMa+55homT57MnDlzmDt3Lk8++SQVFRVce+21zJ49m6VLl7oVyECFat5www3U1dVhmiZPPfUUd9xxB3PnzqWurs6t8VtINtrLFVdcwfTp05k1axbf+MY33GpfPT1/KBTKu59pmnzta1/j9NNPZ968edx8881UVFTwve99j3Q6zZw5czjttNP43ve+B8CFF17Ipk2b+sUJ7MtB95ElD75OdXFHdSNQS83GWJqXb108iC3zGe34ctCjE18O+jji6/j4+PgMV/wBoI/4Oj4+Pj7DFX8A6CO+jo/PUGY4mXh9+k5vP+8BCwMdTZw/vcbv8H2GHOFwmMbGRqqrqymQZuMzgpBS0tjYSDgc7vF7/AHAx2eEcsIJJ7Bv3z4aGvyQ5NFCOBzmhBNO6PH+/gDg4zNCMQyjx1m3PqMT3wfg4+PjM0rxBwAfHx+fUYo/APj4+PiMUoZVJrAQogH45BjfPoahqTfkt6t3+O3qHX67esdIbdeJUspOoYrDagDoC0KIdflSoQcbv129w29X7/Db1TtGW7t8E5CPj4/PKMUfAHx8fHxGKaNpAHh0sBtQAL9dvcNvV+/w29U7RlW7Ro0PwMfHx8cnm9G0AvDx8fHx8eAPAD4+Pj6jlBE1AAghviSE2CiEsIQQBUOmhBCXCCG2CCG2CyHu9GyfKoT4k719lRAi2E/tqhJCvCSE2Gb/rMyzz4VCiA2efwkhxOX2ayuFELs8r9Udr3bZ+5mecz/r2T6Y96tOCPGO/Xl/KIT4sue1fr1fhZ4Xz+sh+/q32/djiue179rbtwghlvalHcfQrluFEJvs+/NHIcSJntfyfqbHqV3LhBANnvNf43ntavtz3yaEuPo4t+shT5u2CiGaPa8N5P1aIYQ4LFSJ3HyvCyHEI3a7PxRCzPe81rf7JaUcMf+AU4EZwGvAmQX20YEdwEmoYvQfALPs1/4LuMr+/WfAX/dTu+4D7rR/vxP4cTf7VwFNQJH990rgiwNwv3rULiBaYPug3S/gFGC6/fsEoB6o6O/71dXz4tnnW8DP7N+vAlbZv8+y9w8BU+3j6MexXRd6nqG/dtrV1Wd6nNq1DPjnPO+tAnbaPyvt3yuPV7ty9v9fwIqBvl/2sRcB84GPCrz+P4DfAQI4B/hTf92vEbUCkFJ+LKXc0s1uC4DtUsqdUsoUqij9ZUIIAVwEPGXv9x/A5f3UtMvs4/X0uF8EfielbO+n8xeit+1yGez7JaXcKqXcZv9+ADgMDERRhrzPSxftfQr4tH1/LgN+JaVMSil3Advt4x2XdkkpX/U8Q+8CPdcJHsB2dcFS4CUpZZOU8ijwEnDJILXrK8Av++ncXSKlfAM14SvEZcB/SsW7QIUQYjz9cL9G1ADQQyYCez1/77O3VQPNUspMzvb+oFZKWW//fhCo7Wb/q+j88P2Dvfx7SAgROs7tCgsh1gkh3nXMUgyh+yWEWICa1e3wbO6v+1Xoecm7j30/WlD3pyfvHch2efkr1CzSId9nejzbdaX9+TwlhJjUy/cOZLuwTWVTgVc8mwfqfvWEQm3v8/0advUAhBAvA+PyvHSXlPKZ490eh67a5f1DSimFEAVjb+2R/XTgD57N30V1hEFUPPAdwA+PY7tOlFLuF0KcBLwihPgLqpM7Zvr5fj0OXC2ltOzNx3y/RiJCiK8BZwKLPZs7faZSyh35j9DvPAf8UkqZFEJcj1o9XXSczt0TrgKeklKanm2Deb8GjGE3AEgpl/TxEPuBSZ6/T7C3NaKWVgF7Fuds73O7hBCHhBDjpZT1dod1uItD/U/gN1LKtOfYzmw4KYR4DLjteLZLSrnf/rlTCPEaMA9YzSDfLyFEGfACavB/13PsY75feSj0vOTbZ58QIgCUo56nnrx3INuFEGIJalBdLKVMOtsLfKb90aF12y4pZaPnz39H+Xyc916Q897X+qFNPWqXh6uAG70bBvB+9YRCbe/z/RqNJqD3gOlCRbAEUR/2s1J5VV5F2d8Brgb6a0XxrH28nhy3k+3R7gQdu/vlQN5ogYFolxCi0jGhCCHGAOcBmwb7ftmf3W9QttGncl7rz/uV93npor1fBF6x78+zwFVCRQlNBaYDa/vQll61SwgxD/g34FIp5WHP9ryf6XFs13jPn5cCH9u//wH4jN2+SuAzZK+EB7Rddttmohyq73i2DeT96gnPAt+wo4HOAVrsSU7f79dAebYH4x9wBcoOlgQOAX+wt08AfuvZ738AW1Ej+F2e7SehvqDbgV8DoX5qVzXwR2Ab8DJQZW8/E/h3z35TUKO6lvP+V4C/oDqyJ4CS49Uu4FP2uT+wf/7VULhfwNeANLDB869uIO5XvucFZVK61P49bF//dvt+nOR57132+7YAn+3n5727dr1sfw+c+/Nsd5/pcWrXj4CN9vlfBWZ63rvcvo/bgW8ez3bZf38fuDfnfQN9v36JimJLo/qvvwJuAG6wXxfAv9jt/gueCMe+3i9fCsLHx8dnlDIaTUA+Pj4+PvgDgI+Pj8+oxR8AfHx8fEYp/gDg4+PjM0rxBwAfHx+fUYo/APj4+PiMUvwBwMfHx2eU4g8APj59QAhxli1qFhZCFAtVn2D2YLfLx6cn+IlgPj59RAhxDyobOALsk1L+aJCb5OPTI/wBwMenj9jaMu8BCeBTMltF0sdnyOKbgHx8+k41UAKUolYCPj7DAn8F4OPTR4SqEfsrVBGR8VLKmwa5ST4+PWLY1QPw8RlKCCG+AaSllE8KIXTgbSHERVLKV7p7r4/PYOOvAHx8fHxGKb4PwMfHx2eU4g8APj4+PqMUfwDw8fHxGaX4A4CPj4/PKMUfAHx8fHxGKf4A4OPj4zNK8QcAHx8fn1HK/wMFhBYBxaq88wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(new_X, emp_stand_noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc_norm, emp_stand_y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(norm_data, trunc_emp_stand_ols.predict(norm_data), color='r', label='ols')\n",
    "plt.plot(norm_data, gt_emp_stand.predict(norm_data), color='green', label='gt')\n",
    "plt.plot(norm_data, unknown_res(Tensor(norm_data)).detach().numpy(), label='unknown', color='blue')\n",
    "plt.legend()\n",
    "ax.set_title(\"Unknown Noise Variance - Normalized\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(X, noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc, y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(unnorm_data, trunc_ols.predict(unnorm_data), label='ols', color='red')\n",
    "plt.plot(unnorm_data, gt_ols.predict(unnorm_data), color='g', label='gt')\n",
    "plt.plot(unnorm_data, (Tensor(unnorm_data)@unknown_weight_unnorm + unknown_bias_unnorm), color='blue', label='unknown')\n",
    "plt.legend()\n",
    "ax.set_title(\"Unknown Noise Variance - UnNormalized\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncate at Zero and Run for High Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.__setattr__('bs', 10)\n",
    "args.__setattr__('steps', 2500)\n",
    "args.__setattr__('step_lr', 100)\n",
    "args.__setattr__('step_lr_gamma', .9)\n",
    "args.__setattr__('tol', 1e-2)\n",
    "args.__setattr__('trials', 20)\n",
    "args.__setattr__('samples', 10000)\n",
    "\n",
    "EXP = 'Checking Something 5_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/ccbbfce7-f95d-4641-92f1-03f3573c3459\n",
      "gt params:  tensor([ 0.1085,  0.2555,  0.6003, -0.6642,  0.4846,  0.6192])\n",
      "0 steps | score: [0.22124223411083221]\n",
      "100 steps | score: [0.011381406337022781]\n",
      "200 steps | score: [0.1283445954322815]\n",
      "300 steps | score: [0.10474556684494019]\n",
      "400 steps | score: [0.19839152693748474]\n",
      "500 steps | score: [0.06396964192390442]\n",
      "600 steps | score: [0.0909557044506073]\n",
      "700 steps | score: [0.03309105336666107]\n",
      "800 steps | score: [0.06927433609962463]\n",
      "900 steps | score: [0.12008286267518997]\n",
      "1000 steps | score: [0.16453717648983002]\n",
      "1100 steps | score: [0.06924748420715332]\n",
      "1200 steps | score: [0.08851287513971329]\n",
      "1300 steps | score: [0.11269135773181915]\n",
      "1400 steps | score: [0.14181354641914368]\n",
      "1500 steps | score: [0.05487704277038574]\n",
      "1600 steps | score: [0.08009228855371475]\n",
      "1700 steps | score: [0.10548804700374603]\n",
      "1800 steps | score: [0.06910786032676697]\n",
      "1900 steps | score: [0.06356599926948547]\n",
      "2000 steps | score: [0.12538276612758636]\n",
      "2100 steps | score: [0.09578648954629898]\n",
      "2200 steps | score: [0.09773542732000351]\n",
      "2300 steps | score: [0.09851321578025818]\n",
      "2400 steps | score: [0.06829992681741714]\n",
      "2500 steps | score: [0.0880746841430664]\n",
      "2600 steps | score: [0.08148888498544693]\n",
      "2700 steps | score: [0.10331105440855026]\n",
      "2800 steps | score: [0.08207938075065613]\n",
      "0 steps | score: [0.3972179889678955, -0.9044169783592224]\n",
      "100 steps | score: [0.042814359068870544, 0.34105604887008667]\n",
      "200 steps | score: [0.03734859079122543, 0.2879469096660614]\n",
      "300 steps | score: [0.09779787808656693, -0.11457368731498718]\n",
      "400 steps | score: [0.3026629686355591, -0.8637930154800415]\n",
      "500 steps | score: [0.19276918470859528, -0.4559507668018341]\n",
      "600 steps | score: [0.5124645233154297, -1.6930158138275146]\n",
      "700 steps | score: [-0.05184042453765869, 0.4589120149612427]\n",
      "800 steps | score: [0.30202966928482056, -0.8301218748092651]\n",
      "900 steps | score: [0.08370263874530792, -0.09212998300790787]\n",
      "1000 steps | score: [0.4908141493797302, -1.7137196063995361]\n",
      "1100 steps | score: [0.1884213089942932, -0.41878271102905273]\n",
      "1200 steps | score: [0.2834760844707489, -0.8546704053878784]\n",
      "1300 steps | score: [0.21371063590049744, -0.4967931807041168]\n",
      "1400 steps | score: [0.41625329852104187, -1.3422890901565552]\n",
      "1500 steps | score: [0.11505551636219025, -0.20751816034317017]\n",
      "1600 steps | score: [0.2083144634962082, -0.5080498456954956]\n",
      "1700 steps | score: [0.2600638270378113, -0.6553802490234375]\n",
      "1800 steps | score: [0.164357990026474, -0.3625935912132263]\n",
      "1900 steps | score: [0.2465631365776062, -0.683262825012207]\n",
      "2000 steps | score: [0.37737029790878296, -1.1863112449645996]\n",
      "2100 steps | score: [0.30275285243988037, -0.9892173409461975]\n",
      "2200 steps | score: [0.2685800790786743, -0.7459616661071777]\n",
      "2300 steps | score: [0.13798393309116364, -0.22773240506649017]\n",
      "2400 steps | score: [0.34860455989837646, -1.070620059967041]\n",
      "2500 steps | score: [0.17048700153827667, -0.3334355354309082]\n",
      "2600 steps | score: [0.28557661175727844, -0.8823345899581909]\n",
      "2700 steps | score: [0.2853640615940094, -0.8636177778244019]\n",
      "2800 steps | score: [0.28380149602890015, -0.8185883164405823]\n",
      "unknown params:  tensor([ 0.1130,  0.2564,  0.6070, -0.6703,  0.4932,  0.5711])\n",
      "gt params:  tensor([ 0.1085,  0.2555,  0.6003, -0.6642,  0.4846,  0.6192])\n",
      "ols params:  tensor([ 0.0956,  0.2216,  0.5248, -0.5729,  0.4238,  1.0907])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(0.0402)\n",
      "gt params:  tensor([ 0.1149,  0.2501,  0.6063, -0.6593,  0.4801,  0.6050])\n",
      "0 steps | score: [0.4131717085838318]\n",
      "100 steps | score: [0.20213627815246582]\n",
      "200 steps | score: [0.1520388275384903]\n",
      "300 steps | score: [0.23429307341575623]\n",
      "400 steps | score: [0.33773964643478394]\n",
      "500 steps | score: [0.2455524057149887]\n",
      "600 steps | score: [0.28993043303489685]\n",
      "700 steps | score: [0.265386164188385]\n",
      "800 steps | score: [0.2668532431125641]\n",
      "900 steps | score: [0.22381338477134705]\n",
      "1000 steps | score: [0.26394155621528625]\n",
      "1100 steps | score: [0.2256627082824707]\n",
      "1200 steps | score: [0.22451256215572357]\n",
      "1300 steps | score: [0.25371089577674866]\n",
      "1400 steps | score: [0.2319677770137787]\n",
      "1500 steps | score: [0.24742433428764343]\n",
      "1600 steps | score: [0.23788544535636902]\n",
      "1700 steps | score: [0.2608094811439514]\n",
      "1800 steps | score: [0.23621699213981628]\n",
      "1900 steps | score: [0.24846650660037994]\n",
      "2000 steps | score: [0.2505303919315338]\n",
      "2100 steps | score: [0.2693435251712799]\n",
      "2200 steps | score: [0.25056540966033936]\n",
      "2300 steps | score: [0.25513866543769836]\n",
      "2400 steps | score: [0.25372302532196045]\n",
      "2500 steps | score: [0.24192920327186584]\n",
      "2600 steps | score: [0.252437025308609]\n",
      "2700 steps | score: [0.25051796436309814]\n",
      "2800 steps | score: [0.24610087275505066]\n",
      "0 steps | score: [0.28138497471809387, -0.41229185461997986]\n",
      "100 steps | score: [-0.06905839592218399, 0.4900362491607666]\n",
      "200 steps | score: [-0.11344543099403381, 0.5518604516983032]\n",
      "300 steps | score: [-0.16032443940639496, 0.7349994778633118]\n",
      "400 steps | score: [0.3145104646682739, -1.0134015083312988]\n",
      "500 steps | score: [0.003311398671939969, 0.12282172590494156]\n",
      "600 steps | score: [0.30665019154548645, -1.0151458978652954]\n",
      "700 steps | score: [0.28463655710220337, -0.8730626106262207]\n",
      "800 steps | score: [0.06397895514965057, -0.07914337515830994]\n",
      "900 steps | score: [0.030665908008813858, -0.039618976414203644]\n",
      "1000 steps | score: [0.07662933319807053, -0.21799719333648682]\n",
      "1100 steps | score: [0.10142327845096588, -0.22028274834156036]\n",
      "1200 steps | score: [0.09868382662534714, -0.23306865990161896]\n",
      "1300 steps | score: [0.04830624908208847, -0.06748379021883011]\n",
      "1400 steps | score: [0.09257728606462479, -0.23839730024337769]\n",
      "1500 steps | score: [0.2254631072282791, -0.7900283932685852]\n",
      "1600 steps | score: [0.14921189844608307, -0.42574554681777954]\n",
      "1700 steps | score: [0.15485771000385284, -0.4915239214897156]\n",
      "1800 steps | score: [0.11378726363182068, -0.30673468112945557]\n",
      "1900 steps | score: [0.09907641261816025, -0.20989063382148743]\n",
      "2000 steps | score: [0.2805045247077942, -0.9282655715942383]\n",
      "2100 steps | score: [0.28760454058647156, -0.9817338585853577]\n",
      "2200 steps | score: [0.1378314048051834, -0.4149770438671112]\n",
      "2300 steps | score: [0.20409436523914337, -0.6902572512626648]\n",
      "2400 steps | score: [0.19514745473861694, -0.5897094011306763]\n",
      "2500 steps | score: [0.14694499969482422, -0.4618557393550873]\n",
      "2600 steps | score: [0.16873590648174286, -0.5863545536994934]\n",
      "2700 steps | score: [0.13978663086891174, -0.43514254689216614]\n",
      "2800 steps | score: [0.18910175561904907, -0.5763744115829468]\n",
      "unknown params:  tensor([ 0.1199,  0.2572,  0.6094, -0.6778,  0.4953,  0.4750])\n",
      "gt params:  tensor([ 0.1149,  0.2501,  0.6063, -0.6593,  0.4801,  0.6050])\n",
      "ols params:  tensor([ 0.0906,  0.2000,  0.4736, -0.5154,  0.3817,  1.4117])\n",
      "unknown mse:  tensor(0.0029)\n",
      "ols mse:  tensor(0.1170)\n",
      "gt params:  tensor([ 0.1097,  0.2544,  0.6053, -0.6665,  0.4832,  0.5896])\n",
      "0 steps | score: [0.22073109447956085]\n",
      "100 steps | score: [0.13875490427017212]\n",
      "200 steps | score: [0.06770820170640945]\n",
      "300 steps | score: [0.08046890795230865]\n",
      "400 steps | score: [0.020215535536408424]\n",
      "500 steps | score: [0.05912373214960098]\n",
      "600 steps | score: [0.035168297588825226]\n",
      "700 steps | score: [-0.04088365659117699]\n",
      "800 steps | score: [0.10442161560058594]\n",
      "900 steps | score: [0.059482377022504807]\n",
      "1000 steps | score: [0.04975907877087593]\n",
      "1100 steps | score: [0.08106996864080429]\n",
      "1200 steps | score: [0.045696597546339035]\n",
      "1300 steps | score: [0.0905025452375412]\n",
      "1400 steps | score: [0.05223745107650757]\n",
      "1500 steps | score: [0.07319314777851105]\n",
      "1600 steps | score: [0.04291117936372757]\n",
      "1700 steps | score: [0.060711972415447235]\n",
      "1800 steps | score: [0.0652368813753128]\n",
      "1900 steps | score: [0.0693688690662384]\n",
      "2000 steps | score: [0.07516748458147049]\n",
      "2100 steps | score: [0.06354635953903198]\n",
      "2200 steps | score: [0.06421927362680435]\n",
      "2300 steps | score: [0.0586034394800663]\n",
      "2400 steps | score: [0.023360606282949448]\n",
      "2500 steps | score: [0.06217208877205849]\n",
      "2600 steps | score: [0.07012660801410675]\n",
      "2700 steps | score: [0.06406725943088531]\n",
      "2800 steps | score: [0.05444062501192093]\n",
      "0 steps | score: [-0.09608205407857895, 1.1793746948242188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [-0.3894366919994354, 1.7398197650909424]\n",
      "200 steps | score: [-0.5315139889717102, 2.0777180194854736]\n",
      "300 steps | score: [-0.48381751775741577, 1.9432371854782104]\n",
      "400 steps | score: [-0.5851250886917114, 2.2070841789245605]\n",
      "500 steps | score: [-0.2490818202495575, 1.2361127138137817]\n",
      "600 steps | score: [-0.2634950578212738, 1.2900598049163818]\n",
      "700 steps | score: [-0.6198322772979736, 2.2687430381774902]\n",
      "800 steps | score: [-0.18957802653312683, 1.053268313407898]\n",
      "900 steps | score: [-0.38219964504241943, 1.69663667678833]\n",
      "1000 steps | score: [-0.3227402865886688, 1.4780232906341553]\n",
      "1100 steps | score: [0.010677785612642765, 0.37832194566726685]\n",
      "1200 steps | score: [-0.36419227719306946, 1.5728354454040527]\n",
      "1300 steps | score: [-0.18833458423614502, 1.0417015552520752]\n",
      "1400 steps | score: [-0.27096766233444214, 1.3009990453720093]\n",
      "1500 steps | score: [-0.3233443796634674, 1.441108226776123]\n",
      "1600 steps | score: [-0.09276354312896729, 0.7703139185905457]\n",
      "1700 steps | score: [-0.27941495180130005, 1.3286221027374268]\n",
      "1800 steps | score: [-0.3212546110153198, 1.4536579847335815]\n",
      "1900 steps | score: [-0.2571046054363251, 1.2395095825195312]\n",
      "2000 steps | score: [-0.18504227697849274, 1.0525407791137695]\n",
      "2100 steps | score: [-0.246826633810997, 1.2587348222732544]\n",
      "2200 steps | score: [-0.2783903181552887, 1.29896879196167]\n",
      "2300 steps | score: [-0.2609260082244873, 1.2607797384262085]\n",
      "2400 steps | score: [-0.3887006938457489, 1.6210075616836548]\n",
      "2500 steps | score: [-0.28129586577415466, 1.2937531471252441]\n",
      "2600 steps | score: [-0.24531972408294678, 1.233797550201416]\n",
      "2700 steps | score: [-0.28781428933143616, 1.3570839166641235]\n",
      "2800 steps | score: [-0.21484661102294922, 1.1508469581604004]\n",
      "unknown params:  tensor([ 0.1139,  0.2715,  0.6160, -0.6665,  0.4957,  0.3806])\n",
      "gt params:  tensor([ 0.1097,  0.2544,  0.6053, -0.6665,  0.4832,  0.5896])\n",
      "ols params:  tensor([ 0.0828,  0.1980,  0.4416, -0.4740,  0.3555,  1.6772])\n",
      "unknown mse:  tensor(0.0074)\n",
      "ols mse:  tensor(0.2112)\n",
      "gt params:  tensor([ 0.1137,  0.2462,  0.5969, -0.6681,  0.4794,  0.6388])\n",
      "0 steps | score: [0.20776082575321198]\n",
      "100 steps | score: [0.11789818108081818]\n",
      "200 steps | score: [0.03863497078418732]\n",
      "300 steps | score: [0.1432303488254547]\n",
      "400 steps | score: [-0.006110047921538353]\n",
      "0 steps | score: [0.09752630442380905, 0.10200835764408112]\n",
      "100 steps | score: [0.35002294182777405, -0.855724036693573]\n",
      "200 steps | score: [-0.1261540800333023, 0.4193306565284729]\n",
      "300 steps | score: [0.29632821679115295, -0.7743782997131348]\n",
      "400 steps | score: [-0.1391746997833252, 0.4755069315433502]\n",
      "500 steps | score: [-0.30952781438827515, 0.856654703617096]\n",
      "600 steps | score: [-0.057169701904058456, 0.26128774881362915]\n",
      "700 steps | score: [0.16000528633594513, -0.37784045934677124]\n",
      "800 steps | score: [0.4271242618560791, -1.2796173095703125]\n",
      "900 steps | score: [-0.02437787875533104, 0.11298023164272308]\n",
      "1000 steps | score: [-0.015422621741890907, 0.08801159262657166]\n",
      "1100 steps | score: [-0.061867184937000275, 0.2748893201351166]\n",
      "1200 steps | score: [-0.04031293839216232, 0.18990162014961243]\n",
      "1300 steps | score: [-0.15231317281723022, 0.4698624908924103]\n",
      "1400 steps | score: [-0.0818333774805069, 0.26556482911109924]\n",
      "1500 steps | score: [0.08687609434127808, -0.15855571627616882]\n",
      "1600 steps | score: [-0.11028178781270981, 0.39556750655174255]\n",
      "1700 steps | score: [-0.026685277000069618, 0.14161081612110138]\n",
      "1800 steps | score: [-0.02864128351211548, 0.12214259058237076]\n",
      "1900 steps | score: [0.0003837030672002584, 0.057684578001499176]\n",
      "2000 steps | score: [-0.0019974505994468927, 0.0679764449596405]\n",
      "2100 steps | score: [-0.15409857034683228, 0.47805988788604736]\n",
      "2200 steps | score: [-0.12361782789230347, 0.4021413028240204]\n",
      "2300 steps | score: [-0.07140728086233139, 0.25496983528137207]\n",
      "2400 steps | score: [-0.029126860201358795, 0.12559883296489716]\n",
      "2500 steps | score: [-0.07400909066200256, 0.2624472379684448]\n",
      "2600 steps | score: [-0.04759690538048744, 0.16165028512477875]\n",
      "2700 steps | score: [-0.12710589170455933, 0.36685121059417725]\n",
      "2800 steps | score: [-0.07442656904459, 0.2548433542251587]\n",
      "unknown params:  tensor([ 0.1192,  0.2559,  0.6028, -0.6726,  0.4886,  0.5035])\n",
      "gt params:  tensor([ 0.1137,  0.2462,  0.5969, -0.6681,  0.4794,  0.6388])\n",
      "ols params:  tensor([ 0.0815,  0.1714,  0.4109, -0.4505,  0.3295,  1.9499])\n",
      "unknown mse:  tensor(0.0031)\n",
      "ols mse:  tensor(0.3050)\n",
      "gt params:  tensor([ 0.1000,  0.2388,  0.6089, -0.6614,  0.5007,  0.5698])\n",
      "0 steps | score: [0.13882386684417725]\n",
      "100 steps | score: [-0.12376365065574646]\n",
      "200 steps | score: [-0.11695780605077744]\n",
      "300 steps | score: [-0.16995929181575775]\n",
      "400 steps | score: [-0.1135125607252121]\n",
      "500 steps | score: [-0.11002348363399506]\n",
      "600 steps | score: [-0.05631949007511139]\n",
      "700 steps | score: [-0.10941755771636963]\n",
      "800 steps | score: [-0.017296187579631805]\n",
      "900 steps | score: [-0.0784616470336914]\n",
      "1000 steps | score: [-0.11852547526359558]\n",
      "1100 steps | score: [-0.12000301480293274]\n",
      "1200 steps | score: [-0.05309968441724777]\n",
      "1300 steps | score: [-0.07533149421215057]\n",
      "1400 steps | score: [-0.11564597487449646]\n",
      "1500 steps | score: [-0.11309382319450378]\n",
      "1600 steps | score: [-0.0963490903377533]\n",
      "1700 steps | score: [-0.10247859358787537]\n",
      "1800 steps | score: [-0.066880963742733]\n",
      "1900 steps | score: [-0.0830308124423027]\n",
      "2000 steps | score: [-0.06950008124113083]\n",
      "2100 steps | score: [-0.10708113014698029]\n",
      "2200 steps | score: [-0.07076869159936905]\n",
      "2300 steps | score: [-0.0541868694126606]\n",
      "2400 steps | score: [-0.07903897017240524]\n",
      "2500 steps | score: [-0.0839000940322876]\n",
      "2600 steps | score: [-0.10509943217039108]\n",
      "2700 steps | score: [-0.11610013246536255]\n",
      "0 steps | score: [0.25678011775016785, -0.2556994557380676]\n",
      "100 steps | score: [-0.05389852449297905, 0.3494582772254944]\n",
      "200 steps | score: [-0.023944014683365822, 0.16656409204006195]\n",
      "300 steps | score: [-0.06510940194129944, 0.3266017436981201]\n",
      "400 steps | score: [0.3927333950996399, -1.1231729984283447]\n",
      "500 steps | score: [0.08495575934648514, -0.13939286768436432]\n",
      "600 steps | score: [0.16067487001419067, -0.3477852940559387]\n",
      "700 steps | score: [0.11653447896242142, -0.21262039244174957]\n",
      "800 steps | score: [0.3959782123565674, -1.030620813369751]\n",
      "900 steps | score: [0.07454309612512589, -0.11869418621063232]\n",
      "1000 steps | score: [-0.008665680885314941, 0.056266993284225464]\n",
      "1100 steps | score: [-0.006370149087160826, 0.08835901319980621]\n",
      "1200 steps | score: [0.13973061740398407, -0.30160558223724365]\n",
      "1300 steps | score: [0.09854909032583237, -0.19134463369846344]\n",
      "1400 steps | score: [0.01049976795911789, 0.1016562432050705]\n",
      "1500 steps | score: [0.1868482530117035, -0.4569934904575348]\n",
      "1600 steps | score: [0.12536992132663727, -0.28925320506095886]\n",
      "1700 steps | score: [0.16239289939403534, -0.411053329706192]\n",
      "1800 steps | score: [0.09953615814447403, -0.23604744672775269]\n",
      "1900 steps | score: [0.1936279684305191, -0.423525869846344]\n",
      "2000 steps | score: [0.27640819549560547, -0.700686514377594]\n",
      "2100 steps | score: [0.10139918327331543, -0.18982145190238953]\n",
      "2200 steps | score: [0.17039670050144196, -0.42633146047592163]\n",
      "2300 steps | score: [0.2349393665790558, -0.6231165528297424]\n",
      "2400 steps | score: [0.13325972855091095, -0.24488100409507751]\n",
      "2500 steps | score: [0.024619068950414658, 0.04284606873989105]\n",
      "2600 steps | score: [0.09144093096256256, -0.16743259131908417]\n",
      "2700 steps | score: [0.11622268706560135, -0.2634202837944031]\n",
      "unknown params:  tensor([ 0.0971,  0.2166,  0.5951, -0.6273,  0.4697,  0.4062])\n",
      "gt params:  tensor([ 0.1000,  0.2388,  0.6089, -0.6614,  0.5007,  0.5698])\n",
      "ols params:  tensor([ 0.0641,  0.1473,  0.3988, -0.4177,  0.3188,  2.1255])\n",
      "unknown mse:  tensor(0.0049)\n",
      "ols mse:  tensor(0.4277)\n",
      "gt params:  tensor([ 0.1147,  0.2549,  0.6132, -0.6519,  0.4837,  0.5984])\n",
      "0 steps | score: [0.30061569809913635]\n",
      "100 steps | score: [0.12024594098329544]\n",
      "200 steps | score: [0.10497695207595825]\n",
      "300 steps | score: [0.13270270824432373]\n",
      "400 steps | score: [0.07376286387443542]\n",
      "500 steps | score: [0.06676578521728516]\n",
      "600 steps | score: [0.08907577395439148]\n",
      "700 steps | score: [0.09049350023269653]\n",
      "800 steps | score: [0.10706498473882675]\n",
      "900 steps | score: [0.08126316219568253]\n",
      "1000 steps | score: [0.117963507771492]\n",
      "1100 steps | score: [0.054265715181827545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 steps | score: [0.06676126271486282]\n",
      "1300 steps | score: [0.08237994462251663]\n",
      "1400 steps | score: [0.10944613814353943]\n",
      "1500 steps | score: [0.0787467435002327]\n",
      "1600 steps | score: [0.06818431615829468]\n",
      "1700 steps | score: [0.0741620808839798]\n",
      "1800 steps | score: [0.07398886978626251]\n",
      "1900 steps | score: [0.10224637389183044]\n",
      "2000 steps | score: [0.11063241213560104]\n",
      "2100 steps | score: [0.08766447752714157]\n",
      "2200 steps | score: [0.0803927332162857]\n",
      "2300 steps | score: [0.07769878208637238]\n",
      "2400 steps | score: [0.07980062812566757]\n",
      "2500 steps | score: [0.10299474745988846]\n",
      "2600 steps | score: [0.10815706849098206]\n",
      "2700 steps | score: [0.09698567539453506]\n",
      "0 steps | score: [-0.11834924668073654, 0.46116459369659424]\n",
      "100 steps | score: [-0.052639465779066086, 0.10713449120521545]\n",
      "200 steps | score: [-0.08285759389400482, 0.0778837502002716]\n",
      "300 steps | score: [-0.08223272114992142, 0.11118049919605255]\n",
      "400 steps | score: [-0.1062169224023819, 0.052340105175971985]\n",
      "500 steps | score: [-0.218928262591362, 0.40378308296203613]\n",
      "600 steps | score: [-0.4012269675731659, 0.8883252739906311]\n",
      "700 steps | score: [-0.06484442949295044, -0.09787914156913757]\n",
      "800 steps | score: [-0.09637784212827682, 0.07072630524635315]\n",
      "900 steps | score: [-0.30465227365493774, 0.668109655380249]\n",
      "1000 steps | score: [-0.20033635199069977, 0.36351004242897034]\n",
      "1100 steps | score: [-0.35720258951187134, 0.7695313692092896]\n",
      "1200 steps | score: [-0.1613650619983673, 0.2338469922542572]\n",
      "1300 steps | score: [-0.3256017565727234, 0.6719006896018982]\n",
      "1400 steps | score: [-0.25500431656837463, 0.5326898097991943]\n",
      "1500 steps | score: [-0.3119199275970459, 0.6057614088058472]\n",
      "1600 steps | score: [-0.22064629197120667, 0.42451566457748413]\n",
      "1700 steps | score: [-0.16553357243537903, 0.2502356767654419]\n",
      "1800 steps | score: [-0.3719702661037445, 0.7689260840415955]\n",
      "1900 steps | score: [-0.31077834963798523, 0.6622844338417053]\n",
      "2000 steps | score: [-0.3060908019542694, 0.6129913330078125]\n",
      "2100 steps | score: [-0.2750202417373657, 0.523327112197876]\n",
      "2200 steps | score: [-0.2518188953399658, 0.46031129360198975]\n",
      "2300 steps | score: [-0.3171673119068146, 0.6574645042419434]\n",
      "2400 steps | score: [-0.2669086456298828, 0.4988425374031067]\n",
      "2500 steps | score: [-0.1536119431257248, 0.2307063341140747]\n",
      "2600 steps | score: [-0.2547752261161804, 0.5040356516838074]\n",
      "2700 steps | score: [-0.32360467314720154, 0.6598653793334961]\n",
      "unknown params:  tensor([ 0.1438,  0.2429,  0.6146, -0.6486,  0.4863,  0.4042])\n",
      "gt params:  tensor([ 0.1147,  0.2549,  0.6132, -0.6519,  0.4837,  0.5984])\n",
      "ols params:  tensor([ 0.0902,  0.1520,  0.3801, -0.3963,  0.3025,  2.3394])\n",
      "unknown mse:  tensor(0.0065)\n",
      "ols mse:  tensor(0.5325)\n",
      "gt params:  tensor([ 0.0947,  0.2613,  0.5960, -0.6568,  0.4731,  0.6543])\n",
      "0 steps | score: [0.2092340886592865]\n",
      "100 steps | score: [-0.06294738501310349]\n",
      "200 steps | score: [-0.05218066647648811]\n",
      "300 steps | score: [-0.007581088691949844]\n",
      "0 steps | score: [-0.0858689397573471, 0.5280941724777222]\n",
      "100 steps | score: [-0.12039229273796082, 0.4056544303894043]\n",
      "200 steps | score: [-0.1438136100769043, 0.4225172996520996]\n",
      "300 steps | score: [-0.27804192900657654, 0.745703399181366]\n",
      "400 steps | score: [-0.4901482164859772, 1.2060552835464478]\n",
      "500 steps | score: [-0.31116971373558044, 0.8172920942306519]\n",
      "600 steps | score: [-0.12071128189563751, 0.3067331314086914]\n",
      "700 steps | score: [-0.42703384160995483, 1.0520581007003784]\n",
      "800 steps | score: [-0.21948976814746857, 0.5189260840415955]\n",
      "900 steps | score: [-0.33598268032073975, 0.8426291346549988]\n",
      "1000 steps | score: [-0.2763544023036957, 0.712968111038208]\n",
      "1100 steps | score: [-0.19698511064052582, 0.5176578760147095]\n",
      "1200 steps | score: [-0.20065440237522125, 0.5429602861404419]\n",
      "1300 steps | score: [-0.3016485273838043, 0.7675889730453491]\n",
      "1400 steps | score: [-0.2816846966743469, 0.6863957643508911]\n",
      "1500 steps | score: [0.05195372551679611, -0.12097418308258057]\n",
      "1600 steps | score: [-0.2448132485151291, 0.6145734786987305]\n",
      "1700 steps | score: [-0.2812437117099762, 0.7419076561927795]\n",
      "1800 steps | score: [-0.12319564074277878, 0.32631009817123413]\n",
      "1900 steps | score: [-0.17646783590316772, 0.4555644392967224]\n",
      "2000 steps | score: [-0.22800806164741516, 0.5565838813781738]\n",
      "2100 steps | score: [-0.2718745470046997, 0.6612681150436401]\n",
      "2200 steps | score: [-0.19623205065727234, 0.517616868019104]\n",
      "2300 steps | score: [-0.1728159338235855, 0.44743210077285767]\n",
      "2400 steps | score: [-0.17362943291664124, 0.450132817029953]\n",
      "2500 steps | score: [-0.21697549521923065, 0.589665412902832]\n",
      "2600 steps | score: [-0.24975916743278503, 0.6457279324531555]\n",
      "2700 steps | score: [-0.18560494482517242, 0.4946868121623993]\n",
      "2800 steps | score: [-0.2029472142457962, 0.533302903175354]\n",
      "unknown params:  tensor([ 0.0772,  0.2600,  0.6068, -0.6562,  0.4655,  0.4581])\n",
      "gt params:  tensor([ 0.0947,  0.2613,  0.5960, -0.6568,  0.4731,  0.6543])\n",
      "ols params:  tensor([ 0.0463,  0.1571,  0.3595, -0.3834,  0.2801,  2.5082])\n",
      "unknown mse:  tensor(0.0065)\n",
      "ols mse:  tensor(0.6030)\n",
      "gt params:  tensor([ 0.0893,  0.2513,  0.6003, -0.6820,  0.4835,  0.5842])\n",
      "0 steps | score: [0.2715771198272705]\n",
      "100 steps | score: [0.0750712975859642]\n",
      "200 steps | score: [-0.00600093649700284]\n",
      "0 steps | score: [0.09982176870107651, 0.10406145453453064]\n",
      "100 steps | score: [-0.13862967491149902, 0.4645046591758728]\n",
      "200 steps | score: [0.3715994358062744, -0.8218138813972473]\n",
      "300 steps | score: [-0.11860761791467667, 0.37476128339767456]\n",
      "400 steps | score: [-0.14014360308647156, 0.39366552233695984]\n",
      "500 steps | score: [0.535385251045227, -1.4074729681015015]\n",
      "600 steps | score: [-0.016676612198352814, 0.13846455514431]\n",
      "700 steps | score: [-0.18737365305423737, 0.5010581612586975]\n",
      "800 steps | score: [0.07490444928407669, -0.08487216383218765]\n",
      "900 steps | score: [-0.23986421525478363, 0.5939403772354126]\n",
      "1000 steps | score: [-0.11336855590343475, 0.3435509502887726]\n",
      "1100 steps | score: [-0.10481395572423935, 0.32082438468933105]\n",
      "1200 steps | score: [-0.09100544452667236, 0.2753680348396301]\n",
      "1300 steps | score: [-0.10713525861501694, 0.31190675497055054]\n",
      "1400 steps | score: [-0.21681837737560272, 0.5661896467208862]\n",
      "1500 steps | score: [-0.07538025081157684, 0.23821498453617096]\n",
      "1600 steps | score: [-0.06733086705207825, 0.23168805241584778]\n",
      "1700 steps | score: [-0.06966955959796906, 0.24326811730861664]\n",
      "1800 steps | score: [-0.03512907773256302, 0.17521773278713226]\n",
      "1900 steps | score: [-0.05326101928949356, 0.2195977419614792]\n",
      "2000 steps | score: [-0.12607841193675995, 0.35494041442871094]\n",
      "2100 steps | score: [-0.045417748391628265, 0.15075111389160156]\n",
      "2200 steps | score: [-0.02241998165845871, 0.12527325749397278]\n",
      "2300 steps | score: [-0.034130219370126724, 0.14442647993564606]\n",
      "2400 steps | score: [-0.16621951758861542, 0.45189225673675537]\n",
      "2500 steps | score: [-0.06066741794347763, 0.20558574795722961]\n",
      "2600 steps | score: [-0.0785086378455162, 0.2571873068809509]\n",
      "2700 steps | score: [-0.12096279859542847, 0.3242347240447998]\n",
      "unknown params:  tensor([ 0.1084,  0.2521,  0.6038, -0.6968,  0.4565,  0.3426])\n",
      "gt params:  tensor([ 0.0893,  0.2513,  0.6003, -0.6820,  0.4835,  0.5842])\n",
      "ols params:  tensor([ 0.0638,  0.1495,  0.3509, -0.3987,  0.2720,  2.6033])\n",
      "unknown mse:  tensor(0.0099)\n",
      "ols mse:  tensor(0.7125)\n",
      "gt params:  tensor([ 0.1186,  0.2384,  0.5913, -0.6653,  0.4871,  0.6105])\n",
      "0 steps | score: [0.07176534831523895]\n",
      "100 steps | score: [-0.15338172018527985]\n",
      "200 steps | score: [-0.1537199765443802]\n",
      "300 steps | score: [-0.11791405081748962]\n",
      "400 steps | score: [-0.18207813799381256]\n",
      "500 steps | score: [-0.16340576112270355]\n",
      "600 steps | score: [-0.1573171466588974]\n",
      "700 steps | score: [-0.1474604308605194]\n",
      "800 steps | score: [-0.1312432885169983]\n",
      "900 steps | score: [-0.1498202681541443]\n",
      "1000 steps | score: [-0.17259524762630463]\n",
      "1100 steps | score: [-0.158611461520195]\n",
      "1200 steps | score: [-0.13173745572566986]\n",
      "1300 steps | score: [-0.12732763588428497]\n",
      "1400 steps | score: [-0.13323698937892914]\n",
      "1500 steps | score: [-0.19126391410827637]\n",
      "1600 steps | score: [-0.19495198130607605]\n",
      "1700 steps | score: [-0.15288040041923523]\n",
      "1800 steps | score: [-0.15293769538402557]\n",
      "1900 steps | score: [-0.144753098487854]\n",
      "2000 steps | score: [-0.15266476571559906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 steps | score: [-0.1971803605556488]\n",
      "2200 steps | score: [-0.16265185177326202]\n",
      "2300 steps | score: [-0.14629095792770386]\n",
      "2400 steps | score: [-0.1416066437959671]\n",
      "2500 steps | score: [-0.15897433459758759]\n",
      "2600 steps | score: [-0.15274183452129364]\n",
      "2700 steps | score: [-0.1267346739768982]\n",
      "0 steps | score: [0.020813018083572388, 0.04383870214223862]\n",
      "100 steps | score: [-0.12489760667085648, 0.2553664445877075]\n",
      "200 steps | score: [-0.19786956906318665, 0.32965272665023804]\n",
      "300 steps | score: [-0.13565243780612946, 0.18798092007637024]\n",
      "400 steps | score: [-0.17463143169879913, 0.2766195237636566]\n",
      "500 steps | score: [-0.15771549940109253, 0.21825076639652252]\n",
      "600 steps | score: [-0.10974430292844772, 0.14721977710723877]\n",
      "700 steps | score: [-0.3266131281852722, 0.5503675937652588]\n",
      "800 steps | score: [-0.12900419533252716, 0.17573896050453186]\n",
      "900 steps | score: [0.005196810699999332, -0.1763521283864975]\n",
      "1000 steps | score: [-0.21799397468566895, 0.3365243673324585]\n",
      "1100 steps | score: [-0.24496634304523468, 0.3936008810997009]\n",
      "1200 steps | score: [-0.043402306735515594, -0.008580788969993591]\n",
      "1300 steps | score: [-0.18096405267715454, 0.25503700971603394]\n",
      "1400 steps | score: [-0.11063316464424133, 0.10259176045656204]\n",
      "1500 steps | score: [-0.23174378275871277, 0.3717896342277527]\n",
      "1600 steps | score: [-0.25115442276000977, 0.37025007605552673]\n",
      "1700 steps | score: [-0.17996734380722046, 0.2528200149536133]\n",
      "1800 steps | score: [-0.1043032705783844, 0.09703823924064636]\n",
      "1900 steps | score: [-0.13315124809741974, 0.16044092178344727]\n",
      "2000 steps | score: [-0.1809716820716858, 0.27213549613952637]\n",
      "2100 steps | score: [-0.25449371337890625, 0.3842187821865082]\n",
      "2200 steps | score: [-0.1969267576932907, 0.29668059945106506]\n",
      "2300 steps | score: [-0.18969516456127167, 0.2715497314929962]\n",
      "2400 steps | score: [-0.12932468950748444, 0.15299510955810547]\n",
      "2500 steps | score: [-0.15891721844673157, 0.2234269231557846]\n",
      "2600 steps | score: [-0.20913122594356537, 0.31398189067840576]\n",
      "2700 steps | score: [-0.15292716026306152, 0.19869257509708405]\n",
      "unknown params:  tensor([ 0.1277,  0.2395,  0.6032, -0.6431,  0.4492,  0.4163])\n",
      "gt params:  tensor([ 0.1186,  0.2384,  0.5913, -0.6653,  0.4871,  0.6105])\n",
      "ols params:  tensor([ 0.0714,  0.1374,  0.3391, -0.3592,  0.2599,  2.8360])\n",
      "unknown mse:  tensor(0.0066)\n",
      "ols mse:  tensor(0.8624)\n",
      "gt params:  tensor([ 0.1037,  0.2418,  0.6104, -0.6422,  0.4944,  0.6268])\n",
      "0 steps | score: [0.3012164235115051]\n",
      "100 steps | score: [-0.02045367658138275]\n",
      "200 steps | score: [0.04745723307132721]\n",
      "300 steps | score: [0.05856538191437721]\n",
      "400 steps | score: [0.04038365185260773]\n",
      "500 steps | score: [0.037675242871046066]\n",
      "600 steps | score: [-0.037487372756004333]\n",
      "700 steps | score: [0.09524618089199066]\n",
      "800 steps | score: [0.060988035053014755]\n",
      "900 steps | score: [0.02355670928955078]\n",
      "1000 steps | score: [0.034909896552562714]\n",
      "1100 steps | score: [0.03119830973446369]\n",
      "1200 steps | score: [0.008662089705467224]\n",
      "0 steps | score: [0.06855421513319016, 0.13874655961990356]\n",
      "100 steps | score: [-0.2293524593114853, 0.6369507312774658]\n",
      "200 steps | score: [-0.2660087049007416, 0.6531080603599548]\n",
      "300 steps | score: [-0.09740452468395233, 0.24987737834453583]\n",
      "400 steps | score: [-0.09134066849946976, 0.24061131477355957]\n",
      "500 steps | score: [-0.009334160014986992, 0.043282393366098404]\n",
      "600 steps | score: [-0.08312676101922989, 0.21004362404346466]\n",
      "700 steps | score: [0.149390310049057, -0.35981491208076477]\n",
      "800 steps | score: [-0.060025621205568314, 0.1324785202741623]\n",
      "900 steps | score: [-0.10181889683008194, 0.2734084129333496]\n",
      "1000 steps | score: [-0.048954833298921585, 0.1298411637544632]\n",
      "1100 steps | score: [-0.13169799745082855, 0.3404521644115448]\n",
      "1200 steps | score: [-0.12183317542076111, 0.3238467574119568]\n",
      "1300 steps | score: [-0.05338773503899574, 0.1464846134185791]\n",
      "1400 steps | score: [-0.12246017158031464, 0.31006690859794617]\n",
      "1500 steps | score: [-0.0071042305789887905, -0.003573235124349594]\n",
      "unknown params:  tensor([ 0.1231,  0.2515,  0.6443, -0.6939,  0.4936,  0.5271])\n",
      "gt params:  tensor([ 0.1037,  0.2418,  0.6104, -0.6422,  0.4944,  0.6268])\n",
      "ols params:  tensor([ 0.0651,  0.1327,  0.3337, -0.3578,  0.2631,  2.9222])\n",
      "unknown mse:  tensor(0.0024)\n",
      "ols mse:  tensor(0.9156)\n",
      "gt params:  tensor([ 0.1282,  0.2523,  0.6050, -0.6582,  0.4975,  0.6472])\n",
      "0 steps | score: [0.14687173068523407]\n",
      "100 steps | score: [-0.1922244131565094]\n",
      "200 steps | score: [-0.042329832911491394]\n",
      "300 steps | score: [-0.15902888774871826]\n",
      "400 steps | score: [-0.13003745675086975]\n",
      "500 steps | score: [-0.13595148921012878]\n",
      "600 steps | score: [-0.0953340008854866]\n",
      "700 steps | score: [-0.19111056625843048]\n",
      "800 steps | score: [-0.11465230584144592]\n",
      "900 steps | score: [-0.11783894896507263]\n",
      "1000 steps | score: [-0.14679911732673645]\n",
      "1100 steps | score: [-0.1776530146598816]\n",
      "1200 steps | score: [-0.1293431967496872]\n",
      "1300 steps | score: [-0.13881899416446686]\n",
      "1400 steps | score: [-0.1313544064760208]\n",
      "1500 steps | score: [-0.15791046619415283]\n",
      "1600 steps | score: [-0.14269328117370605]\n",
      "1700 steps | score: [-0.15340778231620789]\n",
      "1800 steps | score: [-0.15096428990364075]\n",
      "1900 steps | score: [-0.16090171039104462]\n",
      "2000 steps | score: [-0.13177499175071716]\n",
      "2100 steps | score: [-0.1372692883014679]\n",
      "2200 steps | score: [-0.13871139287948608]\n",
      "2300 steps | score: [-0.14808793365955353]\n",
      "2400 steps | score: [-0.13562946021556854]\n",
      "2500 steps | score: [-0.15842843055725098]\n",
      "2600 steps | score: [-0.13563880324363708]\n",
      "2700 steps | score: [-0.13081544637680054]\n",
      "0 steps | score: [0.3587547540664673, -0.4545370936393738]\n",
      "100 steps | score: [0.12811516225337982, -0.1041182354092598]\n",
      "200 steps | score: [0.2684137523174286, -0.47102516889572144]\n",
      "300 steps | score: [0.10823684185743332, -0.12647688388824463]\n",
      "400 steps | score: [0.23529860377311707, -0.41465145349502563]\n",
      "500 steps | score: [0.24236953258514404, -0.432266503572464]\n",
      "600 steps | score: [0.3394586741924286, -0.7064634561538696]\n",
      "700 steps | score: [0.023993471637368202, 0.020539257675409317]\n",
      "800 steps | score: [0.15474878251552582, -0.25907403230667114]\n",
      "900 steps | score: [0.26413342356681824, -0.5004705190658569]\n",
      "1000 steps | score: [0.03284270316362381, 0.031446658074855804]\n",
      "1100 steps | score: [0.14228105545043945, -0.22721457481384277]\n",
      "1200 steps | score: [0.041306763887405396, -0.00878445990383625]\n",
      "1300 steps | score: [0.10170238465070724, -0.13955412805080414]\n",
      "1400 steps | score: [0.1365106701850891, -0.1942860335111618]\n",
      "1500 steps | score: [0.22441308200359344, -0.3893044888973236]\n",
      "1600 steps | score: [0.037542931735515594, -0.0214549470692873]\n",
      "1700 steps | score: [0.26448971033096313, -0.5052136182785034]\n",
      "1800 steps | score: [0.11463230103254318, -0.1825534999370575]\n",
      "1900 steps | score: [0.23054900765419006, -0.3892350494861603]\n",
      "2000 steps | score: [0.13976752758026123, -0.21520984172821045]\n",
      "2100 steps | score: [0.21157468855381012, -0.41099220514297485]\n",
      "2200 steps | score: [0.1084868460893631, -0.156897634267807]\n",
      "2300 steps | score: [0.17887192964553833, -0.32357257604599]\n",
      "2400 steps | score: [0.23422566056251526, -0.41862308979034424]\n",
      "2500 steps | score: [0.13554611802101135, -0.19886475801467896]\n",
      "2600 steps | score: [0.15976499021053314, -0.27019697427749634]\n",
      "2700 steps | score: [0.22061699628829956, -0.38424167037010193]\n",
      "unknown params:  tensor([ 0.1213,  0.2479,  0.5958, -0.6419,  0.4978,  0.3746])\n",
      "gt params:  tensor([ 0.1282,  0.2523,  0.6050, -0.6582,  0.4975,  0.6472])\n",
      "ols params:  tensor([ 0.0706,  0.1362,  0.3329, -0.3538,  0.2766,  3.0470])\n",
      "unknown mse:  tensor(0.0125)\n",
      "ols mse:  tensor(0.9985)\n",
      "gt params:  tensor([ 0.1051,  0.2533,  0.6048, -0.6762,  0.4885,  0.5528])\n",
      "0 steps | score: [0.3908063471317291]\n",
      "100 steps | score: [0.1322125494480133]\n",
      "200 steps | score: [0.12746557593345642]\n",
      "300 steps | score: [0.05446435511112213]\n",
      "400 steps | score: [0.06396409869194031]\n",
      "500 steps | score: [0.11325225979089737]\n",
      "600 steps | score: [0.08273351937532425]\n",
      "700 steps | score: [0.11264269053936005]\n",
      "800 steps | score: [0.16166773438453674]\n",
      "900 steps | score: [0.10681858658790588]\n",
      "1000 steps | score: [0.07392324507236481]\n",
      "1100 steps | score: [0.13481886684894562]\n",
      "1200 steps | score: [0.12440957874059677]\n",
      "1300 steps | score: [0.110958531498909]\n",
      "1400 steps | score: [0.1023554801940918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 steps | score: [0.07905393838882446]\n",
      "1600 steps | score: [0.11065398901700974]\n",
      "1700 steps | score: [0.096174456179142]\n",
      "1800 steps | score: [0.11079123616218567]\n",
      "1900 steps | score: [0.15528987348079681]\n",
      "2000 steps | score: [0.09457636624574661]\n",
      "2100 steps | score: [0.11074164509773254]\n",
      "2200 steps | score: [0.12620829045772552]\n",
      "2300 steps | score: [0.12123255431652069]\n",
      "2400 steps | score: [0.11891941726207733]\n",
      "2500 steps | score: [0.11843222379684448]\n",
      "2600 steps | score: [0.10710006952285767]\n",
      "2700 steps | score: [0.11829058825969696]\n",
      "0 steps | score: [0.285421758890152, -0.29670214653015137]\n",
      "100 steps | score: [-0.12590987980365753, 0.41246554255485535]\n",
      "200 steps | score: [0.0724528431892395, -0.05073259398341179]\n",
      "300 steps | score: [-0.0462208054959774, 0.20216479897499084]\n",
      "400 steps | score: [0.07398885488510132, -0.06590414047241211]\n",
      "500 steps | score: [-0.024642007425427437, 0.1585511565208435]\n",
      "600 steps | score: [0.025535771623253822, 0.04489339143037796]\n",
      "700 steps | score: [0.0986759215593338, -0.11131242662668228]\n",
      "800 steps | score: [0.07268278300762177, -0.04243340715765953]\n",
      "900 steps | score: [0.12876005470752716, -0.17965063452720642]\n",
      "1000 steps | score: [0.18001191318035126, -0.2958631217479706]\n",
      "1100 steps | score: [0.24134759604930878, -0.4653805196285248]\n",
      "1200 steps | score: [0.37080082297325134, -0.7727534770965576]\n",
      "1300 steps | score: [0.17882196605205536, -0.3257056176662445]\n",
      "1400 steps | score: [0.10904917120933533, -0.1446506381034851]\n",
      "1500 steps | score: [0.02974041737616062, 0.04395690932869911]\n",
      "1600 steps | score: [0.16136334836483002, -0.28853732347488403]\n",
      "1700 steps | score: [0.06178569421172142, -0.030120179057121277]\n",
      "1800 steps | score: [0.09410808235406876, -0.12131232023239136]\n",
      "1900 steps | score: [0.22939589619636536, -0.4381103813648224]\n",
      "2000 steps | score: [0.09872028976678848, -0.10714267939329147]\n",
      "2100 steps | score: [0.09272263944149017, -0.10671517252922058]\n",
      "2200 steps | score: [0.24045754969120026, -0.46867990493774414]\n",
      "2300 steps | score: [0.21601298451423645, -0.4247172474861145]\n",
      "2400 steps | score: [0.1435447335243225, -0.23657897114753723]\n",
      "2500 steps | score: [0.08792736381292343, -0.11274248361587524]\n",
      "2600 steps | score: [0.11408980190753937, -0.16270175576210022]\n",
      "2700 steps | score: [0.1468532234430313, -0.25504201650619507]\n",
      "unknown params:  tensor([ 0.0978,  0.2500,  0.6230, -0.6886,  0.5384,  0.3877])\n",
      "gt params:  tensor([ 0.1051,  0.2533,  0.6048, -0.6762,  0.4885,  0.5528])\n",
      "ols params:  tensor([ 0.0488,  0.1303,  0.3095, -0.3338,  0.2696,  3.1361])\n",
      "unknown mse:  tensor(0.0050)\n",
      "ols mse:  tensor(1.1573)\n",
      "gt params:  tensor([ 0.1085,  0.2470,  0.5816, -0.6434,  0.4809,  0.6217])\n",
      "0 steps | score: [0.25581276416778564]\n",
      "100 steps | score: [-0.0373091921210289]\n",
      "200 steps | score: [-0.08574232459068298]\n",
      "300 steps | score: [0.039289385080337524]\n",
      "400 steps | score: [-0.04858388006687164]\n",
      "500 steps | score: [-0.016783645376563072]\n",
      "600 steps | score: [-0.005548790097236633]\n",
      "0 steps | score: [-0.0021239928901195526, 0.28711822628974915]\n",
      "100 steps | score: [0.07402720302343369, -0.044026244431734085]\n",
      "200 steps | score: [-0.1707972139120102, 0.44590094685554504]\n",
      "300 steps | score: [-0.24334442615509033, 0.5885857939720154]\n",
      "400 steps | score: [-0.1370612531900406, 0.33318957686424255]\n",
      "500 steps | score: [-0.1754980981349945, 0.4048364758491516]\n",
      "600 steps | score: [-0.001995386555790901, -0.021426811814308167]\n",
      "700 steps | score: [-0.11879825592041016, 0.25800809264183044]\n",
      "800 steps | score: [-0.14024974405765533, 0.3035036325454712]\n",
      "900 steps | score: [-0.03646843135356903, 0.07811038941144943]\n",
      "1000 steps | score: [-0.1842796504497528, 0.42577946186065674]\n",
      "1100 steps | score: [-0.2613285779953003, 0.6087920665740967]\n",
      "1200 steps | score: [-0.2412782907485962, 0.5756432414054871]\n",
      "1300 steps | score: [-0.18021857738494873, 0.45204848051071167]\n",
      "1400 steps | score: [-0.11211863160133362, 0.23055046796798706]\n",
      "1500 steps | score: [-0.2185102254152298, 0.5027244687080383]\n",
      "1600 steps | score: [-0.13139718770980835, 0.3341788053512573]\n",
      "1700 steps | score: [-0.06744018197059631, 0.1135948896408081]\n",
      "1800 steps | score: [0.05663496255874634, -0.16750237345695496]\n",
      "1900 steps | score: [-0.011971061117947102, 0.03453334420919418]\n",
      "2000 steps | score: [-0.1132328063249588, 0.21108853816986084]\n",
      "2100 steps | score: [-0.19816796481609344, 0.44724729657173157]\n",
      "2200 steps | score: [-0.21998336911201477, 0.5172438621520996]\n",
      "2300 steps | score: [-0.1960408240556717, 0.45725876092910767]\n",
      "2400 steps | score: [-0.1768999546766281, 0.4168723523616791]\n",
      "2500 steps | score: [-0.0251191146671772, 0.012876294553279877]\n",
      "2600 steps | score: [-0.19323010742664337, 0.42811644077301025]\n",
      "2700 steps | score: [-0.09937956184148788, 0.23479890823364258]\n",
      "unknown params:  tensor([ 0.0829,  0.2631,  0.5504, -0.6062,  0.4425,  0.3545])\n",
      "gt params:  tensor([ 0.1085,  0.2470,  0.5816, -0.6434,  0.4809,  0.6217])\n",
      "ols params:  tensor([ 0.0473,  0.1445,  0.2948, -0.3270,  0.2437,  3.2830])\n",
      "unknown mse:  tensor(0.0127)\n",
      "ols mse:  tensor(1.2226)\n",
      "gt params:  tensor([ 0.1037,  0.2644,  0.5956, -0.6391,  0.4998,  0.5642])\n",
      "0 steps | score: [0.06949183344841003]\n",
      "100 steps | score: [-0.2285608947277069]\n",
      "200 steps | score: [-0.18789076805114746]\n",
      "300 steps | score: [-0.21593868732452393]\n",
      "400 steps | score: [-0.2197369933128357]\n",
      "500 steps | score: [-0.18962085247039795]\n",
      "600 steps | score: [-0.23049935698509216]\n",
      "700 steps | score: [-0.19323763251304626]\n",
      "800 steps | score: [-0.1978728026151657]\n",
      "900 steps | score: [-0.1828508973121643]\n",
      "1000 steps | score: [-0.1902245134115219]\n",
      "1100 steps | score: [-0.21291981637477875]\n",
      "1200 steps | score: [-0.21028144657611847]\n",
      "1300 steps | score: [-0.17562392354011536]\n",
      "1400 steps | score: [-0.1988132745027542]\n",
      "1500 steps | score: [-0.20977824926376343]\n",
      "1600 steps | score: [-0.22041021287441254]\n",
      "1700 steps | score: [-0.22029869258403778]\n",
      "1800 steps | score: [-0.2023930549621582]\n",
      "1900 steps | score: [-0.1990307867527008]\n",
      "2000 steps | score: [-0.19173456728458405]\n",
      "2100 steps | score: [-0.2199004590511322]\n",
      "2200 steps | score: [-0.21960362792015076]\n",
      "2300 steps | score: [-0.21433329582214355]\n",
      "2400 steps | score: [-0.20915673673152924]\n",
      "2500 steps | score: [-0.21382959187030792]\n",
      "2600 steps | score: [-0.20509135723114014]\n",
      "2700 steps | score: [-0.20631879568099976]\n",
      "0 steps | score: [0.07125858217477798, 0.25091129541397095]\n",
      "100 steps | score: [-0.04907681420445442, 0.36091065406799316]\n",
      "200 steps | score: [-0.10887838155031204, 0.4566255211830139]\n",
      "300 steps | score: [-0.1896049976348877, 0.6147878766059875]\n",
      "400 steps | score: [-0.21878015995025635, 0.6527071595191956]\n",
      "500 steps | score: [0.13106772303581238, -0.15611399710178375]\n",
      "600 steps | score: [0.10311803966760635, -0.08528230339288712]\n",
      "700 steps | score: [-0.21508526802062988, 0.6390444040298462]\n",
      "800 steps | score: [-0.2629830539226532, 0.7406367659568787]\n",
      "900 steps | score: [0.1714547872543335, -0.29238376021385193]\n",
      "1000 steps | score: [-0.1323508322238922, 0.46005916595458984]\n",
      "1100 steps | score: [-0.08078131079673767, 0.31708580255508423]\n",
      "1200 steps | score: [-0.13679556548595428, 0.4494491219520569]\n",
      "1300 steps | score: [-0.10537993162870407, 0.3987826704978943]\n",
      "1400 steps | score: [-0.024855639785528183, 0.1959628015756607]\n",
      "1500 steps | score: [-0.2276885062456131, 0.6591264605522156]\n",
      "1600 steps | score: [-0.16724099218845367, 0.5161626935005188]\n",
      "1700 steps | score: [0.035444196313619614, 0.05477847903966904]\n",
      "1800 steps | score: [-0.09902267158031464, 0.3768163323402405]\n",
      "1900 steps | score: [-0.11771858483552933, 0.4014289975166321]\n",
      "2000 steps | score: [1.6938520275289193e-05, 0.11731874942779541]\n",
      "2100 steps | score: [-0.05947769060730934, 0.2824828028678894]\n",
      "2200 steps | score: [-0.11182721704244614, 0.3979107141494751]\n",
      "2300 steps | score: [-0.10097108781337738, 0.39728879928588867]\n",
      "2400 steps | score: [-0.05695037543773651, 0.2573939859867096]\n",
      "2500 steps | score: [-0.09527242928743362, 0.3670247793197632]\n",
      "2600 steps | score: [-0.14577075839042664, 0.47047439217567444]\n",
      "2700 steps | score: [-0.0793042778968811, 0.3299635648727417]\n",
      "unknown params:  tensor([ 0.0757,  0.2664,  0.5969, -0.6512,  0.5105,  0.3450])\n",
      "gt params:  tensor([ 0.1037,  0.2644,  0.5956, -0.6391,  0.4998,  0.5642])\n",
      "ols params:  tensor([ 0.0382,  0.1371,  0.3035, -0.3277,  0.2625,  3.3536])\n",
      "unknown mse:  tensor(0.0082)\n",
      "ols mse:  tensor(1.3400)\n",
      "gt params:  tensor([ 0.1029,  0.2463,  0.6196, -0.6600,  0.4936,  0.6274])\n",
      "0 steps | score: [0.17179445922374725]\n",
      "100 steps | score: [-0.07977933436632156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [-0.13095255196094513]\n",
      "300 steps | score: [-0.07038222998380661]\n",
      "400 steps | score: [-0.06745017319917679]\n",
      "500 steps | score: [-0.1065218448638916]\n",
      "600 steps | score: [-0.1216036006808281]\n",
      "700 steps | score: [-0.08608990907669067]\n",
      "800 steps | score: [-0.07888159155845642]\n",
      "900 steps | score: [-0.07261751592159271]\n",
      "1000 steps | score: [-0.06616833806037903]\n",
      "1100 steps | score: [-0.1017797589302063]\n",
      "1200 steps | score: [-0.1300712674856186]\n",
      "1300 steps | score: [-0.1141270101070404]\n",
      "1400 steps | score: [-0.0943940207362175]\n",
      "1500 steps | score: [-0.08136902749538422]\n",
      "1600 steps | score: [-0.11452789604663849]\n",
      "1700 steps | score: [-0.10143503546714783]\n",
      "1800 steps | score: [-0.08149206638336182]\n",
      "1900 steps | score: [-0.08553886413574219]\n",
      "2000 steps | score: [-0.09604048728942871]\n",
      "2100 steps | score: [-0.09642285108566284]\n",
      "2200 steps | score: [-0.11886445432901382]\n",
      "2300 steps | score: [-0.11059023439884186]\n",
      "2400 steps | score: [-0.11751450598239899]\n",
      "2500 steps | score: [-0.09913933277130127]\n",
      "2600 steps | score: [-0.09896485507488251]\n",
      "2700 steps | score: [-0.11827968060970306]\n",
      "0 steps | score: [0.3281797766685486, -0.23328949511051178]\n",
      "100 steps | score: [0.24943600594997406, -0.1820978820323944]\n",
      "200 steps | score: [0.1970023810863495, -0.15985172986984253]\n",
      "300 steps | score: [0.3348785638809204, -0.506324291229248]\n",
      "400 steps | score: [0.1524152308702469, -0.07827529311180115]\n",
      "500 steps | score: [0.21672268211841583, -0.29052209854125977]\n",
      "600 steps | score: [0.11193295568227768, 0.007056817412376404]\n",
      "700 steps | score: [0.0547129325568676, 0.11923255771398544]\n",
      "800 steps | score: [0.28327852487564087, -0.42488595843315125]\n",
      "900 steps | score: [0.3479015529155731, -0.5696314573287964]\n",
      "1000 steps | score: [0.16543839871883392, -0.1499800980091095]\n",
      "1100 steps | score: [0.13678772747516632, -0.08143213391304016]\n",
      "1200 steps | score: [0.32645630836486816, -0.5530349016189575]\n",
      "1300 steps | score: [0.12388858199119568, -0.04320967197418213]\n",
      "1400 steps | score: [0.24785003066062927, -0.3172003924846649]\n",
      "1500 steps | score: [0.1883532553911209, -0.18084393441677094]\n",
      "1600 steps | score: [0.24629124999046326, -0.3278488218784332]\n",
      "1700 steps | score: [0.11195222288370132, -0.04090472310781479]\n",
      "1800 steps | score: [0.17143414914608002, -0.13601520657539368]\n",
      "1900 steps | score: [0.23210902512073517, -0.28359127044677734]\n",
      "2000 steps | score: [0.2771969139575958, -0.43270784616470337]\n",
      "2100 steps | score: [0.2467256784439087, -0.3213922083377838]\n",
      "2200 steps | score: [0.2060236781835556, -0.2523472309112549]\n",
      "2300 steps | score: [0.21996623277664185, -0.25778207182884216]\n",
      "2400 steps | score: [0.1446186900138855, -0.1194770336151123]\n",
      "2500 steps | score: [0.241029754281044, -0.3330127000808716]\n",
      "2600 steps | score: [0.2089979648590088, -0.23446880280971527]\n",
      "2700 steps | score: [0.1933494210243225, -0.20762215554714203]\n",
      "unknown params:  tensor([ 0.1043,  0.2201,  0.5920, -0.6416,  0.4792,  0.3836])\n",
      "gt params:  tensor([ 0.1029,  0.2463,  0.6196, -0.6600,  0.4936,  0.6274])\n",
      "ols params:  tensor([ 0.0504,  0.1148,  0.3009, -0.3239,  0.2452,  3.5341])\n",
      "unknown mse:  tensor(0.0102)\n",
      "ols mse:  tensor(1.4575)\n",
      "gt params:  tensor([ 0.1178,  0.2466,  0.6306, -0.6588,  0.4819,  0.5620])\n",
      "0 steps | score: [0.4105626940727234]\n",
      "100 steps | score: [0.19525562226772308]\n",
      "200 steps | score: [0.12121309340000153]\n",
      "300 steps | score: [0.10642576217651367]\n",
      "400 steps | score: [0.08993348479270935]\n",
      "500 steps | score: [0.16063542664051056]\n",
      "600 steps | score: [0.12701696157455444]\n",
      "700 steps | score: [0.1688428521156311]\n",
      "800 steps | score: [0.1310795545578003]\n",
      "900 steps | score: [0.14602121710777283]\n",
      "1000 steps | score: [0.06962988525629044]\n",
      "1100 steps | score: [0.1123850867152214]\n",
      "1200 steps | score: [0.13519039750099182]\n",
      "1300 steps | score: [0.133988156914711]\n",
      "1400 steps | score: [0.10422134399414062]\n",
      "1500 steps | score: [0.10028122365474701]\n",
      "1600 steps | score: [0.08991935104131699]\n",
      "1700 steps | score: [0.12508198618888855]\n",
      "1800 steps | score: [0.1558895707130432]\n",
      "1900 steps | score: [0.12058254331350327]\n",
      "2000 steps | score: [0.11698751896619797]\n",
      "2100 steps | score: [0.127907857298851]\n",
      "2200 steps | score: [0.08916042745113373]\n",
      "2300 steps | score: [0.09538555145263672]\n",
      "2400 steps | score: [0.09761344641447067]\n",
      "2500 steps | score: [0.13499502837657928]\n",
      "2600 steps | score: [0.10127556324005127]\n",
      "0 steps | score: [0.3148278295993805, -0.2768012583255768]\n",
      "100 steps | score: [0.16283388435840607, -0.0762573704123497]\n",
      "200 steps | score: [0.12741625308990479, -0.07856271415948868]\n",
      "300 steps | score: [0.06484661251306534, 0.05004085600376129]\n",
      "400 steps | score: [0.17328770458698273, -0.1936815083026886]\n",
      "500 steps | score: [0.3210768401622772, -0.5708078145980835]\n",
      "600 steps | score: [0.1666087806224823, -0.18584227561950684]\n",
      "700 steps | score: [0.12929557263851166, -0.11114370822906494]\n",
      "800 steps | score: [0.22422192990779877, -0.34022626280784607]\n",
      "900 steps | score: [0.31822118163108826, -0.5982217788696289]\n",
      "1000 steps | score: [0.0727660208940506, 0.01778721809387207]\n",
      "1100 steps | score: [0.2722281515598297, -0.4626455008983612]\n",
      "1200 steps | score: [0.21135137975215912, -0.31274664402008057]\n",
      "1300 steps | score: [0.17418567836284637, -0.2448759377002716]\n",
      "1400 steps | score: [0.10794737935066223, -0.06050046533346176]\n",
      "1500 steps | score: [0.05403249338269234, 0.06936690211296082]\n",
      "1600 steps | score: [0.06512429565191269, 0.037391483783721924]\n",
      "1700 steps | score: [0.2240372598171234, -0.33178380131721497]\n",
      "1800 steps | score: [0.22392013669013977, -0.32070934772491455]\n",
      "1900 steps | score: [0.22802570462226868, -0.33512115478515625]\n",
      "2000 steps | score: [0.11908259987831116, -0.09105446934700012]\n",
      "2100 steps | score: [0.3861646354198456, -0.7757461071014404]\n",
      "2200 steps | score: [0.1677543818950653, -0.23339858651161194]\n",
      "2300 steps | score: [0.2444801777601242, -0.4215424358844757]\n",
      "2400 steps | score: [0.20451119542121887, -0.3176664113998413]\n",
      "2500 steps | score: [0.1922413408756256, -0.26862257719039917]\n",
      "2600 steps | score: [0.10803169012069702, -0.08957403898239136]\n",
      "unknown params:  tensor([ 0.1214,  0.2538,  0.6671, -0.6734,  0.5026,  0.3740])\n",
      "gt params:  tensor([ 0.1178,  0.2466,  0.6306, -0.6588,  0.4819,  0.5620])\n",
      "ols params:  tensor([ 0.0606,  0.1304,  0.3262, -0.3304,  0.2513,  3.5629])\n",
      "unknown mse:  tensor(0.0062)\n",
      "ols mse:  tensor(1.5460)\n",
      "gt params:  tensor([ 0.0918,  0.2429,  0.6027, -0.6616,  0.5055,  0.5842])\n",
      "0 steps | score: [0.35879623889923096]\n",
      "100 steps | score: [0.021886929869651794]\n",
      "200 steps | score: [0.03522387146949768]\n",
      "300 steps | score: [0.05257566273212433]\n",
      "400 steps | score: [0.139029398560524]\n",
      "500 steps | score: [0.05471939966082573]\n",
      "600 steps | score: [0.045462239533662796]\n",
      "700 steps | score: [0.05616585910320282]\n",
      "800 steps | score: [0.09287688881158829]\n",
      "900 steps | score: [0.11248411983251572]\n",
      "1000 steps | score: [0.10978861153125763]\n",
      "1100 steps | score: [0.07153694331645966]\n",
      "1200 steps | score: [0.05680835247039795]\n",
      "1300 steps | score: [0.08347178250551224]\n",
      "1400 steps | score: [0.06362126767635345]\n",
      "1500 steps | score: [0.07673945277929306]\n",
      "1600 steps | score: [0.06535281985998154]\n",
      "1700 steps | score: [0.06048106402158737]\n",
      "1800 steps | score: [0.0734572559595108]\n",
      "1900 steps | score: [0.08430985361337662]\n",
      "2000 steps | score: [0.10209289938211441]\n",
      "2100 steps | score: [0.08100125938653946]\n",
      "2200 steps | score: [0.08664368093013763]\n",
      "2300 steps | score: [0.08705273270606995]\n",
      "2400 steps | score: [0.08174821734428406]\n",
      "2500 steps | score: [0.07660258561372757]\n",
      "2600 steps | score: [0.074650838971138]\n",
      "2700 steps | score: [0.07860530912876129]\n",
      "0 steps | score: [0.23329176008701324, -0.2365226298570633]\n",
      "100 steps | score: [0.00044757931027561426, 0.10776129364967346]\n",
      "200 steps | score: [-0.0783008262515068, 0.21100133657455444]\n",
      "300 steps | score: [-0.02262035757303238, 0.08187287300825119]\n",
      "400 steps | score: [0.06228923052549362, -0.09013330191373825]\n",
      "500 steps | score: [-0.08225737512111664, 0.1701158583164215]\n",
      "600 steps | score: [-0.12855201959609985, 0.2740567922592163]\n",
      "700 steps | score: [0.015053990297019482, 0.01212109625339508]\n",
      "800 steps | score: [0.06912709027528763, -0.10498356074094772]\n",
      "900 steps | score: [0.10336053371429443, -0.19047804176807404]\n",
      "1000 steps | score: [-0.040948785841464996, 0.12116523832082748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 steps | score: [-0.06514465808868408, 0.1625629961490631]\n",
      "1200 steps | score: [-0.012963001616299152, 0.06452777236700058]\n",
      "1300 steps | score: [0.13843189179897308, -0.28293341398239136]\n",
      "1400 steps | score: [0.08727995306253433, -0.1751219928264618]\n",
      "1500 steps | score: [0.003545238869264722, 0.003751881420612335]\n",
      "unknown params:  tensor([ 0.1372,  0.2276,  0.5718, -0.5982,  0.4913,  0.3781])\n",
      "gt params:  tensor([ 0.0918,  0.2429,  0.6027, -0.6616,  0.5055,  0.5842])\n",
      "ols params:  tensor([ 0.0633,  0.1220,  0.2967, -0.3144,  0.2559,  3.6883])\n",
      "unknown mse:  tensor(0.0083)\n",
      "ols mse:  tensor(1.6545)\n",
      "gt params:  tensor([ 0.0955,  0.2399,  0.5834, -0.6424,  0.5022,  0.5280])\n",
      "0 steps | score: [0.36972373723983765]\n",
      "100 steps | score: [0.06697064638137817]\n",
      "200 steps | score: [0.11767283082008362]\n",
      "300 steps | score: [0.08156280964612961]\n",
      "400 steps | score: [0.08974847197532654]\n",
      "500 steps | score: [0.03818299621343613]\n",
      "600 steps | score: [0.11042632162570953]\n",
      "700 steps | score: [0.039316948503255844]\n",
      "800 steps | score: [0.11076730489730835]\n",
      "900 steps | score: [0.07713679224252701]\n",
      "1000 steps | score: [0.09949043393135071]\n",
      "1100 steps | score: [0.056752175092697144]\n",
      "1200 steps | score: [0.04238385334610939]\n",
      "1300 steps | score: [0.08417444676160812]\n",
      "1400 steps | score: [0.060476355254650116]\n",
      "1500 steps | score: [0.08101961761713028]\n",
      "1600 steps | score: [0.045617908239364624]\n",
      "1700 steps | score: [0.08320563286542892]\n",
      "1800 steps | score: [0.052407898008823395]\n",
      "1900 steps | score: [0.08059129863977432]\n",
      "2000 steps | score: [0.040750522166490555]\n",
      "2100 steps | score: [0.06506174802780151]\n",
      "2200 steps | score: [0.04637625440955162]\n",
      "2300 steps | score: [0.06865023076534271]\n",
      "2400 steps | score: [0.06405539065599442]\n",
      "2500 steps | score: [0.06385299563407898]\n",
      "2600 steps | score: [0.08952739089727402]\n",
      "0 steps | score: [0.10045605897903442, -0.06217382848262787]\n",
      "100 steps | score: [-0.058418165892362595, 0.12884166836738586]\n",
      "200 steps | score: [0.31799542903900146, -0.8293569684028625]\n",
      "300 steps | score: [0.023505540564656258, -0.11712484061717987]\n",
      "400 steps | score: [-0.23335769772529602, 0.44678789377212524]\n",
      "500 steps | score: [-0.05607326328754425, 0.05574668198823929]\n",
      "600 steps | score: [-0.037966251373291016, -0.025118567049503326]\n",
      "700 steps | score: [0.013371648266911507, -0.1473352313041687]\n",
      "800 steps | score: [-0.0002027564332820475, -0.08227548748254776]\n",
      "900 steps | score: [-0.04436993971467018, 0.02760722115635872]\n",
      "1000 steps | score: [-0.09790126234292984, 0.12624788284301758]\n",
      "1100 steps | score: [-0.1329011768102646, 0.19588255882263184]\n",
      "1200 steps | score: [-0.1410074234008789, 0.21226945519447327]\n",
      "1300 steps | score: [-0.13976474106311798, 0.20193257927894592]\n",
      "1400 steps | score: [-0.09794407337903976, 0.12415473163127899]\n",
      "1500 steps | score: [-0.028041092678904533, -0.05137660354375839]\n",
      "1600 steps | score: [-0.09706227481365204, 0.1333945393562317]\n",
      "1700 steps | score: [-0.12212035804986954, 0.17705482244491577]\n",
      "1800 steps | score: [-0.035872530192136765, -0.03389538824558258]\n",
      "1900 steps | score: [-0.06006426364183426, 0.045576587319374084]\n",
      "2000 steps | score: [0.02026703953742981, -0.1418820172548294]\n",
      "2100 steps | score: [-0.13394416868686676, 0.19046345353126526]\n",
      "2200 steps | score: [0.016981566324830055, -0.11016053706407547]\n",
      "2300 steps | score: [-0.03459665924310684, -0.01797589659690857]\n",
      "2400 steps | score: [-0.03434669226408005, -0.024452045559883118]\n",
      "2500 steps | score: [-0.09003488719463348, 0.11851808428764343]\n",
      "2600 steps | score: [0.03488880395889282, -0.16604450345039368]\n",
      "unknown params:  tensor([ 0.1069,  0.3121,  0.5852, -0.6550,  0.4892,  0.1789])\n",
      "gt params:  tensor([ 0.0955,  0.2399,  0.5834, -0.6424,  0.5022,  0.5280])\n",
      "ols params:  tensor([ 0.0514,  0.1521,  0.2781, -0.3039,  0.2360,  3.7163])\n",
      "unknown mse:  tensor(0.0213)\n",
      "ols mse:  tensor(1.7422)\n",
      "gt params:  tensor([ 0.1212,  0.2281,  0.6227, -0.6576,  0.5039,  0.5706])\n",
      "0 steps | score: [0.24459774792194366]\n",
      "100 steps | score: [-0.06594548374414444]\n",
      "200 steps | score: [-0.01651141792535782]\n",
      "300 steps | score: [-0.00803111121058464]\n",
      "0 steps | score: [-0.06837478280067444, 0.5898869037628174]\n",
      "100 steps | score: [-0.1136554479598999, 0.610110342502594]\n",
      "200 steps | score: [-0.29381000995635986, 0.8797929883003235]\n",
      "300 steps | score: [0.28152891993522644, -0.5448035001754761]\n",
      "400 steps | score: [-0.2998822331428528, 0.862614095211029]\n",
      "500 steps | score: [-0.3134930431842804, 0.8795561790466309]\n",
      "600 steps | score: [-0.37794825434684753, 1.009106159210205]\n",
      "700 steps | score: [-0.34449511766433716, 0.9453268647193909]\n",
      "800 steps | score: [-0.288279265165329, 0.7878175377845764]\n",
      "900 steps | score: [-0.060103707015514374, 0.27355796098709106]\n",
      "1000 steps | score: [-0.051191914826631546, 0.2419552356004715]\n",
      "1100 steps | score: [-0.3971897065639496, 1.0393580198287964]\n",
      "1200 steps | score: [-0.26793938875198364, 0.7995963096618652]\n",
      "1300 steps | score: [-0.22755460441112518, 0.695614755153656]\n",
      "1400 steps | score: [-0.17899712920188904, 0.5831697583198547]\n",
      "1500 steps | score: [-0.16875140368938446, 0.5387736558914185]\n",
      "1600 steps | score: [-0.16541548073291779, 0.5449405312538147]\n",
      "1700 steps | score: [-0.31158778071403503, 0.8746245503425598]\n",
      "1800 steps | score: [-0.05860608071088791, 0.2878521978855133]\n",
      "1900 steps | score: [-0.1538817286491394, 0.5367768406867981]\n",
      "2000 steps | score: [-0.08543488383293152, 0.3772662580013275]\n",
      "2100 steps | score: [-0.1651976853609085, 0.5692119002342224]\n",
      "2200 steps | score: [-0.29651039838790894, 0.8458189368247986]\n",
      "2300 steps | score: [-0.28800058364868164, 0.8154191374778748]\n",
      "2400 steps | score: [-0.2753593921661377, 0.796685516834259]\n",
      "2500 steps | score: [-0.21750424802303314, 0.6520395278930664]\n",
      "2600 steps | score: [-0.22038021683692932, 0.6748193502426147]\n",
      "2700 steps | score: [-0.22984986007213593, 0.6951063275337219]\n",
      "unknown params:  tensor([ 0.1380,  0.2689,  0.5609, -0.6715,  0.4125,  0.2791])\n",
      "gt params:  tensor([ 0.1212,  0.2281,  0.6227, -0.6576,  0.5039,  0.5706])\n",
      "ols params:  tensor([ 0.0678,  0.1314,  0.2715, -0.3169,  0.2001,  3.8932])\n",
      "unknown mse:  tensor(0.0166)\n",
      "ols mse:  tensor(1.8972)\n",
      "gt params:  tensor([ 0.1182,  0.2373,  0.6038, -0.6485,  0.4907,  0.5074])\n",
      "0 steps | score: [0.215301975607872]\n",
      "100 steps | score: [-0.030011311173439026]\n",
      "200 steps | score: [-0.06549197435379028]\n",
      "300 steps | score: [-0.1039869487285614]\n",
      "400 steps | score: [-0.08525832742452621]\n",
      "500 steps | score: [-0.07667601853609085]\n",
      "600 steps | score: [-0.07343032211065292]\n",
      "700 steps | score: [-0.11166106164455414]\n",
      "800 steps | score: [-0.11598002910614014]\n",
      "900 steps | score: [-0.06327177584171295]\n",
      "1000 steps | score: [-0.08096538484096527]\n",
      "1100 steps | score: [-0.11066200584173203]\n",
      "1200 steps | score: [-0.07806549221277237]\n",
      "1300 steps | score: [-0.1335630714893341]\n",
      "1400 steps | score: [-0.059075336903333664]\n",
      "1500 steps | score: [-0.13948367536067963]\n",
      "1600 steps | score: [-0.09524175524711609]\n",
      "1700 steps | score: [-0.06714428216218948]\n",
      "1800 steps | score: [-0.09368377178907394]\n",
      "1900 steps | score: [-0.08869745582342148]\n",
      "2000 steps | score: [-0.11474190652370453]\n",
      "2100 steps | score: [-0.12365284562110901]\n",
      "2200 steps | score: [-0.09754392504692078]\n",
      "2300 steps | score: [-0.0915166363120079]\n",
      "2400 steps | score: [-0.09476111084222794]\n",
      "2500 steps | score: [-0.09323696047067642]\n",
      "2600 steps | score: [-0.12137471139431]\n",
      "0 steps | score: [0.37698894739151, -0.4168253242969513]\n",
      "100 steps | score: [0.2077004611492157, -0.1506117582321167]\n",
      "200 steps | score: [0.2790070176124573, -0.39963817596435547]\n",
      "300 steps | score: [0.12057942152023315, -0.11066275835037231]\n",
      "400 steps | score: [0.29244160652160645, -0.4513625502586365]\n",
      "500 steps | score: [0.1740640550851822, -0.2123672366142273]\n",
      "600 steps | score: [0.09639018028974533, -0.031129367649555206]\n",
      "700 steps | score: [0.11826824396848679, -0.08832766115665436]\n",
      "800 steps | score: [0.20964793860912323, -0.2797343134880066]\n",
      "900 steps | score: [0.11192910373210907, -0.08275564759969711]\n",
      "1000 steps | score: [0.41462212800979614, -0.7738877534866333]\n",
      "1100 steps | score: [0.27975401282310486, -0.41425585746765137]\n",
      "1200 steps | score: [0.22563517093658447, -0.2949385643005371]\n",
      "1300 steps | score: [0.008739694952964783, 0.10963571816682816]\n",
      "1400 steps | score: [0.3525126874446869, -0.6036683320999146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 steps | score: [0.03297872096300125, 0.06256595253944397]\n",
      "1600 steps | score: [0.25496068596839905, -0.3950262665748596]\n",
      "1700 steps | score: [0.20599791407585144, -0.24252194166183472]\n",
      "1800 steps | score: [0.2258988618850708, -0.324148565530777]\n",
      "1900 steps | score: [0.20143115520477295, -0.30182188749313354]\n",
      "2000 steps | score: [0.15937753021717072, -0.19949829578399658]\n",
      "2100 steps | score: [0.13269630074501038, -0.12537743151187897]\n",
      "2200 steps | score: [0.25267788767814636, -0.37633851170539856]\n",
      "2300 steps | score: [0.13930027186870575, -0.14309494197368622]\n",
      "2400 steps | score: [0.12168026715517044, -0.12003156542778015]\n",
      "2500 steps | score: [0.17187821865081787, -0.2150726318359375]\n",
      "2600 steps | score: [0.20149226486682892, -0.29194706678390503]\n",
      "unknown params:  tensor([ 0.1138,  0.2387,  0.5754, -0.6448,  0.4770,  0.3543])\n",
      "gt params:  tensor([ 0.1182,  0.2373,  0.6038, -0.6485,  0.4907,  0.5074])\n",
      "ols params:  tensor([ 0.0574,  0.1188,  0.2821, -0.3114,  0.2338,  3.9054])\n",
      "unknown mse:  tensor(0.0041)\n",
      "ols mse:  tensor(1.9747)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/77eff45d-5b81-446d-b76c-61e7b93f220b\n",
      "gt params:  tensor([-0.7269,  0.3035, -0.1797,  0.4703,  0.0096, -0.0656])\n",
      "0 steps | score: [0.024594910442829132]\n",
      "100 steps | score: [-0.15781109035015106]\n",
      "200 steps | score: [-0.05560925230383873]\n",
      "300 steps | score: [-0.18263238668441772]\n",
      "400 steps | score: [-0.08752565085887909]\n",
      "500 steps | score: [-0.10205688327550888]\n",
      "600 steps | score: [-0.10398480296134949]\n",
      "700 steps | score: [-0.17490744590759277]\n",
      "800 steps | score: [-0.1627100259065628]\n",
      "900 steps | score: [-0.11537100374698639]\n",
      "1000 steps | score: [-0.14839410781860352]\n",
      "1100 steps | score: [-0.12175735086202621]\n",
      "1200 steps | score: [-0.15277348458766937]\n",
      "1300 steps | score: [-0.1389201283454895]\n",
      "1400 steps | score: [-0.13897988200187683]\n",
      "1500 steps | score: [-0.13755331933498383]\n",
      "1600 steps | score: [-0.09995461255311966]\n",
      "1700 steps | score: [-0.18510845303535461]\n",
      "1800 steps | score: [-0.154395192861557]\n",
      "1900 steps | score: [-0.10244641453027725]\n",
      "2000 steps | score: [-0.13546398282051086]\n",
      "2100 steps | score: [-0.15083423256874084]\n",
      "2200 steps | score: [-0.14440754055976868]\n",
      "2300 steps | score: [-0.15078504383563995]\n",
      "2400 steps | score: [-0.1172817200422287]\n",
      "2500 steps | score: [-0.10732380300760269]\n",
      "2600 steps | score: [-0.11048507690429688]\n",
      "2700 steps | score: [-0.16904692351818085]\n",
      "2800 steps | score: [-0.10824368894100189]\n",
      "2900 steps | score: [-0.13887128233909607]\n",
      "0 steps | score: [-0.10323242843151093, 0.3861410915851593]\n",
      "100 steps | score: [-0.5976238250732422, 1.8157310485839844]\n",
      "200 steps | score: [-0.19219212234020233, 0.40204373002052307]\n",
      "300 steps | score: [-0.2681087255477905, 0.7518211007118225]\n",
      "400 steps | score: [-0.06001820042729378, -0.18269217014312744]\n",
      "500 steps | score: [-0.20288944244384766, 0.28751063346862793]\n",
      "600 steps | score: [-0.26380443572998047, 0.610978364944458]\n",
      "700 steps | score: [-0.368791788816452, 0.958699107170105]\n",
      "800 steps | score: [-0.002630162052810192, -0.3962862193584442]\n",
      "900 steps | score: [-0.13248981535434723, 0.09030704200267792]\n",
      "1000 steps | score: [-0.4514082670211792, 1.240687370300293]\n",
      "1100 steps | score: [-0.4571040868759155, 1.269159197807312]\n",
      "1200 steps | score: [-0.3865847885608673, 0.9969687461853027]\n",
      "1300 steps | score: [-0.22114920616149902, 0.3618556261062622]\n",
      "1400 steps | score: [-0.2569076418876648, 0.5370599031448364]\n",
      "1500 steps | score: [-0.36773592233657837, 0.9072288870811462]\n",
      "1600 steps | score: [-0.40009263157844543, 1.0490734577178955]\n",
      "1700 steps | score: [-0.35637277364730835, 0.8701646327972412]\n",
      "1800 steps | score: [-0.20598435401916504, 0.3844243288040161]\n",
      "1900 steps | score: [-0.19174082577228546, 0.24538201093673706]\n",
      "2000 steps | score: [-0.3016413152217865, 0.6922625303268433]\n",
      "2100 steps | score: [-0.30754217505455017, 0.7049041986465454]\n",
      "2200 steps | score: [-0.3345951437950134, 0.8019446730613708]\n",
      "2300 steps | score: [-0.2086411714553833, 0.42473214864730835]\n",
      "2400 steps | score: [-0.10050530731678009, -0.1270071268081665]\n",
      "2500 steps | score: [-0.11179129034280777, -0.10812623798847198]\n",
      "2600 steps | score: [-0.25736087560653687, 0.5317279696464539]\n",
      "2700 steps | score: [-0.3463999629020691, 0.8728228211402893]\n",
      "2800 steps | score: [-0.15704163908958435, 0.18757808208465576]\n",
      "2900 steps | score: [-0.2840633690357208, 0.5568734407424927]\n",
      "unknown params:  tensor([-0.7195,  0.3047, -0.1786,  0.4623,  0.0032, -0.0517])\n",
      "gt params:  tensor([-0.7269,  0.3035, -0.1797,  0.4703,  0.0096, -0.0656])\n",
      "ols params:  tensor([-0.5818,  0.2524, -0.1483,  0.3860,  0.0057,  0.5946])\n",
      "unknown mse:  tensor(5.9303e-05)\n",
      "ols mse:  tensor(0.0779)\n",
      "gt params:  tensor([-0.7230,  0.2955, -0.1811,  0.4681,  0.0058, -0.0670])\n",
      "0 steps | score: [0.2259281873703003]\n",
      "100 steps | score: [0.05520818755030632]\n",
      "200 steps | score: [0.020615480840206146]\n",
      "300 steps | score: [0.002248026430606842]\n",
      "0 steps | score: [0.077321358025074, 0.05952140688896179]\n",
      "100 steps | score: [-0.15242783725261688, 0.499726802110672]\n",
      "200 steps | score: [-0.13631486892700195, 0.3180013597011566]\n",
      "300 steps | score: [-0.21589283645153046, 0.5485520958900452]\n",
      "400 steps | score: [-0.13675783574581146, 0.35390785336494446]\n",
      "500 steps | score: [-0.16336438059806824, 0.46743136644363403]\n",
      "600 steps | score: [0.023422004655003548, -0.1520615667104721]\n",
      "700 steps | score: [0.3158499002456665, -1.288917064666748]\n",
      "800 steps | score: [-0.1057538315653801, 0.17750480771064758]\n",
      "900 steps | score: [-0.05790112912654877, 0.09722307324409485]\n",
      "1000 steps | score: [-0.001112009515054524, -0.06470523774623871]\n",
      "1100 steps | score: [-0.22411254048347473, 0.5921500325202942]\n",
      "1200 steps | score: [-0.09860678762197495, 0.18609756231307983]\n",
      "1300 steps | score: [-0.07051992416381836, 0.062264472246170044]\n",
      "1400 steps | score: [-0.04984008148312569, 0.03784322738647461]\n",
      "1500 steps | score: [-0.18762268126010895, 0.47520530223846436]\n",
      "1600 steps | score: [-0.1362636238336563, 0.347887247800827]\n",
      "1700 steps | score: [-0.022688308730721474, -0.06318627297878265]\n",
      "1800 steps | score: [-0.13985802233219147, 0.26830798387527466]\n",
      "1900 steps | score: [-0.06506171822547913, 0.0690336525440216]\n",
      "2000 steps | score: [-0.015921730548143387, -0.09295548498630524]\n",
      "2100 steps | score: [-0.03486289829015732, 0.014553844928741455]\n",
      "2200 steps | score: [-0.005543192382901907, -0.10749955475330353]\n",
      "2300 steps | score: [-0.04704683646559715, -0.023339390754699707]\n",
      "2400 steps | score: [-0.04441078379750252, -0.008051127195358276]\n",
      "2500 steps | score: [-0.06327259540557861, 0.03801348805427551]\n",
      "2600 steps | score: [-0.01352264080196619, -0.07626175880432129]\n",
      "2700 steps | score: [-0.0541435182094574, 0.021298974752426147]\n",
      "2800 steps | score: [0.06698041409254074, -0.3367499113082886]\n",
      "2900 steps | score: [0.010885095223784447, -0.17622287571430206]\n",
      "unknown params:  tensor([-0.6891,  0.2851, -0.1732,  0.4416,  0.0084, -0.0847])\n",
      "gt params:  tensor([-0.7230,  0.2955, -0.1811,  0.4681,  0.0058, -0.0670])\n",
      "ols params:  tensor([-0.4985,  0.2168, -0.1322,  0.3366,  0.0113,  1.0059])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(0.2046)\n",
      "gt params:  tensor([-7.2904e-01,  3.0243e-01, -1.7856e-01,  4.7187e-01,  3.0476e-04,\n",
      "        -9.5625e-02])\n",
      "0 steps | score: [0.13539741933345795]\n",
      "100 steps | score: [0.004834162071347237]\n",
      "0 steps | score: [0.13026009500026703, -0.327178418636322]\n",
      "100 steps | score: [0.12599703669548035, -0.5766504406929016]\n",
      "200 steps | score: [0.2119099646806717, -0.886132001876831]\n",
      "300 steps | score: [-0.011813264340162277, -0.22303305566310883]\n",
      "400 steps | score: [-0.21054105460643768, 0.23737478256225586]\n",
      "500 steps | score: [-0.11228393018245697, -0.05243631452322006]\n",
      "600 steps | score: [0.13813677430152893, -0.7154932022094727]\n",
      "700 steps | score: [-0.09088405966758728, -0.055162545293569565]\n",
      "800 steps | score: [-0.025434283539652824, -0.24895505607128143]\n",
      "900 steps | score: [-0.016323763877153397, -0.2291993796825409]\n",
      "1000 steps | score: [-0.29276129603385925, 0.3899003267288208]\n",
      "1100 steps | score: [-0.1505829095840454, 0.04645056650042534]\n",
      "1200 steps | score: [-0.11347310990095139, -0.028337553143501282]\n",
      "1300 steps | score: [-0.0504043810069561, -0.202008455991745]\n",
      "1400 steps | score: [-0.08631662279367447, -0.09056956321001053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 steps | score: [-0.02538689598441124, -0.24400568008422852]\n",
      "1600 steps | score: [-0.06794423609972, -0.1467166244983673]\n",
      "1700 steps | score: [-0.02356637269258499, -0.24127566814422607]\n",
      "1800 steps | score: [-0.04915023222565651, -0.19333823025226593]\n",
      "1900 steps | score: [-0.03087649494409561, -0.21238678693771362]\n",
      "2000 steps | score: [-0.02979940176010132, -0.2576460540294647]\n",
      "2100 steps | score: [-0.14073780179023743, 0.042526498436927795]\n",
      "2200 steps | score: [-0.06509797275066376, -0.13210688531398773]\n",
      "2300 steps | score: [-0.09016355872154236, -0.09604546427726746]\n",
      "2400 steps | score: [-0.03761798143386841, -0.22767142951488495]\n",
      "2500 steps | score: [-0.007807652000337839, -0.2750176191329956]\n",
      "2600 steps | score: [-0.10894779115915298, -0.0369827076792717]\n",
      "2700 steps | score: [-0.013421623967587948, -0.3137126564979553]\n",
      "2800 steps | score: [-0.10790134221315384, -0.07302892208099365]\n",
      "2900 steps | score: [-0.014293673448264599, -0.28959283232688904]\n",
      "unknown params:  tensor([-0.7626,  0.3145, -0.2031,  0.4751, -0.0182, -0.0773])\n",
      "gt params:  tensor([-7.2904e-01,  3.0243e-01, -1.7856e-01,  4.7187e-01,  3.0476e-04,\n",
      "        -9.5625e-02])\n",
      "ols params:  tensor([-0.4513,  0.1957, -0.1288,  0.2943, -0.0084,  1.3489])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(0.3682)\n",
      "gt params:  tensor([-0.7180,  0.2999, -0.1775,  0.4625,  0.0044, -0.0771])\n",
      "0 steps | score: [0.31516578793525696]\n",
      "100 steps | score: [0.0776558518409729]\n",
      "200 steps | score: [0.048500753939151764]\n",
      "300 steps | score: [0.1699240505695343]\n",
      "400 steps | score: [0.1338118016719818]\n",
      "500 steps | score: [0.1667102426290512]\n",
      "600 steps | score: [0.06535103917121887]\n",
      "700 steps | score: [0.019230345264077187]\n",
      "800 steps | score: [0.10892327129840851]\n",
      "900 steps | score: [0.10886804014444351]\n",
      "1000 steps | score: [0.14274686574935913]\n",
      "1100 steps | score: [0.06946446001529694]\n",
      "1200 steps | score: [0.02824319526553154]\n",
      "1300 steps | score: [0.09231041371822357]\n",
      "1400 steps | score: [0.10025346279144287]\n",
      "1500 steps | score: [0.1189642995595932]\n",
      "1600 steps | score: [0.07782510668039322]\n",
      "1700 steps | score: [0.040693674236536026]\n",
      "1800 steps | score: [0.09339450299739838]\n",
      "1900 steps | score: [0.08220136165618896]\n",
      "2000 steps | score: [0.11986717581748962]\n",
      "2100 steps | score: [0.0775577574968338]\n",
      "2200 steps | score: [0.05614176765084267]\n",
      "2300 steps | score: [0.0748824030160904]\n",
      "2400 steps | score: [0.11909746378660202]\n",
      "2500 steps | score: [0.0955522358417511]\n",
      "2600 steps | score: [0.08676889538764954]\n",
      "2700 steps | score: [0.0874677300453186]\n",
      "2800 steps | score: [0.08947993814945221]\n",
      "2900 steps | score: [0.09959065914154053]\n",
      "0 steps | score: [-0.06350753456354141, 0.331807404756546]\n",
      "100 steps | score: [-0.29642969369888306, 0.68616783618927]\n",
      "200 steps | score: [-0.012788564898073673, -0.0693393349647522]\n",
      "300 steps | score: [0.32150864601135254, -1.0846158266067505]\n",
      "400 steps | score: [-0.25622957944869995, 0.5193178653717041]\n",
      "500 steps | score: [-0.072246253490448, 0.06295697391033173]\n",
      "600 steps | score: [-0.19775910675525665, 0.33089679479599]\n",
      "700 steps | score: [-0.421680748462677, 0.8521538376808167]\n",
      "800 steps | score: [-0.2510374188423157, 0.45109573006629944]\n",
      "900 steps | score: [-0.3683999478816986, 0.7729532122612]\n",
      "1000 steps | score: [-0.2748457193374634, 0.5487922430038452]\n",
      "1100 steps | score: [-0.18212281167507172, 0.300606369972229]\n",
      "1200 steps | score: [-0.3358888626098633, 0.6727277040481567]\n",
      "1300 steps | score: [-0.26035767793655396, 0.46718570590019226]\n",
      "1400 steps | score: [-0.27786368131637573, 0.5336121916770935]\n",
      "1500 steps | score: [-0.22880475223064423, 0.4528404176235199]\n",
      "1600 steps | score: [-0.2678597569465637, 0.49737268686294556]\n",
      "1700 steps | score: [-0.3316260576248169, 0.6386670470237732]\n",
      "1800 steps | score: [-0.25325092673301697, 0.4772927761077881]\n",
      "1900 steps | score: [-0.28558871150016785, 0.5520716309547424]\n",
      "2000 steps | score: [-0.27253204584121704, 0.5451251864433289]\n",
      "2100 steps | score: [-0.2691985070705414, 0.51839280128479]\n",
      "2200 steps | score: [-0.29316461086273193, 0.5726503133773804]\n",
      "2300 steps | score: [-0.3399375081062317, 0.6623828411102295]\n",
      "2400 steps | score: [-0.23452138900756836, 0.45149368047714233]\n",
      "2500 steps | score: [-0.3050435185432434, 0.5822309255599976]\n",
      "2600 steps | score: [-0.28224483132362366, 0.5413581132888794]\n",
      "2700 steps | score: [-0.28308501839637756, 0.5301424264907837]\n",
      "2800 steps | score: [-0.26516953110694885, 0.5156222581863403]\n",
      "2900 steps | score: [-0.25236332416534424, 0.47018951177597046]\n",
      "unknown params:  tensor([-0.7359,  0.3100, -0.1648,  0.4741, -0.0032, -0.0223])\n",
      "gt params:  tensor([-0.7180,  0.2999, -0.1775,  0.4625,  0.0044, -0.0771])\n",
      "ols params:  tensor([-0.4105,  0.1801, -0.0973,  0.2761, -0.0029,  1.6005])\n",
      "unknown mse:  tensor(0.0006)\n",
      "ols mse:  tensor(0.4941)\n",
      "gt params:  tensor([-0.7333,  0.3028, -0.1676,  0.4665,  0.0043, -0.0336])\n",
      "0 steps | score: [0.19872862100601196]\n",
      "100 steps | score: [-0.12049566209316254]\n",
      "200 steps | score: [-0.1257489025592804]\n",
      "300 steps | score: [-0.019418859854340553]\n",
      "400 steps | score: [-0.0483546257019043]\n",
      "500 steps | score: [-0.014982560649514198]\n",
      "600 steps | score: [-0.08984461426734924]\n",
      "700 steps | score: [-0.05452379956841469]\n",
      "800 steps | score: [0.02090277150273323]\n",
      "900 steps | score: [-0.0596306286752224]\n",
      "1000 steps | score: [0.006527669262140989]\n",
      "0 steps | score: [0.21911174058914185, -0.12417511641979218]\n",
      "100 steps | score: [-0.0042127156630158424, 0.23094311356544495]\n",
      "200 steps | score: [-0.1739167869091034, 0.5611052513122559]\n",
      "300 steps | score: [0.11580050736665726, -0.08514673262834549]\n",
      "400 steps | score: [-0.10549664497375488, 0.3530922532081604]\n",
      "500 steps | score: [-0.00812787376344204, 0.17142044007778168]\n",
      "600 steps | score: [-0.0958070456981659, 0.3417336642742157]\n",
      "700 steps | score: [0.024927638471126556, 0.08546443283557892]\n",
      "800 steps | score: [-0.0008971430361270905, 0.13996291160583496]\n",
      "900 steps | score: [-0.02528482861816883, 0.16081023216247559]\n",
      "1000 steps | score: [0.08054652810096741, -0.08158739656209946]\n",
      "1100 steps | score: [-0.07729572802782059, 0.2915761470794678]\n",
      "1200 steps | score: [0.13020022213459015, -0.192740797996521]\n",
      "1300 steps | score: [-0.13800913095474243, 0.44248026609420776]\n",
      "1400 steps | score: [0.08071563392877579, -0.08303230255842209]\n",
      "1500 steps | score: [-0.04802613705396652, 0.24132145941257477]\n",
      "1600 steps | score: [0.34476491808891296, -0.7283768057823181]\n",
      "1700 steps | score: [0.14180012047290802, -0.20175616443157196]\n",
      "1800 steps | score: [0.0291740782558918, 0.06585993617773056]\n",
      "1900 steps | score: [0.03953252732753754, 0.03182230889797211]\n",
      "2000 steps | score: [0.017760535702109337, 0.07456578314304352]\n",
      "2100 steps | score: [0.0666886568069458, -0.052116528153419495]\n",
      "2200 steps | score: [0.006021338514983654, 0.11881209164857864]\n",
      "2300 steps | score: [0.01986871100962162, 0.07823335379362106]\n",
      "2400 steps | score: [0.006785338744521141, 0.12221991270780563]\n",
      "2500 steps | score: [0.006706635933369398, 0.0869736522436142]\n",
      "2600 steps | score: [0.07143557816743851, -0.028186775743961334]\n",
      "2700 steps | score: [0.15120145678520203, -0.23951968550682068]\n",
      "2800 steps | score: [-0.0034700469113886356, 0.12060095369815826]\n",
      "2900 steps | score: [0.0077735367231070995, 0.10855792462825775]\n",
      "unknown params:  tensor([-0.7427,  0.3326, -0.1811,  0.4911,  0.0067, -0.0249])\n",
      "gt params:  tensor([-0.7333,  0.3028, -0.1676,  0.4665,  0.0043, -0.0336])\n",
      "ols params:  tensor([-0.4039,  0.1913, -0.1058,  0.2806,  0.0072,  1.8331])\n",
      "unknown mse:  tensor(0.0003)\n",
      "ols mse:  tensor(0.6073)\n",
      "gt params:  tensor([-0.7230,  0.2972, -0.1732,  0.4596,  0.0102, -0.0845])\n",
      "0 steps | score: [0.1919218748807907]\n",
      "100 steps | score: [-0.02870161086320877]\n",
      "200 steps | score: [-0.08462117612361908]\n",
      "300 steps | score: [-0.05521529167890549]\n",
      "400 steps | score: [-0.023653030395507812]\n",
      "500 steps | score: [-0.0716719776391983]\n",
      "600 steps | score: [-0.05654852092266083]\n",
      "700 steps | score: [-0.0679447203874588]\n",
      "800 steps | score: [-0.09597841650247574]\n",
      "900 steps | score: [-0.05055154860019684]\n",
      "1000 steps | score: [-0.10816827416419983]\n",
      "1100 steps | score: [-0.07613405585289001]\n",
      "1200 steps | score: [-0.09877355396747589]\n",
      "1300 steps | score: [-0.12952259182929993]\n",
      "1400 steps | score: [-0.07216213643550873]\n",
      "1500 steps | score: [-0.07992567121982574]\n",
      "1600 steps | score: [-0.07781234383583069]\n",
      "1700 steps | score: [-0.07863211631774902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 steps | score: [-0.09029331058263779]\n",
      "1900 steps | score: [-0.06838302314281464]\n",
      "2000 steps | score: [-0.08433116972446442]\n",
      "2100 steps | score: [-0.08140057325363159]\n",
      "2200 steps | score: [-0.07252517342567444]\n",
      "2300 steps | score: [-0.12450949102640152]\n",
      "2400 steps | score: [-0.06879233568906784]\n",
      "2500 steps | score: [-0.10254546254873276]\n",
      "2600 steps | score: [-0.06679104268550873]\n",
      "2700 steps | score: [-0.07758090645074844]\n",
      "2800 steps | score: [-0.09126059710979462]\n",
      "2900 steps | score: [-0.07948026061058044]\n",
      "0 steps | score: [0.21905595064163208, -0.07483259588479996]\n",
      "100 steps | score: [0.059276118874549866, 0.1203714907169342]\n",
      "200 steps | score: [0.25371211767196655, -0.4539007842540741]\n",
      "300 steps | score: [0.5083847045898438, -1.228617787361145]\n",
      "400 steps | score: [0.5254474878311157, -1.3121823072433472]\n",
      "500 steps | score: [-0.13823729753494263, 0.4487819969654083]\n",
      "600 steps | score: [-0.044624414294958115, 0.28932708501815796]\n",
      "700 steps | score: [0.10899879783391953, -0.11396171152591705]\n",
      "800 steps | score: [-0.01478822436183691, 0.1736088991165161]\n",
      "900 steps | score: [0.14155612885951996, -0.21614496409893036]\n",
      "1000 steps | score: [-0.00679886294528842, 0.12953819334506989]\n",
      "1100 steps | score: [0.14411219954490662, -0.1989782452583313]\n",
      "1200 steps | score: [0.026894252747297287, 0.10177800059318542]\n",
      "1300 steps | score: [-0.015044116415083408, 0.16365906596183777]\n",
      "1400 steps | score: [0.06667572259902954, -0.02353052794933319]\n",
      "1500 steps | score: [0.05339458957314491, 0.0464794784784317]\n",
      "1600 steps | score: [0.05844716727733612, -0.008209273219108582]\n",
      "1700 steps | score: [0.13588674366474152, -0.21133726835250854]\n",
      "1800 steps | score: [-0.013634251430630684, 0.10911665111780167]\n",
      "1900 steps | score: [0.06312387436628342, -0.008979536592960358]\n",
      "2000 steps | score: [-0.03571157902479172, 0.23645003139972687]\n",
      "2100 steps | score: [0.13671043515205383, -0.21030321717262268]\n",
      "2200 steps | score: [0.12277820706367493, -0.15798896551132202]\n",
      "2300 steps | score: [0.0219340231269598, 0.08997891843318939]\n",
      "2400 steps | score: [0.12089777737855911, -0.16397088766098022]\n",
      "2500 steps | score: [0.0007697479450143874, 0.1432654857635498]\n",
      "2600 steps | score: [0.08177915960550308, -0.06599670648574829]\n",
      "2700 steps | score: [0.11634465306997299, -0.15929239988327026]\n",
      "2800 steps | score: [0.03538041561841965, 0.05811414495110512]\n",
      "2900 steps | score: [0.07448682188987732, -0.04011791571974754]\n",
      "unknown params:  tensor([-0.7464,  0.3323, -0.1671,  0.4620, -0.0111, -0.0610])\n",
      "gt params:  tensor([-0.7230,  0.2972, -0.1732,  0.4596,  0.0102, -0.0845])\n",
      "ols params:  tensor([-0.3729,  0.1768, -0.0907,  0.2396, -0.0056,  2.0194])\n",
      "unknown mse:  tensor(0.0005)\n",
      "ols mse:  tensor(0.7698)\n",
      "gt params:  tensor([-0.7206,  0.2970, -0.1978,  0.4519, -0.0053, -0.0609])\n",
      "0 steps | score: [0.27897119522094727]\n",
      "100 steps | score: [0.019764937460422516]\n",
      "200 steps | score: [0.08218730986118317]\n",
      "300 steps | score: [-5.4385513067245483e-05]\n",
      "0 steps | score: [0.2811167538166046, -0.4391944408416748]\n",
      "100 steps | score: [0.03760937228798866, -0.06529996544122696]\n",
      "200 steps | score: [0.2221290022134781, -0.5448218584060669]\n",
      "300 steps | score: [-0.060212232172489166, 0.06482478231191635]\n",
      "400 steps | score: [-0.11620300263166428, 0.17947597801685333]\n",
      "500 steps | score: [-0.04583713412284851, 0.022350355982780457]\n",
      "600 steps | score: [0.0686628594994545, -0.231155663728714]\n",
      "700 steps | score: [0.03835359588265419, -0.17496946454048157]\n",
      "800 steps | score: [0.19406484067440033, -0.5013930201530457]\n",
      "900 steps | score: [0.17153964936733246, -0.42886045575141907]\n",
      "1000 steps | score: [0.08742600679397583, -0.276189386844635]\n",
      "1100 steps | score: [-0.06276337802410126, 0.045730575919151306]\n",
      "1200 steps | score: [0.33992359042167664, -0.894642174243927]\n",
      "1300 steps | score: [0.07837460190057755, -0.2583395838737488]\n",
      "1400 steps | score: [0.06773952394723892, -0.2190956324338913]\n",
      "1500 steps | score: [0.05685189366340637, -0.20632854104042053]\n",
      "1600 steps | score: [-0.035418134182691574, -0.0022634416818618774]\n",
      "1700 steps | score: [0.17730458080768585, -0.493493914604187]\n",
      "1800 steps | score: [0.20731404423713684, -0.539786696434021]\n",
      "1900 steps | score: [0.15095996856689453, -0.4281483590602875]\n",
      "2000 steps | score: [0.0708928182721138, -0.2522541880607605]\n",
      "2100 steps | score: [-0.03286343067884445, -0.018926769495010376]\n",
      "2200 steps | score: [0.18085964024066925, -0.5157347917556763]\n",
      "2300 steps | score: [0.08317085355520248, -0.2644011080265045]\n",
      "2400 steps | score: [0.07614126801490784, -0.2582649886608124]\n",
      "2500 steps | score: [0.13066136837005615, -0.37894436717033386]\n",
      "2600 steps | score: [0.003057018853724003, -0.09793970733880997]\n",
      "2700 steps | score: [0.15223509073257446, -0.43117380142211914]\n",
      "2800 steps | score: [0.13850434124469757, -0.4062761664390564]\n",
      "2900 steps | score: [0.11213473975658417, -0.34773123264312744]\n",
      "unknown params:  tensor([-0.6514,  0.2749, -0.1864,  0.4562, -0.0175,  0.0280])\n",
      "gt params:  tensor([-0.7206,  0.2970, -0.1978,  0.4519, -0.0053, -0.0609])\n",
      "ols params:  tensor([-0.3328,  0.1497, -0.1003,  0.2394, -0.0077,  2.2230])\n",
      "unknown mse:  tensor(0.0022)\n",
      "ols mse:  tensor(0.9072)\n",
      "gt params:  tensor([-0.7418,  0.2949, -0.1834,  0.4574,  0.0241, -0.0509])\n",
      "0 steps | score: [0.2418106198310852]\n",
      "100 steps | score: [-0.05128981173038483]\n",
      "200 steps | score: [-0.08324198424816132]\n",
      "300 steps | score: [-0.07894885540008545]\n",
      "400 steps | score: [0.04749736934900284]\n",
      "500 steps | score: [0.030920878052711487]\n",
      "600 steps | score: [-0.017597950994968414]\n",
      "700 steps | score: [-0.07789928466081619]\n",
      "800 steps | score: [-0.06159844994544983]\n",
      "900 steps | score: [0.011317182332277298]\n",
      "1000 steps | score: [-0.007357470691204071]\n",
      "0 steps | score: [0.2916051149368286, -0.3876855969429016]\n",
      "100 steps | score: [0.20593419671058655, -0.35305601358413696]\n",
      "200 steps | score: [-0.023788554593920708, 0.06886197626590729]\n",
      "300 steps | score: [-0.15380604565143585, 0.3111344873905182]\n",
      "400 steps | score: [0.11188466846942902, -0.2464866042137146]\n",
      "500 steps | score: [0.7320657968521118, -1.9060842990875244]\n",
      "600 steps | score: [0.3840930461883545, -0.9020325541496277]\n",
      "700 steps | score: [0.0671953335404396, -0.1443563997745514]\n",
      "800 steps | score: [0.004624746274203062, -0.03088853694498539]\n",
      "900 steps | score: [0.13013321161270142, -0.2888373136520386]\n",
      "1000 steps | score: [0.15752047300338745, -0.3286247253417969]\n",
      "1100 steps | score: [-0.014802434481680393, 0.021623320877552032]\n",
      "1200 steps | score: [0.017358846962451935, -0.04915280267596245]\n",
      "1300 steps | score: [0.07113800942897797, -0.14961887896060944]\n",
      "1400 steps | score: [0.15442325174808502, -0.3440491557121277]\n",
      "1500 steps | score: [0.2186463624238968, -0.4943159222602844]\n",
      "1600 steps | score: [0.10943890362977982, -0.25781142711639404]\n",
      "1700 steps | score: [0.028770994395017624, -0.0679272711277008]\n",
      "1800 steps | score: [0.13237449526786804, -0.3309909999370575]\n",
      "1900 steps | score: [0.19795680046081543, -0.46588757634162903]\n",
      "2000 steps | score: [0.2728906571865082, -0.6488113403320312]\n",
      "2100 steps | score: [0.09205525368452072, -0.23815612494945526]\n",
      "2200 steps | score: [0.02517901547253132, -0.08831003308296204]\n",
      "2300 steps | score: [0.13115017116069794, -0.3035547137260437]\n",
      "2400 steps | score: [0.26706287264823914, -0.6335768103599548]\n",
      "2500 steps | score: [0.23602482676506042, -0.5366058349609375]\n",
      "2600 steps | score: [0.12594109773635864, -0.31876567006111145]\n",
      "2700 steps | score: [0.0858074277639389, -0.20608699321746826]\n",
      "2800 steps | score: [0.10997151583433151, -0.24521122872829437]\n",
      "2900 steps | score: [0.16667930781841278, -0.4256696105003357]\n",
      "unknown params:  tensor([-0.7678,  0.2828, -0.1817,  0.4281,  0.0375,  0.0008])\n",
      "gt params:  tensor([-0.7418,  0.2949, -0.1834,  0.4574,  0.0241, -0.0509])\n",
      "ols params:  tensor([-0.3690,  0.1489, -0.0964,  0.2171,  0.0177,  2.3734])\n",
      "unknown mse:  tensor(0.0008)\n",
      "ols mse:  tensor(1.0172)\n",
      "gt params:  tensor([-0.7279,  0.3079, -0.1662,  0.4579, -0.0017, -0.0841])\n",
      "0 steps | score: [0.32419654726982117]\n",
      "100 steps | score: [0.05799786373972893]\n",
      "200 steps | score: [0.03581717237830162]\n",
      "300 steps | score: [-0.011293858289718628]\n",
      "400 steps | score: [0.022891081869602203]\n",
      "500 steps | score: [0.0587652325630188]\n",
      "600 steps | score: [0.04168058931827545]\n",
      "700 steps | score: [0.06223123520612717]\n",
      "800 steps | score: [0.030089497566223145]\n",
      "900 steps | score: [0.0049386657774448395]\n",
      "0 steps | score: [0.17244422435760498, -0.040634747594594955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [0.15167243778705597, -0.1847778707742691]\n",
      "200 steps | score: [-0.014875867404043674, 0.17174957692623138]\n",
      "300 steps | score: [-0.12761220335960388, 0.3472115695476532]\n",
      "400 steps | score: [-0.08618440479040146, 0.2603558599948883]\n",
      "500 steps | score: [0.2130986899137497, -0.38123929500579834]\n",
      "600 steps | score: [-0.21974091231822968, 0.5276752710342407]\n",
      "700 steps | score: [0.13260555267333984, -0.20114877820014954]\n",
      "800 steps | score: [0.008767747320234776, 0.03812490031123161]\n",
      "900 steps | score: [-0.08941628783941269, 0.29247692227363586]\n",
      "1000 steps | score: [0.09250947088003159, -0.107098788022995]\n",
      "1100 steps | score: [-0.1737583875656128, 0.43111127614974976]\n",
      "1200 steps | score: [0.07994590699672699, -0.13183806836605072]\n",
      "1300 steps | score: [0.1199849396944046, -0.19245542585849762]\n",
      "1400 steps | score: [-0.040515899658203125, 0.1614505797624588]\n",
      "1500 steps | score: [0.08272704482078552, -0.12206120043992996]\n",
      "1600 steps | score: [-0.10384277254343033, 0.2875981628894806]\n",
      "1700 steps | score: [0.06215206906199455, -0.06291436403989792]\n",
      "1800 steps | score: [-0.021602286025881767, 0.12502403557300568]\n",
      "1900 steps | score: [0.06458966434001923, -0.046721186488866806]\n",
      "2000 steps | score: [0.009505853988230228, 0.08962809294462204]\n",
      "2100 steps | score: [-0.06495106965303421, 0.21400807797908783]\n",
      "2200 steps | score: [-0.06078625097870827, 0.20077985525131226]\n",
      "2300 steps | score: [-0.04024811461567879, 0.13386674225330353]\n",
      "2400 steps | score: [0.004123195074498653, 0.05193734169006348]\n",
      "2500 steps | score: [0.03341561183333397, -0.010005220770835876]\n",
      "2600 steps | score: [-0.0160575769841671, 0.09838622063398361]\n",
      "2700 steps | score: [-0.02559114247560501, 0.1271888166666031]\n",
      "2800 steps | score: [9.681735537014902e-05, 0.045811694115400314]\n",
      "2900 steps | score: [-0.007873629219830036, 0.06920129060745239]\n",
      "unknown params:  tensor([-0.6890,  0.3519, -0.1671,  0.4757, -0.0131, -0.0181])\n",
      "gt params:  tensor([-0.7279,  0.3079, -0.1662,  0.4579, -0.0017, -0.0841])\n",
      "ols params:  tensor([-0.3344,  0.1775, -0.0847,  0.2361, -0.0058,  2.4554])\n",
      "unknown mse:  tensor(0.0014)\n",
      "ols mse:  tensor(1.1128)\n",
      "gt params:  tensor([-0.7431,  0.2917, -0.1643,  0.4704, -0.0022, -0.0211])\n",
      "0 steps | score: [0.21827690303325653]\n",
      "100 steps | score: [-0.08699716627597809]\n",
      "200 steps | score: [-0.03147490695118904]\n",
      "300 steps | score: [-0.08741125464439392]\n",
      "400 steps | score: [-0.07049255073070526]\n",
      "500 steps | score: [-0.0855737179517746]\n",
      "600 steps | score: [-0.07586342096328735]\n",
      "700 steps | score: [-0.042073458433151245]\n",
      "800 steps | score: [-0.10196889936923981]\n",
      "900 steps | score: [-0.09325376898050308]\n",
      "1000 steps | score: [-0.08984851092100143]\n",
      "1100 steps | score: [-0.06694413721561432]\n",
      "1200 steps | score: [-0.09170657396316528]\n",
      "1300 steps | score: [-0.08571258932352066]\n",
      "1400 steps | score: [-0.08461149036884308]\n",
      "1500 steps | score: [-0.08165990561246872]\n",
      "1600 steps | score: [-0.06548016518354416]\n",
      "1700 steps | score: [-0.07672645896673203]\n",
      "1800 steps | score: [-0.1075824573636055]\n",
      "1900 steps | score: [-0.07648446410894394]\n",
      "2000 steps | score: [-0.06924810260534286]\n",
      "2100 steps | score: [-0.0785687044262886]\n",
      "2200 steps | score: [-0.09412824362516403]\n",
      "2300 steps | score: [-0.089255191385746]\n",
      "2400 steps | score: [-0.0673706904053688]\n",
      "2500 steps | score: [-0.08551003783941269]\n",
      "2600 steps | score: [-0.067711740732193]\n",
      "2700 steps | score: [-0.08285792917013168]\n",
      "2800 steps | score: [-0.07959297299385071]\n",
      "2900 steps | score: [-0.05021757632493973]\n",
      "0 steps | score: [0.013718429021537304, 0.25845637917518616]\n",
      "100 steps | score: [-0.28236332535743713, 0.723323404788971]\n",
      "200 steps | score: [0.4377673864364624, -1.163041114807129]\n",
      "300 steps | score: [-0.2543084919452667, 0.6174848079681396]\n",
      "400 steps | score: [-0.23791839182376862, 0.5205890536308289]\n",
      "500 steps | score: [-0.2472684681415558, 0.5851880311965942]\n",
      "600 steps | score: [-0.0583522766828537, 0.1462157666683197]\n",
      "700 steps | score: [-0.18409191071987152, 0.4466894567012787]\n",
      "800 steps | score: [-0.19513918459415436, 0.46814021468162537]\n",
      "900 steps | score: [-0.3016848564147949, 0.6794315576553345]\n",
      "1000 steps | score: [-0.16796280443668365, 0.39489197731018066]\n",
      "1100 steps | score: [0.03796043246984482, -0.12776359915733337]\n",
      "1200 steps | score: [-0.15700910985469818, 0.3636797070503235]\n",
      "1300 steps | score: [-0.0665184035897255, 0.13321897387504578]\n",
      "1400 steps | score: [-0.23846694827079773, 0.5168896317481995]\n",
      "1500 steps | score: [-0.14497752487659454, 0.32071900367736816]\n",
      "1600 steps | score: [-0.12301266938447952, 0.2774297297000885]\n",
      "1700 steps | score: [-0.14091020822525024, 0.34065166115760803]\n",
      "1800 steps | score: [-0.18811121582984924, 0.41416794061660767]\n",
      "1900 steps | score: [-0.07172828167676926, 0.12756553292274475]\n",
      "2000 steps | score: [-0.19586855173110962, 0.4566001296043396]\n",
      "2100 steps | score: [-0.019817668944597244, -0.020485185086727142]\n",
      "2200 steps | score: [-0.14721515774726868, 0.32597196102142334]\n",
      "2300 steps | score: [-0.15301044285297394, 0.3348813056945801]\n",
      "2400 steps | score: [-0.08450877666473389, 0.20087359845638275]\n",
      "2500 steps | score: [-0.20771640539169312, 0.41942304372787476]\n",
      "2600 steps | score: [-0.10325927287340164, 0.20876415073871613]\n",
      "2700 steps | score: [-0.10702399909496307, 0.2253391593694687]\n",
      "2800 steps | score: [-0.12916384637355804, 0.2910264730453491]\n",
      "2900 steps | score: [-0.08195210248231888, 0.15990227460861206]\n",
      "unknown params:  tensor([-0.7513,  0.3296, -0.1634,  0.4880, -0.0269, -0.0434])\n",
      "gt params:  tensor([-0.7431,  0.2917, -0.1643,  0.4704, -0.0022, -0.0211])\n",
      "ols params:  tensor([-0.3524,  0.1619, -0.0800,  0.2399, -0.0108,  2.5919])\n",
      "unknown mse:  tensor(0.0005)\n",
      "ols mse:  tensor(1.1762)\n",
      "gt params:  tensor([-0.7402,  0.2952, -0.1760,  0.4612, -0.0071, -0.0815])\n",
      "0 steps | score: [0.3163296580314636]\n",
      "100 steps | score: [0.04538364335894585]\n",
      "200 steps | score: [0.05273193120956421]\n",
      "300 steps | score: [0.04428480565547943]\n",
      "400 steps | score: [0.008137045428156853]\n",
      "0 steps | score: [0.12154413014650345, 0.16494348645210266]\n",
      "100 steps | score: [-0.0747145339846611, 0.442990779876709]\n",
      "200 steps | score: [0.013039302080869675, 0.174742192029953]\n",
      "300 steps | score: [-0.129116028547287, 0.4320576786994934]\n",
      "400 steps | score: [-0.04041934385895729, 0.24405862390995026]\n",
      "500 steps | score: [-0.14118744432926178, 0.48613306879997253]\n",
      "600 steps | score: [-0.19316577911376953, 0.5859379768371582]\n",
      "700 steps | score: [-0.12337843328714371, 0.47306933999061584]\n",
      "800 steps | score: [-0.07076934725046158, 0.3037692606449127]\n",
      "900 steps | score: [-0.19573771953582764, 0.5825073719024658]\n",
      "1000 steps | score: [-0.03192121535539627, 0.2192031890153885]\n",
      "1100 steps | score: [-0.12385343015193939, 0.43989524245262146]\n",
      "1200 steps | score: [-0.08617578446865082, 0.33942025899887085]\n",
      "1300 steps | score: [-0.08973817527294159, 0.38195526599884033]\n",
      "1400 steps | score: [0.12502364814281464, -0.10807721316814423]\n",
      "1500 steps | score: [-0.051059287041425705, 0.2566223740577698]\n",
      "1600 steps | score: [-0.012854897417128086, 0.2010936141014099]\n",
      "1700 steps | score: [-0.10242097824811935, 0.3985833525657654]\n",
      "1800 steps | score: [0.07793179899454117, -0.025974944233894348]\n",
      "1900 steps | score: [-0.10130925476551056, 0.3911358118057251]\n",
      "2000 steps | score: [-0.006837972905486822, 0.16891154646873474]\n",
      "2100 steps | score: [-0.10030076652765274, 0.36560750007629395]\n",
      "2200 steps | score: [-0.029210591688752174, 0.20459888875484467]\n",
      "2300 steps | score: [-0.011699696071445942, 0.20103412866592407]\n",
      "2400 steps | score: [-0.11941451579332352, 0.40136322379112244]\n",
      "2500 steps | score: [-0.06085694581270218, 0.2926437258720398]\n",
      "2600 steps | score: [-0.057270899415016174, 0.29468563199043274]\n",
      "2700 steps | score: [-0.03095531277358532, 0.2322046160697937]\n",
      "2800 steps | score: [-0.049411095678806305, 0.2505108118057251]\n",
      "2900 steps | score: [-0.08713997155427933, 0.32475486397743225]\n",
      "unknown params:  tensor([-0.8046,  0.3702, -0.2055,  0.4737, -0.0185, -0.0854])\n",
      "gt params:  tensor([-0.7402,  0.2952, -0.1760,  0.4612, -0.0071, -0.0815])\n",
      "ols params:  tensor([-0.3417,  0.1669, -0.0936,  0.2129, -0.0101,  2.7233])\n",
      "unknown mse:  tensor(0.0018)\n",
      "ols mse:  tensor(1.3517)\n",
      "gt params:  tensor([-0.7316,  0.2909, -0.1899,  0.4589, -0.0042, -0.0799])\n",
      "0 steps | score: [0.3198517858982086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [-0.01127314567565918]\n",
      "200 steps | score: [0.04253321513533592]\n",
      "300 steps | score: [-0.011922918260097504]\n",
      "400 steps | score: [-0.030426282435655594]\n",
      "500 steps | score: [-0.040146030485630035]\n",
      "600 steps | score: [0.0019949637353420258]\n",
      "0 steps | score: [0.18089941143989563, -0.08161485195159912]\n",
      "100 steps | score: [0.18352283537387848, -0.23123610019683838]\n",
      "200 steps | score: [-0.02515590935945511, 0.1523040533065796]\n",
      "300 steps | score: [0.12683123350143433, -0.24515420198440552]\n",
      "400 steps | score: [0.006934851408004761, 0.05588802695274353]\n",
      "500 steps | score: [-0.15364570915699005, 0.41805732250213623]\n",
      "600 steps | score: [0.03062383085489273, -0.00978212058544159]\n",
      "700 steps | score: [-0.03086845390498638, 0.11437022686004639]\n",
      "800 steps | score: [-0.05962607264518738, 0.16432426869869232]\n",
      "900 steps | score: [0.142633318901062, -0.2635537087917328]\n",
      "1000 steps | score: [0.1446709930896759, -0.2566969692707062]\n",
      "1100 steps | score: [0.014665207825601101, 0.012120798230171204]\n",
      "1200 steps | score: [-0.06227470561861992, 0.17612671852111816]\n",
      "1300 steps | score: [0.02525591105222702, -0.006398990750312805]\n",
      "1400 steps | score: [0.06871641427278519, -0.08485372364521027]\n",
      "1500 steps | score: [0.1001386046409607, -0.17366135120391846]\n",
      "1600 steps | score: [0.13684020936489105, -0.27766966819763184]\n",
      "1700 steps | score: [0.0063505168072879314, 0.01723291724920273]\n",
      "1800 steps | score: [-0.09760640561580658, 0.25738242268562317]\n",
      "1900 steps | score: [0.12590865790843964, -0.22310349345207214]\n",
      "2000 steps | score: [0.06445403397083282, -0.08019968867301941]\n",
      "2100 steps | score: [0.04359407350420952, -0.04720362275838852]\n",
      "2200 steps | score: [0.11856923997402191, -0.23269525170326233]\n",
      "2300 steps | score: [-0.004678109660744667, 0.06681016087532043]\n",
      "2400 steps | score: [0.04000023379921913, -0.0525098517537117]\n",
      "2500 steps | score: [0.03156876936554909, -0.021136701107025146]\n",
      "2600 steps | score: [0.030575940385460854, -0.04435671865940094]\n",
      "2700 steps | score: [0.050077881664037704, -0.06961176544427872]\n",
      "2800 steps | score: [0.008948883973062038, 0.0176825150847435]\n",
      "2900 steps | score: [0.04209204018115997, -0.07088153064250946]\n",
      "unknown params:  tensor([-0.7114,  0.2946, -0.2120,  0.4232, -0.0327,  0.1441])\n",
      "gt params:  tensor([-0.7316,  0.2909, -0.1899,  0.4589, -0.0042, -0.0799])\n",
      "ols params:  tensor([-0.3132,  0.1331, -0.0971,  0.1933, -0.0138,  2.8932])\n",
      "unknown mse:  tensor(0.0089)\n",
      "ols mse:  tensor(1.5198)\n",
      "gt params:  tensor([-0.7430,  0.3033, -0.1761,  0.4499, -0.0048, -0.0403])\n",
      "0 steps | score: [0.21376948058605194]\n",
      "100 steps | score: [-0.06862694770097733]\n",
      "200 steps | score: [-0.11732377111911774]\n",
      "300 steps | score: [-0.1338571161031723]\n",
      "400 steps | score: [-0.09453276544809341]\n",
      "500 steps | score: [-0.1342652142047882]\n",
      "600 steps | score: [-0.08783693611621857]\n",
      "700 steps | score: [-0.10484534502029419]\n",
      "800 steps | score: [-0.12561911344528198]\n",
      "900 steps | score: [-0.11708833277225494]\n",
      "1000 steps | score: [-0.14370205998420715]\n",
      "1100 steps | score: [-0.08996725082397461]\n",
      "1200 steps | score: [-0.10646919906139374]\n",
      "1300 steps | score: [-0.11055853962898254]\n",
      "1400 steps | score: [-0.11572898924350739]\n",
      "1500 steps | score: [-0.13830803334712982]\n",
      "1600 steps | score: [-0.08900274336338043]\n",
      "1700 steps | score: [-0.10019153356552124]\n",
      "1800 steps | score: [-0.07839485257863998]\n",
      "1900 steps | score: [-0.11592449247837067]\n",
      "2000 steps | score: [-0.1239660307765007]\n",
      "2100 steps | score: [-0.10892526805400848]\n",
      "2200 steps | score: [-0.11087672412395477]\n",
      "2300 steps | score: [-0.09921357035636902]\n",
      "2400 steps | score: [-0.09573119878768921]\n",
      "2500 steps | score: [-0.11967796087265015]\n",
      "2600 steps | score: [-0.09507586061954498]\n",
      "2700 steps | score: [-0.10147824883460999]\n",
      "2800 steps | score: [-0.08821900188922882]\n",
      "2900 steps | score: [-0.11479641497135162]\n",
      "0 steps | score: [0.15601105988025665, 0.07995021343231201]\n",
      "100 steps | score: [0.2479424625635147, -0.26600778102874756]\n",
      "200 steps | score: [-0.2126566618680954, 0.6236024498939514]\n",
      "300 steps | score: [-0.23823752999305725, 0.6491233706474304]\n",
      "400 steps | score: [-0.187139093875885, 0.5447181463241577]\n",
      "500 steps | score: [0.04774748906493187, 0.034226492047309875]\n",
      "600 steps | score: [0.11448918282985687, -0.1271568238735199]\n",
      "700 steps | score: [-0.18974092602729797, 0.5488336086273193]\n",
      "800 steps | score: [-0.07416681200265884, 0.28924286365509033]\n",
      "900 steps | score: [-0.1312185376882553, 0.3939007520675659]\n",
      "1000 steps | score: [-0.13012266159057617, 0.4208003282546997]\n",
      "1100 steps | score: [0.27740126848220825, -0.5204148292541504]\n",
      "1200 steps | score: [-0.17870266735553741, 0.49697428941726685]\n",
      "1300 steps | score: [0.035038501024246216, 0.05802077800035477]\n",
      "1400 steps | score: [-0.127329021692276, 0.3743903934955597]\n",
      "1500 steps | score: [-0.0776829645037651, 0.30242305994033813]\n",
      "1600 steps | score: [0.11505189538002014, -0.12803152203559875]\n",
      "1700 steps | score: [-0.16681519150733948, 0.4876711666584015]\n",
      "1800 steps | score: [0.0691256895661354, -0.04776217043399811]\n",
      "1900 steps | score: [-0.151290625333786, 0.4534762501716614]\n",
      "2000 steps | score: [-0.06587102264165878, 0.2927483916282654]\n",
      "2100 steps | score: [0.1021558865904808, -0.1128002256155014]\n",
      "2200 steps | score: [-0.05059067904949188, 0.2532682418823242]\n",
      "2300 steps | score: [0.09317899495363235, -0.0836249589920044]\n",
      "2400 steps | score: [-0.04483510181307793, 0.20710162818431854]\n",
      "2500 steps | score: [-0.11976851522922516, 0.37815535068511963]\n",
      "2600 steps | score: [0.017796562984585762, 0.07481002807617188]\n",
      "2700 steps | score: [-0.06690283864736557, 0.26771774888038635]\n",
      "2800 steps | score: [0.06335583329200745, -0.02060021087527275]\n",
      "2900 steps | score: [-0.05503839999437332, 0.2569849491119385]\n",
      "unknown params:  tensor([-0.7448,  0.2915, -0.1504,  0.4388,  0.0019, -0.1164])\n",
      "gt params:  tensor([-0.7430,  0.3033, -0.1761,  0.4499, -0.0048, -0.0403])\n",
      "ols params:  tensor([-3.3060e-01,  1.3614e-01, -7.2594e-02,  2.0492e-01,  1.5423e-03,\n",
      "         2.9423e+00])\n",
      "unknown mse:  tensor(0.0011)\n",
      "ols mse:  tensor(1.5274)\n",
      "gt params:  tensor([-0.7353,  0.3046, -0.1640,  0.4710,  0.0124, -0.1190])\n",
      "0 steps | score: [0.2594909369945526]\n",
      "100 steps | score: [-0.10594502091407776]\n",
      "200 steps | score: [0.001504547894001007]\n",
      "0 steps | score: [0.19883513450622559, -0.14753291010856628]\n",
      "100 steps | score: [-0.17224420607089996, 0.45287081599235535]\n",
      "200 steps | score: [0.5394705533981323, -1.2312238216400146]\n",
      "300 steps | score: [-0.053157202899456024, 0.11379460990428925]\n",
      "400 steps | score: [0.3496714234352112, -0.8913407325744629]\n",
      "500 steps | score: [-0.11750031262636185, 0.2696763277053833]\n",
      "600 steps | score: [0.1640690565109253, -0.3601658344268799]\n",
      "700 steps | score: [-0.04953011870384216, 0.12243723124265671]\n",
      "800 steps | score: [0.10076063871383667, -0.24024561047554016]\n",
      "900 steps | score: [0.14854170382022858, -0.3241872787475586]\n",
      "1000 steps | score: [-0.07063432037830353, 0.15775041282176971]\n",
      "1100 steps | score: [-0.04493590071797371, 0.11047264188528061]\n",
      "1200 steps | score: [0.016834119334816933, -0.027181759476661682]\n",
      "1300 steps | score: [0.12145724147558212, -0.2839418351650238]\n",
      "1400 steps | score: [0.01188037358224392, -0.03308486193418503]\n",
      "1500 steps | score: [-0.03696946054697037, 0.08796826750040054]\n",
      "1600 steps | score: [0.07326529175043106, -0.20857277512550354]\n",
      "1700 steps | score: [0.04855852946639061, -0.10100289434194565]\n",
      "1800 steps | score: [0.025744806975126266, -0.07844553887844086]\n",
      "1900 steps | score: [0.030819138512015343, -0.07721717655658722]\n",
      "2000 steps | score: [0.030595529824495316, -0.09759584814310074]\n",
      "2100 steps | score: [0.14203260838985443, -0.34638917446136475]\n",
      "2200 steps | score: [0.010755715891718864, -0.016331546008586884]\n",
      "2300 steps | score: [0.06009063497185707, -0.1472695767879486]\n",
      "2400 steps | score: [0.09973511099815369, -0.2500356435775757]\n",
      "2500 steps | score: [0.034725889563560486, -0.07395967096090317]\n",
      "2600 steps | score: [0.10804848372936249, -0.2548661530017853]\n",
      "2700 steps | score: [0.03254730626940727, -0.1267203986644745]\n",
      "2800 steps | score: [0.061923567205667496, -0.13267025351524353]\n",
      "2900 steps | score: [0.0899210274219513, -0.2059243619441986]\n",
      "unknown params:  tensor([-0.8032,  0.3239, -0.1845,  0.5252,  0.0207, -0.0934])\n",
      "gt params:  tensor([-0.7353,  0.3046, -0.1640,  0.4710,  0.0124, -0.1190])\n",
      "ols params:  tensor([-0.3291,  0.1419, -0.0786,  0.2221,  0.0094,  3.0353])\n",
      "unknown mse:  tensor(0.0015)\n",
      "ols mse:  tensor(1.7016)\n",
      "gt params:  tensor([-7.3884e-01,  2.8849e-01, -1.5268e-01,  4.5272e-01, -6.8404e-04,\n",
      "        -9.0776e-02])\n",
      "0 steps | score: [0.3518359661102295]\n",
      "100 steps | score: [0.09562563896179199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [0.032978594303131104]\n",
      "300 steps | score: [0.057438917458057404]\n",
      "400 steps | score: [0.01178516075015068]\n",
      "500 steps | score: [0.009326387196779251]\n",
      "0 steps | score: [0.3238999843597412, -0.500566840171814]\n",
      "100 steps | score: [0.19374863803386688, -0.3491165041923523]\n",
      "200 steps | score: [0.36609846353530884, -0.8325767517089844]\n",
      "300 steps | score: [0.3453224301338196, -0.859563946723938]\n",
      "400 steps | score: [0.050264667719602585, -0.16267484426498413]\n",
      "500 steps | score: [0.0017834523459896445, -0.07470422983169556]\n",
      "600 steps | score: [0.051842182874679565, -0.15212436020374298]\n",
      "700 steps | score: [0.06063031032681465, -0.2234744429588318]\n",
      "800 steps | score: [0.17288616299629211, -0.46494078636169434]\n",
      "900 steps | score: [0.17509211599826813, -0.4500279724597931]\n",
      "1000 steps | score: [0.03991706669330597, -0.1682249903678894]\n",
      "1100 steps | score: [0.020546743646264076, -0.12828928232192993]\n",
      "1200 steps | score: [0.11790734529495239, -0.3332677483558655]\n",
      "1300 steps | score: [0.09636640548706055, -0.2762836515903473]\n",
      "1400 steps | score: [0.06070719286799431, -0.20955747365951538]\n",
      "1500 steps | score: [0.14349012076854706, -0.3748355805873871]\n",
      "1600 steps | score: [0.03196518495678902, -0.12605232000350952]\n",
      "1700 steps | score: [0.22492411732673645, -0.5901428461074829]\n",
      "1800 steps | score: [0.09302133321762085, -0.270294189453125]\n",
      "1900 steps | score: [0.20587337017059326, -0.5162845849990845]\n",
      "2000 steps | score: [0.09861207753419876, -0.28088656067848206]\n",
      "2100 steps | score: [0.044520266354084015, -0.1597924828529358]\n",
      "2200 steps | score: [0.1909622699022293, -0.4814811050891876]\n",
      "2300 steps | score: [0.1720333695411682, -0.46344509720802307]\n",
      "2400 steps | score: [0.2555040717124939, -0.6361903548240662]\n",
      "2500 steps | score: [0.1493413746356964, -0.38447004556655884]\n",
      "2600 steps | score: [0.11016502231359482, -0.3290494680404663]\n",
      "2700 steps | score: [0.18687358498573303, -0.49080216884613037]\n",
      "2800 steps | score: [0.18156620860099792, -0.49111855030059814]\n",
      "2900 steps | score: [0.1764780580997467, -0.45571446418762207]\n",
      "unknown params:  tensor([-0.7212,  0.3044, -0.1670,  0.4764,  0.0463, -0.0685])\n",
      "gt params:  tensor([-7.3884e-01,  2.8849e-01, -1.5268e-01,  4.5272e-01, -6.8404e-04,\n",
      "        -9.0776e-02])\n",
      "ols params:  tensor([-0.3087,  0.1365, -0.0759,  0.2108,  0.0229,  3.1626])\n",
      "unknown mse:  tensor(0.0007)\n",
      "ols mse:  tensor(1.8095)\n",
      "gt params:  tensor([-0.7062,  0.3079, -0.1915,  0.4668, -0.0059, -0.0078])\n",
      "0 steps | score: [0.4779462218284607]\n",
      "100 steps | score: [0.151572123169899]\n",
      "200 steps | score: [0.22166195511817932]\n",
      "300 steps | score: [0.11162766069173813]\n",
      "400 steps | score: [0.15685340762138367]\n",
      "500 steps | score: [0.11669240891933441]\n",
      "600 steps | score: [0.17191746830940247]\n",
      "700 steps | score: [0.19177408516407013]\n",
      "800 steps | score: [0.12335895746946335]\n",
      "900 steps | score: [0.14952516555786133]\n",
      "1000 steps | score: [0.15704652667045593]\n",
      "1100 steps | score: [0.17402556538581848]\n",
      "1200 steps | score: [0.19859609007835388]\n",
      "1300 steps | score: [0.156350240111351]\n",
      "1400 steps | score: [0.14233924448490143]\n",
      "1500 steps | score: [0.1568005532026291]\n",
      "1600 steps | score: [0.14703141152858734]\n",
      "1700 steps | score: [0.18771407008171082]\n",
      "1800 steps | score: [0.18611426651477814]\n",
      "1900 steps | score: [0.15843765437602997]\n",
      "2000 steps | score: [0.15295809507369995]\n",
      "2100 steps | score: [0.17295607924461365]\n",
      "2200 steps | score: [0.1756536066532135]\n",
      "2300 steps | score: [0.16864201426506042]\n",
      "2400 steps | score: [0.15761157870292664]\n",
      "2500 steps | score: [0.14989006519317627]\n",
      "2600 steps | score: [0.1735101342201233]\n",
      "2700 steps | score: [0.16675546765327454]\n",
      "2800 steps | score: [0.1564287692308426]\n",
      "2900 steps | score: [0.16622371971607208]\n",
      "0 steps | score: [-0.028838682919740677, 0.5884573459625244]\n",
      "100 steps | score: [-0.3043305575847626, 1.0186150074005127]\n",
      "200 steps | score: [-0.09598856419324875, 0.5405057072639465]\n",
      "300 steps | score: [-0.4861883521080017, 1.3137476444244385]\n",
      "400 steps | score: [-0.3186228275299072, 0.9679402112960815]\n",
      "500 steps | score: [-0.29583558440208435, 0.9109845757484436]\n",
      "600 steps | score: [-0.20433193445205688, 0.7184048295021057]\n",
      "700 steps | score: [-0.22164364159107208, 0.7549499273300171]\n",
      "800 steps | score: [-0.3293193578720093, 1.0073555707931519]\n",
      "900 steps | score: [-0.1944790631532669, 0.688826858997345]\n",
      "1000 steps | score: [0.08535433560609818, -0.006036251783370972]\n",
      "1100 steps | score: [-0.15835042297840118, 0.610666811466217]\n",
      "1200 steps | score: [-0.1347401887178421, 0.546390175819397]\n",
      "1300 steps | score: [-0.21598170697689056, 0.7254241704940796]\n",
      "1400 steps | score: [-0.06905876845121384, 0.4261496663093567]\n",
      "1500 steps | score: [-0.12671393156051636, 0.5519605278968811]\n",
      "1600 steps | score: [-0.12598411738872528, 0.5350691080093384]\n",
      "1700 steps | score: [-0.029305407777428627, 0.29938191175460815]\n",
      "1800 steps | score: [-0.19725263118743896, 0.6927825808525085]\n",
      "1900 steps | score: [-0.14539887011051178, 0.5826829075813293]\n",
      "2000 steps | score: [-0.1601639837026596, 0.6014976501464844]\n",
      "2100 steps | score: [-0.1675354242324829, 0.5980838537216187]\n",
      "2200 steps | score: [-0.13558226823806763, 0.562028706073761]\n",
      "2300 steps | score: [-0.23779350519180298, 0.7915343642234802]\n",
      "2400 steps | score: [-0.13745594024658203, 0.5798680782318115]\n",
      "2500 steps | score: [-0.10816029459238052, 0.4951517581939697]\n",
      "2600 steps | score: [-0.1404222846031189, 0.5613002777099609]\n",
      "2700 steps | score: [-0.10840769112110138, 0.4993216395378113]\n",
      "2800 steps | score: [-0.20661614835262299, 0.7373167872428894]\n",
      "2900 steps | score: [-0.12703633308410645, 0.5210067629814148]\n",
      "unknown params:  tensor([-0.6534,  0.2679, -0.1385,  0.4391, -0.0154,  0.2170])\n",
      "gt params:  tensor([-0.7062,  0.3079, -0.1915,  0.4668, -0.0059, -0.0078])\n",
      "ols params:  tensor([-0.3110,  0.1327, -0.0708,  0.2137, -0.0077,  3.3506])\n",
      "unknown mse:  tensor(0.0098)\n",
      "ols mse:  tensor(1.9240)\n",
      "gt params:  tensor([-0.7248,  0.3195, -0.2015,  0.4606,  0.0297, -0.0735])\n",
      "0 steps | score: [0.2508959174156189]\n",
      "100 steps | score: [-0.0466541089117527]\n",
      "200 steps | score: [-0.053532376885414124]\n",
      "300 steps | score: [-0.11449451744556427]\n",
      "400 steps | score: [-0.0792810246348381]\n",
      "500 steps | score: [-0.07952993363142014]\n",
      "600 steps | score: [-0.017987579107284546]\n",
      "700 steps | score: [-0.026771962642669678]\n",
      "800 steps | score: [-0.08973509073257446]\n",
      "900 steps | score: [-0.11959092319011688]\n",
      "1000 steps | score: [-0.07221099734306335]\n",
      "1100 steps | score: [-0.06422259658575058]\n",
      "1200 steps | score: [-0.04107385128736496]\n",
      "1300 steps | score: [-0.1053391695022583]\n",
      "1400 steps | score: [-0.11277039349079132]\n",
      "1500 steps | score: [-0.08048522472381592]\n",
      "1600 steps | score: [-0.08475521206855774]\n",
      "1700 steps | score: [-0.04470411315560341]\n",
      "1800 steps | score: [-0.10569624602794647]\n",
      "1900 steps | score: [-0.11653818190097809]\n",
      "2000 steps | score: [-0.08752404153347015]\n",
      "2100 steps | score: [-0.10083544254302979]\n",
      "2200 steps | score: [-0.06260815262794495]\n",
      "2300 steps | score: [-0.07639594376087189]\n",
      "2400 steps | score: [-0.09469737112522125]\n",
      "2500 steps | score: [-0.08865988254547119]\n",
      "2600 steps | score: [-0.059450939297676086]\n",
      "2700 steps | score: [-0.07740476727485657]\n",
      "2800 steps | score: [-0.08507570624351501]\n",
      "2900 steps | score: [-0.09799115359783173]\n",
      "0 steps | score: [0.1430123746395111, 0.019080907106399536]\n",
      "100 steps | score: [0.03266182169318199, 0.09858438372612]\n",
      "200 steps | score: [-0.044891320168972015, 0.2019009292125702]\n",
      "300 steps | score: [-0.10849130898714066, 0.3263872563838959]\n",
      "400 steps | score: [-0.025908900424838066, 0.13409651815891266]\n",
      "500 steps | score: [-0.16703948378562927, 0.4164327085018158]\n",
      "600 steps | score: [0.2952921390533447, -0.6618841886520386]\n",
      "700 steps | score: [0.1785011738538742, -0.3283907175064087]\n",
      "800 steps | score: [-0.060641009360551834, 0.21428821980953217]\n",
      "900 steps | score: [-0.058034490793943405, 0.22155863046646118]\n",
      "1000 steps | score: [0.06554281711578369, -0.09562398493289948]\n",
      "1100 steps | score: [-0.07254006713628769, 0.22866135835647583]\n",
      "1200 steps | score: [0.13076956570148468, -0.25729823112487793]\n",
      "1300 steps | score: [-0.23074769973754883, 0.5433667898178101]\n",
      "1400 steps | score: [-0.10882677137851715, 0.28061622381210327]\n",
      "1500 steps | score: [0.1111515611410141, -0.1947421133518219]\n",
      "1600 steps | score: [-0.18581660091876984, 0.44589871168136597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 steps | score: [0.042983122169971466, -0.032748639583587646]\n",
      "1800 steps | score: [-0.2084723562002182, 0.4940783977508545]\n",
      "1900 steps | score: [-0.0438092015683651, 0.1702219843864441]\n",
      "2000 steps | score: [-0.041363295167684555, 0.11545784771442413]\n",
      "2100 steps | score: [-0.01903221569955349, 0.11373884975910187]\n",
      "2200 steps | score: [0.04598608985543251, -0.03984314203262329]\n",
      "2300 steps | score: [-0.16601254045963287, 0.3978784680366516]\n",
      "2400 steps | score: [-0.1058785691857338, 0.2995012402534485]\n",
      "2500 steps | score: [0.05533985048532486, -0.06419031322002411]\n",
      "2600 steps | score: [-0.05223270505666733, 0.16170910000801086]\n",
      "2700 steps | score: [-0.015416537411510944, 0.0893884003162384]\n",
      "2800 steps | score: [-0.11249355971813202, 0.2998809218406677]\n",
      "2900 steps | score: [-0.13003331422805786, 0.335003137588501]\n",
      "unknown params:  tensor([-0.7482,  0.3012, -0.1644,  0.4600,  0.0155, -0.0321])\n",
      "gt params:  tensor([-0.7248,  0.3195, -0.2015,  0.4606,  0.0297, -0.0735])\n",
      "ols params:  tensor([-0.3187,  0.1362, -0.0743,  0.1994,  0.0079,  3.3679])\n",
      "unknown mse:  tensor(0.0007)\n",
      "ols mse:  tensor(2.0212)\n",
      "gt params:  tensor([-0.7044,  0.3317, -0.1750,  0.4614,  0.0123, -0.0256])\n",
      "0 steps | score: [0.41598039865493774]\n",
      "100 steps | score: [0.0984928160905838]\n",
      "200 steps | score: [0.10398618876934052]\n",
      "300 steps | score: [0.1288640797138214]\n",
      "400 steps | score: [0.09521950036287308]\n",
      "500 steps | score: [0.1515124887228012]\n",
      "600 steps | score: [0.07159662991762161]\n",
      "700 steps | score: [0.10003619641065598]\n",
      "800 steps | score: [0.12197726964950562]\n",
      "900 steps | score: [0.09417996555566788]\n",
      "1000 steps | score: [0.16429749131202698]\n",
      "1100 steps | score: [0.09619571268558502]\n",
      "1200 steps | score: [0.078526571393013]\n",
      "1300 steps | score: [0.10954469442367554]\n",
      "1400 steps | score: [0.12260794639587402]\n",
      "1500 steps | score: [0.1394290328025818]\n",
      "1600 steps | score: [0.10003161430358887]\n",
      "1700 steps | score: [0.10955701768398285]\n",
      "1800 steps | score: [0.12364120781421661]\n",
      "1900 steps | score: [0.09544668346643448]\n",
      "2000 steps | score: [0.11791852116584778]\n",
      "2100 steps | score: [0.10138187557458878]\n",
      "2200 steps | score: [0.13211385905742645]\n",
      "2300 steps | score: [0.1416514813899994]\n",
      "2400 steps | score: [0.08747287839651108]\n",
      "2500 steps | score: [0.10183294117450714]\n",
      "2600 steps | score: [0.11738425493240356]\n",
      "2700 steps | score: [0.0866377055644989]\n",
      "2800 steps | score: [0.08390846848487854]\n",
      "2900 steps | score: [0.10924714803695679]\n",
      "0 steps | score: [0.4392892122268677, -0.5635366439819336]\n",
      "100 steps | score: [0.16118201613426208, -0.14923815429210663]\n",
      "200 steps | score: [0.28090474009513855, -0.43218809366226196]\n",
      "300 steps | score: [0.44235482811927795, -0.8286876082420349]\n",
      "400 steps | score: [0.2329578548669815, -0.38549771904945374]\n",
      "500 steps | score: [0.19280436635017395, -0.3115816116333008]\n",
      "600 steps | score: [0.11701150238513947, -0.14360308647155762]\n",
      "700 steps | score: [0.1814819723367691, -0.2584080100059509]\n",
      "800 steps | score: [0.1843172162771225, -0.3216763138771057]\n",
      "900 steps | score: [0.22786259651184082, -0.37891659140586853]\n",
      "1000 steps | score: [0.1854919195175171, -0.2825968563556671]\n",
      "1100 steps | score: [0.16874536871910095, -0.2685115337371826]\n",
      "1200 steps | score: [0.20002402365207672, -0.3243238925933838]\n",
      "1300 steps | score: [0.22153766453266144, -0.3613397479057312]\n",
      "1400 steps | score: [0.2007714956998825, -0.31876617670059204]\n",
      "1500 steps | score: [0.2201128751039505, -0.3521898090839386]\n",
      "1600 steps | score: [0.20650938153266907, -0.3442468047142029]\n",
      "1700 steps | score: [0.1120956540107727, -0.14252375066280365]\n",
      "1800 steps | score: [0.22693127393722534, -0.4054713547229767]\n",
      "1900 steps | score: [0.17818504571914673, -0.28279969096183777]\n",
      "2000 steps | score: [0.26107722520828247, -0.4666213393211365]\n",
      "2100 steps | score: [0.195397287607193, -0.3099960684776306]\n",
      "2200 steps | score: [0.18040190637111664, -0.3073583245277405]\n",
      "2300 steps | score: [0.2510034739971161, -0.4370288848876953]\n",
      "2400 steps | score: [0.2035883218050003, -0.31615835428237915]\n",
      "2500 steps | score: [0.2176894247531891, -0.3795117139816284]\n",
      "2600 steps | score: [0.18207919597625732, -0.297406941652298]\n",
      "2700 steps | score: [0.1557631939649582, -0.25450631976127625]\n",
      "2800 steps | score: [0.20632751286029816, -0.3474634885787964]\n",
      "2900 steps | score: [0.2366499900817871, -0.37553417682647705]\n",
      "unknown params:  tensor([-0.8093,  0.4256, -0.1863,  0.4999, -0.0024, -0.1171])\n",
      "gt params:  tensor([-0.7044,  0.3317, -0.1750,  0.4614,  0.0123, -0.0256])\n",
      "ols params:  tensor([-3.1232e-01,  1.6863e-01, -7.7061e-02,  1.9564e-01, -4.8946e-04,\n",
      "         3.4663e+00])\n",
      "unknown mse:  tensor(0.0050)\n",
      "ols mse:  tensor(2.0756)\n",
      "gt params:  tensor([-0.7378,  0.3205, -0.1756,  0.4741,  0.0041, -0.0507])\n",
      "0 steps | score: [0.476791650056839]\n",
      "100 steps | score: [0.18154151737689972]\n",
      "200 steps | score: [0.19306594133377075]\n",
      "300 steps | score: [0.18626795709133148]\n",
      "400 steps | score: [0.20431357622146606]\n",
      "500 steps | score: [0.13841937482357025]\n",
      "600 steps | score: [0.15517482161521912]\n",
      "700 steps | score: [0.1521928608417511]\n",
      "800 steps | score: [0.17429904639720917]\n",
      "900 steps | score: [0.2341008484363556]\n",
      "1000 steps | score: [0.16475710272789001]\n",
      "1100 steps | score: [0.14912746846675873]\n",
      "1200 steps | score: [0.17099717259407043]\n",
      "1300 steps | score: [0.206763356924057]\n",
      "1400 steps | score: [0.18402372300624847]\n",
      "1500 steps | score: [0.1817971169948578]\n",
      "1600 steps | score: [0.15131577849388123]\n",
      "1700 steps | score: [0.17452920973300934]\n",
      "1800 steps | score: [0.18721050024032593]\n",
      "1900 steps | score: [0.2036355584859848]\n",
      "2000 steps | score: [0.17868775129318237]\n",
      "2100 steps | score: [0.15943115949630737]\n",
      "2200 steps | score: [0.1748504340648651]\n",
      "2300 steps | score: [0.16756603121757507]\n",
      "2400 steps | score: [0.19492018222808838]\n",
      "2500 steps | score: [0.18739338219165802]\n",
      "2600 steps | score: [0.16408176720142365]\n",
      "2700 steps | score: [0.17002272605895996]\n",
      "2800 steps | score: [0.16113638877868652]\n",
      "2900 steps | score: [0.1817966103553772]\n",
      "0 steps | score: [0.09262224286794662, -0.004832979291677475]\n",
      "100 steps | score: [0.014848367311060429, 0.03178595006465912]\n",
      "200 steps | score: [-0.1654551923274994, 0.3725546896457672]\n",
      "300 steps | score: [-0.029653793200850487, 0.039449289441108704]\n",
      "400 steps | score: [0.18478213250637054, -0.4556264877319336]\n",
      "500 steps | score: [-0.030834369361400604, 0.012985680252313614]\n",
      "600 steps | score: [-0.14459510147571564, 0.24685226380825043]\n",
      "700 steps | score: [-0.2730497419834137, 0.49879947304725647]\n",
      "800 steps | score: [0.16002829372882843, -0.44695690274238586]\n",
      "900 steps | score: [0.14659884572029114, -0.40999817848205566]\n",
      "1000 steps | score: [-0.024294095113873482, -0.02374301850795746]\n",
      "1100 steps | score: [-0.09344343841075897, 0.14577294886112213]\n",
      "1200 steps | score: [0.04570556432008743, -0.15038596093654633]\n",
      "1300 steps | score: [0.11491139233112335, -0.32017573714256287]\n",
      "1400 steps | score: [-0.030886728316545486, -0.0015107691287994385]\n",
      "1500 steps | score: [0.031369686126708984, -0.1626778244972229]\n",
      "1600 steps | score: [-0.08524049073457718, 0.1307353973388672]\n",
      "1700 steps | score: [-0.006586942356079817, -0.07017665356397629]\n",
      "1800 steps | score: [-0.049228113144636154, 0.015072867274284363]\n",
      "1900 steps | score: [-0.06173551827669144, 0.027743637561798096]\n",
      "2000 steps | score: [-0.08490002900362015, 0.11536584794521332]\n",
      "2100 steps | score: [-0.07770093530416489, 0.07821375876665115]\n",
      "2200 steps | score: [-0.08151333034038544, 0.0907173603773117]\n",
      "2300 steps | score: [-0.10997895151376724, 0.1689804345369339]\n",
      "2400 steps | score: [-0.04799217730760574, 0.02763769030570984]\n",
      "2500 steps | score: [-0.03152508661150932, 0.03201329708099365]\n",
      "2600 steps | score: [-0.08706448972225189, 0.12494190037250519]\n",
      "2700 steps | score: [-0.04058919847011566, 0.011958945542573929]\n",
      "2800 steps | score: [-0.07031973451375961, 0.04862310364842415]\n",
      "2900 steps | score: [-0.0569467768073082, 0.04554795101284981]\n",
      "unknown params:  tensor([-0.7396,  0.3697, -0.1924,  0.4371,  0.0209, -0.0771])\n",
      "gt params:  tensor([-0.7378,  0.3205, -0.1756,  0.4741,  0.0041, -0.0507])\n",
      "ols params:  tensor([-0.3173,  0.1675, -0.0864,  0.1956,  0.0129,  3.5236])\n",
      "unknown mse:  tensor(0.0008)\n",
      "ols mse:  tensor(2.1769)\n",
      "gt params:  tensor([-7.2079e-01,  3.2267e-01, -1.8547e-01,  4.6065e-01,  5.9076e-04,\n",
      "        -9.5614e-03])\n",
      "0 steps | score: [0.431770920753479]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [0.09339077025651932]\n",
      "200 steps | score: [0.1599644124507904]\n",
      "300 steps | score: [0.07928172498941422]\n",
      "400 steps | score: [0.0818767249584198]\n",
      "500 steps | score: [0.0898447334766388]\n",
      "600 steps | score: [0.08505550771951675]\n",
      "700 steps | score: [0.10350637882947922]\n",
      "800 steps | score: [0.10837643593549728]\n",
      "900 steps | score: [0.07259460538625717]\n",
      "1000 steps | score: [0.06943562626838684]\n",
      "1100 steps | score: [0.08862033486366272]\n",
      "1200 steps | score: [0.1401917189359665]\n",
      "1300 steps | score: [0.08546927571296692]\n",
      "1400 steps | score: [0.05985153093934059]\n",
      "1500 steps | score: [0.08631448447704315]\n",
      "1600 steps | score: [0.06595711410045624]\n",
      "1700 steps | score: [0.08561523258686066]\n",
      "1800 steps | score: [0.10003624111413956]\n",
      "1900 steps | score: [0.08502573519945145]\n",
      "2000 steps | score: [0.08710221946239471]\n",
      "2100 steps | score: [0.09583012759685516]\n",
      "2200 steps | score: [0.09724368155002594]\n",
      "2300 steps | score: [0.09446965903043747]\n",
      "2400 steps | score: [0.09764957427978516]\n",
      "2500 steps | score: [0.08611559867858887]\n",
      "2600 steps | score: [0.054678887128829956]\n",
      "2700 steps | score: [0.07916102558374405]\n",
      "2800 steps | score: [0.11468660831451416]\n",
      "2900 steps | score: [0.08148898929357529]\n",
      "0 steps | score: [0.16658808290958405, 0.07014255225658417]\n",
      "100 steps | score: [-0.11158549785614014, 0.4939648509025574]\n",
      "200 steps | score: [-0.17710041999816895, 0.5566741228103638]\n",
      "300 steps | score: [-0.013884651474654675, 0.21606934070587158]\n",
      "400 steps | score: [0.06308843195438385, 0.040623463690280914]\n",
      "500 steps | score: [-0.09502316266298294, 0.38091573119163513]\n",
      "600 steps | score: [-0.12882262468338013, 0.44154658913612366]\n",
      "700 steps | score: [-0.175673708319664, 0.5362471342086792]\n",
      "800 steps | score: [0.0702323466539383, 0.012743741273880005]\n",
      "900 steps | score: [0.06389718502759933, 0.038612000644207]\n",
      "1000 steps | score: [-0.015743078663945198, 0.2003539651632309]\n",
      "1100 steps | score: [-0.05066791921854019, 0.25547531247138977]\n",
      "1200 steps | score: [-0.02087029255926609, 0.20485809445381165]\n",
      "1300 steps | score: [0.01591739058494568, 0.11268086731433868]\n",
      "1400 steps | score: [-0.04952709749341011, 0.2670813202857971]\n",
      "1500 steps | score: [0.059911686927080154, 0.03814716637134552]\n",
      "1600 steps | score: [-0.05865088105201721, 0.29910334944725037]\n",
      "1700 steps | score: [-0.016113294288516045, 0.18379925191402435]\n",
      "1800 steps | score: [-0.011389894410967827, 0.18554118275642395]\n",
      "1900 steps | score: [0.029935486614704132, 0.10353441536426544]\n",
      "2000 steps | score: [0.015702547505497932, 0.13238337635993958]\n",
      "2100 steps | score: [-0.0317988246679306, 0.23251666128635406]\n",
      "2200 steps | score: [0.06230020895600319, 0.033913806080818176]\n",
      "2300 steps | score: [0.025685029104351997, 0.09903575479984283]\n",
      "2400 steps | score: [0.0027301956433802843, 0.15416181087493896]\n",
      "2500 steps | score: [0.008660855703055859, 0.13727715611457825]\n",
      "2600 steps | score: [0.009576837532222271, 0.16640174388885498]\n",
      "2700 steps | score: [0.07180977612733841, 0.005788356065750122]\n",
      "2800 steps | score: [0.03298792243003845, 0.0729580745100975]\n",
      "2900 steps | score: [0.008532989770174026, 0.16561059653759003]\n",
      "unknown params:  tensor([-0.6858,  0.3525, -0.1823,  0.5082, -0.0352,  0.1177])\n",
      "gt params:  tensor([-7.2079e-01,  3.2267e-01, -1.8547e-01,  4.6065e-01,  5.9076e-04,\n",
      "        -9.5614e-03])\n",
      "ols params:  tensor([-0.2884,  0.1524, -0.0808,  0.2182, -0.0124,  3.6643])\n",
      "unknown mse:  tensor(0.0036)\n",
      "ols mse:  tensor(2.2972)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/14387f63-a5fc-498f-be7c-db0e0ab66d9a\n",
      "gt params:  tensor([-0.3993,  0.0039, -0.7913,  0.2454, -0.0063, -0.3128])\n",
      "0 steps | score: [0.12934046983718872]\n",
      "100 steps | score: [-0.008764883503317833]\n",
      "0 steps | score: [0.17070527374744415, -0.26893967390060425]\n",
      "100 steps | score: [-0.26676443219184875, 0.7703190445899963]\n",
      "200 steps | score: [0.10381744056940079, -0.35204413533210754]\n",
      "300 steps | score: [0.08221438527107239, -0.3428483307361603]\n",
      "400 steps | score: [0.031504400074481964, -0.15164583921432495]\n",
      "500 steps | score: [0.015536299906671047, -0.17391908168792725]\n",
      "600 steps | score: [0.023834310472011566, -0.12447748333215714]\n",
      "700 steps | score: [-0.12557128071784973, 0.32066577672958374]\n",
      "800 steps | score: [0.1551029533147812, -0.618658721446991]\n",
      "900 steps | score: [-0.11161813139915466, 0.2571554481983185]\n",
      "1000 steps | score: [0.15362229943275452, -0.639942467212677]\n",
      "1100 steps | score: [-0.12950579822063446, 0.324447363615036]\n",
      "1200 steps | score: [0.16508157551288605, -0.7115578055381775]\n",
      "1300 steps | score: [-0.18296511471271515, 0.48650142550468445]\n",
      "1400 steps | score: [0.018162420019507408, -0.13152775168418884]\n",
      "1500 steps | score: [0.009403781034052372, -0.0880216583609581]\n",
      "1600 steps | score: [0.081449493765831, -0.35943108797073364]\n",
      "1700 steps | score: [0.009351089596748352, -0.09487349539995193]\n",
      "1800 steps | score: [0.05572317913174629, -0.3024407625198364]\n",
      "1900 steps | score: [0.044978588819503784, -0.27963972091674805]\n",
      "2000 steps | score: [0.05280061066150665, -0.31406068801879883]\n",
      "2100 steps | score: [-0.0042125387117266655, -0.07748355716466904]\n",
      "2200 steps | score: [0.046466127038002014, -0.29925471544265747]\n",
      "2300 steps | score: [0.01472789142280817, -0.15411308407783508]\n",
      "2400 steps | score: [0.023806573823094368, -0.13859644532203674]\n",
      "2500 steps | score: [-0.015485581941902637, -0.0792832151055336]\n",
      "2600 steps | score: [0.1267414391040802, -0.5535745620727539]\n",
      "2700 steps | score: [-0.056174807250499725, 0.05445636808872223]\n",
      "unknown params:  tensor([-0.3863,  0.0104, -0.7724,  0.2487, -0.0069, -0.1863])\n",
      "gt params:  tensor([-0.3993,  0.0039, -0.7913,  0.2454, -0.0063, -0.3128])\n",
      "ols params:  tensor([-0.3182,  0.0067, -0.6060,  0.2017, -0.0060,  0.4728])\n",
      "unknown mse:  tensor(0.0028)\n",
      "ols mse:  tensor(0.1100)\n",
      "gt params:  tensor([-0.3978, -0.0025, -0.7997,  0.2496,  0.0052, -0.2943])\n",
      "0 steps | score: [0.004905911162495613]\n",
      "100 steps | score: [-0.09343554079532623]\n",
      "200 steps | score: [-0.09627766162157059]\n",
      "300 steps | score: [-0.1684422492980957]\n",
      "400 steps | score: [-0.0955839529633522]\n",
      "500 steps | score: [-0.13910631835460663]\n",
      "600 steps | score: [-0.1245163157582283]\n",
      "700 steps | score: [-0.1725657731294632]\n",
      "800 steps | score: [-0.1491619050502777]\n",
      "900 steps | score: [-0.1507977545261383]\n",
      "1000 steps | score: [-0.17975936830043793]\n",
      "1100 steps | score: [-0.09414326399564743]\n",
      "1200 steps | score: [-0.15139353275299072]\n",
      "1300 steps | score: [-0.12285180389881134]\n",
      "1400 steps | score: [-0.12004058808088303]\n",
      "1500 steps | score: [-0.16506695747375488]\n",
      "1600 steps | score: [-0.1418137550354004]\n",
      "1700 steps | score: [-0.15399640798568726]\n",
      "1800 steps | score: [-0.12437404692173004]\n",
      "1900 steps | score: [-0.10882852226495743]\n",
      "2000 steps | score: [-0.12472683191299438]\n",
      "2100 steps | score: [-0.15020935237407684]\n",
      "2200 steps | score: [-0.1434352546930313]\n",
      "2300 steps | score: [-0.13319841027259827]\n",
      "2400 steps | score: [-0.14164794981479645]\n",
      "2500 steps | score: [-0.1285034567117691]\n",
      "2600 steps | score: [-0.11078086495399475]\n",
      "2700 steps | score: [-0.1314234733581543]\n",
      "2800 steps | score: [-0.15183331072330475]\n",
      "0 steps | score: [0.32989755272865295, -0.5272462368011475]\n",
      "100 steps | score: [0.46907293796539307, -1.1143534183502197]\n",
      "200 steps | score: [0.1799546629190445, -0.339557945728302]\n",
      "300 steps | score: [0.20235519111156464, -0.5068982839584351]\n",
      "400 steps | score: [0.3894577920436859, -1.0152055025100708]\n",
      "500 steps | score: [0.03448051959276199, 0.03821490705013275]\n",
      "600 steps | score: [0.023073438555002213, 0.030986838042736053]\n",
      "700 steps | score: [0.11392000317573547, -0.18280665576457977]\n",
      "800 steps | score: [0.1976609230041504, -0.461660236120224]\n",
      "900 steps | score: [0.1496203988790512, -0.3236464858055115]\n",
      "1000 steps | score: [0.17964360117912292, -0.3586583733558655]\n",
      "1100 steps | score: [0.21154631674289703, -0.4860249161720276]\n",
      "1200 steps | score: [0.08862044662237167, -0.13185565173625946]\n",
      "1300 steps | score: [0.1669078916311264, -0.3597683608531952]\n",
      "1400 steps | score: [0.23155094683170319, -0.5883882641792297]\n",
      "1500 steps | score: [0.16960015892982483, -0.35759660601615906]\n",
      "1600 steps | score: [0.13526777923107147, -0.25294798612594604]\n",
      "1700 steps | score: [0.14181682467460632, -0.30803048610687256]\n",
      "1800 steps | score: [0.2744317054748535, -0.6795555949211121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [0.19340263307094574, -0.4387524724006653]\n",
      "2000 steps | score: [0.23421156406402588, -0.5666951537132263]\n",
      "2100 steps | score: [0.14572598040103912, -0.319247841835022]\n",
      "2200 steps | score: [0.2592802345752716, -0.6134099364280701]\n",
      "2300 steps | score: [0.15802636742591858, -0.3238889276981354]\n",
      "2400 steps | score: [0.11828381568193436, -0.24960321187973022]\n",
      "2500 steps | score: [0.22321224212646484, -0.5421223044395447]\n",
      "2600 steps | score: [0.16380971670150757, -0.36194849014282227]\n",
      "2700 steps | score: [0.2517593801021576, -0.633182168006897]\n",
      "2800 steps | score: [0.18415945768356323, -0.4258875846862793]\n",
      "unknown params:  tensor([-0.4112,  0.0011, -0.7998,  0.2431,  0.0100, -0.1970])\n",
      "gt params:  tensor([-0.3978, -0.0025, -0.7997,  0.2496,  0.0052, -0.2943])\n",
      "ols params:  tensor([-2.9043e-01, -3.2496e-04, -5.2774e-01,  1.7439e-01,  5.4252e-03,\n",
      "         9.1743e-01])\n",
      "unknown mse:  tensor(0.0016)\n",
      "ols mse:  tensor(0.2599)\n",
      "gt params:  tensor([-0.3977,  0.0041, -0.7921,  0.2557, -0.0080, -0.3172])\n",
      "0 steps | score: [0.23786517977714539]\n",
      "100 steps | score: [0.037752002477645874]\n",
      "200 steps | score: [-0.011074353009462357]\n",
      "300 steps | score: [0.10110650956630707]\n",
      "400 steps | score: [0.02015889436006546]\n",
      "500 steps | score: [-0.016160134226083755]\n",
      "600 steps | score: [0.024814490228891373]\n",
      "700 steps | score: [0.022071678191423416]\n",
      "800 steps | score: [0.07236788421869278]\n",
      "900 steps | score: [0.08715622127056122]\n",
      "1000 steps | score: [0.05124099180102348]\n",
      "1100 steps | score: [0.034898899495601654]\n",
      "1200 steps | score: [0.02936842292547226]\n",
      "1300 steps | score: [0.07985985279083252]\n",
      "1400 steps | score: [0.06661968678236008]\n",
      "1500 steps | score: [0.04591215029358864]\n",
      "1600 steps | score: [0.04290974512696266]\n",
      "1700 steps | score: [0.0497206449508667]\n",
      "1800 steps | score: [0.07700715959072113]\n",
      "1900 steps | score: [0.046682897955179214]\n",
      "2000 steps | score: [0.03927626460790634]\n",
      "2100 steps | score: [0.027132242918014526]\n",
      "2200 steps | score: [0.0693482756614685]\n",
      "2300 steps | score: [0.0650477483868599]\n",
      "2400 steps | score: [0.04085386171936989]\n",
      "2500 steps | score: [0.030552886426448822]\n",
      "2600 steps | score: [0.050202615559101105]\n",
      "2700 steps | score: [0.07752425223588943]\n",
      "0 steps | score: [0.2485004961490631, -0.2575238347053528]\n",
      "100 steps | score: [0.024091660976409912, 0.1070660650730133]\n",
      "200 steps | score: [-0.2194465547800064, 0.5945088863372803]\n",
      "300 steps | score: [0.36288198828697205, -0.9284601211547852]\n",
      "400 steps | score: [-0.11902173608541489, 0.3879040777683258]\n",
      "500 steps | score: [0.24339568614959717, -0.7025009393692017]\n",
      "600 steps | score: [-0.01258661039173603, 0.07575652748346329]\n",
      "700 steps | score: [-0.06534960865974426, 0.21109677851200104]\n",
      "800 steps | score: [0.18309582769870758, -0.4080204963684082]\n",
      "900 steps | score: [0.08953709900379181, -0.15758658945560455]\n",
      "1000 steps | score: [0.21494551002979279, -0.5390240550041199]\n",
      "1100 steps | score: [0.21165364980697632, -0.5441892147064209]\n",
      "1200 steps | score: [-0.03891363739967346, 0.15068580210208893]\n",
      "1300 steps | score: [0.11094247549772263, -0.2925041615962982]\n",
      "1400 steps | score: [-0.0419212207198143, 0.15682314336299896]\n",
      "1500 steps | score: [0.07168474048376083, -0.11041608452796936]\n",
      "1600 steps | score: [-0.05603756383061409, 0.19076547026634216]\n",
      "1700 steps | score: [0.10615845769643784, -0.24634097516536713]\n",
      "1800 steps | score: [0.11442786455154419, -0.22324685752391815]\n",
      "1900 steps | score: [-0.01599702425301075, 0.10864875465631485]\n",
      "2000 steps | score: [-0.021472085267305374, 0.09063720703125]\n",
      "2100 steps | score: [0.044256217777729034, -0.06682782620191574]\n",
      "2200 steps | score: [0.09197519719600677, -0.21431861817836761]\n",
      "2300 steps | score: [0.1438826322555542, -0.3029773235321045]\n",
      "2400 steps | score: [0.09156854450702667, -0.19921952486038208]\n",
      "2500 steps | score: [0.07875845581293106, -0.13114380836486816]\n",
      "2600 steps | score: [0.09396955370903015, -0.21902616322040558]\n",
      "2700 steps | score: [0.19675534963607788, -0.46245479583740234]\n",
      "unknown params:  tensor([-0.3959,  0.0219, -0.7781,  0.2714,  0.0184, -0.1848])\n",
      "gt params:  tensor([-0.3977,  0.0041, -0.7921,  0.2557, -0.0080, -0.3172])\n",
      "ols params:  tensor([-0.2594,  0.0124, -0.4701,  0.1781,  0.0088,  1.2233])\n",
      "unknown mse:  tensor(0.0032)\n",
      "ols mse:  tensor(0.4170)\n",
      "gt params:  tensor([-0.3986, -0.0022, -0.7990,  0.2430, -0.0023, -0.3475])\n",
      "0 steps | score: [0.2805805802345276]\n",
      "100 steps | score: [0.054333385080099106]\n",
      "200 steps | score: [0.05005548521876335]\n",
      "300 steps | score: [0.005117050372064114]\n",
      "0 steps | score: [0.21141007542610168, -0.22452177107334137]\n",
      "100 steps | score: [0.36618348956108093, -0.7910028696060181]\n",
      "200 steps | score: [0.536760687828064, -1.4522740840911865]\n",
      "300 steps | score: [-0.12388966977596283, 0.2584604024887085]\n",
      "400 steps | score: [0.6134682297706604, -1.7581287622451782]\n",
      "500 steps | score: [-0.012533188797533512, -0.00369909405708313]\n",
      "600 steps | score: [0.03301364555954933, -0.10236729681491852]\n",
      "700 steps | score: [0.03032420575618744, -0.09439428150653839]\n",
      "800 steps | score: [0.0132271908223629, -0.07392262667417526]\n",
      "900 steps | score: [0.06446631252765656, -0.18612033128738403]\n",
      "1000 steps | score: [0.013841543346643448, -0.06748072057962418]\n",
      "1100 steps | score: [0.23088616132736206, -0.6409595012664795]\n",
      "1200 steps | score: [0.22763024270534515, -0.6542273759841919]\n",
      "1300 steps | score: [0.06906094402074814, -0.2180688977241516]\n",
      "1400 steps | score: [0.16722463071346283, -0.5126991868019104]\n",
      "1500 steps | score: [0.0003167775284964591, -0.010970264673233032]\n",
      "1600 steps | score: [0.07520512491464615, -0.2141081839799881]\n",
      "1700 steps | score: [0.27214595675468445, -0.7572318315505981]\n",
      "1800 steps | score: [-0.0017935259966179729, -0.06489326059818268]\n",
      "1900 steps | score: [0.06616567075252533, -0.1977015733718872]\n",
      "2000 steps | score: [0.14602883160114288, -0.3935289978981018]\n",
      "2100 steps | score: [0.002388332039117813, -0.02185991406440735]\n",
      "2200 steps | score: [0.11826719343662262, -0.368475079536438]\n",
      "2300 steps | score: [0.16340409219264984, -0.46320998668670654]\n",
      "2400 steps | score: [0.0953114926815033, -0.2772709131240845]\n",
      "2500 steps | score: [0.14146286249160767, -0.39638206362724304]\n",
      "2600 steps | score: [0.012036091648042202, -0.08451908081769943]\n",
      "2700 steps | score: [-0.015316500328481197, -0.01118294894695282]\n",
      "unknown params:  tensor([-0.4011,  0.0073, -0.7802,  0.2376, -0.0104, -0.2259])\n",
      "gt params:  tensor([-0.3986, -0.0022, -0.7990,  0.2430, -0.0023, -0.3475])\n",
      "ols params:  tensor([-0.2400,  0.0045, -0.4294,  0.1422, -0.0079,  1.5093])\n",
      "unknown mse:  tensor(0.0026)\n",
      "ols mse:  tensor(0.6033)\n",
      "gt params:  tensor([-0.3964, -0.0011, -0.7801,  0.2459, -0.0155, -0.3450])\n",
      "0 steps | score: [0.25113216042518616]\n",
      "100 steps | score: [-0.033425573259592056]\n",
      "200 steps | score: [0.011595457792282104]\n",
      "300 steps | score: [0.07238657772541046]\n",
      "400 steps | score: [-0.03853870555758476]\n",
      "500 steps | score: [-0.01118980348110199]\n",
      "600 steps | score: [-0.026527125388383865]\n",
      "700 steps | score: [-0.010780438780784607]\n",
      "800 steps | score: [0.026626646518707275]\n",
      "900 steps | score: [-0.03518932685256004]\n",
      "1000 steps | score: [0.0352909192442894]\n",
      "1100 steps | score: [0.00695376843214035]\n",
      "0 steps | score: [0.06369415670633316, 0.05574818700551987]\n",
      "100 steps | score: [-0.05096103996038437, 0.16439521312713623]\n",
      "200 steps | score: [-0.1091638132929802, 0.23808252811431885]\n",
      "300 steps | score: [0.14565907418727875, -0.46839410066604614]\n",
      "400 steps | score: [-0.207940474152565, 0.4292786121368408]\n",
      "500 steps | score: [-0.25689876079559326, 0.5462663769721985]\n",
      "600 steps | score: [-0.0077705103904008865, -0.06125059723854065]\n",
      "700 steps | score: [0.058411940932273865, -0.25429320335388184]\n",
      "800 steps | score: [-0.029545126482844353, -0.07347990572452545]\n",
      "900 steps | score: [-0.2711217999458313, 0.6073673367500305]\n",
      "1000 steps | score: [-0.08638069778680801, 0.11707477271556854]\n",
      "1100 steps | score: [-0.16334259510040283, 0.3188234865665436]\n",
      "1200 steps | score: [0.07330378144979477, -0.29160356521606445]\n",
      "1300 steps | score: [-0.061478253453969955, 0.05761551856994629]\n",
      "1400 steps | score: [0.03150849789381027, -0.21848297119140625]\n",
      "1500 steps | score: [0.15557682514190674, -0.5430430173873901]\n",
      "1600 steps | score: [-0.04555665701627731, 0.04405531287193298]\n",
      "1700 steps | score: [0.004673000890761614, -0.11867418885231018]\n",
      "1800 steps | score: [-0.13037477433681488, 0.21027523279190063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [0.020014246925711632, -0.13509254157543182]\n",
      "2000 steps | score: [-0.07779724150896072, 0.08856058120727539]\n",
      "2100 steps | score: [-0.02973215840756893, -0.03596313297748566]\n",
      "2200 steps | score: [0.035398077219724655, -0.24699807167053223]\n",
      "2300 steps | score: [-0.05935823172330856, 0.06023235619068146]\n",
      "2400 steps | score: [0.05949290469288826, -0.27814024686813354]\n",
      "2500 steps | score: [0.004866697359830141, -0.1330096274614334]\n",
      "2600 steps | score: [-0.010493590496480465, -0.11436666548252106]\n",
      "2700 steps | score: [0.037084903568029404, -0.20386996865272522]\n",
      "unknown params:  tensor([-0.4074, -0.0155, -0.7666,  0.2580, -0.0265, -0.2068])\n",
      "gt params:  tensor([-0.3964, -0.0011, -0.7801,  0.2459, -0.0155, -0.3450])\n",
      "ols params:  tensor([-0.2264, -0.0101, -0.3938,  0.1457, -0.0156,  1.7383])\n",
      "unknown mse:  tensor(0.0033)\n",
      "ols mse:  tensor(0.7547)\n",
      "gt params:  tensor([-0.3742,  0.0108, -0.7895,  0.2459, -0.0046, -0.3468])\n",
      "0 steps | score: [0.31792211532592773]\n",
      "100 steps | score: [0.023412389680743217]\n",
      "200 steps | score: [0.06300289928913116]\n",
      "300 steps | score: [0.079918272793293]\n",
      "400 steps | score: [-0.005415141582489014]\n",
      "0 steps | score: [-0.05685794726014137, 0.2868366241455078]\n",
      "100 steps | score: [-0.34318599104881287, 0.7732099890708923]\n",
      "200 steps | score: [-0.2985522449016571, 0.6348387002944946]\n",
      "300 steps | score: [-0.19051098823547363, 0.38104844093322754]\n",
      "400 steps | score: [-0.4779360890388489, 0.9565725922584534]\n",
      "500 steps | score: [-0.27220916748046875, 0.5203648805618286]\n",
      "600 steps | score: [-0.3089034855365753, 0.6091254949569702]\n",
      "700 steps | score: [-0.48332899808883667, 0.9606280326843262]\n",
      "800 steps | score: [-0.28172677755355835, 0.5284041166305542]\n",
      "900 steps | score: [-0.06024549901485443, 0.00034099072217941284]\n",
      "1000 steps | score: [-0.24651692807674408, 0.435969740152359]\n",
      "1100 steps | score: [-0.30877047777175903, 0.6083652973175049]\n",
      "1200 steps | score: [-0.03613705933094025, -0.09012284129858017]\n",
      "1300 steps | score: [-0.2158675640821457, 0.3768543004989624]\n",
      "1400 steps | score: [-0.23551525175571442, 0.4293282628059387]\n",
      "1500 steps | score: [-0.20993690192699432, 0.37190377712249756]\n",
      "1600 steps | score: [-0.28572145104408264, 0.5532035827636719]\n",
      "1700 steps | score: [-0.29044437408447266, 0.5505465269088745]\n",
      "1800 steps | score: [-0.22730478644371033, 0.4082237482070923]\n",
      "1900 steps | score: [-0.20939484238624573, 0.37556129693984985]\n",
      "2000 steps | score: [-0.22222627699375153, 0.41679808497428894]\n",
      "2100 steps | score: [-0.2861465811729431, 0.5472456216812134]\n",
      "2200 steps | score: [-0.23475335538387299, 0.4077369272708893]\n",
      "2300 steps | score: [-0.16332359611988068, 0.21421071887016296]\n",
      "2400 steps | score: [-0.1477685272693634, 0.23240214586257935]\n",
      "2500 steps | score: [-0.23217512667179108, 0.4321250021457672]\n",
      "2600 steps | score: [-0.19635458290576935, 0.31303465366363525]\n",
      "2700 steps | score: [-0.2541697025299072, 0.4702554941177368]\n",
      "unknown params:  tensor([-0.3591,  0.0055, -0.7553,  0.2302, -0.0223, -0.0823])\n",
      "gt params:  tensor([-0.3742,  0.0108, -0.7895,  0.2459, -0.0046, -0.3468])\n",
      "ols params:  tensor([-0.1929,  0.0022, -0.3670,  0.1226, -0.0121,  1.9581])\n",
      "unknown mse:  tensor(0.0120)\n",
      "ols mse:  tensor(0.9231)\n",
      "gt params:  tensor([-0.3868,  0.0073, -0.7888,  0.2400,  0.0111, -0.2791])\n",
      "0 steps | score: [0.2803901433944702]\n",
      "100 steps | score: [0.061887890100479126]\n",
      "200 steps | score: [-0.04037413373589516]\n",
      "300 steps | score: [-0.04031196981668472]\n",
      "400 steps | score: [0.030139394104480743]\n",
      "500 steps | score: [0.07087330520153046]\n",
      "600 steps | score: [0.028531592339277267]\n",
      "700 steps | score: [-0.049969982355833054]\n",
      "800 steps | score: [-0.02321575954556465]\n",
      "900 steps | score: [-0.020482972264289856]\n",
      "1000 steps | score: [0.04932020977139473]\n",
      "1100 steps | score: [-0.001679796725511551]\n",
      "0 steps | score: [0.08122800290584564, -0.05113597959280014]\n",
      "100 steps | score: [-0.09552725404500961, 0.1952384114265442]\n",
      "200 steps | score: [-0.15773271024227142, 0.2315676212310791]\n",
      "300 steps | score: [-0.25237736105918884, 0.40891581773757935]\n",
      "400 steps | score: [0.09166254848241806, -0.41459572315216064]\n",
      "500 steps | score: [-0.17526687681674957, 0.2502005994319916]\n",
      "600 steps | score: [-0.15263576805591583, 0.20158907771110535]\n",
      "700 steps | score: [-0.3330707252025604, 0.5432330369949341]\n",
      "800 steps | score: [-0.25714796781539917, 0.41048264503479004]\n",
      "900 steps | score: [-0.07733844220638275, 0.008631467819213867]\n",
      "1000 steps | score: [-0.1267392635345459, 0.1211702972650528]\n",
      "1100 steps | score: [-0.28552189469337463, 0.4768087565898895]\n",
      "1200 steps | score: [-0.08130941540002823, 0.03302134945988655]\n",
      "1300 steps | score: [-0.2378852814435959, 0.36800211668014526]\n",
      "1400 steps | score: [-0.09886526316404343, 0.07471537590026855]\n",
      "1500 steps | score: [-0.17752233147621155, 0.23781272768974304]\n",
      "1600 steps | score: [-0.19255897402763367, 0.2835034132003784]\n",
      "1700 steps | score: [-0.13260097801685333, 0.14965634047985077]\n",
      "1800 steps | score: [-0.23648276925086975, 0.3679640293121338]\n",
      "1900 steps | score: [-0.09556534886360168, 0.05502618849277496]\n",
      "2000 steps | score: [-0.13798116147518158, 0.13805899024009705]\n",
      "2100 steps | score: [-0.1688852310180664, 0.21636047959327698]\n",
      "2200 steps | score: [-0.2034672647714615, 0.29441261291503906]\n",
      "2300 steps | score: [-0.16274912655353546, 0.2144172191619873]\n",
      "2400 steps | score: [-0.17985595762729645, 0.23203112185001373]\n",
      "2500 steps | score: [-0.10230717808008194, 0.06681481003761292]\n",
      "2600 steps | score: [-0.23854391276836395, 0.3483807146549225]\n",
      "2700 steps | score: [-0.11201008409261703, 0.1057407334446907]\n",
      "2800 steps | score: [-0.13590770959854126, 0.18116971850395203]\n",
      "unknown params:  tensor([-0.4229, -0.0365, -0.8275,  0.2203,  0.0279, -0.0880])\n",
      "gt params:  tensor([-0.3868,  0.0073, -0.7888,  0.2400,  0.0111, -0.2791])\n",
      "ols params:  tensor([-0.2115, -0.0167, -0.3809,  0.1121,  0.0137,  2.1111])\n",
      "unknown mse:  tensor(0.0070)\n",
      "ols mse:  tensor(0.9878)\n",
      "gt params:  tensor([-0.3964,  0.0058, -0.7997,  0.2403,  0.0054, -0.2840])\n",
      "0 steps | score: [0.22720110416412354]\n",
      "100 steps | score: [-0.10840994119644165]\n",
      "200 steps | score: [0.01437582541257143]\n",
      "300 steps | score: [-0.052312448620796204]\n",
      "400 steps | score: [-0.11211967468261719]\n",
      "500 steps | score: [-0.005091349594295025]\n",
      "0 steps | score: [0.19092907011508942, -0.11396253854036331]\n",
      "100 steps | score: [-0.0017268204828724265, 0.17545583844184875]\n",
      "200 steps | score: [0.23451879620552063, -0.3756634593009949]\n",
      "300 steps | score: [-0.062015101313591, 0.21294333040714264]\n",
      "400 steps | score: [-0.10876021534204483, 0.29771047830581665]\n",
      "500 steps | score: [0.043198294937610626, -0.06355473399162292]\n",
      "600 steps | score: [-0.14313815534114838, 0.3549484610557556]\n",
      "700 steps | score: [0.06247900426387787, -0.07480771839618683]\n",
      "800 steps | score: [0.09609134495258331, -0.16677263379096985]\n",
      "900 steps | score: [-0.05417997017502785, 0.18850266933441162]\n",
      "1000 steps | score: [-0.02395285852253437, 0.10066734254360199]\n",
      "1100 steps | score: [0.28152501583099365, -0.6320713758468628]\n",
      "1200 steps | score: [-0.05417743697762489, 0.1791616529226303]\n",
      "1300 steps | score: [0.07291144877672195, -0.09840112179517746]\n",
      "1400 steps | score: [-0.1161530539393425, 0.2853139340877533]\n",
      "1500 steps | score: [-0.001733585842885077, 0.05796720087528229]\n",
      "1600 steps | score: [0.03501027077436447, -0.03640509396791458]\n",
      "1700 steps | score: [-0.011305839754641056, 0.077317014336586]\n",
      "1800 steps | score: [-0.048616234213113785, 0.15509875118732452]\n",
      "1900 steps | score: [0.01706298068165779, 0.004917232319712639]\n",
      "2000 steps | score: [-0.12163909524679184, 0.30608558654785156]\n",
      "2100 steps | score: [0.04317391291260719, -0.07921886444091797]\n",
      "2200 steps | score: [-0.017271513119339943, 0.11509686708450317]\n",
      "2300 steps | score: [-0.07614319771528244, 0.19759590923786163]\n",
      "2400 steps | score: [0.0761018842458725, -0.10283632576465607]\n",
      "2500 steps | score: [-0.07469360530376434, 0.19006189703941345]\n",
      "2600 steps | score: [0.0008292797720059752, 0.03256131336092949]\n",
      "2700 steps | score: [-0.009970512241125107, 0.07724186033010483]\n",
      "2800 steps | score: [-0.02410048618912697, 0.08680389821529388]\n",
      "unknown params:  tensor([-0.3910,  0.0082, -0.7831,  0.2351,  0.0138, -0.0733])\n",
      "gt params:  tensor([-0.3964,  0.0058, -0.7997,  0.2403,  0.0054, -0.2840])\n",
      "ols params:  tensor([-0.1968,  0.0052, -0.3653,  0.1205,  0.0075,  2.2734])\n",
      "unknown mse:  tensor(0.0075)\n",
      "ols mse:  tensor(1.1305)\n",
      "gt params:  tensor([-4.1275e-01, -3.2003e-04, -8.0268e-01,  2.4434e-01, -1.4779e-02,\n",
      "        -4.0077e-01])\n",
      "0 steps | score: [0.33040851354599]\n",
      "100 steps | score: [0.08441604673862457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [0.05916822701692581]\n",
      "300 steps | score: [0.057706620544195175]\n",
      "400 steps | score: [0.013291139155626297]\n",
      "500 steps | score: [0.005167849361896515]\n",
      "0 steps | score: [0.1955982744693756, -0.1796903908252716]\n",
      "100 steps | score: [0.3018791973590851, -0.584348201751709]\n",
      "200 steps | score: [-0.1430085003376007, 0.2699832618236542]\n",
      "300 steps | score: [-0.13059444725513458, 0.2650977373123169]\n",
      "400 steps | score: [0.06133927404880524, -0.16186673939228058]\n",
      "500 steps | score: [-0.07814034074544907, 0.1257510781288147]\n",
      "600 steps | score: [-0.0052976771257817745, -0.022148344665765762]\n",
      "700 steps | score: [-0.0021948469802737236, -0.05702437832951546]\n",
      "800 steps | score: [0.1525142639875412, -0.37396857142448425]\n",
      "900 steps | score: [0.019833896309137344, -0.07321880012750626]\n",
      "1000 steps | score: [-0.1353653073310852, 0.2424357831478119]\n",
      "1100 steps | score: [0.026657063513994217, -0.08991925418376923]\n",
      "1200 steps | score: [-0.009530648589134216, -0.023783601820468903]\n",
      "1300 steps | score: [0.05031415447592735, -0.16879916191101074]\n",
      "1400 steps | score: [-0.008122798055410385, -0.029603730887174606]\n",
      "1500 steps | score: [0.17082476615905762, -0.4786056876182556]\n",
      "1600 steps | score: [-0.1191842257976532, 0.18690921366214752]\n",
      "1700 steps | score: [-0.04688755422830582, 0.05546893924474716]\n",
      "1800 steps | score: [0.06325191259384155, -0.1951173096895218]\n",
      "1900 steps | score: [-0.029988344758749008, 0.03541744127869606]\n",
      "2000 steps | score: [-0.00528796948492527, -0.024642955511808395]\n",
      "2100 steps | score: [0.0004998316871933639, -0.05557018890976906]\n",
      "2200 steps | score: [0.06713934987783432, -0.19017353653907776]\n",
      "2300 steps | score: [-0.0012241258518770337, -0.03730154037475586]\n",
      "2400 steps | score: [-0.023690542206168175, -0.03591076284646988]\n",
      "2500 steps | score: [0.02646740898489952, -0.09783713519573212]\n",
      "2600 steps | score: [-0.026964707300066948, 0.05482606217265129]\n",
      "2700 steps | score: [-0.007367872167378664, -0.04934904724359512]\n",
      "unknown params:  tensor([-0.4156, -0.0290, -0.8286,  0.2582, -0.0123, -0.3092])\n",
      "gt params:  tensor([-4.1275e-01, -3.2003e-04, -8.0268e-01,  2.4434e-01, -1.4779e-02,\n",
      "        -4.0077e-01])\n",
      "ols params:  tensor([-0.1983, -0.0150, -0.3621,  0.1229, -0.0063,  2.3709])\n",
      "unknown mse:  tensor(0.0017)\n",
      "ols mse:  tensor(1.3229)\n",
      "gt params:  tensor([-0.3982, -0.0028, -0.7924,  0.2344, -0.0010, -0.3315])\n",
      "0 steps | score: [0.2881108522415161]\n",
      "100 steps | score: [-0.017838923260569572]\n",
      "200 steps | score: [-0.09452705085277557]\n",
      "300 steps | score: [-0.026267919689416885]\n",
      "400 steps | score: [0.0158714447170496]\n",
      "500 steps | score: [-0.0058434996753931046]\n",
      "0 steps | score: [0.19209253787994385, -0.10655383765697479]\n",
      "100 steps | score: [0.430797278881073, -0.786465048789978]\n",
      "200 steps | score: [-0.07119555026292801, 0.24332179129123688]\n",
      "300 steps | score: [0.10514760762453079, -0.16081354022026062]\n",
      "400 steps | score: [0.3404867351055145, -0.6908224821090698]\n",
      "500 steps | score: [0.29632818698883057, -0.6048269867897034]\n",
      "600 steps | score: [0.15984423458576202, -0.27603235840797424]\n",
      "700 steps | score: [-0.01484981831163168, 0.08509906381368637]\n",
      "800 steps | score: [-0.08841878175735474, 0.26340022683143616]\n",
      "900 steps | score: [0.03772298991680145, 0.00462783919647336]\n",
      "1000 steps | score: [0.08757645636796951, -0.1478518843650818]\n",
      "1100 steps | score: [0.005399524234235287, 0.04190120846033096]\n",
      "1200 steps | score: [0.03406274691224098, -0.023117955774068832]\n",
      "1300 steps | score: [-0.11710605770349503, 0.29062920808792114]\n",
      "1400 steps | score: [-0.025842605158686638, 0.1351996809244156]\n",
      "1500 steps | score: [0.022455718368291855, 0.021398179233074188]\n",
      "1600 steps | score: [0.006503655109554529, 0.0524497851729393]\n",
      "1700 steps | score: [0.02010994218289852, 0.02612416446208954]\n",
      "1800 steps | score: [0.00045873792259953916, 0.07446611672639847]\n",
      "1900 steps | score: [-0.05519966036081314, 0.17591911554336548]\n",
      "2000 steps | score: [0.04391876980662346, -0.019314369186758995]\n",
      "2100 steps | score: [-0.073696069419384, 0.22031205892562866]\n",
      "2200 steps | score: [0.044941309839487076, -0.06444565951824188]\n",
      "2300 steps | score: [0.12724140286445618, -0.22113622725009918]\n",
      "2400 steps | score: [0.014089920558035374, 0.03767607361078262]\n",
      "2500 steps | score: [0.025944119319319725, 0.013757318258285522]\n",
      "2600 steps | score: [0.013192294165492058, -0.004230869468301535]\n",
      "2700 steps | score: [-0.008063500747084618, 0.0681031197309494]\n",
      "2800 steps | score: [0.019969945773482323, 0.022439703345298767]\n",
      "unknown params:  tensor([-4.0575e-01, -1.2456e-02, -7.2805e-01,  2.3448e-01,  2.1782e-04,\n",
      "        -3.2995e-02])\n",
      "gt params:  tensor([-0.3982, -0.0028, -0.7924,  0.2344, -0.0010, -0.3315])\n",
      "ols params:  tensor([-1.9898e-01, -8.3051e-03, -3.3608e-01,  1.1815e-01, -1.0166e-03,\n",
      "         2.5258e+00])\n",
      "unknown mse:  tensor(0.0156)\n",
      "ols mse:  tensor(1.4042)\n",
      "gt params:  tensor([-0.3968, -0.0013, -0.8034,  0.2457, -0.0220, -0.2954])\n",
      "0 steps | score: [0.4220154881477356]\n",
      "100 steps | score: [0.09690926223993301]\n",
      "200 steps | score: [0.10837408900260925]\n",
      "300 steps | score: [0.16972655057907104]\n",
      "400 steps | score: [0.16302785277366638]\n",
      "500 steps | score: [0.11425957083702087]\n",
      "600 steps | score: [0.17388290166854858]\n",
      "700 steps | score: [0.1462469846010208]\n",
      "800 steps | score: [0.170620396733284]\n",
      "900 steps | score: [0.11116652935743332]\n",
      "1000 steps | score: [0.13426941633224487]\n",
      "1100 steps | score: [0.1510658860206604]\n",
      "1200 steps | score: [0.14810964465141296]\n",
      "1300 steps | score: [0.18366125226020813]\n",
      "1400 steps | score: [0.15865309536457062]\n",
      "1500 steps | score: [0.12386426329612732]\n",
      "1600 steps | score: [0.11441399157047272]\n",
      "1700 steps | score: [0.1189088225364685]\n",
      "1800 steps | score: [0.16609421372413635]\n",
      "1900 steps | score: [0.15895384550094604]\n",
      "2000 steps | score: [0.15688976645469666]\n",
      "2100 steps | score: [0.15122342109680176]\n",
      "2200 steps | score: [0.16963645815849304]\n",
      "2300 steps | score: [0.16591712832450867]\n",
      "2400 steps | score: [0.16546659171581268]\n",
      "2500 steps | score: [0.14821918308734894]\n",
      "2600 steps | score: [0.1641523391008377]\n",
      "2700 steps | score: [0.1608256697654724]\n",
      "2800 steps | score: [0.15947437286376953]\n",
      "0 steps | score: [0.34420666098594666, -0.34446874260902405]\n",
      "100 steps | score: [0.22405540943145752, -0.21363414824008942]\n",
      "200 steps | score: [0.390171617269516, -0.7280020117759705]\n",
      "300 steps | score: [0.24253492057323456, -0.3795798122882843]\n",
      "400 steps | score: [0.3111151158809662, -0.606459379196167]\n",
      "500 steps | score: [0.44215095043182373, -0.9015277624130249]\n",
      "600 steps | score: [0.209621399641037, -0.267737478017807]\n",
      "700 steps | score: [0.18073955178260803, -0.288605660200119]\n",
      "800 steps | score: [0.1380847990512848, -0.18037106096744537]\n",
      "900 steps | score: [-0.003593292087316513, 0.1045675128698349]\n",
      "1000 steps | score: [0.19137783348560333, -0.3117198050022125]\n",
      "1100 steps | score: [0.1313866674900055, -0.1494806706905365]\n",
      "1200 steps | score: [0.11046268045902252, -0.0936809554696083]\n",
      "1300 steps | score: [0.27227887511253357, -0.4800357520580292]\n",
      "1400 steps | score: [0.1386268138885498, -0.18725809454917908]\n",
      "1500 steps | score: [0.12355937063694, -0.16804224252700806]\n",
      "1600 steps | score: [0.23184409737586975, -0.42562198638916016]\n",
      "1700 steps | score: [0.08357600122690201, -0.05478519946336746]\n",
      "1800 steps | score: [0.16345040500164032, -0.25794193148612976]\n",
      "1900 steps | score: [0.18355761468410492, -0.3158929944038391]\n",
      "2000 steps | score: [0.133540540933609, -0.17574724555015564]\n",
      "2100 steps | score: [0.19042904675006866, -0.337063193321228]\n",
      "2200 steps | score: [0.18269994854927063, -0.29467999935150146]\n",
      "2300 steps | score: [0.20722010731697083, -0.3584011495113373]\n",
      "2400 steps | score: [0.11943358927965164, -0.14711160957813263]\n",
      "2500 steps | score: [0.22719435393810272, -0.37943223118782043]\n",
      "2600 steps | score: [0.2243487536907196, -0.4059238135814667]\n",
      "2700 steps | score: [0.22285044193267822, -0.37016600370407104]\n",
      "2800 steps | score: [0.23987311124801636, -0.3819444179534912]\n",
      "unknown params:  tensor([-0.4114, -0.0217, -0.8253,  0.2793, -0.0066, -0.2435])\n",
      "gt params:  tensor([-0.3968, -0.0013, -0.8034,  0.2457, -0.0220, -0.2954])\n",
      "ols params:  tensor([-0.1916, -0.0124, -0.3562,  0.1279, -0.0033,  2.6478])\n",
      "unknown mse:  tensor(0.0009)\n",
      "ols mse:  tensor(1.4865)\n",
      "gt params:  tensor([-0.3878,  0.0028, -0.7880,  0.2328, -0.0229, -0.3006])\n",
      "0 steps | score: [0.21688759326934814]\n",
      "100 steps | score: [-0.09037133306264877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [-0.05504714697599411]\n",
      "300 steps | score: [-0.11201794445514679]\n",
      "400 steps | score: [-0.1027170941233635]\n",
      "500 steps | score: [-0.046163082122802734]\n",
      "600 steps | score: [-0.05693824961781502]\n",
      "700 steps | score: [-0.051274463534355164]\n",
      "800 steps | score: [-0.11756113171577454]\n",
      "900 steps | score: [-0.06542600691318512]\n",
      "1000 steps | score: [-0.09145935624837875]\n",
      "1100 steps | score: [-0.07831087708473206]\n",
      "1200 steps | score: [-0.09159765392541885]\n",
      "1300 steps | score: [-0.10262677073478699]\n",
      "1400 steps | score: [-0.046166807413101196]\n",
      "1500 steps | score: [-0.07534775137901306]\n",
      "1600 steps | score: [-0.07481017708778381]\n",
      "1700 steps | score: [-0.07876069843769073]\n",
      "1800 steps | score: [-0.09851396083831787]\n",
      "1900 steps | score: [-0.07474952191114426]\n",
      "2000 steps | score: [-0.08942507207393646]\n",
      "2100 steps | score: [-0.07268662750720978]\n",
      "2200 steps | score: [-0.08389635384082794]\n",
      "2300 steps | score: [-0.08169609308242798]\n",
      "2400 steps | score: [-0.08482890576124191]\n",
      "2500 steps | score: [-0.07655929774045944]\n",
      "2600 steps | score: [-0.07235604524612427]\n",
      "2700 steps | score: [-0.10863079130649567]\n",
      "2800 steps | score: [-0.0976969450712204]\n",
      "0 steps | score: [-0.07974997162818909, 0.4418228566646576]\n",
      "100 steps | score: [-0.27727046608924866, 0.7138864994049072]\n",
      "200 steps | score: [-0.18721431493759155, 0.4758986234664917]\n",
      "300 steps | score: [-0.29485633969306946, 0.683785080909729]\n",
      "400 steps | score: [-0.3913327753543854, 0.8754215240478516]\n",
      "500 steps | score: [0.23647084832191467, -0.6503897905349731]\n",
      "600 steps | score: [0.04229942709207535, -0.15477952361106873]\n",
      "700 steps | score: [-0.37814977765083313, 0.823063850402832]\n",
      "800 steps | score: [-0.29658204317092896, 0.6593151092529297]\n",
      "900 steps | score: [-0.24074874818325043, 0.5491137504577637]\n",
      "1000 steps | score: [-0.2776622474193573, 0.6110901832580566]\n",
      "1100 steps | score: [-0.22891899943351746, 0.5117886662483215]\n",
      "1200 steps | score: [-0.3158110976219177, 0.7089347839355469]\n",
      "1300 steps | score: [-0.21061912178993225, 0.4775691628456116]\n",
      "1400 steps | score: [-0.15745645761489868, 0.33520904183387756]\n",
      "1500 steps | score: [-0.2054876983165741, 0.4500744938850403]\n",
      "1600 steps | score: [-0.36865589022636414, 0.789212167263031]\n",
      "1700 steps | score: [-0.37711936235427856, 0.8406568169593811]\n",
      "1800 steps | score: [-0.2792365252971649, 0.6512182950973511]\n",
      "1900 steps | score: [-0.15099665522575378, 0.3258206248283386]\n",
      "2000 steps | score: [-0.2422272115945816, 0.5295861959457397]\n",
      "2100 steps | score: [-0.2222529947757721, 0.48722901940345764]\n",
      "2200 steps | score: [-0.3742208480834961, 0.8245739936828613]\n",
      "2300 steps | score: [-0.3522341847419739, 0.769431471824646]\n",
      "2400 steps | score: [-0.2673967480659485, 0.5878704190254211]\n",
      "2500 steps | score: [-0.17584016919136047, 0.3979461193084717]\n",
      "2600 steps | score: [-0.24334567785263062, 0.5130817294120789]\n",
      "2700 steps | score: [-0.2905285060405731, 0.6583521962165833]\n",
      "2800 steps | score: [-0.23555567860603333, 0.5131239891052246]\n",
      "unknown params:  tensor([-0.3790,  0.0075, -0.8123,  0.2346,  0.0089, -0.0361])\n",
      "gt params:  tensor([-0.3878,  0.0028, -0.7880,  0.2328, -0.0229, -0.3006])\n",
      "ols params:  tensor([-0.1756,  0.0047, -0.3464,  0.1086,  0.0049,  2.7664])\n",
      "unknown mse:  tensor(0.0119)\n",
      "ols mse:  tensor(1.6105)\n",
      "gt params:  tensor([-0.3993,  0.0426, -0.8021,  0.2491, -0.0266, -0.3425])\n",
      "0 steps | score: [0.400362491607666]\n",
      "100 steps | score: [0.17211060225963593]\n",
      "200 steps | score: [0.10773786157369614]\n",
      "300 steps | score: [0.12758363783359528]\n",
      "400 steps | score: [0.07735157012939453]\n",
      "500 steps | score: [0.06553706526756287]\n",
      "600 steps | score: [0.08462079614400864]\n",
      "700 steps | score: [0.07777216285467148]\n",
      "800 steps | score: [0.07458190619945526]\n",
      "900 steps | score: [0.11603597551584244]\n",
      "1000 steps | score: [0.10073846578598022]\n",
      "1100 steps | score: [0.11689704656600952]\n",
      "1200 steps | score: [0.09126226603984833]\n",
      "1300 steps | score: [0.08173415809869766]\n",
      "1400 steps | score: [0.08922719955444336]\n",
      "1500 steps | score: [0.11053547263145447]\n",
      "1600 steps | score: [0.11881773918867111]\n",
      "1700 steps | score: [0.1074574887752533]\n",
      "1800 steps | score: [0.09779109060764313]\n",
      "1900 steps | score: [0.09960296750068665]\n",
      "2000 steps | score: [0.0735614076256752]\n",
      "2100 steps | score: [0.08889971673488617]\n",
      "2200 steps | score: [0.0997161865234375]\n",
      "2300 steps | score: [0.10903414338827133]\n",
      "2400 steps | score: [0.08626867085695267]\n",
      "2500 steps | score: [0.08466894924640656]\n",
      "2600 steps | score: [0.10313054174184799]\n",
      "2700 steps | score: [0.1151796355843544]\n",
      "2800 steps | score: [0.09699846804141998]\n",
      "0 steps | score: [0.37209826707839966, -0.3933051824569702]\n",
      "100 steps | score: [0.17095176875591278, -0.13555273413658142]\n",
      "200 steps | score: [0.12115836143493652, -0.06879633665084839]\n",
      "300 steps | score: [0.23838701844215393, -0.3503168821334839]\n",
      "400 steps | score: [-0.03997809439897537, 0.18590721487998962]\n",
      "500 steps | score: [0.1857684701681137, -0.2531023919582367]\n",
      "600 steps | score: [0.08057061582803726, -0.03403628617525101]\n",
      "700 steps | score: [0.17493413388729095, -0.23577100038528442]\n",
      "800 steps | score: [0.06589166074991226, 0.015023835003376007]\n",
      "900 steps | score: [0.24621540307998657, -0.3753284215927124]\n",
      "1000 steps | score: [0.3057169020175934, -0.5256646871566772]\n",
      "1100 steps | score: [0.2823082208633423, -0.46884143352508545]\n",
      "1200 steps | score: [0.21398961544036865, -0.30852919816970825]\n",
      "1300 steps | score: [0.09367519617080688, -0.07021138072013855]\n",
      "1400 steps | score: [0.2550923526287079, -0.39164286851882935]\n",
      "1500 steps | score: [0.36524805426597595, -0.6619718074798584]\n",
      "1600 steps | score: [0.2976374328136444, -0.5078918933868408]\n",
      "1700 steps | score: [0.3491281270980835, -0.6901327967643738]\n",
      "1800 steps | score: [0.2739821970462799, -0.46319225430488586]\n",
      "1900 steps | score: [0.1853453516960144, -0.29284998774528503]\n",
      "2000 steps | score: [0.26752451062202454, -0.4393112063407898]\n",
      "2100 steps | score: [0.22044092416763306, -0.3593981862068176]\n",
      "2200 steps | score: [0.24081526696681976, -0.38734015822410583]\n",
      "2300 steps | score: [0.22693806886672974, -0.38777032494544983]\n",
      "2400 steps | score: [0.13630859553813934, -0.1835419088602066]\n",
      "2500 steps | score: [0.2780296206474304, -0.47904977202415466]\n",
      "2600 steps | score: [0.16114863753318787, -0.22503119707107544]\n",
      "2700 steps | score: [0.15350162982940674, -0.21631291508674622]\n",
      "2800 steps | score: [0.22697031497955322, -0.3651009798049927]\n",
      "unknown params:  tensor([-0.4235,  0.0488, -0.7793,  0.2533, -0.0441, -0.1291])\n",
      "gt params:  tensor([-0.3993,  0.0426, -0.8021,  0.2491, -0.0266, -0.3425])\n",
      "ols params:  tensor([-0.1909,  0.0194, -0.3327,  0.1179, -0.0223,  2.8683])\n",
      "unknown mse:  tensor(0.0078)\n",
      "ols mse:  tensor(1.7652)\n",
      "gt params:  tensor([-4.1026e-01, -1.4466e-02, -8.0501e-01,  2.4227e-01,  6.4242e-04,\n",
      "        -3.1060e-01])\n",
      "0 steps | score: [0.4042665362358093]\n",
      "100 steps | score: [0.14322465658187866]\n",
      "200 steps | score: [0.07310990989208221]\n",
      "300 steps | score: [0.08499966561794281]\n",
      "400 steps | score: [0.09944695234298706]\n",
      "500 steps | score: [0.01467270776629448]\n",
      "600 steps | score: [0.06877914071083069]\n",
      "700 steps | score: [0.0839807391166687]\n",
      "800 steps | score: [0.0556475967168808]\n",
      "900 steps | score: [0.050099872052669525]\n",
      "1000 steps | score: [0.010758180171251297]\n",
      "1100 steps | score: [0.055632784962654114]\n",
      "1200 steps | score: [0.08168306946754456]\n",
      "1300 steps | score: [0.05195029824972153]\n",
      "1400 steps | score: [0.06794404238462448]\n",
      "1500 steps | score: [0.05164678394794464]\n",
      "1600 steps | score: [0.01034514605998993]\n",
      "1700 steps | score: [0.06183521822094917]\n",
      "1800 steps | score: [0.0670137107372284]\n",
      "1900 steps | score: [0.06966987252235413]\n",
      "2000 steps | score: [0.0752670019865036]\n",
      "2100 steps | score: [0.06855416297912598]\n",
      "2200 steps | score: [0.06071437895298004]\n",
      "2300 steps | score: [0.04425966739654541]\n",
      "2400 steps | score: [0.04425687715411186]\n",
      "2500 steps | score: [0.056962039321660995]\n",
      "2600 steps | score: [0.04213927686214447]\n",
      "2700 steps | score: [0.06642895936965942]\n",
      "2800 steps | score: [0.08452571928501129]\n",
      "0 steps | score: [0.37036237120628357, -0.5414872169494629]\n",
      "100 steps | score: [0.22828413546085358, -0.3643893897533417]\n",
      "200 steps | score: [0.3292217552661896, -0.61820387840271]\n",
      "300 steps | score: [0.2452315241098404, -0.5143819451332092]\n",
      "400 steps | score: [0.2566409111022949, -0.5329163074493408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [0.007939747534692287, -0.058048948645591736]\n",
      "600 steps | score: [0.16495901346206665, -0.3613843023777008]\n",
      "700 steps | score: [0.31905466318130493, -0.6847675442695618]\n",
      "800 steps | score: [0.06859961897134781, -0.17422328889369965]\n",
      "900 steps | score: [0.3005649149417877, -0.7179697751998901]\n",
      "1000 steps | score: [0.07580588757991791, -0.1900646686553955]\n",
      "1100 steps | score: [0.15053719282150269, -0.32578223943710327]\n",
      "1200 steps | score: [0.1434343308210373, -0.3179086446762085]\n",
      "1300 steps | score: [0.1591438204050064, -0.34984228014945984]\n",
      "1400 steps | score: [0.13949094712734222, -0.3293544054031372]\n",
      "1500 steps | score: [0.2425536960363388, -0.5313470363616943]\n",
      "1600 steps | score: [0.03834908828139305, -0.13609710335731506]\n",
      "1700 steps | score: [0.2296142876148224, -0.48832231760025024]\n",
      "1800 steps | score: [0.19867080450057983, -0.4371485710144043]\n",
      "1900 steps | score: [0.1650645136833191, -0.37366342544555664]\n",
      "2000 steps | score: [0.2578410804271698, -0.5728341341018677]\n",
      "2100 steps | score: [0.1297379732131958, -0.31824392080307007]\n",
      "2200 steps | score: [0.14677301049232483, -0.3129560351371765]\n",
      "2300 steps | score: [0.1784631460905075, -0.3962680697441101]\n",
      "2400 steps | score: [0.1158626452088356, -0.2764444947242737]\n",
      "2500 steps | score: [0.17648792266845703, -0.36754310131073]\n",
      "2600 steps | score: [0.12411029636859894, -0.2706068754196167]\n",
      "2700 steps | score: [0.16441279649734497, -0.379547119140625]\n",
      "2800 steps | score: [0.125991553068161, -0.2738399803638458]\n",
      "unknown params:  tensor([-0.3931,  0.0168, -0.8111,  0.2411, -0.0024, -0.0312])\n",
      "gt params:  tensor([-4.1026e-01, -1.4466e-02, -8.0501e-01,  2.4227e-01,  6.4242e-04,\n",
      "        -3.1060e-01])\n",
      "ols params:  tensor([-0.1751,  0.0069, -0.3368,  0.1086, -0.0056,  2.9620])\n",
      "unknown mse:  tensor(0.0132)\n",
      "ols mse:  tensor(1.8338)\n",
      "gt params:  tensor([-0.4047, -0.0026, -0.7958,  0.2647, -0.0250, -0.3277])\n",
      "0 steps | score: [0.3678267002105713]\n",
      "100 steps | score: [0.04662318527698517]\n",
      "200 steps | score: [0.07147029787302017]\n",
      "300 steps | score: [0.015541566535830498]\n",
      "400 steps | score: [0.022948140278458595]\n",
      "500 steps | score: [0.014866314828395844]\n",
      "600 steps | score: [0.07608486711978912]\n",
      "700 steps | score: [0.06488995254039764]\n",
      "800 steps | score: [0.04400734603404999]\n",
      "900 steps | score: [0.05289280787110329]\n",
      "1000 steps | score: [0.0194740928709507]\n",
      "1100 steps | score: [0.04868074879050255]\n",
      "1200 steps | score: [0.07942545413970947]\n",
      "1300 steps | score: [0.06426673382520676]\n",
      "1400 steps | score: [0.043403856456279755]\n",
      "1500 steps | score: [0.03807444870471954]\n",
      "1600 steps | score: [0.036265790462493896]\n",
      "1700 steps | score: [0.052757956087589264]\n",
      "1800 steps | score: [0.0736619085073471]\n",
      "1900 steps | score: [0.04743459075689316]\n",
      "2000 steps | score: [0.03853931650519371]\n",
      "2100 steps | score: [0.03339701145887375]\n",
      "2200 steps | score: [0.06874552369117737]\n",
      "2300 steps | score: [0.07743039727210999]\n",
      "2400 steps | score: [0.053404971957206726]\n",
      "2500 steps | score: [0.05819566547870636]\n",
      "2600 steps | score: [0.06527886539697647]\n",
      "2700 steps | score: [0.0455862395465374]\n",
      "2800 steps | score: [0.057927098125219345]\n",
      "0 steps | score: [0.29206523299217224, -0.3757556080818176]\n",
      "100 steps | score: [0.3235744535923004, -0.5555455088615417]\n",
      "200 steps | score: [0.2443571835756302, -0.44057995080947876]\n",
      "300 steps | score: [0.0009606076637282968, -0.006516203284263611]\n",
      "unknown params:  tensor([-0.3887, -0.0569, -0.6666,  0.2924,  0.0062,  0.0752])\n",
      "gt params:  tensor([-0.4047, -0.0026, -0.7958,  0.2647, -0.0250, -0.3277])\n",
      "ols params:  tensor([-0.1985, -0.0211, -0.3457,  0.1368, -0.0106,  3.0280])\n",
      "unknown mse:  tensor(0.0307)\n",
      "ols mse:  tensor(1.9205)\n",
      "gt params:  tensor([-0.3767, -0.0180, -0.8076,  0.2643, -0.0174, -0.3363])\n",
      "0 steps | score: [0.18061557412147522]\n",
      "100 steps | score: [-0.11600880324840546]\n",
      "200 steps | score: [-0.09376613050699234]\n",
      "300 steps | score: [-0.1439543068408966]\n",
      "400 steps | score: [-0.14691096544265747]\n",
      "500 steps | score: [-0.18163272738456726]\n",
      "600 steps | score: [-0.1551530659198761]\n",
      "700 steps | score: [-0.14534656703472137]\n",
      "800 steps | score: [-0.13263508677482605]\n",
      "900 steps | score: [-0.13662594556808472]\n",
      "1000 steps | score: [-0.15173651278018951]\n",
      "1100 steps | score: [-0.13987141847610474]\n",
      "1200 steps | score: [-0.13471020758152008]\n",
      "1300 steps | score: [-0.12461522966623306]\n",
      "1400 steps | score: [-0.15098071098327637]\n",
      "1500 steps | score: [-0.16679884493350983]\n",
      "1600 steps | score: [-0.15744951367378235]\n",
      "1700 steps | score: [-0.1461133062839508]\n",
      "1800 steps | score: [-0.1130744218826294]\n",
      "1900 steps | score: [-0.1537465751171112]\n",
      "2000 steps | score: [-0.15779946744441986]\n",
      "2100 steps | score: [-0.15273244678974152]\n",
      "2200 steps | score: [-0.1497495025396347]\n",
      "2300 steps | score: [-0.15002626180648804]\n",
      "2400 steps | score: [-0.1547756791114807]\n",
      "2500 steps | score: [-0.17307205498218536]\n",
      "2600 steps | score: [-0.15051575005054474]\n",
      "2700 steps | score: [-0.16055800020694733]\n",
      "2800 steps | score: [-0.16152778267860413]\n",
      "0 steps | score: [0.1834767758846283, -0.264740914106369]\n",
      "100 steps | score: [0.21013107895851135, -0.4422260522842407]\n",
      "200 steps | score: [0.06485968083143234, -0.23856645822525024]\n",
      "300 steps | score: [0.07426582276821136, -0.2796361446380615]\n",
      "400 steps | score: [-0.08964993059635162, 0.062455907464027405]\n",
      "500 steps | score: [-0.10616707056760788, 0.09740592539310455]\n",
      "600 steps | score: [0.03580541908740997, -0.24008303880691528]\n",
      "700 steps | score: [-0.117775097489357, 0.0940728634595871]\n",
      "800 steps | score: [0.010756001807749271, -0.21336914598941803]\n",
      "900 steps | score: [-0.08942218869924545, 0.020639650523662567]\n",
      "1000 steps | score: [-0.00713207945227623, -0.12439197301864624]\n",
      "1100 steps | score: [0.045348383486270905, -0.246465265750885]\n",
      "1200 steps | score: [0.01339521910995245, -0.1754002571105957]\n",
      "1300 steps | score: [0.041087593883275986, -0.23651324212551117]\n",
      "1400 steps | score: [0.0060453834012150764, -0.13401854038238525]\n",
      "1500 steps | score: [-0.07487592101097107, 0.01849040389060974]\n",
      "1600 steps | score: [0.027717960998415947, -0.23444116115570068]\n",
      "1700 steps | score: [0.0033375993371009827, -0.16430002450942993]\n",
      "1800 steps | score: [0.009376518428325653, -0.18361376225948334]\n",
      "1900 steps | score: [-0.04402955621480942, -0.05715497210621834]\n",
      "2000 steps | score: [-0.01651694066822529, -0.12823010981082916]\n",
      "2100 steps | score: [2.998187301272992e-05, -0.1776229292154312]\n",
      "2200 steps | score: [-0.06054110825061798, -0.05645712465047836]\n",
      "2300 steps | score: [-0.02458789199590683, -0.08407577872276306]\n",
      "2400 steps | score: [0.03143344074487686, -0.22020544111728668]\n",
      "2500 steps | score: [-0.0002900776162277907, -0.13744445145130157]\n",
      "2600 steps | score: [-0.029994478449225426, -0.1019534170627594]\n",
      "2700 steps | score: [0.02547236531972885, -0.18417587876319885]\n",
      "2800 steps | score: [0.024029403924942017, -0.20420898497104645]\n",
      "unknown params:  tensor([-0.4148, -0.0538, -0.8125,  0.2670, -0.0247, -0.2921])\n",
      "gt params:  tensor([-0.3767, -0.0180, -0.8076,  0.2643, -0.0174, -0.3363])\n",
      "ols params:  tensor([-0.1839, -0.0255, -0.3390,  0.1210, -0.0151,  3.1371])\n",
      "unknown mse:  tensor(0.0008)\n",
      "ols mse:  tensor(2.0569)\n",
      "gt params:  tensor([-3.9051e-01, -1.5036e-02, -8.0121e-01,  2.5708e-01, -3.9338e-04,\n",
      "        -2.9614e-01])\n",
      "0 steps | score: [0.5012080073356628]\n",
      "100 steps | score: [0.18816836178302765]\n",
      "200 steps | score: [0.12739990651607513]\n",
      "300 steps | score: [0.184945747256279]\n",
      "400 steps | score: [0.14526182413101196]\n",
      "500 steps | score: [0.12353696674108505]\n",
      "600 steps | score: [0.1627184897661209]\n",
      "700 steps | score: [0.14357540011405945]\n",
      "800 steps | score: [0.13478319346904755]\n",
      "900 steps | score: [0.1529482752084732]\n",
      "1000 steps | score: [0.14306877553462982]\n",
      "1100 steps | score: [0.14425379037857056]\n",
      "1200 steps | score: [0.1660780906677246]\n",
      "1300 steps | score: [0.15830174088478088]\n",
      "1400 steps | score: [0.12461177259683609]\n",
      "1500 steps | score: [0.16747470200061798]\n",
      "1600 steps | score: [0.1751267910003662]\n",
      "1700 steps | score: [0.12671905755996704]\n",
      "1800 steps | score: [0.1716538965702057]\n",
      "1900 steps | score: [0.15329882502555847]\n",
      "2000 steps | score: [0.1743505448102951]\n",
      "2100 steps | score: [0.17953717708587646]\n",
      "2200 steps | score: [0.18010835349559784]\n",
      "2300 steps | score: [0.13275589048862457]\n",
      "2400 steps | score: [0.17077970504760742]\n",
      "2500 steps | score: [0.17250166833400726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600 steps | score: [0.16679608821868896]\n",
      "2700 steps | score: [0.1619119942188263]\n",
      "2800 steps | score: [0.15276481211185455]\n",
      "0 steps | score: [0.11026377975940704, 0.009622380137443542]\n",
      "100 steps | score: [0.42455968260765076, -0.8450320959091187]\n",
      "200 steps | score: [-0.23642244935035706, 0.5392616391181946]\n",
      "300 steps | score: [0.016205240041017532, -0.01360764354467392]\n",
      "400 steps | score: [-0.04730508476495743, 0.08660515397787094]\n",
      "500 steps | score: [-0.13777042925357819, 0.27611520886421204]\n",
      "600 steps | score: [-0.11691854149103165, 0.2449822872877121]\n",
      "700 steps | score: [-0.09745068103075027, 0.21937112510204315]\n",
      "800 steps | score: [-0.20544105768203735, 0.411138653755188]\n",
      "900 steps | score: [-0.283565878868103, 0.5762920379638672]\n",
      "1000 steps | score: [-0.03344748541712761, 0.05276702344417572]\n",
      "1100 steps | score: [-0.15894731879234314, 0.32402557134628296]\n",
      "1200 steps | score: [0.03561825305223465, -0.09935428202152252]\n",
      "1300 steps | score: [-0.02906826324760914, 0.03562460094690323]\n",
      "1400 steps | score: [-0.13008567690849304, 0.24649134278297424]\n",
      "1500 steps | score: [0.03418019413948059, -0.09054291248321533]\n",
      "1600 steps | score: [-0.04225028306245804, 0.05922906845808029]\n",
      "1700 steps | score: [-0.18492965400218964, 0.35124024748802185]\n",
      "1800 steps | score: [0.0051419553346931934, -0.04940374195575714]\n",
      "1900 steps | score: [-0.1329992264509201, 0.264749675989151]\n",
      "2000 steps | score: [-0.09701794385910034, 0.2005338817834854]\n",
      "2100 steps | score: [-0.12359123677015305, 0.21480920910835266]\n",
      "2200 steps | score: [-0.07997611910104752, 0.16518786549568176]\n",
      "2300 steps | score: [-0.08396703004837036, 0.1722756028175354]\n",
      "2400 steps | score: [-0.05752095580101013, 0.09679652750492096]\n",
      "2500 steps | score: [0.01876484602689743, -0.07935074716806412]\n",
      "2600 steps | score: [-0.10862120985984802, 0.21276377141475677]\n",
      "2700 steps | score: [-0.05028363689780235, 0.0799821987748146]\n",
      "2800 steps | score: [-0.0879356637597084, 0.1342797726392746]\n",
      "unknown params:  tensor([-0.3342, -0.0038, -0.7236,  0.2122,  0.0138,  0.1623])\n",
      "gt params:  tensor([-3.9051e-01, -1.5036e-02, -8.0121e-01,  2.5708e-01, -3.9338e-04,\n",
      "        -2.9614e-01])\n",
      "ols params:  tensor([-1.6471e-01, -5.0884e-04, -3.2676e-01,  1.0346e-01,  9.6944e-03,\n",
      "         3.3431e+00])\n",
      "unknown mse:  tensor(0.0369)\n",
      "ols mse:  tensor(2.2574)\n",
      "gt params:  tensor([-0.3897,  0.0410, -0.7964,  0.2376, -0.0167, -0.2895])\n",
      "0 steps | score: [0.33540692925453186]\n",
      "100 steps | score: [0.04987306892871857]\n",
      "200 steps | score: [0.04329972714185715]\n",
      "300 steps | score: [-0.02023443579673767]\n",
      "400 steps | score: [-0.018129106611013412]\n",
      "500 steps | score: [-0.013611894100904465]\n",
      "600 steps | score: [0.02824055776000023]\n",
      "700 steps | score: [0.071306973695755]\n",
      "800 steps | score: [0.017952969297766685]\n",
      "900 steps | score: [-0.012755312025547028]\n",
      "1000 steps | score: [0.031576547771692276]\n",
      "1100 steps | score: [0.030147412791848183]\n",
      "1200 steps | score: [0.03735886141657829]\n",
      "1300 steps | score: [0.018937887623906136]\n",
      "1400 steps | score: [-0.027447398751974106]\n",
      "1500 steps | score: [0.01155722327530384]\n",
      "1600 steps | score: [0.009380772709846497]\n",
      "0 steps | score: [0.20711740851402283, -0.26829105615615845]\n",
      "100 steps | score: [0.06572539359331131, -0.10421383380889893]\n",
      "200 steps | score: [0.04880538955330849, -0.11793990433216095]\n",
      "300 steps | score: [-0.03407762572169304, 0.017585769295692444]\n",
      "400 steps | score: [0.009320673532783985, -0.0607333779335022]\n",
      "500 steps | score: [0.1477118879556656, -0.3727912902832031]\n",
      "600 steps | score: [-0.03609851002693176, 0.030393779277801514]\n",
      "700 steps | score: [0.08341524749994278, -0.22642521560192108]\n",
      "800 steps | score: [0.04723276570439339, -0.17078940570354462]\n",
      "900 steps | score: [-0.11796483397483826, 0.18788650631904602]\n",
      "1000 steps | score: [0.16746361553668976, -0.42761653661727905]\n",
      "1100 steps | score: [-0.022758187726140022, -0.024603962898254395]\n",
      "1200 steps | score: [0.12783396244049072, -0.3357446789741516]\n",
      "1300 steps | score: [0.04351352900266647, -0.16861771047115326]\n",
      "1400 steps | score: [0.12173955142498016, -0.31889063119888306]\n",
      "1500 steps | score: [0.10850594192743301, -0.2969110608100891]\n",
      "1600 steps | score: [0.056436218321323395, -0.21657152473926544]\n",
      "1700 steps | score: [-0.09076933562755585, 0.0945286825299263]\n",
      "1800 steps | score: [0.06671672314405441, -0.19823259115219116]\n",
      "1900 steps | score: [0.046520791947841644, -0.16154319047927856]\n",
      "2000 steps | score: [0.08892430365085602, -0.2369493991136551]\n",
      "2100 steps | score: [0.05252833291888237, -0.19456563889980316]\n",
      "2200 steps | score: [-0.025964265689253807, -0.022601664066314697]\n",
      "2300 steps | score: [0.007163696922361851, -0.09091968834400177]\n",
      "2400 steps | score: [0.04769929125905037, -0.1720130443572998]\n",
      "2500 steps | score: [0.11584841459989548, -0.30692824721336365]\n",
      "2600 steps | score: [0.1477191001176834, -0.4342201352119446]\n",
      "2700 steps | score: [-0.0015443714801222086, -0.06289122998714447]\n",
      "2800 steps | score: [0.0009591453708708286, -0.09997722506523132]\n",
      "unknown params:  tensor([-0.3969,  0.0275, -0.6946,  0.2044, -0.0423,  0.0273])\n",
      "gt params:  tensor([-0.3897,  0.0410, -0.7964,  0.2376, -0.0167, -0.2895])\n",
      "ols params:  tensor([-0.1744,  0.0093, -0.2923,  0.0886, -0.0188,  3.4416])\n",
      "unknown mse:  tensor(0.0188)\n",
      "ols mse:  tensor(2.3742)\n",
      "gt params:  tensor([-0.3778,  0.0075, -0.8025,  0.2216,  0.0074, -0.3182])\n",
      "0 steps | score: [0.23832397162914276]\n",
      "100 steps | score: [-0.07857391983270645]\n",
      "200 steps | score: [-0.0953029915690422]\n",
      "300 steps | score: [-0.06948606669902802]\n",
      "400 steps | score: [-0.10696413367986679]\n",
      "500 steps | score: [-0.09601730108261108]\n",
      "600 steps | score: [-0.0935380831360817]\n",
      "700 steps | score: [-0.063340924680233]\n",
      "800 steps | score: [-0.09801474958658218]\n",
      "900 steps | score: [-0.07868511229753494]\n",
      "1000 steps | score: [-0.10750395059585571]\n",
      "1100 steps | score: [-0.09303232282400131]\n",
      "1200 steps | score: [-0.08716762810945511]\n",
      "1300 steps | score: [-0.07566450536251068]\n",
      "1400 steps | score: [-0.08047188073396683]\n",
      "1500 steps | score: [-0.11284548789262772]\n",
      "1600 steps | score: [-0.08224360644817352]\n",
      "1700 steps | score: [-0.10555785149335861]\n",
      "1800 steps | score: [-0.07546933740377426]\n",
      "1900 steps | score: [-0.0764903873205185]\n",
      "2000 steps | score: [-0.10961730778217316]\n",
      "2100 steps | score: [-0.11094678938388824]\n",
      "2200 steps | score: [-0.08582107722759247]\n",
      "2300 steps | score: [-0.1190698891878128]\n",
      "2400 steps | score: [-0.12922438979148865]\n",
      "2500 steps | score: [-0.12330233305692673]\n",
      "2600 steps | score: [-0.07178781926631927]\n",
      "2700 steps | score: [-0.09620679914951324]\n",
      "2800 steps | score: [-0.07345563173294067]\n",
      "0 steps | score: [0.13568846881389618, 0.10596347600221634]\n",
      "100 steps | score: [-0.0714460015296936, 0.391409695148468]\n",
      "200 steps | score: [-0.17081652581691742, 0.5119000673294067]\n",
      "300 steps | score: [-0.05808347091078758, 0.2530076205730438]\n",
      "400 steps | score: [-0.14514893293380737, 0.43953242897987366]\n",
      "500 steps | score: [-0.026135869324207306, 0.16822880506515503]\n",
      "600 steps | score: [-0.1875384896993637, 0.5085992217063904]\n",
      "700 steps | score: [0.04689137637615204, 0.026844050735235214]\n",
      "800 steps | score: [-0.22608472406864166, 0.5836465358734131]\n",
      "900 steps | score: [-0.044631149619817734, 0.23212924599647522]\n",
      "1000 steps | score: [-0.09033568948507309, 0.29558131098747253]\n",
      "1100 steps | score: [-0.10740305483341217, 0.3566124439239502]\n",
      "1200 steps | score: [0.10497575253248215, -0.13363245129585266]\n",
      "1300 steps | score: [0.20809170603752136, -0.4043380320072174]\n",
      "1400 steps | score: [0.14652569591999054, -0.23621711134910583]\n",
      "1500 steps | score: [-0.10949081927537918, 0.328963041305542]\n",
      "1600 steps | score: [-0.029042724519968033, 0.18466344475746155]\n",
      "1700 steps | score: [-0.12690001726150513, 0.3858944773674011]\n",
      "1800 steps | score: [-0.04445484280586243, 0.20318017899990082]\n",
      "1900 steps | score: [-0.03340340033173561, 0.22207599878311157]\n",
      "2000 steps | score: [-0.027119090780615807, 0.14276331663131714]\n",
      "2100 steps | score: [0.00044591049663722515, 0.12409719824790955]\n",
      "2200 steps | score: [0.012704003602266312, 0.07177369296550751]\n",
      "2300 steps | score: [-0.052346959710121155, 0.21071623265743256]\n",
      "2400 steps | score: [-0.007237075828015804, 0.13876186311244965]\n",
      "2500 steps | score: [-0.0633866935968399, 0.21189311146736145]\n",
      "2600 steps | score: [-0.09079627692699432, 0.28688400983810425]\n",
      "2700 steps | score: [-0.024907510727643967, 0.1518823206424713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800 steps | score: [-0.04189058765769005, 0.19184525310993195]\n",
      "unknown params:  tensor([-0.3624, -0.0218, -0.8362,  0.2562, -0.0299, -0.1638])\n",
      "gt params:  tensor([-0.3778,  0.0075, -0.8025,  0.2216,  0.0074, -0.3182])\n",
      "ols params:  tensor([-0.1542, -0.0050, -0.3311,  0.1082, -0.0151,  3.4552])\n",
      "unknown mse:  tensor(0.0048)\n",
      "ols mse:  tensor(2.4207)\n",
      "gt params:  tensor([-0.4016,  0.0226, -0.7992,  0.1949,  0.0060, -0.3303])\n",
      "0 steps | score: [0.419222354888916]\n",
      "100 steps | score: [0.11287261545658112]\n",
      "200 steps | score: [0.040379006415605545]\n",
      "300 steps | score: [0.046829771250486374]\n",
      "400 steps | score: [0.046267151832580566]\n",
      "500 steps | score: [0.11808010935783386]\n",
      "600 steps | score: [0.07151833176612854]\n",
      "700 steps | score: [0.07033024728298187]\n",
      "800 steps | score: [0.037105973809957504]\n",
      "900 steps | score: [0.05580461025238037]\n",
      "1000 steps | score: [0.09077541530132294]\n",
      "1100 steps | score: [0.10335104167461395]\n",
      "1200 steps | score: [0.05034608393907547]\n",
      "1300 steps | score: [0.042679399251937866]\n",
      "1400 steps | score: [0.0760030597448349]\n",
      "1500 steps | score: [0.09289862215518951]\n",
      "1600 steps | score: [0.08749224245548248]\n",
      "1700 steps | score: [0.06259603798389435]\n",
      "1800 steps | score: [0.04887090623378754]\n",
      "1900 steps | score: [0.05915267765522003]\n",
      "2000 steps | score: [0.06812597811222076]\n",
      "2100 steps | score: [0.07028251886367798]\n",
      "2200 steps | score: [0.08468562364578247]\n",
      "2300 steps | score: [0.03211340680718422]\n",
      "2400 steps | score: [0.07045672833919525]\n",
      "2500 steps | score: [0.0759444534778595]\n",
      "2600 steps | score: [0.0821293294429779]\n",
      "2700 steps | score: [0.05870502069592476]\n",
      "2800 steps | score: [0.056439902633428574]\n",
      "0 steps | score: [0.04287661612033844, 0.2753105163574219]\n",
      "100 steps | score: [-0.28850674629211426, 0.7799278497695923]\n",
      "200 steps | score: [-0.17147262394428253, 0.5127860903739929]\n",
      "300 steps | score: [-0.22488906979560852, 0.5792527198791504]\n",
      "400 steps | score: [-0.18557751178741455, 0.47498536109924316]\n",
      "500 steps | score: [-0.1276523917913437, 0.3593581020832062]\n",
      "600 steps | score: [-0.2277982532978058, 0.5619946718215942]\n",
      "700 steps | score: [-0.15133421123027802, 0.42434805631637573]\n",
      "800 steps | score: [-0.0725574642419815, 0.22701042890548706]\n",
      "900 steps | score: [0.04574282839894295, -0.000132732093334198]\n",
      "1000 steps | score: [-0.061832282692193985, 0.1659163534641266]\n",
      "1100 steps | score: [-0.062491219490766525, 0.20179501175880432]\n",
      "1200 steps | score: [-0.10028152912855148, 0.2977771461009979]\n",
      "1300 steps | score: [-0.22598765790462494, 0.5630905032157898]\n",
      "1400 steps | score: [-0.11692957580089569, 0.2834411561489105]\n",
      "1500 steps | score: [-0.12731462717056274, 0.3417559564113617]\n",
      "1600 steps | score: [-0.14155665040016174, 0.37844765186309814]\n",
      "1700 steps | score: [-0.19133643805980682, 0.5051431655883789]\n",
      "1800 steps | score: [-0.1118561327457428, 0.32599174976348877]\n",
      "1900 steps | score: [-0.10401531308889389, 0.31398963928222656]\n",
      "2000 steps | score: [-0.1597883254289627, 0.40767210721969604]\n",
      "2100 steps | score: [-0.16525334119796753, 0.45620954036712646]\n",
      "2200 steps | score: [-0.11818859726190567, 0.3140009641647339]\n",
      "2300 steps | score: [-0.2271413505077362, 0.5441721081733704]\n",
      "2400 steps | score: [0.007726243697106838, 0.04588678479194641]\n",
      "2500 steps | score: [-0.14418497681617737, 0.3473440706729889]\n",
      "2600 steps | score: [-0.16043010354042053, 0.39527231454849243]\n",
      "2700 steps | score: [-0.21252745389938354, 0.48704975843429565]\n",
      "2800 steps | score: [-0.1642800122499466, 0.4095943868160248]\n",
      "unknown params:  tensor([-0.4448, -0.0016, -0.8922,  0.2508, -0.0274, -0.2984])\n",
      "gt params:  tensor([-0.4016,  0.0226, -0.7992,  0.1949,  0.0060, -0.3303])\n",
      "ols params:  tensor([-1.7023e-01,  7.4449e-04, -3.1891e-01,  9.7005e-02, -1.0551e-02,\n",
      "         3.5278e+00])\n",
      "unknown mse:  tensor(0.0027)\n",
      "ols mse:  tensor(2.5299)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/1d664f51-b2e9-40ad-b274-625b5351f9b9\n",
      "gt params:  tensor([-0.8473,  0.5849, -0.6700, -0.3912, -0.4120,  0.7013])\n",
      "0 steps | score: [0.04736439138650894]\n",
      "100 steps | score: [-0.05200531333684921]\n",
      "200 steps | score: [-0.13146823644638062]\n",
      "300 steps | score: [-0.07422516494989395]\n",
      "400 steps | score: [-0.032439518719911575]\n",
      "500 steps | score: [0.09274337440729141]\n",
      "600 steps | score: [-0.06837017834186554]\n",
      "700 steps | score: [-0.04449573904275894]\n",
      "800 steps | score: [-0.12264059484004974]\n",
      "900 steps | score: [-0.04338332638144493]\n",
      "1000 steps | score: [-0.017651638016104698]\n",
      "1100 steps | score: [0.05035807937383652]\n",
      "1200 steps | score: [-0.048834413290023804]\n",
      "1300 steps | score: [-0.017998553812503815]\n",
      "1400 steps | score: [-0.08525805920362473]\n",
      "1500 steps | score: [-0.055102452635765076]\n",
      "1600 steps | score: [-0.0823478102684021]\n",
      "1700 steps | score: [0.0022016093134880066]\n",
      "0 steps | score: [-0.22632865607738495, 0.741115927696228]\n",
      "100 steps | score: [0.7431371808052063, -1.3152399063110352]\n",
      "200 steps | score: [-2.2776639461517334, 9.632284164428711]\n",
      "300 steps | score: [-2.5240840911865234, 10.078438758850098]\n",
      "400 steps | score: [0.3341638147830963, 0.14358535408973694]\n",
      "500 steps | score: [45.188316345214844, -1363.2449951171875]\n",
      "600 steps | score: [-0.5015178322792053, 3.7069149017333984]\n",
      "700 steps | score: [1.5654939413070679, -7.79987907409668]\n",
      "800 steps | score: [-0.7710564732551575, 4.182464122772217]\n",
      "900 steps | score: [-0.21750496327877045, 0.7069030404090881]\n",
      "1000 steps | score: [-0.7473533153533936, 3.2267818450927734]\n",
      "1100 steps | score: [0.18731944262981415, -1.931160807609558]\n",
      "1200 steps | score: [-0.49570512771606445, 1.818772554397583]\n",
      "1300 steps | score: [0.4836084246635437, -4.348508358001709]\n",
      "1400 steps | score: [-0.2125435471534729, 0.15985850989818573]\n",
      "1500 steps | score: [-0.36449724435806274, 0.9550784826278687]\n",
      "1600 steps | score: [-0.39262887835502625, 1.0537571907043457]\n",
      "1700 steps | score: [-0.3125995397567749, 0.7000768780708313]\n",
      "1800 steps | score: [-0.31305649876594543, 0.711371898651123]\n",
      "1900 steps | score: [-0.2720133364200592, 0.4802018404006958]\n",
      "2000 steps | score: [-0.14574630558490753, -0.3903253674507141]\n",
      "2100 steps | score: [-0.2776954472064972, 0.4046008884906769]\n",
      "2200 steps | score: [-0.3849698305130005, 0.9838926792144775]\n",
      "2300 steps | score: [-0.25993582606315613, 0.3464454114437103]\n",
      "2400 steps | score: [-0.2724711000919342, 0.4499503970146179]\n",
      "2500 steps | score: [-0.42973998188972473, 1.3407378196716309]\n",
      "2600 steps | score: [-0.27281439304351807, 0.22834748029708862]\n",
      "2700 steps | score: [-0.2739713490009308, 0.34121599793434143]\n",
      "2800 steps | score: [-0.25692617893218994, 0.37486663460731506]\n",
      "unknown params:  tensor([-0.8163,  0.5665, -0.6396, -0.3774, -0.4009,  0.4755])\n",
      "gt params:  tensor([-0.8473,  0.5849, -0.6700, -0.3912, -0.4120,  0.7013])\n",
      "ols params:  tensor([-0.7756,  0.5394, -0.6115, -0.3608, -0.3825,  1.0915])\n",
      "unknown mse:  tensor(0.0089)\n",
      "ols mse:  tensor(0.0274)\n",
      "gt params:  tensor([-0.8523,  0.5839, -0.6725, -0.3995, -0.4185,  0.7043])\n",
      "0 steps | score: [0.036114320158958435]\n",
      "100 steps | score: [-0.1069774478673935]\n",
      "200 steps | score: [-0.0583670474588871]\n",
      "300 steps | score: [-0.06463402509689331]\n",
      "400 steps | score: [-0.08748908340930939]\n",
      "500 steps | score: [0.016134178265929222]\n",
      "600 steps | score: [-0.09774023294448853]\n",
      "700 steps | score: [-0.14076337218284607]\n",
      "800 steps | score: [-0.039122406393289566]\n",
      "900 steps | score: [-0.10268912464380264]\n",
      "1000 steps | score: [-0.10207819193601608]\n",
      "1100 steps | score: [-0.06777869164943695]\n",
      "1200 steps | score: [-0.10801126062870026]\n",
      "1300 steps | score: [-0.12220137566328049]\n",
      "1400 steps | score: [-0.06390269845724106]\n",
      "1500 steps | score: [-0.10737458616495132]\n",
      "1600 steps | score: [-0.08474452793598175]\n",
      "1700 steps | score: [-0.05793920159339905]\n",
      "1800 steps | score: [-0.07220504432916641]\n",
      "1900 steps | score: [-0.11870945990085602]\n",
      "2000 steps | score: [-0.08833026885986328]\n",
      "2100 steps | score: [-0.09262405335903168]\n",
      "2200 steps | score: [-0.1011366993188858]\n",
      "2300 steps | score: [-0.08215503394603729]\n",
      "2400 steps | score: [-0.0950654074549675]\n",
      "2500 steps | score: [-0.09137623012065887]\n",
      "2600 steps | score: [-0.08502194285392761]\n",
      "2700 steps | score: [-0.09460325539112091]\n",
      "2800 steps | score: [-0.06368789076805115]\n",
      "0 steps | score: [0.10962232947349548, 0.13433824479579926]\n",
      "100 steps | score: [-0.12185690551996231, 0.7686108350753784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [-0.23387567698955536, 1.1977767944335938]\n",
      "300 steps | score: [-0.16083864867687225, 0.7710434794425964]\n",
      "400 steps | score: [-0.10452906042337418, 0.5821171402931213]\n",
      "500 steps | score: [-0.33913496136665344, 1.4512335062026978]\n",
      "600 steps | score: [0.1439819633960724, -0.5973935723304749]\n",
      "700 steps | score: [0.027985451743006706, -0.08208911120891571]\n",
      "800 steps | score: [0.243723526597023, -0.8060511350631714]\n",
      "900 steps | score: [0.10096870362758636, -0.3662123680114746]\n",
      "1000 steps | score: [-0.2983555495738983, 1.2661266326904297]\n",
      "1100 steps | score: [-0.024601874873042107, 0.1086258590221405]\n",
      "1200 steps | score: [0.0625622421503067, -0.2699838876724243]\n",
      "1300 steps | score: [-0.04558979347348213, 0.23476403951644897]\n",
      "1400 steps | score: [0.029745198786258698, 0.03820271044969559]\n",
      "1500 steps | score: [0.20438380539417267, -0.7545678615570068]\n",
      "1600 steps | score: [-0.06952200084924698, 0.2980802655220032]\n",
      "1700 steps | score: [-0.021353857591748238, 0.18216201663017273]\n",
      "1800 steps | score: [-0.01740444265305996, 0.09375713020563126]\n",
      "1900 steps | score: [-0.20338404178619385, 0.8814277648925781]\n",
      "2000 steps | score: [-0.12441398203372955, 0.6452093124389648]\n",
      "2100 steps | score: [-0.09282717853784561, 0.4653351306915283]\n",
      "2200 steps | score: [0.10537086427211761, -0.3961484432220459]\n",
      "2300 steps | score: [-0.16837365925312042, 0.7240886092185974]\n",
      "2400 steps | score: [-0.0016084716189652681, 0.12294399738311768]\n",
      "2500 steps | score: [0.00854406226426363, 0.05369216203689575]\n",
      "2600 steps | score: [-0.08181115239858627, 0.3732874095439911]\n",
      "2700 steps | score: [-0.05961747467517853, 0.311286985874176]\n",
      "2800 steps | score: [-0.028265388682484627, 0.15885697305202484]\n",
      "unknown params:  tensor([-0.8446,  0.5769, -0.6612, -0.4024, -0.4150,  0.6320])\n",
      "gt params:  tensor([-0.8523,  0.5839, -0.6725, -0.3995, -0.4185,  0.7043])\n",
      "ols params:  tensor([-0.7223,  0.4978, -0.5743, -0.3498, -0.3637,  1.4160])\n",
      "unknown mse:  tensor(0.0009)\n",
      "ols mse:  tensor(0.0910)\n",
      "gt params:  tensor([-0.8529,  0.5860, -0.6614, -0.3904, -0.4251,  0.6947])\n",
      "0 steps | score: [0.2372198849916458]\n",
      "100 steps | score: [0.09955055266618729]\n",
      "200 steps | score: [0.07007584720849991]\n",
      "300 steps | score: [0.08588947355747223]\n",
      "400 steps | score: [0.08204452693462372]\n",
      "500 steps | score: [0.0687626376748085]\n",
      "600 steps | score: [0.06885342299938202]\n",
      "700 steps | score: [0.025423364713788033]\n",
      "800 steps | score: [0.06477421522140503]\n",
      "900 steps | score: [0.04928252100944519]\n",
      "1000 steps | score: [0.04495900869369507]\n",
      "1100 steps | score: [0.05455968156456947]\n",
      "1200 steps | score: [0.05485352873802185]\n",
      "1300 steps | score: [0.0727129578590393]\n",
      "1400 steps | score: [0.0975596159696579]\n",
      "1500 steps | score: [0.02587820217013359]\n",
      "1600 steps | score: [0.0683351382613182]\n",
      "1700 steps | score: [0.055364325642585754]\n",
      "1800 steps | score: [0.03386911749839783]\n",
      "1900 steps | score: [0.04683090001344681]\n",
      "2000 steps | score: [0.05978963524103165]\n",
      "2100 steps | score: [0.06812433153390884]\n",
      "2200 steps | score: [0.053290318697690964]\n",
      "2300 steps | score: [0.07301681488752365]\n",
      "2400 steps | score: [0.029352623969316483]\n",
      "2500 steps | score: [0.07912333309650421]\n",
      "2600 steps | score: [0.09409650415182114]\n",
      "2700 steps | score: [0.06125655025243759]\n",
      "2800 steps | score: [0.06101136654615402]\n",
      "0 steps | score: [0.043298013508319855, 0.17156410217285156]\n",
      "100 steps | score: [-0.22795115411281586, 0.9015360474586487]\n",
      "200 steps | score: [0.10632078349590302, -0.4521208703517914]\n",
      "300 steps | score: [0.23106156289577484, -1.00711190700531]\n",
      "400 steps | score: [0.13515038788318634, -0.683989405632019]\n",
      "500 steps | score: [-0.3406161367893219, 1.159608244895935]\n",
      "600 steps | score: [-0.422689825296402, 1.4820654392242432]\n",
      "700 steps | score: [-0.09436008334159851, 0.23015734553337097]\n",
      "800 steps | score: [-0.04422082379460335, 0.02600189298391342]\n",
      "900 steps | score: [-0.23066306114196777, 0.7874610424041748]\n",
      "1000 steps | score: [-0.11334984004497528, 0.32327955961227417]\n",
      "1100 steps | score: [0.15356141328811646, -0.8126591444015503]\n",
      "1200 steps | score: [-0.09600874781608582, 0.299482524394989]\n",
      "1300 steps | score: [-0.030337821692228317, 0.03805803507566452]\n",
      "1400 steps | score: [-0.08277663588523865, 0.19417007267475128]\n",
      "1500 steps | score: [-0.060223694890737534, 0.15750987827777863]\n",
      "1600 steps | score: [-0.11584634333848953, 0.35072243213653564]\n",
      "1700 steps | score: [0.11140754818916321, -0.6334201097488403]\n",
      "1800 steps | score: [-0.1708909124135971, 0.559045672416687]\n",
      "1900 steps | score: [-0.08278720080852509, 0.22182391583919525]\n",
      "2000 steps | score: [-0.12511658668518066, 0.39151158928871155]\n",
      "2100 steps | score: [-0.008235814049839973, -0.10538987070322037]\n",
      "2200 steps | score: [-0.06384249776601791, 0.14639006555080414]\n",
      "2300 steps | score: [0.03197288513183594, -0.2105949968099594]\n",
      "2400 steps | score: [-0.10047493129968643, 0.23703688383102417]\n",
      "2500 steps | score: [-0.02547094225883484, -0.12121038138866425]\n",
      "2600 steps | score: [-0.01403728872537613, -0.08128562569618225]\n",
      "2700 steps | score: [-0.12106606364250183, 0.32993143796920776]\n",
      "2800 steps | score: [0.027919333428144455, -0.21392692625522614]\n",
      "unknown params:  tensor([-0.8471,  0.5777, -0.6558, -0.3795, -0.4301,  0.6727])\n",
      "gt params:  tensor([-0.8529,  0.5860, -0.6614, -0.3904, -0.4251,  0.6947])\n",
      "ols params:  tensor([-0.6773,  0.4685, -0.5309, -0.3076, -0.3499,  1.6946])\n",
      "unknown mse:  tensor(0.0001)\n",
      "ols mse:  tensor(0.1790)\n",
      "gt params:  tensor([-0.8532,  0.5807, -0.6785, -0.3860, -0.4201,  0.7200])\n",
      "0 steps | score: [0.1661314070224762]\n",
      "100 steps | score: [-0.019365303218364716]\n",
      "200 steps | score: [0.11789072304964066]\n",
      "300 steps | score: [-0.06353475153446198]\n",
      "400 steps | score: [0.03771595284342766]\n",
      "500 steps | score: [0.015967000275850296]\n",
      "600 steps | score: [-0.021085722371935844]\n",
      "700 steps | score: [-0.0013111368753015995]\n",
      "0 steps | score: [0.2044445425271988, -0.23748552799224854]\n",
      "100 steps | score: [-0.028435390442609787, 0.2374877631664276]\n",
      "200 steps | score: [0.05970282107591629, -0.021403655409812927]\n",
      "300 steps | score: [0.038286108523607254, -0.06073285639286041]\n",
      "400 steps | score: [-0.07312607020139694, 0.293343722820282]\n",
      "500 steps | score: [-0.3502439856529236, 1.0053133964538574]\n",
      "600 steps | score: [-0.08101360499858856, 0.33634787797927856]\n",
      "700 steps | score: [0.19687967002391815, -0.5457906126976013]\n",
      "800 steps | score: [-0.11295571178197861, 0.37485748529434204]\n",
      "900 steps | score: [-0.05344683304429054, 0.2179315686225891]\n",
      "1000 steps | score: [-0.00508479168638587, 0.02050340175628662]\n",
      "1100 steps | score: [0.1625528782606125, -0.4645059406757355]\n",
      "1200 steps | score: [0.004327182658016682, 0.059537261724472046]\n",
      "1300 steps | score: [0.0023844423703849316, 0.0479855090379715]\n",
      "1400 steps | score: [0.0038442229852080345, 0.0270521342754364]\n",
      "1500 steps | score: [0.13585972785949707, -0.38725385069847107]\n",
      "1600 steps | score: [0.06586923450231552, -0.1589985191822052]\n",
      "1700 steps | score: [0.13742245733737946, -0.34576088190078735]\n",
      "1800 steps | score: [0.012321840971708298, 0.024545341730117798]\n",
      "1900 steps | score: [0.19910739362239838, -0.5530850291252136]\n",
      "2000 steps | score: [0.019504206255078316, 0.005747184157371521]\n",
      "2100 steps | score: [0.16357582807540894, -0.44023704528808594]\n",
      "2200 steps | score: [0.07155675441026688, -0.17371317744255066]\n",
      "2300 steps | score: [0.04352659359574318, -0.07055748999118805]\n",
      "2400 steps | score: [0.04886684939265251, -0.08518609404563904]\n",
      "2500 steps | score: [0.10233690589666367, -0.2623165249824524]\n",
      "2600 steps | score: [0.08814078569412231, -0.21288052201271057]\n",
      "2700 steps | score: [-0.018359191715717316, 0.08332422375679016]\n",
      "2800 steps | score: [0.04585068300366402, -0.10671922564506531]\n",
      "unknown params:  tensor([-0.8545,  0.5830, -0.6845, -0.3879, -0.4249,  0.5994])\n",
      "gt params:  tensor([-0.8532,  0.5807, -0.6785, -0.3860, -0.4201,  0.7200])\n",
      "ols params:  tensor([-0.6407,  0.4473, -0.5197, -0.2975, -0.3272,  1.9412])\n",
      "unknown mse:  tensor(0.0024)\n",
      "ols mse:  tensor(0.2660)\n",
      "gt params:  tensor([-0.8401,  0.5829, -0.6689, -0.3855, -0.4263,  0.6576])\n",
      "0 steps | score: [0.19668470323085785]\n",
      "100 steps | score: [-0.02828122116625309]\n",
      "200 steps | score: [-0.0016183853149414062]\n",
      "0 steps | score: [0.11416874825954437, -0.08508571982383728]\n",
      "100 steps | score: [0.10855143517255783, -0.3990679085254669]\n",
      "200 steps | score: [-0.17574413120746613, 0.46164679527282715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 steps | score: [0.024079052731394768, -0.19318196177482605]\n",
      "400 steps | score: [-0.138545960187912, 0.2525191009044647]\n",
      "500 steps | score: [-0.08758985996246338, 0.193384051322937]\n",
      "600 steps | score: [-0.16969527304172516, 0.36659926176071167]\n",
      "700 steps | score: [0.01643296517431736, -0.18240736424922943]\n",
      "800 steps | score: [-0.06733401864767075, 0.04874211549758911]\n",
      "900 steps | score: [-0.06886853277683258, 0.051902443170547485]\n",
      "1000 steps | score: [-0.3033653199672699, 0.739940881729126]\n",
      "1100 steps | score: [-0.030928969383239746, -0.032556384801864624]\n",
      "1200 steps | score: [0.20786994695663452, -0.8556973338127136]\n",
      "1300 steps | score: [-0.10387713462114334, 0.17590729892253876]\n",
      "1400 steps | score: [-0.028185592964291573, -0.05362895131111145]\n",
      "1500 steps | score: [-0.14784184098243713, 0.26546669006347656]\n",
      "1600 steps | score: [0.022887106984853745, -0.22941814363002777]\n",
      "1700 steps | score: [-0.03378535434603691, -0.041788771748542786]\n",
      "1800 steps | score: [0.04300835728645325, -0.34548503160476685]\n",
      "1900 steps | score: [-0.06006238982081413, 0.03180009126663208]\n",
      "2000 steps | score: [-0.009382334537804127, -0.11674182116985321]\n",
      "2100 steps | score: [0.007219710852950811, -0.20741654932498932]\n",
      "2200 steps | score: [-0.07309640198945999, 0.04970140755176544]\n",
      "2300 steps | score: [-0.059732165187597275, 0.006521567702293396]\n",
      "2400 steps | score: [-0.11705785989761353, 0.20579597353935242]\n",
      "2500 steps | score: [-0.10068828612565994, 0.13544955849647522]\n",
      "2600 steps | score: [0.053614988923072815, -0.32614314556121826]\n",
      "2700 steps | score: [-0.10458173602819443, 0.13739217817783356]\n",
      "2800 steps | score: [-0.06561785191297531, 0.04638700187206268]\n",
      "unknown params:  tensor([-0.8333,  0.5856, -0.6617, -0.3705, -0.4208,  0.5254])\n",
      "gt params:  tensor([-0.8401,  0.5829, -0.6689, -0.3855, -0.4263,  0.6576])\n",
      "ols params:  tensor([-0.6022,  0.4306, -0.4868, -0.2752, -0.3150,  2.1242])\n",
      "unknown mse:  tensor(0.0030)\n",
      "ols mse:  tensor(0.3814)\n",
      "gt params:  tensor([-0.8552,  0.5987, -0.6679, -0.4021, -0.4201,  0.6722])\n",
      "0 steps | score: [0.21597245335578918]\n",
      "100 steps | score: [0.018366044387221336]\n",
      "200 steps | score: [0.09104893356561661]\n",
      "300 steps | score: [0.007694605737924576]\n",
      "0 steps | score: [-0.07604428380727768, 0.7031214833259583]\n",
      "100 steps | score: [0.04488877207040787, -0.056200332939624786]\n",
      "200 steps | score: [-0.25275781750679016, 0.8901976346969604]\n",
      "300 steps | score: [-0.5280302166938782, 1.5793061256408691]\n",
      "400 steps | score: [-0.5512064099311829, 1.6723791360855103]\n",
      "500 steps | score: [-0.27228742837905884, 0.8615549206733704]\n",
      "600 steps | score: [-0.05173775553703308, 0.17522183060646057]\n",
      "700 steps | score: [-0.147496297955513, 0.46234938502311707]\n",
      "800 steps | score: [-0.33546382188796997, 1.0632116794586182]\n",
      "900 steps | score: [-0.3117689788341522, 0.9272893071174622]\n",
      "1000 steps | score: [-0.2394687980413437, 0.7328267097473145]\n",
      "1100 steps | score: [-0.3943191468715668, 1.2096036672592163]\n",
      "1200 steps | score: [-0.1385764628648758, 0.4451886713504791]\n",
      "1300 steps | score: [-0.41882097721099854, 1.2660883665084839]\n",
      "1400 steps | score: [-0.21253252029418945, 0.6475984454154968]\n",
      "1500 steps | score: [-0.2701447010040283, 0.8416756391525269]\n",
      "1600 steps | score: [-0.23748517036437988, 0.7170177698135376]\n",
      "1700 steps | score: [-0.2090497761964798, 0.6833930015563965]\n",
      "1800 steps | score: [-0.16067323088645935, 0.4482017457485199]\n",
      "1900 steps | score: [-0.04498419165611267, 0.1455794870853424]\n",
      "2000 steps | score: [-0.20417152345180511, 0.6146811246871948]\n",
      "2100 steps | score: [-0.2568018138408661, 0.7968056201934814]\n",
      "2200 steps | score: [-0.08439269661903381, 0.24995636940002441]\n",
      "2300 steps | score: [-0.24948996305465698, 0.7635613083839417]\n",
      "2400 steps | score: [-0.1466856747865677, 0.4324435591697693]\n",
      "2500 steps | score: [-0.3008447587490082, 0.9358549118041992]\n",
      "2600 steps | score: [-0.24851952493190765, 0.7797591686248779]\n",
      "2700 steps | score: [-0.25732630491256714, 0.7745425701141357]\n",
      "2800 steps | score: [-0.24548891186714172, 0.792532742023468]\n",
      "unknown params:  tensor([-0.8681,  0.6162, -0.6903, -0.3978, -0.4527,  0.4956])\n",
      "gt params:  tensor([-0.8552,  0.5987, -0.6679, -0.4021, -0.4201,  0.6722])\n",
      "ols params:  tensor([-0.5852,  0.4275, -0.4726, -0.2786, -0.3170,  2.2726])\n",
      "unknown mse:  tensor(0.0055)\n",
      "ols mse:  tensor(0.4546)\n",
      "gt params:  tensor([-0.8433,  0.5728, -0.6627, -0.3939, -0.4113,  0.7311])\n",
      "0 steps | score: [0.2748303711414337]\n",
      "100 steps | score: [0.025365186855196953]\n",
      "200 steps | score: [0.06714771687984467]\n",
      "300 steps | score: [0.1186622828245163]\n",
      "400 steps | score: [0.03245343640446663]\n",
      "500 steps | score: [0.033884480595588684]\n",
      "600 steps | score: [0.05005646497011185]\n",
      "700 steps | score: [-0.017811961472034454]\n",
      "800 steps | score: [0.03386373445391655]\n",
      "900 steps | score: [0.11063651740550995]\n",
      "1000 steps | score: [0.1282152235507965]\n",
      "1100 steps | score: [0.0686103031039238]\n",
      "1200 steps | score: [-0.002702118828892708]\n",
      "0 steps | score: [0.12222937494516373, -0.0013264268636703491]\n",
      "100 steps | score: [-0.17820437252521515, 0.529453694820404]\n",
      "200 steps | score: [0.23448510468006134, -0.6155749559402466]\n",
      "300 steps | score: [0.27766188979148865, -0.8064379692077637]\n",
      "400 steps | score: [-0.1536739617586136, 0.4312455952167511]\n",
      "500 steps | score: [0.05985982343554497, -0.11113931238651276]\n",
      "600 steps | score: [0.11453951150178909, -0.31964072585105896]\n",
      "700 steps | score: [-0.11491311341524124, 0.30827033519744873]\n",
      "800 steps | score: [0.15969723463058472, -0.4447246193885803]\n",
      "900 steps | score: [0.31663888692855835, -0.9646009206771851]\n",
      "1000 steps | score: [0.16013537347316742, -0.4373536705970764]\n",
      "1100 steps | score: [0.0853850468993187, -0.1884004771709442]\n",
      "1200 steps | score: [-0.1452256739139557, 0.4203282594680786]\n",
      "1300 steps | score: [-0.04243289306759834, 0.17454184591770172]\n",
      "1400 steps | score: [-0.03416788578033447, 0.11322630941867828]\n",
      "1500 steps | score: [0.08924084901809692, -0.25895288586616516]\n",
      "1600 steps | score: [-0.03988772630691528, 0.12705709040164948]\n",
      "1700 steps | score: [0.0067750196903944016, -0.003307994455099106]\n",
      "unknown params:  tensor([-0.8256,  0.5632, -0.6466, -0.3673, -0.4049,  0.6872])\n",
      "gt params:  tensor([-0.8433,  0.5728, -0.6627, -0.3939, -0.4113,  0.7311])\n",
      "ols params:  tensor([-0.5542,  0.3888, -0.4435, -0.2573, -0.2820,  2.5429])\n",
      "unknown mse:  tensor(0.0006)\n",
      "ols mse:  tensor(0.5806)\n",
      "gt params:  tensor([-0.8650,  0.5767, -0.6700, -0.4021, -0.4133,  0.7538])\n",
      "0 steps | score: [0.24182406067848206]\n",
      "100 steps | score: [0.07728586345911026]\n",
      "200 steps | score: [0.03411991894245148]\n",
      "300 steps | score: [0.04779820516705513]\n",
      "400 steps | score: [-0.004194850102066994]\n",
      "0 steps | score: [0.05821860954165459, 0.05241864174604416]\n",
      "100 steps | score: [-0.019713731482625008, 0.09002338349819183]\n",
      "200 steps | score: [-0.07640939950942993, 0.14545822143554688]\n",
      "300 steps | score: [-0.08432569354772568, 0.1367223858833313]\n",
      "400 steps | score: [0.055624399334192276, -0.2849995195865631]\n",
      "500 steps | score: [-0.005385053344070911, -0.05751067399978638]\n",
      "600 steps | score: [-0.13190117478370667, 0.20980052649974823]\n",
      "700 steps | score: [-0.06427308171987534, 0.06482502818107605]\n",
      "800 steps | score: [-0.062184836715459824, 0.06839306652545929]\n",
      "900 steps | score: [-0.03653305768966675, -0.009475812315940857]\n",
      "1000 steps | score: [-0.22909194231033325, 0.5109587907791138]\n",
      "1100 steps | score: [-0.13274206221103668, 0.27340447902679443]\n",
      "1200 steps | score: [-0.16384871304035187, 0.31272092461586]\n",
      "1300 steps | score: [-0.1367577761411667, 0.26915881037712097]\n",
      "1400 steps | score: [-0.014496413059532642, -0.02790471911430359]\n",
      "1500 steps | score: [-0.15805721282958984, 0.3052065372467041]\n",
      "1600 steps | score: [-0.19705642759799957, 0.40007489919662476]\n",
      "1700 steps | score: [-0.16161419451236725, 0.3363024592399597]\n",
      "1800 steps | score: [-0.035663098096847534, 0.006110429763793945]\n",
      "1900 steps | score: [-0.10622679442167282, 0.1757533997297287]\n",
      "2000 steps | score: [0.017229603603482246, -0.14799076318740845]\n",
      "2100 steps | score: [-0.03866436332464218, 0.021161824464797974]\n",
      "2200 steps | score: [-0.08645297586917877, 0.14345714449882507]\n",
      "2300 steps | score: [-0.11185792088508606, 0.19187995791435242]\n",
      "2400 steps | score: [-0.07924488931894302, 0.10495956242084503]\n",
      "2500 steps | score: [-0.12806250154972076, 0.2504649758338928]\n",
      "2600 steps | score: [-0.031358081847429276, -0.005890406668186188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 steps | score: [-0.14701683819293976, 0.28489184379577637]\n",
      "2800 steps | score: [-0.09447955340147018, 0.12918689846992493]\n",
      "unknown params:  tensor([-0.8440,  0.5722, -0.6383, -0.3896, -0.3970,  0.5439])\n",
      "gt params:  tensor([-0.8650,  0.5767, -0.6700, -0.4021, -0.4133,  0.7538])\n",
      "ols params:  tensor([-0.5556,  0.3841, -0.4325, -0.2679, -0.2705,  2.7008])\n",
      "unknown mse:  tensor(0.0077)\n",
      "ols mse:  tensor(0.6697)\n",
      "gt params:  tensor([-0.8444,  0.5892, -0.6699, -0.3880, -0.4071,  0.7074])\n",
      "0 steps | score: [0.18071864545345306]\n",
      "100 steps | score: [0.004416825249791145]\n",
      "0 steps | score: [0.13206471502780914, -0.12862741947174072]\n",
      "100 steps | score: [0.21411870419979095, -0.5802883505821228]\n",
      "200 steps | score: [-0.07697255909442902, 0.1465449333190918]\n",
      "300 steps | score: [-0.13517291843891144, 0.2809104025363922]\n",
      "400 steps | score: [0.024673674255609512, -0.13327749073505402]\n",
      "500 steps | score: [-0.0015518475556746125, -0.10201719403266907]\n",
      "600 steps | score: [-0.08085072040557861, 0.12286949157714844]\n",
      "700 steps | score: [0.02935713715851307, -0.18223220109939575]\n",
      "800 steps | score: [0.1339826136827469, -0.4058954119682312]\n",
      "900 steps | score: [-0.2701784372329712, 0.5579172372817993]\n",
      "1000 steps | score: [-0.15358680486679077, 0.27373188734054565]\n",
      "1100 steps | score: [-0.14220470190048218, 0.24806049466133118]\n",
      "1200 steps | score: [-0.10021241009235382, 0.17164847254753113]\n",
      "1300 steps | score: [-0.11338087916374207, 0.1895695924758911]\n",
      "1400 steps | score: [-0.1544034779071808, 0.2726656496524811]\n",
      "1500 steps | score: [0.1116425171494484, -0.39387744665145874]\n",
      "1600 steps | score: [-0.13176368176937103, 0.24190853536128998]\n",
      "1700 steps | score: [-0.09522754698991776, 0.15294136106967926]\n",
      "1800 steps | score: [-0.15759940445423126, 0.29321011900901794]\n",
      "1900 steps | score: [-0.10108854621648788, 0.15885579586029053]\n",
      "2000 steps | score: [-0.07051964104175568, 0.09888631105422974]\n",
      "2100 steps | score: [-0.08253025263547897, 0.11776518821716309]\n",
      "2200 steps | score: [0.01948397234082222, -0.16289260983467102]\n",
      "2300 steps | score: [-0.13907988369464874, 0.24290266633033752]\n",
      "2400 steps | score: [-0.05373188853263855, -0.01799721270799637]\n",
      "2500 steps | score: [-0.005252627655863762, -0.12314045429229736]\n",
      "2600 steps | score: [-0.030933110043406487, -0.01747133582830429]\n",
      "2700 steps | score: [-0.07496394217014313, 0.07048503309488297]\n",
      "2800 steps | score: [-0.07907428592443466, 0.09674227237701416]\n",
      "unknown params:  tensor([-0.8463,  0.5956, -0.6915, -0.3997, -0.4080,  0.4048])\n",
      "gt params:  tensor([-0.8444,  0.5892, -0.6699, -0.3880, -0.4071,  0.7074])\n",
      "ols params:  tensor([-0.5270,  0.3791, -0.4344, -0.2544, -0.2639,  2.7899])\n",
      "unknown mse:  tensor(0.0154)\n",
      "ols mse:  tensor(0.7626)\n",
      "gt params:  tensor([-0.8308,  0.5829, -0.6704, -0.3943, -0.4034,  0.7194])\n",
      "0 steps | score: [0.2825976014137268]\n",
      "100 steps | score: [0.10010245442390442]\n",
      "200 steps | score: [0.09756344556808472]\n",
      "300 steps | score: [-0.009146880358457565]\n",
      "0 steps | score: [-0.08500475436449051, 0.2204088568687439]\n",
      "100 steps | score: [-0.33841031789779663, 0.6458825469017029]\n",
      "200 steps | score: [-0.43092650175094604, 0.841973066329956]\n",
      "300 steps | score: [-0.34740108251571655, 0.5647214651107788]\n",
      "400 steps | score: [-0.01319222990423441, -0.261787474155426]\n",
      "500 steps | score: [-0.20874489843845367, 0.2894878089427948]\n",
      "600 steps | score: [0.12265978753566742, -0.689132809638977]\n",
      "700 steps | score: [-0.2449997365474701, 0.3718801438808441]\n",
      "800 steps | score: [-0.044039659202098846, -0.2104073315858841]\n",
      "900 steps | score: [0.0480775386095047, -0.48781463503837585]\n",
      "1000 steps | score: [-0.22247694432735443, 0.29457607865333557]\n",
      "1100 steps | score: [-0.26429253816604614, 0.4130818843841553]\n",
      "1200 steps | score: [-0.1651633381843567, 0.17524145543575287]\n",
      "1300 steps | score: [-0.289133757352829, 0.42406731843948364]\n",
      "1400 steps | score: [-0.33038926124572754, 0.573311448097229]\n",
      "1500 steps | score: [-0.3502039313316345, 0.6092865467071533]\n",
      "1600 steps | score: [-0.1787251979112625, 0.12770946323871613]\n",
      "1700 steps | score: [-0.1496758610010147, 0.11088564991950989]\n",
      "1800 steps | score: [-0.2683587074279785, 0.41508686542510986]\n",
      "1900 steps | score: [-0.28373903036117554, 0.4562162160873413]\n",
      "2000 steps | score: [-0.24008619785308838, 0.330464243888855]\n",
      "2100 steps | score: [-0.14972653985023499, 0.07595787942409515]\n",
      "2200 steps | score: [-0.2670390009880066, 0.39798784255981445]\n",
      "2300 steps | score: [-0.08715438842773438, -0.07176578789949417]\n",
      "2400 steps | score: [-0.17404891550540924, 0.16152483224868774]\n",
      "2500 steps | score: [-0.16714893281459808, 0.1447545886039734]\n",
      "2600 steps | score: [-0.13455083966255188, 0.045950062572956085]\n",
      "2700 steps | score: [-0.11110859364271164, -0.02256583794951439]\n",
      "2800 steps | score: [-0.1610962301492691, 0.11097204685211182]\n",
      "unknown params:  tensor([-0.8077,  0.6027, -0.6553, -0.3855, -0.4000,  0.5129])\n",
      "gt params:  tensor([-0.8308,  0.5829, -0.6704, -0.3943, -0.4034,  0.7194])\n",
      "ols params:  tensor([-0.4961,  0.3761, -0.4060, -0.2461, -0.2533,  2.9644])\n",
      "unknown mse:  tensor(0.0073)\n",
      "ols mse:  tensor(0.8848)\n",
      "gt params:  tensor([-0.8566,  0.5868, -0.6593, -0.4056, -0.4202,  0.7796])\n",
      "0 steps | score: [0.19421571493148804]\n",
      "100 steps | score: [-0.06926355510950089]\n",
      "200 steps | score: [-0.013100795447826385]\n",
      "300 steps | score: [0.05793984234333038]\n",
      "400 steps | score: [-0.009842876344919205]\n",
      "0 steps | score: [0.15172255039215088, -0.2572469711303711]\n",
      "100 steps | score: [-0.21477602422237396, 0.47523486614227295]\n",
      "200 steps | score: [0.07753381133079529, -0.3648761510848999]\n",
      "300 steps | score: [0.4702616035938263, -1.5893473625183105]\n",
      "400 steps | score: [0.16623961925506592, -0.678895890712738]\n",
      "500 steps | score: [-0.05881994590163231, -0.020336784422397614]\n",
      "600 steps | score: [-0.08708713948726654, 0.03071526065468788]\n",
      "700 steps | score: [0.21210072934627533, -0.7728897333145142]\n",
      "800 steps | score: [0.20912769436836243, -0.7915447950363159]\n",
      "900 steps | score: [-0.04449160024523735, -0.10227251052856445]\n",
      "1000 steps | score: [0.42415785789489746, -1.5110191106796265]\n",
      "1100 steps | score: [-0.1550896018743515, 0.1971718668937683]\n",
      "1200 steps | score: [-0.0696437656879425, -0.03344736248254776]\n",
      "1300 steps | score: [0.07265014201402664, -0.3900470733642578]\n",
      "1400 steps | score: [0.06469419598579407, -0.4180851876735687]\n",
      "1500 steps | score: [0.019160442054271698, -0.2625706195831299]\n",
      "1600 steps | score: [0.1233898401260376, -0.5724367499351501]\n",
      "1700 steps | score: [0.07115059345960617, -0.4025222659111023]\n",
      "1800 steps | score: [-0.022811129689216614, -0.12064014375209808]\n",
      "1900 steps | score: [0.06478676944971085, -0.38639336824417114]\n",
      "2000 steps | score: [0.13418716192245483, -0.6024980545043945]\n",
      "2100 steps | score: [0.2035929262638092, -0.7943944931030273]\n",
      "2200 steps | score: [0.06433860212564468, -0.4199783205986023]\n",
      "2300 steps | score: [0.032860442996025085, -0.3068666160106659]\n",
      "2400 steps | score: [0.04666106030344963, -0.29963234066963196]\n",
      "2500 steps | score: [0.11160337924957275, -0.5424026250839233]\n",
      "2600 steps | score: [0.03975795954465866, -0.29351770877838135]\n",
      "2700 steps | score: [0.16517432034015656, -0.6545796990394592]\n",
      "2800 steps | score: [-0.013670640997588634, -0.21490192413330078]\n",
      "unknown params:  tensor([-0.7889,  0.5602, -0.6287, -0.3795, -0.4012,  0.4329])\n",
      "gt params:  tensor([-0.8566,  0.5868, -0.6593, -0.4056, -0.4202,  0.7796])\n",
      "ols params:  tensor([-0.4989,  0.3593, -0.4008, -0.2466, -0.2616,  3.1339])\n",
      "unknown mse:  tensor(0.0212)\n",
      "ols mse:  tensor(0.9733)\n",
      "gt params:  tensor([-0.8601,  0.5749, -0.6531, -0.3810, -0.3962,  0.7441])\n",
      "0 steps | score: [0.27548107504844666]\n",
      "100 steps | score: [0.13532871007919312]\n",
      "200 steps | score: [0.0921161025762558]\n",
      "300 steps | score: [0.08601932227611542]\n",
      "400 steps | score: [0.1741853952407837]\n",
      "500 steps | score: [0.07709656655788422]\n",
      "600 steps | score: [0.031689174473285675]\n",
      "700 steps | score: [0.03414987400174141]\n",
      "800 steps | score: [0.13807961344718933]\n",
      "900 steps | score: [0.09960030764341354]\n",
      "1000 steps | score: [0.030704062432050705]\n",
      "1100 steps | score: [0.06833870708942413]\n",
      "1200 steps | score: [0.05146283656358719]\n",
      "1300 steps | score: [0.03409950062632561]\n",
      "1400 steps | score: [0.0700310617685318]\n",
      "1500 steps | score: [0.07314562797546387]\n",
      "1600 steps | score: [0.06477151811122894]\n",
      "1700 steps | score: [0.07412391901016235]\n",
      "1800 steps | score: [0.05822921171784401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [0.058320458978414536]\n",
      "2000 steps | score: [0.06546919792890549]\n",
      "2100 steps | score: [0.057729125022888184]\n",
      "2200 steps | score: [0.062295302748680115]\n",
      "2300 steps | score: [0.04371632635593414]\n",
      "2400 steps | score: [0.03546296805143356]\n",
      "2500 steps | score: [0.07206340879201889]\n",
      "2600 steps | score: [0.06795495748519897]\n",
      "2700 steps | score: [0.07497216761112213]\n",
      "0 steps | score: [0.1463012546300888, -0.08167038857936859]\n",
      "100 steps | score: [1.2870672941207886, -3.9969515800476074]\n",
      "200 steps | score: [0.03963428735733032, -0.06762216985225677]\n",
      "300 steps | score: [-0.04569435119628906, 0.16722601652145386]\n",
      "400 steps | score: [0.38500508666038513, -0.9840248227119446]\n",
      "500 steps | score: [0.28018152713775635, -0.6607880592346191]\n",
      "600 steps | score: [-0.20142090320587158, 0.46588951349258423]\n",
      "700 steps | score: [-0.11393671482801437, 0.26500940322875977]\n",
      "800 steps | score: [-0.009848453104496002, 0.006718762218952179]\n",
      "unknown params:  tensor([-0.8528,  0.5996, -0.6960, -0.3412, -0.3910,  0.5594])\n",
      "gt params:  tensor([-0.8601,  0.5749, -0.6531, -0.3810, -0.3962,  0.7441])\n",
      "ols params:  tensor([-0.4840,  0.3467, -0.3921, -0.2053, -0.2359,  3.2747])\n",
      "unknown mse:  tensor(0.0064)\n",
      "ols mse:  tensor(1.1204)\n",
      "gt params:  tensor([-0.8671,  0.5810, -0.6632, -0.4208, -0.4155,  0.6758])\n",
      "0 steps | score: [0.24175836145877838]\n",
      "100 steps | score: [-0.0442986898124218]\n",
      "200 steps | score: [-0.045469969511032104]\n",
      "300 steps | score: [-0.03146960586309433]\n",
      "400 steps | score: [-0.04503320902585983]\n",
      "500 steps | score: [-0.0985383689403534]\n",
      "600 steps | score: [-0.03008132055401802]\n",
      "700 steps | score: [-0.026813555508852005]\n",
      "800 steps | score: [-0.05419033765792847]\n",
      "900 steps | score: [0.01279979757964611]\n",
      "1000 steps | score: [0.008441057056188583]\n",
      "0 steps | score: [0.08274702727794647, 0.10323762893676758]\n",
      "100 steps | score: [-0.2240740954875946, 0.5888311266899109]\n",
      "200 steps | score: [-0.30162352323532104, 0.7372255325317383]\n",
      "300 steps | score: [-0.21863889694213867, 0.4893059730529785]\n",
      "400 steps | score: [-0.15713855624198914, 0.35164061188697815]\n",
      "500 steps | score: [-0.18387392163276672, 0.4081737697124481]\n",
      "600 steps | score: [-0.04517389088869095, 0.12409791350364685]\n",
      "700 steps | score: [-0.31539395451545715, 0.724494993686676]\n",
      "800 steps | score: [0.006636578589677811, -0.03263450413942337]\n",
      "900 steps | score: [-0.09847348183393478, 0.2410518229007721]\n",
      "1000 steps | score: [-0.07123160362243652, 0.1522759646177292]\n",
      "1100 steps | score: [0.05714511498808861, -0.21955013275146484]\n",
      "1200 steps | score: [-0.048223044723272324, 0.08070164918899536]\n",
      "1300 steps | score: [0.07686564326286316, -0.21162830293178558]\n",
      "1400 steps | score: [-0.12510903179645538, 0.24609927833080292]\n",
      "1500 steps | score: [-0.10584758222103119, 0.2520257234573364]\n",
      "1600 steps | score: [-0.24880990386009216, 0.5720498561859131]\n",
      "1700 steps | score: [-0.13326531648635864, 0.3041481375694275]\n",
      "1800 steps | score: [-0.06359139829874039, 0.13730409741401672]\n",
      "1900 steps | score: [-0.13010215759277344, 0.25147706270217896]\n",
      "2000 steps | score: [-0.08873149007558823, 0.18588870763778687]\n",
      "2100 steps | score: [-0.03419312462210655, 0.06897766888141632]\n",
      "2200 steps | score: [-0.06228814274072647, 0.10105821490287781]\n",
      "2300 steps | score: [-0.12873497605323792, 0.29236841201782227]\n",
      "2400 steps | score: [-0.08508085459470749, 0.1395818591117859]\n",
      "2500 steps | score: [-0.1029008999466896, 0.21647894382476807]\n",
      "2600 steps | score: [-0.06097421422600746, 0.12338308990001678]\n",
      "2700 steps | score: [-0.08035198599100113, 0.14989271759986877]\n",
      "unknown params:  tensor([-0.8815,  0.5759, -0.6881, -0.4258, -0.4084,  0.5327])\n",
      "gt params:  tensor([-0.8671,  0.5810, -0.6632, -0.4208, -0.4155,  0.6758])\n",
      "ols params:  tensor([-0.4835,  0.3307, -0.3881, -0.2435, -0.2326,  3.3191])\n",
      "unknown mse:  tensor(0.0036)\n",
      "ols mse:  tensor(1.2229)\n",
      "gt params:  tensor([-0.8403,  0.5699, -0.6705, -0.3986, -0.3955,  0.6855])\n",
      "0 steps | score: [0.3040350675582886]\n",
      "100 steps | score: [0.05243367701768875]\n",
      "200 steps | score: [0.06838838756084442]\n",
      "300 steps | score: [0.10107074677944183]\n",
      "400 steps | score: [0.09543713927268982]\n",
      "500 steps | score: [0.13100826740264893]\n",
      "600 steps | score: [0.015653669834136963]\n",
      "700 steps | score: [0.049754366278648376]\n",
      "800 steps | score: [0.1178029254078865]\n",
      "900 steps | score: [0.022705547511577606]\n",
      "1000 steps | score: [0.04441862553358078]\n",
      "1100 steps | score: [0.031492121517658234]\n",
      "1200 steps | score: [0.02152012288570404]\n",
      "1300 steps | score: [0.04401687532663345]\n",
      "1400 steps | score: [0.029018543660640717]\n",
      "1500 steps | score: [0.06878507137298584]\n",
      "1600 steps | score: [0.0662035420536995]\n",
      "1700 steps | score: [0.06653924286365509]\n",
      "1800 steps | score: [0.05238358676433563]\n",
      "1900 steps | score: [0.05505116283893585]\n",
      "2000 steps | score: [0.022835195064544678]\n",
      "2100 steps | score: [0.04476648569107056]\n",
      "2200 steps | score: [0.08458420634269714]\n",
      "2300 steps | score: [0.043380603194236755]\n",
      "2400 steps | score: [0.05321863293647766]\n",
      "2500 steps | score: [0.07568920403718948]\n",
      "2600 steps | score: [0.041648782789707184]\n",
      "2700 steps | score: [0.024271249771118164]\n",
      "0 steps | score: [0.20698344707489014, -0.10093939304351807]\n",
      "100 steps | score: [0.01118882279843092, 0.22473713755607605]\n",
      "200 steps | score: [-0.10097607970237732, 0.371128112077713]\n",
      "300 steps | score: [0.1927366852760315, -0.3273969292640686]\n",
      "400 steps | score: [0.09855423867702484, -0.12502089142799377]\n",
      "500 steps | score: [0.20086146891117096, -0.3530379831790924]\n",
      "600 steps | score: [0.07620582729578018, -0.10020241141319275]\n",
      "700 steps | score: [0.12198657542467117, -0.12833833694458008]\n",
      "800 steps | score: [0.09556452184915543, -0.1134110689163208]\n",
      "900 steps | score: [-0.07025634497404099, 0.2669745087623596]\n",
      "1000 steps | score: [-0.1272992342710495, 0.3776189386844635]\n",
      "1100 steps | score: [-0.14663273096084595, 0.4386371970176697]\n",
      "1200 steps | score: [-0.0010082345688715577, 0.11482211947441101]\n",
      "1300 steps | score: [0.011581206694245338, 0.09681743383407593]\n",
      "1400 steps | score: [-0.04353061690926552, 0.19203492999076843]\n",
      "1500 steps | score: [0.1162046492099762, -0.16386118531227112]\n",
      "1600 steps | score: [0.020705759525299072, 0.034229159355163574]\n",
      "1700 steps | score: [-0.07014768570661545, 0.2426825314760208]\n",
      "1800 steps | score: [-0.00999009795486927, 0.1337818056344986]\n",
      "1900 steps | score: [-0.03360987454652786, 0.1657789945602417]\n",
      "2000 steps | score: [-0.10852514952421188, 0.35254305601119995]\n",
      "2100 steps | score: [0.012510511092841625, 0.07697319984436035]\n",
      "2200 steps | score: [0.027633247897028923, 0.04977154731750488]\n",
      "2300 steps | score: [0.016537168994545937, 0.06901323795318604]\n",
      "2400 steps | score: [-0.06529047340154648, 0.24355706572532654]\n",
      "2500 steps | score: [-0.03805539011955261, 0.19517487287521362]\n",
      "2600 steps | score: [0.06487499922513962, -0.038455069065093994]\n",
      "2700 steps | score: [0.022489773109555244, 0.05904345214366913]\n",
      "unknown params:  tensor([-0.8522,  0.5963, -0.6812, -0.3853, -0.4127,  0.3969])\n",
      "gt params:  tensor([-0.8403,  0.5699, -0.6705, -0.3986, -0.3955,  0.6855])\n",
      "ols params:  tensor([-0.4715,  0.3345, -0.3838, -0.2160, -0.2346,  3.3578])\n",
      "unknown mse:  tensor(0.0141)\n",
      "ols mse:  tensor(1.2457)\n",
      "gt params:  tensor([-0.8580,  0.5861, -0.6441, -0.3939, -0.4090,  0.6805])\n",
      "0 steps | score: [0.3726494312286377]\n",
      "100 steps | score: [0.1235252171754837]\n",
      "200 steps | score: [0.11614961177110672]\n",
      "300 steps | score: [0.08065292239189148]\n",
      "400 steps | score: [0.15515491366386414]\n",
      "500 steps | score: [0.14504335820674896]\n",
      "600 steps | score: [0.06631262600421906]\n",
      "700 steps | score: [0.1126568540930748]\n",
      "800 steps | score: [0.10210604965686798]\n",
      "900 steps | score: [0.1291133463382721]\n",
      "1000 steps | score: [0.15274010598659515]\n",
      "1100 steps | score: [0.10534117370843887]\n",
      "1200 steps | score: [0.0861247181892395]\n",
      "1300 steps | score: [0.09531383961439133]\n",
      "1400 steps | score: [0.1159185916185379]\n",
      "1500 steps | score: [0.12634402513504028]\n",
      "1600 steps | score: [0.14322605729103088]\n",
      "1700 steps | score: [0.10922576487064362]\n",
      "1800 steps | score: [0.11691597104072571]\n",
      "1900 steps | score: [0.09818758815526962]\n",
      "2000 steps | score: [0.11522787809371948]\n",
      "2100 steps | score: [0.11474719643592834]\n",
      "2200 steps | score: [0.1264917254447937]\n",
      "2300 steps | score: [0.11061554402112961]\n",
      "2400 steps | score: [0.11266867816448212]\n",
      "2500 steps | score: [0.08071281760931015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600 steps | score: [0.125556081533432]\n",
      "2700 steps | score: [0.11917679756879807]\n",
      "0 steps | score: [0.15789704024791718, -0.023784860968589783]\n",
      "100 steps | score: [-0.11522338539361954, 0.38642898201942444]\n",
      "200 steps | score: [-0.0036545214243233204, 0.11153655499219894]\n",
      "300 steps | score: [-0.0893501341342926, 0.2760699689388275]\n",
      "400 steps | score: [0.23506461083889008, -0.4774264693260193]\n",
      "500 steps | score: [0.09663590788841248, -0.18493396043777466]\n",
      "600 steps | score: [-0.22026801109313965, 0.5527598857879639]\n",
      "700 steps | score: [-0.11723253130912781, 0.31348922848701477]\n",
      "800 steps | score: [-0.11241843551397324, 0.3088070750236511]\n",
      "900 steps | score: [0.04482993111014366, -0.058624185621738434]\n",
      "1000 steps | score: [0.20485229790210724, -0.4553443193435669]\n",
      "1100 steps | score: [-0.12261998653411865, 0.3438968360424042]\n",
      "1200 steps | score: [-0.10071652382612228, 0.2745172381401062]\n",
      "1300 steps | score: [-0.16526049375534058, 0.4179433286190033]\n",
      "1400 steps | score: [0.028883686289191246, -0.03862198069691658]\n",
      "1500 steps | score: [-0.025996292009949684, 0.10694511979818344]\n",
      "1600 steps | score: [-0.0371193066239357, 0.13994722068309784]\n",
      "1700 steps | score: [-0.031720519065856934, 0.15731075406074524]\n",
      "1800 steps | score: [0.0006618413608521223, 0.03244321793317795]\n",
      "1900 steps | score: [0.06701213121414185, -0.09803363680839539]\n",
      "2000 steps | score: [-0.04957016929984093, 0.15133124589920044]\n",
      "2100 steps | score: [-0.07088834792375565, 0.20274032652378082]\n",
      "2200 steps | score: [-0.04474407806992531, 0.1566976010799408]\n",
      "2300 steps | score: [0.02889435924589634, -0.016398601233959198]\n",
      "2400 steps | score: [-0.05516570433974266, 0.1901913583278656]\n",
      "2500 steps | score: [-0.0668320283293724, 0.19983506202697754]\n",
      "2600 steps | score: [0.027619771659374237, -0.0015776529908180237]\n",
      "2700 steps | score: [0.058438755571842194, -0.08084894716739655]\n",
      "unknown params:  tensor([-0.8794,  0.5922, -0.6464, -0.3988, -0.3852,  0.3664])\n",
      "gt params:  tensor([-0.8580,  0.5861, -0.6441, -0.3939, -0.4090,  0.6805])\n",
      "ols params:  tensor([-0.4780,  0.3319, -0.3664, -0.2288, -0.2222,  3.4916])\n",
      "unknown mse:  tensor(0.0166)\n",
      "ols mse:  tensor(1.3752)\n",
      "gt params:  tensor([-0.8417,  0.5550, -0.6877, -0.3970, -0.4075,  0.6962])\n",
      "0 steps | score: [0.11422684788703918]\n",
      "100 steps | score: [-0.08516263961791992]\n",
      "200 steps | score: [-0.1378810852766037]\n",
      "300 steps | score: [-0.126895934343338]\n",
      "400 steps | score: [-0.1348494440317154]\n",
      "500 steps | score: [-0.11343380063772202]\n",
      "600 steps | score: [-0.07324621081352234]\n",
      "700 steps | score: [-0.13070008158683777]\n",
      "800 steps | score: [-0.14424028992652893]\n",
      "900 steps | score: [-0.05706528574228287]\n",
      "1000 steps | score: [-0.09782073646783829]\n",
      "1100 steps | score: [-0.12548166513442993]\n",
      "1200 steps | score: [-0.08210201561450958]\n",
      "1300 steps | score: [-0.11689643561840057]\n",
      "1400 steps | score: [-0.12471754848957062]\n",
      "1500 steps | score: [-0.12145820260047913]\n",
      "1600 steps | score: [-0.13182029128074646]\n",
      "1700 steps | score: [-0.10435562580823898]\n",
      "1800 steps | score: [-0.11589069664478302]\n",
      "1900 steps | score: [-0.1280519813299179]\n",
      "2000 steps | score: [-0.08113077282905579]\n",
      "2100 steps | score: [-0.1067686676979065]\n",
      "2200 steps | score: [-0.11813092231750488]\n",
      "2300 steps | score: [-0.11554475873708725]\n",
      "2400 steps | score: [-0.09700024873018265]\n",
      "2500 steps | score: [-0.10324546694755554]\n",
      "2600 steps | score: [-0.10673615336418152]\n",
      "2700 steps | score: [-0.1281241476535797]\n",
      "0 steps | score: [0.15817730128765106, -0.08864520490169525]\n",
      "100 steps | score: [0.11964411288499832, -0.15666402876377106]\n",
      "200 steps | score: [-0.05186239257454872, 0.14977402985095978]\n",
      "300 steps | score: [-0.16708864271640778, 0.39300572872161865]\n",
      "400 steps | score: [0.04510987177491188, -0.15127518773078918]\n",
      "500 steps | score: [0.011120741255581379, -0.07039971649646759]\n",
      "600 steps | score: [0.11400099098682404, -0.3218160569667816]\n",
      "700 steps | score: [-0.1786229908466339, 0.3666817545890808]\n",
      "800 steps | score: [-0.11804822087287903, 0.24869219958782196]\n",
      "900 steps | score: [-0.07430461049079895, 0.14084535837173462]\n",
      "1000 steps | score: [-0.00955491978675127, -0.00286749005317688]\n",
      "unknown params:  tensor([-0.7815,  0.5253, -0.6490, -0.3811, -0.3438,  0.6596])\n",
      "gt params:  tensor([-0.8417,  0.5550, -0.6877, -0.3970, -0.4075,  0.6962])\n",
      "ols params:  tensor([-0.4546,  0.3124, -0.3764, -0.2207, -0.2156,  3.6317])\n",
      "unknown mse:  tensor(0.0019)\n",
      "ols mse:  tensor(1.4985)\n",
      "gt params:  tensor([-0.8578,  0.6060, -0.6518, -0.3766, -0.4142,  0.6337])\n",
      "0 steps | score: [0.28959158062934875]\n",
      "100 steps | score: [0.04065973311662674]\n",
      "200 steps | score: [0.0030541729647666216]\n",
      "0 steps | score: [0.5101038217544556, -0.7566946744918823]\n",
      "100 steps | score: [0.35778313875198364, -0.5715317130088806]\n",
      "200 steps | score: [0.3314792811870575, -0.5413709878921509]\n",
      "300 steps | score: [0.156143456697464, -0.23363392055034637]\n",
      "400 steps | score: [0.28566882014274597, -0.5222136378288269]\n",
      "500 steps | score: [0.3539291322231293, -0.6312817931175232]\n",
      "600 steps | score: [0.33963897824287415, -0.6269575357437134]\n",
      "700 steps | score: [0.3584340214729309, -0.6923486590385437]\n",
      "800 steps | score: [0.3238319456577301, -0.6121996641159058]\n",
      "900 steps | score: [0.4567930996417999, -0.9096014499664307]\n",
      "1000 steps | score: [0.19387227296829224, -0.3161943852901459]\n",
      "1100 steps | score: [0.18795253336429596, -0.2705146074295044]\n",
      "1200 steps | score: [0.30182284116744995, -0.5278594493865967]\n",
      "1300 steps | score: [0.3198644816875458, -0.5806359052658081]\n",
      "1400 steps | score: [0.19332420825958252, -0.307364821434021]\n",
      "1500 steps | score: [0.31032663583755493, -0.5942844152450562]\n",
      "1600 steps | score: [0.32887086272239685, -0.593277633190155]\n",
      "1700 steps | score: [0.39062419533729553, -0.7173752784729004]\n",
      "1800 steps | score: [0.34183037281036377, -0.6371972560882568]\n",
      "1900 steps | score: [0.3634638786315918, -0.6938863396644592]\n",
      "2000 steps | score: [0.35174626111984253, -0.6820129752159119]\n",
      "2100 steps | score: [0.21883946657180786, -0.3803003430366516]\n",
      "2200 steps | score: [0.2756354510784149, -0.4775009751319885]\n",
      "2300 steps | score: [0.33823153376579285, -0.642431378364563]\n",
      "2400 steps | score: [0.30120331048965454, -0.5575110912322998]\n",
      "2500 steps | score: [0.2880914509296417, -0.5216566324234009]\n",
      "2600 steps | score: [0.31142330169677734, -0.5785365104675293]\n",
      "2700 steps | score: [0.31273967027664185, -0.5935576558113098]\n",
      "unknown params:  tensor([-0.8140,  0.5911, -0.5904, -0.3700, -0.3948,  0.4081])\n",
      "gt params:  tensor([-0.8578,  0.6060, -0.6518, -0.3766, -0.4142,  0.6337])\n",
      "ols params:  tensor([-0.4619,  0.3427, -0.3448, -0.2154, -0.2348,  3.7314])\n",
      "unknown mse:  tensor(0.0095)\n",
      "ols mse:  tensor(1.6623)\n",
      "gt params:  tensor([-0.8663,  0.5632, -0.6552, -0.3893, -0.4260,  0.6564])\n",
      "0 steps | score: [0.242391899228096]\n",
      "100 steps | score: [0.008581504225730896]\n",
      "0 steps | score: [0.3282034397125244, -0.5695053339004517]\n",
      "100 steps | score: [0.3329516351222992, -0.7286038398742676]\n",
      "200 steps | score: [0.03507741540670395, -0.16339778900146484]\n",
      "300 steps | score: [0.1606409102678299, -0.4429023265838623]\n",
      "400 steps | score: [0.10164548456668854, -0.3741794228553772]\n",
      "500 steps | score: [0.16627690196037292, -0.4791044592857361]\n",
      "600 steps | score: [0.3476804494857788, -0.922610342502594]\n",
      "700 steps | score: [0.14217838644981384, -0.4009714722633362]\n",
      "800 steps | score: [0.19298633933067322, -0.5882971286773682]\n",
      "900 steps | score: [0.18321533501148224, -0.5290466547012329]\n",
      "1000 steps | score: [0.09974458813667297, -0.32665306329727173]\n",
      "1100 steps | score: [0.18073353171348572, -0.4968410134315491]\n",
      "1200 steps | score: [0.15014755725860596, -0.4299529194831848]\n",
      "1300 steps | score: [0.1208462342619896, -0.3753083348274231]\n",
      "1400 steps | score: [0.09526144713163376, -0.3188677430152893]\n",
      "1500 steps | score: [0.13840685784816742, -0.4282447099685669]\n",
      "1600 steps | score: [0.1328677535057068, -0.432403564453125]\n",
      "1700 steps | score: [0.2792675793170929, -0.7983593940734863]\n",
      "1800 steps | score: [0.143228679895401, -0.44856294989585876]\n",
      "1900 steps | score: [0.1950843185186386, -0.5811245441436768]\n",
      "2000 steps | score: [0.09986681491136551, -0.35259178280830383]\n",
      "2100 steps | score: [0.048901449888944626, -0.22966477274894714]\n",
      "2200 steps | score: [0.12335570901632309, -0.38275226950645447]\n",
      "2300 steps | score: [0.14907076954841614, -0.47123169898986816]\n",
      "2400 steps | score: [0.1314341425895691, -0.42738524079322815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 steps | score: [0.11284482479095459, -0.3908357620239258]\n",
      "2600 steps | score: [0.17493587732315063, -0.5078065395355225]\n",
      "2700 steps | score: [0.16586913168430328, -0.4960345923900604]\n",
      "unknown params:  tensor([-0.9004,  0.5829, -0.6639, -0.4087, -0.4358,  0.2896])\n",
      "gt params:  tensor([-0.8663,  0.5632, -0.6552, -0.3893, -0.4260,  0.6564])\n",
      "ols params:  tensor([-0.4593,  0.3080, -0.3475, -0.2169, -0.2340,  3.8641])\n",
      "unknown mse:  tensor(0.0228)\n",
      "ols mse:  tensor(1.7803)\n",
      "gt params:  tensor([-0.8496,  0.5793, -0.6475, -0.3818, -0.4157,  0.6777])\n",
      "0 steps | score: [0.24591456353664398]\n",
      "100 steps | score: [0.005249960348010063]\n",
      "0 steps | score: [-0.15613235533237457, 0.48927223682403564]\n",
      "100 steps | score: [-0.2582907974720001, 0.5636932849884033]\n",
      "200 steps | score: [-0.47733592987060547, 0.9550881385803223]\n",
      "300 steps | score: [-0.3032030165195465, 0.5806550979614258]\n",
      "400 steps | score: [-0.3895242214202881, 0.7553019523620605]\n",
      "500 steps | score: [-0.2490796446800232, 0.4373660981655121]\n",
      "600 steps | score: [-0.4886350929737091, 0.9167169332504272]\n",
      "700 steps | score: [-0.34121084213256836, 0.6294175982475281]\n",
      "800 steps | score: [-0.14223815500736237, 0.1705419272184372]\n",
      "900 steps | score: [-0.3555171489715576, 0.6544548273086548]\n",
      "1000 steps | score: [-0.2993772625923157, 0.526165783405304]\n",
      "1100 steps | score: [-0.1847606897354126, 0.2329936921596527]\n",
      "1200 steps | score: [-0.35901203751564026, 0.6632953882217407]\n",
      "1300 steps | score: [-0.393486887216568, 0.7347191572189331]\n",
      "1400 steps | score: [-0.17479978501796722, 0.25956135988235474]\n",
      "1500 steps | score: [-0.3248579204082489, 0.5978022217750549]\n",
      "1600 steps | score: [-0.27477970719337463, 0.45919710397720337]\n",
      "1700 steps | score: [-0.40487223863601685, 0.7685279250144958]\n",
      "1800 steps | score: [-0.36137425899505615, 0.6816604137420654]\n",
      "1900 steps | score: [-0.14817772805690765, 0.14805755019187927]\n",
      "2000 steps | score: [-0.4147166311740875, 0.7666133046150208]\n",
      "2100 steps | score: [-0.3215133547782898, 0.597557783126831]\n",
      "2200 steps | score: [-0.29169198870658875, 0.507367730140686]\n",
      "2300 steps | score: [-0.38460418581962585, 0.7058039903640747]\n",
      "2400 steps | score: [-0.37058016657829285, 0.6704553961753845]\n",
      "2500 steps | score: [-0.22950218617916107, 0.38484203815460205]\n",
      "2600 steps | score: [-0.34333592653274536, 0.6275951266288757]\n",
      "2700 steps | score: [-0.2891409695148468, 0.5197767019271851]\n",
      "unknown params:  tensor([-0.9148,  0.6123, -0.6860, -0.4099, -0.4969,  0.3213])\n",
      "gt params:  tensor([-0.8496,  0.5793, -0.6475, -0.3818, -0.4157,  0.6777])\n",
      "ols params:  tensor([-0.4493,  0.3065, -0.3475, -0.2039, -0.2505,  3.8842])\n",
      "unknown mse:  tensor(0.0235)\n",
      "ols mse:  tensor(1.7775)\n",
      "gt params:  tensor([-0.8475,  0.5989, -0.6711, -0.3863, -0.4046,  0.7158])\n",
      "0 steps | score: [0.19219715893268585]\n",
      "100 steps | score: [-0.010576944798231125]\n",
      "200 steps | score: [0.030503030866384506]\n",
      "300 steps | score: [-0.05230367183685303]\n",
      "400 steps | score: [-0.05313919857144356]\n",
      "500 steps | score: [-0.00012528151273727417]\n",
      "0 steps | score: [-0.049228016287088394, 0.39510878920555115]\n",
      "100 steps | score: [0.03249061852693558, 0.055104538798332214]\n",
      "200 steps | score: [-0.2666547894477844, 0.7234327793121338]\n",
      "300 steps | score: [-0.16574834287166595, 0.4964882433414459]\n",
      "400 steps | score: [0.07088592648506165, -0.20308220386505127]\n",
      "500 steps | score: [0.1147494688630104, -0.398584246635437]\n",
      "600 steps | score: [-0.10513412952423096, 0.28364241123199463]\n",
      "700 steps | score: [-0.0076901610009372234, 0.014945968985557556]\n",
      "800 steps | score: [-0.2256878763437271, 0.5649644136428833]\n",
      "900 steps | score: [-0.0664253979921341, 0.1663387417793274]\n",
      "1000 steps | score: [0.02787717990577221, -0.14288219809532166]\n",
      "1100 steps | score: [-0.24194525182247162, 0.5586086511611938]\n",
      "1200 steps | score: [-0.22031651437282562, 0.5509423017501831]\n",
      "1300 steps | score: [-0.08631230890750885, 0.2357574999332428]\n",
      "1400 steps | score: [-0.22994878888130188, 0.5632016062736511]\n",
      "1500 steps | score: [-0.25134706497192383, 0.605042576789856]\n",
      "1600 steps | score: [-0.24461729824543, 0.5752744674682617]\n",
      "1700 steps | score: [-0.3450646996498108, 0.7870702147483826]\n",
      "1800 steps | score: [-0.25123894214630127, 0.626502513885498]\n",
      "1900 steps | score: [-0.13410167396068573, 0.32443928718566895]\n",
      "2000 steps | score: [-0.14250397682189941, 0.3692306578159332]\n",
      "2100 steps | score: [-0.06580579280853271, 0.12590166926383972]\n",
      "2200 steps | score: [-0.2664353549480438, 0.6570160388946533]\n",
      "2300 steps | score: [-0.20131701231002808, 0.4718135595321655]\n",
      "2400 steps | score: [-0.17273478209972382, 0.37822097539901733]\n",
      "2500 steps | score: [-0.2430051565170288, 0.5818589329719543]\n",
      "2600 steps | score: [-0.18079935014247894, 0.45147743821144104]\n",
      "2700 steps | score: [-0.14749807119369507, 0.3064367175102234]\n",
      "unknown params:  tensor([-0.7811,  0.5338, -0.6487, -0.3778, -0.3828,  0.6905])\n",
      "gt params:  tensor([-0.8475,  0.5989, -0.6711, -0.3863, -0.4046,  0.7158])\n",
      "ols params:  tensor([-0.4403,  0.3090, -0.3718, -0.2176, -0.2238,  4.0911])\n",
      "unknown mse:  tensor(0.0017)\n",
      "ols mse:  tensor(1.9655)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/321ea2f5-e77d-4b1d-adad-4b2a3d1090c0\n",
      "gt params:  tensor([-0.4218, -0.4035, -0.3855,  0.5433, -0.2174, -0.5212])\n",
      "0 steps | score: [0.17214013636112213]\n",
      "100 steps | score: [-0.07393041253089905]\n",
      "200 steps | score: [0.07915845513343811]\n",
      "300 steps | score: [-0.01508018746972084]\n",
      "400 steps | score: [0.1525236815214157]\n",
      "500 steps | score: [-0.012107698246836662]\n",
      "600 steps | score: [0.028353765606880188]\n",
      "700 steps | score: [0.05091053992509842]\n",
      "800 steps | score: [0.038726937025785446]\n",
      "900 steps | score: [0.054774802178144455]\n",
      "1000 steps | score: [0.011567369103431702]\n",
      "1100 steps | score: [0.11666509509086609]\n",
      "1200 steps | score: [-0.0016533425077795982]\n",
      "0 steps | score: [0.038052741438150406, 0.5410432815551758]\n",
      "100 steps | score: [-0.18440259993076324, 0.9629696607589722]\n",
      "200 steps | score: [-0.5441377758979797, 1.9303828477859497]\n",
      "300 steps | score: [-0.48735660314559937, 1.8249009847640991]\n",
      "400 steps | score: [-0.13258416950702667, 0.625998854637146]\n",
      "500 steps | score: [-0.34500330686569214, 1.379795789718628]\n",
      "600 steps | score: [-0.3651529550552368, 1.440422534942627]\n",
      "700 steps | score: [-0.3538610637187958, 1.3961341381072998]\n",
      "800 steps | score: [-0.03116750903427601, 0.3769376873970032]\n",
      "900 steps | score: [-0.3549211621284485, 1.3764991760253906]\n",
      "1000 steps | score: [0.06836830824613571, -0.008013781160116196]\n",
      "1100 steps | score: [0.12134945392608643, -0.2283889800310135]\n",
      "1200 steps | score: [-0.22058932483196259, 0.9587240815162659]\n",
      "1300 steps | score: [0.032848943024873734, 0.1598377227783203]\n",
      "1400 steps | score: [-0.11274651437997818, 0.6020585894584656]\n",
      "1500 steps | score: [-0.11099141091108322, 0.5679467916488647]\n",
      "1600 steps | score: [-0.3652420938014984, 1.3822877407073975]\n",
      "1700 steps | score: [-0.2506151497364044, 1.028378963470459]\n",
      "1800 steps | score: [-0.3372962176799774, 1.2710487842559814]\n",
      "1900 steps | score: [-0.08721469342708588, 0.5291277766227722]\n",
      "2000 steps | score: [-0.2594364583492279, 1.0359665155410767]\n",
      "2100 steps | score: [-0.10308059304952621, 0.578769326210022]\n",
      "2200 steps | score: [-0.07799363136291504, 0.46887484192848206]\n",
      "2300 steps | score: [-0.16170136630535126, 0.733891487121582]\n",
      "2400 steps | score: [-0.10789725184440613, 0.5525881052017212]\n",
      "2500 steps | score: [-0.06742849200963974, 0.4603383243083954]\n",
      "unknown params:  tensor([-0.4459, -0.4255, -0.4082,  0.5770, -0.2336, -0.4423])\n",
      "gt params:  tensor([-0.4218, -0.4035, -0.3855,  0.5433, -0.2174, -0.5212])\n",
      "ols params:  tensor([-0.3306, -0.3194, -0.3079,  0.4269, -0.1761,  0.2776])\n",
      "unknown mse:  tensor(0.0015)\n",
      "ols mse:  tensor(0.1124)\n",
      "gt params:  tensor([-0.4221, -0.4113, -0.3879,  0.5517, -0.2086, -0.5313])\n",
      "0 steps | score: [0.2002052366733551]\n",
      "100 steps | score: [-0.04170208424329758]\n",
      "200 steps | score: [-0.06883300840854645]\n",
      "300 steps | score: [-0.050516627728939056]\n",
      "400 steps | score: [-0.002713128924369812]\n",
      "0 steps | score: [-0.07310610264539719, 0.2560712695121765]\n",
      "100 steps | score: [-0.1097005233168602, 0.035994403064250946]\n",
      "200 steps | score: [-0.27303415536880493, 0.5070837736129761]\n",
      "300 steps | score: [-0.5529280304908752, 1.3180584907531738]\n",
      "400 steps | score: [-0.031887706369161606, -0.253953754901886]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [-0.3658525049686432, 0.7951725721359253]\n",
      "600 steps | score: [0.21416334807872772, -1.2637463808059692]\n",
      "700 steps | score: [0.16200979053974152, -0.9652527570724487]\n",
      "800 steps | score: [-0.019711732864379883, -0.3042696416378021]\n",
      "900 steps | score: [0.3610866367816925, -1.656320333480835]\n",
      "1000 steps | score: [-0.0932212695479393, -0.156269371509552]\n",
      "1100 steps | score: [0.30895528197288513, -1.5505223274230957]\n",
      "1200 steps | score: [-0.19769319891929626, 0.24848295748233795]\n",
      "1300 steps | score: [-0.17006444931030273, 0.17853528261184692]\n",
      "1400 steps | score: [-0.509023904800415, 1.1272928714752197]\n",
      "1500 steps | score: [-0.28005439043045044, 0.47133034467697144]\n",
      "1600 steps | score: [-0.2786708474159241, 0.5015662908554077]\n",
      "1700 steps | score: [-0.18735752999782562, 0.19110459089279175]\n",
      "1800 steps | score: [-0.07930505275726318, -0.16831661760807037]\n",
      "1900 steps | score: [-0.14104275405406952, 0.05438367277383804]\n",
      "2000 steps | score: [-0.054893817752599716, -0.205362930893898]\n",
      "2100 steps | score: [-0.03471706062555313, -0.30779361724853516]\n",
      "2200 steps | score: [-0.27656790614128113, 0.4864271879196167]\n",
      "2300 steps | score: [-0.22642305493354797, 0.3210331201553345]\n",
      "2400 steps | score: [-0.06816079467535019, -0.17649778723716736]\n",
      "2500 steps | score: [-0.1884564608335495, 0.22625082731246948]\n",
      "unknown params:  tensor([-0.4274, -0.3991, -0.3935,  0.5515, -0.2033, -0.3872])\n",
      "gt params:  tensor([-0.4221, -0.4113, -0.3879,  0.5517, -0.2086, -0.5313])\n",
      "ols params:  tensor([-0.2848, -0.2716, -0.2652,  0.3656, -0.1400,  0.7723])\n",
      "unknown mse:  tensor(0.0035)\n",
      "ols mse:  tensor(0.2987)\n",
      "gt params:  tensor([-0.4113, -0.4033, -0.3878,  0.5601, -0.2055, -0.5244])\n",
      "0 steps | score: [0.3419824540615082]\n",
      "100 steps | score: [0.09585541486740112]\n",
      "200 steps | score: [0.04945698752999306]\n",
      "300 steps | score: [0.10563443601131439]\n",
      "400 steps | score: [0.0519319623708725]\n",
      "500 steps | score: [0.043985653668642044]\n",
      "600 steps | score: [0.06650421023368835]\n",
      "700 steps | score: [0.10661955177783966]\n",
      "800 steps | score: [0.06370806694030762]\n",
      "900 steps | score: [0.09569169580936432]\n",
      "1000 steps | score: [0.04754619672894478]\n",
      "1100 steps | score: [0.09103013575077057]\n",
      "1200 steps | score: [0.11171644926071167]\n",
      "1300 steps | score: [0.11677128821611404]\n",
      "1400 steps | score: [0.061192870140075684]\n",
      "1500 steps | score: [0.05479537323117256]\n",
      "1600 steps | score: [0.08656729757785797]\n",
      "1700 steps | score: [0.053851500153541565]\n",
      "1800 steps | score: [0.08411027491092682]\n",
      "1900 steps | score: [0.07143505662679672]\n",
      "2000 steps | score: [0.0943753644824028]\n",
      "2100 steps | score: [0.09998161345720291]\n",
      "2200 steps | score: [0.1035870611667633]\n",
      "2300 steps | score: [0.05755011737346649]\n",
      "2400 steps | score: [0.03688586503267288]\n",
      "2500 steps | score: [0.08443893492221832]\n",
      "0 steps | score: [0.2324967086315155, -0.3651100993156433]\n",
      "100 steps | score: [-0.02325107902288437, 0.05031757801771164]\n",
      "200 steps | score: [0.10093142837285995, -0.31703948974609375]\n",
      "300 steps | score: [0.2775130569934845, -0.9165046215057373]\n",
      "400 steps | score: [-0.06391406059265137, 0.019425513222813606]\n",
      "500 steps | score: [-0.13677626848220825, 0.22988039255142212]\n",
      "600 steps | score: [0.02362792007625103, -0.17291226983070374]\n",
      "700 steps | score: [0.17697057127952576, -0.6335885524749756]\n",
      "800 steps | score: [0.19095100462436676, -0.7464844584465027]\n",
      "900 steps | score: [-0.08487705886363983, 0.04427247494459152]\n",
      "1000 steps | score: [0.28933185338974, -1.0363552570343018]\n",
      "1100 steps | score: [0.07864405959844589, -0.35874292254447937]\n",
      "1200 steps | score: [0.37082064151763916, -1.286982536315918]\n",
      "1300 steps | score: [0.2716500461101532, -1.003883957862854]\n",
      "1400 steps | score: [-0.03953956067562103, -0.03788662701845169]\n",
      "1500 steps | score: [0.033329520374536514, -0.23083293437957764]\n",
      "1600 steps | score: [0.13265563547611237, -0.508784294128418]\n",
      "1700 steps | score: [0.016783591359853745, -0.19297915697097778]\n",
      "1800 steps | score: [0.15790124237537384, -0.5803655982017517]\n",
      "1900 steps | score: [0.1967717409133911, -0.7653310298919678]\n",
      "2000 steps | score: [0.14016997814178467, -0.5524617433547974]\n",
      "2100 steps | score: [0.05244896188378334, -0.31035125255584717]\n",
      "2200 steps | score: [0.05428985878825188, -0.3427007794380188]\n",
      "2300 steps | score: [0.11688826978206635, -0.5173681378364563]\n",
      "2400 steps | score: [0.09274490177631378, -0.42162373661994934]\n",
      "2500 steps | score: [0.1371370553970337, -0.5408301949501038]\n",
      "unknown params:  tensor([-0.4221, -0.4295, -0.4194,  0.5721, -0.2143, -0.3301])\n",
      "gt params:  tensor([-0.4113, -0.4033, -0.3878,  0.5601, -0.2055, -0.5244])\n",
      "ols params:  tensor([-0.2432, -0.2480, -0.2430,  0.3228, -0.1242,  1.1360])\n",
      "unknown mse:  tensor(0.0066)\n",
      "ols mse:  tensor(0.4822)\n",
      "gt params:  tensor([-0.4274, -0.4049, -0.3786,  0.5630, -0.2085, -0.5525])\n",
      "0 steps | score: [0.47465407848358154]\n",
      "100 steps | score: [0.30625611543655396]\n",
      "200 steps | score: [0.23139983415603638]\n",
      "300 steps | score: [0.2555788457393646]\n",
      "400 steps | score: [0.2709508538246155]\n",
      "500 steps | score: [0.19659867882728577]\n",
      "600 steps | score: [0.22523339092731476]\n",
      "700 steps | score: [0.20176821947097778]\n",
      "800 steps | score: [0.16036352515220642]\n",
      "900 steps | score: [0.22537726163864136]\n",
      "1000 steps | score: [0.2715142071247101]\n",
      "1100 steps | score: [0.28141891956329346]\n",
      "1200 steps | score: [0.18828362226486206]\n",
      "1300 steps | score: [0.24734848737716675]\n",
      "1400 steps | score: [0.22709937393665314]\n",
      "1500 steps | score: [0.2161913365125656]\n",
      "1600 steps | score: [0.23911011219024658]\n",
      "1700 steps | score: [0.2508907616138458]\n",
      "1800 steps | score: [0.20207780599594116]\n",
      "1900 steps | score: [0.22547155618667603]\n",
      "2000 steps | score: [0.20629504323005676]\n",
      "2100 steps | score: [0.19735299050807953]\n",
      "2200 steps | score: [0.19710969924926758]\n",
      "2300 steps | score: [0.22535786032676697]\n",
      "2400 steps | score: [0.2406492382287979]\n",
      "2500 steps | score: [0.2229456752538681]\n",
      "2600 steps | score: [0.21501731872558594]\n",
      "0 steps | score: [0.19854572415351868, -0.22011688351631165]\n",
      "100 steps | score: [0.25649189949035645, -0.5844805240631104]\n",
      "200 steps | score: [0.10993315279483795, -0.3155707120895386]\n",
      "300 steps | score: [-0.0897684395313263, 0.15886226296424866]\n",
      "400 steps | score: [-0.05929518863558769, 0.07072190195322037]\n",
      "500 steps | score: [0.019112924113869667, -0.10567240417003632]\n",
      "600 steps | score: [-0.06798264384269714, 0.08818923681974411]\n",
      "700 steps | score: [-0.06416861712932587, 0.07008172571659088]\n",
      "800 steps | score: [-0.1884123682975769, 0.359801322221756]\n",
      "900 steps | score: [-0.001924225129187107, -0.06223876774311066]\n",
      "1000 steps | score: [0.06424162536859512, -0.22539636492729187]\n",
      "1100 steps | score: [0.12797129154205322, -0.40915027260780334]\n",
      "1200 steps | score: [-0.07936379313468933, 0.09397654980421066]\n",
      "1300 steps | score: [-0.055832404643297195, 0.045062191784381866]\n",
      "1400 steps | score: [0.09921657294034958, -0.326600044965744]\n",
      "1500 steps | score: [-0.05911318212747574, 0.030659180134534836]\n",
      "1600 steps | score: [0.023730367422103882, -0.12211446464061737]\n",
      "1700 steps | score: [0.057559866458177567, -0.18829181790351868]\n",
      "1800 steps | score: [-0.049758609384298325, 0.04783807322382927]\n",
      "1900 steps | score: [-0.09542125463485718, 0.11432380974292755]\n",
      "2000 steps | score: [-0.03499773144721985, 0.014867573976516724]\n",
      "2100 steps | score: [-0.13178561627864838, 0.22731515765190125]\n",
      "2200 steps | score: [-0.07679783552885056, 0.08374286442995071]\n",
      "2300 steps | score: [-0.022851815447211266, -0.006234191358089447]\n",
      "2400 steps | score: [0.03977815806865692, -0.1681002676486969]\n",
      "2500 steps | score: [-0.08096209168434143, 0.12488119304180145]\n",
      "2600 steps | score: [-0.02154948003590107, -0.039153534919023514]\n",
      "unknown params:  tensor([-0.4409, -0.4225, -0.3782,  0.5408, -0.2258, -0.3068])\n",
      "gt params:  tensor([-0.4274, -0.4049, -0.3786,  0.5630, -0.2085, -0.5525])\n",
      "ols params:  tensor([-0.2410, -0.2353, -0.2132,  0.2934, -0.1272,  1.3643])\n",
      "unknown mse:  tensor(0.0103)\n",
      "ols mse:  tensor(0.6407)\n",
      "gt params:  tensor([-0.4288, -0.4046, -0.3945,  0.5515, -0.2141, -0.4951])\n",
      "0 steps | score: [0.21431203186511993]\n",
      "100 steps | score: [0.0062524378299713135]\n",
      "0 steps | score: [0.2573084831237793, -0.1357041299343109]\n",
      "100 steps | score: [0.13366127014160156, -0.04290572181344032]\n",
      "200 steps | score: [0.39922258257865906, -0.7695515751838684]\n",
      "300 steps | score: [0.028023477643728256, 0.12182175368070602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 steps | score: [0.056892476975917816, 0.030610300600528717]\n",
      "500 steps | score: [-0.16222523152828217, 0.5512189269065857]\n",
      "600 steps | score: [0.0018374079372733831, 0.18181435763835907]\n",
      "700 steps | score: [0.30003684759140015, -0.5855820178985596]\n",
      "800 steps | score: [-0.013233337551355362, 0.19738101959228516]\n",
      "900 steps | score: [0.1483936309814453, -0.18172848224639893]\n",
      "1000 steps | score: [0.04882586747407913, 0.04454794153571129]\n",
      "1100 steps | score: [-0.05736977234482765, 0.29199719429016113]\n",
      "1200 steps | score: [0.12359219044446945, -0.10190893709659576]\n",
      "1300 steps | score: [-0.06857815384864807, 0.2909209132194519]\n",
      "1400 steps | score: [0.04241831228137016, 0.05840055271983147]\n",
      "1500 steps | score: [0.12677817046642303, -0.13435934484004974]\n",
      "1600 steps | score: [-0.07806471735239029, 0.33507293462753296]\n",
      "1700 steps | score: [-0.06482724845409393, 0.27886512875556946]\n",
      "1800 steps | score: [0.06539160013198853, 0.05214567109942436]\n",
      "1900 steps | score: [0.0853729173541069, -0.023811500519514084]\n",
      "2000 steps | score: [0.14478376507759094, -0.12284435331821442]\n",
      "2100 steps | score: [0.011455905623733997, 0.127933531999588]\n",
      "2200 steps | score: [-0.04275180399417877, 0.24910207092761993]\n",
      "2300 steps | score: [0.04599277302622795, 0.08060233294963837]\n",
      "2400 steps | score: [0.10601174831390381, -0.054662320762872696]\n",
      "2500 steps | score: [0.08910088241100311, -0.03921685367822647]\n",
      "2600 steps | score: [0.015803366899490356, 0.14382034540176392]\n",
      "unknown params:  tensor([-0.3905, -0.4052, -0.3713,  0.5081, -0.2087, -0.2892])\n",
      "gt params:  tensor([-0.4288, -0.4046, -0.3945,  0.5515, -0.2141, -0.4951])\n",
      "ols params:  tensor([-0.2220, -0.2317, -0.2166,  0.2889, -0.1238,  1.6035])\n",
      "unknown mse:  tensor(0.0077)\n",
      "ols mse:  tensor(0.7643)\n",
      "gt params:  tensor([-0.4218, -0.4053, -0.3870,  0.5364, -0.2322, -0.5198])\n",
      "0 steps | score: [0.43570566177368164]\n",
      "100 steps | score: [0.11789111793041229]\n",
      "200 steps | score: [0.13112682104110718]\n",
      "300 steps | score: [0.11177142709493637]\n",
      "400 steps | score: [0.14767834544181824]\n",
      "500 steps | score: [0.16114655137062073]\n",
      "600 steps | score: [0.15556354820728302]\n",
      "700 steps | score: [0.16140617430210114]\n",
      "800 steps | score: [0.08334235846996307]\n",
      "900 steps | score: [0.10506828874349594]\n",
      "1000 steps | score: [0.14329028129577637]\n",
      "1100 steps | score: [0.1059185266494751]\n",
      "1200 steps | score: [0.11932816356420517]\n",
      "1300 steps | score: [0.16681881248950958]\n",
      "1400 steps | score: [0.1322251856327057]\n",
      "1500 steps | score: [0.141253262758255]\n",
      "1600 steps | score: [0.12679438292980194]\n",
      "1700 steps | score: [0.11363252997398376]\n",
      "1800 steps | score: [0.12300203740596771]\n",
      "1900 steps | score: [0.13953745365142822]\n",
      "2000 steps | score: [0.11252537369728088]\n",
      "2100 steps | score: [0.138104647397995]\n",
      "2200 steps | score: [0.12351710349321365]\n",
      "2300 steps | score: [0.13408567011356354]\n",
      "2400 steps | score: [0.124629445374012]\n",
      "2500 steps | score: [0.12900909781455994]\n",
      "2600 steps | score: [0.12526680529117584]\n",
      "0 steps | score: [0.4641024172306061, -0.6860513687133789]\n",
      "100 steps | score: [0.24462322890758514, -0.36323100328445435]\n",
      "200 steps | score: [0.10700152069330215, -0.13775715231895447]\n",
      "300 steps | score: [0.2610391676425934, -0.500267505645752]\n",
      "400 steps | score: [0.3265198767185211, -0.6502947211265564]\n",
      "500 steps | score: [0.5731504559516907, -1.4288071393966675]\n",
      "600 steps | score: [0.635932981967926, -1.5881249904632568]\n",
      "700 steps | score: [0.3593084216117859, -0.8257193565368652]\n",
      "800 steps | score: [0.2875778377056122, -0.5947334170341492]\n",
      "900 steps | score: [0.24491818249225616, -0.47727471590042114]\n",
      "1000 steps | score: [0.4007781445980072, -0.9290004372596741]\n",
      "1100 steps | score: [0.269361674785614, -0.5797081589698792]\n",
      "1200 steps | score: [0.3208567202091217, -0.6577321887016296]\n",
      "1300 steps | score: [0.35947510600090027, -0.8192715644836426]\n",
      "1400 steps | score: [0.3811798095703125, -0.9176826477050781]\n",
      "1500 steps | score: [0.46037745475769043, -1.0361838340759277]\n",
      "1600 steps | score: [0.481486439704895, -1.177625298500061]\n",
      "1700 steps | score: [0.3924867510795593, -0.8657617568969727]\n",
      "1800 steps | score: [0.23923490941524506, -0.5052648782730103]\n",
      "1900 steps | score: [0.2611961364746094, -0.5313876867294312]\n",
      "2000 steps | score: [0.24295063316822052, -0.5083291530609131]\n",
      "2100 steps | score: [0.25366654992103577, -0.5411834120750427]\n",
      "2200 steps | score: [0.41667813062667847, -0.9599595665931702]\n",
      "2300 steps | score: [0.3314554691314697, -0.739207923412323]\n",
      "2400 steps | score: [0.38889166712760925, -0.861872673034668]\n",
      "2500 steps | score: [0.39262107014656067, -0.8602707982063293]\n",
      "2600 steps | score: [0.3756679594516754, -0.8728072643280029]\n",
      "unknown params:  tensor([-0.4208, -0.4106, -0.3754,  0.5265, -0.2419, -0.3138])\n",
      "gt params:  tensor([-0.4218, -0.4053, -0.3870,  0.5364, -0.2322, -0.5198])\n",
      "ols params:  tensor([-0.2129, -0.2084, -0.1915,  0.2645, -0.1246,  1.8074])\n",
      "unknown mse:  tensor(0.0071)\n",
      "ols mse:  tensor(0.9370)\n",
      "gt params:  tensor([-0.4201, -0.4026, -0.3837,  0.5588, -0.2139, -0.5104])\n",
      "0 steps | score: [0.5190834999084473]\n",
      "100 steps | score: [0.24734371900558472]\n",
      "200 steps | score: [0.24003830552101135]\n",
      "300 steps | score: [0.2563377320766449]\n",
      "400 steps | score: [0.20856767892837524]\n",
      "500 steps | score: [0.23778507113456726]\n",
      "600 steps | score: [0.2508210241794586]\n",
      "700 steps | score: [0.23910824954509735]\n",
      "800 steps | score: [0.21431219577789307]\n",
      "900 steps | score: [0.19643014669418335]\n",
      "1000 steps | score: [0.18125692009925842]\n",
      "1100 steps | score: [0.19221162796020508]\n",
      "1200 steps | score: [0.2174825817346573]\n",
      "1300 steps | score: [0.1884201467037201]\n",
      "1400 steps | score: [0.18173450231552124]\n",
      "1500 steps | score: [0.20858386158943176]\n",
      "1600 steps | score: [0.22492440044879913]\n",
      "1700 steps | score: [0.19722536206245422]\n",
      "1800 steps | score: [0.1903110146522522]\n",
      "1900 steps | score: [0.21570536494255066]\n",
      "2000 steps | score: [0.21379373967647552]\n",
      "2100 steps | score: [0.20961174368858337]\n",
      "2200 steps | score: [0.19832833111286163]\n",
      "2300 steps | score: [0.20048171281814575]\n",
      "2400 steps | score: [0.19467651844024658]\n",
      "2500 steps | score: [0.2003713995218277]\n",
      "2600 steps | score: [0.2110079973936081]\n",
      "0 steps | score: [0.30193832516670227, -0.45823922753334045]\n",
      "100 steps | score: [0.3885990381240845, -0.8982617855072021]\n",
      "200 steps | score: [0.13155913352966309, -0.3253321349620819]\n",
      "300 steps | score: [0.13150149583816528, -0.3247028589248657]\n",
      "400 steps | score: [-0.0026389104314148426, -0.0646391212940216]\n",
      "500 steps | score: [0.11299454420804977, -0.3210628628730774]\n",
      "600 steps | score: [0.1622365266084671, -0.4457690715789795]\n",
      "700 steps | score: [0.12721242010593414, -0.36676454544067383]\n",
      "800 steps | score: [0.3074742257595062, -0.8018991351127625]\n",
      "900 steps | score: [-0.061882250010967255, 0.03888550028204918]\n",
      "1000 steps | score: [0.10648825019598007, -0.3645499348640442]\n",
      "1100 steps | score: [0.0026424783281981945, -0.11329385638237]\n",
      "1200 steps | score: [-0.0473964661359787, 0.031850144267082214]\n",
      "1300 steps | score: [0.05326113849878311, -0.2185274064540863]\n",
      "1400 steps | score: [0.00789504311978817, -0.10219866037368774]\n",
      "1500 steps | score: [0.10224388539791107, -0.30456700921058655]\n",
      "1600 steps | score: [0.1845344603061676, -0.5322293043136597]\n",
      "1700 steps | score: [0.16131527721881866, -0.44515830278396606]\n",
      "1800 steps | score: [0.09666532278060913, -0.3187684118747711]\n",
      "1900 steps | score: [0.11787538975477219, -0.3646925389766693]\n",
      "2000 steps | score: [0.13926178216934204, -0.42211437225341797]\n",
      "2100 steps | score: [0.15046657621860504, -0.45108693838119507]\n",
      "2200 steps | score: [0.05977324768900871, -0.22330652177333832]\n",
      "2300 steps | score: [0.10631263256072998, -0.33742642402648926]\n",
      "2400 steps | score: [0.06152121722698212, -0.24542295932769775]\n",
      "2500 steps | score: [0.09369498491287231, -0.3187613785266876]\n",
      "2600 steps | score: [0.0725567489862442, -0.2937144637107849]\n",
      "unknown params:  tensor([-0.4197, -0.4502, -0.3835,  0.5522, -0.2245, -0.2987])\n",
      "gt params:  tensor([-0.4201, -0.4026, -0.3837,  0.5588, -0.2139, -0.5104])\n",
      "ols params:  tensor([-0.2079, -0.2206, -0.1906,  0.2664, -0.1127,  1.9500])\n",
      "unknown mse:  tensor(0.0079)\n",
      "ols mse:  tensor(1.0442)\n",
      "gt params:  tensor([-0.4376, -0.3955, -0.3860,  0.5577, -0.1940, -0.5203])\n",
      "0 steps | score: [0.4020160734653473]\n",
      "100 steps | score: [0.07934799790382385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [0.11938366293907166]\n",
      "300 steps | score: [0.1097484901547432]\n",
      "400 steps | score: [0.14435219764709473]\n",
      "500 steps | score: [0.11589504778385162]\n",
      "600 steps | score: [0.07152317464351654]\n",
      "700 steps | score: [0.13652953505516052]\n",
      "800 steps | score: [0.11762157827615738]\n",
      "900 steps | score: [0.13145500421524048]\n",
      "1000 steps | score: [0.08124846965074539]\n",
      "1100 steps | score: [0.10846652090549469]\n",
      "1200 steps | score: [0.08301019668579102]\n",
      "1300 steps | score: [0.13467518985271454]\n",
      "1400 steps | score: [0.109745092689991]\n",
      "1500 steps | score: [0.08517557382583618]\n",
      "1600 steps | score: [0.11346769332885742]\n",
      "1700 steps | score: [0.11417500674724579]\n",
      "1800 steps | score: [0.13713952898979187]\n",
      "1900 steps | score: [0.09238419681787491]\n",
      "2000 steps | score: [0.0848546251654625]\n",
      "2100 steps | score: [0.08911971002817154]\n",
      "2200 steps | score: [0.11146167665719986]\n",
      "2300 steps | score: [0.11171382665634155]\n",
      "2400 steps | score: [0.1023343950510025]\n",
      "2500 steps | score: [0.11063873767852783]\n",
      "2600 steps | score: [0.10927548259496689]\n",
      "0 steps | score: [0.20301993191242218, -0.15136078000068665]\n",
      "100 steps | score: [0.39901700615882874, -0.8737368583679199]\n",
      "200 steps | score: [0.16012807190418243, -0.3444136381149292]\n",
      "300 steps | score: [-0.23304595053195953, 0.4920368194580078]\n",
      "400 steps | score: [0.034304454922676086, -0.012542515993118286]\n",
      "500 steps | score: [-0.09923220425844193, 0.21274107694625854]\n",
      "600 steps | score: [-0.16802579164505005, 0.34785935282707214]\n",
      "700 steps | score: [0.2821411192417145, -0.6851916313171387]\n",
      "800 steps | score: [0.024391429498791695, -0.06312254816293716]\n",
      "900 steps | score: [0.034351497888565063, -0.101673424243927]\n",
      "1000 steps | score: [-0.03531105816364288, 0.03620653599500656]\n",
      "1100 steps | score: [0.025204593315720558, -0.06280894577503204]\n",
      "1200 steps | score: [-0.10722262412309647, 0.21868741512298584]\n",
      "1300 steps | score: [0.03358149901032448, -0.07587245106697083]\n",
      "1400 steps | score: [-0.014531190507113934, 0.02479960396885872]\n",
      "1500 steps | score: [-0.13120803236961365, 0.26182419061660767]\n",
      "1600 steps | score: [0.0654294490814209, -0.2034282684326172]\n",
      "1700 steps | score: [0.003027503378689289, -0.017199154943227768]\n",
      "1800 steps | score: [0.10656062513589859, -0.24799899756908417]\n",
      "1900 steps | score: [-0.0584036223590374, 0.14901791512966156]\n",
      "2000 steps | score: [0.014680859632790089, -0.02572128176689148]\n",
      "2100 steps | score: [-0.07018376141786575, 0.14667737483978271]\n",
      "2200 steps | score: [0.04694278910756111, -0.11255200207233429]\n",
      "2300 steps | score: [-0.023048890754580498, 0.025890417397022247]\n",
      "2400 steps | score: [-0.07787345349788666, 0.1751946210861206]\n",
      "2500 steps | score: [0.03137369081377983, -0.10820455849170685]\n",
      "2600 steps | score: [0.044268324971199036, -0.10332269966602325]\n",
      "unknown params:  tensor([-0.4690, -0.4013, -0.4067,  0.5715, -0.1989, -0.2446])\n",
      "gt params:  tensor([-0.4376, -0.3955, -0.3860,  0.5577, -0.1940, -0.5203])\n",
      "ols params:  tensor([-0.2137, -0.1857, -0.1876,  0.2611, -0.0940,  2.0928])\n",
      "unknown mse:  tensor(0.0129)\n",
      "ols mse:  tensor(1.1766)\n",
      "gt params:  tensor([-0.4227, -0.3999, -0.3938,  0.5533, -0.2203, -0.5426])\n",
      "0 steps | score: [0.4797525405883789]\n",
      "100 steps | score: [0.17883455753326416]\n",
      "200 steps | score: [0.14592041075229645]\n",
      "300 steps | score: [0.20039953291416168]\n",
      "400 steps | score: [0.16425418853759766]\n",
      "500 steps | score: [0.17422236502170563]\n",
      "600 steps | score: [0.14785851538181305]\n",
      "700 steps | score: [0.12251553684473038]\n",
      "800 steps | score: [0.12408775091171265]\n",
      "900 steps | score: [0.17599590122699738]\n",
      "1000 steps | score: [0.1345936357975006]\n",
      "1100 steps | score: [0.10852743685245514]\n",
      "1200 steps | score: [0.15537628531455994]\n",
      "1300 steps | score: [0.15318116545677185]\n",
      "1400 steps | score: [0.14559808373451233]\n",
      "1500 steps | score: [0.16372372210025787]\n",
      "1600 steps | score: [0.12657438218593597]\n",
      "1700 steps | score: [0.13299337029457092]\n",
      "1800 steps | score: [0.15921609103679657]\n",
      "1900 steps | score: [0.12891361117362976]\n",
      "2000 steps | score: [0.12883423268795013]\n",
      "2100 steps | score: [0.16951709985733032]\n",
      "2200 steps | score: [0.11566868424415588]\n",
      "2300 steps | score: [0.14418449997901917]\n",
      "2400 steps | score: [0.18057569861412048]\n",
      "2500 steps | score: [0.1486276537179947]\n",
      "2600 steps | score: [0.13266095519065857]\n",
      "0 steps | score: [0.1876668930053711, 0.08293047547340393]\n",
      "100 steps | score: [-0.173678919672966, 0.6418610215187073]\n",
      "200 steps | score: [0.0013638221425935626, 0.25985026359558105]\n",
      "300 steps | score: [0.03802444413304329, 0.1918453425168991]\n",
      "400 steps | score: [0.08704818040132523, 0.058648206293582916]\n",
      "500 steps | score: [-0.133077010512352, 0.4893921911716461]\n",
      "600 steps | score: [-0.11430449783802032, 0.4327937066555023]\n",
      "700 steps | score: [-0.17605647444725037, 0.5925709009170532]\n",
      "800 steps | score: [-0.07087862491607666, 0.37515807151794434]\n",
      "900 steps | score: [-0.009731617756187916, 0.19919893145561218]\n",
      "1000 steps | score: [-0.07420429587364197, 0.36521297693252563]\n",
      "1100 steps | score: [-0.13046671450138092, 0.4812101721763611]\n",
      "1200 steps | score: [0.07167494297027588, 0.037841200828552246]\n",
      "1300 steps | score: [0.0915740579366684, 0.014968596398830414]\n",
      "1400 steps | score: [-0.06370270252227783, 0.3563479781150818]\n",
      "1500 steps | score: [-0.08077399432659149, 0.3870919346809387]\n",
      "1600 steps | score: [-0.0769873559474945, 0.36246824264526367]\n",
      "1700 steps | score: [-0.04906398057937622, 0.3176422119140625]\n",
      "1800 steps | score: [-0.031198348850011826, 0.24184760451316833]\n",
      "1900 steps | score: [-0.08366582542657852, 0.39369961619377136]\n",
      "2000 steps | score: [-0.032583385705947876, 0.27941131591796875]\n",
      "2100 steps | score: [0.00047955772606655955, 0.23423728346824646]\n",
      "2200 steps | score: [0.06582650542259216, 0.030839279294013977]\n",
      "2300 steps | score: [-0.008481188677251339, 0.23462913930416107]\n",
      "2400 steps | score: [-0.0651543140411377, 0.34050536155700684]\n",
      "2500 steps | score: [-0.0509469173848629, 0.3293323516845703]\n",
      "2600 steps | score: [-0.06573992967605591, 0.3435162603855133]\n",
      "unknown params:  tensor([-0.3974, -0.4058, -0.4047,  0.5279, -0.2268, -0.1606])\n",
      "gt params:  tensor([-0.4227, -0.3999, -0.3938,  0.5533, -0.2203, -0.5426])\n",
      "ols params:  tensor([-0.1869, -0.1913, -0.1893,  0.2460, -0.1072,  2.2797])\n",
      "unknown mse:  tensor(0.0246)\n",
      "ols mse:  tensor(1.3690)\n",
      "gt params:  tensor([-0.3979, -0.4052, -0.3848,  0.5643, -0.2301, -0.5374])\n",
      "0 steps | score: [0.3678100109100342]\n",
      "100 steps | score: [0.01915448158979416]\n",
      "200 steps | score: [0.06335887312889099]\n",
      "300 steps | score: [0.057076580822467804]\n",
      "400 steps | score: [0.06881239265203476]\n",
      "500 steps | score: [0.06479057669639587]\n",
      "600 steps | score: [0.058817051351070404]\n",
      "700 steps | score: [0.026616353541612625]\n",
      "800 steps | score: [0.014478961005806923]\n",
      "900 steps | score: [0.05209711194038391]\n",
      "1000 steps | score: [0.0433218777179718]\n",
      "1100 steps | score: [0.006523602642118931]\n",
      "0 steps | score: [0.03072485327720642, 0.17652104794979095]\n",
      "100 steps | score: [-0.26809266209602356, 0.622151255607605]\n",
      "200 steps | score: [-0.19696582853794098, 0.4383890628814697]\n",
      "300 steps | score: [-0.34669041633605957, 0.7435202598571777]\n",
      "400 steps | score: [0.1112341657280922, -0.32347631454467773]\n",
      "500 steps | score: [-0.265590637922287, 0.5548022985458374]\n",
      "600 steps | score: [-0.207307368516922, 0.4633308947086334]\n",
      "700 steps | score: [-0.09723453223705292, 0.21629899740219116]\n",
      "800 steps | score: [-0.3464275300502777, 0.7206544876098633]\n",
      "900 steps | score: [-0.21184010803699493, 0.41222652792930603]\n",
      "1000 steps | score: [-0.16023273766040802, 0.31214138865470886]\n",
      "1100 steps | score: [-0.3314790725708008, 0.6770609021186829]\n",
      "1200 steps | score: [-0.30085697770118713, 0.6082972884178162]\n",
      "1300 steps | score: [-0.1978580206632614, 0.39390474557876587]\n",
      "1400 steps | score: [-0.17967605590820312, 0.3795712888240814]\n",
      "1500 steps | score: [-0.11897292733192444, 0.2546825408935547]\n",
      "1600 steps | score: [-0.1335025578737259, 0.27073657512664795]\n",
      "1700 steps | score: [-0.08828887343406677, 0.1857903152704239]\n",
      "1800 steps | score: [-0.20654621720314026, 0.42871737480163574]\n",
      "1900 steps | score: [-0.15381933748722076, 0.31091421842575073]\n",
      "2000 steps | score: [-0.26185858249664307, 0.5236358642578125]\n",
      "2100 steps | score: [-0.16476042568683624, 0.32888028025627136]\n",
      "2200 steps | score: [-0.1723582148551941, 0.3218629062175751]\n",
      "2300 steps | score: [-0.14428165555000305, 0.2524271011352539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 steps | score: [-0.106406070291996, 0.18992440402507782]\n",
      "2500 steps | score: [-0.11667384207248688, 0.22912734746932983]\n",
      "2600 steps | score: [-0.14017458260059357, 0.2814216613769531]\n",
      "unknown params:  tensor([-0.3922, -0.4047, -0.3359,  0.5302, -0.2357, -0.1372])\n",
      "gt params:  tensor([-0.3979, -0.4052, -0.3848,  0.5643, -0.2301, -0.5374])\n",
      "ols params:  tensor([-0.1832, -0.1911, -0.1615,  0.2455, -0.1134,  2.4332])\n",
      "unknown mse:  tensor(0.0273)\n",
      "ols mse:  tensor(1.5136)\n",
      "gt params:  tensor([-0.4221, -0.4133, -0.3791,  0.5460, -0.2079, -0.5636])\n",
      "0 steps | score: [0.39557603001594543]\n",
      "100 steps | score: [0.0861717239022255]\n",
      "200 steps | score: [0.10736432671546936]\n",
      "300 steps | score: [0.029742762446403503]\n",
      "400 steps | score: [0.0779486894607544]\n",
      "500 steps | score: [0.13661348819732666]\n",
      "600 steps | score: [0.07243329286575317]\n",
      "700 steps | score: [0.08127808570861816]\n",
      "800 steps | score: [0.06453217566013336]\n",
      "900 steps | score: [0.12269261479377747]\n",
      "1000 steps | score: [0.05663979426026344]\n",
      "1100 steps | score: [0.07161397486925125]\n",
      "1200 steps | score: [0.0934702455997467]\n",
      "1300 steps | score: [0.07419479638338089]\n",
      "1400 steps | score: [0.0962238758802414]\n",
      "1500 steps | score: [0.09486985206604004]\n",
      "1600 steps | score: [0.06304936856031418]\n",
      "1700 steps | score: [0.05356445163488388]\n",
      "1800 steps | score: [0.08470599353313446]\n",
      "1900 steps | score: [0.08599475771188736]\n",
      "2000 steps | score: [0.11134201288223267]\n",
      "2100 steps | score: [0.09779053926467896]\n",
      "2200 steps | score: [0.08626894652843475]\n",
      "2300 steps | score: [0.08407017588615417]\n",
      "2400 steps | score: [0.1016344428062439]\n",
      "2500 steps | score: [0.09321106970310211]\n",
      "2600 steps | score: [0.09935778379440308]\n",
      "0 steps | score: [0.31198468804359436, -0.29724153876304626]\n",
      "100 steps | score: [0.27207496762275696, -0.32895395159721375]\n",
      "200 steps | score: [0.1318753957748413, -0.10131043195724487]\n",
      "300 steps | score: [-0.011334761045873165, 0.13967947661876678]\n",
      "400 steps | score: [-0.01676522009074688, 0.13541565835475922]\n",
      "500 steps | score: [0.12950018048286438, -0.150639608502388]\n",
      "600 steps | score: [0.06698484718799591, -0.02706976607441902]\n",
      "700 steps | score: [0.030606096610426903, 0.032038234174251556]\n",
      "800 steps | score: [0.1179443970322609, -0.14573772251605988]\n",
      "900 steps | score: [0.2990131080150604, -0.5522597432136536]\n",
      "1000 steps | score: [0.005454725120216608, 0.0732683539390564]\n",
      "1100 steps | score: [0.05312489718198776, -0.009095337241888046]\n",
      "1200 steps | score: [0.18571431934833527, -0.3019457161426544]\n",
      "1300 steps | score: [0.19076283276081085, -0.31990301609039307]\n",
      "1400 steps | score: [0.07300715148448944, -0.04832787066698074]\n",
      "1500 steps | score: [0.1967800259590149, -0.2930837869644165]\n",
      "1600 steps | score: [-0.02412283420562744, 0.13109473884105682]\n",
      "1700 steps | score: [0.08956148475408554, -0.08187413215637207]\n",
      "1800 steps | score: [0.19850322604179382, -0.33317628502845764]\n",
      "1900 steps | score: [0.08655942231416702, -0.07510378956794739]\n",
      "2000 steps | score: [0.09736760705709457, -0.1022624522447586]\n",
      "2100 steps | score: [0.14857687056064606, -0.1995982825756073]\n",
      "2200 steps | score: [0.12629856169223785, -0.16361750662326813]\n",
      "2300 steps | score: [0.09331110119819641, -0.08347700536251068]\n",
      "2400 steps | score: [0.11039246618747711, -0.12221868336200714]\n",
      "2500 steps | score: [0.093497134745121, -0.09898965060710907]\n",
      "2600 steps | score: [0.09103386104106903, -0.0865178257226944]\n",
      "unknown params:  tensor([-0.4404, -0.3449, -0.3659,  0.5243, -0.2100, -0.1784])\n",
      "gt params:  tensor([-0.4221, -0.4133, -0.3791,  0.5460, -0.2079, -0.5636])\n",
      "ols params:  tensor([-0.1932, -0.1543, -0.1639,  0.2262, -0.0939,  2.5837])\n",
      "unknown mse:  tensor(0.0257)\n",
      "ols mse:  tensor(1.6977)\n",
      "gt params:  tensor([-0.4480, -0.3973, -0.3856,  0.5378, -0.1959, -0.5732])\n",
      "0 steps | score: [0.18550656735897064]\n",
      "100 steps | score: [-0.12847012281417847]\n",
      "200 steps | score: [-0.10770772397518158]\n",
      "300 steps | score: [-0.12948596477508545]\n",
      "400 steps | score: [-0.10331068933010101]\n",
      "500 steps | score: [-0.12055955827236176]\n",
      "600 steps | score: [-0.05819167196750641]\n",
      "700 steps | score: [-0.10329493135213852]\n",
      "800 steps | score: [-0.070071741938591]\n",
      "900 steps | score: [-0.11454597115516663]\n",
      "1000 steps | score: [-0.07506664097309113]\n",
      "1100 steps | score: [-0.07915876805782318]\n",
      "1200 steps | score: [-0.1409740447998047]\n",
      "1300 steps | score: [-0.094645194709301]\n",
      "1400 steps | score: [-0.1376562863588333]\n",
      "1500 steps | score: [-0.08541950583457947]\n",
      "1600 steps | score: [-0.11586377769708633]\n",
      "1700 steps | score: [-0.08971567451953888]\n",
      "1800 steps | score: [-0.10411641001701355]\n",
      "1900 steps | score: [-0.09545913338661194]\n",
      "2000 steps | score: [-0.12110636383295059]\n",
      "2100 steps | score: [-0.11276733130216599]\n",
      "2200 steps | score: [-0.12133299559354782]\n",
      "2300 steps | score: [-0.11271863430738449]\n",
      "2400 steps | score: [-0.0849083662033081]\n",
      "2500 steps | score: [-0.10305990278720856]\n",
      "2600 steps | score: [-0.09013925492763519]\n",
      "0 steps | score: [0.2058105319738388, -0.18009069561958313]\n",
      "100 steps | score: [-0.06940053403377533, 0.20665641129016876]\n",
      "200 steps | score: [-0.10749852657318115, 0.2524876594543457]\n",
      "300 steps | score: [-0.07857201248407364, 0.1698157787322998]\n",
      "400 steps | score: [0.0037022866308689117, 0.022794462740421295]\n",
      "500 steps | score: [-0.017245445400476456, 0.023792468011379242]\n",
      "600 steps | score: [0.09223729372024536, -0.19737675786018372]\n",
      "700 steps | score: [-0.014456427656114101, 0.017845697700977325]\n",
      "800 steps | score: [0.3023039400577545, -0.6823279857635498]\n",
      "900 steps | score: [0.01550273783504963, -0.05349601060152054]\n",
      "1000 steps | score: [0.08257891237735748, -0.22963109612464905]\n",
      "1100 steps | score: [0.00286166463047266, -0.01852741837501526]\n",
      "1200 steps | score: [-0.10186239331960678, 0.1935715228319168]\n",
      "1300 steps | score: [0.04238520562648773, -0.1277627944946289]\n",
      "1400 steps | score: [-0.05375632271170616, 0.09226832538843155]\n",
      "1500 steps | score: [-0.10996317863464355, 0.18541443347930908]\n",
      "1600 steps | score: [0.029771713539958, -0.07782838493585587]\n",
      "1700 steps | score: [0.11396508663892746, -0.27747899293899536]\n",
      "1800 steps | score: [-0.02830912545323372, 0.047907114028930664]\n",
      "1900 steps | score: [0.03761579096317291, -0.07879764586687088]\n",
      "2000 steps | score: [-0.05292213708162308, 0.09380490332841873]\n",
      "2100 steps | score: [-0.03618227690458298, 0.09408058226108551]\n",
      "2200 steps | score: [-0.02774583175778389, 0.05567657947540283]\n",
      "2300 steps | score: [0.039789047092199326, -0.08240525424480438]\n",
      "2400 steps | score: [-0.005874539725482464, -0.02683233469724655]\n",
      "2500 steps | score: [0.029086530208587646, -0.05887971073389053]\n",
      "2600 steps | score: [0.007930858992040157, -0.03654143214225769]\n",
      "unknown params:  tensor([-0.4558, -0.3999, -0.3936,  0.5330, -0.1921, -0.2837])\n",
      "gt params:  tensor([-0.4480, -0.3973, -0.3856,  0.5378, -0.1959, -0.5732])\n",
      "ols params:  tensor([-0.1947, -0.1787, -0.1703,  0.2311, -0.0876,  2.6159])\n",
      "unknown mse:  tensor(0.0140)\n",
      "ols mse:  tensor(1.7390)\n",
      "gt params:  tensor([-0.4043, -0.3950, -0.4075,  0.5546, -0.1944, -0.5323])\n",
      "0 steps | score: [0.26811641454696655]\n",
      "100 steps | score: [-0.055974796414375305]\n",
      "200 steps | score: [-0.0885964184999466]\n",
      "300 steps | score: [-0.02714858576655388]\n",
      "400 steps | score: [-0.010009489953517914]\n",
      "500 steps | score: [-0.03988325595855713]\n",
      "600 steps | score: [-0.08668600767850876]\n",
      "700 steps | score: [-0.07208201289176941]\n",
      "800 steps | score: [-0.06793570518493652]\n",
      "900 steps | score: [-0.01637204736471176]\n",
      "1000 steps | score: [-0.0376780740916729]\n",
      "1100 steps | score: [-0.05548740178346634]\n",
      "1200 steps | score: [-0.025168489664793015]\n",
      "1300 steps | score: [-0.030854512006044388]\n",
      "1400 steps | score: [-0.054341044276952744]\n",
      "1500 steps | score: [-0.06044645234942436]\n",
      "1600 steps | score: [-0.05547340586781502]\n",
      "1700 steps | score: [-0.04136974737048149]\n",
      "1800 steps | score: [-0.043235860764980316]\n",
      "1900 steps | score: [-0.0657762959599495]\n",
      "2000 steps | score: [-0.03140580654144287]\n",
      "2100 steps | score: [-0.040832482278347015]\n",
      "2200 steps | score: [-0.022790193557739258]\n",
      "2300 steps | score: [-0.04770123213529587]\n",
      "2400 steps | score: [-0.05478383228182793]\n",
      "2500 steps | score: [-0.06737326085567474]\n",
      "2600 steps | score: [-0.05587516725063324]\n",
      "2700 steps | score: [-0.04165760055184364]\n",
      "0 steps | score: [0.2808423340320587, -0.522728443145752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [0.3055787980556488, -0.719485878944397]\n",
      "200 steps | score: [-0.23788714408874512, 0.28140509128570557]\n",
      "300 steps | score: [0.2675538659095764, -0.8042453527450562]\n",
      "400 steps | score: [0.4828783869743347, -1.3384525775909424]\n",
      "500 steps | score: [0.21258096396923065, -0.6332805156707764]\n",
      "600 steps | score: [-0.16185997426509857, 0.11992830038070679]\n",
      "700 steps | score: [0.11021377146244049, -0.45828545093536377]\n",
      "800 steps | score: [0.15058737993240356, -0.5219462513923645]\n",
      "900 steps | score: [0.14539572596549988, -0.5166140794754028]\n",
      "1000 steps | score: [0.2021099179983139, -0.640796959400177]\n",
      "1100 steps | score: [-0.07009731233119965, -0.049181316047906876]\n",
      "1200 steps | score: [0.22813375294208527, -0.7282583117485046]\n",
      "1300 steps | score: [0.2546314299106598, -0.7470775246620178]\n",
      "1400 steps | score: [0.1411803960800171, -0.4878699481487274]\n",
      "1500 steps | score: [-0.08943444490432739, -0.02104802429676056]\n",
      "1600 steps | score: [0.10814324021339417, -0.40465348958969116]\n",
      "1700 steps | score: [0.12472229450941086, -0.4696997106075287]\n",
      "1800 steps | score: [0.16467122733592987, -0.5835312008857727]\n",
      "1900 steps | score: [0.14307264983654022, -0.5213494300842285]\n",
      "2000 steps | score: [0.04143819212913513, -0.2912156581878662]\n",
      "2100 steps | score: [0.19675299525260925, -0.6677483916282654]\n",
      "2200 steps | score: [0.20909209549427032, -0.6526001691818237]\n",
      "2300 steps | score: [0.1245991513133049, -0.44291144609451294]\n",
      "2400 steps | score: [0.03773898631334305, -0.27556946873664856]\n",
      "2500 steps | score: [0.08276817202568054, -0.3659011125564575]\n",
      "2600 steps | score: [0.12278469651937485, -0.4461720585823059]\n",
      "2700 steps | score: [0.13143755495548248, -0.49770066142082214]\n",
      "unknown params:  tensor([-0.3529, -0.4118, -0.3850,  0.5881, -0.1777, -0.1537])\n",
      "gt params:  tensor([-0.4043, -0.3950, -0.4075,  0.5546, -0.1944, -0.5323])\n",
      "ols params:  tensor([-0.1543, -0.1762, -0.1664,  0.2475, -0.0781,  2.8043])\n",
      "unknown mse:  tensor(0.0247)\n",
      "ols mse:  tensor(1.9015)\n",
      "gt params:  tensor([-0.4361, -0.4021, -0.3606,  0.5637, -0.2013, -0.5171])\n",
      "0 steps | score: [0.409010112285614]\n",
      "100 steps | score: [0.09612125903367996]\n",
      "200 steps | score: [0.08501189947128296]\n",
      "300 steps | score: [0.07851775735616684]\n",
      "400 steps | score: [0.09776037186384201]\n",
      "500 steps | score: [0.07742500305175781]\n",
      "600 steps | score: [0.11610580235719681]\n",
      "700 steps | score: [0.06495261937379837]\n",
      "800 steps | score: [0.07709992676973343]\n",
      "900 steps | score: [0.07596959173679352]\n",
      "1000 steps | score: [0.08284381031990051]\n",
      "1100 steps | score: [0.07234673202037811]\n",
      "1200 steps | score: [0.07700102776288986]\n",
      "1300 steps | score: [0.09913994371891022]\n",
      "1400 steps | score: [0.09432997554540634]\n",
      "1500 steps | score: [0.10529518872499466]\n",
      "1600 steps | score: [0.09702378511428833]\n",
      "1700 steps | score: [0.08382125198841095]\n",
      "1800 steps | score: [0.08418766409158707]\n",
      "1900 steps | score: [0.11043089628219604]\n",
      "2000 steps | score: [0.0963730663061142]\n",
      "2100 steps | score: [0.09974988549947739]\n",
      "2200 steps | score: [0.10072442144155502]\n",
      "2300 steps | score: [0.07678329199552536]\n",
      "2400 steps | score: [0.1021517887711525]\n",
      "2500 steps | score: [0.11171398311853409]\n",
      "2600 steps | score: [0.07972394675016403]\n",
      "2700 steps | score: [0.08208972960710526]\n",
      "0 steps | score: [0.24868537485599518, -0.38322913646698]\n",
      "100 steps | score: [0.11956161260604858, -0.2531592845916748]\n",
      "200 steps | score: [-0.061740726232528687, 0.03571005165576935]\n",
      "300 steps | score: [-0.03486198931932449, -0.012396767735481262]\n",
      "400 steps | score: [-0.058883413672447205, -0.011077232658863068]\n",
      "500 steps | score: [-0.13376183807849884, 0.13441260159015656]\n",
      "600 steps | score: [0.018729373812675476, -0.1450261026620865]\n",
      "700 steps | score: [-0.04337752237915993, -0.032541029155254364]\n",
      "800 steps | score: [0.21953877806663513, -0.6028212308883667]\n",
      "900 steps | score: [-0.0580768957734108, -0.01773028075695038]\n",
      "1000 steps | score: [0.04902740567922592, -0.22104941308498383]\n",
      "1100 steps | score: [0.03926125913858414, -0.1980040967464447]\n",
      "1200 steps | score: [0.1156497672200203, -0.3874884247779846]\n",
      "1300 steps | score: [-0.01884474977850914, -0.093840092420578]\n",
      "1400 steps | score: [0.0020428579300642014, -0.12986579537391663]\n",
      "1500 steps | score: [0.1606949269771576, -0.4980939030647278]\n",
      "1600 steps | score: [-0.0155085613951087, -0.09905597567558289]\n",
      "1700 steps | score: [0.06567911803722382, -0.2669243812561035]\n",
      "1800 steps | score: [0.10699944198131561, -0.408947229385376]\n",
      "1900 steps | score: [-0.03176219016313553, -0.07963424921035767]\n",
      "2000 steps | score: [0.025853578001260757, -0.1580585241317749]\n",
      "2100 steps | score: [-0.008751198649406433, -0.08142142742872238]\n",
      "2200 steps | score: [0.07101649045944214, -0.28043246269226074]\n",
      "2300 steps | score: [0.09442339092493057, -0.33691689372062683]\n",
      "2400 steps | score: [0.09857335686683655, -0.3429783284664154]\n",
      "2500 steps | score: [0.11190283298492432, -0.36430823802948]\n",
      "2600 steps | score: [0.0515468493103981, -0.2729203999042511]\n",
      "2700 steps | score: [0.0007348665967583656, -0.14696714282035828]\n",
      "unknown params:  tensor([-0.4099, -0.4366, -0.3521,  0.5483, -0.1948, -0.2386])\n",
      "gt params:  tensor([-0.4361, -0.4021, -0.3606,  0.5637, -0.2013, -0.5171])\n",
      "ols params:  tensor([-0.1683, -0.1822, -0.1456,  0.2264, -0.0851,  2.9013])\n",
      "unknown mse:  tensor(0.0133)\n",
      "ols mse:  tensor(1.9965)\n",
      "gt params:  tensor([-0.4154, -0.3997, -0.3877,  0.5492, -0.2204, -0.4219])\n",
      "0 steps | score: [0.37349677085876465]\n",
      "100 steps | score: [0.05870930105447769]\n",
      "200 steps | score: [0.08652441948652267]\n",
      "300 steps | score: [0.061537228524684906]\n",
      "400 steps | score: [-0.003307383507490158]\n",
      "0 steps | score: [0.06866425275802612, 0.18174657225608826]\n",
      "100 steps | score: [-0.14896470308303833, 0.48372983932495117]\n",
      "200 steps | score: [0.8328685760498047, -2.206537961959839]\n",
      "300 steps | score: [-0.07391583174467087, 0.24202373623847961]\n",
      "400 steps | score: [0.029916388913989067, 0.010569136589765549]\n",
      "500 steps | score: [-0.06988465040922165, 0.19697678089141846]\n",
      "600 steps | score: [-0.03830229863524437, 0.17039552330970764]\n",
      "700 steps | score: [-0.05332886055111885, 0.21669110655784607]\n",
      "800 steps | score: [-0.11455346643924713, 0.30690398812294006]\n",
      "900 steps | score: [0.014258285984396935, 0.04519571363925934]\n",
      "1000 steps | score: [0.0729474350810051, -0.12264969944953918]\n",
      "1100 steps | score: [-0.1272391527891159, 0.32544687390327454]\n",
      "1200 steps | score: [-0.10926129668951035, 0.3118661344051361]\n",
      "1300 steps | score: [-0.19889843463897705, 0.47721633315086365]\n",
      "1400 steps | score: [-0.10315324366092682, 0.2880706787109375]\n",
      "1500 steps | score: [-0.15296396613121033, 0.38094115257263184]\n",
      "1600 steps | score: [0.03178532049059868, -0.0050405822694301605]\n",
      "1700 steps | score: [0.033315662294626236, -0.051102351397275925]\n",
      "1800 steps | score: [-0.187928706407547, 0.45197513699531555]\n",
      "1900 steps | score: [-0.11770179122686386, 0.3128855228424072]\n",
      "2000 steps | score: [-0.0670989379286766, 0.17304295301437378]\n",
      "2100 steps | score: [-0.08072168380022049, 0.21771995723247528]\n",
      "2200 steps | score: [-0.08524470031261444, 0.26495489478111267]\n",
      "2300 steps | score: [-0.052027493715286255, 0.16529594361782074]\n",
      "2400 steps | score: [-0.0056926473043859005, 0.04635694995522499]\n",
      "2500 steps | score: [-0.03477541357278824, 0.11058592796325684]\n",
      "2600 steps | score: [-0.11174459755420685, 0.30632284283638]\n",
      "2700 steps | score: [-0.1747427135705948, 0.4324430525302887]\n",
      "unknown params:  tensor([-0.4235, -0.3345, -0.3789,  0.5751, -0.2023, -0.2135])\n",
      "gt params:  tensor([-0.4154, -0.3997, -0.3877,  0.5492, -0.2204, -0.4219])\n",
      "ols params:  tensor([-0.1743, -0.1403, -0.1579,  0.2362, -0.0870,  3.1008])\n",
      "unknown mse:  tensor(0.0081)\n",
      "ols mse:  tensor(2.1173)\n",
      "gt params:  tensor([-0.4255, -0.4192, -0.3763,  0.5420, -0.1991, -0.5540])\n",
      "0 steps | score: [0.49852439761161804]\n",
      "100 steps | score: [0.18844985961914062]\n",
      "200 steps | score: [0.18286006152629852]\n",
      "300 steps | score: [0.19788306951522827]\n",
      "400 steps | score: [0.22765351831912994]\n",
      "500 steps | score: [0.19683101773262024]\n",
      "600 steps | score: [0.1693619191646576]\n",
      "700 steps | score: [0.19272716343402863]\n",
      "800 steps | score: [0.16383475065231323]\n",
      "900 steps | score: [0.17613980174064636]\n",
      "1000 steps | score: [0.17964071035385132]\n",
      "1100 steps | score: [0.18882641196250916]\n",
      "1200 steps | score: [0.19901736080646515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 steps | score: [0.20807616412639618]\n",
      "1400 steps | score: [0.16826362907886505]\n",
      "1500 steps | score: [0.18082495033740997]\n",
      "1600 steps | score: [0.2101314514875412]\n",
      "1700 steps | score: [0.21164463460445404]\n",
      "1800 steps | score: [0.1797138750553131]\n",
      "1900 steps | score: [0.19277724623680115]\n",
      "2000 steps | score: [0.18752487003803253]\n",
      "2100 steps | score: [0.17561283707618713]\n",
      "2200 steps | score: [0.18252241611480713]\n",
      "2300 steps | score: [0.16996055841445923]\n",
      "2400 steps | score: [0.18306392431259155]\n",
      "2500 steps | score: [0.19576728343963623]\n",
      "2600 steps | score: [0.16839005053043365]\n",
      "2700 steps | score: [0.2081090807914734]\n",
      "0 steps | score: [0.3874962031841278, -0.3784322738647461]\n",
      "100 steps | score: [0.13466031849384308, -0.005856722593307495]\n",
      "200 steps | score: [0.08940930664539337, 0.013095349073410034]\n",
      "300 steps | score: [0.18561774492263794, -0.20208768546581268]\n",
      "400 steps | score: [0.20000460743904114, -0.24021749198436737]\n",
      "500 steps | score: [0.3758070468902588, -0.6081118583679199]\n",
      "600 steps | score: [0.3569951057434082, -0.5713306069374084]\n",
      "700 steps | score: [0.06696061044931412, 0.05421985685825348]\n",
      "800 steps | score: [0.24091973900794983, -0.33768200874328613]\n",
      "900 steps | score: [0.2281114012002945, -0.2710433006286621]\n",
      "1000 steps | score: [0.2582589387893677, -0.36437755823135376]\n",
      "1100 steps | score: [0.20931187272071838, -0.27235230803489685]\n",
      "1200 steps | score: [0.24869360029697418, -0.35304129123687744]\n",
      "1300 steps | score: [0.18555805087089539, -0.20740757882595062]\n",
      "1400 steps | score: [0.21881258487701416, -0.2834464907646179]\n",
      "1500 steps | score: [0.13864389061927795, -0.11656275391578674]\n",
      "1600 steps | score: [0.2247631847858429, -0.28697270154953003]\n",
      "1700 steps | score: [0.20505866408348083, -0.2752414345741272]\n",
      "1800 steps | score: [0.1503932625055313, -0.14101703464984894]\n",
      "1900 steps | score: [0.2968089282512665, -0.46377888321876526]\n",
      "2000 steps | score: [0.33221301436424255, -0.5158763527870178]\n",
      "2100 steps | score: [0.2196243405342102, -0.30052798986434937]\n",
      "2200 steps | score: [0.23061013221740723, -0.30480968952178955]\n",
      "2300 steps | score: [0.13440737128257751, -0.11556720733642578]\n",
      "2400 steps | score: [0.10243479162454605, -0.06358574330806732]\n",
      "2500 steps | score: [0.24442094564437866, -0.3164428174495697]\n",
      "2600 steps | score: [0.19355612993240356, -0.20842421054840088]\n",
      "2700 steps | score: [0.14135517179965973, -0.13638773560523987]\n",
      "unknown params:  tensor([-0.3804, -0.3930, -0.3054,  0.4462, -0.2144, -0.0705])\n",
      "gt params:  tensor([-0.4255, -0.4192, -0.3763,  0.5420, -0.1991, -0.5540])\n",
      "ols params:  tensor([-0.1744, -0.1750, -0.1388,  0.2008, -0.1005,  3.1378])\n",
      "unknown mse:  tensor(0.0418)\n",
      "ols mse:  tensor(2.3224)\n",
      "gt params:  tensor([-0.4209, -0.3961, -0.3865,  0.5292, -0.2195, -0.5061])\n",
      "0 steps | score: [0.29948297142982483]\n",
      "100 steps | score: [-0.005233846604824066]\n",
      "0 steps | score: [0.2976841628551483, -0.4220696687698364]\n",
      "100 steps | score: [0.19528545439243317, -0.35474181175231934]\n",
      "200 steps | score: [-0.057945430278778076, 0.06684032082557678]\n",
      "300 steps | score: [0.0913516953587532, -0.22548630833625793]\n",
      "400 steps | score: [0.08172434568405151, -0.19003808498382568]\n",
      "500 steps | score: [0.15076564252376556, -0.3553919792175293]\n",
      "600 steps | score: [-0.05672541633248329, 0.01898869499564171]\n",
      "700 steps | score: [0.05510277301073074, -0.1849120408296585]\n",
      "800 steps | score: [0.030399512499570847, -0.12639956176280975]\n",
      "900 steps | score: [0.4369206428527832, -1.049032211303711]\n",
      "1000 steps | score: [0.05308016762137413, -0.1895158737897873]\n",
      "1100 steps | score: [0.1412353813648224, -0.3504340946674347]\n",
      "1200 steps | score: [0.19939126074314117, -0.4976522922515869]\n",
      "1300 steps | score: [0.08401591330766678, -0.23302441835403442]\n",
      "1400 steps | score: [0.014293774962425232, -0.0954275131225586]\n",
      "1500 steps | score: [0.07266991585493088, -0.2199474722146988]\n",
      "1600 steps | score: [0.05209199711680412, -0.19887343049049377]\n",
      "1700 steps | score: [0.12960097193717957, -0.314858615398407]\n",
      "1800 steps | score: [0.2544468343257904, -0.6197168231010437]\n",
      "1900 steps | score: [0.17959018051624298, -0.43396806716918945]\n",
      "2000 steps | score: [0.1753087043762207, -0.42635002732276917]\n",
      "2100 steps | score: [0.1446813941001892, -0.37613189220428467]\n",
      "2200 steps | score: [0.06303579360246658, -0.2117035686969757]\n",
      "2300 steps | score: [0.16223327815532684, -0.40903088450431824]\n",
      "2400 steps | score: [0.052452195435762405, -0.1741556078195572]\n",
      "2500 steps | score: [0.06253550946712494, -0.18882021307945251]\n",
      "2600 steps | score: [0.14080797135829926, -0.35931578278541565]\n",
      "2700 steps | score: [0.10286879539489746, -0.278721421957016]\n",
      "unknown params:  tensor([-0.4062, -0.3821, -0.4724,  0.5790, -0.2617, -0.2459])\n",
      "gt params:  tensor([-0.4209, -0.3961, -0.3865,  0.5292, -0.2195, -0.5061])\n",
      "ols params:  tensor([-0.1562, -0.1473, -0.1800,  0.2141, -0.0990,  3.2175])\n",
      "unknown mse:  tensor(0.0133)\n",
      "ols mse:  tensor(2.3589)\n",
      "gt params:  tensor([-0.4343, -0.4120, -0.3806,  0.5381, -0.2049, -0.5413])\n",
      "0 steps | score: [0.2425178587436676]\n",
      "100 steps | score: [-0.11153863370418549]\n",
      "200 steps | score: [-0.09971471130847931]\n",
      "300 steps | score: [-0.10627882182598114]\n",
      "400 steps | score: [-0.041318219155073166]\n",
      "500 steps | score: [-0.06572642922401428]\n",
      "600 steps | score: [-0.08917170763015747]\n",
      "700 steps | score: [-0.10150163620710373]\n",
      "800 steps | score: [-0.07777217030525208]\n",
      "900 steps | score: [-0.09643357992172241]\n",
      "1000 steps | score: [-0.09038028866052628]\n",
      "1100 steps | score: [-0.08421512693166733]\n",
      "1200 steps | score: [-0.11264176666736603]\n",
      "1300 steps | score: [-0.0654192864894867]\n",
      "1400 steps | score: [-0.06469833850860596]\n",
      "1500 steps | score: [-0.09340248256921768]\n",
      "1600 steps | score: [-0.09670205414295197]\n",
      "1700 steps | score: [-0.06826083362102509]\n",
      "1800 steps | score: [-0.09101702272891998]\n",
      "1900 steps | score: [-0.0538235679268837]\n",
      "2000 steps | score: [-0.08119460195302963]\n",
      "2100 steps | score: [-0.06199921667575836]\n",
      "2200 steps | score: [-0.08994399011135101]\n",
      "2300 steps | score: [-0.06279259920120239]\n",
      "2400 steps | score: [-0.05854407697916031]\n",
      "2500 steps | score: [-0.07466834783554077]\n",
      "2600 steps | score: [-0.05901658907532692]\n",
      "2700 steps | score: [-0.06422065943479538]\n",
      "0 steps | score: [0.46858420968055725, -0.5884314775466919]\n",
      "100 steps | score: [0.22060053050518036, -0.20319005846977234]\n",
      "200 steps | score: [0.3454136848449707, -0.4932774305343628]\n",
      "300 steps | score: [0.1909179836511612, -0.22096535563468933]\n",
      "400 steps | score: [0.4196058213710785, -0.7163175940513611]\n",
      "500 steps | score: [0.25961846113204956, -0.37705081701278687]\n",
      "600 steps | score: [0.33040595054626465, -0.5510120391845703]\n",
      "700 steps | score: [0.07097847759723663, -0.03169391304254532]\n",
      "800 steps | score: [0.420219749212265, -0.7932639122009277]\n",
      "900 steps | score: [0.15135632455348969, -0.14141511917114258]\n",
      "1000 steps | score: [0.14589007198810577, -0.16897021234035492]\n",
      "1100 steps | score: [0.2452620267868042, -0.3602483868598938]\n",
      "1200 steps | score: [0.27469897270202637, -0.44003280997276306]\n",
      "1300 steps | score: [0.26698029041290283, -0.4072093367576599]\n",
      "1400 steps | score: [0.2570313811302185, -0.37922853231430054]\n",
      "1500 steps | score: [0.2293456345796585, -0.31541264057159424]\n",
      "1600 steps | score: [0.14641498029232025, -0.16676057875156403]\n",
      "1700 steps | score: [0.35683703422546387, -0.6455788016319275]\n",
      "1800 steps | score: [0.17100003361701965, -0.20638447999954224]\n",
      "1900 steps | score: [0.2731797397136688, -0.4177452325820923]\n",
      "2000 steps | score: [0.1740730106830597, -0.22323505580425262]\n",
      "2100 steps | score: [0.22605372965335846, -0.3457928001880646]\n",
      "2200 steps | score: [0.2666701376438141, -0.4355037808418274]\n",
      "2300 steps | score: [0.2534162402153015, -0.39758050441741943]\n",
      "2400 steps | score: [0.21825169026851654, -0.3193751275539398]\n",
      "2500 steps | score: [0.21056705713272095, -0.29851850867271423]\n",
      "2600 steps | score: [0.2781931459903717, -0.4315841794013977]\n",
      "2700 steps | score: [0.25622203946113586, -0.39112138748168945]\n",
      "unknown params:  tensor([-0.3984, -0.3469, -0.3592,  0.5340, -0.2180,  0.0999])\n",
      "gt params:  tensor([-0.4343, -0.4120, -0.3806,  0.5381, -0.2049, -0.5413])\n",
      "ols params:  tensor([-0.1796, -0.1593, -0.1631,  0.2400, -0.1006,  3.3201])\n",
      "unknown mse:  tensor(0.0696)\n",
      "ols mse:  tensor(2.5310)\n",
      "gt params:  tensor([-0.4341, -0.4387, -0.3992,  0.5635, -0.2082, -0.5819])\n",
      "0 steps | score: [0.3512909412384033]\n",
      "100 steps | score: [0.05536605417728424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [0.056551847606897354]\n",
      "300 steps | score: [0.004182633012533188]\n",
      "0 steps | score: [0.2308328002691269, -0.06410883367061615]\n",
      "100 steps | score: [-0.014693059958517551, 0.27862709760665894]\n",
      "200 steps | score: [0.33192527294158936, -0.5088790655136108]\n",
      "300 steps | score: [0.026403991505503654, 0.11326882243156433]\n",
      "400 steps | score: [-0.0232479739934206, 0.2368796169757843]\n",
      "500 steps | score: [-0.16866962611675262, 0.49521124362945557]\n",
      "600 steps | score: [-0.0021374935749918222, 0.19292044639587402]\n",
      "700 steps | score: [-0.06649524718523026, 0.2975386083126068]\n",
      "800 steps | score: [0.1477716863155365, -0.1929864138364792]\n",
      "900 steps | score: [-0.015665657818317413, 0.19399920105934143]\n",
      "1000 steps | score: [0.03315833956003189, 0.07867500185966492]\n",
      "1100 steps | score: [-0.1065242663025856, 0.36979547142982483]\n",
      "1200 steps | score: [0.015634415671229362, 0.15126536786556244]\n",
      "1300 steps | score: [-0.00393214775249362, 0.1392551064491272]\n",
      "1400 steps | score: [0.0018235170282423496, 0.1580759584903717]\n",
      "1500 steps | score: [-0.03503672033548355, 0.24112920463085175]\n",
      "1600 steps | score: [0.08098109811544418, -0.019922852516174316]\n",
      "1700 steps | score: [0.018943646922707558, 0.09936316311359406]\n",
      "1800 steps | score: [0.05693279951810837, 0.03722630441188812]\n",
      "1900 steps | score: [0.08415025472640991, -0.014421440660953522]\n",
      "2000 steps | score: [0.006006861105561256, 0.1416778415441513]\n",
      "2100 steps | score: [-0.04604824259877205, 0.25910165905952454]\n",
      "2200 steps | score: [0.06556552648544312, 0.03307611495256424]\n",
      "2300 steps | score: [0.051910243928432465, 0.05819341540336609]\n",
      "2400 steps | score: [-0.06136196106672287, 0.27978646755218506]\n",
      "2500 steps | score: [-0.04911276325583458, 0.2501586079597473]\n",
      "2600 steps | score: [-0.012446139939129353, 0.18579789996147156]\n",
      "2700 steps | score: [-0.0013167831348255277, 0.1633928418159485]\n",
      "unknown params:  tensor([-0.3883, -0.4006, -0.4031,  0.5109, -0.1523, -0.0518])\n",
      "gt params:  tensor([-0.4341, -0.4387, -0.3992,  0.5635, -0.2082, -0.5819])\n",
      "ols params:  tensor([-0.1668, -0.1710, -0.1723,  0.2179, -0.0670,  3.4042])\n",
      "unknown mse:  tensor(0.0484)\n",
      "ols mse:  tensor(2.7039)\n",
      "gt params:  tensor([-0.3978, -0.4299, -0.4022,  0.5368, -0.2060, -0.4978])\n",
      "0 steps | score: [0.2844437062740326]\n",
      "100 steps | score: [-0.03782566636800766]\n",
      "200 steps | score: [-0.038586124777793884]\n",
      "300 steps | score: [-0.0386139452457428]\n",
      "400 steps | score: [-0.11765969544649124]\n",
      "500 steps | score: [-0.019657500088214874]\n",
      "600 steps | score: [-0.052822403609752655]\n",
      "700 steps | score: [0.019023872911930084]\n",
      "800 steps | score: [-0.04910479485988617]\n",
      "900 steps | score: [-0.0608336478471756]\n",
      "1000 steps | score: [-0.08791504800319672]\n",
      "1100 steps | score: [-0.04584234207868576]\n",
      "1200 steps | score: [-0.01792546734213829]\n",
      "1300 steps | score: [-0.05674832686781883]\n",
      "1400 steps | score: [-0.05732082948088646]\n",
      "1500 steps | score: [-0.06033133715391159]\n",
      "1600 steps | score: [-0.032960571348667145]\n",
      "1700 steps | score: [-0.039484407752752304]\n",
      "1800 steps | score: [-0.07618990540504456]\n",
      "1900 steps | score: [-0.057981736958026886]\n",
      "2000 steps | score: [-0.0568106472492218]\n",
      "2100 steps | score: [-0.04160766303539276]\n",
      "2200 steps | score: [-0.05285937711596489]\n",
      "2300 steps | score: [-0.05020643025636673]\n",
      "2400 steps | score: [-0.03238502889871597]\n",
      "2500 steps | score: [-0.07132206112146378]\n",
      "2600 steps | score: [-0.040740128606557846]\n",
      "2700 steps | score: [-0.04659570753574371]\n",
      "0 steps | score: [0.06740288436412811, 0.04812230169773102]\n",
      "100 steps | score: [-0.15730665624141693, 0.36428961157798767]\n",
      "200 steps | score: [-0.10946521162986755, 0.2286374866962433]\n",
      "300 steps | score: [-0.03764721378684044, 0.062084585428237915]\n",
      "400 steps | score: [-0.25154992938041687, 0.44346553087234497]\n",
      "500 steps | score: [-0.10670878738164902, 0.11530062556266785]\n",
      "600 steps | score: [-0.24045881628990173, 0.4005902409553528]\n",
      "700 steps | score: [-0.09292008727788925, 0.1409064084291458]\n",
      "800 steps | score: [-0.2512062191963196, 0.45598718523979187]\n",
      "900 steps | score: [-0.20691479742527008, 0.3474280834197998]\n",
      "1000 steps | score: [-0.12207776308059692, 0.21330073475837708]\n",
      "1100 steps | score: [-0.24361321330070496, 0.4226011633872986]\n",
      "1200 steps | score: [0.0436091274023056, -0.1967342495918274]\n",
      "1300 steps | score: [-0.2165241241455078, 0.3849696218967438]\n",
      "1400 steps | score: [-0.1494361311197281, 0.2561541795730591]\n",
      "1500 steps | score: [-0.14379437267780304, 0.24058696627616882]\n",
      "1600 steps | score: [-0.06304583698511124, 0.028795436024665833]\n",
      "1700 steps | score: [-0.1478731483221054, 0.23525771498680115]\n",
      "1800 steps | score: [-0.08622584491968155, 0.12085524201393127]\n",
      "1900 steps | score: [-0.22650665044784546, 0.3739718198776245]\n",
      "2000 steps | score: [-0.08686614036560059, 0.10843652486801147]\n",
      "2100 steps | score: [-0.11051558703184128, 0.16414880752563477]\n",
      "2200 steps | score: [-0.12582151591777802, 0.18108110129833221]\n",
      "2300 steps | score: [-0.19891874492168427, 0.3256206512451172]\n",
      "2400 steps | score: [-0.17256757616996765, 0.2848259508609772]\n",
      "2500 steps | score: [-0.17395636439323425, 0.2704986333847046]\n",
      "2600 steps | score: [-0.15793918073177338, 0.2405538260936737]\n",
      "2700 steps | score: [-0.21618755161762238, 0.34920820593833923]\n",
      "unknown params:  tensor([-0.4535, -0.4072, -0.4015,  0.4933, -0.1785, -0.2781])\n",
      "gt params:  tensor([-0.3978, -0.4299, -0.4022,  0.5368, -0.2060, -0.4978])\n",
      "ols params:  tensor([-0.1858, -0.1664, -0.1627,  0.1997, -0.0723,  3.5077])\n",
      "unknown mse:  tensor(0.0091)\n",
      "ols mse:  tensor(2.7245)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/04b556d1-228c-4ec2-b11a-7689d4011342\n",
      "gt params:  tensor([ 0.4775,  0.0079, -0.9618, -0.1515, -0.6860,  0.3251])\n",
      "0 steps | score: [0.29312145709991455]\n",
      "100 steps | score: [0.1767062097787857]\n",
      "200 steps | score: [0.23543177545070648]\n",
      "300 steps | score: [0.14459574222564697]\n",
      "400 steps | score: [0.12826822698116302]\n",
      "500 steps | score: [0.18802781403064728]\n",
      "600 steps | score: [0.18994054198265076]\n",
      "700 steps | score: [0.07587648928165436]\n",
      "800 steps | score: [0.14267654716968536]\n",
      "900 steps | score: [0.2413918823003769]\n",
      "1000 steps | score: [0.16118232905864716]\n",
      "1100 steps | score: [0.1482464224100113]\n",
      "1200 steps | score: [0.1643250584602356]\n",
      "1300 steps | score: [0.16947950422763824]\n",
      "1400 steps | score: [0.12633629143238068]\n",
      "1500 steps | score: [0.15694944560527802]\n",
      "1600 steps | score: [0.12381332367658615]\n",
      "1700 steps | score: [0.13363435864448547]\n",
      "1800 steps | score: [0.15669851005077362]\n",
      "1900 steps | score: [0.17814715206623077]\n",
      "2000 steps | score: [0.17365343868732452]\n",
      "2100 steps | score: [0.1411515474319458]\n",
      "2200 steps | score: [0.16075503826141357]\n",
      "2300 steps | score: [0.1524791419506073]\n",
      "2400 steps | score: [0.13245680928230286]\n",
      "2500 steps | score: [0.15669076144695282]\n",
      "2600 steps | score: [0.14971603453159332]\n",
      "0 steps | score: [0.20087207853794098, -0.5254958868026733]\n",
      "100 steps | score: [-0.14448444545269012, 0.7462723851203918]\n",
      "200 steps | score: [0.5275672078132629, -2.2924797534942627]\n",
      "300 steps | score: [0.2176443338394165, -0.8043869733810425]\n",
      "400 steps | score: [-0.385500967502594, 1.6411449909210205]\n",
      "500 steps | score: [-0.13230648636817932, 0.6765369176864624]\n",
      "600 steps | score: [0.06276927888393402, -0.2546929121017456]\n",
      "700 steps | score: [-0.014573059976100922, 0.08497995138168335]\n",
      "800 steps | score: [0.3455809950828552, -1.5794992446899414]\n",
      "900 steps | score: [0.08441176265478134, -0.361768901348114]\n",
      "1000 steps | score: [0.12875458598136902, -0.5149796605110168]\n",
      "1100 steps | score: [0.1504194438457489, -0.6552815437316895]\n",
      "1200 steps | score: [0.26828229427337646, -1.1607879400253296]\n",
      "1300 steps | score: [0.1902599036693573, -0.8507711887359619]\n",
      "1400 steps | score: [0.06905472278594971, -0.3463529944419861]\n",
      "1500 steps | score: [-0.1252444088459015, 0.49493512511253357]\n",
      "1600 steps | score: [-0.0958881825208664, 0.39909863471984863]\n",
      "1700 steps | score: [0.03033125028014183, -0.1154940128326416]\n",
      "1800 steps | score: [0.08334702998399734, -0.33556702733039856]\n",
      "1900 steps | score: [0.20018039643764496, -0.9152112603187561]\n",
      "2000 steps | score: [0.05888355150818825, -0.23996451497077942]\n",
      "2100 steps | score: [0.04569527506828308, -0.16777603328227997]\n",
      "2200 steps | score: [-0.04212493821978569, 0.16844400763511658]\n",
      "2300 steps | score: [0.21271193027496338, -0.9622572660446167]\n",
      "2400 steps | score: [0.012379751540720463, -0.06372804194688797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 steps | score: [-0.06709352135658264, 0.3081868588924408]\n",
      "2600 steps | score: [0.05707699432969093, -0.2942463159561157]\n",
      "unknown params:  tensor([ 0.4775,  0.0086, -0.9476, -0.1562, -0.6783,  0.3367])\n",
      "gt params:  tensor([ 0.4775,  0.0079, -0.9618, -0.1515, -0.6860,  0.3251])\n",
      "ols params:  tensor([ 0.4317,  0.0082, -0.8503, -0.1397, -0.6169,  0.8150])\n",
      "unknown mse:  tensor(6.9686e-05)\n",
      "ols mse:  tensor(0.0432)\n",
      "gt params:  tensor([ 0.4839,  0.0122, -0.9668, -0.1559, -0.6887,  0.3375])\n",
      "0 steps | score: [0.38252320885658264]\n",
      "100 steps | score: [0.26274898648262024]\n",
      "200 steps | score: [0.22107288241386414]\n",
      "300 steps | score: [0.3101373016834259]\n",
      "400 steps | score: [0.18261149525642395]\n",
      "500 steps | score: [0.26419252157211304]\n",
      "600 steps | score: [0.26140686869621277]\n",
      "700 steps | score: [0.2961060702800751]\n",
      "800 steps | score: [0.20869626104831696]\n",
      "900 steps | score: [0.16033616662025452]\n",
      "1000 steps | score: [0.26193374395370483]\n",
      "1100 steps | score: [0.2924302816390991]\n",
      "1200 steps | score: [0.2485719621181488]\n",
      "1300 steps | score: [0.2887425124645233]\n",
      "1400 steps | score: [0.2618061900138855]\n",
      "1500 steps | score: [0.2431352287530899]\n",
      "1600 steps | score: [0.28659772872924805]\n",
      "1700 steps | score: [0.3016663193702698]\n",
      "1800 steps | score: [0.3014891743659973]\n",
      "1900 steps | score: [0.298784077167511]\n",
      "2000 steps | score: [0.24262624979019165]\n",
      "2100 steps | score: [0.25670328736305237]\n",
      "2200 steps | score: [0.2893792986869812]\n",
      "2300 steps | score: [0.28559577465057373]\n",
      "2400 steps | score: [0.2784349322319031]\n",
      "2500 steps | score: [0.2235240936279297]\n",
      "2600 steps | score: [0.26390671730041504]\n",
      "0 steps | score: [0.19260439276695251, -0.34999018907546997]\n",
      "100 steps | score: [0.171346977353096, -0.5606389045715332]\n",
      "200 steps | score: [-0.3114824891090393, 1.1973947286605835]\n",
      "300 steps | score: [0.3457673192024231, -1.245242714881897]\n",
      "400 steps | score: [-0.10032306611537933, 0.3231181204319]\n",
      "500 steps | score: [0.25201329588890076, -1.0346534252166748]\n",
      "600 steps | score: [-0.367635577917099, 1.1945068836212158]\n",
      "700 steps | score: [1.1357256174087524, -5.256011486053467]\n",
      "800 steps | score: [-0.13051164150238037, 0.42908933758735657]\n",
      "900 steps | score: [-0.15494801104068756, 0.47772514820098877]\n",
      "1000 steps | score: [0.22984124720096588, -0.9470818042755127]\n",
      "1100 steps | score: [-0.012327677570283413, 0.020473934710025787]\n",
      "1200 steps | score: [-0.03788966313004494, 0.0639743059873581]\n",
      "1300 steps | score: [-0.07748807966709137, 0.19257313013076782]\n",
      "1400 steps | score: [0.09555050730705261, -0.444747656583786]\n",
      "1500 steps | score: [0.028625210747122765, -0.14253979921340942]\n",
      "1600 steps | score: [0.18184292316436768, -0.7270350456237793]\n",
      "1700 steps | score: [0.0056570242159068584, -0.05741892009973526]\n",
      "1800 steps | score: [0.03961945325136185, -0.23215776681900024]\n",
      "1900 steps | score: [-0.05101662501692772, 0.13290049135684967]\n",
      "2000 steps | score: [0.06956859678030014, -0.27525976300239563]\n",
      "2100 steps | score: [0.021847473457455635, -0.19850364327430725]\n",
      "2200 steps | score: [0.1307348608970642, -0.526271641254425]\n",
      "2300 steps | score: [0.07609310746192932, -0.3855873942375183]\n",
      "2400 steps | score: [0.10307260602712631, -0.4551510810852051]\n",
      "2500 steps | score: [-0.05971050262451172, 0.15384072065353394]\n",
      "2600 steps | score: [0.01486237347126007, -0.11662520468235016]\n",
      "unknown params:  tensor([ 0.5042,  0.0134, -0.9857, -0.1543, -0.6953,  0.3128])\n",
      "gt params:  tensor([ 0.4839,  0.0122, -0.9668, -0.1559, -0.6887,  0.3375])\n",
      "ols params:  tensor([ 0.4056,  0.0093, -0.7724, -0.1212, -0.5569,  1.2252])\n",
      "unknown mse:  tensor(0.0002)\n",
      "ols mse:  tensor(0.1417)\n",
      "gt params:  tensor([ 0.4788,  0.0059, -0.9719, -0.1585, -0.6856,  0.3147])\n",
      "0 steps | score: [0.40453284978866577]\n",
      "100 steps | score: [0.185921773314476]\n",
      "200 steps | score: [0.30771708488464355]\n",
      "300 steps | score: [0.1808318942785263]\n",
      "400 steps | score: [0.2378973662853241]\n",
      "500 steps | score: [0.23467376828193665]\n",
      "600 steps | score: [0.20019450783729553]\n",
      "700 steps | score: [0.19436053931713104]\n",
      "800 steps | score: [0.24069254100322723]\n",
      "900 steps | score: [0.255504846572876]\n",
      "1000 steps | score: [0.18558531999588013]\n",
      "1100 steps | score: [0.2003197968006134]\n",
      "1200 steps | score: [0.20572873950004578]\n",
      "1300 steps | score: [0.2592049837112427]\n",
      "1400 steps | score: [0.25244536995887756]\n",
      "1500 steps | score: [0.20712921023368835]\n",
      "1600 steps | score: [0.2222650945186615]\n",
      "1700 steps | score: [0.19422703981399536]\n",
      "1800 steps | score: [0.2195284068584442]\n",
      "1900 steps | score: [0.23343992233276367]\n",
      "2000 steps | score: [0.2166009247303009]\n",
      "2100 steps | score: [0.22346781194210052]\n",
      "2200 steps | score: [0.20154526829719543]\n",
      "2300 steps | score: [0.21181592345237732]\n",
      "2400 steps | score: [0.245487242937088]\n",
      "2500 steps | score: [0.2278788685798645]\n",
      "2600 steps | score: [0.24168957769870758]\n",
      "0 steps | score: [0.19392617046833038, -0.34474116563796997]\n",
      "100 steps | score: [-0.04440394788980484, 0.1984245628118515]\n",
      "200 steps | score: [0.31502971053123474, -1.1099534034729004]\n",
      "300 steps | score: [0.07445140928030014, -0.27674365043640137]\n",
      "400 steps | score: [-0.030947929248213768, 0.10177041590213776]\n",
      "500 steps | score: [-0.14844295382499695, 0.4607599079608917]\n",
      "600 steps | score: [-0.08872412890195847, 0.247914120554924]\n",
      "700 steps | score: [-0.2253384292125702, 0.6599015593528748]\n",
      "800 steps | score: [0.0003685475967358798, 0.03912875056266785]\n",
      "900 steps | score: [0.05851230025291443, -0.22254058718681335]\n",
      "1000 steps | score: [0.008224226534366608, -0.052909448742866516]\n",
      "1100 steps | score: [0.1463993638753891, -0.4875446557998657]\n",
      "1200 steps | score: [-0.007387918420135975, -0.05216661095619202]\n",
      "1300 steps | score: [0.0888887420296669, -0.31254392862319946]\n",
      "1400 steps | score: [0.286377876996994, -1.0600860118865967]\n",
      "1500 steps | score: [0.06106293573975563, -0.22042438387870789]\n",
      "1600 steps | score: [0.08996009826660156, -0.3213317394256592]\n",
      "1700 steps | score: [0.09109052270650864, -0.3100888729095459]\n",
      "1800 steps | score: [0.12045896053314209, -0.41512390971183777]\n",
      "1900 steps | score: [0.05442025139927864, -0.23610670864582062]\n",
      "2000 steps | score: [-0.10116761922836304, 0.3179478645324707]\n",
      "2100 steps | score: [0.08372163772583008, -0.28504350781440735]\n",
      "2200 steps | score: [-0.030090827494859695, 0.0641356110572815]\n",
      "2300 steps | score: [0.15763182938098907, -0.6241436004638672]\n",
      "2400 steps | score: [0.14463384449481964, -0.5538690090179443]\n",
      "2500 steps | score: [0.044823888689279556, -0.15637806057929993]\n",
      "2600 steps | score: [0.09723269939422607, -0.3439174294471741]\n",
      "unknown params:  tensor([ 0.4651,  0.0066, -0.9331, -0.1492, -0.6586,  0.3839])\n",
      "gt params:  tensor([ 0.4788,  0.0059, -0.9719, -0.1585, -0.6856,  0.3147])\n",
      "ols params:  tensor([ 0.3686,  0.0069, -0.7198, -0.1169, -0.5222,  1.5045])\n",
      "unknown mse:  tensor(0.0012)\n",
      "ols mse:  tensor(0.2533)\n",
      "gt params:  tensor([ 0.4871,  0.0157, -0.9565, -0.1476, -0.6916,  0.3205])\n",
      "0 steps | score: [0.2911849617958069]\n",
      "100 steps | score: [0.13277439773082733]\n",
      "200 steps | score: [0.14633598923683167]\n",
      "300 steps | score: [0.04624921455979347]\n",
      "400 steps | score: [0.11697547882795334]\n",
      "500 steps | score: [0.04005297273397446]\n",
      "600 steps | score: [0.059031762182712555]\n",
      "700 steps | score: [0.030561499297618866]\n",
      "800 steps | score: [0.002054281532764435]\n",
      "0 steps | score: [0.20883458852767944, -0.11841801553964615]\n",
      "100 steps | score: [-0.10815271735191345, 0.5729965567588806]\n",
      "200 steps | score: [0.006684946361929178, 0.10279953479766846]\n",
      "300 steps | score: [-0.19476699829101562, 0.6144527196884155]\n",
      "400 steps | score: [-0.08517597615718842, 0.38099753856658936]\n",
      "500 steps | score: [0.02356734871864319, 0.154196098446846]\n",
      "600 steps | score: [0.22608034312725067, -0.5111794471740723]\n",
      "700 steps | score: [0.2113504558801651, -0.45189204812049866]\n",
      "800 steps | score: [-0.21767418086528778, 0.6617631316184998]\n",
      "900 steps | score: [-0.06820850074291229, 0.3601984679698944]\n",
      "1000 steps | score: [0.09893544018268585, -0.10935468226671219]\n",
      "1100 steps | score: [-0.009056606329977512, 0.19080355763435364]\n",
      "1200 steps | score: [0.07387805730104446, -0.054563116282224655]\n",
      "1300 steps | score: [0.24371318519115448, -0.6618327498435974]\n",
      "1400 steps | score: [-0.04878133162856102, 0.254242479801178]\n",
      "1500 steps | score: [0.08108245581388474, -0.1475275754928589]\n",
      "1600 steps | score: [0.18021412193775177, -0.40106144547462463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 steps | score: [0.11365809291601181, -0.18056878447532654]\n",
      "1800 steps | score: [0.1074293702840805, -0.13724616169929504]\n",
      "1900 steps | score: [0.03018052875995636, -0.013867069035768509]\n",
      "2000 steps | score: [0.14898066222667694, -0.3467543423175812]\n",
      "2100 steps | score: [0.12012644112110138, -0.16285769641399384]\n",
      "2200 steps | score: [0.01665182039141655, 0.1163596659898758]\n",
      "2300 steps | score: [0.14844030141830444, -0.3141838312149048]\n",
      "2400 steps | score: [0.06986363232135773, -0.0709730014204979]\n",
      "2500 steps | score: [0.10073087364435196, -0.20082062482833862]\n",
      "2600 steps | score: [0.10543616861104965, -0.17735160887241364]\n",
      "unknown params:  tensor([ 0.4780,  0.0133, -0.9298, -0.1472, -0.6832,  0.3362])\n",
      "gt params:  tensor([ 0.4871,  0.0157, -0.9565, -0.1476, -0.6916,  0.3205])\n",
      "ols params:  tensor([ 0.3518,  0.0113, -0.6645, -0.1083, -0.5022,  1.7516])\n",
      "unknown mse:  tensor(0.0002)\n",
      "ols mse:  tensor(0.3648)\n",
      "gt params:  tensor([ 0.4827,  0.0247, -0.9719, -0.1677, -0.6812,  0.3560])\n",
      "0 steps | score: [0.19922605156898499]\n",
      "100 steps | score: [-0.01867227628827095]\n",
      "200 steps | score: [0.1230531707406044]\n",
      "300 steps | score: [-0.07303919643163681]\n",
      "400 steps | score: [0.06652548164129257]\n",
      "500 steps | score: [-0.021090824156999588]\n",
      "600 steps | score: [-0.013236695900559425]\n",
      "700 steps | score: [-0.037746913731098175]\n",
      "800 steps | score: [-0.017511041834950447]\n",
      "900 steps | score: [0.025843527168035507]\n",
      "1000 steps | score: [-0.009849628433585167]\n",
      "0 steps | score: [0.07235346734523773, 0.30277740955352783]\n",
      "100 steps | score: [-0.361115962266922, 1.252973198890686]\n",
      "200 steps | score: [-1.1576406955718994, 2.8904809951782227]\n",
      "300 steps | score: [-0.05768440291285515, 0.27103182673454285]\n",
      "400 steps | score: [-0.16895103454589844, 0.6733513474464417]\n",
      "500 steps | score: [-0.23424167931079865, 0.8439080715179443]\n",
      "600 steps | score: [-0.04256756976246834, 0.275647908449173]\n",
      "700 steps | score: [-0.19532442092895508, 0.7329833507537842]\n",
      "800 steps | score: [0.06678933650255203, -0.12634029984474182]\n",
      "900 steps | score: [0.09986095875501633, -0.2286813110113144]\n",
      "1000 steps | score: [-0.09611768275499344, 0.38980865478515625]\n",
      "1100 steps | score: [-0.12430012226104736, 0.5313818454742432]\n",
      "1200 steps | score: [-0.022370385006070137, 0.15621989965438843]\n",
      "1300 steps | score: [-0.12193446606397629, 0.4653583765029907]\n",
      "1400 steps | score: [0.02400723472237587, -0.0011358410120010376]\n",
      "1500 steps | score: [-0.03386681154370308, 0.19301164150238037]\n",
      "1600 steps | score: [-0.058267854154109955, 0.2888564169406891]\n",
      "1700 steps | score: [-0.1113278716802597, 0.45611658692359924]\n",
      "1800 steps | score: [-0.08584476262331009, 0.375083863735199]\n",
      "1900 steps | score: [-0.17469336092472076, 0.5556513667106628]\n",
      "2000 steps | score: [-0.11787344515323639, 0.4442340135574341]\n",
      "2100 steps | score: [-0.09106044471263885, 0.3257433772087097]\n",
      "2200 steps | score: [-0.04318778216838837, 0.2264106720685959]\n",
      "2300 steps | score: [-0.04308108985424042, 0.20898446440696716]\n",
      "2400 steps | score: [0.05609726160764694, -0.09891243278980255]\n",
      "2500 steps | score: [-0.09986548870801926, 0.40318548679351807]\n",
      "2600 steps | score: [-0.08485317975282669, 0.35031113028526306]\n",
      "unknown params:  tensor([ 0.4787,  0.0195, -0.9631, -0.1611, -0.6821,  0.1569])\n",
      "gt params:  tensor([ 0.4827,  0.0247, -0.9719, -0.1677, -0.6812,  0.3560])\n",
      "ols params:  tensor([ 0.3441,  0.0146, -0.6615, -0.1119, -0.4853,  1.9472])\n",
      "unknown mse:  tensor(0.0066)\n",
      "ols mse:  tensor(0.4482)\n",
      "gt params:  tensor([ 0.4703,  0.0061, -0.9582, -0.1509, -0.6795,  0.3361])\n",
      "0 steps | score: [0.2141881138086319]\n",
      "100 steps | score: [0.0073979198932647705]\n",
      "0 steps | score: [0.18154504895210266, 0.10924430191516876]\n",
      "100 steps | score: [0.3756495714187622, -0.7351455092430115]\n",
      "200 steps | score: [0.1999935507774353, -0.3045099377632141]\n",
      "300 steps | score: [-0.17900069057941437, 0.7665151953697205]\n",
      "400 steps | score: [0.4000139832496643, -0.8834271430969238]\n",
      "500 steps | score: [-0.08223168551921844, 0.45688462257385254]\n",
      "600 steps | score: [0.5085727572441101, -1.2001779079437256]\n",
      "700 steps | score: [0.15966199338436127, -0.2570508122444153]\n",
      "800 steps | score: [0.09551279246807098, -0.014401301741600037]\n",
      "900 steps | score: [-0.13874344527721405, 0.5904717445373535]\n",
      "1000 steps | score: [0.06589524447917938, 0.09369415044784546]\n",
      "1100 steps | score: [0.2533320188522339, -0.5214934945106506]\n",
      "1200 steps | score: [0.09911574423313141, -0.03831351548433304]\n",
      "1300 steps | score: [0.0309520922601223, 0.158229798078537]\n",
      "1400 steps | score: [-0.09964729100465775, 0.49997463822364807]\n",
      "1500 steps | score: [-0.08777694404125214, 0.47501176595687866]\n",
      "1600 steps | score: [0.1997552216053009, -0.27260085940361023]\n",
      "1700 steps | score: [0.0382176972925663, 0.16022203862667084]\n",
      "1800 steps | score: [0.0891771912574768, -0.013642698526382446]\n",
      "1900 steps | score: [-0.07392620295286179, 0.45850831270217896]\n",
      "2000 steps | score: [-0.019808389246463776, 0.33961209654808044]\n",
      "2100 steps | score: [0.06903758645057678, 0.042401865124702454]\n",
      "2200 steps | score: [0.15861256420612335, -0.2012614607810974]\n",
      "2300 steps | score: [0.06731541454792023, 0.04344065487384796]\n",
      "2400 steps | score: [0.0720272958278656, 0.08785182237625122]\n",
      "2500 steps | score: [0.0378144271671772, 0.1849387139081955]\n",
      "2600 steps | score: [0.04492541775107384, 0.13752256333827972]\n",
      "unknown params:  tensor([ 0.4855,  0.0152, -0.9483, -0.1607, -0.6536,  0.3009])\n",
      "gt params:  tensor([ 0.4703,  0.0061, -0.9582, -0.1509, -0.6795,  0.3361])\n",
      "ols params:  tensor([ 0.3185,  0.0127, -0.5937, -0.1072, -0.4270,  2.2151])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(0.6254)\n",
      "gt params:  tensor([ 0.4724,  0.0075, -0.9746, -0.1466, -0.6822,  0.3737])\n",
      "0 steps | score: [0.19455678761005402]\n",
      "100 steps | score: [0.014970418065786362]\n",
      "200 steps | score: [-0.025337625294923782]\n",
      "300 steps | score: [-0.04078996554017067]\n",
      "400 steps | score: [0.05458664521574974]\n",
      "500 steps | score: [0.020854301750659943]\n",
      "600 steps | score: [-0.05244738981127739]\n",
      "700 steps | score: [-0.0839703306555748]\n",
      "800 steps | score: [-0.021108845248818398]\n",
      "900 steps | score: [-0.022319160401821136]\n",
      "1000 steps | score: [-0.014613009989261627]\n",
      "1100 steps | score: [-0.027367616072297096]\n",
      "1200 steps | score: [-0.033645596355199814]\n",
      "1300 steps | score: [-0.06277092546224594]\n",
      "1400 steps | score: [-0.06059134379029274]\n",
      "1500 steps | score: [-0.02694198489189148]\n",
      "1600 steps | score: [-0.02292006090283394]\n",
      "1700 steps | score: [-0.05436769872903824]\n",
      "1800 steps | score: [-0.06846009939908981]\n",
      "1900 steps | score: [-0.0708877220749855]\n",
      "2000 steps | score: [-0.02997591346502304]\n",
      "2100 steps | score: [-0.0165223628282547]\n",
      "2200 steps | score: [-0.05939657986164093]\n",
      "2300 steps | score: [-0.05390453338623047]\n",
      "2400 steps | score: [-0.053843073546886444]\n",
      "2500 steps | score: [-0.0041242484003305435]\n",
      "0 steps | score: [0.14182555675506592, -0.22772714495658875]\n",
      "100 steps | score: [0.44084227085113525, -1.2613528966903687]\n",
      "200 steps | score: [-0.16950398683547974, 0.35937607288360596]\n",
      "300 steps | score: [-0.14658409357070923, 0.24000035226345062]\n",
      "400 steps | score: [-0.007847248576581478, -0.1419784277677536]\n",
      "500 steps | score: [0.49093911051750183, -1.6994670629501343]\n",
      "600 steps | score: [-0.1883925050497055, 0.30287572741508484]\n",
      "700 steps | score: [-0.15852628648281097, 0.2745676040649414]\n",
      "800 steps | score: [0.08211784064769745, -0.3822374939918518]\n",
      "900 steps | score: [-0.1134800985455513, 0.15695834159851074]\n",
      "1000 steps | score: [0.1316060721874237, -0.6231195330619812]\n",
      "1100 steps | score: [0.23664724826812744, -0.8546833395957947]\n",
      "1200 steps | score: [0.05717327445745468, -0.3242587745189667]\n",
      "1300 steps | score: [0.10623615235090256, -0.5221809148788452]\n",
      "1400 steps | score: [-0.051837194710969925, -0.03866199776530266]\n",
      "1500 steps | score: [0.07863658666610718, -0.42529574036598206]\n",
      "1600 steps | score: [0.036549996584653854, -0.2913667559623718]\n",
      "1700 steps | score: [-0.06875354051589966, 0.04183962196111679]\n",
      "1800 steps | score: [-0.08213240653276443, 0.06842399388551712]\n",
      "1900 steps | score: [-0.10895852744579315, 0.08461899310350418]\n",
      "2000 steps | score: [0.06726966053247452, -0.3701292872428894]\n",
      "2100 steps | score: [0.12480056285858154, -0.5250537395477295]\n",
      "2200 steps | score: [-0.059805963188409805, -0.002135287970304489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300 steps | score: [0.024187790229916573, -0.21120640635490417]\n",
      "2400 steps | score: [-0.029731472954154015, -0.1061798706650734]\n",
      "2500 steps | score: [0.07457984983921051, -0.36290207505226135]\n",
      "2600 steps | score: [-0.04289455711841583, -0.06037788838148117]\n",
      "unknown params:  tensor([ 0.4583, -0.0018, -0.9011, -0.1524, -0.6535,  0.5683])\n",
      "gt params:  tensor([ 0.4724,  0.0075, -0.9746, -0.1466, -0.6822,  0.3737])\n",
      "ols params:  tensor([ 0.3099,  0.0033, -0.5837, -0.0991, -0.4403,  2.4051])\n",
      "unknown mse:  tensor(0.0074)\n",
      "ols mse:  tensor(0.7278)\n",
      "gt params:  tensor([ 0.4754,  0.0091, -0.9735, -0.1582, -0.6793,  0.3327])\n",
      "0 steps | score: [0.32795727252960205]\n",
      "100 steps | score: [0.1406320482492447]\n",
      "200 steps | score: [0.07848361879587173]\n",
      "300 steps | score: [0.13627386093139648]\n",
      "400 steps | score: [0.11763940751552582]\n",
      "500 steps | score: [0.1027340218424797]\n",
      "600 steps | score: [0.1388288140296936]\n",
      "700 steps | score: [0.11266424506902695]\n",
      "800 steps | score: [0.12363967299461365]\n",
      "900 steps | score: [0.10511146485805511]\n",
      "1000 steps | score: [0.09612017124891281]\n",
      "1100 steps | score: [0.11745212972164154]\n",
      "1200 steps | score: [0.13882432878017426]\n",
      "1300 steps | score: [0.08582103997468948]\n",
      "1400 steps | score: [0.12550826370716095]\n",
      "1500 steps | score: [0.11703483760356903]\n",
      "1600 steps | score: [0.1039896309375763]\n",
      "1700 steps | score: [0.11645946651697159]\n",
      "1800 steps | score: [0.11996490508317947]\n",
      "1900 steps | score: [0.12043755501508713]\n",
      "2000 steps | score: [0.11994427442550659]\n",
      "2100 steps | score: [0.10915325582027435]\n",
      "2200 steps | score: [0.08797074109315872]\n",
      "2300 steps | score: [0.10802161693572998]\n",
      "2400 steps | score: [0.11608002334833145]\n",
      "2500 steps | score: [0.09931744635105133]\n",
      "2600 steps | score: [0.1061568558216095]\n",
      "0 steps | score: [0.08076364547014236, -0.04043571650981903]\n",
      "100 steps | score: [-0.07269665598869324, 0.1414603292942047]\n",
      "200 steps | score: [-0.11330701410770416, 0.19887509942054749]\n",
      "300 steps | score: [-0.10263358801603317, 0.1729968637228012]\n",
      "400 steps | score: [-0.20397712290287018, 0.39010322093963623]\n",
      "500 steps | score: [-0.17948134243488312, 0.29883891344070435]\n",
      "600 steps | score: [0.036246128380298615, -0.24106749892234802]\n",
      "700 steps | score: [0.05185557156801224, -0.26295632123947144]\n",
      "800 steps | score: [-0.15426947176456451, 0.25181692838668823]\n",
      "900 steps | score: [-0.11975841969251633, 0.18656447529792786]\n",
      "1000 steps | score: [-0.21447895467281342, 0.4150438904762268]\n",
      "1100 steps | score: [-0.006561393849551678, -0.14156705141067505]\n",
      "1200 steps | score: [0.09317729622125626, -0.4420192837715149]\n",
      "1300 steps | score: [-0.0020644080359488726, -0.15388137102127075]\n",
      "1400 steps | score: [0.005669024772942066, -0.12031765282154083]\n",
      "1500 steps | score: [-0.2222788780927658, 0.42242419719696045]\n",
      "1600 steps | score: [-0.15778803825378418, 0.23201265931129456]\n",
      "1700 steps | score: [-0.20368346571922302, 0.39266008138656616]\n",
      "1800 steps | score: [-0.06338047236204147, 0.011946290731430054]\n",
      "1900 steps | score: [-0.03109816275537014, -0.06243874132633209]\n",
      "2000 steps | score: [0.08197617530822754, -0.3786465525627136]\n",
      "2100 steps | score: [-0.1306094527244568, 0.22540372610092163]\n",
      "2200 steps | score: [-0.08897866308689117, 0.07719366252422333]\n",
      "2300 steps | score: [-0.11860419064760208, 0.12003667652606964]\n",
      "2400 steps | score: [-0.027743736281991005, -0.06501859426498413]\n",
      "2500 steps | score: [-0.14720816910266876, 0.20208384096622467]\n",
      "2600 steps | score: [-0.05697861313819885, -0.02258068323135376]\n",
      "unknown params:  tensor([ 0.4937, -0.0187, -0.9813, -0.1788, -0.7049,  0.1873])\n",
      "gt params:  tensor([ 0.4754,  0.0091, -0.9735, -0.1582, -0.6793,  0.3327])\n",
      "ols params:  tensor([ 0.3039, -0.0057, -0.5769, -0.1042, -0.4289,  2.4806])\n",
      "unknown mse:  tensor(0.0039)\n",
      "ols mse:  tensor(0.8110)\n",
      "gt params:  tensor([ 0.4963,  0.0070, -0.9512, -0.1523, -0.6771,  0.3141])\n",
      "0 steps | score: [0.4155937433242798]\n",
      "100 steps | score: [0.18203043937683105]\n",
      "200 steps | score: [0.27605634927749634]\n",
      "300 steps | score: [0.1192505732178688]\n",
      "400 steps | score: [0.2126782238483429]\n",
      "500 steps | score: [0.20207339525222778]\n",
      "600 steps | score: [0.22950530052185059]\n",
      "700 steps | score: [0.18821653723716736]\n",
      "800 steps | score: [0.16221588850021362]\n",
      "900 steps | score: [0.18827775120735168]\n",
      "1000 steps | score: [0.22595150768756866]\n",
      "1100 steps | score: [0.19562773406505585]\n",
      "1200 steps | score: [0.17232432961463928]\n",
      "1300 steps | score: [0.1951676905155182]\n",
      "1400 steps | score: [0.1595853865146637]\n",
      "1500 steps | score: [0.21132370829582214]\n",
      "1600 steps | score: [0.2001684606075287]\n",
      "1700 steps | score: [0.19674736261367798]\n",
      "1800 steps | score: [0.20956754684448242]\n",
      "1900 steps | score: [0.1787939965724945]\n",
      "2000 steps | score: [0.22477532923221588]\n",
      "2100 steps | score: [0.2072763442993164]\n",
      "2200 steps | score: [0.19155281782150269]\n",
      "2300 steps | score: [0.17763559520244598]\n",
      "2400 steps | score: [0.1730271875858307]\n",
      "2500 steps | score: [0.18490716814994812]\n",
      "2600 steps | score: [0.20747798681259155]\n",
      "0 steps | score: [0.09529892355203629, 0.09603212773799896]\n",
      "100 steps | score: [-0.19779548048973083, 0.6282406449317932]\n",
      "200 steps | score: [-0.044662293046712875, 0.2051801234483719]\n",
      "300 steps | score: [-0.13518834114074707, 0.4217899441719055]\n",
      "400 steps | score: [0.13053560256958008, -0.34773609042167664]\n",
      "500 steps | score: [-0.12552088499069214, 0.3166413903236389]\n",
      "600 steps | score: [0.16149938106536865, -0.4219537675380707]\n",
      "700 steps | score: [-0.01745842769742012, 0.08328854292631149]\n",
      "800 steps | score: [-0.05559737607836723, 0.1833803355693817]\n",
      "900 steps | score: [-0.09170176088809967, 0.233971506357193]\n",
      "1000 steps | score: [-0.012262416072189808, 0.03899914398789406]\n",
      "1100 steps | score: [-0.13833272457122803, 0.36936503648757935]\n",
      "1200 steps | score: [0.014828205108642578, -0.013742394745349884]\n",
      "1300 steps | score: [-0.04059354588389397, 0.16564321517944336]\n",
      "1400 steps | score: [-0.04798286035656929, 0.12835654616355896]\n",
      "1500 steps | score: [-0.058895621448755264, 0.12840376794338226]\n",
      "1600 steps | score: [-0.004177210386842489, -0.017722483724355698]\n",
      "1700 steps | score: [-0.11013390123844147, 0.29443129897117615]\n",
      "1800 steps | score: [-0.053924560546875, 0.15629559755325317]\n",
      "1900 steps | score: [-0.025154544040560722, 0.08467670530080795]\n",
      "2000 steps | score: [-0.006527552846819162, 0.0323990061879158]\n",
      "2100 steps | score: [-0.12279902398586273, 0.32069826126098633]\n",
      "2200 steps | score: [-0.08357599377632141, 0.2252151370048523]\n",
      "2300 steps | score: [-0.08604420721530914, 0.24487191438674927]\n",
      "2400 steps | score: [-0.05991814285516739, 0.18869930505752563]\n",
      "2500 steps | score: [-0.06476172804832458, 0.20660406351089478]\n",
      "2600 steps | score: [-0.06376203149557114, 0.1709446907043457]\n",
      "unknown params:  tensor([ 0.5344,  0.0062, -1.0051, -0.1577, -0.6914,  0.1410])\n",
      "gt params:  tensor([ 0.4963,  0.0070, -0.9512, -0.1523, -0.6771,  0.3141])\n",
      "ols params:  tensor([ 0.3071,  0.0053, -0.5508, -0.0875, -0.3981,  2.6283])\n",
      "unknown mse:  tensor(0.0058)\n",
      "ols mse:  tensor(0.9389)\n",
      "gt params:  tensor([ 0.4828,  0.0052, -0.9636, -0.1415, -0.6953,  0.3257])\n",
      "0 steps | score: [0.12579743564128876]\n",
      "100 steps | score: [-0.09976938366889954]\n",
      "200 steps | score: [-0.05696680396795273]\n",
      "300 steps | score: [-0.08013620972633362]\n",
      "400 steps | score: [-0.0889652669429779]\n",
      "500 steps | score: [-0.10852967202663422]\n",
      "600 steps | score: [-0.13129480183124542]\n",
      "700 steps | score: [-0.09967637062072754]\n",
      "800 steps | score: [-0.13358423113822937]\n",
      "900 steps | score: [-0.1433454006910324]\n",
      "1000 steps | score: [-0.13675786554813385]\n",
      "1100 steps | score: [-0.13138067722320557]\n",
      "1200 steps | score: [-0.1451108604669571]\n",
      "1300 steps | score: [-0.15425997972488403]\n",
      "1400 steps | score: [-0.09772147238254547]\n",
      "1500 steps | score: [-0.11052404344081879]\n",
      "1600 steps | score: [-0.13225679099559784]\n",
      "1700 steps | score: [-0.11689192056655884]\n",
      "1800 steps | score: [-0.11044257879257202]\n",
      "1900 steps | score: [-0.08873167634010315]\n",
      "2000 steps | score: [-0.07873713970184326]\n",
      "2100 steps | score: [-0.11045071482658386]\n",
      "2200 steps | score: [-0.13178253173828125]\n",
      "2300 steps | score: [-0.10546667873859406]\n",
      "2400 steps | score: [-0.11591836810112]\n",
      "2500 steps | score: [-0.08094845712184906]\n",
      "0 steps | score: [0.22053754329681396, -0.1778583824634552]\n",
      "100 steps | score: [-0.029941285029053688, 0.2968815863132477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [-0.10340479016304016, 0.3412933349609375]\n",
      "300 steps | score: [0.09715087711811066, -0.1882154792547226]\n",
      "400 steps | score: [0.16478589177131653, -0.3010457456111908]\n",
      "500 steps | score: [-0.04979194700717926, 0.24526384472846985]\n",
      "600 steps | score: [-0.09826014935970306, 0.3356199860572815]\n",
      "700 steps | score: [0.2347894161939621, -0.5774057507514954]\n",
      "800 steps | score: [0.20765750110149384, -0.5026631355285645]\n",
      "900 steps | score: [-0.12747685611248016, 0.3935088813304901]\n",
      "1000 steps | score: [-0.0507957823574543, 0.21664774417877197]\n",
      "1100 steps | score: [0.13420361280441284, -0.27224022150039673]\n",
      "1200 steps | score: [-0.022332709282636642, 0.08865584433078766]\n",
      "1300 steps | score: [0.041306957602500916, -0.043417468667030334]\n",
      "1400 steps | score: [0.033981990069150925, 0.008605293929576874]\n",
      "1500 steps | score: [-0.029932592064142227, 0.15908929705619812]\n",
      "1600 steps | score: [0.041688691824674606, -0.04956968501210213]\n",
      "1700 steps | score: [-0.018973829224705696, 0.09362300485372543]\n",
      "1800 steps | score: [-0.017591455951333046, 0.09133744239807129]\n",
      "1900 steps | score: [0.04755989462137222, -0.041989561170339584]\n",
      "2000 steps | score: [0.21564176678657532, -0.5555270910263062]\n",
      "2100 steps | score: [0.00969592947512865, 0.049153029918670654]\n",
      "2200 steps | score: [0.02067749574780464, -0.012441478669643402]\n",
      "2300 steps | score: [0.056049562990665436, -0.08315391838550568]\n",
      "2400 steps | score: [0.20185306668281555, -0.5166007876396179]\n",
      "2500 steps | score: [0.13416235148906708, -0.2812720835208893]\n",
      "unknown params:  tensor([ 0.4347, -0.0055, -0.9081, -0.1379, -0.6452,  0.3315])\n",
      "gt params:  tensor([ 0.4828,  0.0052, -0.9636, -0.1415, -0.6953,  0.3257])\n",
      "ols params:  tensor([ 2.7910e-01, -2.1700e-03, -5.5618e-01, -8.7746e-02, -4.1311e-01,\n",
      "         2.7967e+00])\n",
      "unknown mse:  tensor(0.0013)\n",
      "ols mse:  tensor(1.0660)\n",
      "gt params:  tensor([ 0.4904,  0.0179, -0.9583, -0.1402, -0.6841,  0.2951])\n",
      "0 steps | score: [0.3172486126422882]\n",
      "100 steps | score: [-0.029245644807815552]\n",
      "200 steps | score: [0.08165593445301056]\n",
      "300 steps | score: [0.08026912808418274]\n",
      "400 steps | score: [0.11814233660697937]\n",
      "500 steps | score: [0.048067301511764526]\n",
      "600 steps | score: [0.06050371751189232]\n",
      "700 steps | score: [0.021431392058730125]\n",
      "800 steps | score: [0.05274498462677002]\n",
      "900 steps | score: [0.06873588263988495]\n",
      "1000 steps | score: [0.047049663960933685]\n",
      "1100 steps | score: [0.0912245661020279]\n",
      "1200 steps | score: [0.0422004833817482]\n",
      "1300 steps | score: [0.050283048301935196]\n",
      "1400 steps | score: [0.04790790006518364]\n",
      "1500 steps | score: [0.069908007979393]\n",
      "1600 steps | score: [0.04087873920798302]\n",
      "1700 steps | score: [0.031581178307533264]\n",
      "1800 steps | score: [0.038292594254016876]\n",
      "1900 steps | score: [0.03997638449072838]\n",
      "2000 steps | score: [0.0362066812813282]\n",
      "2100 steps | score: [0.053760699927806854]\n",
      "2200 steps | score: [0.035730376839637756]\n",
      "2300 steps | score: [0.027193695306777954]\n",
      "2400 steps | score: [0.041372109204530716]\n",
      "2500 steps | score: [0.07249701023101807]\n",
      "2600 steps | score: [0.041053034365177155]\n",
      "0 steps | score: [0.4334115982055664, -0.5406315922737122]\n",
      "100 steps | score: [0.15723343193531036, -0.08150938153266907]\n",
      "200 steps | score: [0.31165197491645813, -0.46904170513153076]\n",
      "300 steps | score: [0.5268409252166748, -1.0624256134033203]\n",
      "400 steps | score: [0.2543354630470276, -0.4003109335899353]\n",
      "500 steps | score: [0.20383667945861816, -0.24667581915855408]\n",
      "600 steps | score: [0.20720268785953522, -0.2773849368095398]\n",
      "700 steps | score: [0.30264267325401306, -0.5388292670249939]\n",
      "800 steps | score: [0.17760725319385529, -0.2154039442539215]\n",
      "900 steps | score: [0.3207966089248657, -0.5276092290878296]\n",
      "1000 steps | score: [0.1829940676689148, -0.24699170887470245]\n",
      "1100 steps | score: [0.25878432393074036, -0.43285542726516724]\n",
      "1200 steps | score: [0.25925248861312866, -0.42128175497055054]\n",
      "1300 steps | score: [0.26700371503829956, -0.4191679358482361]\n",
      "1400 steps | score: [0.24038416147232056, -0.3557262420654297]\n",
      "1500 steps | score: [0.21963246166706085, -0.36432161927223206]\n",
      "1600 steps | score: [0.23513513803482056, -0.367171049118042]\n",
      "1700 steps | score: [0.303081750869751, -0.5212666392326355]\n",
      "1800 steps | score: [0.17640286684036255, -0.21035200357437134]\n",
      "1900 steps | score: [0.26946476101875305, -0.42724689841270447]\n",
      "2000 steps | score: [0.23858150839805603, -0.3609144389629364]\n",
      "2100 steps | score: [0.1668308675289154, -0.19720542430877686]\n",
      "2200 steps | score: [0.20169752836227417, -0.2724161744117737]\n",
      "2300 steps | score: [0.2232896238565445, -0.29875507950782776]\n",
      "2400 steps | score: [0.27216336131095886, -0.45560646057128906]\n",
      "2500 steps | score: [0.30723318457603455, -0.5697301626205444]\n",
      "2600 steps | score: [0.22400467097759247, -0.35882318019866943]\n",
      "unknown params:  tensor([ 0.4995,  0.0260, -0.9132, -0.1346, -0.6914,  0.1329])\n",
      "gt params:  tensor([ 0.4904,  0.0179, -0.9583, -0.1402, -0.6841,  0.2951])\n",
      "ols params:  tensor([ 0.2960,  0.0201, -0.5192, -0.0754, -0.4029,  2.8756])\n",
      "unknown mse:  tensor(0.0048)\n",
      "ols mse:  tensor(1.1621)\n",
      "gt params:  tensor([ 0.4816,  0.0177, -0.9698, -0.1522, -0.6852,  0.3148])\n",
      "0 steps | score: [0.4127129316329956]\n",
      "100 steps | score: [0.223707377910614]\n",
      "200 steps | score: [0.10078581422567368]\n",
      "300 steps | score: [0.22637362778186798]\n",
      "400 steps | score: [0.1387813538312912]\n",
      "500 steps | score: [0.15380670130252838]\n",
      "600 steps | score: [0.16000783443450928]\n",
      "700 steps | score: [0.17368416488170624]\n",
      "800 steps | score: [0.14640110731124878]\n",
      "900 steps | score: [0.14330339431762695]\n",
      "1000 steps | score: [0.2120353728532791]\n",
      "1100 steps | score: [0.13577580451965332]\n",
      "1200 steps | score: [0.19823670387268066]\n",
      "1300 steps | score: [0.13800738751888275]\n",
      "1400 steps | score: [0.1509609967470169]\n",
      "1500 steps | score: [0.20236024260520935]\n",
      "1600 steps | score: [0.19921177625656128]\n",
      "1700 steps | score: [0.21221646666526794]\n",
      "1800 steps | score: [0.1891515702009201]\n",
      "1900 steps | score: [0.16566060483455658]\n",
      "2000 steps | score: [0.19308781623840332]\n",
      "2100 steps | score: [0.17973682284355164]\n",
      "2200 steps | score: [0.19103986024856567]\n",
      "2300 steps | score: [0.168216735124588]\n",
      "2400 steps | score: [0.1713479608297348]\n",
      "2500 steps | score: [0.15839523077011108]\n",
      "0 steps | score: [0.04548904299736023, 0.15043309330940247]\n",
      "100 steps | score: [-0.104426808655262, 0.3753548264503479]\n",
      "200 steps | score: [-0.1775229275226593, 0.471938818693161]\n",
      "300 steps | score: [-0.015174678526818752, 0.04392212629318237]\n",
      "400 steps | score: [-0.15053024888038635, 0.33581432700157166]\n",
      "500 steps | score: [-0.23266978561878204, 0.5211890935897827]\n",
      "600 steps | score: [-0.12043317407369614, 0.28599709272384644]\n",
      "700 steps | score: [-0.28568321466445923, 0.6329207420349121]\n",
      "800 steps | score: [-0.18496058881282806, 0.4045216143131256]\n",
      "900 steps | score: [-0.14144989848136902, 0.30563950538635254]\n",
      "1000 steps | score: [-0.1768369972705841, 0.4250414967536926]\n",
      "1100 steps | score: [-0.1857938915491104, 0.45098307728767395]\n",
      "1200 steps | score: [0.00559795880690217, -0.015183031558990479]\n",
      "1300 steps | score: [-0.12573696672916412, 0.307148277759552]\n",
      "1400 steps | score: [-0.15944546461105347, 0.34631839394569397]\n",
      "1500 steps | score: [-0.10362015664577484, 0.2388990819454193]\n",
      "1600 steps | score: [-0.1778246909379959, 0.37595194578170776]\n",
      "1700 steps | score: [-0.1085306704044342, 0.24512606859207153]\n",
      "1800 steps | score: [-0.0560932382941246, 0.12686097621917725]\n",
      "1900 steps | score: [-0.19478268921375275, 0.4261413812637329]\n",
      "2000 steps | score: [0.10894305258989334, -0.33183178305625916]\n",
      "2100 steps | score: [-0.2255307137966156, 0.5128461718559265]\n",
      "2200 steps | score: [-0.12222286313772202, 0.28099602460861206]\n",
      "2300 steps | score: [-0.12532733380794525, 0.29054543375968933]\n",
      "2400 steps | score: [-0.13740582764148712, 0.30576857924461365]\n",
      "2500 steps | score: [-0.09771256893873215, 0.21505548059940338]\n",
      "unknown params:  tensor([ 0.4895,  0.0084, -0.9767, -0.1354, -0.6833,  0.2473])\n",
      "gt params:  tensor([ 0.4816,  0.0177, -0.9698, -0.1522, -0.6852,  0.3148])\n",
      "ols params:  tensor([ 0.2692,  0.0080, -0.5116, -0.0735, -0.3726,  3.0471])\n",
      "unknown mse:  tensor(0.0008)\n",
      "ols mse:  tensor(1.3041)\n",
      "gt params:  tensor([ 0.4569,  0.0133, -0.9878, -0.1431, -0.6654,  0.3584])\n",
      "0 steps | score: [0.35657986998558044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [0.12647148966789246]\n",
      "200 steps | score: [0.13092643022537231]\n",
      "300 steps | score: [0.12192533910274506]\n",
      "400 steps | score: [0.10978476703166962]\n",
      "500 steps | score: [0.16798339784145355]\n",
      "600 steps | score: [0.14023452997207642]\n",
      "700 steps | score: [0.14960700273513794]\n",
      "800 steps | score: [0.08709116280078888]\n",
      "900 steps | score: [0.09031486511230469]\n",
      "1000 steps | score: [0.14877118170261383]\n",
      "1100 steps | score: [0.12037508934736252]\n",
      "1200 steps | score: [0.1387355923652649]\n",
      "1300 steps | score: [0.07198232412338257]\n",
      "1400 steps | score: [0.06238643825054169]\n",
      "1500 steps | score: [0.10315662622451782]\n",
      "1600 steps | score: [0.08959761261940002]\n",
      "1700 steps | score: [0.13497856259346008]\n",
      "1800 steps | score: [0.10563860088586807]\n",
      "1900 steps | score: [0.09115171432495117]\n",
      "2000 steps | score: [0.07330372929573059]\n",
      "2100 steps | score: [0.10674154758453369]\n",
      "2200 steps | score: [0.12523001432418823]\n",
      "2300 steps | score: [0.13564710319042206]\n",
      "2400 steps | score: [0.10744320601224899]\n",
      "2500 steps | score: [0.08392547070980072]\n",
      "2600 steps | score: [0.09561165422201157]\n",
      "0 steps | score: [0.09721340984106064, -0.06714386492967606]\n",
      "100 steps | score: [-0.10998988896608353, 0.2609824538230896]\n",
      "200 steps | score: [-0.0900297686457634, 0.14357125759124756]\n",
      "300 steps | score: [-0.10706472396850586, 0.15769606828689575]\n",
      "400 steps | score: [-0.04482756555080414, 0.024013981223106384]\n",
      "500 steps | score: [0.27395692467689514, -0.879938542842865]\n",
      "600 steps | score: [-0.04134785756468773, -0.02313697710633278]\n",
      "700 steps | score: [0.30358588695526123, -0.9846594333648682]\n",
      "800 steps | score: [-0.19175201654434204, 0.3602339029312134]\n",
      "900 steps | score: [0.23070135712623596, -0.7781175374984741]\n",
      "1000 steps | score: [0.19614721834659576, -0.7414012551307678]\n",
      "1100 steps | score: [-0.10677889734506607, 0.14632540941238403]\n",
      "1200 steps | score: [0.019837435334920883, -0.22993193566799164]\n",
      "1300 steps | score: [0.028570327907800674, -0.21042805910110474]\n",
      "1400 steps | score: [-0.003722114721313119, -0.15258798003196716]\n",
      "1500 steps | score: [-0.01822977513074875, -0.08212757855653763]\n",
      "1600 steps | score: [-0.05305757373571396, -0.002686604857444763]\n",
      "1700 steps | score: [0.054606154561042786, -0.29894447326660156]\n",
      "1800 steps | score: [-0.14333409070968628, 0.22364212572574615]\n",
      "1900 steps | score: [-0.10364262759685516, 0.12298817187547684]\n",
      "2000 steps | score: [0.0380672849714756, -0.27124810218811035]\n",
      "2100 steps | score: [0.05154075101017952, -0.30224698781967163]\n",
      "2200 steps | score: [-0.0404505729675293, -0.05530282109975815]\n",
      "2300 steps | score: [-0.07964915037155151, 0.062532439827919]\n",
      "2400 steps | score: [0.0292491652071476, -0.21040108799934387]\n",
      "2500 steps | score: [0.0036138223949819803, -0.15887977182865143]\n",
      "2600 steps | score: [0.06637362390756607, -0.32941386103630066]\n",
      "unknown params:  tensor([ 0.4563,  0.0089, -1.0128, -0.1577, -0.7437,  0.2265])\n",
      "gt params:  tensor([ 0.4569,  0.0133, -0.9878, -0.1431, -0.6654,  0.3584])\n",
      "ols params:  tensor([ 0.2450,  0.0067, -0.5192, -0.0840, -0.3918,  3.1491])\n",
      "unknown mse:  tensor(0.0041)\n",
      "ols mse:  tensor(1.3551)\n",
      "gt params:  tensor([ 0.4875,  0.0459, -0.9720, -0.1538, -0.6956,  0.3819])\n",
      "0 steps | score: [0.4804609417915344]\n",
      "100 steps | score: [0.17970097064971924]\n",
      "200 steps | score: [0.19584356248378754]\n",
      "300 steps | score: [0.2828328609466553]\n",
      "400 steps | score: [0.2230561077594757]\n",
      "500 steps | score: [0.1922106295824051]\n",
      "600 steps | score: [0.17956532537937164]\n",
      "700 steps | score: [0.1869969666004181]\n",
      "800 steps | score: [0.2731917202472687]\n",
      "900 steps | score: [0.21992738544940948]\n",
      "1000 steps | score: [0.2264515906572342]\n",
      "1100 steps | score: [0.19069555401802063]\n",
      "1200 steps | score: [0.1705356240272522]\n",
      "1300 steps | score: [0.22309812903404236]\n",
      "1400 steps | score: [0.19807688891887665]\n",
      "1500 steps | score: [0.1901044398546219]\n",
      "1600 steps | score: [0.142957866191864]\n",
      "1700 steps | score: [0.16583798825740814]\n",
      "1800 steps | score: [0.2026805579662323]\n",
      "1900 steps | score: [0.2464304119348526]\n",
      "2000 steps | score: [0.21936380863189697]\n",
      "2100 steps | score: [0.20369070768356323]\n",
      "2200 steps | score: [0.17578501999378204]\n",
      "2300 steps | score: [0.18905362486839294]\n",
      "2400 steps | score: [0.2194894552230835]\n",
      "2500 steps | score: [0.235948383808136]\n",
      "2600 steps | score: [0.20896875858306885]\n",
      "0 steps | score: [0.06568200886249542, 0.29010385274887085]\n",
      "100 steps | score: [0.26278239488601685, -0.4328742027282715]\n",
      "200 steps | score: [-0.12353198230266571, 0.4652642607688904]\n",
      "300 steps | score: [-0.2443157434463501, 0.7205758690834045]\n",
      "400 steps | score: [-0.22333502769470215, 0.6746083498001099]\n",
      "500 steps | score: [-0.264229953289032, 0.7180437445640564]\n",
      "600 steps | score: [-0.2931230068206787, 0.8237535357475281]\n",
      "700 steps | score: [-0.03651612251996994, 0.19809451699256897]\n",
      "800 steps | score: [-0.15174123644828796, 0.4559171795845032]\n",
      "900 steps | score: [-0.05462752282619476, 0.23388436436653137]\n",
      "1000 steps | score: [-0.08057588338851929, 0.3092799782752991]\n",
      "1100 steps | score: [-0.2001102715730667, 0.6007749438285828]\n",
      "1200 steps | score: [-0.2548597753047943, 0.7206259965896606]\n",
      "1300 steps | score: [-0.09500015527009964, 0.34306949377059937]\n",
      "1400 steps | score: [-0.0600554458796978, 0.24471797049045563]\n",
      "1500 steps | score: [-0.12738704681396484, 0.43675845861434937]\n",
      "1600 steps | score: [-0.11005937308073044, 0.3718385696411133]\n",
      "1700 steps | score: [-0.13238266110420227, 0.40830695629119873]\n",
      "1800 steps | score: [-0.10632675886154175, 0.37293869256973267]\n",
      "1900 steps | score: [-0.14576882123947144, 0.46926188468933105]\n",
      "2000 steps | score: [-0.10640694946050644, 0.3369434177875519]\n",
      "2100 steps | score: [-0.20601987838745117, 0.5904814004898071]\n",
      "2200 steps | score: [-0.12534259259700775, 0.4141353368759155]\n",
      "2300 steps | score: [-0.07342391461133957, 0.3198186159133911]\n",
      "2400 steps | score: [-0.04355153068900108, 0.1861925572156906]\n",
      "2500 steps | score: [-0.12492921948432922, 0.38598400354385376]\n",
      "2600 steps | score: [-0.06290484964847565, 0.2623554468154907]\n",
      "unknown params:  tensor([ 0.4804,  0.0682, -0.9564, -0.1366, -0.6865,  0.1573])\n",
      "gt params:  tensor([ 0.4875,  0.0459, -0.9720, -0.1538, -0.6956,  0.3819])\n",
      "ols params:  tensor([ 0.2745,  0.0424, -0.5170, -0.0720, -0.3862,  3.2788])\n",
      "unknown mse:  tensor(0.0086)\n",
      "ols mse:  tensor(1.4578)\n",
      "gt params:  tensor([ 0.4766,  0.0125, -0.9428, -0.1660, -0.6576,  0.3507])\n",
      "0 steps | score: [0.33159878849983215]\n",
      "100 steps | score: [0.12497422099113464]\n",
      "200 steps | score: [0.1085611879825592]\n",
      "300 steps | score: [0.12126593291759491]\n",
      "400 steps | score: [0.02484005317091942]\n",
      "500 steps | score: [0.03129382058978081]\n",
      "600 steps | score: [0.09545250982046127]\n",
      "700 steps | score: [0.019019216299057007]\n",
      "800 steps | score: [0.06383532285690308]\n",
      "900 steps | score: [0.03447210043668747]\n",
      "1000 steps | score: [0.06228604167699814]\n",
      "1100 steps | score: [0.08260636031627655]\n",
      "1200 steps | score: [0.05400259420275688]\n",
      "1300 steps | score: [0.0670645609498024]\n",
      "1400 steps | score: [0.07252873480319977]\n",
      "1500 steps | score: [0.07724733650684357]\n",
      "1600 steps | score: [0.04369203746318817]\n",
      "1700 steps | score: [0.09649801254272461]\n",
      "1800 steps | score: [0.06533873081207275]\n",
      "1900 steps | score: [0.06193438544869423]\n",
      "2000 steps | score: [0.0469922237098217]\n",
      "2100 steps | score: [0.07066870480775833]\n",
      "2200 steps | score: [0.09072692692279816]\n",
      "2300 steps | score: [0.06065637245774269]\n",
      "2400 steps | score: [0.06513508409261703]\n",
      "2500 steps | score: [0.0707612931728363]\n",
      "2600 steps | score: [0.06231432780623436]\n",
      "0 steps | score: [0.21132878959178925, -0.02052909880876541]\n",
      "100 steps | score: [0.10818139463663101, 0.09140065312385559]\n",
      "200 steps | score: [0.344037264585495, -0.6045144200325012]\n",
      "300 steps | score: [0.0833582654595375, 0.028702231124043465]\n",
      "400 steps | score: [-0.2390640527009964, 0.7121728658676147]\n",
      "500 steps | score: [0.10359705239534378, -0.06081361696124077]\n",
      "600 steps | score: [0.07007408142089844, 0.0471869595348835]\n",
      "700 steps | score: [-0.005719141103327274, 0.22367742657661438]\n",
      "800 steps | score: [0.06946839392185211, 0.05498123914003372]\n",
      "900 steps | score: [0.15084657073020935, -0.15608865022659302]\n",
      "1000 steps | score: [0.002988694468513131, 0.17576056718826294]\n",
      "1100 steps | score: [0.12116524577140808, -0.08049368113279343]\n",
      "1200 steps | score: [0.06218556687235832, 0.05417763814330101]\n",
      "1300 steps | score: [0.04341720789670944, 0.09676429629325867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 steps | score: [0.1104886531829834, -0.07355998456478119]\n",
      "1500 steps | score: [0.2350572794675827, -0.36435621976852417]\n",
      "1600 steps | score: [0.10550065338611603, -0.038326047360897064]\n",
      "1700 steps | score: [0.18086186051368713, -0.20313319563865662]\n",
      "1800 steps | score: [0.05682013928890228, 0.0589720755815506]\n",
      "1900 steps | score: [0.04897097870707512, 0.06830114126205444]\n",
      "2000 steps | score: [0.12051621079444885, -0.10217902064323425]\n",
      "2100 steps | score: [0.11121151596307755, -0.038493528962135315]\n",
      "2200 steps | score: [0.2261783629655838, -0.3787223696708679]\n",
      "2300 steps | score: [0.06308373063802719, 0.04842223599553108]\n",
      "2400 steps | score: [0.12159588932991028, -0.13225120306015015]\n",
      "2500 steps | score: [0.17733894288539886, -0.25974521040916443]\n",
      "2600 steps | score: [0.08755519986152649, 0.01142686977982521]\n",
      "unknown params:  tensor([ 0.4806,  0.0026, -0.9056, -0.1730, -0.6775,  0.2067])\n",
      "gt params:  tensor([ 0.4766,  0.0125, -0.9428, -0.1660, -0.6576,  0.3507])\n",
      "ols params:  tensor([ 0.2583,  0.0086, -0.4623, -0.0879, -0.3541,  3.3432])\n",
      "unknown mse:  tensor(0.0038)\n",
      "ols mse:  tensor(1.5553)\n",
      "gt params:  tensor([ 0.4442,  0.0195, -0.9730, -0.1662, -0.6713,  0.3504])\n",
      "0 steps | score: [0.243689626455307]\n",
      "100 steps | score: [0.04583745449781418]\n",
      "200 steps | score: [-0.024587105959653854]\n",
      "300 steps | score: [-0.07407990097999573]\n",
      "400 steps | score: [-0.06141534075140953]\n",
      "500 steps | score: [0.0674578845500946]\n",
      "600 steps | score: [0.06937158107757568]\n",
      "700 steps | score: [-0.06622030586004257]\n",
      "800 steps | score: [-0.03923538699746132]\n",
      "900 steps | score: [-0.03531846031546593]\n",
      "1000 steps | score: [-0.012585574761033058]\n",
      "1100 steps | score: [0.0045419782400131226]\n",
      "0 steps | score: [-0.09155969321727753, 0.4366847276687622]\n",
      "100 steps | score: [-0.19687654078006744, 0.49854516983032227]\n",
      "200 steps | score: [-0.26592379808425903, 0.6204329133033752]\n",
      "300 steps | score: [-0.3629826307296753, 0.7971326112747192]\n",
      "400 steps | score: [-0.45671793818473816, 0.9498094916343689]\n",
      "500 steps | score: [-0.15752805769443512, 0.291100412607193]\n",
      "600 steps | score: [-0.08655314892530441, 0.1465023159980774]\n",
      "700 steps | score: [-0.38760027289390564, 0.8354042768478394]\n",
      "800 steps | score: [-0.3867543339729309, 0.8660526275634766]\n",
      "900 steps | score: [-0.38831841945648193, 0.8411362171173096]\n",
      "1000 steps | score: [-0.2661020755767822, 0.549683690071106]\n",
      "1100 steps | score: [-0.39323708415031433, 0.8474255800247192]\n",
      "1200 steps | score: [-0.3618536591529846, 0.785111665725708]\n",
      "1300 steps | score: [-0.3617629110813141, 0.7808034420013428]\n",
      "1400 steps | score: [-0.2638856768608093, 0.5472842454910278]\n",
      "1500 steps | score: [-0.24778014421463013, 0.5017935633659363]\n",
      "1600 steps | score: [-0.2008969634771347, 0.3786261975765228]\n",
      "1700 steps | score: [-0.11014696210622787, 0.15451301634311676]\n",
      "1800 steps | score: [-0.2493196278810501, 0.5057772397994995]\n",
      "1900 steps | score: [-0.20744585990905762, 0.41197532415390015]\n",
      "2000 steps | score: [-0.23907142877578735, 0.4804074168205261]\n",
      "2100 steps | score: [-0.16447797417640686, 0.2967311441898346]\n",
      "2200 steps | score: [-0.2130575329065323, 0.44138020277023315]\n",
      "2300 steps | score: [-0.2671285569667816, 0.5487328171730042]\n",
      "2400 steps | score: [-0.29734742641448975, 0.6359126567840576]\n",
      "2500 steps | score: [-0.31054574251174927, 0.6277744770050049]\n",
      "2600 steps | score: [-0.2131202518939972, 0.41698700189590454]\n",
      "unknown params:  tensor([ 0.4198,  0.0581, -0.9677, -0.1792, -0.6496,  0.3697])\n",
      "gt params:  tensor([ 0.4442,  0.0195, -0.9730, -0.1662, -0.6713,  0.3504])\n",
      "ols params:  tensor([ 0.2302,  0.0323, -0.4953, -0.0945, -0.3496,  3.4939])\n",
      "unknown mse:  tensor(0.0005)\n",
      "ols mse:  tensor(1.7107)\n",
      "gt params:  tensor([ 0.4991,  0.0138, -0.9416, -0.1749, -0.6844,  0.3447])\n",
      "0 steps | score: [0.08612731099128723]\n",
      "100 steps | score: [-0.19751502573490143]\n",
      "200 steps | score: [-0.19857913255691528]\n",
      "300 steps | score: [-0.1539929360151291]\n",
      "400 steps | score: [-0.20270058512687683]\n",
      "500 steps | score: [-0.20436987280845642]\n",
      "600 steps | score: [-0.19566267728805542]\n",
      "700 steps | score: [-0.20013746619224548]\n",
      "800 steps | score: [-0.14993354678153992]\n",
      "900 steps | score: [-0.18373794853687286]\n",
      "1000 steps | score: [-0.19361788034439087]\n",
      "1100 steps | score: [-0.18484842777252197]\n",
      "1200 steps | score: [-0.19186611473560333]\n",
      "1300 steps | score: [-0.19582903385162354]\n",
      "1400 steps | score: [-0.19329050183296204]\n",
      "1500 steps | score: [-0.2134043574333191]\n",
      "1600 steps | score: [-0.19641348719596863]\n",
      "1700 steps | score: [-0.20822767913341522]\n",
      "1800 steps | score: [-0.1870613694190979]\n",
      "1900 steps | score: [-0.17750518023967743]\n",
      "2000 steps | score: [-0.19487622380256653]\n",
      "2100 steps | score: [-0.2186218500137329]\n",
      "2200 steps | score: [-0.19847413897514343]\n",
      "2300 steps | score: [-0.197684183716774]\n",
      "2400 steps | score: [-0.15743380784988403]\n",
      "2500 steps | score: [-0.2008603811264038]\n",
      "2600 steps | score: [-0.1906156688928604]\n",
      "0 steps | score: [0.03439857438206673, 0.3340641260147095]\n",
      "100 steps | score: [0.041249290108680725, 0.11241883784532547]\n",
      "200 steps | score: [-0.21536540985107422, 0.6336347460746765]\n",
      "300 steps | score: [-0.23870179057121277, 0.6805803775787354]\n",
      "400 steps | score: [-0.1717739999294281, 0.5189191102981567]\n",
      "500 steps | score: [-0.13058257102966309, 0.39791935682296753]\n",
      "600 steps | score: [-0.276945561170578, 0.7368592619895935]\n",
      "700 steps | score: [-0.15822255611419678, 0.419140487909317]\n",
      "800 steps | score: [0.16770091652870178, -0.35099756717681885]\n",
      "900 steps | score: [-0.1781340390443802, 0.510159969329834]\n",
      "1000 steps | score: [0.046321697533130646, -0.05753087252378464]\n",
      "1100 steps | score: [-0.15704110264778137, 0.41876310110092163]\n",
      "1200 steps | score: [-0.334635466337204, 0.8191637396812439]\n",
      "1300 steps | score: [-0.1339346468448639, 0.37525808811187744]\n",
      "1400 steps | score: [-0.09735089540481567, 0.3086443543434143]\n",
      "1500 steps | score: [-0.2074873000383377, 0.5613448023796082]\n",
      "1600 steps | score: [-0.17691607773303986, 0.47372525930404663]\n",
      "1700 steps | score: [-0.09192967414855957, 0.30649811029434204]\n",
      "1800 steps | score: [-0.17221872508525848, 0.44017067551612854]\n",
      "1900 steps | score: [-0.1226804330945015, 0.3566230535507202]\n",
      "2000 steps | score: [-0.17746175825595856, 0.49473533034324646]\n",
      "2100 steps | score: [-0.10734610259532928, 0.2993701696395874]\n",
      "2200 steps | score: [-0.13611485064029694, 0.4288070797920227]\n",
      "2300 steps | score: [-0.12969747185707092, 0.38458865880966187]\n",
      "2400 steps | score: [0.005314432084560394, 0.050081342458724976]\n",
      "2500 steps | score: [-0.136421337723732, 0.3929537534713745]\n",
      "2600 steps | score: [-0.11637179553508759, 0.3642478585243225]\n",
      "unknown params:  tensor([ 0.5502,  0.0336, -0.9523, -0.1971, -0.7037,  0.0589])\n",
      "gt params:  tensor([ 0.4991,  0.0138, -0.9416, -0.1749, -0.6844,  0.3447])\n",
      "ols params:  tensor([ 0.2769,  0.0222, -0.4604, -0.0996, -0.3500,  3.5452])\n",
      "unknown mse:  tensor(0.0143)\n",
      "ols mse:  tensor(1.7736)\n",
      "gt params:  tensor([ 0.4910,  0.0142, -0.9575, -0.1284, -0.6773,  0.2575])\n",
      "0 steps | score: [0.3886833190917969]\n",
      "100 steps | score: [0.030602941289544106]\n",
      "200 steps | score: [0.09981255233287811]\n",
      "300 steps | score: [0.1026051938533783]\n",
      "400 steps | score: [0.14165683090686798]\n",
      "500 steps | score: [0.11309274286031723]\n",
      "600 steps | score: [0.12382823973894119]\n",
      "700 steps | score: [0.054675206542015076]\n",
      "800 steps | score: [0.10151099413633347]\n",
      "900 steps | score: [0.09580327570438385]\n",
      "1000 steps | score: [0.14485971629619598]\n",
      "1100 steps | score: [0.15810853242874146]\n",
      "1200 steps | score: [0.1010792925953865]\n",
      "1300 steps | score: [0.12180215120315552]\n",
      "1400 steps | score: [0.15238900482654572]\n",
      "1500 steps | score: [0.12449144572019577]\n",
      "1600 steps | score: [0.14137431979179382]\n",
      "1700 steps | score: [0.11804337799549103]\n",
      "1800 steps | score: [0.09677939862012863]\n",
      "1900 steps | score: [0.12342800199985504]\n",
      "2000 steps | score: [0.1666065901517868]\n",
      "2100 steps | score: [0.12337462604045868]\n",
      "2200 steps | score: [0.09129472076892853]\n",
      "2300 steps | score: [0.11672273278236389]\n",
      "2400 steps | score: [0.09149662405252457]\n",
      "2500 steps | score: [0.12794281542301178]\n",
      "0 steps | score: [-0.006476312410086393, 0.3989345133304596]\n",
      "100 steps | score: [-0.364922434091568, 0.9684504270553589]\n",
      "200 steps | score: [-0.3821510970592499, 0.9496889114379883]\n",
      "300 steps | score: [-0.2851605713367462, 0.743746817111969]\n",
      "400 steps | score: [-0.06507393717765808, 0.23014017939567566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [-0.24436913430690765, 0.6542016863822937]\n",
      "600 steps | score: [-0.34542766213417053, 0.8678697943687439]\n",
      "700 steps | score: [-0.27031490206718445, 0.6927967667579651]\n",
      "800 steps | score: [-0.3425693213939667, 0.8416692018508911]\n",
      "900 steps | score: [-0.0590023510158062, 0.239216148853302]\n",
      "1000 steps | score: [-0.2473902404308319, 0.6729632019996643]\n",
      "1100 steps | score: [0.06784947961568832, -0.06717130541801453]\n",
      "1200 steps | score: [-0.34980669617652893, 0.8704060316085815]\n",
      "1300 steps | score: [-0.23285193741321564, 0.6241579651832581]\n",
      "1400 steps | score: [-0.230513334274292, 0.5984456539154053]\n",
      "1500 steps | score: [-0.1472949981689453, 0.4268224239349365]\n",
      "1600 steps | score: [-0.26298949122428894, 0.7126061916351318]\n",
      "1700 steps | score: [-0.2494436502456665, 0.6717839241027832]\n",
      "1800 steps | score: [-0.14669211208820343, 0.4281201958656311]\n",
      "1900 steps | score: [-0.15915676951408386, 0.4738493859767914]\n",
      "2000 steps | score: [-0.08877311646938324, 0.3012489378452301]\n",
      "2100 steps | score: [-0.2051873505115509, 0.5805856585502625]\n",
      "2200 steps | score: [-0.199030801653862, 0.5429436564445496]\n",
      "2300 steps | score: [-0.16862212121486664, 0.46656954288482666]\n",
      "2400 steps | score: [-0.21807695925235748, 0.5726170539855957]\n",
      "2500 steps | score: [-0.19367597997188568, 0.5239572525024414]\n",
      "unknown params:  tensor([ 0.5372, -0.0158, -0.9523, -0.1606, -0.6804,  0.1737])\n",
      "gt params:  tensor([ 0.4910,  0.0142, -0.9575, -0.1284, -0.6773,  0.2575])\n",
      "ols params:  tensor([ 0.2723, -0.0061, -0.4643, -0.0772, -0.3454,  3.6352])\n",
      "unknown mse:  tensor(0.0019)\n",
      "ols mse:  tensor(1.9688)\n",
      "gt params:  tensor([ 0.4622,  0.0093, -0.9547, -0.1587, -0.6681,  0.3387])\n",
      "0 steps | score: [0.08729967474937439]\n",
      "100 steps | score: [-0.23077823221683502]\n",
      "200 steps | score: [-0.20090477168560028]\n",
      "300 steps | score: [-0.18448235094547272]\n",
      "400 steps | score: [-0.1994163691997528]\n",
      "500 steps | score: [-0.1383848786354065]\n",
      "600 steps | score: [-0.18787118792533875]\n",
      "700 steps | score: [-0.24465695023536682]\n",
      "800 steps | score: [-0.21369516849517822]\n",
      "900 steps | score: [-0.21876893937587738]\n",
      "1000 steps | score: [-0.19270145893096924]\n",
      "1100 steps | score: [-0.14542405307292938]\n",
      "1200 steps | score: [-0.21028582751750946]\n",
      "1300 steps | score: [-0.24404850602149963]\n",
      "1400 steps | score: [-0.21273408830165863]\n",
      "1500 steps | score: [-0.17518872022628784]\n",
      "1600 steps | score: [-0.18848831951618195]\n",
      "1700 steps | score: [-0.20065626502037048]\n",
      "1800 steps | score: [-0.2101626694202423]\n",
      "1900 steps | score: [-0.2298315018415451]\n",
      "2000 steps | score: [-0.19661742448806763]\n",
      "2100 steps | score: [-0.1646876037120819]\n",
      "2200 steps | score: [-0.19771447777748108]\n",
      "2300 steps | score: [-0.22226683795452118]\n",
      "2400 steps | score: [-0.224442720413208]\n",
      "2500 steps | score: [-0.1921086609363556]\n",
      "2600 steps | score: [-0.18876586854457855]\n",
      "0 steps | score: [0.09091085195541382, -0.0868045836687088]\n",
      "100 steps | score: [-0.291331022977829, 0.527167558670044]\n",
      "200 steps | score: [0.5491120219230652, -1.6417567729949951]\n",
      "300 steps | score: [-0.020596258342266083, -0.08087266981601715]\n",
      "400 steps | score: [-0.26809751987457275, 0.44688543677330017]\n",
      "500 steps | score: [-0.0370299257338047, -0.030921872705221176]\n",
      "600 steps | score: [-0.17846345901489258, 0.26644301414489746]\n",
      "700 steps | score: [-0.14416275918483734, 0.15658658742904663]\n",
      "800 steps | score: [-0.320738822221756, 0.5223698019981384]\n",
      "900 steps | score: [-0.1787075698375702, 0.24264007806777954]\n",
      "1000 steps | score: [-0.10357855260372162, 0.05682360753417015]\n",
      "1100 steps | score: [0.059698835015296936, -0.3087034821510315]\n",
      "1200 steps | score: [-0.015273361466825008, -0.14687791466712952]\n",
      "1300 steps | score: [-0.1803065538406372, 0.2272849977016449]\n",
      "1400 steps | score: [-0.0738697350025177, 0.027517996728420258]\n",
      "1500 steps | score: [-0.003694538027048111, -0.13163408637046814]\n",
      "1600 steps | score: [-0.010893456637859344, -0.11446970701217651]\n",
      "1700 steps | score: [-0.16062712669372559, 0.18226972222328186]\n",
      "1800 steps | score: [-0.1283443719148636, 0.12512552738189697]\n",
      "1900 steps | score: [-0.099001444876194, 0.05503281205892563]\n",
      "2000 steps | score: [-0.1086924746632576, 0.07863584160804749]\n",
      "2100 steps | score: [-0.08091709017753601, 0.037639494985342026]\n",
      "2200 steps | score: [-0.15144453942775726, 0.1775900423526764]\n",
      "2300 steps | score: [-0.19320642948150635, 0.25959861278533936]\n",
      "2400 steps | score: [-0.07351536303758621, -0.002359136939048767]\n",
      "2500 steps | score: [-0.04573981091380119, -0.08991003036499023]\n",
      "2600 steps | score: [0.0038167673628777266, -0.1407301425933838]\n",
      "unknown params:  tensor([ 0.4559, -0.0095, -1.0084, -0.1120, -0.6888,  0.2163])\n",
      "gt params:  tensor([ 0.4622,  0.0093, -0.9547, -0.1587, -0.6681,  0.3387])\n",
      "ols params:  tensor([ 2.2647e-01, -1.3728e-03, -4.7081e-01, -5.2319e-02, -3.3191e-01,\n",
      "         3.7326e+00])\n",
      "unknown mse:  tensor(0.0035)\n",
      "ols mse:  tensor(1.9889)\n",
      "gt params:  tensor([ 0.4690,  0.0119, -0.9704, -0.1474, -0.6991,  0.3721])\n",
      "0 steps | score: [0.2949037253856659]\n",
      "100 steps | score: [-0.03206026926636696]\n",
      "200 steps | score: [0.07314082980155945]\n",
      "300 steps | score: [-0.013210971839725971]\n",
      "400 steps | score: [-0.004518669098615646]\n",
      "0 steps | score: [-0.12757761776447296, 0.5849319696426392]\n",
      "100 steps | score: [-0.4168812930583954, 1.0558221340179443]\n",
      "200 steps | score: [-0.18774886429309845, 0.5549130439758301]\n",
      "300 steps | score: [-0.09657873213291168, 0.24937930703163147]\n",
      "400 steps | score: [-0.38341841101646423, 0.9114815592765808]\n",
      "500 steps | score: [-0.27317848801612854, 0.6232014298439026]\n",
      "600 steps | score: [-0.140237495303154, 0.3411005735397339]\n",
      "700 steps | score: [-0.14355014264583588, 0.3294091820716858]\n",
      "800 steps | score: [-0.5310930609703064, 1.1697479486465454]\n",
      "900 steps | score: [-0.4411417841911316, 1.0212130546569824]\n",
      "1000 steps | score: [-0.36713340878486633, 0.8431106209754944]\n",
      "1100 steps | score: [-0.3608943223953247, 0.8527566194534302]\n",
      "1200 steps | score: [-0.3919333219528198, 0.8794180154800415]\n",
      "1300 steps | score: [-0.3392477333545685, 0.7908389568328857]\n",
      "1400 steps | score: [-0.37926995754241943, 0.8984050750732422]\n",
      "1500 steps | score: [-0.3503146171569824, 0.7891923785209656]\n",
      "1600 steps | score: [-0.32348862290382385, 0.7847797274589539]\n",
      "1700 steps | score: [-0.28824013471603394, 0.6726865172386169]\n",
      "1800 steps | score: [-0.1351521611213684, 0.3206113874912262]\n",
      "1900 steps | score: [-0.3566867709159851, 0.827060341835022]\n",
      "2000 steps | score: [-0.13492901623249054, 0.36090007424354553]\n",
      "2100 steps | score: [-0.38891372084617615, 0.9069016575813293]\n",
      "2200 steps | score: [-0.29742178320884705, 0.6813355088233948]\n",
      "2300 steps | score: [-0.3478899300098419, 0.7969950437545776]\n",
      "2400 steps | score: [-0.35317274928092957, 0.8092675805091858]\n",
      "2500 steps | score: [-0.25272566080093384, 0.6134052872657776]\n",
      "unknown params:  tensor([ 0.5118, -0.0026, -1.0035, -0.1414, -0.6791,  0.2468])\n",
      "gt params:  tensor([ 0.4690,  0.0119, -0.9704, -0.1474, -0.6991,  0.3721])\n",
      "ols params:  tensor([ 2.5928e-01,  3.0544e-03, -4.8601e-01, -7.1408e-02, -3.4220e-01,\n",
      "         3.8911e+00])\n",
      "unknown mse:  tensor(0.0032)\n",
      "ols mse:  tensor(2.1325)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/37af8a5c-a50e-43da-9d58-540e0b62e9b7\n",
      "gt params:  tensor([-0.4107, -0.8216, -0.0928, -0.9513,  0.7557,  0.8851])\n",
      "0 steps | score: [0.10829495638608932]\n",
      "100 steps | score: [0.08174029737710953]\n",
      "200 steps | score: [-0.06708158552646637]\n",
      "300 steps | score: [-0.03293536975979805]\n",
      "400 steps | score: [0.08244644850492477]\n",
      "500 steps | score: [-0.07740602642297745]\n",
      "600 steps | score: [-0.006981328129768372]\n",
      "0 steps | score: [0.009764350950717926, 0.2169187366962433]\n",
      "100 steps | score: [-4.363786220550537, 13.144357681274414]\n",
      "200 steps | score: [-3.725691795349121, 12.834319114685059]\n",
      "300 steps | score: [4.270665168762207, -26.45393180847168]\n",
      "400 steps | score: [7.99670934677124, -68.1807632446289]\n",
      "500 steps | score: [-0.3326866924762726, 4.072787761688232]\n",
      "600 steps | score: [0.7798595428466797, -1.6087346076965332]\n",
      "700 steps | score: [-0.7301567196846008, 5.37121057510376]\n",
      "800 steps | score: [-2.5887868404388428, 11.197052955627441]\n",
      "900 steps | score: [-1.7037485837936401, 8.987753868103027]\n",
      "1000 steps | score: [0.4636929929256439, -0.8342926502227783]\n",
      "1100 steps | score: [10.821431159973145, -128.45350646972656]\n",
      "1200 steps | score: [1.4963493347167969, -8.772239685058594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 steps | score: [0.49016082286834717, -2.5494613647460938]\n",
      "1400 steps | score: [1.3053940534591675, -8.726844787597656]\n",
      "1500 steps | score: [0.7783553600311279, -5.181097030639648]\n",
      "1600 steps | score: [-0.4830018877983093, 2.624307632446289]\n",
      "1700 steps | score: [0.02309224382042885, -0.24557845294475555]\n",
      "1800 steps | score: [0.170378640294075, -1.1612532138824463]\n",
      "1900 steps | score: [-0.12408097833395004, 0.47521209716796875]\n",
      "2000 steps | score: [-0.3391455113887787, 1.779164433479309]\n",
      "2100 steps | score: [0.013014017604291439, -0.3081955909729004]\n",
      "2200 steps | score: [-0.11119525879621506, 0.4036283791065216]\n",
      "2300 steps | score: [-0.16135790944099426, 0.7457838654518127]\n",
      "2400 steps | score: [0.20371785759925842, -1.5881820917129517]\n",
      "2500 steps | score: [0.09150128066539764, -0.782540500164032]\n",
      "2600 steps | score: [0.011398129165172577, -0.35358840227127075]\n",
      "2700 steps | score: [-0.1797470599412918, 0.8014676570892334]\n",
      "2800 steps | score: [-0.10914021730422974, 0.2834986448287964]\n",
      "unknown params:  tensor([-0.4177, -0.8269, -0.0949, -0.9387,  0.7530,  0.4485])\n",
      "gt params:  tensor([-0.4107, -0.8216, -0.0928, -0.9513,  0.7557,  0.8851])\n",
      "ols params:  tensor([-0.3842, -0.7689, -0.0863, -0.8780,  0.7071,  1.2398])\n",
      "unknown mse:  tensor(0.0318)\n",
      "ols mse:  tensor(0.0228)\n",
      "gt params:  tensor([-0.4086, -0.8202, -0.0982, -0.9524,  0.7541,  0.8785])\n",
      "0 steps | score: [-0.030739134177565575]\n",
      "100 steps | score: [-0.12002059817314148]\n",
      "200 steps | score: [-0.1536688357591629]\n",
      "300 steps | score: [-0.1369897425174713]\n",
      "400 steps | score: [-0.20112770795822144]\n",
      "500 steps | score: [-0.1473352462053299]\n",
      "600 steps | score: [-0.11964935064315796]\n",
      "700 steps | score: [-0.10031288117170334]\n",
      "800 steps | score: [-0.08738318085670471]\n",
      "900 steps | score: [-0.06954820454120636]\n",
      "1000 steps | score: [-0.14961987733840942]\n",
      "1100 steps | score: [-0.1698710173368454]\n",
      "1200 steps | score: [-0.18894004821777344]\n",
      "1300 steps | score: [-0.1739218384027481]\n",
      "1400 steps | score: [-0.12163526564836502]\n",
      "1500 steps | score: [-0.15367388725280762]\n",
      "1600 steps | score: [-0.15057465434074402]\n",
      "1700 steps | score: [-0.15189878642559052]\n",
      "1800 steps | score: [-0.16426222026348114]\n",
      "1900 steps | score: [-0.13831189274787903]\n",
      "2000 steps | score: [-0.132501021027565]\n",
      "2100 steps | score: [-0.12072686851024628]\n",
      "2200 steps | score: [-0.15708217024803162]\n",
      "2300 steps | score: [-0.18200790882110596]\n",
      "2400 steps | score: [-0.14891460537910461]\n",
      "2500 steps | score: [-0.1468866616487503]\n",
      "2600 steps | score: [-0.14521615207195282]\n",
      "2700 steps | score: [-0.15685346722602844]\n",
      "2800 steps | score: [-0.13496063649654388]\n",
      "0 steps | score: [0.28648731112480164, -0.6867424249649048]\n",
      "100 steps | score: [0.3190433979034424, -0.97072434425354]\n",
      "200 steps | score: [-1.0762487649917603, 4.045030117034912]\n",
      "300 steps | score: [6.215134143829346, -38.740936279296875]\n",
      "400 steps | score: [0.41614046692848206, -0.26721975207328796]\n",
      "500 steps | score: [-0.46235203742980957, 2.318385362625122]\n",
      "600 steps | score: [0.07167385518550873, 0.13131371140480042]\n",
      "700 steps | score: [0.1886882483959198, -0.4349728524684906]\n",
      "800 steps | score: [-1.0468724966049194, 3.7909865379333496]\n",
      "900 steps | score: [0.1429644376039505, -0.2915395498275757]\n",
      "1000 steps | score: [0.051243554800748825, -0.02155502326786518]\n",
      "1100 steps | score: [0.47916659712791443, -1.978346824645996]\n",
      "1200 steps | score: [-0.16848844289779663, 0.7662235498428345]\n",
      "1300 steps | score: [0.1321142613887787, -0.46730145812034607]\n",
      "1400 steps | score: [0.13688741624355316, -0.5004147887229919]\n",
      "1500 steps | score: [-0.0204367283731699, 0.19451335072517395]\n",
      "1600 steps | score: [0.37151020765304565, -1.4874382019042969]\n",
      "1700 steps | score: [-0.06883539259433746, 0.41371089220046997]\n",
      "1800 steps | score: [0.2603880763053894, -1.1471996307373047]\n",
      "1900 steps | score: [0.18548430502414703, -0.7376261949539185]\n",
      "2000 steps | score: [0.09535184502601624, -0.3231293857097626]\n",
      "2100 steps | score: [0.22289255261421204, -0.8942727446556091]\n",
      "2200 steps | score: [0.22439171373844147, -0.7850975394248962]\n",
      "2300 steps | score: [0.1469312459230423, -0.5538643002510071]\n",
      "2400 steps | score: [0.22481830418109894, -0.8907778859138489]\n",
      "2500 steps | score: [0.1625940501689911, -0.6231853365898132]\n",
      "2600 steps | score: [0.2277868092060089, -0.9062161445617676]\n",
      "2700 steps | score: [0.15545880794525146, -0.5055549144744873]\n",
      "2800 steps | score: [0.0556216835975647, -0.20150959491729736]\n",
      "unknown params:  tensor([-0.4040, -0.8148, -0.0946, -0.9426,  0.7429,  0.5689])\n",
      "gt params:  tensor([-0.4086, -0.8202, -0.0982, -0.9524,  0.7541,  0.8785])\n",
      "ols params:  tensor([-0.3574, -0.7198, -0.0854, -0.8289,  0.6580,  1.5258])\n",
      "unknown mse:  tensor(0.0160)\n",
      "ols mse:  tensor(0.0761)\n",
      "gt params:  tensor([-0.4073, -0.8201, -0.0962, -0.9423,  0.7577,  0.8761])\n",
      "0 steps | score: [0.0036698952317237854]\n",
      "100 steps | score: [-0.09919646382331848]\n",
      "200 steps | score: [-0.12640468776226044]\n",
      "300 steps | score: [-0.1365106701850891]\n",
      "400 steps | score: [-0.1252099871635437]\n",
      "500 steps | score: [-0.11343985795974731]\n",
      "600 steps | score: [-0.14723077416419983]\n",
      "700 steps | score: [-0.1689089983701706]\n",
      "800 steps | score: [-0.18359297513961792]\n",
      "900 steps | score: [-0.1915082335472107]\n",
      "1000 steps | score: [-0.12539951503276825]\n",
      "1100 steps | score: [-0.09969479590654373]\n",
      "1200 steps | score: [-0.14854958653450012]\n",
      "1300 steps | score: [-0.18455426394939423]\n",
      "1400 steps | score: [-0.09356094896793365]\n",
      "1500 steps | score: [-0.17545729875564575]\n",
      "1600 steps | score: [-0.1431032121181488]\n",
      "1700 steps | score: [-0.13326752185821533]\n",
      "1800 steps | score: [-0.15016597509384155]\n",
      "1900 steps | score: [-0.14778104424476624]\n",
      "2000 steps | score: [-0.11640377342700958]\n",
      "2100 steps | score: [-0.11375529319047928]\n",
      "2200 steps | score: [-0.11214403808116913]\n",
      "2300 steps | score: [-0.126260444521904]\n",
      "2400 steps | score: [-0.15860746800899506]\n",
      "2500 steps | score: [-0.1319972276687622]\n",
      "2600 steps | score: [-0.13813091814517975]\n",
      "2700 steps | score: [-0.12770645320415497]\n",
      "2800 steps | score: [-0.12716087698936462]\n",
      "0 steps | score: [0.11921854317188263, -0.4250001609325409]\n",
      "100 steps | score: [-0.0444016233086586, -0.07076448202133179]\n",
      "200 steps | score: [0.31127163767814636, -1.460062861442566]\n",
      "300 steps | score: [0.22425608336925507, -1.1497647762298584]\n",
      "400 steps | score: [-0.019924910739064217, -0.2509436011314392]\n",
      "500 steps | score: [0.00021469489729497582, -0.3780736029148102]\n",
      "600 steps | score: [-0.013232679106295109, -0.2678079605102539]\n",
      "700 steps | score: [0.04565119370818138, -0.47836625576019287]\n",
      "800 steps | score: [0.05137437954545021, -0.6466156840324402]\n",
      "900 steps | score: [-0.2541552186012268, 0.45773327350616455]\n",
      "1000 steps | score: [-0.3134230971336365, 0.6695233583450317]\n",
      "1100 steps | score: [-0.016332557424902916, -0.2687426209449768]\n",
      "1200 steps | score: [0.0068407561630010605, -0.430325984954834]\n",
      "1300 steps | score: [-0.12785367667675018, 0.0448867604136467]\n",
      "1400 steps | score: [0.016575351357460022, -0.4269690215587616]\n",
      "1500 steps | score: [0.02873271331191063, -0.5123239755630493]\n",
      "1600 steps | score: [-0.12513436377048492, 0.03380593657493591]\n",
      "1700 steps | score: [-0.08029629290103912, -0.09722118079662323]\n",
      "1800 steps | score: [0.20648378133773804, -1.1581089496612549]\n",
      "1900 steps | score: [-0.03658346086740494, -0.2763781249523163]\n",
      "2000 steps | score: [-0.032595548778772354, -0.2920708656311035]\n",
      "2100 steps | score: [-0.013649091124534607, -0.3409082591533661]\n",
      "2200 steps | score: [0.07539312541484833, -0.6665680408477783]\n",
      "2300 steps | score: [-0.0331307053565979, -0.2837044298648834]\n",
      "2400 steps | score: [-0.052194610238075256, -0.1979677826166153]\n",
      "2500 steps | score: [-0.07401376217603683, -0.13242554664611816]\n",
      "2600 steps | score: [-0.1676221489906311, 0.18879780173301697]\n",
      "2700 steps | score: [-0.09524904191493988, -0.08650685846805573]\n",
      "2800 steps | score: [-0.02918159030377865, -0.3193979561328888]\n",
      "unknown params:  tensor([-0.4191, -0.8237, -0.0941, -0.9560,  0.7595,  0.7333])\n",
      "gt params:  tensor([-0.4073, -0.8201, -0.0962, -0.9423,  0.7577,  0.8761])\n",
      "ols params:  tensor([-0.3475, -0.6736, -0.0857, -0.7840,  0.6287,  1.8003])\n",
      "unknown mse:  tensor(0.0035)\n",
      "ols mse:  tensor(0.1535)\n",
      "gt params:  tensor([-0.4162, -0.8251, -0.1040, -0.9550,  0.7631,  0.8425])\n",
      "0 steps | score: [0.20543748140335083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [-0.07451356202363968]\n",
      "200 steps | score: [-0.025677889585494995]\n",
      "300 steps | score: [0.06359098851680756]\n",
      "400 steps | score: [0.08486610651016235]\n",
      "500 steps | score: [0.13288182020187378]\n",
      "600 steps | score: [0.12275303900241852]\n",
      "700 steps | score: [0.04878413677215576]\n",
      "800 steps | score: [0.04578418284654617]\n",
      "900 steps | score: [0.06103954464197159]\n",
      "1000 steps | score: [0.11432535201311111]\n",
      "1100 steps | score: [0.03829365223646164]\n",
      "1200 steps | score: [0.0833025574684143]\n",
      "1300 steps | score: [0.09946352988481522]\n",
      "1400 steps | score: [0.06085280701518059]\n",
      "1500 steps | score: [0.05231919512152672]\n",
      "1600 steps | score: [0.10507608950138092]\n",
      "1700 steps | score: [0.11219392716884613]\n",
      "1800 steps | score: [0.05208674818277359]\n",
      "1900 steps | score: [0.014635391533374786]\n",
      "2000 steps | score: [0.038919296115636826]\n",
      "2100 steps | score: [0.06569360196590424]\n",
      "2200 steps | score: [0.0679873377084732]\n",
      "2300 steps | score: [0.058968041092157364]\n",
      "2400 steps | score: [0.06901583075523376]\n",
      "2500 steps | score: [0.02476145327091217]\n",
      "2600 steps | score: [0.044100530445575714]\n",
      "2700 steps | score: [0.06919969618320465]\n",
      "2800 steps | score: [0.08829565346240997]\n",
      "0 steps | score: [0.1390276849269867, -0.36060938239097595]\n",
      "100 steps | score: [-0.15734371542930603, 0.31698980927467346]\n",
      "200 steps | score: [-0.28231924772262573, 0.6295930743217468]\n",
      "300 steps | score: [0.07789482921361923, -0.47480034828186035]\n",
      "400 steps | score: [-0.05218924954533577, -0.050386250019073486]\n",
      "500 steps | score: [0.10073082149028778, -0.4480716586112976]\n",
      "600 steps | score: [0.02987782470881939, -0.23274831473827362]\n",
      "700 steps | score: [0.025578761473298073, -0.3048878312110901]\n",
      "800 steps | score: [-0.2612451910972595, 0.4981657862663269]\n",
      "900 steps | score: [-0.12458906322717667, 0.114077128469944]\n",
      "1000 steps | score: [0.09537960588932037, -0.5501325130462646]\n",
      "1100 steps | score: [-0.08923670649528503, 0.08415757119655609]\n",
      "1200 steps | score: [-0.10963185876607895, 0.10260234028100967]\n",
      "1300 steps | score: [0.01618431881070137, -0.2598087787628174]\n",
      "1400 steps | score: [-0.103182353079319, 0.06818243861198425]\n",
      "1500 steps | score: [0.033441536128520966, -0.34536388516426086]\n",
      "1600 steps | score: [0.032110799103975296, -0.34644198417663574]\n",
      "1700 steps | score: [-0.004258244764059782, -0.24632486701011658]\n",
      "1800 steps | score: [-0.06906891614198685, -0.05169298127293587]\n",
      "1900 steps | score: [-0.14881210029125214, 0.20853914320468903]\n",
      "2000 steps | score: [-0.06552161276340485, -0.01507461629807949]\n",
      "2100 steps | score: [-0.07530002295970917, -0.018832970410585403]\n",
      "2200 steps | score: [0.03650829195976257, -0.35718485713005066]\n",
      "2300 steps | score: [-0.03727459907531738, -0.13231606781482697]\n",
      "2400 steps | score: [0.0746542364358902, -0.48937350511550903]\n",
      "2500 steps | score: [-0.07402405887842178, -0.006268834695219994]\n",
      "2600 steps | score: [-0.024266790598630905, -0.18966028094291687]\n",
      "2700 steps | score: [0.025735490024089813, -0.3137911260128021]\n",
      "2800 steps | score: [0.06166171655058861, -0.42321842908859253]\n",
      "unknown params:  tensor([-0.4304, -0.8512, -0.1042, -0.9908,  0.7825,  0.6903])\n",
      "gt params:  tensor([-0.4162, -0.8251, -0.1040, -0.9550,  0.7631,  0.8425])\n",
      "ols params:  tensor([-0.3312, -0.6497, -0.0866, -0.7537,  0.6017,  1.9989])\n",
      "unknown mse:  tensor(0.0043)\n",
      "ols mse:  tensor(0.2403)\n",
      "gt params:  tensor([-0.4029, -0.8308, -0.0788, -0.9312,  0.7453,  0.9075])\n",
      "0 steps | score: [0.30179890990257263]\n",
      "100 steps | score: [0.1805211901664734]\n",
      "200 steps | score: [0.10728190839290619]\n",
      "300 steps | score: [0.2262430191040039]\n",
      "400 steps | score: [0.13498404622077942]\n",
      "500 steps | score: [0.1030028685927391]\n",
      "600 steps | score: [0.12780040502548218]\n",
      "700 steps | score: [0.09298279136419296]\n",
      "800 steps | score: [0.13639116287231445]\n",
      "900 steps | score: [0.12905322015285492]\n",
      "1000 steps | score: [0.08400078117847443]\n",
      "1100 steps | score: [0.0963631123304367]\n",
      "1200 steps | score: [0.15960396826267242]\n",
      "1300 steps | score: [0.12383599579334259]\n",
      "1400 steps | score: [0.1611223965883255]\n",
      "1500 steps | score: [0.1330154687166214]\n",
      "1600 steps | score: [0.09113341569900513]\n",
      "1700 steps | score: [0.12202060222625732]\n",
      "1800 steps | score: [0.18242891132831573]\n",
      "1900 steps | score: [0.16110065579414368]\n",
      "2000 steps | score: [0.159318208694458]\n",
      "2100 steps | score: [0.14869172871112823]\n",
      "2200 steps | score: [0.13627353310585022]\n",
      "2300 steps | score: [0.1203586682677269]\n",
      "2400 steps | score: [0.15169908106327057]\n",
      "2500 steps | score: [0.13319635391235352]\n",
      "2600 steps | score: [0.1651054322719574]\n",
      "2700 steps | score: [0.11432620882987976]\n",
      "2800 steps | score: [0.12272068858146667]\n",
      "0 steps | score: [0.1455867439508438, -0.2573436498641968]\n",
      "100 steps | score: [-0.1051337867975235, 0.30677926540374756]\n",
      "200 steps | score: [-0.29913750290870667, 0.774677574634552]\n",
      "300 steps | score: [-0.13336993753910065, 0.28933805227279663]\n",
      "400 steps | score: [0.23181091248989105, -0.8842084407806396]\n",
      "500 steps | score: [-0.07041635364294052, 0.12163671851158142]\n",
      "600 steps | score: [-0.3103141486644745, 0.758762776851654]\n",
      "700 steps | score: [-0.0925782173871994, 0.08112628012895584]\n",
      "800 steps | score: [0.11529017984867096, -0.5071094632148743]\n",
      "900 steps | score: [-0.22496435046195984, 0.5440248250961304]\n",
      "1000 steps | score: [0.10814638435840607, -0.49285557866096497]\n",
      "1100 steps | score: [-0.10672905296087265, 0.2156033217906952]\n",
      "1200 steps | score: [0.05314958468079567, -0.33542993664741516]\n",
      "1300 steps | score: [0.17026160657405853, -0.7547045350074768]\n",
      "1400 steps | score: [-0.026811614632606506, -0.056260574609041214]\n",
      "1500 steps | score: [-0.04805455356836319, 0.0048976135440170765]\n",
      "1600 steps | score: [-0.0039039149414747953, -0.1369318664073944]\n",
      "1700 steps | score: [-0.06259892880916595, 0.09270146489143372]\n",
      "1800 steps | score: [-0.015427233651280403, -0.1125325858592987]\n",
      "1900 steps | score: [0.10370241105556488, -0.4887896776199341]\n",
      "2000 steps | score: [0.07256895303726196, -0.3901321291923523]\n",
      "2100 steps | score: [0.0025913245044648647, -0.1660858541727066]\n",
      "2200 steps | score: [-0.04123230278491974, -0.022354157641530037]\n",
      "2300 steps | score: [0.044856633991003036, -0.31893113255500793]\n",
      "2400 steps | score: [0.01963292434811592, -0.2079421579837799]\n",
      "2500 steps | score: [-0.016523435711860657, -0.07986698299646378]\n",
      "2600 steps | score: [0.11499417573213577, -0.5071888566017151]\n",
      "2700 steps | score: [-0.07807067036628723, 0.08701132237911224]\n",
      "2800 steps | score: [0.0005898180534131825, -0.108150914311409]\n",
      "unknown params:  tensor([-0.3660, -0.8003, -0.0514, -0.9009,  0.7328,  0.8137])\n",
      "gt params:  tensor([-0.4029, -0.8308, -0.0788, -0.9312,  0.7453,  0.9075])\n",
      "ols params:  tensor([-0.2919, -0.6282, -0.0484, -0.7019,  0.5749,  2.2385])\n",
      "unknown mse:  tensor(0.0022)\n",
      "ols mse:  tensor(0.3179)\n",
      "gt params:  tensor([-0.3964, -0.8282, -0.1062, -0.9486,  0.7560,  0.8574])\n",
      "0 steps | score: [0.023391783237457275]\n",
      "100 steps | score: [-0.05523648113012314]\n",
      "200 steps | score: [-0.16847151517868042]\n",
      "300 steps | score: [-0.1738116443157196]\n",
      "400 steps | score: [-0.06020987778902054]\n",
      "500 steps | score: [-0.08758299797773361]\n",
      "600 steps | score: [-0.1878097504377365]\n",
      "700 steps | score: [-0.14033004641532898]\n",
      "800 steps | score: [-0.15916025638580322]\n",
      "900 steps | score: [-0.13863302767276764]\n",
      "1000 steps | score: [-0.0702015832066536]\n",
      "1100 steps | score: [-0.11870788037776947]\n",
      "1200 steps | score: [-0.13013118505477905]\n",
      "1300 steps | score: [-0.09137136489152908]\n",
      "1400 steps | score: [-0.1165710836648941]\n",
      "1500 steps | score: [-0.10397976636886597]\n",
      "1600 steps | score: [-0.08178625255823135]\n",
      "1700 steps | score: [-0.14745348691940308]\n",
      "1800 steps | score: [-0.1265549659729004]\n",
      "1900 steps | score: [-0.12580545246601105]\n",
      "2000 steps | score: [-0.1195392832159996]\n",
      "2100 steps | score: [-0.11027871072292328]\n",
      "2200 steps | score: [-0.06586135923862457]\n",
      "2300 steps | score: [-0.10859815776348114]\n",
      "2400 steps | score: [-0.13111233711242676]\n",
      "2500 steps | score: [-0.13779589533805847]\n",
      "2600 steps | score: [-0.12622396647930145]\n",
      "2700 steps | score: [-0.10335014015436172]\n",
      "2800 steps | score: [-0.09810631722211838]\n",
      "0 steps | score: [0.08874673396348953, -0.23784203827381134]\n",
      "100 steps | score: [-0.24759411811828613, 0.48993903398513794]\n",
      "200 steps | score: [-0.1439710259437561, 0.1870872527360916]\n",
      "300 steps | score: [-0.13822275400161743, 0.09639766067266464]\n",
      "400 steps | score: [-0.08322536945343018, -0.03874719515442848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [0.03458573669195175, -0.35244742035865784]\n",
      "600 steps | score: [-0.16354155540466309, 0.1785687357187271]\n",
      "700 steps | score: [-0.11069022119045258, 0.05283420532941818]\n",
      "800 steps | score: [-0.012937088496983051, -0.29849156737327576]\n",
      "900 steps | score: [-0.2883121967315674, 0.5768461227416992]\n",
      "1000 steps | score: [-0.11796031892299652, 0.0502110980451107]\n",
      "1100 steps | score: [-0.022436602041125298, -0.22964762151241302]\n",
      "1200 steps | score: [0.008213256485760212, -0.3368026912212372]\n",
      "1300 steps | score: [-0.09249584376811981, -0.0054913051426410675]\n",
      "1400 steps | score: [-0.12245284020900726, 0.07155264168977737]\n",
      "1500 steps | score: [-0.06776180118322372, -0.11247316002845764]\n",
      "1600 steps | score: [0.058300428092479706, -0.5201566815376282]\n",
      "1700 steps | score: [-0.1743181198835373, 0.26980364322662354]\n",
      "1800 steps | score: [-0.01819373294711113, -0.2700968086719513]\n",
      "1900 steps | score: [-0.03761108219623566, -0.2060396522283554]\n",
      "2000 steps | score: [-0.0914965271949768, -0.05112143233418465]\n",
      "2100 steps | score: [0.037854477763175964, -0.462413489818573]\n",
      "2200 steps | score: [0.021559327840805054, -0.3791990578174591]\n",
      "2300 steps | score: [-0.1320250928401947, 0.09197094291448593]\n",
      "2400 steps | score: [-0.055779360234737396, -0.12062302976846695]\n",
      "2500 steps | score: [-0.045778125524520874, -0.17852070927619934]\n",
      "2600 steps | score: [-0.10494353622198105, -0.03365688398480415]\n",
      "2700 steps | score: [-0.05247068032622337, -0.1662926971912384]\n",
      "2800 steps | score: [-0.00574214244261384, -0.3070008456707001]\n",
      "unknown params:  tensor([-0.3889, -0.7968, -0.1109, -0.9101,  0.7193,  0.6309])\n",
      "gt params:  tensor([-0.3964, -0.8282, -0.1062, -0.9486,  0.7560,  0.8574])\n",
      "ols params:  tensor([-0.2996, -0.6075, -0.0879, -0.6894,  0.5510,  2.4020])\n",
      "unknown mse:  tensor(0.0092)\n",
      "ols mse:  tensor(0.4256)\n",
      "gt params:  tensor([-0.4149, -0.8226, -0.0802, -0.9417,  0.7531,  0.8974])\n",
      "0 steps | score: [0.31878769397735596]\n",
      "100 steps | score: [0.19228126108646393]\n",
      "200 steps | score: [0.17648732662200928]\n",
      "300 steps | score: [0.09513796120882034]\n",
      "400 steps | score: [0.11046116054058075]\n",
      "500 steps | score: [0.153123676776886]\n",
      "600 steps | score: [0.09406892210245132]\n",
      "700 steps | score: [0.1557203084230423]\n",
      "800 steps | score: [0.06476671993732452]\n",
      "900 steps | score: [0.10943211615085602]\n",
      "1000 steps | score: [0.15554706752300262]\n",
      "1100 steps | score: [0.12007283419370651]\n",
      "1200 steps | score: [0.08804746717214584]\n",
      "1300 steps | score: [0.15327738225460052]\n",
      "1400 steps | score: [0.06792423874139786]\n",
      "1500 steps | score: [0.14547674357891083]\n",
      "1600 steps | score: [0.15219764411449432]\n",
      "1700 steps | score: [0.07834050804376602]\n",
      "1800 steps | score: [0.09400591254234314]\n",
      "1900 steps | score: [0.13259972631931305]\n",
      "2000 steps | score: [0.09253157675266266]\n",
      "2100 steps | score: [0.09851568937301636]\n",
      "2200 steps | score: [0.13719971477985382]\n",
      "2300 steps | score: [0.0923590138554573]\n",
      "2400 steps | score: [0.14346736669540405]\n",
      "2500 steps | score: [0.11588442325592041]\n",
      "2600 steps | score: [0.09206624329090118]\n",
      "2700 steps | score: [0.1221231147646904]\n",
      "2800 steps | score: [0.11210357397794724]\n",
      "0 steps | score: [0.24050113558769226, -0.11944518238306046]\n",
      "100 steps | score: [0.45154234766960144, -0.9348387122154236]\n",
      "200 steps | score: [0.060799628496170044, 0.06462305039167404]\n",
      "300 steps | score: [-0.030848175287246704, 0.2898159325122833]\n",
      "400 steps | score: [-0.05197862535715103, 0.34200406074523926]\n",
      "500 steps | score: [0.20659314095973969, -0.3569876551628113]\n",
      "600 steps | score: [-0.04785365238785744, 0.3327748775482178]\n",
      "700 steps | score: [0.2539978325366974, -0.4310030937194824]\n",
      "800 steps | score: [-0.06667468696832657, 0.360147088766098]\n",
      "900 steps | score: [0.16301502287387848, -0.21851679682731628]\n",
      "1000 steps | score: [0.13449668884277344, -0.1793278157711029]\n",
      "1100 steps | score: [-0.06216546148061752, 0.3324805200099945]\n",
      "1200 steps | score: [0.12189102172851562, -0.1417447328567505]\n",
      "1300 steps | score: [0.08482473343610764, -0.024927135556936264]\n",
      "1400 steps | score: [-0.043324608355760574, 0.3103276789188385]\n",
      "1500 steps | score: [0.11562339216470718, -0.09773073345422745]\n",
      "1600 steps | score: [0.15529340505599976, -0.18543079495429993]\n",
      "1700 steps | score: [0.04439869523048401, 0.05808062106370926]\n",
      "1800 steps | score: [-0.020547425374388695, 0.23526696860790253]\n",
      "1900 steps | score: [0.15751004219055176, -0.2564149796962738]\n",
      "2000 steps | score: [0.10424838960170746, -0.08715606480836868]\n",
      "2100 steps | score: [0.0069765569642186165, 0.19316786527633667]\n",
      "2200 steps | score: [0.11677678674459457, -0.11451946198940277]\n",
      "2300 steps | score: [0.0010534373577684164, 0.1792779117822647]\n",
      "2400 steps | score: [0.17457722127437592, -0.29738879203796387]\n",
      "2500 steps | score: [0.006966468878090382, 0.16421395540237427]\n",
      "2600 steps | score: [0.0823565274477005, -0.02022843435406685]\n",
      "2700 steps | score: [0.08682691305875778, -0.050322629511356354]\n",
      "2800 steps | score: [-0.007302305195480585, 0.21749091148376465]\n",
      "unknown params:  tensor([-0.4018, -0.8150, -0.0766, -0.9357,  0.7314,  0.7122])\n",
      "gt params:  tensor([-0.4149, -0.8226, -0.0802, -0.9417,  0.7531,  0.8974])\n",
      "ols params:  tensor([-0.2897, -0.5764, -0.0578, -0.6566,  0.5218,  2.6275])\n",
      "unknown mse:  tensor(0.0058)\n",
      "ols mse:  tensor(0.5342)\n",
      "gt params:  tensor([-0.4030, -0.8245, -0.0905, -0.9577,  0.7608,  0.9125])\n",
      "0 steps | score: [0.1916199028491974]\n",
      "100 steps | score: [0.03354885056614876]\n",
      "200 steps | score: [0.004735926166176796]\n",
      "0 steps | score: [0.4073638319969177, -0.5672715902328491]\n",
      "100 steps | score: [0.22336415946483612, -0.3212985098361969]\n",
      "200 steps | score: [0.39141297340393066, -0.9379287958145142]\n",
      "300 steps | score: [0.3073333501815796, -0.6854569315910339]\n",
      "400 steps | score: [-0.1352042555809021, 0.5620938539505005]\n",
      "500 steps | score: [0.36786872148513794, -0.936923086643219]\n",
      "600 steps | score: [0.35627415776252747, -0.850485622882843]\n",
      "700 steps | score: [0.2312902957201004, -0.5352290868759155]\n",
      "800 steps | score: [0.3047618269920349, -0.7369653582572937]\n",
      "900 steps | score: [0.406553715467453, -1.1100579500198364]\n",
      "1000 steps | score: [0.2336917221546173, -0.48079714179039]\n",
      "1100 steps | score: [0.3605455458164215, -0.8890389204025269]\n",
      "1200 steps | score: [0.22436609864234924, -0.41968974471092224]\n",
      "1300 steps | score: [0.2794357240200043, -0.6233043670654297]\n",
      "1400 steps | score: [0.1941862255334854, -0.36482298374176025]\n",
      "1500 steps | score: [0.15251794457435608, -0.2750132381916046]\n",
      "1600 steps | score: [0.3171273469924927, -0.770958423614502]\n",
      "1700 steps | score: [0.22044844925403595, -0.4709448218345642]\n",
      "1800 steps | score: [0.3641650676727295, -0.9101979732513428]\n",
      "1900 steps | score: [0.3238941729068756, -0.8393522500991821]\n",
      "2000 steps | score: [0.32950904965400696, -0.8439250588417053]\n",
      "2100 steps | score: [0.33450525999069214, -0.8078139424324036]\n",
      "2200 steps | score: [0.25562208890914917, -0.5625542402267456]\n",
      "2300 steps | score: [0.2631846070289612, -0.5842572450637817]\n",
      "2400 steps | score: [0.2934190630912781, -0.6728506684303284]\n",
      "2500 steps | score: [0.2799208462238312, -0.687345027923584]\n",
      "2600 steps | score: [0.22191479802131653, -0.48148179054260254]\n",
      "2700 steps | score: [0.26177841424942017, -0.5728644132614136]\n",
      "2800 steps | score: [0.33992287516593933, -0.8829929232597351]\n",
      "unknown params:  tensor([-0.4070, -0.8362, -0.0881, -0.9487,  0.7565,  0.6575])\n",
      "gt params:  tensor([-0.4030, -0.8245, -0.0905, -0.9577,  0.7608,  0.9125])\n",
      "ols params:  tensor([-0.2861, -0.5804, -0.0643, -0.6552,  0.5283,  2.7284])\n",
      "unknown mse:  tensor(0.0109)\n",
      "ols mse:  tensor(0.5861)\n",
      "gt params:  tensor([-0.4040, -0.8315, -0.0869, -0.9633,  0.7762,  0.9200])\n",
      "0 steps | score: [0.13495966792106628]\n",
      "100 steps | score: [-0.13030758500099182]\n",
      "200 steps | score: [-0.026980586349964142]\n",
      "300 steps | score: [0.0607324056327343]\n",
      "400 steps | score: [-0.0254713986068964]\n",
      "500 steps | score: [-0.06566018611192703]\n",
      "600 steps | score: [-0.040904343128204346]\n",
      "700 steps | score: [-0.13385705649852753]\n",
      "800 steps | score: [-0.009550145827233791]\n",
      "0 steps | score: [0.14077173173427582, 0.091156005859375]\n",
      "100 steps | score: [-0.2796812951564789, 0.9063060879707336]\n",
      "200 steps | score: [0.24519814550876617, -0.585938036441803]\n",
      "300 steps | score: [0.23069129884243011, -0.5447348356246948]\n",
      "400 steps | score: [0.02782290242612362, 0.09706491976976395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [-0.015847552567720413, 0.18597973883152008]\n",
      "600 steps | score: [-0.20309600234031677, 0.6491830348968506]\n",
      "700 steps | score: [-0.10475809127092361, 0.43550190329551697]\n",
      "800 steps | score: [0.16136132180690765, -0.32610708475112915]\n",
      "900 steps | score: [-0.01233298797160387, 0.1689639836549759]\n",
      "1000 steps | score: [-0.06449812650680542, 0.33471986651420593]\n",
      "1100 steps | score: [0.05087881535291672, -0.05044908449053764]\n",
      "1200 steps | score: [-0.16487038135528564, 0.5527417659759521]\n",
      "1300 steps | score: [-0.013167820870876312, 0.15493689477443695]\n",
      "1400 steps | score: [0.0033762892708182335, 0.1291295439004898]\n",
      "1500 steps | score: [0.06617294996976852, -0.0841446965932846]\n",
      "1600 steps | score: [0.015895381569862366, 0.06233541667461395]\n",
      "1700 steps | score: [0.09269063174724579, -0.16113591194152832]\n",
      "1800 steps | score: [-0.19154000282287598, 0.6296103000640869]\n",
      "1900 steps | score: [-0.06587100028991699, 0.31735795736312866]\n",
      "2000 steps | score: [-0.018796253949403763, 0.17637304961681366]\n",
      "2100 steps | score: [0.03001120500266552, 0.0059420205652713776]\n",
      "2200 steps | score: [-0.06867066770792007, 0.31315019726753235]\n",
      "2300 steps | score: [-0.04781618341803551, 0.276695191860199]\n",
      "2400 steps | score: [-0.11923196166753769, 0.4116981625556946]\n",
      "2500 steps | score: [0.01191913802176714, 0.07355302572250366]\n",
      "2600 steps | score: [-0.06331381946802139, 0.27104997634887695]\n",
      "2700 steps | score: [-0.02094319462776184, 0.16617688536643982]\n",
      "2800 steps | score: [-0.013817579485476017, 0.12609679996967316]\n",
      "unknown params:  tensor([-0.4162, -0.8359, -0.0923, -0.9783,  0.7785,  0.6544])\n",
      "gt params:  tensor([-0.4040, -0.8315, -0.0869, -0.9633,  0.7762,  0.9200])\n",
      "ols params:  tensor([-0.2816, -0.5536, -0.0656, -0.6436,  0.5195,  2.9037])\n",
      "unknown mse:  tensor(0.0118)\n",
      "ols mse:  tensor(0.6993)\n",
      "gt params:  tensor([-0.4298, -0.8311, -0.1054, -0.9475,  0.7459,  0.8866])\n",
      "0 steps | score: [0.024247270077466965]\n",
      "100 steps | score: [-0.17087791860103607]\n",
      "200 steps | score: [-0.20290377736091614]\n",
      "300 steps | score: [-0.20774351060390472]\n",
      "400 steps | score: [-0.1984989047050476]\n",
      "500 steps | score: [-0.16113144159317017]\n",
      "600 steps | score: [-0.1442175805568695]\n",
      "700 steps | score: [-0.1785275638103485]\n",
      "800 steps | score: [-0.12161224335432053]\n",
      "900 steps | score: [-0.1597103774547577]\n",
      "1000 steps | score: [-0.17615023255348206]\n",
      "1100 steps | score: [-0.143880695104599]\n",
      "1200 steps | score: [-0.10352039337158203]\n",
      "1300 steps | score: [-0.17339518666267395]\n",
      "1400 steps | score: [-0.14862602949142456]\n",
      "1500 steps | score: [-0.11690230667591095]\n",
      "1600 steps | score: [-0.15538425743579865]\n",
      "1700 steps | score: [-0.13481780886650085]\n",
      "1800 steps | score: [-0.17291578650474548]\n",
      "1900 steps | score: [-0.15503044426441193]\n",
      "2000 steps | score: [-0.14649540185928345]\n",
      "2100 steps | score: [-0.18955092132091522]\n",
      "2200 steps | score: [-0.1604887992143631]\n",
      "2300 steps | score: [-0.14375045895576477]\n",
      "2400 steps | score: [-0.147367924451828]\n",
      "2500 steps | score: [-0.13928139209747314]\n",
      "2600 steps | score: [-0.13896490633487701]\n",
      "2700 steps | score: [-0.14245493710041046]\n",
      "2800 steps | score: [-0.1438099443912506]\n",
      "0 steps | score: [0.2666921019554138, -0.3116393983364105]\n",
      "100 steps | score: [0.006367733236402273, 0.08931007981300354]\n",
      "200 steps | score: [0.13746540248394012, -0.24546605348587036]\n",
      "300 steps | score: [0.039475973695516586, -0.020121604204177856]\n",
      "400 steps | score: [0.0489015206694603, -0.01952412724494934]\n",
      "500 steps | score: [0.16743570566177368, -0.3470471203327179]\n",
      "600 steps | score: [0.37271180748939514, -0.9353365898132324]\n",
      "700 steps | score: [0.04613788053393364, -0.05863712355494499]\n",
      "800 steps | score: [0.2153254896402359, -0.5085197687149048]\n",
      "900 steps | score: [0.04777424409985542, -0.031221196055412292]\n",
      "1000 steps | score: [0.049613505601882935, -0.054942335933446884]\n",
      "1100 steps | score: [0.05640243738889694, -0.046908117830753326]\n",
      "1200 steps | score: [0.24514152109622955, -0.5626542568206787]\n",
      "1300 steps | score: [0.06390295922756195, -0.08082812279462814]\n",
      "1400 steps | score: [0.16208240389823914, -0.3569476008415222]\n",
      "1500 steps | score: [0.1919526755809784, -0.45163068175315857]\n",
      "1600 steps | score: [0.051061827689409256, -0.040144823491573334]\n",
      "1700 steps | score: [0.16965502500534058, -0.34884199500083923]\n",
      "1800 steps | score: [0.04039992764592171, -0.06984603404998779]\n",
      "1900 steps | score: [0.1353486031293869, -0.2737538814544678]\n",
      "2000 steps | score: [0.18048731982707977, -0.3761863112449646]\n",
      "2100 steps | score: [0.13404923677444458, -0.2517891824245453]\n",
      "2200 steps | score: [0.19374118745326996, -0.46329158544540405]\n",
      "2300 steps | score: [0.1476832628250122, -0.34224238991737366]\n",
      "2400 steps | score: [0.08833028376102448, -0.13771019876003265]\n",
      "2500 steps | score: [0.09093313664197922, -0.16872504353523254]\n",
      "2600 steps | score: [0.10056868195533752, -0.19777870178222656]\n",
      "2700 steps | score: [0.15468908846378326, -0.32277995347976685]\n",
      "2800 steps | score: [0.197405144572258, -0.3902430236339569]\n",
      "unknown params:  tensor([-0.3961, -0.7988, -0.1016, -0.8936,  0.7181,  0.7506])\n",
      "gt params:  tensor([-0.4298, -0.8311, -0.1054, -0.9475,  0.7459,  0.8866])\n",
      "ols params:  tensor([-0.2724, -0.5342, -0.0726, -0.5972,  0.4845,  3.0816])\n",
      "unknown mse:  tensor(0.0041)\n",
      "ols mse:  tensor(0.8539)\n",
      "gt params:  tensor([-0.4069, -0.8341, -0.0961, -0.9732,  0.7406,  0.9201])\n",
      "0 steps | score: [0.10884127765893936]\n",
      "100 steps | score: [-0.11148736625909805]\n",
      "200 steps | score: [-0.05624382197856903]\n",
      "300 steps | score: [-0.0767798200249672]\n",
      "400 steps | score: [-0.10405483096837997]\n",
      "500 steps | score: [-0.09491997212171555]\n",
      "600 steps | score: [-0.1610637903213501]\n",
      "700 steps | score: [-0.09836025536060333]\n",
      "800 steps | score: [-0.120372474193573]\n",
      "900 steps | score: [-0.13887685537338257]\n",
      "1000 steps | score: [-0.1252780556678772]\n",
      "1100 steps | score: [-0.16219677031040192]\n",
      "1200 steps | score: [-0.14054585993289948]\n",
      "1300 steps | score: [-0.14337772130966187]\n",
      "1400 steps | score: [-0.11884516477584839]\n",
      "1500 steps | score: [-0.11465352028608322]\n",
      "1600 steps | score: [-0.1444983333349228]\n",
      "1700 steps | score: [-0.13893702626228333]\n",
      "1800 steps | score: [-0.15235257148742676]\n",
      "1900 steps | score: [-0.158754363656044]\n",
      "2000 steps | score: [-0.13752958178520203]\n",
      "2100 steps | score: [-0.10862661153078079]\n",
      "2200 steps | score: [-0.15489862859249115]\n",
      "2300 steps | score: [-0.1300903707742691]\n",
      "2400 steps | score: [-0.1392880082130432]\n",
      "2500 steps | score: [-0.1318032145500183]\n",
      "2600 steps | score: [-0.11892584711313248]\n",
      "2700 steps | score: [-0.13800354301929474]\n",
      "2800 steps | score: [-0.12976746261119843]\n",
      "0 steps | score: [0.07450550049543381, 0.30556267499923706]\n",
      "100 steps | score: [0.14042091369628906, -0.05348975211381912]\n",
      "200 steps | score: [-0.28726354241371155, 0.9118338823318481]\n",
      "300 steps | score: [0.06252636760473251, 0.01688506081700325]\n",
      "400 steps | score: [-0.19805380702018738, 0.6517711877822876]\n",
      "500 steps | score: [0.42549243569374084, -1.093147873878479]\n",
      "600 steps | score: [0.009856395423412323, 0.1550445556640625]\n",
      "700 steps | score: [-0.01815422996878624, 0.25419318675994873]\n",
      "800 steps | score: [-0.05003272742033005, 0.2818332612514496]\n",
      "900 steps | score: [-0.12804071605205536, 0.48383134603500366]\n",
      "1000 steps | score: [-0.2186482548713684, 0.7155304551124573]\n",
      "1100 steps | score: [-0.07210977375507355, 0.3288240134716034]\n",
      "1200 steps | score: [-0.10639183223247528, 0.41211429238319397]\n",
      "1300 steps | score: [-0.11465451121330261, 0.46519044041633606]\n",
      "1400 steps | score: [-0.019939469173550606, 0.21429643034934998]\n",
      "1500 steps | score: [-0.20846246182918549, 0.6829396486282349]\n",
      "1600 steps | score: [-0.11352171748876572, 0.4532920718193054]\n",
      "1700 steps | score: [-0.09384375810623169, 0.44362497329711914]\n",
      "1800 steps | score: [0.002103712409734726, 0.18973536789417267]\n",
      "1900 steps | score: [-0.16256976127624512, 0.5611624717712402]\n",
      "2000 steps | score: [-0.10722093284130096, 0.46264082193374634]\n",
      "2100 steps | score: [-0.07158834487199783, 0.3280264437198639]\n",
      "2200 steps | score: [-0.1060798242688179, 0.4468995928764343]\n",
      "2300 steps | score: [-0.09749852120876312, 0.44199270009994507]\n",
      "2400 steps | score: [-0.06705866008996964, 0.342538982629776]\n",
      "2500 steps | score: [-0.04140063375234604, 0.2798433303833008]\n",
      "2600 steps | score: [-0.019102875143289566, 0.19206637144088745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 steps | score: [-0.1661885678768158, 0.5547524690628052]\n",
      "2800 steps | score: [-0.08779115974903107, 0.3915184438228607]\n",
      "unknown params:  tensor([-0.4072, -0.8482, -0.1013, -0.9794,  0.7278,  0.6120])\n",
      "gt params:  tensor([-0.4069, -0.8341, -0.0961, -0.9732,  0.7406,  0.9201])\n",
      "ols params:  tensor([-0.2666, -0.5438, -0.0662, -0.6190,  0.4687,  3.1603])\n",
      "unknown mse:  tensor(0.0159)\n",
      "ols mse:  tensor(0.8871)\n",
      "gt params:  tensor([-0.4178, -0.8434, -0.0963, -0.9390,  0.7407,  0.9352])\n",
      "0 steps | score: [0.29554617404937744]\n",
      "100 steps | score: [0.00091595109552145]\n",
      "0 steps | score: [0.057444311678409576, -0.09539170563220978]\n",
      "100 steps | score: [-0.1255987584590912, 0.15384288132190704]\n",
      "200 steps | score: [0.6535758376121521, -2.4763708114624023]\n",
      "300 steps | score: [-0.18046395480632782, 0.1917533576488495]\n",
      "400 steps | score: [0.36463573575019836, -1.4668138027191162]\n",
      "500 steps | score: [-0.22300109267234802, 0.25592881441116333]\n",
      "600 steps | score: [0.004009093623608351, -0.2861955463886261]\n",
      "700 steps | score: [-0.20353540778160095, 0.24740459024906158]\n",
      "800 steps | score: [-0.26660022139549255, 0.4140699505805969]\n",
      "900 steps | score: [-0.1638958752155304, 0.13647723197937012]\n",
      "1000 steps | score: [-0.12112769484519958, -0.010706864297389984]\n",
      "1100 steps | score: [0.24001827836036682, -1.051904320716858]\n",
      "1200 steps | score: [-0.16074618697166443, 0.1597582995891571]\n",
      "1300 steps | score: [-0.11077220737934113, 0.019394174218177795]\n",
      "1400 steps | score: [-0.0664483904838562, -0.14671315252780914]\n",
      "1500 steps | score: [0.10509045422077179, -0.6462133526802063]\n",
      "1600 steps | score: [0.012529155239462852, -0.41586625576019287]\n",
      "1700 steps | score: [-0.04647403582930565, -0.21081285178661346]\n",
      "1800 steps | score: [-0.07050058245658875, -0.10309669375419617]\n",
      "1900 steps | score: [-0.017789939418435097, -0.2817448675632477]\n",
      "2000 steps | score: [0.024369195103645325, -0.4059865176677704]\n",
      "2100 steps | score: [-0.000180426228325814, -0.3174663186073303]\n",
      "2200 steps | score: [-0.12312153726816177, 0.012662425637245178]\n",
      "2300 steps | score: [-0.03430158644914627, -0.224783793091774]\n",
      "2400 steps | score: [0.04942284896969795, -0.46063345670700073]\n",
      "2500 steps | score: [-0.021152105182409286, -0.2543136477470398]\n",
      "2600 steps | score: [-0.17579051852226257, 0.13826172053813934]\n",
      "2700 steps | score: [-0.07290048897266388, -0.09965598583221436]\n",
      "2800 steps | score: [0.018403157591819763, -0.37518513202667236]\n",
      "unknown params:  tensor([-0.4897, -0.9060, -0.0720, -0.9629,  0.7880,  0.5551])\n",
      "gt params:  tensor([-0.4178, -0.8434, -0.0963, -0.9390,  0.7407,  0.9352])\n",
      "ols params:  tensor([-0.2943, -0.5340, -0.0484, -0.5737,  0.4743,  3.2812])\n",
      "unknown mse:  tensor(0.0262)\n",
      "ols mse:  tensor(0.9702)\n",
      "gt params:  tensor([-0.4245, -0.8170, -0.0966, -0.9515,  0.7627,  0.9039])\n",
      "0 steps | score: [0.2057190090417862]\n",
      "100 steps | score: [-0.017859699204564095]\n",
      "200 steps | score: [-0.042525582015514374]\n",
      "300 steps | score: [0.034072186797857285]\n",
      "400 steps | score: [0.018161015585064888]\n",
      "500 steps | score: [-0.07275331765413284]\n",
      "600 steps | score: [-0.014497239142656326]\n",
      "700 steps | score: [-0.012589948251843452]\n",
      "800 steps | score: [-0.024044375866651535]\n",
      "900 steps | score: [0.012089848518371582]\n",
      "1000 steps | score: [0.009180133230984211]\n",
      "0 steps | score: [-0.18411941826343536, 0.7914433479309082]\n",
      "100 steps | score: [-0.4850228428840637, 1.2828853130340576]\n",
      "200 steps | score: [-0.5021287798881531, 1.284059762954712]\n",
      "300 steps | score: [-0.15944500267505646, 0.43150320649147034]\n",
      "400 steps | score: [-0.3393620252609253, 0.8972191214561462]\n",
      "500 steps | score: [-0.4853460192680359, 1.218869924545288]\n",
      "600 steps | score: [-0.3137029707431793, 0.7958249449729919]\n",
      "700 steps | score: [-0.45977431535720825, 1.1457946300506592]\n",
      "800 steps | score: [-0.49391648173332214, 1.2115426063537598]\n",
      "900 steps | score: [-0.3359624743461609, 0.8771443963050842]\n",
      "1000 steps | score: [-0.14863091707229614, 0.3746010959148407]\n",
      "1100 steps | score: [-0.253500372171402, 0.666560709476471]\n",
      "1200 steps | score: [-0.4558228850364685, 1.1380388736724854]\n",
      "1300 steps | score: [-0.38841712474823, 0.9602400660514832]\n",
      "1400 steps | score: [-0.3295745551586151, 0.8296916484832764]\n",
      "1500 steps | score: [-0.44021257758140564, 1.085384488105774]\n",
      "1600 steps | score: [-0.48111531138420105, 1.1977143287658691]\n",
      "1700 steps | score: [-0.48338404297828674, 1.1785032749176025]\n",
      "1800 steps | score: [-0.419054239988327, 1.0027228593826294]\n",
      "1900 steps | score: [-0.3378145396709442, 0.8683479428291321]\n",
      "2000 steps | score: [-0.39846041798591614, 0.9870761632919312]\n",
      "2100 steps | score: [-0.4325675070285797, 1.096398949623108]\n",
      "2200 steps | score: [-0.48391324281692505, 1.2003710269927979]\n",
      "2300 steps | score: [-0.3800385594367981, 0.9561477303504944]\n",
      "2400 steps | score: [-0.3987896740436554, 0.9806292057037354]\n",
      "2500 steps | score: [-0.4331132769584656, 1.0728461742401123]\n",
      "2600 steps | score: [-0.3904222548007965, 0.9683401584625244]\n",
      "2700 steps | score: [-0.3328354060649872, 0.8532403707504272]\n",
      "2800 steps | score: [-0.4064919948577881, 1.0380960702896118]\n",
      "unknown params:  tensor([-0.4196, -0.8210, -0.1092, -1.0178,  0.7761,  0.5271])\n",
      "gt params:  tensor([-0.4245, -0.8170, -0.0966, -0.9515,  0.7627,  0.9039])\n",
      "ols params:  tensor([-0.2578, -0.4923, -0.0693, -0.5999,  0.4671,  3.4216])\n",
      "unknown mse:  tensor(0.0245)\n",
      "ols mse:  tensor(1.1140)\n",
      "gt params:  tensor([-0.4271, -0.8225, -0.1018, -0.9340,  0.7447,  0.7915])\n",
      "0 steps | score: [0.07469019293785095]\n",
      "100 steps | score: [-0.16406013071537018]\n",
      "200 steps | score: [-0.057811081409454346]\n",
      "300 steps | score: [-0.19291403889656067]\n",
      "400 steps | score: [-0.2262153923511505]\n",
      "500 steps | score: [-0.17753733694553375]\n",
      "600 steps | score: [-0.15795472264289856]\n",
      "700 steps | score: [-0.13834352791309357]\n",
      "800 steps | score: [-0.14044660329818726]\n",
      "900 steps | score: [-0.19293104112148285]\n",
      "1000 steps | score: [-0.20866167545318604]\n",
      "1100 steps | score: [-0.16291433572769165]\n",
      "1200 steps | score: [-0.18465732038021088]\n",
      "1300 steps | score: [-0.12997391819953918]\n",
      "1400 steps | score: [-0.16642983257770538]\n",
      "1500 steps | score: [-0.19040101766586304]\n",
      "1600 steps | score: [-0.19216518104076385]\n",
      "1700 steps | score: [-0.16641342639923096]\n",
      "1800 steps | score: [-0.17231683433055878]\n",
      "1900 steps | score: [-0.1311739683151245]\n",
      "2000 steps | score: [-0.15157455205917358]\n",
      "2100 steps | score: [-0.17450390756130219]\n",
      "2200 steps | score: [-0.15908128023147583]\n",
      "2300 steps | score: [-0.15794989466667175]\n",
      "2400 steps | score: [-0.14833299815654755]\n",
      "2500 steps | score: [-0.15463776886463165]\n",
      "2600 steps | score: [-0.16701312363147736]\n",
      "2700 steps | score: [-0.1809152513742447]\n",
      "0 steps | score: [0.09395770728588104, 0.20019634068012238]\n",
      "100 steps | score: [-0.03811943903565407, 0.3356010913848877]\n",
      "200 steps | score: [0.2505932152271271, -0.5374678373336792]\n",
      "300 steps | score: [-0.17891645431518555, 0.5552982687950134]\n",
      "400 steps | score: [-0.41376233100891113, 1.087924599647522]\n",
      "500 steps | score: [-0.12620095908641815, 0.45181870460510254]\n",
      "600 steps | score: [-0.21624237298965454, 0.6955026388168335]\n",
      "700 steps | score: [0.15248778462409973, -0.3105497360229492]\n",
      "800 steps | score: [-0.10420425981283188, 0.4120433032512665]\n",
      "900 steps | score: [-0.06464218348264694, 0.2854154407978058]\n",
      "1000 steps | score: [-0.061366934329271317, 0.288064569234848]\n",
      "1100 steps | score: [-0.11750093102455139, 0.3582231402397156]\n",
      "1200 steps | score: [-0.19481904804706573, 0.6297686696052551]\n",
      "1300 steps | score: [0.0638551115989685, -0.05858689546585083]\n",
      "1400 steps | score: [-0.12932313978672028, 0.4257497787475586]\n",
      "1500 steps | score: [-0.06320571154356003, 0.28801193833351135]\n",
      "1600 steps | score: [-0.05687498301267624, 0.2470693141222]\n",
      "1700 steps | score: [-0.12100573629140854, 0.4149307608604431]\n",
      "1800 steps | score: [0.05711721256375313, -0.03885690122842789]\n",
      "1900 steps | score: [0.0344582237303257, 0.012139976024627686]\n",
      "2000 steps | score: [-0.1148514449596405, 0.40446120500564575]\n",
      "2100 steps | score: [-0.1398443579673767, 0.4778350293636322]\n",
      "2200 steps | score: [-0.0910712331533432, 0.3456253409385681]\n",
      "2300 steps | score: [-0.10874252766370773, 0.37039387226104736]\n",
      "2400 steps | score: [-0.050219595432281494, 0.23583409190177917]\n",
      "2500 steps | score: [-0.11071838438510895, 0.40037617087364197]\n",
      "2600 steps | score: [-0.12361356616020203, 0.41994673013687134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 steps | score: [-0.04614763706922531, 0.22293701767921448]\n",
      "unknown params:  tensor([-0.4371, -0.8139, -0.1101, -0.9164,  0.7251,  0.5759])\n",
      "gt params:  tensor([-0.4271, -0.8225, -0.1018, -0.9340,  0.7447,  0.7915])\n",
      "ols params:  tensor([-0.2672, -0.4896, -0.0702, -0.5463,  0.4354,  3.5046])\n",
      "unknown mse:  tensor(0.0079)\n",
      "ols mse:  tensor(1.2907)\n",
      "gt params:  tensor([-0.3868, -0.8053, -0.0864, -0.9552,  0.7577,  0.8207])\n",
      "0 steps | score: [0.13987357914447784]\n",
      "100 steps | score: [-0.0799541249871254]\n",
      "200 steps | score: [-0.009146845899522305]\n",
      "0 steps | score: [0.1394081711769104, 0.031604014337062836]\n",
      "100 steps | score: [0.029991181567311287, 0.12087605893611908]\n",
      "200 steps | score: [-0.04530024155974388, 0.28694266080856323]\n",
      "300 steps | score: [-0.07359357178211212, 0.34269970655441284]\n",
      "400 steps | score: [0.1560949683189392, -0.3074073791503906]\n",
      "500 steps | score: [-0.0698101744055748, 0.24656623601913452]\n",
      "600 steps | score: [0.09611573815345764, -0.18035933375358582]\n",
      "700 steps | score: [0.1807737797498703, -0.4064146876335144]\n",
      "800 steps | score: [-0.07819636166095734, 0.30861029028892517]\n",
      "900 steps | score: [0.01026146300137043, 0.08173564076423645]\n",
      "1000 steps | score: [-0.04886717349290848, 0.18162789940834045]\n",
      "1100 steps | score: [-0.013396586291491985, 0.090665303170681]\n",
      "1200 steps | score: [-0.04596288502216339, 0.1854291707277298]\n",
      "1300 steps | score: [-9.749587479745969e-05, 0.10364532470703125]\n",
      "1400 steps | score: [-0.13557174801826477, 0.4206933379173279]\n",
      "1500 steps | score: [-0.025127559900283813, 0.16256645321846008]\n",
      "1600 steps | score: [-0.03885596618056297, 0.19461603462696075]\n",
      "1700 steps | score: [0.06596735864877701, -0.0727103054523468]\n",
      "1800 steps | score: [0.0038765824865549803, 0.07962987571954727]\n",
      "1900 steps | score: [-0.01964488811790943, 0.16386914253234863]\n",
      "2000 steps | score: [-0.04025733843445778, 0.17259156703948975]\n",
      "2100 steps | score: [-0.03586214408278465, 0.17429935932159424]\n",
      "2200 steps | score: [-0.03351229429244995, 0.1748652309179306]\n",
      "2300 steps | score: [-0.036016520112752914, 0.1664135754108429]\n",
      "2400 steps | score: [0.08225517719984055, -0.10744042694568634]\n",
      "2500 steps | score: [-0.07489446550607681, 0.26128074526786804]\n",
      "2600 steps | score: [0.04343429207801819, -0.03457850217819214]\n",
      "2700 steps | score: [-0.030782004818320274, 0.16198253631591797]\n",
      "unknown params:  tensor([-0.3798, -0.7980, -0.0869, -0.9722,  0.7698,  0.4879])\n",
      "gt params:  tensor([-0.3868, -0.8053, -0.0864, -0.9552,  0.7577,  0.8207])\n",
      "ols params:  tensor([-0.2327, -0.4756, -0.0535, -0.5667,  0.4581,  3.6351])\n",
      "unknown mse:  tensor(0.0185)\n",
      "ols mse:  tensor(1.3825)\n",
      "gt params:  tensor([-0.3893, -0.8331, -0.0816, -0.9446,  0.7595,  0.8969])\n",
      "0 steps | score: [0.40221554040908813]\n",
      "100 steps | score: [0.08516916632652283]\n",
      "200 steps | score: [0.1757902055978775]\n",
      "300 steps | score: [0.16285856068134308]\n",
      "400 steps | score: [0.13657930493354797]\n",
      "500 steps | score: [0.1811576932668686]\n",
      "600 steps | score: [0.1324497014284134]\n",
      "700 steps | score: [0.13245965540409088]\n",
      "800 steps | score: [0.17477385699748993]\n",
      "900 steps | score: [0.1355949193239212]\n",
      "1000 steps | score: [0.18796293437480927]\n",
      "1100 steps | score: [0.16374030709266663]\n",
      "1200 steps | score: [0.10822048783302307]\n",
      "1300 steps | score: [0.11142387241125107]\n",
      "1400 steps | score: [0.1768416166305542]\n",
      "1500 steps | score: [0.17692478001117706]\n",
      "1600 steps | score: [0.16338104009628296]\n",
      "1700 steps | score: [0.15878769755363464]\n",
      "1800 steps | score: [0.14190928637981415]\n",
      "1900 steps | score: [0.1283443421125412]\n",
      "2000 steps | score: [0.14999449253082275]\n",
      "2100 steps | score: [0.15684308111667633]\n",
      "2200 steps | score: [0.1881747543811798]\n",
      "2300 steps | score: [0.15478411316871643]\n",
      "2400 steps | score: [0.15649330615997314]\n",
      "2500 steps | score: [0.15164268016815186]\n",
      "2600 steps | score: [0.13642755150794983]\n",
      "2700 steps | score: [0.17916004359722137]\n",
      "2800 steps | score: [0.17123445868492126]\n",
      "0 steps | score: [0.2021985799074173, -0.26393938064575195]\n",
      "100 steps | score: [0.05591657757759094, -0.05930815637111664]\n",
      "200 steps | score: [0.12163830548524857, -0.300638347864151]\n",
      "300 steps | score: [-0.03186152130365372, 0.06468413770198822]\n",
      "400 steps | score: [-0.13422919809818268, 0.25470438599586487]\n",
      "500 steps | score: [-0.0273189228028059, 0.004279173910617828]\n",
      "600 steps | score: [-0.04920172691345215, 0.08427271991968155]\n",
      "700 steps | score: [0.07014629244804382, -0.21132299304008484]\n",
      "800 steps | score: [-0.01823514699935913, 0.01016407459974289]\n",
      "900 steps | score: [-0.1022326871752739, 0.18835896253585815]\n",
      "1000 steps | score: [0.08201635628938675, -0.21260736882686615]\n",
      "1100 steps | score: [-0.14848235249519348, 0.27432143688201904]\n",
      "1200 steps | score: [-0.1597803235054016, 0.28334832191467285]\n",
      "1300 steps | score: [0.06845802068710327, -0.20577707886695862]\n",
      "1400 steps | score: [0.07767131924629211, -0.22427748143672943]\n",
      "1500 steps | score: [0.09326671063899994, -0.2736032009124756]\n",
      "1600 steps | score: [0.016012629494071007, -0.10603450238704681]\n",
      "1700 steps | score: [-0.06540645658969879, 0.08872202783823013]\n",
      "1800 steps | score: [0.008215263485908508, -0.08463077247142792]\n",
      "1900 steps | score: [-0.03166517987847328, 0.001867927610874176]\n",
      "2000 steps | score: [-0.050317637622356415, 0.06806115061044693]\n",
      "2100 steps | score: [0.050711628049612045, -0.1559036374092102]\n",
      "2200 steps | score: [0.10705610364675522, -0.31025370955467224]\n",
      "2300 steps | score: [0.028543340042233467, -0.10806070268154144]\n",
      "2400 steps | score: [0.03346934914588928, -0.13774073123931885]\n",
      "2500 steps | score: [0.09937632828950882, -0.27717500925064087]\n",
      "2600 steps | score: [0.008290331810712814, -0.07027973979711533]\n",
      "2700 steps | score: [0.07053501904010773, -0.2098604440689087]\n",
      "2800 steps | score: [0.019775068387389183, -0.08989939838647842]\n",
      "unknown params:  tensor([-0.3830, -0.7832, -0.0787, -0.9132,  0.7594,  0.5725])\n",
      "gt params:  tensor([-0.3893, -0.8331, -0.0816, -0.9446,  0.7595,  0.8969])\n",
      "ols params:  tensor([-0.2309, -0.4603, -0.0496, -0.5276,  0.4449,  3.7239])\n",
      "unknown mse:  tensor(0.0181)\n",
      "ols mse:  tensor(1.4050)\n",
      "gt params:  tensor([-0.4273, -0.8194, -0.1157, -0.9457,  0.7589,  0.8937])\n",
      "0 steps | score: [0.3114597201347351]\n",
      "100 steps | score: [0.09894105046987534]\n",
      "200 steps | score: [0.1867268979549408]\n",
      "300 steps | score: [0.07986397296190262]\n",
      "400 steps | score: [0.1032029464840889]\n",
      "500 steps | score: [0.06212393566966057]\n",
      "600 steps | score: [0.067948117852211]\n",
      "700 steps | score: [0.09604296088218689]\n",
      "800 steps | score: [0.08413545042276382]\n",
      "900 steps | score: [0.09749935567378998]\n",
      "1000 steps | score: [0.06624987721443176]\n",
      "1100 steps | score: [0.04950377717614174]\n",
      "1200 steps | score: [0.07273174822330475]\n",
      "1300 steps | score: [0.11813706159591675]\n",
      "1400 steps | score: [0.12919768691062927]\n",
      "1500 steps | score: [0.11378513276576996]\n",
      "1600 steps | score: [0.07271842658519745]\n",
      "1700 steps | score: [0.05653632432222366]\n",
      "1800 steps | score: [0.08714757859706879]\n",
      "1900 steps | score: [0.09914147853851318]\n",
      "2000 steps | score: [0.07056406885385513]\n",
      "2100 steps | score: [0.08219442516565323]\n",
      "2200 steps | score: [0.1032455712556839]\n",
      "2300 steps | score: [0.07616785913705826]\n",
      "2400 steps | score: [0.1080373004078865]\n",
      "2500 steps | score: [0.06860752403736115]\n",
      "2600 steps | score: [0.10010894387960434]\n",
      "2700 steps | score: [0.09256681799888611]\n",
      "0 steps | score: [0.35072168707847595, -0.5897295475006104]\n",
      "100 steps | score: [0.20496124029159546, -0.4438137412071228]\n",
      "200 steps | score: [0.38192540407180786, -0.8976355791091919]\n",
      "300 steps | score: [0.030517231673002243, -0.09074057638645172]\n",
      "400 steps | score: [0.10075009614229202, -0.2605423629283905]\n",
      "500 steps | score: [0.05455521121621132, -0.159727081656456]\n",
      "600 steps | score: [0.0030439894180744886, -0.06141052395105362]\n",
      "700 steps | score: [0.1780763417482376, -0.43467894196510315]\n",
      "800 steps | score: [0.01205885224044323, -0.06928267329931259]\n",
      "900 steps | score: [0.26948028802871704, -0.7109301090240479]\n",
      "1000 steps | score: [0.06599685549736023, -0.2337436079978943]\n",
      "1100 steps | score: [0.07109256833791733, -0.2374207079410553]\n",
      "1200 steps | score: [0.073227658867836, -0.23643632233142853]\n",
      "1300 steps | score: [0.22392219305038452, -0.5721514225006104]\n",
      "1400 steps | score: [0.24301981925964355, -0.6081107258796692]\n",
      "1500 steps | score: [0.1968829184770584, -0.4992993175983429]\n",
      "1600 steps | score: [0.241324320435524, -0.5989614129066467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 steps | score: [0.289339154958725, -0.7302289009094238]\n",
      "1800 steps | score: [0.15382646024227142, -0.43258047103881836]\n",
      "1900 steps | score: [0.1749047487974167, -0.4287271499633789]\n",
      "2000 steps | score: [0.16322705149650574, -0.4290616810321808]\n",
      "2100 steps | score: [0.14950677752494812, -0.39546871185302734]\n",
      "2200 steps | score: [0.12965261936187744, -0.3542235791683197]\n",
      "2300 steps | score: [0.23881413042545319, -0.6270752549171448]\n",
      "2400 steps | score: [0.3272428512573242, -0.8125666379928589]\n",
      "2500 steps | score: [0.22713595628738403, -0.5938413143157959]\n",
      "2600 steps | score: [0.26642701029777527, -0.6611871123313904]\n",
      "2700 steps | score: [0.1434422731399536, -0.38565561175346375]\n",
      "unknown params:  tensor([-0.4324, -0.7702, -0.1426, -0.9171,  0.6896,  0.6183])\n",
      "gt params:  tensor([-0.4273, -0.8194, -0.1157, -0.9457,  0.7589,  0.8937])\n",
      "ols params:  tensor([-0.2626, -0.4577, -0.0902, -0.5372,  0.4142,  3.8809])\n",
      "unknown mse:  tensor(0.0141)\n",
      "ols mse:  tensor(1.5613)\n",
      "gt params:  tensor([-0.4128, -0.8426, -0.0955, -0.9462,  0.7507,  0.8885])\n",
      "0 steps | score: [0.351925790309906]\n",
      "100 steps | score: [0.07380934059619904]\n",
      "200 steps | score: [0.10758268088102341]\n",
      "300 steps | score: [0.09208601713180542]\n",
      "400 steps | score: [0.16552695631980896]\n",
      "500 steps | score: [0.0864870548248291]\n",
      "600 steps | score: [0.12772265076637268]\n",
      "700 steps | score: [0.10044429451227188]\n",
      "800 steps | score: [0.10208678245544434]\n",
      "900 steps | score: [0.04631888121366501]\n",
      "1000 steps | score: [0.08772403001785278]\n",
      "1100 steps | score: [0.07802000641822815]\n",
      "1200 steps | score: [0.08824390918016434]\n",
      "1300 steps | score: [0.08412341773509979]\n",
      "1400 steps | score: [0.10982927680015564]\n",
      "1500 steps | score: [0.11162825673818588]\n",
      "1600 steps | score: [0.1066519021987915]\n",
      "1700 steps | score: [0.08991774171590805]\n",
      "1800 steps | score: [0.11932842433452606]\n",
      "1900 steps | score: [0.09560550004243851]\n",
      "2000 steps | score: [0.08992686867713928]\n",
      "2100 steps | score: [0.13397693634033203]\n",
      "2200 steps | score: [0.10372696816921234]\n",
      "2300 steps | score: [0.09661366790533066]\n",
      "2400 steps | score: [0.1216992735862732]\n",
      "2500 steps | score: [0.10743115097284317]\n",
      "2600 steps | score: [0.0968410074710846]\n",
      "2700 steps | score: [0.10162977874279022]\n",
      "0 steps | score: [0.18132776021957397, -0.2551976442337036]\n",
      "100 steps | score: [0.10809541493654251, -0.2724785804748535]\n",
      "200 steps | score: [-0.07100297510623932, 0.116584911942482]\n",
      "300 steps | score: [-0.022964520379900932, -0.06854808330535889]\n",
      "400 steps | score: [0.2890946865081787, -0.8104727268218994]\n",
      "500 steps | score: [0.12702493369579315, -0.4011300206184387]\n",
      "600 steps | score: [-0.0631314292550087, 0.03510555624961853]\n",
      "700 steps | score: [-0.03074587695300579, -0.026263922452926636]\n",
      "800 steps | score: [-0.01790641061961651, -0.08203789591789246]\n",
      "900 steps | score: [-0.01850133016705513, -0.05703270435333252]\n",
      "1000 steps | score: [-0.1652231365442276, 0.2527967095375061]\n",
      "1100 steps | score: [-0.1259739100933075, 0.17209020256996155]\n",
      "1200 steps | score: [-0.06464283168315887, 0.04303082823753357]\n",
      "1300 steps | score: [0.08208926767110825, -0.32145553827285767]\n",
      "1400 steps | score: [-0.11343666166067123, 0.13134798407554626]\n",
      "1500 steps | score: [0.023727528750896454, -0.17210467159748077]\n",
      "1600 steps | score: [0.04449276998639107, -0.2511388957500458]\n",
      "1700 steps | score: [0.09952282905578613, -0.3488526940345764]\n",
      "1800 steps | score: [0.05463714525103569, -0.23958496749401093]\n",
      "1900 steps | score: [0.036638423800468445, -0.21180668473243713]\n",
      "2000 steps | score: [-0.13636983931064606, 0.20006656646728516]\n",
      "2100 steps | score: [-8.51760123623535e-05, -0.1253829002380371]\n",
      "2200 steps | score: [-0.011057875119149685, -0.08241111040115356]\n",
      "2300 steps | score: [-0.055651742964982986, 0.029509440064430237]\n",
      "2400 steps | score: [-0.015746213495731354, -0.09638167917728424]\n",
      "2500 steps | score: [-0.020331164821982384, -0.06706967949867249]\n",
      "2600 steps | score: [-0.03650134056806564, -0.04567998647689819]\n",
      "2700 steps | score: [-0.003445463255047798, -0.10453523695468903]\n",
      "unknown params:  tensor([-0.3953, -0.8241, -0.1045, -0.9238,  0.7515,  0.4085])\n",
      "gt params:  tensor([-0.4128, -0.8426, -0.0955, -0.9462,  0.7507,  0.8885])\n",
      "ols params:  tensor([-0.2325, -0.4681, -0.0640, -0.5206,  0.4324,  3.9644])\n",
      "unknown mse:  tensor(0.0386)\n",
      "ols mse:  tensor(1.6529)\n",
      "gt params:  tensor([-0.4118, -0.8207, -0.0751, -0.9459,  0.7427,  0.7913])\n",
      "0 steps | score: [0.20808377861976624]\n",
      "100 steps | score: [-0.0006884410977363586]\n",
      "0 steps | score: [0.33508944511413574, -0.5548365116119385]\n",
      "100 steps | score: [0.22664198279380798, -0.5054526925086975]\n",
      "200 steps | score: [0.08963519334793091, -0.21745967864990234]\n",
      "300 steps | score: [0.19412516057491302, -0.48729801177978516]\n",
      "400 steps | score: [0.19953034818172455, -0.531440258026123]\n",
      "500 steps | score: [0.23694267868995667, -0.613150417804718]\n",
      "600 steps | score: [0.31527644395828247, -0.8235185742378235]\n",
      "700 steps | score: [0.15146346390247345, -0.4073147773742676]\n",
      "800 steps | score: [0.29735520482063293, -0.8080722689628601]\n",
      "900 steps | score: [0.09362635016441345, -0.2521441876888275]\n",
      "1000 steps | score: [0.046492695808410645, -0.1689406931400299]\n",
      "1100 steps | score: [0.19938145577907562, -0.5401284098625183]\n",
      "1200 steps | score: [0.3490397334098816, -0.9708021879196167]\n",
      "1300 steps | score: [0.22928687930107117, -0.6098042130470276]\n",
      "1400 steps | score: [0.3535059690475464, -0.9074922800064087]\n",
      "1500 steps | score: [0.3254416584968567, -0.8822638988494873]\n",
      "1600 steps | score: [0.12480231374502182, -0.33975327014923096]\n",
      "1700 steps | score: [0.33415257930755615, -0.9048430919647217]\n",
      "1800 steps | score: [0.26709043979644775, -0.7709310054779053]\n",
      "1900 steps | score: [0.2367323786020279, -0.6447634100914001]\n",
      "2000 steps | score: [0.08068391680717468, -0.2593870460987091]\n",
      "2100 steps | score: [0.13556258380413055, -0.38896527886390686]\n",
      "2200 steps | score: [0.18071787059307098, -0.49016037583351135]\n",
      "2300 steps | score: [0.2064359039068222, -0.5551202893257141]\n",
      "2400 steps | score: [0.12215466797351837, -0.3742039203643799]\n",
      "2500 steps | score: [0.30178189277648926, -0.8179953694343567]\n",
      "2600 steps | score: [0.18809546530246735, -0.5366218686103821]\n",
      "2700 steps | score: [0.1569463014602661, -0.46981194615364075]\n",
      "unknown params:  tensor([-0.3735, -0.8274, -0.1248, -0.9721,  0.7758,  0.4168])\n",
      "gt params:  tensor([-0.4118, -0.8207, -0.0751, -0.9459,  0.7427,  0.7913])\n",
      "ols params:  tensor([-0.2145, -0.4538, -0.0735, -0.5334,  0.4285,  3.9687])\n",
      "unknown mse:  tensor(0.0243)\n",
      "ols mse:  tensor(1.7563)\n",
      "gt params:  tensor([-0.4078, -0.8579, -0.1023, -0.9540,  0.7659,  0.9620])\n",
      "0 steps | score: [0.2705882787704468]\n",
      "100 steps | score: [0.05504699796438217]\n",
      "200 steps | score: [0.01716785877943039]\n",
      "300 steps | score: [-0.059891555458307266]\n",
      "400 steps | score: [-0.059642642736434937]\n",
      "500 steps | score: [0.0112350694835186]\n",
      "600 steps | score: [0.03854849934577942]\n",
      "700 steps | score: [0.035890623927116394]\n",
      "800 steps | score: [0.0014070160686969757]\n",
      "0 steps | score: [0.40668490529060364, -0.5940829515457153]\n",
      "100 steps | score: [0.4344637393951416, -0.8308183550834656]\n",
      "200 steps | score: [0.42070895433425903, -0.8751720190048218]\n",
      "300 steps | score: [0.25317898392677307, -0.45555999875068665]\n",
      "400 steps | score: [0.28806111216545105, -0.6151691675186157]\n",
      "500 steps | score: [0.17246685922145844, -0.30224186182022095]\n",
      "600 steps | score: [0.30651578307151794, -0.6242825984954834]\n",
      "700 steps | score: [0.20516552031040192, -0.417160302400589]\n",
      "800 steps | score: [0.14928217232227325, -0.27857786417007446]\n",
      "900 steps | score: [0.2324225753545761, -0.5011050701141357]\n",
      "1000 steps | score: [0.27525201439857483, -0.5548877120018005]\n",
      "1100 steps | score: [0.2860582172870636, -0.5637859106063843]\n",
      "1200 steps | score: [0.34344246983528137, -0.7390389442443848]\n",
      "1300 steps | score: [0.24732616543769836, -0.5173722505569458]\n",
      "1400 steps | score: [0.1707000881433487, -0.32976415753364563]\n",
      "1500 steps | score: [0.1445428878068924, -0.2648210823535919]\n",
      "1600 steps | score: [0.23931781947612762, -0.4698430895805359]\n",
      "1700 steps | score: [0.2830791771411896, -0.5783681273460388]\n",
      "1800 steps | score: [0.4105467200279236, -0.8864510655403137]\n",
      "1900 steps | score: [0.2627667486667633, -0.5204737186431885]\n",
      "2000 steps | score: [0.21234087646007538, -0.4322225749492645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 steps | score: [0.36630725860595703, -0.7997148036956787]\n",
      "2200 steps | score: [0.16256913542747498, -0.31973081827163696]\n",
      "2300 steps | score: [0.18834178149700165, -0.3580627143383026]\n",
      "2400 steps | score: [0.2183714509010315, -0.4060111343860626]\n",
      "2500 steps | score: [0.20197489857673645, -0.39982911944389343]\n",
      "2600 steps | score: [0.18177500367164612, -0.36674314737319946]\n",
      "2700 steps | score: [0.2527841627597809, -0.5329188108444214]\n",
      "2800 steps | score: [0.16367283463478088, -0.31030428409576416]\n",
      "unknown params:  tensor([-0.3590, -0.8026, -0.0770, -0.8659,  0.6956,  0.7785])\n",
      "gt params:  tensor([-0.4078, -0.8579, -0.1023, -0.9540,  0.7659,  0.9620])\n",
      "ols params:  tensor([-0.2179, -0.4677, -0.0474, -0.5057,  0.4101,  4.2255])\n",
      "unknown mse:  tensor(0.0087)\n",
      "ols mse:  tensor(1.8616)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/2772a86a-870d-4bce-aacd-eaee1ac1b865\n",
      "gt params:  tensor([-0.6886, -0.0344,  0.7077,  0.0616,  0.6581,  0.5773])\n",
      "0 steps | score: [-0.1778729259967804]\n",
      "100 steps | score: [-0.1683589071035385]\n",
      "200 steps | score: [-0.24321652948856354]\n",
      "300 steps | score: [-0.32113438844680786]\n",
      "400 steps | score: [-0.22167690098285675]\n",
      "500 steps | score: [-0.21413454413414001]\n",
      "600 steps | score: [-0.22599980235099792]\n",
      "700 steps | score: [-0.28786492347717285]\n",
      "800 steps | score: [-0.25645655393600464]\n",
      "900 steps | score: [-0.22206443548202515]\n",
      "1000 steps | score: [-0.26434263586997986]\n",
      "1100 steps | score: [-0.2851613461971283]\n",
      "1200 steps | score: [-0.26988592743873596]\n",
      "1300 steps | score: [-0.24082837998867035]\n",
      "1400 steps | score: [-0.28945815563201904]\n",
      "1500 steps | score: [-0.21874380111694336]\n",
      "1600 steps | score: [-0.2850866913795471]\n",
      "1700 steps | score: [-0.30248138308525085]\n",
      "1800 steps | score: [-0.2553475499153137]\n",
      "1900 steps | score: [-0.2790440320968628]\n",
      "2000 steps | score: [-0.23279421031475067]\n",
      "2100 steps | score: [-0.280150443315506]\n",
      "2200 steps | score: [-0.25376856327056885]\n",
      "2300 steps | score: [-0.26712334156036377]\n",
      "2400 steps | score: [-0.25887128710746765]\n",
      "2500 steps | score: [-0.2637648582458496]\n",
      "2600 steps | score: [-0.23947523534297943]\n",
      "2700 steps | score: [-0.27458879351615906]\n",
      "2800 steps | score: [-0.3084096610546112]\n",
      "0 steps | score: [-0.14701047539710999, 0.9582762718200684]\n",
      "100 steps | score: [10.631152153015137, -97.39112854003906]\n",
      "200 steps | score: [-0.9272421598434448, 4.5571699142456055]\n",
      "300 steps | score: [-1.6703057289123535, 6.3892645835876465]\n",
      "400 steps | score: [-1.6861820220947266, 6.467331886291504]\n",
      "500 steps | score: [0.5468335747718811, -1.4240310192108154]\n",
      "600 steps | score: [-0.9439549446105957, 4.628354072570801]\n",
      "700 steps | score: [0.39365851879119873, -1.3925126791000366]\n",
      "800 steps | score: [0.6907241940498352, -3.0095252990722656]\n",
      "900 steps | score: [-0.25998401641845703, 1.4143222570419312]\n",
      "1000 steps | score: [-0.0944884642958641, 0.38341015577316284]\n",
      "1100 steps | score: [-0.5798870921134949, 2.52490496635437]\n",
      "1200 steps | score: [-0.2352166473865509, 0.8928103446960449]\n",
      "1300 steps | score: [-0.32018670439720154, 1.2516673803329468]\n",
      "1400 steps | score: [-0.2478513866662979, 1.0167574882507324]\n",
      "1500 steps | score: [-0.16106297075748444, 0.5599657297134399]\n",
      "1600 steps | score: [-0.35100215673446655, 1.3888212442398071]\n",
      "1700 steps | score: [-0.22214375436306, 0.8955150842666626]\n",
      "1800 steps | score: [0.010899819433689117, -0.3508812487125397]\n",
      "1900 steps | score: [-0.12684905529022217, 0.41441810131073]\n",
      "2000 steps | score: [-0.3733118176460266, 1.4673309326171875]\n",
      "2100 steps | score: [-0.324162095785141, 1.3236836194992065]\n",
      "2200 steps | score: [-0.3749729096889496, 1.463196039199829]\n",
      "2300 steps | score: [-0.13684949278831482, 0.45055678486824036]\n",
      "2400 steps | score: [-0.26526862382888794, 0.9883047342300415]\n",
      "2500 steps | score: [-0.27798065543174744, 0.9696519374847412]\n",
      "2600 steps | score: [-0.19244790077209473, 0.6040015816688538]\n",
      "2700 steps | score: [-0.44962382316589355, 1.7980211973190308]\n",
      "2800 steps | score: [-0.28615692257881165, 1.0681483745574951]\n",
      "unknown params:  tensor([-0.6828, -0.0355,  0.6966,  0.0593,  0.6470,  0.4105])\n",
      "gt params:  tensor([-0.6886, -0.0344,  0.7077,  0.0616,  0.6581,  0.5773])\n",
      "ols params:  tensor([-0.6126, -0.0279,  0.6315,  0.0512,  0.5852,  1.0282])\n",
      "unknown mse:  tensor(0.0047)\n",
      "ols mse:  tensor(0.0367)\n",
      "gt params:  tensor([-0.6863, -0.0372,  0.6924,  0.0599,  0.6653,  0.5556])\n",
      "0 steps | score: [0.12085516005754471]\n",
      "100 steps | score: [0.004294136539101601]\n",
      "0 steps | score: [0.034508440643548965, 0.2769768238067627]\n",
      "100 steps | score: [0.2452598214149475, -0.7297860383987427]\n",
      "200 steps | score: [0.1601150631904602, -0.6847883462905884]\n",
      "300 steps | score: [0.19347381591796875, -0.9171785116195679]\n",
      "400 steps | score: [-0.1752098798751831, 0.6148613691329956]\n",
      "500 steps | score: [-0.2050367295742035, 0.7369844317436218]\n",
      "600 steps | score: [-0.3713320791721344, 1.346952199935913]\n",
      "700 steps | score: [-0.220631942152977, 0.7726424932479858]\n",
      "800 steps | score: [0.16339312493801117, -0.7263867259025574]\n",
      "900 steps | score: [-0.17897072434425354, 0.566775918006897]\n",
      "1000 steps | score: [-0.09205697476863861, 0.2683117985725403]\n",
      "1100 steps | score: [0.06488269567489624, -0.41439753770828247]\n",
      "1200 steps | score: [-0.20180478692054749, 0.7514417171478271]\n",
      "1300 steps | score: [-0.12301700562238693, 0.4080517590045929]\n",
      "1400 steps | score: [-0.12268417328596115, 0.34044700860977173]\n",
      "1500 steps | score: [0.014059960842132568, -0.17397484183311462]\n",
      "1600 steps | score: [-0.0497935526072979, 0.1492297351360321]\n",
      "1700 steps | score: [-0.10562054067850113, 0.32297953963279724]\n",
      "1800 steps | score: [0.038050491362810135, -0.2403772473335266]\n",
      "1900 steps | score: [-0.16517485678195953, 0.5073995590209961]\n",
      "2000 steps | score: [-0.24312971532344818, 0.8115143775939941]\n",
      "2100 steps | score: [-0.023869415745139122, -0.008632123470306396]\n",
      "2200 steps | score: [-0.08430524915456772, 0.24466009438037872]\n",
      "2300 steps | score: [-0.20270013809204102, 0.677886962890625]\n",
      "2400 steps | score: [-0.12564091384410858, 0.381957471370697]\n",
      "2500 steps | score: [-0.13523460924625397, 0.3736443519592285]\n",
      "2600 steps | score: [-0.009650129824876785, -0.06716358661651611]\n",
      "2700 steps | score: [-0.041282378137111664, 0.02138984203338623]\n",
      "unknown params:  tensor([-0.6985, -0.0398,  0.7034,  0.0567,  0.6843,  0.5309])\n",
      "gt params:  tensor([-0.6863, -0.0372,  0.6924,  0.0599,  0.6653,  0.5556])\n",
      "ols params:  tensor([-0.5539, -0.0300,  0.5578,  0.0460,  0.5451,  1.3591])\n",
      "unknown mse:  tensor(0.0002)\n",
      "ols mse:  tensor(0.1160)\n",
      "gt params:  tensor([-0.6817, -0.0244,  0.6994,  0.0583,  0.6642,  0.6001])\n",
      "0 steps | score: [0.22170616686344147]\n",
      "100 steps | score: [0.12911683320999146]\n",
      "200 steps | score: [0.056164633482694626]\n",
      "300 steps | score: [0.00729607418179512]\n",
      "0 steps | score: [0.1809941679239273, -0.5527587532997131]\n",
      "100 steps | score: [0.09440267831087112, -0.5169491767883301]\n",
      "200 steps | score: [-0.04245941340923309, -0.21171090006828308]\n",
      "300 steps | score: [-0.14012528955936432, 0.026477321982383728]\n",
      "400 steps | score: [0.056732796132564545, -0.5191538333892822]\n",
      "500 steps | score: [-0.00722225196659565, -0.32324230670928955]\n",
      "600 steps | score: [-0.017924197018146515, -0.29840004444122314]\n",
      "700 steps | score: [0.056952446699142456, -0.5655178427696228]\n",
      "800 steps | score: [0.19508890807628632, -0.9757367968559265]\n",
      "900 steps | score: [-0.035928938537836075, -0.22971104085445404]\n",
      "1000 steps | score: [-0.15933085978031158, 0.034389808773994446]\n",
      "1100 steps | score: [0.06586670875549316, -0.5928598642349243]\n",
      "1200 steps | score: [0.147904172539711, -0.8092291355133057]\n",
      "1300 steps | score: [-0.15024401247501373, 0.07113033533096313]\n",
      "1400 steps | score: [0.043046772480010986, -0.48620057106018066]\n",
      "1500 steps | score: [-0.06872178614139557, -0.19471678137779236]\n",
      "1600 steps | score: [0.07141248136758804, -0.6151562929153442]\n",
      "1700 steps | score: [0.15789160132408142, -0.8534643650054932]\n",
      "1800 steps | score: [-0.09187179058790207, -0.13548782467842102]\n",
      "1900 steps | score: [-0.0010066089453175664, -0.4081721901893616]\n",
      "2000 steps | score: [0.05203140899538994, -0.5345374345779419]\n",
      "2100 steps | score: [-0.027438484132289886, -0.30892300605773926]\n",
      "2200 steps | score: [0.08959107846021652, -0.6639711260795593]\n",
      "2300 steps | score: [-0.01659955270588398, -0.34164226055145264]\n",
      "2400 steps | score: [0.06030933931469917, -0.5389615893363953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 steps | score: [-0.02713739313185215, -0.3297971785068512]\n",
      "2600 steps | score: [-0.06260683387517929, -0.1632556915283203]\n",
      "2700 steps | score: [-0.08267161250114441, -0.13388362526893616]\n",
      "2800 steps | score: [-0.001176365651190281, -0.401939332485199]\n",
      "unknown params:  tensor([-0.6857, -0.0299,  0.7050,  0.0604,  0.6672,  0.4527])\n",
      "gt params:  tensor([-0.6817, -0.0244,  0.6994,  0.0583,  0.6642,  0.6001])\n",
      "ols params:  tensor([-0.5176, -0.0229,  0.5282,  0.0451,  0.5032,  1.6586])\n",
      "unknown mse:  tensor(0.0036)\n",
      "ols mse:  tensor(0.2004)\n",
      "gt params:  tensor([-0.6813, -0.0257,  0.7004,  0.0606,  0.6659,  0.5885])\n",
      "0 steps | score: [0.405315101146698]\n",
      "100 steps | score: [0.24341556429862976]\n",
      "200 steps | score: [0.18181772530078888]\n",
      "300 steps | score: [0.2405872941017151]\n",
      "400 steps | score: [0.2069774866104126]\n",
      "500 steps | score: [0.20867465436458588]\n",
      "600 steps | score: [0.23319795727729797]\n",
      "700 steps | score: [0.21110272407531738]\n",
      "800 steps | score: [0.1981188952922821]\n",
      "900 steps | score: [0.27987661957740784]\n",
      "1000 steps | score: [0.25862839818000793]\n",
      "1100 steps | score: [0.23099857568740845]\n",
      "1200 steps | score: [0.2209833860397339]\n",
      "1300 steps | score: [0.24929189682006836]\n",
      "1400 steps | score: [0.22084525227546692]\n",
      "1500 steps | score: [0.24982938170433044]\n",
      "1600 steps | score: [0.21742704510688782]\n",
      "1700 steps | score: [0.23975127935409546]\n",
      "1800 steps | score: [0.24455195665359497]\n",
      "1900 steps | score: [0.20828069746494293]\n",
      "2000 steps | score: [0.26768776774406433]\n",
      "2100 steps | score: [0.21352849900722504]\n",
      "2200 steps | score: [0.20628882944583893]\n",
      "2300 steps | score: [0.23719431459903717]\n",
      "2400 steps | score: [0.24516794085502625]\n",
      "2500 steps | score: [0.23963865637779236]\n",
      "2600 steps | score: [0.2351556420326233]\n",
      "2700 steps | score: [0.24454300105571747]\n",
      "0 steps | score: [0.1513042151927948, 0.11506789922714233]\n",
      "100 steps | score: [0.5402366518974304, -1.472161054611206]\n",
      "200 steps | score: [-0.0014653077814728022, 0.2822604179382324]\n",
      "300 steps | score: [-0.10897041112184525, 0.536523163318634]\n",
      "400 steps | score: [0.012896135449409485, 0.13325466215610504]\n",
      "500 steps | score: [0.10130217671394348, -0.1421319544315338]\n",
      "600 steps | score: [0.038496486842632294, 0.08840574324131012]\n",
      "700 steps | score: [-0.13361996412277222, 0.6132724285125732]\n",
      "800 steps | score: [-0.13329850137233734, 0.6024609804153442]\n",
      "900 steps | score: [-0.0626983493566513, 0.38347601890563965]\n",
      "1000 steps | score: [-0.060349464416503906, 0.3930441439151764]\n",
      "1100 steps | score: [0.15320546925067902, -0.3203693926334381]\n",
      "1200 steps | score: [-0.06754220277070999, 0.3938782215118408]\n",
      "1300 steps | score: [-0.01004235353320837, 0.23161205649375916]\n",
      "1400 steps | score: [0.058435823768377304, -0.08735055476427078]\n",
      "1500 steps | score: [-0.039652127772569656, 0.2939150333404541]\n",
      "1600 steps | score: [-0.1636991798877716, 0.6344830989837646]\n",
      "1700 steps | score: [0.0013296332908794284, 0.20862722396850586]\n",
      "1800 steps | score: [0.024232307448983192, 0.08270524442195892]\n",
      "1900 steps | score: [-0.08998130261898041, 0.4500729739665985]\n",
      "2000 steps | score: [0.00547597324475646, 0.1352153718471527]\n",
      "2100 steps | score: [-0.03818779066205025, 0.28270578384399414]\n",
      "2200 steps | score: [0.021457288414239883, 0.1139536052942276]\n",
      "2300 steps | score: [0.04433107748627663, 0.006835997104644775]\n",
      "2400 steps | score: [0.05996543541550636, -0.025536179542541504]\n",
      "2500 steps | score: [0.06298612803220749, -0.01789715886116028]\n",
      "2600 steps | score: [0.11320256441831589, -0.2674991488456726]\n",
      "2700 steps | score: [0.020728522911667824, 0.08528706431388855]\n",
      "unknown params:  tensor([-0.7180, -0.0298,  0.7297,  0.0582,  0.7033,  0.4606])\n",
      "gt params:  tensor([-0.6813, -0.0257,  0.7004,  0.0606,  0.6659,  0.5885])\n",
      "ols params:  tensor([-0.4914, -0.0204,  0.4962,  0.0399,  0.4813,  1.8878])\n",
      "unknown mse:  tensor(0.0033)\n",
      "ols mse:  tensor(0.3001)\n",
      "gt params:  tensor([-0.6784, -0.0395,  0.6917,  0.0637,  0.6638,  0.5979])\n",
      "0 steps | score: [0.06626921892166138]\n",
      "100 steps | score: [-0.11214053630828857]\n",
      "200 steps | score: [-0.02628282830119133]\n",
      "300 steps | score: [-0.12059934437274933]\n",
      "400 steps | score: [-0.07144350558519363]\n",
      "500 steps | score: [-0.11080820858478546]\n",
      "600 steps | score: [-0.052029695361852646]\n",
      "700 steps | score: [-0.10147367417812347]\n",
      "800 steps | score: [-0.09955403208732605]\n",
      "900 steps | score: [-0.13963714241981506]\n",
      "1000 steps | score: [-0.06321243941783905]\n",
      "1100 steps | score: [-0.09382607042789459]\n",
      "1200 steps | score: [-0.11394134163856506]\n",
      "1300 steps | score: [-0.09555565565824509]\n",
      "1400 steps | score: [-0.08962461352348328]\n",
      "1500 steps | score: [-0.12144093215465546]\n",
      "1600 steps | score: [-0.07543370127677917]\n",
      "1700 steps | score: [-0.089632049202919]\n",
      "1800 steps | score: [-0.0944126769900322]\n",
      "1900 steps | score: [-0.05572209134697914]\n",
      "2000 steps | score: [-0.11522733420133591]\n",
      "2100 steps | score: [-0.09741441160440445]\n",
      "2200 steps | score: [-0.06303007900714874]\n",
      "2300 steps | score: [-0.06480271369218826]\n",
      "2400 steps | score: [-0.07498197257518768]\n",
      "2500 steps | score: [-0.072723388671875]\n",
      "2600 steps | score: [-0.10124839842319489]\n",
      "2700 steps | score: [-0.08387842774391174]\n",
      "2800 steps | score: [-0.08829353749752045]\n",
      "0 steps | score: [0.01644882932305336, 0.3514552116394043]\n",
      "100 steps | score: [-0.24518366158008575, 0.8307921290397644]\n",
      "200 steps | score: [0.17049656808376312, -0.5919941663742065]\n",
      "300 steps | score: [0.05352402850985527, -0.36114048957824707]\n",
      "400 steps | score: [-0.06847413629293442, 0.14995700120925903]\n",
      "500 steps | score: [-0.31017404794692993, 0.9415696859359741]\n",
      "600 steps | score: [-0.012689336203038692, 0.00324152410030365]\n",
      "700 steps | score: [-0.324931800365448, 0.9499534368515015]\n",
      "800 steps | score: [-0.1529211848974228, 0.4259454011917114]\n",
      "900 steps | score: [-0.2367883026599884, 0.6069389581680298]\n",
      "1000 steps | score: [0.08807116746902466, -0.36342594027519226]\n",
      "1100 steps | score: [-0.12817935645580292, 0.4088512063026428]\n",
      "1200 steps | score: [-0.07357677072286606, 0.1650625616312027]\n",
      "1300 steps | score: [-0.14819647371768951, 0.4272476136684418]\n",
      "1400 steps | score: [-0.07154242694377899, 0.09471482038497925]\n",
      "1500 steps | score: [-0.043821703642606735, 0.0411105751991272]\n",
      "1600 steps | score: [-0.09269072115421295, 0.25747668743133545]\n",
      "1700 steps | score: [-0.08176811039447784, 0.1839330792427063]\n",
      "1800 steps | score: [-0.004892133641988039, -0.07289241254329681]\n",
      "1900 steps | score: [-0.0211994256824255, -0.007433652877807617]\n",
      "2000 steps | score: [-0.11725734919309616, 0.30567091703414917]\n",
      "2100 steps | score: [-0.05979830399155617, 0.09154015779495239]\n",
      "2200 steps | score: [-0.098759226500988, 0.2784115672111511]\n",
      "2300 steps | score: [0.03391759470105171, -0.20055519044399261]\n",
      "2400 steps | score: [-0.05762222036719322, 0.06760808825492859]\n",
      "2500 steps | score: [0.03795453906059265, -0.23240037262439728]\n",
      "2600 steps | score: [-0.14053048193454742, 0.3799937963485718]\n",
      "2700 steps | score: [-0.06059408560395241, 0.11804361641407013]\n",
      "2800 steps | score: [-0.030504126101732254, 0.04795995354652405]\n",
      "unknown params:  tensor([-0.6711, -0.0347,  0.6729,  0.0602,  0.6638,  0.4627])\n",
      "gt params:  tensor([-0.6784, -0.0395,  0.6917,  0.0637,  0.6638,  0.5979])\n",
      "ols params:  tensor([-0.4609, -0.0207,  0.4608,  0.0420,  0.4563,  2.0933])\n",
      "unknown mse:  tensor(0.0031)\n",
      "ols mse:  tensor(0.3968)\n",
      "gt params:  tensor([-0.6955, -0.0373,  0.6887,  0.0640,  0.6567,  0.5620])\n",
      "0 steps | score: [0.16905219852924347]\n",
      "100 steps | score: [0.05183059722185135]\n",
      "200 steps | score: [-0.042991071939468384]\n",
      "300 steps | score: [-0.06960474699735641]\n",
      "400 steps | score: [-0.012953607365489006]\n",
      "500 steps | score: [-0.006222626194357872]\n",
      "0 steps | score: [0.37635305523872375, -0.6392813324928284]\n",
      "100 steps | score: [0.4069996178150177, -0.889741837978363]\n",
      "200 steps | score: [0.12570923566818237, -0.22457614541053772]\n",
      "300 steps | score: [0.08697030693292618, -0.17126905918121338]\n",
      "400 steps | score: [0.4616997539997101, -1.1972423791885376]\n",
      "500 steps | score: [0.35029712319374084, -0.8781538605690002]\n",
      "600 steps | score: [0.14378345012664795, -0.3199220299720764]\n",
      "700 steps | score: [0.11710093915462494, -0.2520090639591217]\n",
      "800 steps | score: [0.3014368414878845, -0.7016514539718628]\n",
      "900 steps | score: [0.14001518487930298, -0.29349079728126526]\n",
      "1000 steps | score: [0.1382678598165512, -0.32794100046157837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 steps | score: [0.09305199980735779, -0.22666268050670624]\n",
      "1200 steps | score: [0.19048964977264404, -0.43443363904953003]\n",
      "1300 steps | score: [0.19387127459049225, -0.41499221324920654]\n",
      "1400 steps | score: [0.18760448694229126, -0.4421952962875366]\n",
      "1500 steps | score: [0.187924325466156, -0.4528330862522125]\n",
      "1600 steps | score: [0.3342745900154114, -0.8183769583702087]\n",
      "1700 steps | score: [0.17735357582569122, -0.39673420786857605]\n",
      "1800 steps | score: [0.2808705270290375, -0.7037343978881836]\n",
      "1900 steps | score: [0.28697511553764343, -0.6969956755638123]\n",
      "2000 steps | score: [0.17612722516059875, -0.418849378824234]\n",
      "2100 steps | score: [0.16450898349285126, -0.4041095972061157]\n",
      "2200 steps | score: [0.14522485435009003, -0.3265818953514099]\n",
      "2300 steps | score: [0.25466957688331604, -0.6317270994186401]\n",
      "2400 steps | score: [0.1502286195755005, -0.3357287645339966]\n",
      "2500 steps | score: [0.19469772279262543, -0.49300211668014526]\n",
      "2600 steps | score: [0.12894968688488007, -0.3141266107559204]\n",
      "2700 steps | score: [0.24426628649234772, -0.605883777141571]\n",
      "unknown params:  tensor([-0.6947, -0.0302,  0.6849,  0.0711,  0.6829,  0.3812])\n",
      "gt params:  tensor([-0.6955, -0.0373,  0.6887,  0.0640,  0.6567,  0.5620])\n",
      "ols params:  tensor([-0.4505, -0.0170,  0.4385,  0.0457,  0.4397,  2.2757])\n",
      "unknown mse:  tensor(0.0056)\n",
      "ols mse:  tensor(0.5179)\n",
      "gt params:  tensor([-0.6936, -0.0223,  0.7022,  0.0588,  0.6752,  0.5940])\n",
      "0 steps | score: [0.2499369978904724]\n",
      "100 steps | score: [0.043339770287275314]\n",
      "200 steps | score: [0.01744002476334572]\n",
      "300 steps | score: [0.03556722402572632]\n",
      "400 steps | score: [0.10535326600074768]\n",
      "500 steps | score: [0.03397035598754883]\n",
      "600 steps | score: [0.05552937835454941]\n",
      "700 steps | score: [0.005140189081430435]\n",
      "0 steps | score: [0.1408505141735077, -0.1127672865986824]\n",
      "100 steps | score: [0.4785127341747284, -1.2926663160324097]\n",
      "200 steps | score: [0.09992715716362, -0.2650739848613739]\n",
      "300 steps | score: [0.2153947353363037, -0.6077510714530945]\n",
      "400 steps | score: [0.2487824261188507, -0.6973330974578857]\n",
      "500 steps | score: [-0.15359452366828918, 0.342085063457489]\n",
      "600 steps | score: [0.008787515573203564, -0.03534548729658127]\n",
      "700 steps | score: [0.05357998237013817, -0.14367254078388214]\n",
      "800 steps | score: [0.09837964177131653, -0.28750091791152954]\n",
      "900 steps | score: [0.17420977354049683, -0.5055204033851624]\n",
      "1000 steps | score: [0.1946813315153122, -0.5628378987312317]\n",
      "1100 steps | score: [-0.06149674206972122, 0.15222609043121338]\n",
      "1200 steps | score: [0.10735010355710983, -0.3166833221912384]\n",
      "1300 steps | score: [-0.0075571853667497635, -0.027829095721244812]\n",
      "1400 steps | score: [-0.07655123621225357, 0.11450016498565674]\n",
      "1500 steps | score: [0.24091726541519165, -0.720570981502533]\n",
      "1600 steps | score: [0.021784000098705292, -0.0771026611328125]\n",
      "1700 steps | score: [-0.05184929445385933, 0.10264754295349121]\n",
      "1800 steps | score: [-0.03886955603957176, 0.07208913564682007]\n",
      "1900 steps | score: [-0.027936534956097603, 0.03145572543144226]\n",
      "2000 steps | score: [-0.016899531707167625, 0.005625426769256592]\n",
      "2100 steps | score: [0.07720477879047394, -0.25198736786842346]\n",
      "2200 steps | score: [0.006082306150346994, -0.04586955904960632]\n",
      "2300 steps | score: [-0.03730551153421402, 0.05099186301231384]\n",
      "2400 steps | score: [0.013567527756094933, -0.10189104080200195]\n",
      "2500 steps | score: [0.01741800270974636, -0.07710962742567062]\n",
      "2600 steps | score: [0.0040505677461624146, -0.09124074876308441]\n",
      "2700 steps | score: [0.03311732038855553, -0.14446061849594116]\n",
      "unknown params:  tensor([-0.6881, -0.0448,  0.7285,  0.0537,  0.6808,  0.3625])\n",
      "gt params:  tensor([-0.6936, -0.0223,  0.7022,  0.0588,  0.6752,  0.5940])\n",
      "ols params:  tensor([-0.4248, -0.0269,  0.4455,  0.0357,  0.4241,  2.4731])\n",
      "unknown mse:  tensor(0.0092)\n",
      "ols mse:  tensor(0.6221)\n",
      "gt params:  tensor([-0.6936, -0.0426,  0.7201,  0.0721,  0.6618,  0.5958])\n",
      "0 steps | score: [0.342035710811615]\n",
      "100 steps | score: [0.03048759326338768]\n",
      "200 steps | score: [0.12786632776260376]\n",
      "300 steps | score: [0.1263025403022766]\n",
      "400 steps | score: [0.1591964066028595]\n",
      "500 steps | score: [0.07894379645586014]\n",
      "600 steps | score: [0.14009740948677063]\n",
      "700 steps | score: [0.0658222883939743]\n",
      "800 steps | score: [0.12053444981575012]\n",
      "900 steps | score: [0.11120691895484924]\n",
      "1000 steps | score: [0.089743971824646]\n",
      "1100 steps | score: [0.11803443729877472]\n",
      "1200 steps | score: [0.12192402780056]\n",
      "1300 steps | score: [0.09766793251037598]\n",
      "1400 steps | score: [0.14270369708538055]\n",
      "1500 steps | score: [0.13596689701080322]\n",
      "1600 steps | score: [0.08789744973182678]\n",
      "1700 steps | score: [0.12888836860656738]\n",
      "1800 steps | score: [0.07350543141365051]\n",
      "1900 steps | score: [0.1058511883020401]\n",
      "2000 steps | score: [0.10460424423217773]\n",
      "2100 steps | score: [0.10359181463718414]\n",
      "2200 steps | score: [0.0744047537446022]\n",
      "2300 steps | score: [0.11398299783468246]\n",
      "2400 steps | score: [0.07717487215995789]\n",
      "2500 steps | score: [0.11560764908790588]\n",
      "2600 steps | score: [0.07597851753234863]\n",
      "2700 steps | score: [0.09573343396186829]\n",
      "0 steps | score: [0.241629958152771, -0.3347990810871124]\n",
      "100 steps | score: [-0.15272283554077148, 0.36784422397613525]\n",
      "200 steps | score: [0.12780863046646118, -0.27123063802719116]\n",
      "300 steps | score: [-0.10566936433315277, 0.2606746256351471]\n",
      "400 steps | score: [0.10790611803531647, -0.22905953228473663]\n",
      "500 steps | score: [0.12442140281200409, -0.3370603919029236]\n",
      "600 steps | score: [0.0422394685447216, -0.1351754069328308]\n",
      "700 steps | score: [0.11314104497432709, -0.2989523410797119]\n",
      "800 steps | score: [-0.16225650906562805, 0.3512387275695801]\n",
      "900 steps | score: [0.21716228127479553, -0.4977857172489166]\n",
      "1000 steps | score: [0.04845961555838585, -0.13606204092502594]\n",
      "1100 steps | score: [0.03819940239191055, -0.10334012657403946]\n",
      "1200 steps | score: [-0.051808618009090424, 0.07561153173446655]\n",
      "1300 steps | score: [0.05394203960895538, -0.16201908886432648]\n",
      "1400 steps | score: [0.1593700349330902, -0.4198601245880127]\n",
      "1500 steps | score: [0.21039089560508728, -0.5345191955566406]\n",
      "1600 steps | score: [0.05650167167186737, -0.13385741412639618]\n",
      "1700 steps | score: [0.20510081946849823, -0.5456254482269287]\n",
      "1800 steps | score: [-0.014197309501469135, 0.016471777111291885]\n",
      "1900 steps | score: [0.20224379003047943, -0.5445166230201721]\n",
      "2000 steps | score: [0.07417510449886322, -0.21119673550128937]\n",
      "2100 steps | score: [0.03200528398156166, -0.07723154127597809]\n",
      "2200 steps | score: [0.16848161816596985, -0.45701703429222107]\n",
      "2300 steps | score: [0.10320034623146057, -0.32198089361190796]\n",
      "2400 steps | score: [0.03521726280450821, -0.12080969661474228]\n",
      "2500 steps | score: [0.06584986299276352, -0.23026876151561737]\n",
      "2600 steps | score: [-0.0005975079839117825, -0.013513651676476002]\n",
      "2700 steps | score: [-0.03513655439019203, 0.07191264629364014]\n",
      "unknown params:  tensor([-0.6940, -0.0413,  0.7090,  0.0668,  0.6652,  0.3587])\n",
      "gt params:  tensor([-0.6936, -0.0426,  0.7201,  0.0721,  0.6618,  0.5958])\n",
      "ols params:  tensor([-0.4260, -0.0257,  0.4312,  0.0431,  0.4095,  2.5893])\n",
      "unknown mse:  tensor(0.0094)\n",
      "ols mse:  tensor(0.6990)\n",
      "gt params:  tensor([-0.6967, -0.0155,  0.7105,  0.0636,  0.6569,  0.5612])\n",
      "0 steps | score: [0.286943256855011]\n",
      "100 steps | score: [0.03972679749131203]\n",
      "200 steps | score: [0.04361005872488022]\n",
      "300 steps | score: [0.05324683338403702]\n",
      "400 steps | score: [0.08045122027397156]\n",
      "500 steps | score: [0.0689891055226326]\n",
      "600 steps | score: [0.004786619916558266]\n",
      "0 steps | score: [0.005469083320349455, 0.2096102237701416]\n",
      "100 steps | score: [0.4859371483325958, -1.3659999370574951]\n",
      "200 steps | score: [-0.023686017841100693, 0.06935596466064453]\n",
      "300 steps | score: [0.011107424274086952, -0.06263625621795654]\n",
      "400 steps | score: [-0.08686939626932144, 0.20235715806484222]\n",
      "500 steps | score: [-0.2744291126728058, 0.6482020020484924]\n",
      "600 steps | score: [-0.020014449954032898, -0.028089694678783417]\n",
      "700 steps | score: [-0.21633939445018768, 0.5093093514442444]\n",
      "800 steps | score: [-0.08310803771018982, 0.17449674010276794]\n",
      "900 steps | score: [-0.0977088138461113, 0.19780361652374268]\n",
      "1000 steps | score: [-0.05357559025287628, 0.12960517406463623]\n",
      "1100 steps | score: [-0.14272837340831757, 0.32540959119796753]\n",
      "1200 steps | score: [-0.015377693809568882, -0.02464551106095314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 steps | score: [-0.05977610498666763, 0.15859341621398926]\n",
      "1400 steps | score: [0.14079713821411133, -0.47207629680633545]\n",
      "1500 steps | score: [0.012562592513859272, -0.07502330839633942]\n",
      "1600 steps | score: [-0.02927316725254059, 0.00027638673782348633]\n",
      "1700 steps | score: [-0.13012127578258514, 0.2587679624557495]\n",
      "1800 steps | score: [-0.12403968721628189, 0.2722311019897461]\n",
      "1900 steps | score: [-0.23231635987758636, 0.5189813375473022]\n",
      "2000 steps | score: [-0.13666105270385742, 0.31496167182922363]\n",
      "2100 steps | score: [-0.09203125536441803, 0.16431857645511627]\n",
      "2200 steps | score: [-0.08900639414787292, 0.1724078357219696]\n",
      "2300 steps | score: [-0.1675644963979721, 0.39076942205429077]\n",
      "2400 steps | score: [-0.17714950442314148, 0.3644470274448395]\n",
      "2500 steps | score: [-0.04233263432979584, 0.0768875703215599]\n",
      "2600 steps | score: [-0.01988014206290245, -0.0001707896590232849]\n",
      "2700 steps | score: [-0.0786982923746109, 0.1409720480442047]\n",
      "unknown params:  tensor([-0.6570, -0.0183,  0.6693,  0.0748,  0.6426,  0.5405])\n",
      "gt params:  tensor([-0.6967, -0.0155,  0.7105,  0.0636,  0.6569,  0.5612])\n",
      "ols params:  tensor([-0.3982, -0.0095,  0.4023,  0.0444,  0.3910,  2.7854])\n",
      "unknown mse:  tensor(0.0007)\n",
      "ols mse:  tensor(0.8671)\n",
      "gt params:  tensor([-0.6880, -0.0255,  0.7046,  0.0585,  0.6471,  0.5989])\n",
      "0 steps | score: [0.25059884786605835]\n",
      "100 steps | score: [-0.0749291479587555]\n",
      "200 steps | score: [0.014633433893322945]\n",
      "300 steps | score: [0.07784995436668396]\n",
      "400 steps | score: [0.04095277190208435]\n",
      "500 steps | score: [0.003787897527217865]\n",
      "0 steps | score: [0.18355457484722137, -0.2997462749481201]\n",
      "100 steps | score: [-0.07898367196321487, 0.1433711051940918]\n",
      "200 steps | score: [0.07998020201921463, -0.28431791067123413]\n",
      "300 steps | score: [0.126241534948349, -0.3983309864997864]\n",
      "400 steps | score: [0.28736841678619385, -0.8127750754356384]\n",
      "500 steps | score: [0.052085552364587784, -0.28186434507369995]\n",
      "600 steps | score: [-0.0693843886256218, 0.007392562925815582]\n",
      "700 steps | score: [-0.010071325115859509, -0.11338202655315399]\n",
      "800 steps | score: [0.01803801953792572, -0.17140571773052216]\n",
      "900 steps | score: [-0.059966154396533966, 0.027804497629404068]\n",
      "1000 steps | score: [0.02608782984316349, -0.21315936744213104]\n",
      "1100 steps | score: [0.2253105491399765, -0.747849702835083]\n",
      "1200 steps | score: [-0.03826628252863884, -0.05696498602628708]\n",
      "1300 steps | score: [0.1886865794658661, -0.6333076357841492]\n",
      "1400 steps | score: [0.11530585587024689, -0.4499480724334717]\n",
      "1500 steps | score: [0.13560830056667328, -0.47226282954216003]\n",
      "1600 steps | score: [0.12341093271970749, -0.4647081196308136]\n",
      "1700 steps | score: [-0.029989082366228104, -0.07535101473331451]\n",
      "1800 steps | score: [0.012560122646391392, -0.17524634301662445]\n",
      "1900 steps | score: [0.14221875369548798, -0.5096996426582336]\n",
      "2000 steps | score: [0.06835237145423889, -0.2722794711589813]\n",
      "2100 steps | score: [0.07625248283147812, -0.33884745836257935]\n",
      "2200 steps | score: [0.01935536041855812, -0.20813974738121033]\n",
      "2300 steps | score: [0.02912452071905136, -0.19873091578483582]\n",
      "2400 steps | score: [0.05704697594046593, -0.3026888966560364]\n",
      "2500 steps | score: [0.09107664972543716, -0.37604856491088867]\n",
      "2600 steps | score: [0.12555065751075745, -0.47324925661087036]\n",
      "2700 steps | score: [0.0477185994386673, -0.27087080478668213]\n",
      "unknown params:  tensor([-0.6627, -0.0310,  0.6833,  0.0644,  0.6479,  0.4521])\n",
      "gt params:  tensor([-0.6880, -0.0255,  0.7046,  0.0585,  0.6471,  0.5989])\n",
      "ols params:  tensor([-0.3886, -0.0194,  0.3964,  0.0413,  0.3790,  2.9576])\n",
      "unknown mse:  tensor(0.0038)\n",
      "ols mse:  tensor(0.9700)\n",
      "gt params:  tensor([-0.6862, -0.0334,  0.7076,  0.0604,  0.6618,  0.5873])\n",
      "0 steps | score: [0.21021795272827148]\n",
      "100 steps | score: [-0.0284108966588974]\n",
      "200 steps | score: [-0.03689311072230339]\n",
      "300 steps | score: [-0.04471590742468834]\n",
      "400 steps | score: [0.03048386424779892]\n",
      "500 steps | score: [-0.07401159405708313]\n",
      "600 steps | score: [-0.04729175940155983]\n",
      "700 steps | score: [-0.016224492341279984]\n",
      "800 steps | score: [-0.0031334683299064636]\n",
      "0 steps | score: [0.39028918743133545, -0.6543103456497192]\n",
      "100 steps | score: [0.14871443808078766, -0.288643479347229]\n",
      "200 steps | score: [0.15659573674201965, -0.3506966233253479]\n",
      "300 steps | score: [0.4045374393463135, -0.9507628679275513]\n",
      "400 steps | score: [0.5757870674133301, -1.4079291820526123]\n",
      "500 steps | score: [0.09553378820419312, -0.2585437595844269]\n",
      "600 steps | score: [0.20044371485710144, -0.49715104699134827]\n",
      "700 steps | score: [0.20949658751487732, -0.5331685543060303]\n",
      "800 steps | score: [0.25344645977020264, -0.6312036514282227]\n",
      "900 steps | score: [0.21962082386016846, -0.5075634717941284]\n",
      "1000 steps | score: [0.2418893724679947, -0.6018925905227661]\n",
      "1100 steps | score: [0.23576998710632324, -0.6124958395957947]\n",
      "1200 steps | score: [0.24642981588840485, -0.6353636980056763]\n",
      "1300 steps | score: [0.1223016008734703, -0.3154304623603821]\n",
      "1400 steps | score: [0.10097513347864151, -0.28512638807296753]\n",
      "1500 steps | score: [0.26686009764671326, -0.6623280048370361]\n",
      "1600 steps | score: [0.03608513996005058, -0.16751204431056976]\n",
      "1700 steps | score: [0.29107025265693665, -0.7301534414291382]\n",
      "1800 steps | score: [0.24581585824489594, -0.5850633382797241]\n",
      "1900 steps | score: [0.2914888858795166, -0.7202612161636353]\n",
      "2000 steps | score: [0.1846008598804474, -0.4780321419239044]\n",
      "2100 steps | score: [0.2249639630317688, -0.529460072517395]\n",
      "2200 steps | score: [0.18955866992473602, -0.4913009703159332]\n",
      "2300 steps | score: [0.2218255251646042, -0.5639822483062744]\n",
      "2400 steps | score: [0.16831707954406738, -0.40565037727355957]\n",
      "2500 steps | score: [0.1284763216972351, -0.3435826897621155]\n",
      "2600 steps | score: [0.23632670938968658, -0.5930423140525818]\n",
      "2700 steps | score: [0.14719362556934357, -0.39233511686325073]\n",
      "unknown params:  tensor([-0.7233, -0.0518,  0.7315,  0.0441,  0.6728,  0.3784])\n",
      "gt params:  tensor([-0.6862, -0.0334,  0.7076,  0.0604,  0.6618,  0.5873])\n",
      "ols params:  tensor([-0.3863, -0.0280,  0.3894,  0.0234,  0.3618,  3.0434])\n",
      "unknown mse:  tensor(0.0077)\n",
      "ols mse:  tensor(1.0525)\n",
      "gt params:  tensor([-0.6618, -0.0329,  0.7111,  0.0674,  0.6648,  0.5346])\n",
      "0 steps | score: [0.17914661765098572]\n",
      "100 steps | score: [-0.09644657373428345]\n",
      "200 steps | score: [-0.04839343577623367]\n",
      "300 steps | score: [-0.05273449793457985]\n",
      "400 steps | score: [-0.028721008449792862]\n",
      "500 steps | score: [-0.0848844051361084]\n",
      "600 steps | score: [-0.14156799018383026]\n",
      "700 steps | score: [-0.1136702224612236]\n",
      "800 steps | score: [-0.07047443836927414]\n",
      "900 steps | score: [-0.09859961271286011]\n",
      "1000 steps | score: [-0.09638158977031708]\n",
      "1100 steps | score: [-0.05258575454354286]\n",
      "1200 steps | score: [-0.11610876023769379]\n",
      "1300 steps | score: [-0.04911472648382187]\n",
      "1400 steps | score: [-0.06922564655542374]\n",
      "1500 steps | score: [-0.06785877794027328]\n",
      "1600 steps | score: [-0.09453084319829941]\n",
      "1700 steps | score: [-0.09721322357654572]\n",
      "1800 steps | score: [-0.07103760540485382]\n",
      "1900 steps | score: [-0.0842113196849823]\n",
      "2000 steps | score: [-0.07405763119459152]\n",
      "2100 steps | score: [-0.09869672358036041]\n",
      "2200 steps | score: [-0.07939401268959045]\n",
      "2300 steps | score: [-0.09901492297649384]\n",
      "2400 steps | score: [-0.0720161572098732]\n",
      "2500 steps | score: [-0.06632734835147858]\n",
      "2600 steps | score: [-0.060298386961221695]\n",
      "2700 steps | score: [-0.07442708313465118]\n",
      "0 steps | score: [0.11366088688373566, 0.011933669447898865]\n",
      "100 steps | score: [0.4406698942184448, -1.0196329355239868]\n",
      "200 steps | score: [0.1476343423128128, -0.3240426778793335]\n",
      "300 steps | score: [-0.05616801604628563, 0.15449202060699463]\n",
      "400 steps | score: [0.026848627254366875, -0.05771259963512421]\n",
      "500 steps | score: [-0.14852680265903473, 0.35091933608055115]\n",
      "600 steps | score: [-0.13282331824302673, 0.33974239230155945]\n",
      "700 steps | score: [-0.07557201385498047, 0.20193703472614288]\n",
      "800 steps | score: [-0.06051803380250931, 0.15588659048080444]\n",
      "900 steps | score: [-0.07483579963445663, 0.1478317677974701]\n",
      "1000 steps | score: [0.01509497407823801, -0.03791080415248871]\n",
      "1100 steps | score: [0.05624179542064667, -0.1456049680709839]\n",
      "1200 steps | score: [0.0968184769153595, -0.23597535490989685]\n",
      "1300 steps | score: [0.11723177134990692, -0.29833948612213135]\n",
      "1400 steps | score: [-0.007331763859838247, 0.025212973356246948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 steps | score: [0.10078307241201401, -0.28338271379470825]\n",
      "1600 steps | score: [-0.21562086045742035, 0.46193569898605347]\n",
      "1700 steps | score: [-0.08911460638046265, 0.26772570610046387]\n",
      "1800 steps | score: [0.09051160514354706, -0.20587000250816345]\n",
      "1900 steps | score: [0.03156592324376106, -0.08727684617042542]\n",
      "2000 steps | score: [-0.09419864416122437, 0.2075175940990448]\n",
      "2100 steps | score: [-0.06611043214797974, 0.15205048024654388]\n",
      "2200 steps | score: [-0.004448195453733206, -0.030151695013046265]\n",
      "2300 steps | score: [-0.026971319690346718, 0.05565217137336731]\n",
      "2400 steps | score: [0.03161299228668213, -0.11598499119281769]\n",
      "2500 steps | score: [-0.05053345859050751, 0.1352616846561432]\n",
      "2600 steps | score: [0.033280644565820694, -0.07833307981491089]\n",
      "2700 steps | score: [-0.0726814866065979, 0.16847993433475494]\n",
      "unknown params:  tensor([-0.6839, -0.0132,  0.7145,  0.1055,  0.6947,  0.3775])\n",
      "gt params:  tensor([-0.6618, -0.0329,  0.7111,  0.0674,  0.6648,  0.5346])\n",
      "ols params:  tensor([-0.3640, -0.0101,  0.3749,  0.0569,  0.3662,  3.0944])\n",
      "unknown mse:  tensor(0.0046)\n",
      "ols mse:  tensor(1.1407)\n",
      "gt params:  tensor([-0.6724, -0.0280,  0.7318,  0.0613,  0.6755,  0.6232])\n",
      "0 steps | score: [0.2049388736486435]\n",
      "100 steps | score: [-0.09613440185785294]\n",
      "200 steps | score: [-0.07707135379314423]\n",
      "300 steps | score: [0.014482714235782623]\n",
      "400 steps | score: [-0.049685150384902954]\n",
      "500 steps | score: [-0.059019021689891815]\n",
      "600 steps | score: [-0.038540102541446686]\n",
      "700 steps | score: [-0.07577762007713318]\n",
      "800 steps | score: [-0.04087340086698532]\n",
      "900 steps | score: [-0.0027907155454158783]\n",
      "0 steps | score: [0.2281588912010193, -0.39509931206703186]\n",
      "100 steps | score: [0.020078394562005997, -0.12933635711669922]\n",
      "200 steps | score: [0.048521701246500015, -0.24195325374603271]\n",
      "300 steps | score: [0.025728298351168633, -0.181104838848114]\n",
      "400 steps | score: [0.09385170787572861, -0.36671334505081177]\n",
      "500 steps | score: [-0.13971102237701416, 0.14683234691619873]\n",
      "600 steps | score: [0.31752124428749084, -0.8516878485679626]\n",
      "700 steps | score: [0.009321448393166065, -0.19382114708423615]\n",
      "800 steps | score: [-0.10729847848415375, 0.08541634678840637]\n",
      "900 steps | score: [0.13560476899147034, -0.4890389144420624]\n",
      "1000 steps | score: [-0.018478820100426674, -0.09323298186063766]\n",
      "1100 steps | score: [-0.09585452079772949, 0.06338001787662506]\n",
      "1200 steps | score: [-0.04002055153250694, -0.055438049137592316]\n",
      "1300 steps | score: [0.016513532027602196, -0.21785984933376312]\n",
      "1400 steps | score: [0.11862605810165405, -0.41099458932876587]\n",
      "1500 steps | score: [-0.016428055241703987, -0.12679097056388855]\n",
      "1600 steps | score: [0.03401319682598114, -0.23875460028648376]\n",
      "1700 steps | score: [0.044863808900117874, -0.24500113725662231]\n",
      "1800 steps | score: [0.026600126177072525, -0.21495142579078674]\n",
      "1900 steps | score: [0.08217906206846237, -0.365788996219635]\n",
      "2000 steps | score: [0.13102978467941284, -0.4865818917751312]\n",
      "2100 steps | score: [0.04615021124482155, -0.25863033533096313]\n",
      "2200 steps | score: [-0.027804164215922356, -0.09766081720590591]\n",
      "2300 steps | score: [0.0467425175011158, -0.23546135425567627]\n",
      "2400 steps | score: [-0.020280800759792328, -0.08597411960363388]\n",
      "2500 steps | score: [0.13125905394554138, -0.4813261926174164]\n",
      "2600 steps | score: [-0.006078911479562521, -0.15134268999099731]\n",
      "2700 steps | score: [0.04373741149902344, -0.24313029646873474]\n",
      "unknown params:  tensor([-0.6717, -0.0232,  0.6793,  0.0557,  0.6669,  0.3285])\n",
      "gt params:  tensor([-0.6724, -0.0280,  0.7318,  0.0613,  0.6755,  0.6232])\n",
      "ols params:  tensor([-0.3769, -0.0141,  0.3805,  0.0333,  0.3715,  3.2715])\n",
      "unknown mse:  tensor(0.0150)\n",
      "ols mse:  tensor(1.2195)\n",
      "gt params:  tensor([-0.6737, -0.0454,  0.7020,  0.0672,  0.6802,  0.6327])\n",
      "0 steps | score: [0.0028745904564857483]\n",
      "100 steps | score: [-0.3294024169445038]\n",
      "200 steps | score: [-0.2046470046043396]\n",
      "300 steps | score: [-0.23988831043243408]\n",
      "400 steps | score: [-0.2533213198184967]\n",
      "500 steps | score: [-0.24101683497428894]\n",
      "600 steps | score: [-0.2201276570558548]\n",
      "700 steps | score: [-0.2963999807834625]\n",
      "800 steps | score: [-0.25033071637153625]\n",
      "900 steps | score: [-0.21914155781269073]\n",
      "1000 steps | score: [-0.230637788772583]\n",
      "1100 steps | score: [-0.2281729280948639]\n",
      "1200 steps | score: [-0.1880568265914917]\n",
      "1300 steps | score: [-0.22685003280639648]\n",
      "1400 steps | score: [-0.20635133981704712]\n",
      "1500 steps | score: [-0.21779043972492218]\n",
      "1600 steps | score: [-0.2063479721546173]\n",
      "1700 steps | score: [-0.22409428656101227]\n",
      "1800 steps | score: [-0.24363139271736145]\n",
      "1900 steps | score: [-0.23880350589752197]\n",
      "2000 steps | score: [-0.20839570462703705]\n",
      "2100 steps | score: [-0.22665512561798096]\n",
      "2200 steps | score: [-0.22040876746177673]\n",
      "2300 steps | score: [-0.2236092984676361]\n",
      "2400 steps | score: [-0.23336739838123322]\n",
      "2500 steps | score: [-0.21702811121940613]\n",
      "2600 steps | score: [-0.23956121504306793]\n",
      "2700 steps | score: [-0.22226549685001373]\n",
      "0 steps | score: [0.31824079155921936, -0.40525609254837036]\n",
      "100 steps | score: [-0.06354844570159912, 0.23453859984874725]\n",
      "200 steps | score: [0.3252418041229248, -0.6548082232475281]\n",
      "300 steps | score: [-0.0072928983718156815, 0.06824466586112976]\n",
      "400 steps | score: [-0.003925133962184191, 0.03208939731121063]\n",
      "500 steps | score: [0.0801890417933464, -0.12618869543075562]\n",
      "600 steps | score: [-0.023595575243234634, 0.07194745540618896]\n",
      "700 steps | score: [-0.11807344108819962, 0.2655324637889862]\n",
      "800 steps | score: [0.1655394285917282, -0.37052181363105774]\n",
      "900 steps | score: [0.33509427309036255, -0.7110077142715454]\n",
      "1000 steps | score: [0.16473710536956787, -0.3197549879550934]\n",
      "1100 steps | score: [0.06219831109046936, -0.10110315680503845]\n",
      "1200 steps | score: [0.18692877888679504, -0.36482420563697815]\n",
      "1300 steps | score: [0.32605165243148804, -0.7473477721214294]\n",
      "1400 steps | score: [0.2671421766281128, -0.6048617959022522]\n",
      "1500 steps | score: [0.23510929942131042, -0.48221588134765625]\n",
      "1600 steps | score: [0.13170404732227325, -0.2451365888118744]\n",
      "1700 steps | score: [0.15722286701202393, -0.31114381551742554]\n",
      "1800 steps | score: [0.13270340859889984, -0.2893954813480377]\n",
      "1900 steps | score: [0.09465272724628448, -0.17705132067203522]\n",
      "2000 steps | score: [0.215301975607872, -0.4228864312171936]\n",
      "2100 steps | score: [0.15322661399841309, -0.33023446798324585]\n",
      "2200 steps | score: [0.14309874176979065, -0.31358063220977783]\n",
      "2300 steps | score: [0.1366662234067917, -0.28583550453186035]\n",
      "2400 steps | score: [0.03876768797636032, -0.03949430584907532]\n",
      "2500 steps | score: [0.21409101784229279, -0.47142961621284485]\n",
      "2600 steps | score: [0.16582368314266205, -0.34015896916389465]\n",
      "2700 steps | score: [0.13497641682624817, -0.24081365764141083]\n",
      "unknown params:  tensor([-0.7011, -0.0569,  0.7224,  0.0548,  0.7388,  0.2692])\n",
      "gt params:  tensor([-0.6737, -0.0454,  0.7020,  0.0672,  0.6802,  0.6327])\n",
      "ols params:  tensor([-0.3511, -0.0306,  0.3579,  0.0281,  0.3655,  3.3629])\n",
      "unknown mse:  tensor(0.0228)\n",
      "ols mse:  tensor(1.2963)\n",
      "gt params:  tensor([-0.6848, -0.0372,  0.7093,  0.0579,  0.6625,  0.5522])\n",
      "0 steps | score: [0.16403624415397644]\n",
      "100 steps | score: [-0.09424735605716705]\n",
      "200 steps | score: [-0.11522774398326874]\n",
      "300 steps | score: [-0.12508231401443481]\n",
      "400 steps | score: [-0.1294238418340683]\n",
      "500 steps | score: [-0.15335713326931]\n",
      "600 steps | score: [-0.12208972126245499]\n",
      "700 steps | score: [-0.11216474324464798]\n",
      "800 steps | score: [-0.13108667731285095]\n",
      "900 steps | score: [-0.12637801468372345]\n",
      "1000 steps | score: [-0.148495614528656]\n",
      "1100 steps | score: [-0.15667136013507843]\n",
      "1200 steps | score: [-0.10562925785779953]\n",
      "1300 steps | score: [-0.12077265232801437]\n",
      "1400 steps | score: [-0.1240943968296051]\n",
      "1500 steps | score: [-0.10105986893177032]\n",
      "1600 steps | score: [-0.14905518293380737]\n",
      "1700 steps | score: [-0.11119908094406128]\n",
      "1800 steps | score: [-0.12008392810821533]\n",
      "1900 steps | score: [-0.14362935721874237]\n",
      "2000 steps | score: [-0.12347741425037384]\n",
      "2100 steps | score: [-0.14807094633579254]\n",
      "2200 steps | score: [-0.16174983978271484]\n",
      "2300 steps | score: [-0.10072106122970581]\n",
      "2400 steps | score: [-0.10848650336265564]\n",
      "2500 steps | score: [-0.09585613012313843]\n",
      "2600 steps | score: [-0.10882340371608734]\n",
      "2700 steps | score: [-0.14210912585258484]\n",
      "0 steps | score: [0.11565196514129639, 0.1822594851255417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [-0.18429811298847198, 0.6717789769172668]\n",
      "200 steps | score: [-0.1599077433347702, 0.5815553665161133]\n",
      "300 steps | score: [0.09990158677101135, 0.031118668615818024]\n",
      "400 steps | score: [-0.1714067906141281, 0.6042689085006714]\n",
      "500 steps | score: [-0.07888039201498032, 0.3887946307659149]\n",
      "600 steps | score: [-0.17587822675704956, 0.5951860547065735]\n",
      "700 steps | score: [-0.18515387177467346, 0.6101007461547852]\n",
      "800 steps | score: [-0.014292494393885136, 0.2409498393535614]\n",
      "900 steps | score: [-0.0783371701836586, 0.3908507227897644]\n",
      "1000 steps | score: [-0.1526033878326416, 0.529965341091156]\n",
      "1100 steps | score: [-0.1805366426706314, 0.5920401215553284]\n",
      "1200 steps | score: [-0.08906303346157074, 0.40177392959594727]\n",
      "1300 steps | score: [-0.11497812718153, 0.4548942744731903]\n",
      "1400 steps | score: [0.049914371222257614, 0.0669068917632103]\n",
      "1500 steps | score: [0.09025857597589493, -0.05276854336261749]\n",
      "1600 steps | score: [0.007220541592687368, 0.15373806655406952]\n",
      "1700 steps | score: [-0.04945017769932747, 0.27621492743492126]\n",
      "1800 steps | score: [-0.03608711063861847, 0.2656708061695099]\n",
      "1900 steps | score: [-0.13242915272712708, 0.4878136217594147]\n",
      "2000 steps | score: [0.029114965349435806, 0.12545239925384521]\n",
      "2100 steps | score: [-0.10085106641054153, 0.43071913719177246]\n",
      "2200 steps | score: [-0.013449097983539104, 0.19859378039836884]\n",
      "2300 steps | score: [0.0804835855960846, -0.012694690376520157]\n",
      "2400 steps | score: [-0.09713608026504517, 0.4079474210739136]\n",
      "2500 steps | score: [0.06131913512945175, 0.04284767061471939]\n",
      "2600 steps | score: [-0.0740477442741394, 0.3314017653465271]\n",
      "2700 steps | score: [-0.06579633802175522, 0.32695838809013367]\n",
      "unknown params:  tensor([-0.6176, -0.0120,  0.6533,  0.0634,  0.5867,  0.4154])\n",
      "gt params:  tensor([-0.6848, -0.0372,  0.7093,  0.0579,  0.6625,  0.5522])\n",
      "ols params:  tensor([-0.3525, -0.0056,  0.3651,  0.0382,  0.3350,  3.4768])\n",
      "unknown mse:  tensor(0.0055)\n",
      "ols mse:  tensor(1.4818)\n",
      "gt params:  tensor([-0.7084, -0.0289,  0.7073,  0.0442,  0.6513,  0.5861])\n",
      "0 steps | score: [0.3320115804672241]\n",
      "100 steps | score: [0.07575046271085739]\n",
      "200 steps | score: [0.07356679439544678]\n",
      "300 steps | score: [0.10370182991027832]\n",
      "400 steps | score: [0.07474847882986069]\n",
      "500 steps | score: [0.08253458142280579]\n",
      "600 steps | score: [0.04892333596944809]\n",
      "700 steps | score: [0.001313135027885437]\n",
      "0 steps | score: [0.049895718693733215, 0.23963379859924316]\n",
      "100 steps | score: [-0.14047829806804657, 0.514362633228302]\n",
      "200 steps | score: [0.03520563989877701, 0.08256582915782928]\n",
      "300 steps | score: [0.09260419756174088, -0.07253829389810562]\n",
      "400 steps | score: [-0.12186428904533386, 0.4095480442047119]\n",
      "500 steps | score: [-0.09861277043819427, 0.3620889186859131]\n",
      "600 steps | score: [-0.1962880641222, 0.5290729999542236]\n",
      "700 steps | score: [-0.15996594727039337, 0.4914250373840332]\n",
      "800 steps | score: [-0.08962248265743256, 0.32402682304382324]\n",
      "900 steps | score: [-0.1478589028120041, 0.42771559953689575]\n",
      "1000 steps | score: [-0.04536990076303482, 0.20549185574054718]\n",
      "1100 steps | score: [-0.0878770723938942, 0.2916427254676819]\n",
      "1200 steps | score: [-0.24082180857658386, 0.6190174221992493]\n",
      "1300 steps | score: [-0.15043824911117554, 0.43556034564971924]\n",
      "1400 steps | score: [-0.061116743832826614, 0.22606605291366577]\n",
      "1500 steps | score: [-0.1532604843378067, 0.44031357765197754]\n",
      "1600 steps | score: [-0.12590143084526062, 0.3795441687107086]\n",
      "1700 steps | score: [-0.23004905879497528, 0.6208022236824036]\n",
      "1800 steps | score: [-0.19082656502723694, 0.5376166105270386]\n",
      "1900 steps | score: [-0.09255748987197876, 0.2779090404510498]\n",
      "2000 steps | score: [-0.04434780776500702, 0.21257779002189636]\n",
      "2100 steps | score: [-0.13114409148693085, 0.3671397566795349]\n",
      "2200 steps | score: [-0.019510438665747643, 0.1388969123363495]\n",
      "2300 steps | score: [-0.1826210469007492, 0.49300417304039]\n",
      "2400 steps | score: [-0.16390767693519592, 0.43278974294662476]\n",
      "2500 steps | score: [-0.042188502848148346, 0.2028268575668335]\n",
      "2600 steps | score: [-0.16670626401901245, 0.47016531229019165]\n",
      "2700 steps | score: [-0.10082998871803284, 0.29985618591308594]\n",
      "unknown params:  tensor([-0.7433, -0.0408,  0.7646,  0.0319,  0.6705,  0.3735])\n",
      "gt params:  tensor([-0.7084, -0.0289,  0.7073,  0.0442,  0.6513,  0.5861])\n",
      "ols params:  tensor([-0.3718, -0.0225,  0.3789,  0.0224,  0.3366,  3.5975])\n",
      "unknown mse:  tensor(0.0084)\n",
      "ols mse:  tensor(1.5649)\n",
      "gt params:  tensor([-0.6490, -0.0251,  0.6978,  0.0735,  0.6682,  0.5613])\n",
      "0 steps | score: [0.2914524972438812]\n",
      "100 steps | score: [-0.009083885699510574]\n",
      "0 steps | score: [0.3970700204372406, -0.6242772936820984]\n",
      "100 steps | score: [0.20504605770111084, -0.38711509108543396]\n",
      "200 steps | score: [0.002196726854890585, -0.009289130568504333]\n",
      "unknown params:  tensor([-0.4709, -0.0096,  0.5046,  0.0888,  0.4828,  0.7739])\n",
      "gt params:  tensor([-0.6490, -0.0251,  0.6978,  0.0735,  0.6682,  0.5613])\n",
      "ols params:  tensor([-0.3383, -0.0221,  0.3602,  0.0596,  0.3506,  3.6291])\n",
      "unknown mse:  tensor(0.0248)\n",
      "ols mse:  tensor(1.6204)\n",
      "gt params:  tensor([-0.6891, -0.0182,  0.7178,  0.0589,  0.6885,  0.6756])\n",
      "0 steps | score: [0.278891921043396]\n",
      "100 steps | score: [0.0405043326318264]\n",
      "200 steps | score: [-0.0013552196323871613]\n",
      "0 steps | score: [0.33130785822868347, -0.4575621485710144]\n",
      "100 steps | score: [0.20271266996860504, -0.3218414783477783]\n",
      "200 steps | score: [0.03774689882993698, -0.04226743057370186]\n",
      "300 steps | score: [0.3540751338005066, -0.7192237973213196]\n",
      "400 steps | score: [0.05999118462204933, -0.0823538601398468]\n",
      "500 steps | score: [-0.07003571838140488, 0.14195965230464935]\n",
      "600 steps | score: [-0.02199007384479046, 0.04944593459367752]\n",
      "700 steps | score: [0.06623087078332901, -0.09429876506328583]\n",
      "800 steps | score: [0.13323882222175598, -0.24834731221199036]\n",
      "900 steps | score: [0.23154190182685852, -0.4707493782043457]\n",
      "1000 steps | score: [0.34398311376571655, -0.7338992357254028]\n",
      "1100 steps | score: [0.36720457673072815, -0.7862159013748169]\n",
      "1200 steps | score: [0.172383651137352, -0.37349575757980347]\n",
      "1300 steps | score: [0.11371276527643204, -0.21083280444145203]\n",
      "1400 steps | score: [0.14600048959255219, -0.27285611629486084]\n",
      "1500 steps | score: [0.20846955478191376, -0.41941848397254944]\n",
      "1600 steps | score: [0.019123690202832222, -0.019093018025159836]\n",
      "1700 steps | score: [0.11612755805253983, -0.2404251992702484]\n",
      "1800 steps | score: [0.0525193028151989, -0.09525422751903534]\n",
      "1900 steps | score: [0.05897322669625282, -0.13263700902462006]\n",
      "2000 steps | score: [0.13626110553741455, -0.25952479243278503]\n",
      "2100 steps | score: [0.23124539852142334, -0.4776180684566498]\n",
      "2200 steps | score: [0.23903144896030426, -0.5153532028198242]\n",
      "2300 steps | score: [0.1603795289993286, -0.3248656094074249]\n",
      "2400 steps | score: [0.0996483862400055, -0.20561367273330688]\n",
      "2500 steps | score: [0.09089881926774979, -0.18878473341464996]\n",
      "2600 steps | score: [0.1433504968881607, -0.27469402551651]\n",
      "2700 steps | score: [0.09434831142425537, -0.16889184713363647]\n",
      "unknown params:  tensor([-0.6981, -0.0269,  0.7659,  0.0578,  0.7039,  0.4141])\n",
      "gt params:  tensor([-0.6891, -0.0182,  0.7178,  0.0589,  0.6885,  0.6756])\n",
      "ols params:  tensor([-0.3447, -0.0098,  0.3749,  0.0299,  0.3451,  3.8131])\n",
      "unknown mse:  tensor(0.0119)\n",
      "ols mse:  tensor(1.6998)\n",
      "gt params:  tensor([-0.6670, -0.0278,  0.7540,  0.0653,  0.6584,  0.5599])\n",
      "0 steps | score: [0.012930180877447128]\n",
      "100 steps | score: [-0.28642410039901733]\n",
      "200 steps | score: [-0.19737374782562256]\n",
      "300 steps | score: [-0.2320842444896698]\n",
      "400 steps | score: [-0.2878084182739258]\n",
      "500 steps | score: [-0.22408224642276764]\n",
      "600 steps | score: [-0.24575351178646088]\n",
      "700 steps | score: [-0.2382822334766388]\n",
      "800 steps | score: [-0.24110259115695953]\n",
      "900 steps | score: [-0.28562429547309875]\n",
      "1000 steps | score: [-0.27109524607658386]\n",
      "1100 steps | score: [-0.28397083282470703]\n",
      "1200 steps | score: [-0.2574157416820526]\n",
      "1300 steps | score: [-0.26102158427238464]\n",
      "1400 steps | score: [-0.2767684757709503]\n",
      "1500 steps | score: [-0.27112019062042236]\n",
      "1600 steps | score: [-0.26447126269340515]\n",
      "1700 steps | score: [-0.2760297656059265]\n",
      "1800 steps | score: [-0.23383641242980957]\n",
      "1900 steps | score: [-0.2422974407672882]\n",
      "2000 steps | score: [-0.2602880895137787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 steps | score: [-0.2571225166320801]\n",
      "2200 steps | score: [-0.25281447172164917]\n",
      "2300 steps | score: [-0.2779133915901184]\n",
      "2400 steps | score: [-0.23689617216587067]\n",
      "2500 steps | score: [-0.2528764009475708]\n",
      "2600 steps | score: [-0.2469206154346466]\n",
      "2700 steps | score: [-0.2542262673377991]\n",
      "0 steps | score: [0.06647824496030807, -0.1283740997314453]\n",
      "100 steps | score: [-0.06362468004226685, 0.012680165469646454]\n",
      "200 steps | score: [-0.015366517938673496, -0.17484557628631592]\n",
      "300 steps | score: [0.031567323952913284, -0.31559979915618896]\n",
      "400 steps | score: [-0.22662998735904694, 0.2686893939971924]\n",
      "500 steps | score: [0.0356844924390316, -0.3746127486228943]\n",
      "600 steps | score: [0.051255278289318085, -0.42348915338516235]\n",
      "700 steps | score: [-0.2076379358768463, 0.2025804966688156]\n",
      "800 steps | score: [-0.017275048419833183, -0.2335851639509201]\n",
      "900 steps | score: [-0.03897879272699356, -0.1162753701210022]\n",
      "1000 steps | score: [-0.12873677909374237, 0.030999451875686646]\n",
      "1100 steps | score: [-0.13044710457324982, 0.024049431085586548]\n",
      "1200 steps | score: [0.07326141744852066, -0.4730631411075592]\n",
      "1300 steps | score: [-0.25152236223220825, 0.299418181180954]\n",
      "1400 steps | score: [-0.23704175651073456, 0.2605993151664734]\n",
      "1500 steps | score: [-0.09222175925970078, -0.0288442000746727]\n",
      "1600 steps | score: [-0.005285703111439943, -0.27331605553627014]\n",
      "1700 steps | score: [-0.04920836165547371, -0.1732843518257141]\n",
      "1800 steps | score: [0.04809236153960228, -0.4031788110733032]\n",
      "1900 steps | score: [-0.06320708990097046, -0.13625288009643555]\n",
      "2000 steps | score: [-0.14701220393180847, 0.07322835922241211]\n",
      "2100 steps | score: [-0.16057756543159485, 0.10903694480657578]\n",
      "2200 steps | score: [-0.1193227469921112, -0.021126851439476013]\n",
      "2300 steps | score: [-0.08872263133525848, -0.06023706495761871]\n",
      "2400 steps | score: [-0.07925552129745483, -0.06453786790370941]\n",
      "2500 steps | score: [-0.21236300468444824, 0.17515814304351807]\n",
      "2600 steps | score: [-0.09667929261922836, -0.05669774115085602]\n",
      "2700 steps | score: [-0.06137586012482643, -0.13160201907157898]\n",
      "unknown params:  tensor([-0.6702, -0.0341,  0.7426,  0.0390,  0.6453,  0.3631])\n",
      "gt params:  tensor([-0.6670, -0.0278,  0.7540,  0.0653,  0.6584,  0.5599])\n",
      "ols params:  tensor([-0.3302, -0.0181,  0.3612,  0.0213,  0.3196,  3.8694])\n",
      "unknown mse:  tensor(0.0066)\n",
      "ols mse:  tensor(1.8896)\n",
      "gt params:  tensor([-0.6488, -0.0385,  0.7220,  0.0490,  0.6763,  0.6327])\n",
      "0 steps | score: [0.008086178451776505]\n",
      "100 steps | score: [-0.25814107060432434]\n",
      "200 steps | score: [-0.22109395265579224]\n",
      "300 steps | score: [-0.22084100544452667]\n",
      "400 steps | score: [-0.2730613946914673]\n",
      "500 steps | score: [-0.3173114061355591]\n",
      "600 steps | score: [-0.2781965136528015]\n",
      "700 steps | score: [-0.2460680603981018]\n",
      "800 steps | score: [-0.21267709136009216]\n",
      "900 steps | score: [-0.2515687644481659]\n",
      "1000 steps | score: [-0.2966874837875366]\n",
      "1100 steps | score: [-0.31461411714553833]\n",
      "1200 steps | score: [-0.28326836228370667]\n",
      "1300 steps | score: [-0.2760428190231323]\n",
      "1400 steps | score: [-0.23044456541538239]\n",
      "1500 steps | score: [-0.2599184513092041]\n",
      "1600 steps | score: [-0.2855389714241028]\n",
      "1700 steps | score: [-0.28831207752227783]\n",
      "1800 steps | score: [-0.2779507637023926]\n",
      "1900 steps | score: [-0.25466060638427734]\n",
      "2000 steps | score: [-0.26336878538131714]\n",
      "2100 steps | score: [-0.26731130480766296]\n",
      "2200 steps | score: [-0.3085564076900482]\n",
      "2300 steps | score: [-0.2687493562698364]\n",
      "2400 steps | score: [-0.27331626415252686]\n",
      "2500 steps | score: [-0.2750158905982971]\n",
      "2600 steps | score: [-0.2895543575286865]\n",
      "2700 steps | score: [-0.2940397560596466]\n",
      "0 steps | score: [0.03827859088778496, 0.16140776872634888]\n",
      "100 steps | score: [-0.015032864175736904, 0.18768346309661865]\n",
      "200 steps | score: [-0.03464232385158539, 0.13229969143867493]\n",
      "300 steps | score: [0.03347993269562721, -0.036156829446554184]\n",
      "400 steps | score: [-0.27545997500419617, 0.6027017831802368]\n",
      "500 steps | score: [-0.25761643052101135, 0.5655757188796997]\n",
      "600 steps | score: [-0.17691931128501892, 0.4000071883201599]\n",
      "700 steps | score: [0.08547436445951462, -0.21852615475654602]\n",
      "800 steps | score: [-0.2118072211742401, 0.47325071692466736]\n",
      "900 steps | score: [-0.15153032541275024, 0.34506499767303467]\n",
      "1000 steps | score: [-0.23302191495895386, 0.5200989842414856]\n",
      "1100 steps | score: [-0.1456546038389206, 0.32511112093925476]\n",
      "1200 steps | score: [-0.2547091245651245, 0.5584195852279663]\n",
      "1300 steps | score: [-0.07770530134439468, 0.17473717033863068]\n",
      "1400 steps | score: [-0.2137007862329483, 0.46808189153671265]\n",
      "1500 steps | score: [-0.25567907094955444, 0.5701121091842651]\n",
      "1600 steps | score: [-0.19267615675926208, 0.4137571454048157]\n",
      "1700 steps | score: [-0.10368778556585312, 0.23936718702316284]\n",
      "1800 steps | score: [-0.09263129532337189, 0.20770998299121857]\n",
      "1900 steps | score: [-0.0998944416642189, 0.23427370190620422]\n",
      "2000 steps | score: [-0.15696868300437927, 0.35616809129714966]\n",
      "2100 steps | score: [-0.23837460577487946, 0.541779100894928]\n",
      "2200 steps | score: [-0.13077229261398315, 0.2772364020347595]\n",
      "2300 steps | score: [-0.1858150064945221, 0.4192329943180084]\n",
      "2400 steps | score: [-0.11610045284032822, 0.23342940211296082]\n",
      "2500 steps | score: [-0.12905842065811157, 0.2981739938259125]\n",
      "2600 steps | score: [-0.18040601909160614, 0.4006366431713104]\n",
      "2700 steps | score: [-0.21654540300369263, 0.4692816138267517]\n",
      "unknown params:  tensor([-0.6111, -0.0267,  0.7288,  0.0656,  0.6465,  0.2864])\n",
      "gt params:  tensor([-0.6488, -0.0385,  0.7220,  0.0490,  0.6763,  0.6327])\n",
      "ols params:  tensor([-0.3071, -0.0159,  0.3640,  0.0343,  0.3288,  3.9654])\n",
      "unknown mse:  tensor(0.0204)\n",
      "ols mse:  tensor(1.9123)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/27237978-b606-4a69-99bf-1669f072f520\n",
      "gt params:  tensor([-0.4502, -0.1515,  0.3160, -0.6047, -0.0831,  0.1110])\n",
      "0 steps | score: [0.02714923769235611]\n",
      "100 steps | score: [-0.05668828263878822]\n",
      "200 steps | score: [-0.1454755663871765]\n",
      "300 steps | score: [0.0012517217546701431]\n",
      "0 steps | score: [0.36158740520477295, -0.6783133745193481]\n",
      "100 steps | score: [-0.09698741883039474, 0.6270754933357239]\n",
      "200 steps | score: [0.33161503076553345, -0.9295653700828552]\n",
      "300 steps | score: [0.6160032749176025, -2.0616607666015625]\n",
      "400 steps | score: [0.1559205949306488, -0.29082968831062317]\n",
      "500 steps | score: [-0.1358056515455246, 0.622815728187561]\n",
      "600 steps | score: [0.2742270827293396, -0.7369203567504883]\n",
      "700 steps | score: [0.06732753664255142, -0.009630892425775528]\n",
      "800 steps | score: [0.037050072103738785, 0.06338794529438019]\n",
      "900 steps | score: [-0.08354857563972473, 0.44746237993240356]\n",
      "1000 steps | score: [0.2519795596599579, -0.7300442457199097]\n",
      "1100 steps | score: [0.25774863362312317, -0.7084026336669922]\n",
      "1200 steps | score: [0.09568291157484055, -0.14424556493759155]\n",
      "1300 steps | score: [0.04913747310638428, 0.06425297260284424]\n",
      "1400 steps | score: [0.031078863888978958, 0.05331731587648392]\n",
      "1500 steps | score: [0.20980314910411835, -0.637642502784729]\n",
      "1600 steps | score: [0.2904013991355896, -0.8908364176750183]\n",
      "1700 steps | score: [0.21729381382465363, -0.6141197681427002]\n",
      "1800 steps | score: [0.45521125197410583, -1.580017328262329]\n",
      "1900 steps | score: [0.18223416805267334, -0.4408412575721741]\n",
      "2000 steps | score: [0.1297762095928192, -0.2862336039543152]\n",
      "2100 steps | score: [0.05787932500243187, -0.005000479519367218]\n",
      "2200 steps | score: [0.3201451599597931, -0.9405198693275452]\n",
      "2300 steps | score: [0.18732506036758423, -0.4863733649253845]\n",
      "2400 steps | score: [0.13235965371131897, -0.30169612169265747]\n",
      "2500 steps | score: [0.1582861840724945, -0.3703514337539673]\n",
      "unknown params:  tensor([-0.4589, -0.1580,  0.3250, -0.6096, -0.0857,  0.1250])\n",
      "gt params:  tensor([-0.4502, -0.1515,  0.3160, -0.6047, -0.0831,  0.1110])\n",
      "ols params:  tensor([-0.3610, -0.1259,  0.2561, -0.4735, -0.0693,  0.7683])\n",
      "unknown mse:  tensor(7.1104e-05)\n",
      "ols mse:  tensor(0.0770)\n",
      "gt params:  tensor([-0.4494, -0.1510,  0.3226, -0.6071, -0.0870,  0.1081])\n",
      "0 steps | score: [0.2564598619937897]\n",
      "100 steps | score: [0.08271057158708572]\n",
      "200 steps | score: [0.1259128302335739]\n",
      "300 steps | score: [0.04765886440873146]\n",
      "400 steps | score: [0.0042517296969890594]\n",
      "0 steps | score: [-0.11470987647771835, 0.6631759405136108]\n",
      "100 steps | score: [-0.3164563775062561, 1.0416738986968994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [-0.24242548644542694, 0.7376589775085449]\n",
      "300 steps | score: [-0.13503216207027435, 0.3986476957798004]\n",
      "400 steps | score: [-0.4556886553764343, 1.3111530542373657]\n",
      "500 steps | score: [-0.036651089787483215, 0.04189169406890869]\n",
      "600 steps | score: [-0.20939740538597107, 0.6237136125564575]\n",
      "700 steps | score: [-0.2555435299873352, 0.7473897933959961]\n",
      "800 steps | score: [-0.024566104635596275, 0.04338417947292328]\n",
      "900 steps | score: [-0.2777597904205322, 0.8198997974395752]\n",
      "1000 steps | score: [-0.08698718249797821, 0.24526485800743103]\n",
      "1100 steps | score: [-0.200949028134346, 0.6015279293060303]\n",
      "1200 steps | score: [-0.446590393781662, 1.2697091102600098]\n",
      "1300 steps | score: [-0.3220810294151306, 0.9438607096672058]\n",
      "1400 steps | score: [-0.18067367374897003, 0.5289022922515869]\n",
      "1500 steps | score: [-0.20236821472644806, 0.562707245349884]\n",
      "1600 steps | score: [-0.16641679406166077, 0.4725381135940552]\n",
      "1700 steps | score: [-0.2598779499530792, 0.7238444089889526]\n",
      "1800 steps | score: [-0.2778577506542206, 0.8080060482025146]\n",
      "1900 steps | score: [-0.2572813630104065, 0.729826807975769]\n",
      "2000 steps | score: [-0.2682654559612274, 0.7618701457977295]\n",
      "2100 steps | score: [-0.3305569291114807, 0.9311275482177734]\n",
      "2200 steps | score: [-0.2136424034833908, 0.617053210735321]\n",
      "2300 steps | score: [-0.33562424778938293, 0.9483593106269836]\n",
      "2400 steps | score: [-0.20731498301029205, 0.5421748757362366]\n",
      "2500 steps | score: [-0.25242331624031067, 0.7324209213256836]\n",
      "unknown params:  tensor([-0.4708, -0.1641,  0.3351, -0.6296, -0.0818,  0.0370])\n",
      "gt params:  tensor([-0.4494, -0.1510,  0.3226, -0.6071, -0.0870,  0.1081])\n",
      "ols params:  tensor([-0.3173, -0.1103,  0.2291, -0.4136, -0.0537,  1.1390])\n",
      "unknown mse:  tensor(0.0011)\n",
      "ols mse:  tensor(0.1882)\n",
      "gt params:  tensor([-0.4450, -0.1475,  0.3186, -0.5857, -0.0866,  0.0883])\n",
      "0 steps | score: [0.3266754150390625]\n",
      "100 steps | score: [0.08774618804454803]\n",
      "200 steps | score: [0.1305965930223465]\n",
      "300 steps | score: [0.10029201954603195]\n",
      "400 steps | score: [0.10239872336387634]\n",
      "500 steps | score: [0.1149878054857254]\n",
      "600 steps | score: [0.04906321316957474]\n",
      "700 steps | score: [0.11011718213558197]\n",
      "800 steps | score: [0.09766677021980286]\n",
      "900 steps | score: [0.06339877843856812]\n",
      "1000 steps | score: [0.08620911836624146]\n",
      "1100 steps | score: [0.04922766983509064]\n",
      "1200 steps | score: [0.10714094340801239]\n",
      "1300 steps | score: [0.07082566618919373]\n",
      "1400 steps | score: [0.0829559862613678]\n",
      "1500 steps | score: [0.09006042778491974]\n",
      "1600 steps | score: [0.07021777331829071]\n",
      "1700 steps | score: [0.08970595896244049]\n",
      "1800 steps | score: [0.07307089120149612]\n",
      "1900 steps | score: [0.08819450438022614]\n",
      "2000 steps | score: [0.08036713302135468]\n",
      "2100 steps | score: [0.08040591329336166]\n",
      "2200 steps | score: [0.06488081067800522]\n",
      "2300 steps | score: [0.06498204171657562]\n",
      "2400 steps | score: [0.08847887068986893]\n",
      "2500 steps | score: [0.11048328131437302]\n",
      "0 steps | score: [0.04036661982536316, 0.12177286297082901]\n",
      "100 steps | score: [-0.07062637060880661, 0.22760069370269775]\n",
      "200 steps | score: [-0.09557416290044785, 0.24355950951576233]\n",
      "300 steps | score: [-0.10570381581783295, 0.2226041853427887]\n",
      "400 steps | score: [-0.0858038067817688, 0.14977166056632996]\n",
      "500 steps | score: [-0.07970017939805984, 0.13899143040180206]\n",
      "600 steps | score: [-0.07262393832206726, 0.07354888319969177]\n",
      "700 steps | score: [-0.13863903284072876, 0.28937795758247375]\n",
      "800 steps | score: [-0.022244498133659363, -0.030868709087371826]\n",
      "900 steps | score: [-0.1560123711824417, 0.30670860409736633]\n",
      "1000 steps | score: [-0.09755890816450119, 0.14981073141098022]\n",
      "1100 steps | score: [0.013164699077606201, -0.17521095275878906]\n",
      "1200 steps | score: [-0.28962084650993347, 0.6463819146156311]\n",
      "1300 steps | score: [-0.20024935901165009, 0.4152511954307556]\n",
      "1400 steps | score: [-0.21385781466960907, 0.4679127335548401]\n",
      "1500 steps | score: [-0.26586103439331055, 0.5609738826751709]\n",
      "1600 steps | score: [-0.15467557311058044, 0.28425055742263794]\n",
      "1700 steps | score: [-0.18974719941616058, 0.3861474394798279]\n",
      "1800 steps | score: [-0.25123605132102966, 0.5271878242492676]\n",
      "1900 steps | score: [-0.1847781091928482, 0.3463453948497772]\n",
      "2000 steps | score: [-0.18920372426509857, 0.39139407873153687]\n",
      "2100 steps | score: [-0.2032933533191681, 0.4149089455604553]\n",
      "2200 steps | score: [-0.12114647030830383, 0.22657789289951324]\n",
      "2300 steps | score: [-0.2265046387910843, 0.47040992975234985]\n",
      "2400 steps | score: [-0.1146610677242279, 0.21209022402763367]\n",
      "2500 steps | score: [-0.1491403728723526, 0.2558158338069916]\n",
      "unknown params:  tensor([-0.4480, -0.1599,  0.3316, -0.6303, -0.0986,  0.0642])\n",
      "gt params:  tensor([-0.4450, -0.1475,  0.3186, -0.5857, -0.0866,  0.0883])\n",
      "ols params:  tensor([-0.2750, -0.0992,  0.2078, -0.3715, -0.0606,  1.4397])\n",
      "unknown mse:  tensor(0.0005)\n",
      "ols mse:  tensor(0.3194)\n",
      "gt params:  tensor([-0.4473, -0.1438,  0.3279, -0.6021, -0.0955,  0.1184])\n",
      "0 steps | score: [0.15686684846878052]\n",
      "100 steps | score: [-0.1104518324136734]\n",
      "200 steps | score: [-0.029854262247681618]\n",
      "300 steps | score: [-0.17620542645454407]\n",
      "400 steps | score: [-0.12461919337511063]\n",
      "500 steps | score: [-0.07080637663602829]\n",
      "600 steps | score: [-0.05925140902400017]\n",
      "700 steps | score: [-0.018473567441105843]\n",
      "800 steps | score: [-0.08069820702075958]\n",
      "900 steps | score: [-0.13557247817516327]\n",
      "1000 steps | score: [-0.06345103681087494]\n",
      "1100 steps | score: [-0.09120281785726547]\n",
      "1200 steps | score: [-0.029622076079249382]\n",
      "1300 steps | score: [-0.039463192224502563]\n",
      "1400 steps | score: [-0.12932217121124268]\n",
      "1500 steps | score: [-0.10586027801036835]\n",
      "1600 steps | score: [-0.08079369366168976]\n",
      "1700 steps | score: [-0.0182048249989748]\n",
      "1800 steps | score: [-0.04069418087601662]\n",
      "1900 steps | score: [-0.11602255702018738]\n",
      "2000 steps | score: [-0.0860111266374588]\n",
      "2100 steps | score: [-0.09472040832042694]\n",
      "2200 steps | score: [-0.05450824648141861]\n",
      "2300 steps | score: [-0.05011937394738197]\n",
      "2400 steps | score: [-0.08686430752277374]\n",
      "2500 steps | score: [-0.08466403186321259]\n",
      "0 steps | score: [0.1561853438615799, 0.0873994380235672]\n",
      "100 steps | score: [-0.11528991162776947, 0.5120854377746582]\n",
      "200 steps | score: [-0.10870801657438278, 0.457091361284256]\n",
      "300 steps | score: [-0.36012622714042664, 0.942112147808075]\n",
      "400 steps | score: [-0.24492929875850677, 0.7003657817840576]\n",
      "500 steps | score: [-0.03943270817399025, 0.27624446153640747]\n",
      "600 steps | score: [-0.19600670039653778, 0.6072808504104614]\n",
      "700 steps | score: [-0.026930805295705795, 0.28982770442962646]\n",
      "800 steps | score: [-0.1513528823852539, 0.539085865020752]\n",
      "900 steps | score: [-0.05023455619812012, 0.2774806022644043]\n",
      "1000 steps | score: [-0.0633002519607544, 0.3208085000514984]\n",
      "1100 steps | score: [-0.059747520834207535, 0.29186609387397766]\n",
      "1200 steps | score: [-0.12828141450881958, 0.4510933756828308]\n",
      "1300 steps | score: [0.017802683636546135, 0.13193443417549133]\n",
      "1400 steps | score: [-0.1147378534078598, 0.4063684642314911]\n",
      "1500 steps | score: [-0.07514181733131409, 0.33496522903442383]\n",
      "1600 steps | score: [-0.0258446354418993, 0.2411661446094513]\n",
      "1700 steps | score: [0.12327458709478378, -0.16366532444953918]\n",
      "1800 steps | score: [-0.051984962075948715, 0.28474754095077515]\n",
      "1900 steps | score: [-0.11894006282091141, 0.400543212890625]\n",
      "2000 steps | score: [-0.11848839372396469, 0.40765219926834106]\n",
      "2100 steps | score: [-0.018899578601121902, 0.2090185284614563]\n",
      "2200 steps | score: [0.08821974694728851, -0.08480994403362274]\n",
      "2300 steps | score: [0.03642226383090019, 0.08193540573120117]\n",
      "2400 steps | score: [-0.1969076693058014, 0.5790194869041443]\n",
      "2500 steps | score: [-0.05651536211371422, 0.29301899671554565]\n",
      "unknown params:  tensor([-0.4550, -0.1418,  0.3172, -0.6146, -0.0727, -0.0044])\n",
      "gt params:  tensor([-0.4473, -0.1438,  0.3279, -0.6021, -0.0955,  0.1184])\n",
      "ols params:  tensor([-0.2680, -0.0841,  0.1915, -0.3492, -0.0445,  1.6865])\n",
      "unknown mse:  tensor(0.0027)\n",
      "ols mse:  tensor(0.4300)\n",
      "gt params:  tensor([-0.4443, -0.1431,  0.3418, -0.5970, -0.0812,  0.1307])\n",
      "0 steps | score: [0.17505940794944763]\n",
      "100 steps | score: [-0.0724201574921608]\n",
      "200 steps | score: [-0.019788721576333046]\n",
      "300 steps | score: [-0.1214015781879425]\n",
      "400 steps | score: [-0.05412949621677399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [-0.09381064027547836]\n",
      "600 steps | score: [-0.0960347056388855]\n",
      "700 steps | score: [-0.048032600432634354]\n",
      "800 steps | score: [-0.12761661410331726]\n",
      "900 steps | score: [-0.05925021320581436]\n",
      "1000 steps | score: [-0.06323473900556564]\n",
      "1100 steps | score: [-0.10565958172082901]\n",
      "1200 steps | score: [-0.052670903503894806]\n",
      "1300 steps | score: [-0.12738409638404846]\n",
      "1400 steps | score: [-0.07566025853157043]\n",
      "1500 steps | score: [-0.04420814290642738]\n",
      "1600 steps | score: [-0.10437284409999847]\n",
      "1700 steps | score: [-0.046617329120635986]\n",
      "1800 steps | score: [-0.07031795382499695]\n",
      "1900 steps | score: [-0.07063780725002289]\n",
      "2000 steps | score: [-0.0565793514251709]\n",
      "2100 steps | score: [-0.09843520820140839]\n",
      "2200 steps | score: [-0.09029674530029297]\n",
      "2300 steps | score: [-0.04253879189491272]\n",
      "2400 steps | score: [-0.0913248360157013]\n",
      "2500 steps | score: [-0.09504728764295578]\n",
      "0 steps | score: [0.18925827741622925, -0.19190865755081177]\n",
      "100 steps | score: [-0.14416976273059845, 0.3760717809200287]\n",
      "200 steps | score: [0.36308223009109497, -0.9611120820045471]\n",
      "300 steps | score: [0.00258897733874619, -0.058116376399993896]\n",
      "400 steps | score: [0.0415206253528595, -0.1469341218471527]\n",
      "500 steps | score: [-0.12321169674396515, 0.22508999705314636]\n",
      "600 steps | score: [0.10888410359621048, -0.3283253610134125]\n",
      "700 steps | score: [-0.05808987468481064, 0.09828910231590271]\n",
      "800 steps | score: [0.04038652032613754, -0.17629210650920868]\n",
      "900 steps | score: [0.02070005051791668, -0.13472670316696167]\n",
      "1000 steps | score: [0.03836935758590698, -0.14007599651813507]\n",
      "1100 steps | score: [0.11152488738298416, -0.36892998218536377]\n",
      "1200 steps | score: [0.13000260293483734, -0.3568245470523834]\n",
      "1300 steps | score: [-0.051955487579107285, 0.07726266980171204]\n",
      "1400 steps | score: [0.05872058868408203, -0.24883724749088287]\n",
      "1500 steps | score: [0.20136596262454987, -0.5811008810997009]\n",
      "1600 steps | score: [0.02549557574093342, -0.16847234964370728]\n",
      "1700 steps | score: [0.11680898815393448, -0.3661397099494934]\n",
      "1800 steps | score: [0.07386330515146255, -0.2427227646112442]\n",
      "1900 steps | score: [0.029780356213450432, -0.16010835766792297]\n",
      "2000 steps | score: [0.09966472536325455, -0.3351691663265228]\n",
      "2100 steps | score: [-0.053137388080358505, 0.04413878545165062]\n",
      "2200 steps | score: [0.0594572015106678, -0.23507557809352875]\n",
      "2300 steps | score: [0.0561370849609375, -0.2076086699962616]\n",
      "2400 steps | score: [0.0053848521783947945, -0.1405942589044571]\n",
      "2500 steps | score: [0.10803219676017761, -0.3410574495792389]\n",
      "unknown params:  tensor([-0.4439, -0.1152,  0.3527, -0.6023, -0.0774,  0.0369])\n",
      "gt params:  tensor([-0.4443, -0.1431,  0.3418, -0.5970, -0.0812,  0.1307])\n",
      "ols params:  tensor([-0.2448, -0.0666,  0.1973, -0.3204, -0.0446,  1.9198])\n",
      "unknown mse:  tensor(0.0016)\n",
      "ols mse:  tensor(0.5575)\n",
      "gt params:  tensor([-0.4479, -0.1563,  0.3179, -0.6051, -0.0749,  0.0745])\n",
      "0 steps | score: [-0.017732735723257065]\n",
      "100 steps | score: [-0.3006610870361328]\n",
      "200 steps | score: [-0.3199891448020935]\n",
      "300 steps | score: [-0.2871975898742676]\n",
      "400 steps | score: [-0.258341908454895]\n",
      "500 steps | score: [-0.2321571707725525]\n",
      "600 steps | score: [-0.30899399518966675]\n",
      "700 steps | score: [-0.3119662404060364]\n",
      "800 steps | score: [-0.3037477135658264]\n",
      "900 steps | score: [-0.2772916555404663]\n",
      "1000 steps | score: [-0.24077045917510986]\n",
      "1100 steps | score: [-0.28662943840026855]\n",
      "1200 steps | score: [-0.27848193049430847]\n",
      "1300 steps | score: [-0.3017321825027466]\n",
      "1400 steps | score: [-0.2647554278373718]\n",
      "1500 steps | score: [-0.26475033164024353]\n",
      "1600 steps | score: [-0.3210196793079376]\n",
      "1700 steps | score: [-0.3018709123134613]\n",
      "1800 steps | score: [-0.3015478551387787]\n",
      "1900 steps | score: [-0.2975887954235077]\n",
      "2000 steps | score: [-0.290199339389801]\n",
      "2100 steps | score: [-0.3131769895553589]\n",
      "2200 steps | score: [-0.29955920577049255]\n",
      "2300 steps | score: [-0.3061163127422333]\n",
      "2400 steps | score: [-0.2804207503795624]\n",
      "2500 steps | score: [-0.2791542410850525]\n",
      "0 steps | score: [0.5048773884773254, -0.7500669956207275]\n",
      "100 steps | score: [0.22510462999343872, -0.31003913283348083]\n",
      "200 steps | score: [0.2887755334377289, -0.4938161373138428]\n",
      "300 steps | score: [0.30205515027046204, -0.5363209247589111]\n",
      "400 steps | score: [0.3286481499671936, -0.5968374013900757]\n",
      "500 steps | score: [0.5773256421089172, -1.2377841472625732]\n",
      "600 steps | score: [0.2071494311094284, -0.3608412742614746]\n",
      "700 steps | score: [0.10835585743188858, -0.15717941522598267]\n",
      "800 steps | score: [0.31903529167175293, -0.5784446001052856]\n",
      "900 steps | score: [0.29611122608184814, -0.553229570388794]\n",
      "1000 steps | score: [0.4755219519138336, -0.9742958545684814]\n",
      "1100 steps | score: [0.3565114140510559, -0.7132815718650818]\n",
      "1200 steps | score: [0.1885843724012375, -0.2977987229824066]\n",
      "1300 steps | score: [0.2743397355079651, -0.5183504223823547]\n",
      "1400 steps | score: [0.2923462390899658, -0.5158001184463501]\n",
      "1500 steps | score: [0.3930453956127167, -0.8041409850120544]\n",
      "1600 steps | score: [0.32981568574905396, -0.6539708971977234]\n",
      "1700 steps | score: [0.28280192613601685, -0.5217572450637817]\n",
      "1800 steps | score: [0.3619022071361542, -0.7457207441329956]\n",
      "1900 steps | score: [0.33977973461151123, -0.6802476644515991]\n",
      "2000 steps | score: [0.4010060429573059, -0.8320187926292419]\n",
      "2100 steps | score: [0.33781054615974426, -0.6701942086219788]\n",
      "2200 steps | score: [0.3605615794658661, -0.7329103350639343]\n",
      "2300 steps | score: [0.30340543389320374, -0.5535413026809692]\n",
      "2400 steps | score: [0.36012569069862366, -0.7589775323867798]\n",
      "2500 steps | score: [0.4029405415058136, -0.8121827244758606]\n",
      "unknown params:  tensor([-0.4434, -0.1705,  0.3386, -0.6433, -0.0695, -0.0077])\n",
      "gt params:  tensor([-0.4479, -0.1563,  0.3179, -0.6051, -0.0749,  0.0745])\n",
      "ols params:  tensor([-0.2305, -0.0917,  0.1758, -0.3170, -0.0366,  2.0787])\n",
      "unknown mse:  tensor(0.0015)\n",
      "ols mse:  tensor(0.6955)\n",
      "gt params:  tensor([-0.4634, -0.1497,  0.3208, -0.6098, -0.0825,  0.0795])\n",
      "0 steps | score: [0.5161474347114563]\n",
      "100 steps | score: [0.23266646265983582]\n",
      "200 steps | score: [0.19096535444259644]\n",
      "300 steps | score: [0.19192908704280853]\n",
      "400 steps | score: [0.2093023955821991]\n",
      "500 steps | score: [0.27099505066871643]\n",
      "600 steps | score: [0.19966311752796173]\n",
      "700 steps | score: [0.21625681221485138]\n",
      "800 steps | score: [0.20331020653247833]\n",
      "900 steps | score: [0.2254674732685089]\n",
      "1000 steps | score: [0.2285383939743042]\n",
      "1100 steps | score: [0.2477392554283142]\n",
      "1200 steps | score: [0.259080708026886]\n",
      "1300 steps | score: [0.22454380989074707]\n",
      "1400 steps | score: [0.25122949481010437]\n",
      "1500 steps | score: [0.22038552165031433]\n",
      "1600 steps | score: [0.2599512040615082]\n",
      "1700 steps | score: [0.22523963451385498]\n",
      "1800 steps | score: [0.2330474555492401]\n",
      "1900 steps | score: [0.26671579480171204]\n",
      "2000 steps | score: [0.24927783012390137]\n",
      "2100 steps | score: [0.24887993931770325]\n",
      "2200 steps | score: [0.23996108770370483]\n",
      "2300 steps | score: [0.22730597853660583]\n",
      "2400 steps | score: [0.23580898344516754]\n",
      "2500 steps | score: [0.23566657304763794]\n",
      "0 steps | score: [0.17125746607780457, -0.1953718364238739]\n",
      "100 steps | score: [-0.008274589665234089, 0.02722100168466568]\n",
      "200 steps | score: [-0.1281100958585739, 0.21037161350250244]\n",
      "300 steps | score: [-0.017145641148090363, -0.009184502065181732]\n",
      "400 steps | score: [-0.0066698770970106125, -0.030144155025482178]\n",
      "500 steps | score: [0.029489781707525253, -0.14834365248680115]\n",
      "600 steps | score: [-0.15353521704673767, 0.2556779682636261]\n",
      "700 steps | score: [-0.04659120365977287, -0.008199907839298248]\n",
      "800 steps | score: [-0.028361529111862183, -0.013984732329845428]\n",
      "900 steps | score: [-0.10388144850730896, 0.1504666805267334]\n",
      "1000 steps | score: [0.042612336575984955, -0.17536544799804688]\n",
      "1100 steps | score: [-0.07463569194078445, 0.07099748402833939]\n",
      "1200 steps | score: [0.03507106751203537, -0.13866573572158813]\n",
      "1300 steps | score: [-0.11352252215147018, 0.17319157719612122]\n",
      "1400 steps | score: [-0.026070915162563324, -0.030534014105796814]\n",
      "1500 steps | score: [-0.11832549422979355, 0.17721393704414368]\n",
      "1600 steps | score: [-0.04885563254356384, 0.04160749912261963]\n",
      "1700 steps | score: [-0.08117930591106415, 0.09200850129127502]\n",
      "1800 steps | score: [-0.07004042714834213, 0.042398951947689056]\n",
      "1900 steps | score: [-0.07110854983329773, 0.047227874398231506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 steps | score: [-0.06792695075273514, 0.024734850972890854]\n",
      "2100 steps | score: [-0.0006914273835718632, -0.07511136680841446]\n",
      "2200 steps | score: [-0.09488173574209213, 0.13450199365615845]\n",
      "2300 steps | score: [-0.030391260981559753, -0.018581755459308624]\n",
      "2400 steps | score: [0.05262316018342972, -0.17691609263420105]\n",
      "2500 steps | score: [-0.020812196657061577, -0.017791442573070526]\n",
      "unknown params:  tensor([-0.4801, -0.1510,  0.3286, -0.6224, -0.0834,  0.1970])\n",
      "gt params:  tensor([-0.4634, -0.1497,  0.3208, -0.6098, -0.0825,  0.0795])\n",
      "ols params:  tensor([-0.2333, -0.0751,  0.1644, -0.2971, -0.0398,  2.2551])\n",
      "unknown mse:  tensor(0.0024)\n",
      "ols mse:  tensor(0.8193)\n",
      "gt params:  tensor([-0.4353, -0.1511,  0.3187, -0.5933, -0.0946,  0.0711])\n",
      "0 steps | score: [0.32655036449432373]\n",
      "100 steps | score: [0.06133299693465233]\n",
      "200 steps | score: [0.009582379832863808]\n",
      "0 steps | score: [-0.023200439289212227, 0.4098707437515259]\n",
      "100 steps | score: [-0.019531046971678734, 0.24354320764541626]\n",
      "200 steps | score: [-0.48316025733947754, 1.12255859375]\n",
      "300 steps | score: [0.2092680037021637, -0.5177738666534424]\n",
      "400 steps | score: [-0.30065813660621643, 0.751702606678009]\n",
      "500 steps | score: [-0.2355726957321167, 0.6006011962890625]\n",
      "600 steps | score: [-0.08894143998622894, 0.2775881290435791]\n",
      "700 steps | score: [-0.2060546725988388, 0.5658077001571655]\n",
      "800 steps | score: [-0.07526182383298874, 0.23787036538124084]\n",
      "900 steps | score: [-0.3078671097755432, 0.7695777416229248]\n",
      "1000 steps | score: [-0.21735642850399017, 0.5717957019805908]\n",
      "1100 steps | score: [-0.1741315871477127, 0.4854649305343628]\n",
      "1200 steps | score: [-0.25276198983192444, 0.6387938261032104]\n",
      "1300 steps | score: [-0.20391465723514557, 0.5413723587989807]\n",
      "1400 steps | score: [-0.11471199989318848, 0.3467881381511688]\n",
      "1500 steps | score: [-0.0017382345395162702, 0.05484149605035782]\n",
      "1600 steps | score: [-0.16465920209884644, 0.44548657536506653]\n",
      "1700 steps | score: [-0.11317839473485947, 0.3454707860946655]\n",
      "1800 steps | score: [-0.24213971197605133, 0.6098573207855225]\n",
      "1900 steps | score: [-0.25455835461616516, 0.6573675870895386]\n",
      "2000 steps | score: [-0.17300724983215332, 0.45552849769592285]\n",
      "2100 steps | score: [-0.20143817365169525, 0.5227078199386597]\n",
      "2200 steps | score: [-0.19829870760440826, 0.5256528854370117]\n",
      "2300 steps | score: [-0.2202524095773697, 0.5827702283859253]\n",
      "2400 steps | score: [-0.26921746134757996, 0.6614049077033997]\n",
      "2500 steps | score: [-0.22769559919834137, 0.557113528251648]\n",
      "unknown params:  tensor([-0.4486, -0.1587,  0.3346, -0.5979, -0.0710,  0.1106])\n",
      "gt params:  tensor([-0.4353, -0.1511,  0.3187, -0.5933, -0.0946,  0.0711])\n",
      "ols params:  tensor([-0.2124, -0.0762,  0.1627, -0.2801, -0.0365,  2.3623])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(0.9051)\n",
      "gt params:  tensor([-0.4523, -0.1509,  0.3323, -0.5964, -0.0727,  0.1332])\n",
      "0 steps | score: [0.2555563151836395]\n",
      "100 steps | score: [-0.038685642182826996]\n",
      "200 steps | score: [0.013383213430643082]\n",
      "300 steps | score: [-0.03733764588832855]\n",
      "400 steps | score: [-0.01609642431139946]\n",
      "500 steps | score: [-0.06383314728736877]\n",
      "600 steps | score: [-0.06334468722343445]\n",
      "700 steps | score: [0.031885210424661636]\n",
      "800 steps | score: [-0.011657078750431538]\n",
      "900 steps | score: [-0.021836750209331512]\n",
      "1000 steps | score: [-0.05424441769719124]\n",
      "1100 steps | score: [-0.03502249717712402]\n",
      "1200 steps | score: [-0.011046310886740685]\n",
      "1300 steps | score: [0.020660964772105217]\n",
      "1400 steps | score: [0.0019027311354875565]\n",
      "0 steps | score: [0.09731274843215942, 0.22080321609973907]\n",
      "100 steps | score: [0.0003616707108449191, 0.2378934919834137]\n",
      "200 steps | score: [-0.05859020724892616, 0.319316565990448]\n",
      "300 steps | score: [-0.21971480548381805, 0.6634519696235657]\n",
      "400 steps | score: [0.032830461859703064, 0.10549245774745941]\n",
      "500 steps | score: [0.01844146102666855, 0.14301662147045135]\n",
      "600 steps | score: [-0.28279343247413635, 0.7405397891998291]\n",
      "700 steps | score: [0.07245420664548874, 0.007750213146209717]\n",
      "800 steps | score: [0.054525814950466156, 0.00986403226852417]\n",
      "900 steps | score: [-0.17339615523815155, 0.5696114897727966]\n",
      "1000 steps | score: [-0.12344751507043839, 0.43034473061561584]\n",
      "1100 steps | score: [-0.22820286452770233, 0.6441605687141418]\n",
      "1200 steps | score: [-0.0314774326980114, 0.2695406675338745]\n",
      "1300 steps | score: [-0.06613489240407944, 0.29431208968162537]\n",
      "1400 steps | score: [-0.08075539767742157, 0.33124688267707825]\n",
      "1500 steps | score: [-0.20382528007030487, 0.6169415712356567]\n",
      "1600 steps | score: [0.01471860520541668, 0.13066896796226501]\n",
      "1700 steps | score: [0.008696482516825199, 0.10311788320541382]\n",
      "1800 steps | score: [-0.10288883000612259, 0.38326603174209595]\n",
      "1900 steps | score: [-0.04151942580938339, 0.2687855362892151]\n",
      "2000 steps | score: [-0.08292170614004135, 0.33859962224960327]\n",
      "2100 steps | score: [0.00015111573156900704, 0.16378627717494965]\n",
      "2200 steps | score: [-0.06087624654173851, 0.2982155978679657]\n",
      "2300 steps | score: [-0.0026122990529984236, 0.1271379590034485]\n",
      "2400 steps | score: [-0.03807626664638519, 0.22027066349983215]\n",
      "2500 steps | score: [-0.12676985561847687, 0.4332253634929657]\n",
      "unknown params:  tensor([-0.4440, -0.1414,  0.3058, -0.5110, -0.0631,  0.1811])\n",
      "gt params:  tensor([-0.4523, -0.1509,  0.3323, -0.5964, -0.0727,  0.1332])\n",
      "ols params:  tensor([-0.2324, -0.0774,  0.1623, -0.2635, -0.0345,  2.5735])\n",
      "unknown mse:  tensor(0.0018)\n",
      "ols mse:  tensor(1.0250)\n",
      "gt params:  tensor([-0.4364, -0.1482,  0.3314, -0.6048, -0.0767,  0.1001])\n",
      "0 steps | score: [0.3330637216567993]\n",
      "100 steps | score: [-0.03660941123962402]\n",
      "200 steps | score: [-0.011110387742519379]\n",
      "300 steps | score: [0.007693979889154434]\n",
      "0 steps | score: [0.4664032459259033, -0.8144915103912354]\n",
      "100 steps | score: [0.1526721566915512, -0.3261356055736542]\n",
      "200 steps | score: [0.08278723806142807, -0.27086159586906433]\n",
      "300 steps | score: [0.502387523651123, -1.1814064979553223]\n",
      "400 steps | score: [0.4624776840209961, -1.0753082036972046]\n",
      "500 steps | score: [0.24707065522670746, -0.5948182940483093]\n",
      "600 steps | score: [0.26291757822036743, -0.6514008045196533]\n",
      "700 steps | score: [0.3578993082046509, -0.8481064438819885]\n",
      "800 steps | score: [0.32274186611175537, -0.7803351879119873]\n",
      "900 steps | score: [0.4191628098487854, -0.9793340563774109]\n",
      "1000 steps | score: [0.2689785361289978, -0.6523136496543884]\n",
      "1100 steps | score: [0.1868952214717865, -0.4924764931201935]\n",
      "1200 steps | score: [0.19141043722629547, -0.49025318026542664]\n",
      "1300 steps | score: [0.363637775182724, -0.8050127029418945]\n",
      "1400 steps | score: [0.26569071412086487, -0.6756627559661865]\n",
      "1500 steps | score: [0.24621844291687012, -0.599122166633606]\n",
      "1600 steps | score: [0.31860747933387756, -0.7876459360122681]\n",
      "1700 steps | score: [0.20471462607383728, -0.5155035257339478]\n",
      "1800 steps | score: [0.25934091210365295, -0.6656583547592163]\n",
      "1900 steps | score: [0.2019028514623642, -0.5108723044395447]\n",
      "2000 steps | score: [0.23881438374519348, -0.5811191201210022]\n",
      "2100 steps | score: [0.250190794467926, -0.6065494418144226]\n",
      "2200 steps | score: [0.1913699507713318, -0.5243498682975769]\n",
      "2300 steps | score: [0.24363593757152557, -0.6367613077163696]\n",
      "2400 steps | score: [0.31032177805900574, -0.7422767281532288]\n",
      "2500 steps | score: [0.2793136537075043, -0.7099352478981018]\n",
      "unknown params:  tensor([-0.4179, -0.1292,  0.3218, -0.6055, -0.0255, -0.0806])\n",
      "gt params:  tensor([-0.4364, -0.1482,  0.3314, -0.6048, -0.0767,  0.1001])\n",
      "ols params:  tensor([-0.1964, -0.0632,  0.1528, -0.2775, -0.0134,  2.6986])\n",
      "unknown mse:  tensor(0.0060)\n",
      "ols mse:  tensor(1.1600)\n",
      "gt params:  tensor([-0.4417, -0.1344,  0.3020, -0.5879, -0.0770,  0.0439])\n",
      "0 steps | score: [0.45246657729148865]\n",
      "100 steps | score: [0.1271858513355255]\n",
      "200 steps | score: [0.19313539564609528]\n",
      "300 steps | score: [0.0866234302520752]\n",
      "400 steps | score: [0.1368589699268341]\n",
      "500 steps | score: [0.11799245327711105]\n",
      "600 steps | score: [0.12751270830631256]\n",
      "700 steps | score: [0.1673993170261383]\n",
      "800 steps | score: [0.10866305232048035]\n",
      "900 steps | score: [0.1215767115354538]\n",
      "1000 steps | score: [0.09162493050098419]\n",
      "1100 steps | score: [0.1408141404390335]\n",
      "1200 steps | score: [0.16523832082748413]\n",
      "1300 steps | score: [0.107497438788414]\n",
      "1400 steps | score: [0.11553475260734558]\n",
      "1500 steps | score: [0.12403935194015503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 steps | score: [0.13355576992034912]\n",
      "1700 steps | score: [0.12430281192064285]\n",
      "1800 steps | score: [0.14936085045337677]\n",
      "1900 steps | score: [0.14268261194229126]\n",
      "2000 steps | score: [0.12297306209802628]\n",
      "2100 steps | score: [0.11866209656000137]\n",
      "2200 steps | score: [0.16706296801567078]\n",
      "2300 steps | score: [0.1114249974489212]\n",
      "2400 steps | score: [0.12475429475307465]\n",
      "2500 steps | score: [0.10373683273792267]\n",
      "0 steps | score: [0.4205319583415985, -0.603026807308197]\n",
      "100 steps | score: [0.2838350534439087, -0.4107567369937897]\n",
      "200 steps | score: [0.43667322397232056, -0.848904013633728]\n",
      "300 steps | score: [-0.05304601415991783, 0.11131934076547623]\n",
      "400 steps | score: [0.10559365153312683, -0.1714347004890442]\n",
      "500 steps | score: [0.43562525510787964, -0.9493399858474731]\n",
      "600 steps | score: [0.1874023824930191, -0.35566461086273193]\n",
      "700 steps | score: [0.24987344443798065, -0.5042537450790405]\n",
      "800 steps | score: [0.27334582805633545, -0.5766293406486511]\n",
      "900 steps | score: [0.3716869056224823, -0.8172668218612671]\n",
      "1000 steps | score: [0.13206404447555542, -0.2640666961669922]\n",
      "1100 steps | score: [0.3331833481788635, -0.6824796199798584]\n",
      "1200 steps | score: [0.4023471772670746, -0.8534594178199768]\n",
      "1300 steps | score: [0.24188263714313507, -0.5084441304206848]\n",
      "1400 steps | score: [0.2609008550643921, -0.5134978890419006]\n",
      "1500 steps | score: [0.26921290159225464, -0.5563206672668457]\n",
      "1600 steps | score: [0.160812109708786, -0.31805238127708435]\n",
      "1700 steps | score: [0.29248061776161194, -0.5813944339752197]\n",
      "1800 steps | score: [0.30464082956314087, -0.6627871990203857]\n",
      "1900 steps | score: [0.2994505763053894, -0.6363639235496521]\n",
      "2000 steps | score: [0.25502732396125793, -0.5086327195167542]\n",
      "2100 steps | score: [0.2532264292240143, -0.5149784088134766]\n",
      "2200 steps | score: [0.34191933274269104, -0.7237351536750793]\n",
      "2300 steps | score: [0.2813824415206909, -0.6125117540359497]\n",
      "2400 steps | score: [0.24439510703086853, -0.5150787234306335]\n",
      "2500 steps | score: [0.28444012999534607, -0.6344954371452332]\n",
      "unknown params:  tensor([-0.4498, -0.1459,  0.3484, -0.6691, -0.0908, -0.0734])\n",
      "gt params:  tensor([-0.4417, -0.1344,  0.3020, -0.5879, -0.0770,  0.0439])\n",
      "ols params:  tensor([-0.1876, -0.0637,  0.1464, -0.2684, -0.0366,  2.7346])\n",
      "unknown mse:  tensor(0.0038)\n",
      "ols mse:  tensor(1.2396)\n",
      "gt params:  tensor([-0.4393, -0.1720,  0.3273, -0.6249, -0.0670,  0.0650])\n",
      "0 steps | score: [0.39359933137893677]\n",
      "100 steps | score: [0.09745277464389801]\n",
      "200 steps | score: [0.09528966248035431]\n",
      "300 steps | score: [0.03221006691455841]\n",
      "400 steps | score: [0.05992000922560692]\n",
      "500 steps | score: [0.09341908991336823]\n",
      "600 steps | score: [0.0795283392071724]\n",
      "700 steps | score: [0.06705062836408615]\n",
      "800 steps | score: [0.03440694510936737]\n",
      "900 steps | score: [0.07656947523355484]\n",
      "1000 steps | score: [0.09449440240859985]\n",
      "1100 steps | score: [0.0879540741443634]\n",
      "1200 steps | score: [0.07817760854959488]\n",
      "1300 steps | score: [0.07371267676353455]\n",
      "1400 steps | score: [0.07114066183567047]\n",
      "1500 steps | score: [0.08406409621238708]\n",
      "1600 steps | score: [0.0782877504825592]\n",
      "1700 steps | score: [0.08566659688949585]\n",
      "1800 steps | score: [0.08813035488128662]\n",
      "1900 steps | score: [0.055436644703149796]\n",
      "2000 steps | score: [0.08222050219774246]\n",
      "2100 steps | score: [0.09364798665046692]\n",
      "2200 steps | score: [0.10129532963037491]\n",
      "2300 steps | score: [0.11586807668209076]\n",
      "2400 steps | score: [0.08079273998737335]\n",
      "2500 steps | score: [0.08972544968128204]\n",
      "0 steps | score: [0.07394933700561523, 0.13546086847782135]\n",
      "100 steps | score: [0.0565529502928257, 0.033582933247089386]\n",
      "200 steps | score: [0.009550969116389751, 0.0940210372209549]\n",
      "300 steps | score: [-0.17490461468696594, 0.4230576157569885]\n",
      "400 steps | score: [-0.14539361000061035, 0.40649011731147766]\n",
      "500 steps | score: [-0.06400714069604874, 0.21172818541526794]\n",
      "600 steps | score: [-0.19266480207443237, 0.48921167850494385]\n",
      "700 steps | score: [-0.10427400469779968, 0.2847594916820526]\n",
      "800 steps | score: [-0.22259405255317688, 0.524904727935791]\n",
      "900 steps | score: [-0.13385942578315735, 0.34681665897369385]\n",
      "1000 steps | score: [-0.06530794501304626, 0.1875101625919342]\n",
      "1100 steps | score: [-0.022099904716014862, 0.0803912878036499]\n",
      "1200 steps | score: [-0.03546632453799248, 0.1278204470872879]\n",
      "1300 steps | score: [-0.16897547245025635, 0.4115586280822754]\n",
      "1400 steps | score: [-0.08891575038433075, 0.23488730192184448]\n",
      "1500 steps | score: [-0.095497727394104, 0.2650015354156494]\n",
      "1600 steps | score: [-0.02579973265528679, 0.10244523733854294]\n",
      "1700 steps | score: [-0.12033214420080185, 0.2657017707824707]\n",
      "1800 steps | score: [-0.0882691740989685, 0.211040198802948]\n",
      "1900 steps | score: [-0.07744625210762024, 0.21710741519927979]\n",
      "2000 steps | score: [-0.09348578751087189, 0.26508715748786926]\n",
      "2100 steps | score: [-0.002829201053828001, 0.07285673171281815]\n",
      "2200 steps | score: [-0.03711271658539772, 0.14305979013442993]\n",
      "2300 steps | score: [0.047380413860082626, -0.050836771726608276]\n",
      "2400 steps | score: [-0.12941060960292816, 0.3381175994873047]\n",
      "2500 steps | score: [0.06909791380167007, -0.12520015239715576]\n",
      "unknown params:  tensor([-0.4216, -0.1722,  0.3198, -0.6573, -0.0353,  0.0093])\n",
      "gt params:  tensor([-0.4393, -0.1720,  0.3273, -0.6249, -0.0670,  0.0650])\n",
      "ols params:  tensor([-0.1833, -0.0723,  0.1417, -0.2754, -0.0163,  2.8822])\n",
      "unknown mse:  tensor(0.0009)\n",
      "ols mse:  tensor(1.3619)\n",
      "gt params:  tensor([-0.4480, -0.1617,  0.3160, -0.6066, -0.1004,  0.0952])\n",
      "0 steps | score: [0.27052032947540283]\n",
      "100 steps | score: [-0.11060310155153275]\n",
      "200 steps | score: [-0.01267595961689949]\n",
      "300 steps | score: [-0.06400540471076965]\n",
      "400 steps | score: [-0.05170802026987076]\n",
      "500 steps | score: [-0.09249886125326157]\n",
      "600 steps | score: [-0.11863625049591064]\n",
      "700 steps | score: [-0.009387310594320297]\n",
      "0 steps | score: [0.19650448858737946, -0.021487943828105927]\n",
      "100 steps | score: [-0.10980880260467529, 0.456769734621048]\n",
      "200 steps | score: [0.5118292570114136, -1.1106301546096802]\n",
      "300 steps | score: [-0.08210813254117966, 0.3041287660598755]\n",
      "400 steps | score: [0.08020143955945969, -0.08690555393695831]\n",
      "500 steps | score: [0.03487304225564003, 0.07806834578514099]\n",
      "600 steps | score: [-0.03145662322640419, 0.1730252504348755]\n",
      "700 steps | score: [0.11571584641933441, -0.14709211885929108]\n",
      "800 steps | score: [-0.07970506697893143, 0.2905082702636719]\n",
      "900 steps | score: [0.001624533673748374, 0.12455745786428452]\n",
      "1000 steps | score: [-0.018669413402676582, 0.2004619687795639]\n",
      "1100 steps | score: [-0.03560708090662956, 0.21450647711753845]\n",
      "1200 steps | score: [-0.05844865366816521, 0.22265809774398804]\n",
      "1300 steps | score: [0.19842438399791718, -0.3558412790298462]\n",
      "1400 steps | score: [0.2986784279346466, -0.5938685536384583]\n",
      "1500 steps | score: [0.3196865916252136, -0.6955540180206299]\n",
      "1600 steps | score: [0.004172124434262514, 0.10823473334312439]\n",
      "1700 steps | score: [0.1733977496623993, -0.2917802333831787]\n",
      "1800 steps | score: [0.009899592027068138, 0.12141315639019012]\n",
      "1900 steps | score: [0.10258007049560547, -0.09862768650054932]\n",
      "2000 steps | score: [0.1372956931591034, -0.18628588318824768]\n",
      "2100 steps | score: [0.0622476264834404, -0.020555656403303146]\n",
      "2200 steps | score: [0.04016294702887535, -0.004160961136221886]\n",
      "2300 steps | score: [-0.06411215662956238, 0.25139319896698]\n",
      "2400 steps | score: [0.06564689427614212, -0.03277752175927162]\n",
      "2500 steps | score: [0.03431005775928497, 0.042242154479026794]\n",
      "unknown params:  tensor([-0.4175, -0.1356,  0.3160, -0.5605, -0.0810, -0.0511])\n",
      "gt params:  tensor([-0.4480, -0.1617,  0.3160, -0.6066, -0.1004,  0.0952])\n",
      "ols params:  tensor([-0.1976, -0.0665,  0.1495, -0.2571, -0.0422,  3.0034])\n",
      "unknown mse:  tensor(0.0043)\n",
      "ols mse:  tensor(1.4471)\n",
      "gt params:  tensor([-0.4555, -0.1323,  0.3302, -0.5896, -0.0732,  0.1024])\n",
      "0 steps | score: [0.24570101499557495]\n",
      "100 steps | score: [-0.022586427628993988]\n",
      "200 steps | score: [-0.04299667477607727]\n",
      "300 steps | score: [-0.10078679025173187]\n",
      "400 steps | score: [-0.041062261909246445]\n",
      "500 steps | score: [-0.14862340688705444]\n",
      "600 steps | score: [-0.07582785934209824]\n",
      "700 steps | score: [-0.045434173196554184]\n",
      "800 steps | score: [-0.06791570037603378]\n",
      "900 steps | score: [-0.07426130771636963]\n",
      "1000 steps | score: [-0.13046269118785858]\n",
      "1100 steps | score: [-0.09173216670751572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 steps | score: [-0.05578263849020004]\n",
      "1300 steps | score: [-0.05174802243709564]\n",
      "1400 steps | score: [-0.06541142612695694]\n",
      "1500 steps | score: [-0.12208083271980286]\n",
      "1600 steps | score: [-0.08442384749650955]\n",
      "1700 steps | score: [-0.058624498546123505]\n",
      "1800 steps | score: [-0.05608479678630829]\n",
      "1900 steps | score: [-0.1118299663066864]\n",
      "2000 steps | score: [-0.09471314400434494]\n",
      "2100 steps | score: [-0.08112271130084991]\n",
      "2200 steps | score: [-0.05354004353284836]\n",
      "2300 steps | score: [-0.08339983224868774]\n",
      "2400 steps | score: [-0.08669747412204742]\n",
      "2500 steps | score: [-0.0797165110707283]\n",
      "0 steps | score: [0.11989008635282516, 0.11123225837945938]\n",
      "100 steps | score: [0.06273271888494492, 0.13515600562095642]\n",
      "200 steps | score: [-0.17949815094470978, 0.5128695964813232]\n",
      "300 steps | score: [-0.2602296769618988, 0.641156017780304]\n",
      "400 steps | score: [0.10500852018594742, -0.1037684977054596]\n",
      "500 steps | score: [0.03968369588255882, 0.049528032541275024]\n",
      "600 steps | score: [0.03933119773864746, 0.04209425300359726]\n",
      "700 steps | score: [0.20195509493350983, -0.3703368008136749]\n",
      "800 steps | score: [-0.12530280649662018, 0.3798713982105255]\n",
      "900 steps | score: [-0.10484453290700912, 0.3415450155735016]\n",
      "1000 steps | score: [-0.23313239216804504, 0.6092228889465332]\n",
      "1100 steps | score: [-0.08996134996414185, 0.3094099462032318]\n",
      "1200 steps | score: [-0.1985330581665039, 0.5256272554397583]\n",
      "1300 steps | score: [-0.09895263612270355, 0.3167802095413208]\n",
      "1400 steps | score: [-0.12404915690422058, 0.36401596665382385]\n",
      "1500 steps | score: [-0.30164605379104614, 0.6865955591201782]\n",
      "1600 steps | score: [-0.05756700783967972, 0.24752089381217957]\n",
      "1700 steps | score: [-0.08717764914035797, 0.2965743839740753]\n",
      "1800 steps | score: [-0.07658844441175461, 0.2716560661792755]\n",
      "1900 steps | score: [-0.16885513067245483, 0.4609418511390686]\n",
      "2000 steps | score: [-0.19107680022716522, 0.4851967394351959]\n",
      "2100 steps | score: [-0.12976709008216858, 0.39261987805366516]\n",
      "2200 steps | score: [-0.02665673941373825, 0.1711343377828598]\n",
      "2300 steps | score: [-0.035467084497213364, 0.1857653707265854]\n",
      "2400 steps | score: [-0.09871023148298264, 0.30545422434806824]\n",
      "2500 steps | score: [-0.13227607309818268, 0.3745604157447815]\n",
      "unknown params:  tensor([-0.4139, -0.1133,  0.2943, -0.5427, -0.0981,  0.1047])\n",
      "gt params:  tensor([-0.4555, -0.1323,  0.3302, -0.5896, -0.0732,  0.1024])\n",
      "ols params:  tensor([-0.1949, -0.0547,  0.1416, -0.2525, -0.0478,  3.1669])\n",
      "unknown mse:  tensor(0.0010)\n",
      "ols mse:  tensor(1.6024)\n",
      "gt params:  tensor([-0.4473, -0.1563,  0.3417, -0.5972, -0.0937,  0.1190])\n",
      "0 steps | score: [0.47902894020080566]\n",
      "100 steps | score: [0.17452959716320038]\n",
      "200 steps | score: [0.137067511677742]\n",
      "300 steps | score: [0.1744818091392517]\n",
      "400 steps | score: [0.14346125721931458]\n",
      "500 steps | score: [0.11936764419078827]\n",
      "600 steps | score: [0.16502414643764496]\n",
      "700 steps | score: [0.13817299902439117]\n",
      "800 steps | score: [0.16420169174671173]\n",
      "900 steps | score: [0.1456371247768402]\n",
      "1000 steps | score: [0.12807466089725494]\n",
      "1100 steps | score: [0.14182661473751068]\n",
      "1200 steps | score: [0.1328645795583725]\n",
      "1300 steps | score: [0.1590064913034439]\n",
      "1400 steps | score: [0.1431453824043274]\n",
      "1500 steps | score: [0.14717386662960052]\n",
      "1600 steps | score: [0.14458289742469788]\n",
      "1700 steps | score: [0.13108789920806885]\n",
      "1800 steps | score: [0.14419154822826385]\n",
      "1900 steps | score: [0.1531144380569458]\n",
      "2000 steps | score: [0.1618746817111969]\n",
      "2100 steps | score: [0.14188508689403534]\n",
      "2200 steps | score: [0.1480383723974228]\n",
      "2300 steps | score: [0.16079773008823395]\n",
      "2400 steps | score: [0.16341833770275116]\n",
      "2500 steps | score: [0.16329483687877655]\n",
      "0 steps | score: [0.4053489863872528, -0.5407449007034302]\n",
      "100 steps | score: [0.11927676200866699, -0.07091797143220901]\n",
      "200 steps | score: [0.28382331132888794, -0.4418940544128418]\n",
      "300 steps | score: [0.4009391963481903, -0.7642972469329834]\n",
      "400 steps | score: [0.2905026972293854, -0.515316367149353]\n",
      "500 steps | score: [0.3116057217121124, -0.5840569138526917]\n",
      "600 steps | score: [0.27533552050590515, -0.47136443853378296]\n",
      "700 steps | score: [0.18394729495048523, -0.28332066535949707]\n",
      "800 steps | score: [0.19260133802890778, -0.35542547702789307]\n",
      "900 steps | score: [0.18871398270130157, -0.33811816573143005]\n",
      "1000 steps | score: [0.1663450002670288, -0.29278039932250977]\n",
      "1100 steps | score: [0.3128126859664917, -0.5638405084609985]\n",
      "1200 steps | score: [0.04981178045272827, -0.037944644689559937]\n",
      "1300 steps | score: [0.2840637266635895, -0.5422117710113525]\n",
      "1400 steps | score: [0.19386805593967438, -0.3385472595691681]\n",
      "1500 steps | score: [0.1888047754764557, -0.3293871283531189]\n",
      "1600 steps | score: [0.2933279871940613, -0.562716543674469]\n",
      "1700 steps | score: [0.2455841600894928, -0.4397120177745819]\n",
      "1800 steps | score: [0.28501296043395996, -0.5221508741378784]\n",
      "1900 steps | score: [0.22650672495365143, -0.385685533285141]\n",
      "2000 steps | score: [0.16906830668449402, -0.2950303256511688]\n",
      "2100 steps | score: [0.29053252935409546, -0.5615026950836182]\n",
      "2200 steps | score: [0.2923373579978943, -0.5162012577056885]\n",
      "2300 steps | score: [0.2680321931838989, -0.5025194883346558]\n",
      "2400 steps | score: [0.2391088306903839, -0.44162631034851074]\n",
      "2500 steps | score: [0.2285124659538269, -0.4232347309589386]\n",
      "unknown params:  tensor([-0.4366, -0.2018,  0.2748, -0.5537, -0.1080,  0.0794])\n",
      "gt params:  tensor([-0.4473, -0.1563,  0.3417, -0.5972, -0.0937,  0.1190])\n",
      "ols params:  tensor([-0.1970, -0.0925,  0.1276, -0.2463, -0.0498,  3.2765])\n",
      "unknown mse:  tensor(0.0017)\n",
      "ols mse:  tensor(1.7012)\n",
      "gt params:  tensor([-0.4285, -0.1615,  0.3073, -0.6109, -0.0862,  0.0690])\n",
      "0 steps | score: [0.433463990688324]\n",
      "100 steps | score: [0.11774075031280518]\n",
      "200 steps | score: [0.0710892528295517]\n",
      "300 steps | score: [0.11457594484090805]\n",
      "400 steps | score: [0.07324571907520294]\n",
      "500 steps | score: [0.14464488625526428]\n",
      "600 steps | score: [0.10298596322536469]\n",
      "700 steps | score: [0.0943143218755722]\n",
      "800 steps | score: [0.09487686306238174]\n",
      "900 steps | score: [0.07783561944961548]\n",
      "1000 steps | score: [0.1387457400560379]\n",
      "1100 steps | score: [0.12426342815160751]\n",
      "1200 steps | score: [0.11042429506778717]\n",
      "1300 steps | score: [0.06418071687221527]\n",
      "1400 steps | score: [0.10392136871814728]\n",
      "1500 steps | score: [0.12823261320590973]\n",
      "1600 steps | score: [0.09975768625736237]\n",
      "1700 steps | score: [0.10846520960330963]\n",
      "1800 steps | score: [0.08900193870067596]\n",
      "1900 steps | score: [0.06430189311504364]\n",
      "2000 steps | score: [0.11555743962526321]\n",
      "2100 steps | score: [0.09704718738794327]\n",
      "2200 steps | score: [0.10530606657266617]\n",
      "2300 steps | score: [0.0967215895652771]\n",
      "2400 steps | score: [0.09790504723787308]\n",
      "2500 steps | score: [0.1047452986240387]\n",
      "0 steps | score: [0.26578885316848755, -0.37599045038223267]\n",
      "100 steps | score: [0.14240451157093048, -0.2817172706127167]\n",
      "200 steps | score: [-0.13361132144927979, 0.20143425464630127]\n",
      "300 steps | score: [0.110659658908844, -0.3045692443847656]\n",
      "400 steps | score: [0.06184303015470505, -0.2526666522026062]\n",
      "500 steps | score: [0.004878870211541653, -0.08362569659948349]\n",
      "600 steps | score: [0.11220769584178925, -0.3363018035888672]\n",
      "700 steps | score: [-0.04293567314743996, -0.03665950894355774]\n",
      "800 steps | score: [0.282900869846344, -0.7202572226524353]\n",
      "900 steps | score: [0.036044709384441376, -0.1802937388420105]\n",
      "1000 steps | score: [0.11914242804050446, -0.36942005157470703]\n",
      "1100 steps | score: [0.06484030932188034, -0.2403373122215271]\n",
      "1200 steps | score: [0.16623744368553162, -0.4514467716217041]\n",
      "1300 steps | score: [0.02979450486600399, -0.16439089179039001]\n",
      "1400 steps | score: [-0.019258055835962296, -0.08699974417686462]\n",
      "1500 steps | score: [0.11479344964027405, -0.325224369764328]\n",
      "1600 steps | score: [0.05316491425037384, -0.19197186827659607]\n",
      "1700 steps | score: [0.1260502189397812, -0.35852208733558655]\n",
      "1800 steps | score: [-0.0584014467895031, -0.010071814060211182]\n",
      "1900 steps | score: [-0.0027590389363467693, -0.13084295392036438]\n",
      "2000 steps | score: [0.04303543642163277, -0.21975213289260864]\n",
      "2100 steps | score: [0.07836178690195084, -0.25876086950302124]\n",
      "2200 steps | score: [0.10555758327245712, -0.36013728380203247]\n",
      "2300 steps | score: [0.05119679495692253, -0.22893622517585754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 steps | score: [0.09679530560970306, -0.33513420820236206]\n",
      "2500 steps | score: [0.1174500584602356, -0.3758530020713806]\n",
      "unknown params:  tensor([-0.4513, -0.1750,  0.3328, -0.5956, -0.0816,  0.0096])\n",
      "gt params:  tensor([-0.4285, -0.1615,  0.3073, -0.6109, -0.0862,  0.0690])\n",
      "ols params:  tensor([-0.1959, -0.0775,  0.1463, -0.2551, -0.0376,  3.2993])\n",
      "unknown mse:  tensor(0.0009)\n",
      "ols mse:  tensor(1.7752)\n",
      "gt params:  tensor([-0.4638, -0.1378,  0.3268, -0.6061, -0.0923,  0.0867])\n",
      "0 steps | score: [0.16963955760002136]\n",
      "100 steps | score: [-0.19212763011455536]\n",
      "200 steps | score: [-0.10285212844610214]\n",
      "300 steps | score: [-0.11823928356170654]\n",
      "400 steps | score: [-0.12986253201961517]\n",
      "500 steps | score: [-0.10012083500623703]\n",
      "600 steps | score: [-0.19055140018463135]\n",
      "700 steps | score: [-0.12790484726428986]\n",
      "800 steps | score: [-0.09387192875146866]\n",
      "900 steps | score: [-0.13580003380775452]\n",
      "1000 steps | score: [-0.11153385043144226]\n",
      "1100 steps | score: [-0.1841425746679306]\n",
      "1200 steps | score: [-0.12967318296432495]\n",
      "1300 steps | score: [-0.10929176211357117]\n",
      "1400 steps | score: [-0.11423241347074509]\n",
      "1500 steps | score: [-0.11064082384109497]\n",
      "1600 steps | score: [-0.1719302237033844]\n",
      "1700 steps | score: [-0.179645374417305]\n",
      "1800 steps | score: [-0.12595637142658234]\n",
      "1900 steps | score: [-0.12368110567331314]\n",
      "2000 steps | score: [-0.12190641462802887]\n",
      "2100 steps | score: [-0.15169347822666168]\n",
      "2200 steps | score: [-0.1266329288482666]\n",
      "2300 steps | score: [-0.1259482204914093]\n",
      "2400 steps | score: [-0.13420622050762177]\n",
      "2500 steps | score: [-0.1253931075334549]\n",
      "0 steps | score: [-0.05784230679273605, 0.3455275595188141]\n",
      "100 steps | score: [-0.12125582993030548, 0.3733031749725342]\n",
      "200 steps | score: [-0.05705665796995163, 0.13197140395641327]\n",
      "300 steps | score: [-0.24869060516357422, 0.5399911403656006]\n",
      "400 steps | score: [-0.14888468384742737, 0.3215477168560028]\n",
      "500 steps | score: [0.1426558494567871, -0.3988538980484009]\n",
      "600 steps | score: [-0.23429900407791138, 0.4795582592487335]\n",
      "700 steps | score: [-0.28128141164779663, 0.5382179021835327]\n",
      "800 steps | score: [-0.18666644394397736, 0.3780006170272827]\n",
      "900 steps | score: [-0.17026622593402863, 0.3496575355529785]\n",
      "1000 steps | score: [-0.3165815770626068, 0.6486913561820984]\n",
      "1100 steps | score: [-0.382434219121933, 0.7622721195220947]\n",
      "1200 steps | score: [0.11829391866922379, -0.4386399984359741]\n",
      "1300 steps | score: [-0.2735820412635803, 0.5475139617919922]\n",
      "1400 steps | score: [-0.33908724784851074, 0.6651308536529541]\n",
      "1500 steps | score: [-0.18172821402549744, 0.37121400237083435]\n",
      "1600 steps | score: [-0.2972343862056732, 0.6155733466148376]\n",
      "1700 steps | score: [-0.2825840413570404, 0.5691251754760742]\n",
      "1800 steps | score: [-0.20988255739212036, 0.4038330316543579]\n",
      "1900 steps | score: [-0.32794123888015747, 0.656768262386322]\n",
      "2000 steps | score: [-0.214641273021698, 0.4028540551662445]\n",
      "2100 steps | score: [-0.34680771827697754, 0.6857205033302307]\n",
      "2200 steps | score: [-0.23236846923828125, 0.44522398710250854]\n",
      "2300 steps | score: [-0.2095164656639099, 0.39575326442718506]\n",
      "2400 steps | score: [-0.28688111901283264, 0.5934872627258301]\n",
      "2500 steps | score: [-0.18528325855731964, 0.3651520907878876]\n",
      "unknown params:  tensor([-0.4996, -0.0891,  0.2840, -0.6808, -0.0303,  0.0436])\n",
      "gt params:  tensor([-0.4638, -0.1378,  0.3268, -0.6061, -0.0923,  0.0867])\n",
      "ols params:  tensor([-0.2093, -0.0367,  0.1229, -0.2775, -0.0150,  3.4168])\n",
      "unknown mse:  tensor(0.0028)\n",
      "ols mse:  tensor(1.8867)\n",
      "gt params:  tensor([-0.4321, -0.1585,  0.3097, -0.6212, -0.0974,  0.0324])\n",
      "0 steps | score: [0.09560760855674744]\n",
      "100 steps | score: [-0.14854981005191803]\n",
      "200 steps | score: [-0.1971634030342102]\n",
      "300 steps | score: [-0.18339574337005615]\n",
      "400 steps | score: [-0.18518485128879547]\n",
      "500 steps | score: [-0.18621650338172913]\n",
      "600 steps | score: [-0.14362134039402008]\n",
      "700 steps | score: [-0.2138177752494812]\n",
      "800 steps | score: [-0.16921912133693695]\n",
      "900 steps | score: [-0.19694200158119202]\n",
      "1000 steps | score: [-0.1979874074459076]\n",
      "1100 steps | score: [-0.15710079669952393]\n",
      "1200 steps | score: [-0.21264514327049255]\n",
      "1300 steps | score: [-0.20124125480651855]\n",
      "1400 steps | score: [-0.19303007423877716]\n",
      "1500 steps | score: [-0.18607455492019653]\n",
      "1600 steps | score: [-0.18229058384895325]\n",
      "1700 steps | score: [-0.18501800298690796]\n",
      "1800 steps | score: [-0.2026551514863968]\n",
      "1900 steps | score: [-0.1763945072889328]\n",
      "2000 steps | score: [-0.19676856696605682]\n",
      "2100 steps | score: [-0.20394080877304077]\n",
      "2200 steps | score: [-0.19458165764808655]\n",
      "2300 steps | score: [-0.21099787950515747]\n",
      "2400 steps | score: [-0.19581343233585358]\n",
      "2500 steps | score: [-0.21279358863830566]\n",
      "2600 steps | score: [-0.18402805924415588]\n",
      "2700 steps | score: [-0.2038908451795578]\n",
      "2800 steps | score: [-0.20907308161258698]\n",
      "2900 steps | score: [-0.19876503944396973]\n",
      "0 steps | score: [0.1632588803768158, 0.08374542742967606]\n",
      "100 steps | score: [0.061364881694316864, 0.16161759197711945]\n",
      "200 steps | score: [0.3369143605232239, -0.5208907723426819]\n",
      "300 steps | score: [-0.1556597799062729, 0.5139676332473755]\n",
      "400 steps | score: [0.09215734899044037, 0.01829141192138195]\n",
      "500 steps | score: [0.12778083980083466, -0.044000156223773956]\n",
      "600 steps | score: [0.1554899960756302, -0.1590803563594818]\n",
      "700 steps | score: [0.04462996497750282, 0.10999900102615356]\n",
      "800 steps | score: [0.011576810851693153, 0.16804763674736023]\n",
      "900 steps | score: [0.0584193654358387, 0.08934520930051804]\n",
      "1000 steps | score: [0.1435520201921463, -0.11298488080501556]\n",
      "1100 steps | score: [0.18199600279331207, -0.19992884993553162]\n",
      "1200 steps | score: [0.12955743074417114, -0.0978398472070694]\n",
      "1300 steps | score: [0.05248124897480011, 0.0808006003499031]\n",
      "1400 steps | score: [0.0809856504201889, -0.01565835066139698]\n",
      "1500 steps | score: [0.03396490216255188, 0.15586204826831818]\n",
      "1600 steps | score: [0.17530594766139984, -0.21658718585968018]\n",
      "1700 steps | score: [0.059485647827386856, 0.033851224929094315]\n",
      "1800 steps | score: [0.016473010182380676, 0.15550808608531952]\n",
      "1900 steps | score: [0.04819068685173988, 0.07378921657800674]\n",
      "2000 steps | score: [0.012808777391910553, 0.16350282728672028]\n",
      "2100 steps | score: [0.18505506217479706, -0.22402708232402802]\n",
      "2200 steps | score: [0.008161372505128384, 0.18035531044006348]\n",
      "2300 steps | score: [0.00434691458940506, 0.17846614122390747]\n",
      "2400 steps | score: [0.09856659919023514, 0.023836715146899223]\n",
      "2500 steps | score: [-0.02286597527563572, 0.22552898526191711]\n",
      "2600 steps | score: [0.09824679046869278, -0.02979143336415291]\n",
      "2700 steps | score: [0.014187059365212917, 0.14511118829250336]\n",
      "2800 steps | score: [0.01512611098587513, 0.1647941917181015]\n",
      "2900 steps | score: [0.025205515325069427, 0.09539063274860382]\n",
      "unknown params:  tensor([-0.3949, -0.1384,  0.2542, -0.5409, -0.0695,  0.2051])\n",
      "gt params:  tensor([-0.4321, -0.1585,  0.3097, -0.6212, -0.0974,  0.0324])\n",
      "ols params:  tensor([-0.1742, -0.0628,  0.1163, -0.2317, -0.0318,  3.5573])\n",
      "unknown mse:  tensor(0.0070)\n",
      "ols mse:  tensor(2.1156)\n",
      "gt params:  tensor([-0.4540, -0.1477,  0.3280, -0.6209, -0.0994,  0.1441])\n",
      "0 steps | score: [0.3145348131656647]\n",
      "100 steps | score: [-0.028701534494757652]\n",
      "200 steps | score: [-0.005355628207325935]\n",
      "0 steps | score: [0.21044187247753143, -0.3548341989517212]\n",
      "100 steps | score: [-0.05229358375072479, 0.03848644345998764]\n",
      "200 steps | score: [0.5761149525642395, -1.5597518682479858]\n",
      "300 steps | score: [0.06949290633201599, -0.29123955965042114]\n",
      "400 steps | score: [-0.03625761345028877, -0.05718996375799179]\n",
      "500 steps | score: [0.19251152873039246, -0.6059514880180359]\n",
      "600 steps | score: [0.2977011203765869, -0.8388811945915222]\n",
      "700 steps | score: [-0.10444218665361404, 0.030277397483587265]\n",
      "800 steps | score: [0.008066965267062187, -0.16342952847480774]\n",
      "900 steps | score: [0.0876917913556099, -0.3576878309249878]\n",
      "1000 steps | score: [0.2093072235584259, -0.6379414796829224]\n",
      "1100 steps | score: [0.013767403550446033, -0.1944379061460495]\n",
      "1200 steps | score: [-0.11425404250621796, 0.08036225289106369]\n",
      "1300 steps | score: [0.023094676434993744, -0.22147879004478455]\n",
      "1400 steps | score: [0.22794397175312042, -0.6788261532783508]\n",
      "1500 steps | score: [0.16699489951133728, -0.528837263584137]\n",
      "1600 steps | score: [0.11317578703165054, -0.39841723442077637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 steps | score: [0.04557866230607033, -0.26265841722488403]\n",
      "1800 steps | score: [-0.03782593086361885, -0.10043826699256897]\n",
      "1900 steps | score: [-0.012457329779863358, -0.15697064995765686]\n",
      "2000 steps | score: [0.03624635934829712, -0.25376319885253906]\n",
      "2100 steps | score: [0.10076281428337097, -0.39375579357147217]\n",
      "2200 steps | score: [0.1530502438545227, -0.49833929538726807]\n",
      "2300 steps | score: [-0.016972778365015984, -0.11056675016880035]\n",
      "2400 steps | score: [0.0008699976606294513, -0.187651127576828]\n",
      "2500 steps | score: [0.033696457743644714, -0.20938768982887268]\n",
      "unknown params:  tensor([-0.5120, -0.1708,  0.3073, -0.6397, -0.0430,  0.1732])\n",
      "gt params:  tensor([-0.4540, -0.1477,  0.3280, -0.6209, -0.0994,  0.1441])\n",
      "ols params:  tensor([-0.2082, -0.0741,  0.1321, -0.2637, -0.0171,  3.6502])\n",
      "unknown mse:  tensor(0.0015)\n",
      "ols mse:  tensor(2.0886)\n",
      "gt params:  tensor([-0.4363, -0.1330,  0.3261, -0.6326, -0.0861,  0.0836])\n",
      "0 steps | score: [0.5109639763832092]\n",
      "100 steps | score: [0.18265226483345032]\n",
      "200 steps | score: [0.2220085859298706]\n",
      "300 steps | score: [0.21361945569515228]\n",
      "400 steps | score: [0.22633793950080872]\n",
      "500 steps | score: [0.18538402020931244]\n",
      "600 steps | score: [0.1415439248085022]\n",
      "700 steps | score: [0.17546847462654114]\n",
      "800 steps | score: [0.18474815785884857]\n",
      "900 steps | score: [0.23706649243831635]\n",
      "1000 steps | score: [0.19500260055065155]\n",
      "1100 steps | score: [0.16111934185028076]\n",
      "1200 steps | score: [0.19345387816429138]\n",
      "1300 steps | score: [0.19873201847076416]\n",
      "1400 steps | score: [0.206795334815979]\n",
      "1500 steps | score: [0.19276295602321625]\n",
      "1600 steps | score: [0.18471625447273254]\n",
      "1700 steps | score: [0.17684972286224365]\n",
      "1800 steps | score: [0.17226186394691467]\n",
      "1900 steps | score: [0.17042717337608337]\n",
      "2000 steps | score: [0.20632967352867126]\n",
      "2100 steps | score: [0.1753241866827011]\n",
      "2200 steps | score: [0.1631350964307785]\n",
      "2300 steps | score: [0.17572951316833496]\n",
      "2400 steps | score: [0.18170136213302612]\n",
      "2500 steps | score: [0.17842674255371094]\n",
      "0 steps | score: [-0.10953611135482788, 0.45715081691741943]\n",
      "100 steps | score: [-0.3195951282978058, 0.7469127774238586]\n",
      "200 steps | score: [-0.013366371393203735, 0.08892632275819778]\n",
      "300 steps | score: [-0.3039989769458771, 0.6605556607246399]\n",
      "400 steps | score: [-0.15214718878269196, 0.32031798362731934]\n",
      "500 steps | score: [-0.3406325876712799, 0.6982588171958923]\n",
      "600 steps | score: [-0.4534003734588623, 0.9095720648765564]\n",
      "700 steps | score: [-0.31797292828559875, 0.6348543167114258]\n",
      "800 steps | score: [-0.33902987837791443, 0.7034026980400085]\n",
      "900 steps | score: [-0.18888315558433533, 0.38863712549209595]\n",
      "1000 steps | score: [-0.3377165198326111, 0.6694098711013794]\n",
      "1100 steps | score: [-0.4309426248073578, 0.8742280006408691]\n",
      "1200 steps | score: [-0.3094761073589325, 0.6307932138442993]\n",
      "1300 steps | score: [-0.1516154408454895, 0.2903640568256378]\n",
      "1400 steps | score: [-0.08145572990179062, 0.17508269846439362]\n",
      "1500 steps | score: [-0.44374534487724304, 0.8988171219825745]\n",
      "1600 steps | score: [-0.32361701130867004, 0.6442296504974365]\n",
      "1700 steps | score: [-0.20094558596611023, 0.3739408850669861]\n",
      "1800 steps | score: [-0.1956498771905899, 0.4211363196372986]\n",
      "1900 steps | score: [-0.27553418278694153, 0.5308789610862732]\n",
      "2000 steps | score: [-0.20321011543273926, 0.34796589612960815]\n",
      "2100 steps | score: [-0.2905777096748352, 0.5919079184532166]\n",
      "2200 steps | score: [-0.2791791558265686, 0.5757265090942383]\n",
      "2300 steps | score: [-0.27498799562454224, 0.5874833464622498]\n",
      "2400 steps | score: [-0.2614140808582306, 0.5017147660255432]\n",
      "2500 steps | score: [-0.12455353140830994, 0.23719929158687592]\n",
      "unknown params:  tensor([-0.3547, -0.1265,  0.3141, -0.6233, -0.0787,  0.0110])\n",
      "gt params:  tensor([-0.4363, -0.1330,  0.3261, -0.6326, -0.0861,  0.0836])\n",
      "ols params:  tensor([-0.1592, -0.0564,  0.1415, -0.2768, -0.0353,  3.7148])\n",
      "unknown mse:  tensor(0.0020)\n",
      "ols mse:  tensor(2.2385)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/e3d94045-48be-4fea-9056-36efffeb84fa\n",
      "gt params:  tensor([ 0.9529, -0.0516,  0.1180,  0.0872, -0.1854,  0.1477])\n",
      "0 steps | score: [0.06893251091241837]\n",
      "100 steps | score: [0.002796076238155365]\n",
      "0 steps | score: [0.023228758946061134, 0.3603888154029846]\n",
      "100 steps | score: [-0.26796600222587585, 1.2652300596237183]\n",
      "200 steps | score: [0.15708385407924652, -0.4228302538394928]\n",
      "300 steps | score: [-0.3070327043533325, 1.323660135269165]\n",
      "400 steps | score: [0.06962089240550995, -0.18480533361434937]\n",
      "500 steps | score: [-0.1619095802307129, 0.7141751050949097]\n",
      "600 steps | score: [0.014040929265320301, 0.04806046932935715]\n",
      "700 steps | score: [0.07184679061174393, -0.19178183376789093]\n",
      "800 steps | score: [-0.09348268061876297, 0.49224263429641724]\n",
      "900 steps | score: [-0.2128830999135971, 0.9235895276069641]\n",
      "1000 steps | score: [0.11150572448968887, -0.38316959142684937]\n",
      "1100 steps | score: [-0.1484987586736679, 0.6276713013648987]\n",
      "1200 steps | score: [-0.252362459897995, 1.0495755672454834]\n",
      "1300 steps | score: [-0.14837539196014404, 0.682776689529419]\n",
      "1400 steps | score: [-0.10861187428236008, 0.4966309070587158]\n",
      "1500 steps | score: [-0.06024160236120224, 0.3336930572986603]\n",
      "1600 steps | score: [-0.2933790683746338, 1.1540812253952026]\n",
      "1700 steps | score: [-0.0698765218257904, 0.34787964820861816]\n",
      "1800 steps | score: [0.03163224831223488, 0.010426923632621765]\n",
      "1900 steps | score: [-0.06703825294971466, 0.3559942841529846]\n",
      "2000 steps | score: [-0.14256180822849274, 0.6526947021484375]\n",
      "2100 steps | score: [-0.22881972789764404, 0.9267862439155579]\n",
      "2200 steps | score: [-0.04521496966481209, 0.24278733134269714]\n",
      "2300 steps | score: [0.027302877977490425, 0.041145794093608856]\n",
      "2400 steps | score: [-0.15972572565078735, 0.7383659482002258]\n",
      "2500 steps | score: [-0.04899274930357933, 0.2632356882095337]\n",
      "2600 steps | score: [-0.13527195155620575, 0.5658848285675049]\n",
      "unknown params:  tensor([ 0.8868, -0.0391,  0.1070,  0.0763, -0.1739,  0.1796])\n",
      "gt params:  tensor([ 0.9529, -0.0516,  0.1180,  0.0872, -0.1854,  0.1477])\n",
      "ols params:  tensor([ 0.7643, -0.0362,  0.0975,  0.0695, -0.1568,  0.7982])\n",
      "unknown mse:  tensor(0.0010)\n",
      "ols mse:  tensor(0.0768)\n",
      "gt params:  tensor([ 0.9490, -0.0394,  0.1138,  0.0889, -0.1769,  0.1360])\n",
      "0 steps | score: [0.2801882028579712]\n",
      "100 steps | score: [0.21521930396556854]\n",
      "200 steps | score: [0.18801841139793396]\n",
      "300 steps | score: [0.10425499826669693]\n",
      "400 steps | score: [0.1397189348936081]\n",
      "500 steps | score: [0.14628252387046814]\n",
      "600 steps | score: [0.11521625518798828]\n",
      "700 steps | score: [0.10852549970149994]\n",
      "800 steps | score: [0.023827984929084778]\n",
      "900 steps | score: [0.17402984201908112]\n",
      "1000 steps | score: [0.17412883043289185]\n",
      "1100 steps | score: [0.08642397075891495]\n",
      "1200 steps | score: [0.0960124284029007]\n",
      "1300 steps | score: [0.09347166866064072]\n",
      "1400 steps | score: [0.10219597071409225]\n",
      "1500 steps | score: [0.10733199864625931]\n",
      "1600 steps | score: [0.11315233260393143]\n",
      "1700 steps | score: [0.07780887186527252]\n",
      "1800 steps | score: [0.120276540517807]\n",
      "1900 steps | score: [0.07724085450172424]\n",
      "2000 steps | score: [0.10841161012649536]\n",
      "2100 steps | score: [0.11103498935699463]\n",
      "2200 steps | score: [0.11702171713113785]\n",
      "2300 steps | score: [0.13841935992240906]\n",
      "2400 steps | score: [0.10030166059732437]\n",
      "2500 steps | score: [0.09948789328336716]\n",
      "0 steps | score: [-0.09033800661563873, 0.5147667527198792]\n",
      "100 steps | score: [0.4707854092121124, -1.569176197052002]\n",
      "200 steps | score: [-0.3272709548473358, 0.9772819876670837]\n",
      "300 steps | score: [-0.1426185965538025, 0.42319801449775696]\n",
      "400 steps | score: [-0.40719473361968994, 1.2053030729293823]\n",
      "500 steps | score: [-0.45794692635536194, 1.343313217163086]\n",
      "600 steps | score: [-0.026244595646858215, 0.03174103796482086]\n",
      "700 steps | score: [-0.2747485041618347, 0.7431752681732178]\n",
      "800 steps | score: [-0.48991134762763977, 1.4025473594665527]\n",
      "900 steps | score: [0.23266567289829254, -0.8762078881263733]\n",
      "1000 steps | score: [0.12183179706335068, -0.45725420117378235]\n",
      "1100 steps | score: [-0.29506242275238037, 0.8692710399627686]\n",
      "1200 steps | score: [-0.1811961829662323, 0.5191519856452942]\n",
      "1300 steps | score: [-0.4407607316970825, 1.2559260129928589]\n",
      "1400 steps | score: [-0.05091799050569534, 0.09865571558475494]\n",
      "1500 steps | score: [-0.23031584918498993, 0.6546872854232788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 steps | score: [-0.27712520956993103, 0.7922048568725586]\n",
      "1700 steps | score: [-0.3003675937652588, 0.8664345145225525]\n",
      "1800 steps | score: [-0.28701141476631165, 0.8188459873199463]\n",
      "1900 steps | score: [-0.262767493724823, 0.763005256652832]\n",
      "2000 steps | score: [-0.19593705236911774, 0.5620722770690918]\n",
      "2100 steps | score: [-0.1848796159029007, 0.501352846622467]\n",
      "2200 steps | score: [-0.2238665521144867, 0.6540970206260681]\n",
      "2300 steps | score: [-0.07998236268758774, 0.19664841890335083]\n",
      "2400 steps | score: [-0.25837403535842896, 0.7041231989860535]\n",
      "2500 steps | score: [-0.17522814869880676, 0.4895501732826233]\n",
      "unknown params:  tensor([ 0.9433, -0.0321,  0.1206,  0.0879, -0.1658,  0.0925])\n",
      "gt params:  tensor([ 0.9490, -0.0394,  0.1138,  0.0889, -0.1769,  0.1360])\n",
      "ols params:  tensor([ 0.6798, -0.0270,  0.0952,  0.0712, -0.1314,  1.1370])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(0.1796)\n",
      "gt params:  tensor([ 0.9623, -0.0442,  0.1174,  0.0872, -0.1925,  0.1610])\n",
      "0 steps | score: [0.2166893631219864]\n",
      "100 steps | score: [0.0662844255566597]\n",
      "200 steps | score: [-0.008033005520701408]\n",
      "0 steps | score: [0.2817942202091217, 0.05802364647388458]\n",
      "100 steps | score: [0.15643706917762756, 0.23996850848197937]\n",
      "200 steps | score: [0.0988340824842453, 0.3167398273944855]\n",
      "300 steps | score: [-0.01982865110039711, 0.5653769969940186]\n",
      "400 steps | score: [0.10481054335832596, 0.3063834011554718]\n",
      "500 steps | score: [-0.06846699863672256, 0.6632176041603088]\n",
      "600 steps | score: [0.12869566679000854, 0.22563685476779938]\n",
      "700 steps | score: [0.18134213984012604, 0.09982514381408691]\n",
      "800 steps | score: [0.2487429827451706, -0.12180624902248383]\n",
      "900 steps | score: [0.056358452886343, 0.40387725830078125]\n",
      "1000 steps | score: [-0.05233195424079895, 0.6479021310806274]\n",
      "1100 steps | score: [0.14755870401859283, 0.16224022209644318]\n",
      "1200 steps | score: [0.027747292071580887, 0.46255189180374146]\n",
      "1300 steps | score: [0.19804787635803223, 0.01874595880508423]\n",
      "1400 steps | score: [0.1441907286643982, 0.14809423685073853]\n",
      "1500 steps | score: [0.1821405291557312, 0.0804169625043869]\n",
      "1600 steps | score: [0.09633732587099075, 0.24837660789489746]\n",
      "1700 steps | score: [0.20856520533561707, -0.014918476343154907]\n",
      "1800 steps | score: [-0.03138415887951851, 0.5875135660171509]\n",
      "1900 steps | score: [0.2014237344264984, -0.026127740740776062]\n",
      "2000 steps | score: [0.16815777122974396, 0.0765673965215683]\n",
      "2100 steps | score: [0.09207764267921448, 0.26896053552627563]\n",
      "2200 steps | score: [0.11308906972408295, 0.25733330845832825]\n",
      "2300 steps | score: [0.04046165198087692, 0.4109993577003479]\n",
      "2400 steps | score: [0.14665597677230835, 0.13673704862594604]\n",
      "2500 steps | score: [0.08665234595537186, 0.26999711990356445]\n",
      "2600 steps | score: [0.021102892234921455, 0.44779065251350403]\n",
      "unknown params:  tensor([ 0.8843, -0.0436,  0.1058,  0.0816, -0.1885,  0.1499])\n",
      "gt params:  tensor([ 0.9623, -0.0442,  0.1174,  0.0872, -0.1925,  0.1610])\n",
      "ols params:  tensor([ 0.6047, -0.0347,  0.0803,  0.0645, -0.1417,  1.5174])\n",
      "unknown mse:  tensor(0.0011)\n",
      "ols mse:  tensor(0.3287)\n",
      "gt params:  tensor([ 0.9548, -0.0431,  0.1253,  0.0838, -0.1881,  0.1446])\n",
      "0 steps | score: [0.2891703248023987]\n",
      "100 steps | score: [0.06404749304056168]\n",
      "200 steps | score: [0.01962105929851532]\n",
      "300 steps | score: [0.08346828818321228]\n",
      "400 steps | score: [0.09877568483352661]\n",
      "500 steps | score: [0.09957916289567947]\n",
      "600 steps | score: [0.030218182131648064]\n",
      "700 steps | score: [0.04214823991060257]\n",
      "800 steps | score: [0.05544091388583183]\n",
      "900 steps | score: [0.0743478313088417]\n",
      "1000 steps | score: [0.1105039194226265]\n",
      "1100 steps | score: [0.1097913309931755]\n",
      "1200 steps | score: [0.10052171349525452]\n",
      "1300 steps | score: [0.04146919399499893]\n",
      "1400 steps | score: [0.07665028423070908]\n",
      "1500 steps | score: [0.0978870540857315]\n",
      "1600 steps | score: [0.10261617600917816]\n",
      "1700 steps | score: [0.09013290703296661]\n",
      "1800 steps | score: [0.07982488721609116]\n",
      "1900 steps | score: [0.032700344920158386]\n",
      "2000 steps | score: [0.06473392248153687]\n",
      "2100 steps | score: [0.07097889482975006]\n",
      "2200 steps | score: [0.06348849833011627]\n",
      "2300 steps | score: [0.05589227005839348]\n",
      "2400 steps | score: [0.054978352040052414]\n",
      "2500 steps | score: [0.08904703706502914]\n",
      "0 steps | score: [0.20262126624584198, -0.10141933709383011]\n",
      "100 steps | score: [0.15453460812568665, -0.12521333992481232]\n",
      "200 steps | score: [0.1617540568113327, -0.21217620372772217]\n",
      "300 steps | score: [0.12173282355070114, -0.1866856813430786]\n",
      "400 steps | score: [0.1656603068113327, -0.24168577790260315]\n",
      "500 steps | score: [0.0003685871488414705, 0.13812248408794403]\n",
      "600 steps | score: [-0.11307184398174286, 0.3699478805065155]\n",
      "700 steps | score: [-0.054445307701826096, 0.2508128881454468]\n",
      "800 steps | score: [0.08560522645711899, -0.08415809273719788]\n",
      "900 steps | score: [0.05796763673424721, -0.033652134239673615]\n",
      "1000 steps | score: [0.295895516872406, -0.650628387928009]\n",
      "1100 steps | score: [0.1185244619846344, -0.1444714367389679]\n",
      "1200 steps | score: [0.1210852861404419, -0.1857517808675766]\n",
      "1300 steps | score: [0.005089964717626572, 0.10748278349637985]\n",
      "1400 steps | score: [0.16659222543239594, -0.34514787793159485]\n",
      "1500 steps | score: [0.02040030248463154, 0.031056884676218033]\n",
      "1600 steps | score: [0.16101770102977753, -0.30877313017845154]\n",
      "1700 steps | score: [0.14630839228630066, -0.2690166234970093]\n",
      "1800 steps | score: [-0.01455218717455864, 0.12065127491950989]\n",
      "1900 steps | score: [-0.006505099590867758, 0.14923158288002014]\n",
      "2000 steps | score: [0.04238767921924591, 0.02991868555545807]\n",
      "2100 steps | score: [0.1576802134513855, -0.2942240834236145]\n",
      "2200 steps | score: [0.0917799174785614, -0.1195434033870697]\n",
      "2300 steps | score: [0.0871819257736206, -0.08417831361293793]\n",
      "2400 steps | score: [0.05948154255747795, -0.02177388221025467]\n",
      "2500 steps | score: [0.13024820387363434, -0.2448878288269043]\n",
      "unknown params:  tensor([ 0.9551, -0.0475,  0.1121,  0.0585, -0.1936, -0.0302])\n",
      "gt params:  tensor([ 0.9548, -0.0431,  0.1253,  0.0838, -0.1881,  0.1446])\n",
      "ols params:  tensor([ 0.5714, -0.0318,  0.0775,  0.0412, -0.1299,  1.7349])\n",
      "unknown mse:  tensor(0.0052)\n",
      "ols mse:  tensor(0.4472)\n",
      "gt params:  tensor([ 0.9577, -0.0598,  0.1127,  0.0705, -0.1970,  0.1450])\n",
      "0 steps | score: [0.3126527965068817]\n",
      "100 steps | score: [0.13126163184642792]\n",
      "200 steps | score: [0.0623643696308136]\n",
      "300 steps | score: [0.03606969490647316]\n",
      "400 steps | score: [0.04387292638421059]\n",
      "500 steps | score: [0.09793417155742645]\n",
      "600 steps | score: [0.08705957978963852]\n",
      "700 steps | score: [0.12901930510997772]\n",
      "800 steps | score: [0.05421975255012512]\n",
      "900 steps | score: [0.0718151330947876]\n",
      "1000 steps | score: [0.12768258154392242]\n",
      "1100 steps | score: [0.1228475570678711]\n",
      "1200 steps | score: [0.0830535739660263]\n",
      "1300 steps | score: [0.05436273291707039]\n",
      "1400 steps | score: [0.1088351458311081]\n",
      "1500 steps | score: [0.12717707455158234]\n",
      "1600 steps | score: [0.0976674035191536]\n",
      "1700 steps | score: [0.08937261253595352]\n",
      "1800 steps | score: [0.07489226758480072]\n",
      "1900 steps | score: [0.0841667503118515]\n",
      "2000 steps | score: [0.08456739783287048]\n",
      "2100 steps | score: [0.09102233499288559]\n",
      "2200 steps | score: [0.09307440370321274]\n",
      "2300 steps | score: [0.08045674115419388]\n",
      "2400 steps | score: [0.07277122139930725]\n",
      "2500 steps | score: [0.08206222951412201]\n",
      "0 steps | score: [-0.0685528889298439, 0.3105083405971527]\n",
      "100 steps | score: [-0.27550008893013, 0.636431097984314]\n",
      "200 steps | score: [-0.506493866443634, 1.0930544137954712]\n",
      "300 steps | score: [-0.409802109003067, 0.8751267194747925]\n",
      "400 steps | score: [-0.37668707966804504, 0.7800590991973877]\n",
      "500 steps | score: [-0.3775526285171509, 0.7424171566963196]\n",
      "600 steps | score: [-0.3842993974685669, 0.7929744720458984]\n",
      "700 steps | score: [0.3589910864830017, -1.352390170097351]\n",
      "800 steps | score: [-0.15834587812423706, 0.2663504481315613]\n",
      "900 steps | score: [-0.3540351688861847, 0.7242251634597778]\n",
      "1000 steps | score: [-0.25753679871559143, 0.449241578578949]\n",
      "1100 steps | score: [-0.3065844774246216, 0.6341070532798767]\n",
      "1200 steps | score: [-0.33970722556114197, 0.665017306804657]\n",
      "1300 steps | score: [-0.2910657823085785, 0.5509006381034851]\n",
      "1400 steps | score: [-0.13218440115451813, 0.17608654499053955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 steps | score: [-0.07871966809034348, 0.04866417497396469]\n",
      "1600 steps | score: [-0.22583721578121185, 0.3720191717147827]\n",
      "1700 steps | score: [-0.34000086784362793, 0.663343608379364]\n",
      "1800 steps | score: [-0.3309364914894104, 0.6548793911933899]\n",
      "1900 steps | score: [-0.25175827741622925, 0.4438328146934509]\n",
      "2000 steps | score: [-0.23289541900157928, 0.43838733434677124]\n",
      "2100 steps | score: [-0.15718188881874084, 0.20958663523197174]\n",
      "2200 steps | score: [-0.20145480334758759, 0.34730181097984314]\n",
      "2300 steps | score: [-0.30391985177993774, 0.5998218059539795]\n",
      "2400 steps | score: [-0.18916942179203033, 0.32276278734207153]\n",
      "2500 steps | score: [-0.29140689969062805, 0.562353253364563]\n",
      "unknown params:  tensor([ 1.0065, -0.0658,  0.1303,  0.0803, -0.1958,  0.0303])\n",
      "gt params:  tensor([ 0.9577, -0.0598,  0.1127,  0.0705, -0.1970,  0.1450])\n",
      "ols params:  tensor([ 0.5338, -0.0384,  0.0787,  0.0500, -0.1197,  1.9529])\n",
      "unknown mse:  tensor(0.0027)\n",
      "ols mse:  tensor(0.5760)\n",
      "gt params:  tensor([ 0.9572, -0.0525,  0.1154,  0.0834, -0.1813,  0.1319])\n",
      "0 steps | score: [0.1825081706047058]\n",
      "100 steps | score: [-0.06034975126385689]\n",
      "200 steps | score: [-0.10269725322723389]\n",
      "300 steps | score: [-0.04272736981511116]\n",
      "400 steps | score: [-0.09563535451889038]\n",
      "500 steps | score: [-0.04122164472937584]\n",
      "600 steps | score: [0.0036482438445091248]\n",
      "0 steps | score: [-0.1889580637216568, 0.634234607219696]\n",
      "100 steps | score: [-0.1310116946697235, 0.34567052125930786]\n",
      "200 steps | score: [-0.35630571842193604, 0.8008090853691101]\n",
      "300 steps | score: [-0.3893715441226959, 0.8296177387237549]\n",
      "400 steps | score: [-0.508534848690033, 1.1132385730743408]\n",
      "500 steps | score: [-0.5690913796424866, 1.2002609968185425]\n",
      "600 steps | score: [-0.4461984932422638, 0.9694133996963501]\n",
      "700 steps | score: [-0.22884613275527954, 0.4523993730545044]\n",
      "800 steps | score: [-0.43138280510902405, 0.9496838450431824]\n",
      "900 steps | score: [-0.44786033034324646, 0.9478932023048401]\n",
      "1000 steps | score: [-0.39461347460746765, 0.8295741677284241]\n",
      "1100 steps | score: [-0.25797373056411743, 0.5078610181808472]\n",
      "1200 steps | score: [-0.31437769532203674, 0.6549697518348694]\n",
      "1300 steps | score: [-0.3996735215187073, 0.8626575469970703]\n",
      "1400 steps | score: [-0.48342034220695496, 1.0491095781326294]\n",
      "1500 steps | score: [-0.4636237919330597, 0.9862417578697205]\n",
      "1600 steps | score: [-0.2502974271774292, 0.49626484513282776]\n",
      "1700 steps | score: [-0.3457467555999756, 0.6991978883743286]\n",
      "1800 steps | score: [-0.36344388127326965, 0.7518500685691833]\n",
      "1900 steps | score: [-0.41016140580177307, 0.8664016127586365]\n",
      "2000 steps | score: [-0.2576020359992981, 0.5052605867385864]\n",
      "2100 steps | score: [-0.3236698806285858, 0.6489388942718506]\n",
      "2200 steps | score: [-0.27552270889282227, 0.5274736285209656]\n",
      "2300 steps | score: [-0.2973358929157257, 0.5976845026016235]\n",
      "2400 steps | score: [-0.38490498065948486, 0.7990395426750183]\n",
      "2500 steps | score: [-0.3060922622680664, 0.6044069528579712]\n",
      "unknown params:  tensor([ 0.9426, -0.0524,  0.1117,  0.0539, -0.1999,  0.0957])\n",
      "gt params:  tensor([ 0.9572, -0.0525,  0.1154,  0.0834, -0.1813,  0.1319])\n",
      "ols params:  tensor([ 0.5015, -0.0327,  0.0680,  0.0366, -0.1193,  2.1431])\n",
      "unknown mse:  tensor(0.0005)\n",
      "ols mse:  tensor(0.7102)\n",
      "gt params:  tensor([ 0.9477, -0.0296,  0.1191,  0.0847, -0.1996,  0.1216])\n",
      "0 steps | score: [0.05184710770845413]\n",
      "100 steps | score: [-0.1624157875776291]\n",
      "200 steps | score: [-0.18738557398319244]\n",
      "300 steps | score: [-0.14484594762325287]\n",
      "400 steps | score: [-0.10982608795166016]\n",
      "500 steps | score: [-0.18412774801254272]\n",
      "600 steps | score: [-0.19728392362594604]\n",
      "700 steps | score: [-0.14936885237693787]\n",
      "800 steps | score: [-0.12875410914421082]\n",
      "900 steps | score: [-0.17246808111667633]\n",
      "1000 steps | score: [-0.20223453640937805]\n",
      "1100 steps | score: [-0.17028962075710297]\n",
      "1200 steps | score: [-0.13282398879528046]\n",
      "1300 steps | score: [-0.17109858989715576]\n",
      "1400 steps | score: [-0.17695832252502441]\n",
      "1500 steps | score: [-0.18195277452468872]\n",
      "1600 steps | score: [-0.19572150707244873]\n",
      "1700 steps | score: [-0.13697762787342072]\n",
      "1800 steps | score: [-0.14564795792102814]\n",
      "1900 steps | score: [-0.159532830119133]\n",
      "2000 steps | score: [-0.15893828868865967]\n",
      "2100 steps | score: [-0.1936608850955963]\n",
      "2200 steps | score: [-0.17661593854427338]\n",
      "2300 steps | score: [-0.17629367113113403]\n",
      "2400 steps | score: [-0.1797885298728943]\n",
      "2500 steps | score: [-0.13484303653240204]\n",
      "0 steps | score: [0.08763918280601501, 0.19455605745315552]\n",
      "100 steps | score: [0.07370346039533615, 0.04133281111717224]\n",
      "200 steps | score: [-0.1681658923625946, 0.5388047099113464]\n",
      "300 steps | score: [-0.06269651651382446, 0.32030385732650757]\n",
      "400 steps | score: [0.11484561860561371, -0.16026653349399567]\n",
      "500 steps | score: [-0.14300641417503357, 0.43887585401535034]\n",
      "600 steps | score: [-0.14669953286647797, 0.45364829897880554]\n",
      "700 steps | score: [-0.10454700142145157, 0.32952845096588135]\n",
      "800 steps | score: [-0.10149521380662918, 0.32691890001296997]\n",
      "900 steps | score: [-0.17238827049732208, 0.5136446952819824]\n",
      "1000 steps | score: [-0.1504533737897873, 0.45661991834640503]\n",
      "1100 steps | score: [-0.07034216076135635, 0.23785673081874847]\n",
      "1200 steps | score: [0.028680900111794472, -0.016065865755081177]\n",
      "1300 steps | score: [0.00019763050659094006, 0.08352680504322052]\n",
      "1400 steps | score: [-0.12325548380613327, 0.37650221586227417]\n",
      "1500 steps | score: [-0.24288487434387207, 0.6806064248085022]\n",
      "1600 steps | score: [-0.1681765764951706, 0.49726712703704834]\n",
      "1700 steps | score: [0.006503916345536709, 0.04676523804664612]\n",
      "1800 steps | score: [-0.06232040002942085, 0.21926823258399963]\n",
      "1900 steps | score: [-0.14398297667503357, 0.4321707487106323]\n",
      "2000 steps | score: [-0.08733026683330536, 0.297212690114975]\n",
      "2100 steps | score: [-0.0576789528131485, 0.20083975791931152]\n",
      "2200 steps | score: [-0.08392950892448425, 0.2877371311187744]\n",
      "2300 steps | score: [-0.012517940253019333, 0.1773533970117569]\n",
      "2400 steps | score: [-0.08277314901351929, 0.2623620927333832]\n",
      "2500 steps | score: [-0.026599332690238953, 0.14536063373088837]\n",
      "unknown params:  tensor([ 0.8919, -0.0261,  0.1134,  0.0664, -0.2017,  0.1482])\n",
      "gt params:  tensor([ 0.9477, -0.0296,  0.1191,  0.0847, -0.1996,  0.1216])\n",
      "ols params:  tensor([ 0.4594, -0.0124,  0.0662,  0.0437, -0.1174,  2.3466])\n",
      "unknown mse:  tensor(0.0007)\n",
      "ols mse:  tensor(0.8668)\n",
      "gt params:  tensor([ 0.9604, -0.0480,  0.1037,  0.0902, -0.1812,  0.1533])\n",
      "0 steps | score: [0.20915187895298004]\n",
      "100 steps | score: [0.005718374624848366]\n",
      "0 steps | score: [0.13020169734954834, -0.08459602296352386]\n",
      "100 steps | score: [0.0965970903635025, -0.13926610350608826]\n",
      "200 steps | score: [0.1725265383720398, -0.40327584743499756]\n",
      "300 steps | score: [-0.1027781292796135, 0.2064186930656433]\n",
      "400 steps | score: [0.03128129616379738, -0.10316131263971329]\n",
      "500 steps | score: [0.0012048088246956468, -0.05369679257273674]\n",
      "600 steps | score: [-0.11027135699987411, 0.2065323442220688]\n",
      "700 steps | score: [-0.05111462622880936, 0.09138831496238708]\n",
      "800 steps | score: [-0.10371919721364975, 0.18573862314224243]\n",
      "900 steps | score: [-0.022427605465054512, 0.01767462119460106]\n",
      "1000 steps | score: [-0.0796164944767952, 0.12206938862800598]\n",
      "1100 steps | score: [-0.02781885489821434, 0.024598650634288788]\n",
      "1200 steps | score: [0.09131183475255966, -0.277283638715744]\n",
      "1300 steps | score: [-0.0936514288187027, 0.15941843390464783]\n",
      "1400 steps | score: [-0.013757199048995972, -0.03767378628253937]\n",
      "1500 steps | score: [-0.2884981036186218, 0.5147371292114258]\n",
      "1600 steps | score: [-0.07894988358020782, 0.12393514811992645]\n",
      "1700 steps | score: [-0.09539967775344849, 0.1743626743555069]\n",
      "1800 steps | score: [-0.0974278599023819, 0.18413309752941132]\n",
      "1900 steps | score: [-0.03251369297504425, 0.052673112601041794]\n",
      "2000 steps | score: [-0.19445602595806122, 0.3503568470478058]\n",
      "2100 steps | score: [-0.03983413055539131, 0.044232599437236786]\n",
      "2200 steps | score: [-0.06247398629784584, 0.10642652213573456]\n",
      "2300 steps | score: [-0.08440311998128891, 0.10772289335727692]\n",
      "2400 steps | score: [-0.08259011059999466, 0.10174714028835297]\n",
      "2500 steps | score: [-0.0354517437517643, 0.02224021963775158]\n",
      "2600 steps | score: [-0.06557118892669678, 0.08690553158521652]\n",
      "unknown params:  tensor([ 0.9199, -0.0380,  0.1123,  0.0930, -0.1768,  0.1323])\n",
      "gt params:  tensor([ 0.9604, -0.0480,  0.1037,  0.0902, -0.1812,  0.1533])\n",
      "ols params:  tensor([ 0.4711, -0.0253,  0.0648,  0.0563, -0.1028,  2.4640])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(0.9313)\n",
      "gt params:  tensor([ 0.9609, -0.0545,  0.1211,  0.0835, -0.1860,  0.1442])\n",
      "0 steps | score: [0.2960749864578247]\n",
      "100 steps | score: [0.023544972762465477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [0.06443864852190018]\n",
      "300 steps | score: [0.015986237674951553]\n",
      "400 steps | score: [0.051569901406764984]\n",
      "500 steps | score: [0.06151140481233597]\n",
      "600 steps | score: [0.026024693623185158]\n",
      "700 steps | score: [-0.005445053800940514]\n",
      "0 steps | score: [0.015796110033988953, 0.24698945879936218]\n",
      "100 steps | score: [-0.23830120265483856, 0.648393452167511]\n",
      "200 steps | score: [-0.2431238889694214, 0.6077733635902405]\n",
      "300 steps | score: [-0.06889798492193222, 0.21787382662296295]\n",
      "400 steps | score: [-0.2605591118335724, 0.6243860125541687]\n",
      "500 steps | score: [-0.04392047971487045, 0.17961716651916504]\n",
      "600 steps | score: [-0.2961261570453644, 0.6608914136886597]\n",
      "700 steps | score: [-0.2527870535850525, 0.5893184542655945]\n",
      "800 steps | score: [-0.09707610309123993, 0.27452200651168823]\n",
      "900 steps | score: [-0.19924120604991913, 0.4869832694530487]\n",
      "1000 steps | score: [0.02932199090719223, -0.04599509760737419]\n",
      "1100 steps | score: [-0.0705803632736206, 0.17449814081192017]\n",
      "1200 steps | score: [-0.09108008444309235, 0.23375998437404633]\n",
      "1300 steps | score: [-0.2071647346019745, 0.49365124106407166]\n",
      "1400 steps | score: [-0.2079637050628662, 0.4880552589893341]\n",
      "1500 steps | score: [-0.11087477207183838, 0.3149288296699524]\n",
      "1600 steps | score: [-0.14817607402801514, 0.3615474998950958]\n",
      "1700 steps | score: [-0.18686527013778687, 0.4708503782749176]\n",
      "1800 steps | score: [-0.08596035838127136, 0.20028026401996613]\n",
      "1900 steps | score: [-0.1791718751192093, 0.4322967231273651]\n",
      "2000 steps | score: [-0.1248454824090004, 0.3364555835723877]\n",
      "2100 steps | score: [-0.15593531727790833, 0.4220587909221649]\n",
      "2200 steps | score: [-0.19600136578083038, 0.4689135253429413]\n",
      "2300 steps | score: [-0.15242353081703186, 0.35375499725341797]\n",
      "2400 steps | score: [-0.06029093265533447, 0.17061540484428406]\n",
      "2500 steps | score: [-0.1684526801109314, 0.41481491923332214]\n",
      "unknown params:  tensor([ 0.9770, -0.0422,  0.1057,  0.1019, -0.1712,  0.0552])\n",
      "gt params:  tensor([ 0.9609, -0.0545,  0.1211,  0.0835, -0.1860,  0.1442])\n",
      "ols params:  tensor([ 0.4585, -0.0225,  0.0562,  0.0568, -0.0904,  2.6067])\n",
      "unknown mse:  tensor(0.0015)\n",
      "ols mse:  tensor(1.0552)\n",
      "gt params:  tensor([ 0.9450, -0.0397,  0.1287,  0.0807, -0.1802,  0.1320])\n",
      "0 steps | score: [0.24735598266124725]\n",
      "100 steps | score: [0.03391718119382858]\n",
      "200 steps | score: [-0.04330652579665184]\n",
      "300 steps | score: [-0.019665926694869995]\n",
      "400 steps | score: [-0.06493692845106125]\n",
      "500 steps | score: [-0.03578588366508484]\n",
      "600 steps | score: [0.02290419489145279]\n",
      "700 steps | score: [-0.05094172805547714]\n",
      "800 steps | score: [-0.028017792850732803]\n",
      "900 steps | score: [-0.038167621940374374]\n",
      "1000 steps | score: [-0.030758697539567947]\n",
      "1100 steps | score: [-0.05109277367591858]\n",
      "1200 steps | score: [-0.02706090547144413]\n",
      "1300 steps | score: [-0.02021416462957859]\n",
      "1400 steps | score: [-0.017789728939533234]\n",
      "1500 steps | score: [-0.060254380106925964]\n",
      "1600 steps | score: [-0.042415227741003036]\n",
      "1700 steps | score: [-0.04267574101686478]\n",
      "1800 steps | score: [-0.055779825896024704]\n",
      "1900 steps | score: [-0.013332029804587364]\n",
      "2000 steps | score: [-0.046481966972351074]\n",
      "2100 steps | score: [-0.06811319291591644]\n",
      "2200 steps | score: [-0.013145681470632553]\n",
      "2300 steps | score: [-0.021021757274866104]\n",
      "2400 steps | score: [-0.032513950020074844]\n",
      "2500 steps | score: [-0.04183941334486008]\n",
      "0 steps | score: [0.09666209667921066, 0.1840355396270752]\n",
      "100 steps | score: [-0.03854917734861374, 0.35535743832588196]\n",
      "200 steps | score: [-0.33949437737464905, 0.8757184743881226]\n",
      "300 steps | score: [0.003931831102818251, 0.09981829673051834]\n",
      "400 steps | score: [-0.18163494765758514, 0.531503438949585]\n",
      "500 steps | score: [-0.16185130178928375, 0.5111840963363647]\n",
      "600 steps | score: [0.06636316329240799, -0.03198777139186859]\n",
      "700 steps | score: [-0.24046733975410461, 0.6774173974990845]\n",
      "800 steps | score: [-0.16004812717437744, 0.46867653727531433]\n",
      "900 steps | score: [-0.12893949449062347, 0.39015263319015503]\n",
      "1000 steps | score: [0.03251376003026962, 0.05424685776233673]\n",
      "1100 steps | score: [-0.23801729083061218, 0.6561262011528015]\n",
      "1200 steps | score: [0.02693878673017025, 0.05593738704919815]\n",
      "1300 steps | score: [-0.058128781616687775, 0.24721242487430573]\n",
      "1400 steps | score: [-0.045044027268886566, 0.2617848217487335]\n",
      "1500 steps | score: [-0.14585092663764954, 0.4395928680896759]\n",
      "1600 steps | score: [-0.0973031222820282, 0.34675949811935425]\n",
      "1700 steps | score: [-0.22829926013946533, 0.6243685483932495]\n",
      "1800 steps | score: [-0.15276558697223663, 0.4621601998806]\n",
      "1900 steps | score: [0.032640136778354645, 0.051570042967796326]\n",
      "2000 steps | score: [-0.17068736255168915, 0.5126465559005737]\n",
      "2100 steps | score: [-0.0803033709526062, 0.29806995391845703]\n",
      "2200 steps | score: [-0.08475657552480698, 0.3266066610813141]\n",
      "2300 steps | score: [-0.04840583726763725, 0.2431037425994873]\n",
      "2400 steps | score: [-0.1270294338464737, 0.40229564905166626]\n",
      "2500 steps | score: [-0.08819566667079926, 0.3187274932861328]\n",
      "unknown params:  tensor([ 0.9128, -0.0592,  0.1077,  0.0500, -0.1699,  0.0451])\n",
      "gt params:  tensor([ 0.9450, -0.0397,  0.1287,  0.0807, -0.1802,  0.1320])\n",
      "ols params:  tensor([ 0.4429, -0.0327,  0.0577,  0.0296, -0.0896,  2.7201])\n",
      "unknown mse:  tensor(0.0017)\n",
      "ols mse:  tensor(1.1611)\n",
      "gt params:  tensor([ 0.9635, -0.0523,  0.1099,  0.1059, -0.1887,  0.2102])\n",
      "0 steps | score: [0.20648719370365143]\n",
      "100 steps | score: [-0.04105884209275246]\n",
      "200 steps | score: [-0.1026669591665268]\n",
      "300 steps | score: [-0.027176929637789726]\n",
      "400 steps | score: [-0.023701485246419907]\n",
      "500 steps | score: [0.009312686510384083]\n",
      "0 steps | score: [0.24840424954891205, -0.3963841199874878]\n",
      "100 steps | score: [0.09836073964834213, -0.16886751353740692]\n",
      "200 steps | score: [0.36623477935791016, -0.8578145503997803]\n",
      "300 steps | score: [0.030152378603816032, -0.128438800573349]\n",
      "400 steps | score: [0.40175384283065796, -1.0412193536758423]\n",
      "500 steps | score: [0.17583753168582916, -0.4923592209815979]\n",
      "600 steps | score: [0.16936030983924866, -0.4226023256778717]\n",
      "700 steps | score: [-0.03918849304318428, 0.022094134241342545]\n",
      "800 steps | score: [0.013667559251189232, -0.11280906200408936]\n",
      "900 steps | score: [0.36614832282066345, -0.9451295733451843]\n",
      "1000 steps | score: [0.1925911158323288, -0.529991865158081]\n",
      "1100 steps | score: [0.07685861736536026, -0.25343024730682373]\n",
      "1200 steps | score: [0.15200559794902802, -0.4083307683467865]\n",
      "1300 steps | score: [0.17004770040512085, -0.4481608271598816]\n",
      "1400 steps | score: [0.3823833465576172, -1.004784107208252]\n",
      "1500 steps | score: [0.1233174055814743, -0.35054564476013184]\n",
      "1600 steps | score: [0.1253761202096939, -0.3835263252258301]\n",
      "1700 steps | score: [0.06533545255661011, -0.22107189893722534]\n",
      "1800 steps | score: [0.10024456679821014, -0.3064071238040924]\n",
      "1900 steps | score: [0.24723336100578308, -0.652793288230896]\n",
      "2000 steps | score: [0.15923148393630981, -0.43727877736091614]\n",
      "2100 steps | score: [0.14437828958034515, -0.40623340010643005]\n",
      "2200 steps | score: [0.031880635768175125, -0.1474776417016983]\n",
      "2300 steps | score: [0.11052108556032181, -0.35015594959259033]\n",
      "2400 steps | score: [0.1790977269411087, -0.4875120222568512]\n",
      "2500 steps | score: [0.14696981012821198, -0.4109359383583069]\n",
      "unknown params:  tensor([ 0.9193, -0.0622,  0.1082,  0.1186, -0.1816,  0.3061])\n",
      "gt params:  tensor([ 0.9635, -0.0523,  0.1099,  0.1059, -0.1887,  0.2102])\n",
      "ols params:  tensor([ 0.4432, -0.0339,  0.0572,  0.0659, -0.0963,  2.9267])\n",
      "unknown mse:  tensor(0.0019)\n",
      "ols mse:  tensor(1.2773)\n",
      "gt params:  tensor([ 0.9635, -0.0242,  0.1217,  0.0966, -0.1881,  0.1462])\n",
      "0 steps | score: [0.26245957612991333]\n",
      "100 steps | score: [0.020876571536064148]\n",
      "200 steps | score: [-0.029194338247179985]\n",
      "300 steps | score: [-0.019214242696762085]\n",
      "400 steps | score: [0.0010279957205057144]\n",
      "0 steps | score: [-0.062305595725774765, 0.46902939677238464]\n",
      "100 steps | score: [-0.12338711321353912, 0.4907570779323578]\n",
      "200 steps | score: [-0.35288503766059875, 0.8855798840522766]\n",
      "300 steps | score: [-0.12611399590969086, 0.3267514705657959]\n",
      "400 steps | score: [-0.3383271396160126, 0.7911633253097534]\n",
      "500 steps | score: [-0.1178407147526741, 0.3304222822189331]\n",
      "600 steps | score: [-0.39125749468803406, 0.9205734133720398]\n",
      "700 steps | score: [-0.2786461412906647, 0.6579031944274902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 steps | score: [-0.25935712456703186, 0.623505175113678]\n",
      "900 steps | score: [-0.23910021781921387, 0.5629234313964844]\n",
      "1000 steps | score: [-0.03940447047352791, 0.08834405243396759]\n",
      "1100 steps | score: [-0.13984550535678864, 0.356390118598938]\n",
      "1200 steps | score: [-0.4358711838722229, 1.0020685195922852]\n",
      "1300 steps | score: [-0.2955497205257416, 0.7126504182815552]\n",
      "1400 steps | score: [-0.23327741026878357, 0.5666665434837341]\n",
      "1500 steps | score: [-0.1790751814842224, 0.4284820854663849]\n",
      "1600 steps | score: [-0.2184983193874359, 0.5403720140457153]\n",
      "1700 steps | score: [-0.2163284868001938, 0.5247794985771179]\n",
      "1800 steps | score: [-0.2021653801202774, 0.49082136154174805]\n",
      "1900 steps | score: [-0.2946925759315491, 0.6986386775970459]\n",
      "2000 steps | score: [0.050970546901226044, -0.16128283739089966]\n",
      "2100 steps | score: [-0.19671449065208435, 0.47942915558815]\n",
      "2200 steps | score: [-0.17695733904838562, 0.4526386559009552]\n",
      "2300 steps | score: [-0.2330407053232193, 0.5485364198684692]\n",
      "2400 steps | score: [-0.2705901265144348, 0.6602501273155212]\n",
      "2500 steps | score: [-0.21638397872447968, 0.4842977523803711]\n",
      "unknown params:  tensor([ 1.0436, -0.0187,  0.1116,  0.1072, -0.2035, -0.0105])\n",
      "gt params:  tensor([ 0.9635, -0.0242,  0.1217,  0.0966, -0.1881,  0.1462])\n",
      "ols params:  tensor([ 0.4570, -0.0073,  0.0531,  0.0528, -0.1021,  2.9531])\n",
      "unknown mse:  tensor(0.0052)\n",
      "ols mse:  tensor(1.3583)\n",
      "gt params:  tensor([ 0.9389, -0.0638,  0.1204,  0.0590, -0.1928,  0.0835])\n",
      "0 steps | score: [0.21924862265586853]\n",
      "100 steps | score: [-0.012001007795333862]\n",
      "200 steps | score: [-0.07128006964921951]\n",
      "300 steps | score: [-0.07187197357416153]\n",
      "400 steps | score: [-0.087577685713768]\n",
      "500 steps | score: [-0.026613950729370117]\n",
      "600 steps | score: [-0.03517582267522812]\n",
      "700 steps | score: [-0.06193959712982178]\n",
      "800 steps | score: [-0.08823642134666443]\n",
      "900 steps | score: [-0.07640610635280609]\n",
      "1000 steps | score: [-0.003093734383583069]\n",
      "0 steps | score: [0.1948067992925644, -0.05377223342657089]\n",
      "100 steps | score: [0.1380625218153, -0.04826618358492851]\n",
      "200 steps | score: [-0.017918769270181656, 0.21679502725601196]\n",
      "300 steps | score: [-0.02566753700375557, 0.22245673835277557]\n",
      "400 steps | score: [-0.05487016215920448, 0.2417358160018921]\n",
      "500 steps | score: [-0.08323390036821365, 0.29887303709983826]\n",
      "600 steps | score: [-0.07646101713180542, 0.2965041697025299]\n",
      "700 steps | score: [-0.17369459569454193, 0.47784167528152466]\n",
      "800 steps | score: [-0.11191917210817337, 0.3515896201133728]\n",
      "900 steps | score: [-0.10629547387361526, 0.3564341068267822]\n",
      "1000 steps | score: [0.08278295397758484, -0.05923766270279884]\n",
      "1100 steps | score: [-0.019288429990410805, 0.1865740418434143]\n",
      "1200 steps | score: [-0.10201255232095718, 0.33190029859542847]\n",
      "1300 steps | score: [0.06622862070798874, -0.006616402417421341]\n",
      "1400 steps | score: [-0.12111751735210419, 0.37601810693740845]\n",
      "1500 steps | score: [0.1018681451678276, -0.09985938668251038]\n",
      "1600 steps | score: [0.043613750487565994, 0.048546962440013885]\n",
      "1700 steps | score: [-0.05251569673418999, 0.23046144843101501]\n",
      "1800 steps | score: [0.04836404696106911, 0.02582257241010666]\n",
      "1900 steps | score: [-0.0876716896891594, 0.30679523944854736]\n",
      "2000 steps | score: [0.052102912217378616, -0.005506154149770737]\n",
      "2100 steps | score: [-0.02819487638771534, 0.15360087156295776]\n",
      "2200 steps | score: [0.06001802533864975, -0.021744269877672195]\n",
      "2300 steps | score: [-0.012633061967790127, 0.1456819623708725]\n",
      "2400 steps | score: [0.004600989632308483, 0.11558972299098969]\n",
      "2500 steps | score: [0.04452555626630783, 0.01926591992378235]\n",
      "unknown params:  tensor([ 0.9317, -0.0567,  0.1053,  0.0463, -0.2006,  0.1301])\n",
      "gt params:  tensor([ 0.9389, -0.0638,  0.1204,  0.0590, -0.1928,  0.0835])\n",
      "ols params:  tensor([ 0.4180, -0.0279,  0.0509,  0.0252, -0.0971,  3.0734])\n",
      "unknown mse:  tensor(0.0005)\n",
      "ols mse:  tensor(1.5379)\n",
      "gt params:  tensor([ 0.9511, -0.0706,  0.1038,  0.0863, -0.2005,  0.1231])\n",
      "0 steps | score: [0.22379399836063385]\n",
      "100 steps | score: [-0.04042823985219002]\n",
      "200 steps | score: [-0.0694609209895134]\n",
      "300 steps | score: [-0.04015376791357994]\n",
      "400 steps | score: [-0.09930559247732162]\n",
      "500 steps | score: [-0.10046233236789703]\n",
      "600 steps | score: [-0.026655049994587898]\n",
      "700 steps | score: [-0.02946487069129944]\n",
      "800 steps | score: [-0.052067629992961884]\n",
      "900 steps | score: [-0.06390833109617233]\n",
      "1000 steps | score: [-0.051356807351112366]\n",
      "1100 steps | score: [-0.02261425368487835]\n",
      "1200 steps | score: [-0.018158424645662308]\n",
      "1300 steps | score: [-0.04228350520133972]\n",
      "1400 steps | score: [-0.05629312992095947]\n",
      "1500 steps | score: [-0.045418351888656616]\n",
      "1600 steps | score: [-0.027588162571191788]\n",
      "1700 steps | score: [-0.03268549218773842]\n",
      "1800 steps | score: [-0.04231249913573265]\n",
      "1900 steps | score: [-0.03310312703251839]\n",
      "2000 steps | score: [-0.06715065240859985]\n",
      "2100 steps | score: [-0.039064276963472366]\n",
      "2200 steps | score: [-0.028963161632418633]\n",
      "2300 steps | score: [-0.05200900882482529]\n",
      "2400 steps | score: [-0.017266936600208282]\n",
      "2500 steps | score: [-0.05231623724102974]\n",
      "0 steps | score: [-0.3054681122303009, 0.9544774293899536]\n",
      "100 steps | score: [-0.3908786177635193, 1.0142455101013184]\n",
      "200 steps | score: [-0.4162420332431793, 0.9992022514343262]\n",
      "300 steps | score: [-0.3028087913990021, 0.6987687945365906]\n",
      "400 steps | score: [-0.6934004426002502, 1.4953621625900269]\n",
      "500 steps | score: [-0.654967725276947, 1.4182610511779785]\n",
      "600 steps | score: [-0.526113748550415, 1.1582775115966797]\n",
      "700 steps | score: [-0.45065510272979736, 1.02908456325531]\n",
      "800 steps | score: [-0.5610164403915405, 1.2747472524642944]\n",
      "900 steps | score: [-0.530885636806488, 1.2039142847061157]\n",
      "1000 steps | score: [-0.4497147500514984, 1.0194331407546997]\n",
      "1100 steps | score: [-0.5186755657196045, 1.155832052230835]\n",
      "1200 steps | score: [-0.5025656819343567, 1.1378623247146606]\n",
      "1300 steps | score: [-0.49780064821243286, 1.1273863315582275]\n",
      "1400 steps | score: [-0.4625098705291748, 1.0285509824752808]\n",
      "1500 steps | score: [-0.45974624156951904, 1.0535073280334473]\n",
      "1600 steps | score: [-0.4809005558490753, 1.0858001708984375]\n",
      "1700 steps | score: [-0.3680565655231476, 0.8228108882904053]\n",
      "1800 steps | score: [-0.39775797724723816, 0.9076956510543823]\n",
      "1900 steps | score: [-0.3478296101093292, 0.7903991341590881]\n",
      "2000 steps | score: [-0.5595884323120117, 1.24028480052948]\n",
      "2100 steps | score: [-0.3200097382068634, 0.6963237524032593]\n",
      "2200 steps | score: [-0.4354981780052185, 0.976483941078186]\n",
      "2300 steps | score: [-0.4786858856678009, 1.08424973487854]\n",
      "2400 steps | score: [-0.4432023763656616, 0.9861292839050293]\n",
      "2500 steps | score: [-0.4310658276081085, 1.0009335279464722]\n",
      "unknown params:  tensor([ 0.9617, -0.0958,  0.0832,  0.0654, -0.1998,  0.1346])\n",
      "gt params:  tensor([ 0.9511, -0.0706,  0.1038,  0.0863, -0.2005,  0.1231])\n",
      "ols params:  tensor([ 0.4329, -0.0455,  0.0436,  0.0387, -0.1005,  3.1738])\n",
      "unknown mse:  tensor(0.0003)\n",
      "ols mse:  tensor(1.5987)\n",
      "gt params:  tensor([ 0.9569, -0.0480,  0.1075,  0.0889, -0.1965,  0.1592])\n",
      "0 steps | score: [0.2926802337169647]\n",
      "100 steps | score: [-0.0008986406028270721]\n",
      "0 steps | score: [0.07658751308917999, -0.08759117126464844]\n",
      "100 steps | score: [-0.17187322676181793, 0.27659872174263]\n",
      "200 steps | score: [-0.29368361830711365, 0.4992981553077698]\n",
      "300 steps | score: [-0.0706658884882927, -0.01855531334877014]\n",
      "400 steps | score: [-0.17988817393779755, 0.22164279222488403]\n",
      "500 steps | score: [-0.03950129449367523, -0.06757733225822449]\n",
      "600 steps | score: [-0.08325199782848358, -0.03197001665830612]\n",
      "700 steps | score: [0.0006729986052960157, -0.2113361656665802]\n",
      "800 steps | score: [0.06446897238492966, -0.3618464767932892]\n",
      "900 steps | score: [0.011377623304724693, -0.2639734447002411]\n",
      "1000 steps | score: [0.24639850854873657, -0.8167049288749695]\n",
      "1100 steps | score: [-0.0015625163214281201, -0.20570960640907288]\n",
      "1200 steps | score: [-0.10028810799121857, 0.0032831020653247833]\n",
      "1300 steps | score: [-0.008389906957745552, -0.18655188381671906]\n",
      "1400 steps | score: [-0.10382776707410812, 0.02844437211751938]\n",
      "1500 steps | score: [-0.14701855182647705, 0.11650735139846802]\n",
      "1600 steps | score: [0.1430572122335434, -0.5427428483963013]\n",
      "1700 steps | score: [-0.125065416097641, 0.09738678485155106]\n",
      "1800 steps | score: [0.12269940972328186, -0.5071667432785034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [-0.17263606190681458, 0.17424356937408447]\n",
      "2000 steps | score: [-0.13707904517650604, 0.11911892890930176]\n",
      "2100 steps | score: [-0.0320199690759182, -0.11665357649326324]\n",
      "2200 steps | score: [-0.04296563193202019, -0.10371103137731552]\n",
      "2300 steps | score: [-0.04415508732199669, -0.09630408883094788]\n",
      "2400 steps | score: [-0.09953350573778152, 0.02544097602367401]\n",
      "2500 steps | score: [-0.1715700924396515, 0.1716262698173523]\n",
      "unknown params:  tensor([ 0.9821, -0.0578,  0.1216,  0.1002, -0.1763,  0.2230])\n",
      "gt params:  tensor([ 0.9569, -0.0480,  0.1075,  0.0889, -0.1965,  0.1592])\n",
      "ols params:  tensor([ 0.4432, -0.0281,  0.0570,  0.0528, -0.0899,  3.3082])\n",
      "unknown mse:  tensor(0.0009)\n",
      "ols mse:  tensor(1.6992)\n",
      "gt params:  tensor([ 0.9595, -0.0474,  0.1314,  0.0957, -0.1711,  0.0962])\n",
      "0 steps | score: [0.2827308177947998]\n",
      "100 steps | score: [-0.043758198618888855]\n",
      "200 steps | score: [0.03384774923324585]\n",
      "300 steps | score: [-0.05229134112596512]\n",
      "400 steps | score: [-0.01679881289601326]\n",
      "500 steps | score: [-0.008943714201450348]\n",
      "0 steps | score: [0.27661198377609253, -0.3559516966342926]\n",
      "100 steps | score: [-0.08086712658405304, 0.20879773795604706]\n",
      "200 steps | score: [0.22851954400539398, -0.44719886779785156]\n",
      "300 steps | score: [-0.09016015380620956, 0.18369944393634796]\n",
      "400 steps | score: [0.5098320245742798, -1.2142924070358276]\n",
      "500 steps | score: [-0.14780651032924652, 0.24033205211162567]\n",
      "600 steps | score: [0.06136972829699516, -0.11972986906766891]\n",
      "700 steps | score: [0.0859091505408287, -0.17708440124988556]\n",
      "800 steps | score: [0.15737803280353546, -0.3572627007961273]\n",
      "900 steps | score: [0.1250166893005371, -0.29061955213546753]\n",
      "1000 steps | score: [0.282005250453949, -0.6646313071250916]\n",
      "1100 steps | score: [0.11941714584827423, -0.3008652329444885]\n",
      "1200 steps | score: [0.19248740375041962, -0.4344078302383423]\n",
      "1300 steps | score: [0.20559504628181458, -0.43655550479888916]\n",
      "1400 steps | score: [0.20632904767990112, -0.48213186860084534]\n",
      "1500 steps | score: [0.0329132117331028, -0.09256773442029953]\n",
      "1600 steps | score: [0.07663921266794205, -0.19299370050430298]\n",
      "1700 steps | score: [0.05466332659125328, -0.14173288643360138]\n",
      "1800 steps | score: [0.13361166417598724, -0.29274994134902954]\n",
      "1900 steps | score: [0.21258988976478577, -0.5018998384475708]\n",
      "2000 steps | score: [0.1319034993648529, -0.3084840774536133]\n",
      "2100 steps | score: [0.0896122083067894, -0.20044894516468048]\n",
      "2200 steps | score: [0.055075738579034805, -0.1578751653432846]\n",
      "2300 steps | score: [0.14317013323307037, -0.3453309237957001]\n",
      "2400 steps | score: [0.23147457838058472, -0.5468199253082275]\n",
      "2500 steps | score: [0.09472988545894623, -0.2460123896598816]\n",
      "unknown params:  tensor([ 0.8411, -0.0543,  0.1129,  0.0811, -0.2017,  0.0477])\n",
      "gt params:  tensor([ 0.9595, -0.0474,  0.1314,  0.0957, -0.1711,  0.0962])\n",
      "ols params:  tensor([ 0.3793, -0.0273,  0.0539,  0.0409, -0.0978,  3.3754])\n",
      "unknown mse:  tensor(0.0030)\n",
      "ols mse:  tensor(1.8507)\n",
      "gt params:  tensor([ 0.9514, -0.0389,  0.1353,  0.0796, -0.1797,  0.1064])\n",
      "0 steps | score: [0.3075017035007477]\n",
      "100 steps | score: [-0.04246949404478073]\n",
      "200 steps | score: [0.006013408303260803]\n",
      "0 steps | score: [0.012161259539425373, 0.161040261387825]\n",
      "100 steps | score: [-0.42331644892692566, 0.8606452345848083]\n",
      "200 steps | score: [-0.2330842912197113, 0.47270673513412476]\n",
      "300 steps | score: [-0.36279934644699097, 0.7159976363182068]\n",
      "400 steps | score: [-0.24645215272903442, 0.4810601472854614]\n",
      "500 steps | score: [-0.013541795313358307, -0.03522416949272156]\n",
      "600 steps | score: [-0.20456324517726898, 0.377963125705719]\n",
      "700 steps | score: [-0.22373247146606445, 0.4277869462966919]\n",
      "800 steps | score: [-0.26460665464401245, 0.5133332014083862]\n",
      "900 steps | score: [-0.0940222516655922, 0.14176025986671448]\n",
      "1000 steps | score: [-0.010695663280785084, -0.02955544739961624]\n",
      "1100 steps | score: [-0.07518958300352097, 0.09027682989835739]\n",
      "1200 steps | score: [-0.1278766542673111, 0.20710381865501404]\n",
      "1300 steps | score: [-0.27588289976119995, 0.5192484855651855]\n",
      "1400 steps | score: [-0.2125653177499771, 0.38239389657974243]\n",
      "1500 steps | score: [-0.10874106734991074, 0.15886342525482178]\n",
      "1600 steps | score: [-0.06503371149301529, 0.05112111568450928]\n",
      "1700 steps | score: [-0.12054041028022766, 0.17504051327705383]\n",
      "1800 steps | score: [-0.06919418275356293, 0.0951303020119667]\n",
      "1900 steps | score: [-0.20495018362998962, 0.3617369830608368]\n",
      "2000 steps | score: [-0.14653122425079346, 0.2397834062576294]\n",
      "2100 steps | score: [-0.15603192150592804, 0.2921212911605835]\n",
      "2200 steps | score: [-0.21831689774990082, 0.4149682819843292]\n",
      "2300 steps | score: [-0.15322284400463104, 0.2524605691432953]\n",
      "2400 steps | score: [-0.16120243072509766, 0.2815518379211426]\n",
      "2500 steps | score: [-0.17603927850723267, 0.3076331615447998]\n",
      "unknown params:  tensor([ 0.9832, -0.0249,  0.1472,  0.0662, -0.2081,  0.2265])\n",
      "gt params:  tensor([ 0.9514, -0.0389,  0.1353,  0.0796, -0.1797,  0.1064])\n",
      "ols params:  tensor([ 0.4077, -0.0121,  0.0638,  0.0341, -0.0902,  3.5083])\n",
      "unknown mse:  tensor(0.0028)\n",
      "ols mse:  tensor(1.9807)\n",
      "gt params:  tensor([ 0.9554, -0.0362,  0.1075,  0.0917, -0.1767,  0.1443])\n",
      "0 steps | score: [0.33605697751045227]\n",
      "100 steps | score: [0.060961537063121796]\n",
      "200 steps | score: [0.024808768182992935]\n",
      "300 steps | score: [-0.05033433437347412]\n",
      "400 steps | score: [-0.009236201643943787]\n",
      "0 steps | score: [-0.0014231180539354682, 0.5424342155456543]\n",
      "100 steps | score: [-0.2548293471336365, 0.8996224999427795]\n",
      "200 steps | score: [-0.16469597816467285, 0.709703266620636]\n",
      "300 steps | score: [-0.32712826132774353, 0.9732509255409241]\n",
      "400 steps | score: [-0.23787176609039307, 0.7999767065048218]\n",
      "500 steps | score: [-0.27374032139778137, 0.8797593116760254]\n",
      "600 steps | score: [-0.21957840025424957, 0.723741888999939]\n",
      "700 steps | score: [-0.2594156265258789, 0.8433881998062134]\n",
      "800 steps | score: [-0.2625899910926819, 0.833037793636322]\n",
      "900 steps | score: [-0.26016271114349365, 0.8266209959983826]\n",
      "1000 steps | score: [0.053850673139095306, 0.12978075444698334]\n",
      "1100 steps | score: [-0.2479112595319748, 0.782691478729248]\n",
      "1200 steps | score: [-0.2154027819633484, 0.7237691879272461]\n",
      "1300 steps | score: [-0.14672625064849854, 0.5854718089103699]\n",
      "1400 steps | score: [-0.23212751746177673, 0.7715126276016235]\n",
      "1500 steps | score: [-0.1939544826745987, 0.6666001081466675]\n",
      "1600 steps | score: [-0.25253790616989136, 0.827997624874115]\n",
      "1700 steps | score: [-0.04214410111308098, 0.36100324988365173]\n",
      "1800 steps | score: [-0.2723468542098999, 0.8511241674423218]\n",
      "1900 steps | score: [-0.2014741450548172, 0.7120260000228882]\n",
      "2000 steps | score: [-0.10065259039402008, 0.49710318446159363]\n",
      "2100 steps | score: [-0.1552678644657135, 0.61625075340271]\n",
      "2200 steps | score: [-0.04473654925823212, 0.3127198815345764]\n",
      "2300 steps | score: [-0.1021571084856987, 0.46428996324539185]\n",
      "2400 steps | score: [-0.21882732212543488, 0.7413692474365234]\n",
      "2500 steps | score: [-0.10813707113265991, 0.4973874092102051]\n",
      "unknown params:  tensor([ 0.9034, -0.0113,  0.1031,  0.0989, -0.1903,  0.0362])\n",
      "gt params:  tensor([ 0.9554, -0.0362,  0.1075,  0.0917, -0.1767,  0.1443])\n",
      "ols params:  tensor([ 0.4068, -0.0072,  0.0511,  0.0516, -0.0945,  3.5735])\n",
      "unknown mse:  tensor(0.0025)\n",
      "ols mse:  tensor(2.0121)\n",
      "gt params:  tensor([ 0.9560, -0.0477,  0.1133,  0.0798, -0.2119,  0.2159])\n",
      "0 steps | score: [0.3314324915409088]\n",
      "100 steps | score: [0.030717991292476654]\n",
      "200 steps | score: [0.030652211979031563]\n",
      "300 steps | score: [0.07677517086267471]\n",
      "400 steps | score: [0.04168815165758133]\n",
      "500 steps | score: [-0.027795789763331413]\n",
      "600 steps | score: [-0.0018753614276647568]\n",
      "0 steps | score: [0.0632423385977745, 0.0592615082859993]\n",
      "100 steps | score: [0.08053145557641983, -0.13594451546669006]\n",
      "200 steps | score: [0.042735107243061066, -0.0979180857539177]\n",
      "300 steps | score: [0.15163294970989227, -0.38702356815338135]\n",
      "400 steps | score: [-0.13820184767246246, 0.226164773106575]\n",
      "500 steps | score: [-0.2248179167509079, 0.427092581987381]\n",
      "600 steps | score: [-0.1007365956902504, 0.15689346194267273]\n",
      "700 steps | score: [-0.1973104029893875, 0.34184491634368896]\n",
      "800 steps | score: [-0.2594078481197357, 0.43493133783340454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 steps | score: [-0.19826465845108032, 0.34623923897743225]\n",
      "1000 steps | score: [-0.2688446342945099, 0.4847307801246643]\n",
      "1100 steps | score: [-0.09452497959136963, 0.14532800018787384]\n",
      "1200 steps | score: [-0.1319718211889267, 0.2273353636264801]\n",
      "1300 steps | score: [-0.07882187515497208, 0.11545197665691376]\n",
      "1400 steps | score: [-0.11403840780258179, 0.1371745765209198]\n",
      "1500 steps | score: [-0.1599690020084381, 0.2737714350223541]\n",
      "1600 steps | score: [-0.17321187257766724, 0.2984699606895447]\n",
      "1700 steps | score: [-0.10041127353906631, 0.1276892125606537]\n",
      "1800 steps | score: [-0.0552385151386261, 0.047380998730659485]\n",
      "1900 steps | score: [-0.11869492381811142, 0.14084696769714355]\n",
      "2000 steps | score: [-0.09944457560777664, 0.14666587114334106]\n",
      "2100 steps | score: [-0.11746346950531006, 0.18358135223388672]\n",
      "2200 steps | score: [-0.15107890963554382, 0.23359741270542145]\n",
      "2300 steps | score: [-0.11541135609149933, 0.1571832001209259]\n",
      "2400 steps | score: [-0.06639969348907471, 0.06995414197444916]\n",
      "2500 steps | score: [-0.09110450744628906, 0.11799758672714233]\n",
      "2600 steps | score: [-0.15022985637187958, 0.24177345633506775]\n",
      "unknown params:  tensor([ 0.8962, -0.0337,  0.1035,  0.0492, -0.2211,  0.1336])\n",
      "gt params:  tensor([ 0.9560, -0.0477,  0.1133,  0.0798, -0.2119,  0.2159])\n",
      "ols params:  tensor([ 0.3930, -0.0127,  0.0475,  0.0222, -0.1049,  3.7510])\n",
      "unknown mse:  tensor(0.0019)\n",
      "ols mse:  tensor(2.1390)\n",
      "gt params:  tensor([ 0.9521, -0.0296,  0.1232,  0.0817, -0.1847,  0.0967])\n",
      "0 steps | score: [0.3129367232322693]\n",
      "100 steps | score: [0.040679045021533966]\n",
      "200 steps | score: [-0.07706907391548157]\n",
      "300 steps | score: [-0.048081547021865845]\n",
      "400 steps | score: [-0.06803940236568451]\n",
      "500 steps | score: [0.025145113468170166]\n",
      "600 steps | score: [-0.007193803787231445]\n",
      "0 steps | score: [0.2860940396785736, -0.22202713787555695]\n",
      "100 steps | score: [0.22150734066963196, -0.1827705204486847]\n",
      "200 steps | score: [0.2810577154159546, -0.4175165891647339]\n",
      "300 steps | score: [-0.019623201340436935, 0.20001256465911865]\n",
      "400 steps | score: [-0.02711651101708412, 0.20130757987499237]\n",
      "500 steps | score: [0.1439809948205948, -0.1277582347393036]\n",
      "600 steps | score: [0.15260480344295502, -0.1641083061695099]\n",
      "700 steps | score: [-0.07665389031171799, 0.26956236362457275]\n",
      "800 steps | score: [0.197645902633667, -0.2856556177139282]\n",
      "900 steps | score: [0.018418239429593086, 0.09363377094268799]\n",
      "1000 steps | score: [0.29534199833869934, -0.4769015908241272]\n",
      "1100 steps | score: [0.33679795265197754, -0.5768305063247681]\n",
      "1200 steps | score: [-0.08620688319206238, 0.2742902636528015]\n",
      "1300 steps | score: [-0.0062908753752708435, 0.13378989696502686]\n",
      "1400 steps | score: [0.07798110693693161, -0.024397507309913635]\n",
      "1500 steps | score: [0.08622249215841293, -0.051402218639850616]\n",
      "1600 steps | score: [0.08019515872001648, -0.05639376491308212]\n",
      "1700 steps | score: [-0.01348767802119255, 0.16431111097335815]\n",
      "1800 steps | score: [0.09145665913820267, -0.059104740619659424]\n",
      "1900 steps | score: [0.19351713359355927, -0.2569649815559387]\n",
      "2000 steps | score: [0.09410161525011063, -0.04288259148597717]\n",
      "2100 steps | score: [0.08326686173677444, -0.03355337679386139]\n",
      "2200 steps | score: [0.04068143665790558, 0.05458866059780121]\n",
      "2300 steps | score: [0.1241874173283577, -0.12956634163856506]\n",
      "2400 steps | score: [0.12259531021118164, -0.11824959516525269]\n",
      "2500 steps | score: [0.11388056725263596, -0.12411537766456604]\n",
      "unknown params:  tensor([ 0.9531, -0.0086,  0.1832,  0.1194, -0.1705,  0.1972])\n",
      "gt params:  tensor([ 0.9521, -0.0296,  0.1232,  0.0817, -0.1847,  0.0967])\n",
      "ols params:  tensor([ 0.3851, -0.0046,  0.0767,  0.0506, -0.0758,  3.7669])\n",
      "unknown mse:  tensor(0.0026)\n",
      "ols mse:  tensor(2.3012)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/3680678d-656b-4f5b-9fd1-48b8856871f5\n",
      "gt params:  tensor([ 0.2764,  0.4150, -0.0568,  0.1592,  0.5720,  0.0139])\n",
      "0 steps | score: [0.0034107770770788193]\n",
      "100 steps | score: [-0.25184595584869385]\n",
      "200 steps | score: [-0.14318802952766418]\n",
      "300 steps | score: [-0.17488102614879608]\n",
      "400 steps | score: [-0.1306086927652359]\n",
      "500 steps | score: [-0.13083776831626892]\n",
      "600 steps | score: [-0.16297417879104614]\n",
      "700 steps | score: [-0.10875017195940018]\n",
      "800 steps | score: [-0.1429617702960968]\n",
      "900 steps | score: [-0.058856770396232605]\n",
      "1000 steps | score: [-0.1475437879562378]\n",
      "1100 steps | score: [-0.17437240481376648]\n",
      "1200 steps | score: [-0.13179299235343933]\n",
      "1300 steps | score: [-0.14914043247699738]\n",
      "1400 steps | score: [-0.10409510135650635]\n",
      "1500 steps | score: [-0.1369873732328415]\n",
      "1600 steps | score: [-0.14875821769237518]\n",
      "1700 steps | score: [-0.14253729581832886]\n",
      "1800 steps | score: [-0.12187023460865021]\n",
      "1900 steps | score: [-0.09117437899112701]\n",
      "2000 steps | score: [-0.1363525092601776]\n",
      "2100 steps | score: [-0.12730509042739868]\n",
      "2200 steps | score: [-0.12922866642475128]\n",
      "2300 steps | score: [-0.14962325990200043]\n",
      "2400 steps | score: [-0.10385870933532715]\n",
      "2500 steps | score: [-0.1058845967054367]\n",
      "0 steps | score: [0.19339619576931, -0.18423344194889069]\n",
      "100 steps | score: [-0.15746738016605377, 0.6923142671585083]\n",
      "200 steps | score: [-0.06594464927911758, 0.31068331003189087]\n",
      "300 steps | score: [0.1751730889081955, -0.4255746304988861]\n",
      "400 steps | score: [-0.2382686734199524, 0.8044741749763489]\n",
      "500 steps | score: [-0.06932898610830307, 0.30920594930648804]\n",
      "600 steps | score: [-0.04426680877804756, 0.24759811162948608]\n",
      "700 steps | score: [0.0651923418045044, -0.13511908054351807]\n",
      "800 steps | score: [0.1329006552696228, -0.3683260679244995]\n",
      "900 steps | score: [0.32620909810066223, -1.0373834371566772]\n",
      "1000 steps | score: [0.04537154734134674, -0.0760788694024086]\n",
      "1100 steps | score: [-0.07053192704916, 0.32532843947410583]\n",
      "1200 steps | score: [0.05740756541490555, -0.11153452098369598]\n",
      "1300 steps | score: [-0.23552092909812927, 0.7956432104110718]\n",
      "1400 steps | score: [-0.051310233771800995, 0.2479456067085266]\n",
      "1500 steps | score: [0.05872489884495735, -0.04706317186355591]\n",
      "1600 steps | score: [0.003100499976426363, 0.04209200292825699]\n",
      "1700 steps | score: [0.11635135859251022, -0.3009827136993408]\n",
      "1800 steps | score: [-0.09594093263149261, 0.3782626688480377]\n",
      "1900 steps | score: [0.08784572780132294, -0.21747100353240967]\n",
      "2000 steps | score: [-0.07596594840288162, 0.2903178930282593]\n",
      "2100 steps | score: [0.02429639734327793, -0.013405948877334595]\n",
      "2200 steps | score: [0.060118451714515686, -0.0900648981332779]\n",
      "2300 steps | score: [0.04026225209236145, -0.009057343006134033]\n",
      "2400 steps | score: [0.1765017956495285, -0.5207552909851074]\n",
      "2500 steps | score: [-0.05426211655139923, 0.23804055154323578]\n",
      "unknown params:  tensor([ 0.2854,  0.4292, -0.0544,  0.1765,  0.6024, -0.0193])\n",
      "gt params:  tensor([ 0.2764,  0.4150, -0.0568,  0.1592,  0.5720,  0.0139])\n",
      "ols params:  tensor([ 0.2137,  0.3225, -0.0425,  0.1320,  0.4373,  0.6988])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(0.0834)\n",
      "gt params:  tensor([ 0.2857,  0.4236, -0.0563,  0.1614,  0.5731,  0.0184])\n",
      "0 steps | score: [0.269623339176178]\n",
      "100 steps | score: [0.09266118705272675]\n",
      "200 steps | score: [0.03562849014997482]\n",
      "300 steps | score: [0.00048181042075157166]\n",
      "0 steps | score: [0.41125237941741943, -0.8166542053222656]\n",
      "100 steps | score: [0.5249903798103333, -1.4372570514678955]\n",
      "200 steps | score: [0.32014063000679016, -0.9677575826644897]\n",
      "300 steps | score: [-0.007754819002002478, -0.025618329644203186]\n",
      "400 steps | score: [0.2881583869457245, -0.8469958305358887]\n",
      "500 steps | score: [0.6536192893981934, -2.0088133811950684]\n",
      "600 steps | score: [0.24777626991271973, -0.704436719417572]\n",
      "700 steps | score: [0.30651411414146423, -0.9617993235588074]\n",
      "800 steps | score: [0.08141281455755234, -0.2801048457622528]\n",
      "900 steps | score: [0.43504372239112854, -1.369582176208496]\n",
      "1000 steps | score: [0.48638761043548584, -1.5146751403808594]\n",
      "1100 steps | score: [0.21467338502407074, -0.6482968330383301]\n",
      "1200 steps | score: [0.1435496062040329, -0.4933837354183197]\n",
      "1300 steps | score: [0.11299659311771393, -0.36677584052085876]\n",
      "1400 steps | score: [0.32804933190345764, -0.987017810344696]\n",
      "1500 steps | score: [0.40126901865005493, -1.2459510564804077]\n",
      "1600 steps | score: [0.3373908996582031, -1.012921929359436]\n",
      "1700 steps | score: [0.217415913939476, -0.7008786797523499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 steps | score: [0.22018302977085114, -0.6406155228614807]\n",
      "1900 steps | score: [0.28747808933258057, -0.8689464926719666]\n",
      "2000 steps | score: [0.4420144855976105, -1.4016937017440796]\n",
      "2100 steps | score: [0.2730832099914551, -0.7991786003112793]\n",
      "2200 steps | score: [0.2504684329032898, -0.731943666934967]\n",
      "2300 steps | score: [0.28358563780784607, -0.8630246520042419]\n",
      "2400 steps | score: [0.3067743480205536, -0.9030423760414124]\n",
      "2500 steps | score: [0.3434319794178009, -1.0682653188705444]\n",
      "unknown params:  tensor([ 0.3152,  0.4545, -0.0540,  0.1795,  0.6336, -0.0199])\n",
      "gt params:  tensor([ 0.2857,  0.4236, -0.0563,  0.1614,  0.5731,  0.0184])\n",
      "ols params:  tensor([ 0.1981,  0.2794, -0.0360,  0.1111,  0.3782,  1.1231])\n",
      "unknown mse:  tensor(0.0012)\n",
      "ols mse:  tensor(0.2149)\n",
      "gt params:  tensor([ 0.2705,  0.4192, -0.0499,  0.1596,  0.5718,  0.0585])\n",
      "0 steps | score: [0.22167347371578217]\n",
      "100 steps | score: [0.023039819672703743]\n",
      "200 steps | score: [-0.07923880219459534]\n",
      "300 steps | score: [-0.022853301838040352]\n",
      "400 steps | score: [-0.00420021265745163]\n",
      "0 steps | score: [0.007302200421690941, 0.3764697313308716]\n",
      "100 steps | score: [0.04509061947464943, 0.026964113116264343]\n",
      "200 steps | score: [-0.26709237694740295, 0.7720527648925781]\n",
      "300 steps | score: [-0.19548586010932922, 0.5880239605903625]\n",
      "400 steps | score: [-0.25873273611068726, 0.6961265206336975]\n",
      "500 steps | score: [-0.2541853189468384, 0.7414911985397339]\n",
      "600 steps | score: [0.22884368896484375, -0.657723605632782]\n",
      "700 steps | score: [-0.39315885305404663, 1.0701854228973389]\n",
      "800 steps | score: [0.014736741781234741, -0.021411672234535217]\n",
      "900 steps | score: [-0.03150390461087227, 0.12810450792312622]\n",
      "1000 steps | score: [-0.0021966309286653996, 0.04606747627258301]\n",
      "1100 steps | score: [-0.08527912944555283, 0.27438509464263916]\n",
      "1200 steps | score: [-0.2480124682188034, 0.670113205909729]\n",
      "1300 steps | score: [-0.20953477919101715, 0.5818386077880859]\n",
      "1400 steps | score: [-0.1554744690656662, 0.4243025779724121]\n",
      "1500 steps | score: [-0.041172225028276443, 0.1084713339805603]\n",
      "1600 steps | score: [-0.025480231270194054, 0.10894396156072617]\n",
      "1700 steps | score: [-0.1162276491522789, 0.36292755603790283]\n",
      "1800 steps | score: [-0.17258648574352264, 0.5003008246421814]\n",
      "1900 steps | score: [-0.1723814159631729, 0.5168395042419434]\n",
      "2000 steps | score: [-0.01888227090239525, 0.11783668398857117]\n",
      "2100 steps | score: [0.007394556887447834, -0.04039835184812546]\n",
      "2200 steps | score: [-0.07571074366569519, 0.24927549064159393]\n",
      "2300 steps | score: [-0.21617871522903442, 0.636025071144104]\n",
      "2400 steps | score: [-0.14940521121025085, 0.3838297128677368]\n",
      "2500 steps | score: [-0.1000576764345169, 0.3363940119743347]\n",
      "unknown params:  tensor([ 0.2811,  0.4265, -0.0306,  0.1750,  0.6032,  0.1015])\n",
      "gt params:  tensor([ 0.2705,  0.4192, -0.0499,  0.1596,  0.5718,  0.0585])\n",
      "ols params:  tensor([ 0.1654,  0.2461, -0.0218,  0.1033,  0.3387,  1.4600])\n",
      "unknown mse:  tensor(0.0006)\n",
      "ols mse:  tensor(0.3440)\n",
      "gt params:  tensor([ 0.2707,  0.4097, -0.0502,  0.1682,  0.5822,  0.0131])\n",
      "0 steps | score: [0.3869640827178955]\n",
      "100 steps | score: [0.1519044041633606]\n",
      "200 steps | score: [0.16147984564304352]\n",
      "300 steps | score: [0.16648122668266296]\n",
      "400 steps | score: [0.17298932373523712]\n",
      "500 steps | score: [0.1571725606918335]\n",
      "600 steps | score: [0.14987021684646606]\n",
      "700 steps | score: [0.16038906574249268]\n",
      "800 steps | score: [0.16358420252799988]\n",
      "900 steps | score: [0.19294744729995728]\n",
      "1000 steps | score: [0.14533478021621704]\n",
      "1100 steps | score: [0.1726917028427124]\n",
      "1200 steps | score: [0.15708871185779572]\n",
      "1300 steps | score: [0.20109416544437408]\n",
      "1400 steps | score: [0.15045735239982605]\n",
      "1500 steps | score: [0.16102564334869385]\n",
      "1600 steps | score: [0.12854287028312683]\n",
      "1700 steps | score: [0.1480134129524231]\n",
      "1800 steps | score: [0.14688000082969666]\n",
      "1900 steps | score: [0.16655054688453674]\n",
      "2000 steps | score: [0.15134671330451965]\n",
      "2100 steps | score: [0.1314692348241806]\n",
      "2200 steps | score: [0.1436796486377716]\n",
      "2300 steps | score: [0.13586091995239258]\n",
      "2400 steps | score: [0.1462957262992859]\n",
      "2500 steps | score: [0.15434637665748596]\n",
      "0 steps | score: [0.135605126619339, -0.027602672576904297]\n",
      "100 steps | score: [-0.17528636753559113, 0.46712541580200195]\n",
      "200 steps | score: [-0.08955644816160202, 0.21347713470458984]\n",
      "300 steps | score: [-0.04328358173370361, 0.11286509037017822]\n",
      "400 steps | score: [-0.1293933093547821, 0.3093504309654236]\n",
      "500 steps | score: [-0.1686490923166275, 0.403158038854599]\n",
      "600 steps | score: [0.010039694607257843, -0.04668843001127243]\n",
      "700 steps | score: [0.07918185740709305, -0.18364006280899048]\n",
      "800 steps | score: [-0.14103518426418304, 0.29966655373573303]\n",
      "900 steps | score: [-0.03712848573923111, 0.06321649253368378]\n",
      "1000 steps | score: [-0.050803329795598984, 0.10448978841304779]\n",
      "1100 steps | score: [-0.026152316480875015, 0.0450173057615757]\n",
      "1200 steps | score: [-0.14205464720726013, 0.282778799533844]\n",
      "1300 steps | score: [0.03554548695683479, -0.10172989219427109]\n",
      "1400 steps | score: [0.00533860269933939, -0.018219053745269775]\n",
      "1500 steps | score: [0.008373386226594448, -0.023665308952331543]\n",
      "1600 steps | score: [-0.037401776760816574, 0.03288103640079498]\n",
      "1700 steps | score: [-0.10231489688158035, 0.21616312861442566]\n",
      "1800 steps | score: [-0.03772073611617088, 0.07273979485034943]\n",
      "1900 steps | score: [-0.042480140924453735, 0.08333567529916763]\n",
      "2000 steps | score: [-0.03188106045126915, 0.07922118902206421]\n",
      "2100 steps | score: [-0.10581428557634354, 0.20009714365005493]\n",
      "2200 steps | score: [-0.08444918692111969, 0.188068687915802]\n",
      "2300 steps | score: [-0.05002140626311302, 0.09120355546474457]\n",
      "2400 steps | score: [-0.030177531763911247, 0.044593971222639084]\n",
      "2500 steps | score: [-0.04991419240832329, 0.10794876515865326]\n",
      "unknown params:  tensor([ 0.2806,  0.3968, -0.0293,  0.1769,  0.6022,  0.0468])\n",
      "gt params:  tensor([ 0.2707,  0.4097, -0.0502,  0.1682,  0.5822,  0.0131])\n",
      "ols params:  tensor([ 0.1573,  0.2182, -0.0194,  0.0987,  0.3165,  1.6869])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(0.4879)\n",
      "gt params:  tensor([ 0.2767,  0.4287, -0.0539,  0.1527,  0.5704,  0.0662])\n",
      "0 steps | score: [0.5276488661766052]\n",
      "100 steps | score: [0.23204533755779266]\n",
      "200 steps | score: [0.2577716112136841]\n",
      "300 steps | score: [0.22014732658863068]\n",
      "400 steps | score: [0.2410205900669098]\n",
      "500 steps | score: [0.24389566481113434]\n",
      "600 steps | score: [0.2507184147834778]\n",
      "700 steps | score: [0.2346222996711731]\n",
      "800 steps | score: [0.21567240357398987]\n",
      "900 steps | score: [0.20879711210727692]\n",
      "1000 steps | score: [0.21343503892421722]\n",
      "1100 steps | score: [0.24379494786262512]\n",
      "1200 steps | score: [0.2238859236240387]\n",
      "1300 steps | score: [0.2346888780593872]\n",
      "1400 steps | score: [0.2556382715702057]\n",
      "1500 steps | score: [0.24853886663913727]\n",
      "1600 steps | score: [0.22330935299396515]\n",
      "1700 steps | score: [0.24158839881420135]\n",
      "1800 steps | score: [0.20049801468849182]\n",
      "1900 steps | score: [0.25245633721351624]\n",
      "2000 steps | score: [0.228361576795578]\n",
      "2100 steps | score: [0.21242831647396088]\n",
      "2200 steps | score: [0.2211776226758957]\n",
      "2300 steps | score: [0.19111965596675873]\n",
      "2400 steps | score: [0.2160840630531311]\n",
      "2500 steps | score: [0.21625080704689026]\n",
      "0 steps | score: [0.15918007493019104, 0.01665351912379265]\n",
      "100 steps | score: [-0.11432243883609772, 0.4718422293663025]\n",
      "200 steps | score: [0.1503911018371582, -0.2289605438709259]\n",
      "300 steps | score: [-0.03810492530465126, 0.19731278717517853]\n",
      "400 steps | score: [-0.16839422285556793, 0.5111240148544312]\n",
      "500 steps | score: [-0.044067442417144775, 0.21200159192085266]\n",
      "600 steps | score: [-0.07972384244203568, 0.29041898250579834]\n",
      "700 steps | score: [-0.10569274425506592, 0.36217546463012695]\n",
      "800 steps | score: [-0.14192040264606476, 0.42683401703834534]\n",
      "900 steps | score: [-0.0019482537172734737, 0.1107437014579773]\n",
      "1000 steps | score: [0.04230332374572754, -0.005656346678733826]\n",
      "1100 steps | score: [-0.08990128338336945, 0.3400895297527313]\n",
      "1200 steps | score: [-0.0782172828912735, 0.2728835940361023]\n",
      "1300 steps | score: [0.025076353922486305, 0.004329510033130646]\n",
      "1400 steps | score: [0.0767059251666069, -0.14690351486206055]\n",
      "1500 steps | score: [0.07166185230016708, -0.0927727073431015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 steps | score: [0.02045966312289238, 0.04424906149506569]\n",
      "1700 steps | score: [0.003910903353244066, 0.0830865129828453]\n",
      "1800 steps | score: [-0.04174596071243286, 0.1470944583415985]\n",
      "1900 steps | score: [-0.008213290013372898, 0.09289322793483734]\n",
      "2000 steps | score: [-0.005445082671940327, 0.08543048799037933]\n",
      "2100 steps | score: [0.030853882431983948, 0.005559444427490234]\n",
      "2200 steps | score: [0.045135777443647385, -0.06006889417767525]\n",
      "2300 steps | score: [-0.09613653272390366, 0.3155343234539032]\n",
      "2400 steps | score: [0.06608472764492035, -0.08136321604251862]\n",
      "2500 steps | score: [0.006513537373393774, 0.062087833881378174]\n",
      "unknown params:  tensor([ 0.2571,  0.4513, -0.0357,  0.1455,  0.5890,  0.0546])\n",
      "gt params:  tensor([ 0.2767,  0.4287, -0.0539,  0.1527,  0.5704,  0.0662])\n",
      "ols params:  tensor([ 0.1417,  0.2402, -0.0227,  0.0793,  0.3049,  1.8921])\n",
      "unknown mse:  tensor(0.0003)\n",
      "ols mse:  tensor(0.5774)\n",
      "gt params:  tensor([ 0.2690,  0.4097, -0.0421,  0.1487,  0.5731, -0.0298])\n",
      "0 steps | score: [0.40877413749694824]\n",
      "100 steps | score: [0.14093273878097534]\n",
      "200 steps | score: [0.12044980376958847]\n",
      "300 steps | score: [0.1129063069820404]\n",
      "400 steps | score: [0.17970040440559387]\n",
      "500 steps | score: [0.10639812797307968]\n",
      "600 steps | score: [0.16744734346866608]\n",
      "700 steps | score: [0.14768299460411072]\n",
      "800 steps | score: [0.09269864857196808]\n",
      "900 steps | score: [0.1317451447248459]\n",
      "1000 steps | score: [0.10920945554971695]\n",
      "1100 steps | score: [0.1309991180896759]\n",
      "1200 steps | score: [0.10342664271593094]\n",
      "1300 steps | score: [0.12337957322597504]\n",
      "1400 steps | score: [0.10231152921915054]\n",
      "1500 steps | score: [0.10881015658378601]\n",
      "1600 steps | score: [0.10157012939453125]\n",
      "1700 steps | score: [0.11941064894199371]\n",
      "1800 steps | score: [0.12213554978370667]\n",
      "1900 steps | score: [0.11221125721931458]\n",
      "2000 steps | score: [0.11982828378677368]\n",
      "2100 steps | score: [0.11335136741399765]\n",
      "2200 steps | score: [0.13743630051612854]\n",
      "2300 steps | score: [0.1189737617969513]\n",
      "2400 steps | score: [0.09690169990062714]\n",
      "2500 steps | score: [0.09557417035102844]\n",
      "2600 steps | score: [0.11225585639476776]\n",
      "2700 steps | score: [0.12119925022125244]\n",
      "2800 steps | score: [0.10924363136291504]\n",
      "2900 steps | score: [0.09912475943565369]\n",
      "0 steps | score: [0.2559886872768402, -0.26197177171707153]\n",
      "100 steps | score: [-0.11127062886953354, 0.3022422790527344]\n",
      "200 steps | score: [0.03669552132487297, -0.010476704686880112]\n",
      "300 steps | score: [0.31138840317726135, -0.6455326080322266]\n",
      "400 steps | score: [0.05595039948821068, -0.08809445798397064]\n",
      "500 steps | score: [0.008146504871547222, -0.027422579005360603]\n",
      "600 steps | score: [-0.013986006379127502, 0.06242797151207924]\n",
      "700 steps | score: [0.20264558494091034, -0.44699716567993164]\n",
      "800 steps | score: [0.24922172725200653, -0.5444081425666809]\n",
      "900 steps | score: [-0.052456069737672806, 0.11595480144023895]\n",
      "1000 steps | score: [-0.03126299008727074, 0.08889132738113403]\n",
      "1100 steps | score: [0.11027184873819351, -0.2312074899673462]\n",
      "1200 steps | score: [0.1222677230834961, -0.21623682975769043]\n",
      "1300 steps | score: [0.092196524143219, -0.16714197397232056]\n",
      "1400 steps | score: [-0.09163534641265869, 0.18739162385463715]\n",
      "1500 steps | score: [0.05564788728952408, -0.057506050914525986]\n",
      "1600 steps | score: [0.00935452152043581, -0.013895798474550247]\n",
      "1700 steps | score: [0.025242170318961143, -0.023076506331562996]\n",
      "1800 steps | score: [0.014004451222717762, -0.023998353630304337]\n",
      "1900 steps | score: [0.011064506135880947, 0.005507338792085648]\n",
      "2000 steps | score: [0.10612639039754868, -0.22603154182434082]\n",
      "2100 steps | score: [0.026297669857740402, -0.04425286874175072]\n",
      "2200 steps | score: [0.03296038135886192, -0.028315842151641846]\n",
      "2300 steps | score: [0.05816786363720894, -0.11815372854471207]\n",
      "2400 steps | score: [0.08491619676351547, -0.13861224055290222]\n",
      "2500 steps | score: [0.05188069865107536, -0.11793799698352814]\n",
      "2600 steps | score: [0.03719697520136833, -0.05265304818749428]\n",
      "2700 steps | score: [0.03435078263282776, -0.05327523127198219]\n",
      "2800 steps | score: [0.0405939444899559, -0.05506639927625656]\n",
      "2900 steps | score: [0.09122859686613083, -0.15035229921340942]\n",
      "unknown params:  tensor([ 0.3042,  0.4235, -0.0549,  0.1447,  0.5996, -0.0629])\n",
      "gt params:  tensor([ 0.2690,  0.4097, -0.0421,  0.1487,  0.5731, -0.0298])\n",
      "ols params:  tensor([ 0.1479,  0.2024, -0.0273,  0.0725,  0.2791,  2.0248])\n",
      "unknown mse:  tensor(0.0006)\n",
      "ols mse:  tensor(0.7286)\n",
      "gt params:  tensor([ 0.2784,  0.4152, -0.0548,  0.1765,  0.5783,  0.0224])\n",
      "0 steps | score: [0.30822688341140747]\n",
      "100 steps | score: [0.02846534550189972]\n",
      "200 steps | score: [-0.027768360450863838]\n",
      "300 steps | score: [-0.020030956715345383]\n",
      "400 steps | score: [-0.0058930544182658195]\n",
      "0 steps | score: [0.08728577941656113, 0.014489546418190002]\n",
      "100 steps | score: [-0.021344255656003952, 0.14636170864105225]\n",
      "200 steps | score: [-0.16502070426940918, 0.34719669818878174]\n",
      "300 steps | score: [-0.3989056348800659, 0.7775498032569885]\n",
      "400 steps | score: [-0.27938762307167053, 0.5419974327087402]\n",
      "500 steps | score: [-0.15525326132774353, 0.31008562445640564]\n",
      "600 steps | score: [-0.17834508419036865, 0.3582933247089386]\n",
      "700 steps | score: [-0.20042787492275238, 0.35282018780708313]\n",
      "800 steps | score: [-0.08226232975721359, 0.12965458631515503]\n",
      "900 steps | score: [-0.16601161658763885, 0.30254697799682617]\n",
      "1000 steps | score: [-0.15708623826503754, 0.2792239189147949]\n",
      "1100 steps | score: [-0.14041951298713684, 0.23236748576164246]\n",
      "1200 steps | score: [-0.24222052097320557, 0.4835374355316162]\n",
      "1300 steps | score: [-0.12822091579437256, 0.23128202557563782]\n",
      "1400 steps | score: [-0.16964909434318542, 0.35931694507598877]\n",
      "1500 steps | score: [-0.1385505348443985, 0.22707611322402954]\n",
      "1600 steps | score: [-0.1250440627336502, 0.22761845588684082]\n",
      "1700 steps | score: [-0.15505793690681458, 0.2776694595813751]\n",
      "1800 steps | score: [-0.03873583301901817, 0.03144792467355728]\n",
      "1900 steps | score: [-0.22485744953155518, 0.42382457852363586]\n",
      "2000 steps | score: [-0.06728149950504303, 0.10601546615362167]\n",
      "2100 steps | score: [-0.1697414070367813, 0.2941933870315552]\n",
      "2200 steps | score: [-0.15524649620056152, 0.2850424349308014]\n",
      "2300 steps | score: [-0.12182653695344925, 0.15081000328063965]\n",
      "2400 steps | score: [-0.18502047657966614, 0.32494595646858215]\n",
      "2500 steps | score: [-0.04043596237897873, 0.04721546918153763]\n",
      "unknown params:  tensor([ 0.2768,  0.4379, -0.0625,  0.2201,  0.5812, -0.0555])\n",
      "gt params:  tensor([ 0.2784,  0.4152, -0.0548,  0.1765,  0.5783,  0.0224])\n",
      "ols params:  tensor([ 0.1347,  0.2084, -0.0301,  0.1036,  0.2654,  2.1988])\n",
      "unknown mse:  tensor(0.0014)\n",
      "ols mse:  tensor(0.8173)\n",
      "gt params:  tensor([ 0.2750,  0.4173, -0.0469,  0.1623,  0.5889,  0.0436])\n",
      "0 steps | score: [0.30444422364234924]\n",
      "100 steps | score: [-0.02238927036523819]\n",
      "200 steps | score: [-0.005715373903512955]\n",
      "0 steps | score: [0.16670198738574982, -0.10675150156021118]\n",
      "100 steps | score: [0.1167236939072609, -0.12003859877586365]\n",
      "200 steps | score: [0.2048054188489914, -0.40038543939590454]\n",
      "300 steps | score: [0.035401880741119385, -0.030703984200954437]\n",
      "400 steps | score: [-0.01915179006755352, 0.06091564893722534]\n",
      "500 steps | score: [0.18184176087379456, -0.4436478018760681]\n",
      "600 steps | score: [0.006214226130396128, 0.0007179304957389832]\n",
      "unknown params:  tensor([ 0.2832,  0.3520, -0.0507,  0.1327,  0.5773,  0.0631])\n",
      "gt params:  tensor([ 0.2750,  0.4173, -0.0469,  0.1623,  0.5889,  0.0436])\n",
      "ols params:  tensor([ 0.1369,  0.1794, -0.0161,  0.0616,  0.2705,  2.3854])\n",
      "unknown mse:  tensor(0.0010)\n",
      "ols mse:  tensor(0.9453)\n",
      "gt params:  tensor([ 0.2718,  0.4261, -0.0442,  0.1573,  0.5807,  0.0298])\n",
      "0 steps | score: [0.23189221322536469]\n",
      "100 steps | score: [-0.05899818241596222]\n",
      "200 steps | score: [-0.04551319032907486]\n",
      "300 steps | score: [-0.09416411072015762]\n",
      "400 steps | score: [-0.07287515699863434]\n",
      "500 steps | score: [-0.033489491790533066]\n",
      "600 steps | score: [-0.04609609395265579]\n",
      "700 steps | score: [-0.06200722977519035]\n",
      "800 steps | score: [-0.07042676955461502]\n",
      "900 steps | score: [-0.044159211218357086]\n",
      "1000 steps | score: [-0.0380292683839798]\n",
      "1100 steps | score: [-0.07072792202234268]\n",
      "1200 steps | score: [-0.027722306549549103]\n",
      "1300 steps | score: [-0.047030314803123474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 steps | score: [-0.05133197829127312]\n",
      "1500 steps | score: [-0.04779243469238281]\n",
      "1600 steps | score: [-0.042764462530612946]\n",
      "1700 steps | score: [-0.05172117054462433]\n",
      "1800 steps | score: [-0.028169654309749603]\n",
      "1900 steps | score: [-0.03491993620991707]\n",
      "2000 steps | score: [-0.0511186346411705]\n",
      "2100 steps | score: [-0.04197196662425995]\n",
      "2200 steps | score: [-0.06126658245921135]\n",
      "2300 steps | score: [-0.08742451667785645]\n",
      "2400 steps | score: [-0.052786894142627716]\n",
      "2500 steps | score: [-0.04742325097322464]\n",
      "0 steps | score: [0.2609156668186188, -0.31758174300193787]\n",
      "100 steps | score: [0.19024835526943207, -0.31865549087524414]\n",
      "200 steps | score: [0.23396028578281403, -0.507568895816803]\n",
      "300 steps | score: [-0.09967267513275146, 0.2245786041021347]\n",
      "400 steps | score: [-0.11987737566232681, 0.23380622267723083]\n",
      "500 steps | score: [0.0869942307472229, -0.1843319833278656]\n",
      "600 steps | score: [0.22508612275123596, -0.5139225125312805]\n",
      "700 steps | score: [-0.027415981516242027, 0.012371761724352837]\n",
      "800 steps | score: [0.06107306852936745, -0.1476021260023117]\n",
      "900 steps | score: [0.08840657025575638, -0.20525944232940674]\n",
      "1000 steps | score: [0.05635036528110504, -0.12229878455400467]\n",
      "1100 steps | score: [0.11513835936784744, -0.2543916702270508]\n",
      "1200 steps | score: [0.10278315097093582, -0.2381836324930191]\n",
      "1300 steps | score: [0.022379670292139053, -0.07173416018486023]\n",
      "1400 steps | score: [0.13572725653648376, -0.3144700825214386]\n",
      "1500 steps | score: [0.11721884459257126, -0.2593817114830017]\n",
      "1600 steps | score: [0.1219634860754013, -0.2736271023750305]\n",
      "1700 steps | score: [0.08290678262710571, -0.24215318262577057]\n",
      "1800 steps | score: [0.07881340384483337, -0.17494526505470276]\n",
      "1900 steps | score: [0.11763671040534973, -0.28193461894989014]\n",
      "2000 steps | score: [0.02857627160847187, -0.08524762094020844]\n",
      "2100 steps | score: [0.10551891475915909, -0.2764570713043213]\n",
      "2200 steps | score: [0.12474749237298965, -0.31348612904548645]\n",
      "2300 steps | score: [0.03697970137000084, -0.1021948754787445]\n",
      "2400 steps | score: [0.11845146119594574, -0.31569066643714905]\n",
      "2500 steps | score: [0.10148615390062332, -0.22955045104026794]\n",
      "unknown params:  tensor([ 0.2874,  0.4127, -0.0714,  0.1692,  0.5803, -0.1002])\n",
      "gt params:  tensor([ 0.2718,  0.4261, -0.0442,  0.1573,  0.5807,  0.0298])\n",
      "ols params:  tensor([ 0.1348,  0.1923, -0.0364,  0.0813,  0.2599,  2.4892])\n",
      "unknown mse:  tensor(0.0030)\n",
      "ols mse:  tensor(1.0385)\n",
      "gt params:  tensor([ 0.2764,  0.4218, -0.0320,  0.1720,  0.5745,  0.0138])\n",
      "0 steps | score: [0.2484913468360901]\n",
      "100 steps | score: [-0.025315240025520325]\n",
      "200 steps | score: [-0.046173423528671265]\n",
      "300 steps | score: [-0.1118803471326828]\n",
      "400 steps | score: [-0.09179230034351349]\n",
      "500 steps | score: [-0.10112343728542328]\n",
      "600 steps | score: [0.0018791258335113525]\n",
      "0 steps | score: [0.15056249499320984, 0.040010735392570496]\n",
      "100 steps | score: [0.03484503552317619, 0.14920544624328613]\n",
      "200 steps | score: [0.07197263091802597, -0.0021831393241882324]\n",
      "300 steps | score: [-0.1579117476940155, 0.4446468949317932]\n",
      "400 steps | score: [-0.07390622049570084, 0.27970248460769653]\n",
      "500 steps | score: [0.06163961440324783, -0.06328518688678741]\n",
      "600 steps | score: [-0.010238300077617168, 0.13442125916481018]\n",
      "700 steps | score: [-0.030660251155495644, 0.1828552931547165]\n",
      "800 steps | score: [-0.01785840094089508, 0.14982670545578003]\n",
      "900 steps | score: [0.06455618888139725, -0.027797721326351166]\n",
      "1000 steps | score: [-0.15984034538269043, 0.42447566986083984]\n",
      "1100 steps | score: [-0.13050010800361633, 0.3824567198753357]\n",
      "1200 steps | score: [-0.006572973448783159, 0.12121066451072693]\n",
      "1300 steps | score: [-0.05468377098441124, 0.21947118639945984]\n",
      "1400 steps | score: [-0.06131526455283165, 0.22031886875629425]\n",
      "1500 steps | score: [-0.08240073174238205, 0.2635272145271301]\n",
      "1600 steps | score: [0.1283109188079834, -0.18650168180465698]\n",
      "1700 steps | score: [0.05778229609131813, -0.04389064013957977]\n",
      "1800 steps | score: [-0.02195773459970951, 0.12461943179368973]\n",
      "1900 steps | score: [-0.08196210116147995, 0.26165473461151123]\n",
      "2000 steps | score: [-0.10837597399950027, 0.32412436604499817]\n",
      "2100 steps | score: [-0.006149477791041136, 0.07899636030197144]\n",
      "2200 steps | score: [0.022220855578780174, 0.07265035808086395]\n",
      "2300 steps | score: [-0.0482160784304142, 0.1980442851781845]\n",
      "2400 steps | score: [-0.013399824500083923, 0.11181676387786865]\n",
      "2500 steps | score: [-0.11028040945529938, 0.31896722316741943]\n",
      "unknown params:  tensor([ 0.2166,  0.4025, -0.0206,  0.1694,  0.5831, -0.0892])\n",
      "gt params:  tensor([ 0.2764,  0.4218, -0.0320,  0.1720,  0.5745,  0.0138])\n",
      "ols params:  tensor([ 0.1008,  0.1880, -0.0106,  0.0798,  0.2607,  2.5922])\n",
      "unknown mse:  tensor(0.0025)\n",
      "ols mse:  tensor(1.1402)\n",
      "gt params:  tensor([ 0.2737,  0.4335, -0.0399,  0.1529,  0.5575,  0.0119])\n",
      "0 steps | score: [0.09243092685937881]\n",
      "100 steps | score: [-0.2209581434726715]\n",
      "200 steps | score: [-0.21787884831428528]\n",
      "300 steps | score: [-0.20542386174201965]\n",
      "400 steps | score: [-0.27009156346321106]\n",
      "500 steps | score: [-0.16093847155570984]\n",
      "600 steps | score: [-0.23525390028953552]\n",
      "700 steps | score: [-0.21383628249168396]\n",
      "800 steps | score: [-0.21695049107074738]\n",
      "900 steps | score: [-0.24541088938713074]\n",
      "1000 steps | score: [-0.20652085542678833]\n",
      "1100 steps | score: [-0.21121542155742645]\n",
      "1200 steps | score: [-0.24118366837501526]\n",
      "1300 steps | score: [-0.23325064778327942]\n",
      "1400 steps | score: [-0.24749533832073212]\n",
      "1500 steps | score: [-0.225507915019989]\n",
      "1600 steps | score: [-0.21515929698944092]\n",
      "1700 steps | score: [-0.21804316341876984]\n",
      "1800 steps | score: [-0.22646968066692352]\n",
      "1900 steps | score: [-0.2177947461605072]\n",
      "2000 steps | score: [-0.22517269849777222]\n",
      "2100 steps | score: [-0.21508115530014038]\n",
      "2200 steps | score: [-0.19929425418376923]\n",
      "2300 steps | score: [-0.2387467622756958]\n",
      "2400 steps | score: [-0.2123412787914276]\n",
      "2500 steps | score: [-0.2305508553981781]\n",
      "0 steps | score: [0.26512888073921204, -0.3131113648414612]\n",
      "100 steps | score: [-0.04323922470211983, 0.15861383080482483]\n",
      "200 steps | score: [0.24712659418582916, -0.47084861993789673]\n",
      "300 steps | score: [0.15428787469863892, -0.27323004603385925]\n",
      "400 steps | score: [-0.1878923922777176, 0.35264286398887634]\n",
      "500 steps | score: [0.2808002531528473, -0.6031772494316101]\n",
      "600 steps | score: [0.08495519310235977, -0.18139046430587769]\n",
      "700 steps | score: [-0.09024667739868164, 0.14086854457855225]\n",
      "800 steps | score: [0.16404274106025696, -0.3516174852848053]\n",
      "900 steps | score: [-0.135332852602005, 0.24924176931381226]\n",
      "1000 steps | score: [0.1489618420600891, -0.30473315715789795]\n",
      "1100 steps | score: [0.08054061233997345, -0.16591089963912964]\n",
      "1200 steps | score: [0.03226608410477638, -0.0853690430521965]\n",
      "1300 steps | score: [0.06397970020771027, -0.11165929585695267]\n",
      "1400 steps | score: [-0.06408356875181198, 0.11556496471166611]\n",
      "1500 steps | score: [0.15144285559654236, -0.355182945728302]\n",
      "1600 steps | score: [0.09964372962713242, -0.20859311521053314]\n",
      "1700 steps | score: [-0.029486818239092827, 0.03453893959522247]\n",
      "1800 steps | score: [-0.04869722202420235, 0.07897062599658966]\n",
      "1900 steps | score: [-0.01937527395784855, 0.021595284342765808]\n",
      "2000 steps | score: [0.09050440788269043, -0.2111673355102539]\n",
      "2100 steps | score: [0.0050084562972188, -0.02747446671128273]\n",
      "2200 steps | score: [0.03009842522442341, -0.06585769355297089]\n",
      "2300 steps | score: [0.03372887521982193, -0.0987686961889267]\n",
      "2400 steps | score: [-0.008811105042696, -0.0191827192902565]\n",
      "2500 steps | score: [0.05294525623321533, -0.14821705222129822]\n",
      "unknown params:  tensor([ 0.2741,  0.4500, -0.0705,  0.1386,  0.5236,  0.1158])\n",
      "gt params:  tensor([ 0.2737,  0.4335, -0.0399,  0.1529,  0.5575,  0.0119])\n",
      "ols params:  tensor([ 0.1171,  0.1926, -0.0319,  0.0604,  0.2224,  2.7996])\n",
      "unknown mse:  tensor(0.0022)\n",
      "ols mse:  tensor(1.3292)\n",
      "gt params:  tensor([ 0.2633,  0.4283, -0.0519,  0.1765,  0.5401,  0.0266])\n",
      "0 steps | score: [0.37338027358055115]\n",
      "100 steps | score: [0.11862332373857498]\n",
      "200 steps | score: [0.07858465611934662]\n",
      "300 steps | score: [0.08421654254198074]\n",
      "400 steps | score: [0.04518888145685196]\n",
      "500 steps | score: [0.05277722328901291]\n",
      "600 steps | score: [0.08322715759277344]\n",
      "700 steps | score: [0.06171376258134842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 steps | score: [0.090499147772789]\n",
      "900 steps | score: [0.04826541990041733]\n",
      "1000 steps | score: [0.06962209939956665]\n",
      "1100 steps | score: [0.08947554975748062]\n",
      "1200 steps | score: [0.054638948291540146]\n",
      "1300 steps | score: [0.070400670170784]\n",
      "1400 steps | score: [0.03530391678214073]\n",
      "1500 steps | score: [0.05239124968647957]\n",
      "1600 steps | score: [0.09633296728134155]\n",
      "1700 steps | score: [0.06029561161994934]\n",
      "1800 steps | score: [0.09138070046901703]\n",
      "1900 steps | score: [0.07824952900409698]\n",
      "2000 steps | score: [0.07960664480924606]\n",
      "2100 steps | score: [0.0923205018043518]\n",
      "2200 steps | score: [0.05749792605638504]\n",
      "2300 steps | score: [0.058534372597932816]\n",
      "2400 steps | score: [0.05351715162396431]\n",
      "2500 steps | score: [0.0717625766992569]\n",
      "0 steps | score: [0.22009558975696564, -0.2271689772605896]\n",
      "100 steps | score: [0.16290485858917236, -0.2287670075893402]\n",
      "200 steps | score: [0.4443756639957428, -0.9750611186027527]\n",
      "300 steps | score: [0.10105015337467194, -0.18110284209251404]\n",
      "400 steps | score: [-0.10197874158620834, 0.21863727271556854]\n",
      "500 steps | score: [-0.184562087059021, 0.3745839595794678]\n",
      "600 steps | score: [0.17112937569618225, -0.37150484323501587]\n",
      "700 steps | score: [0.38503965735435486, -0.9425114393234253]\n",
      "800 steps | score: [0.27637946605682373, -0.6337558031082153]\n",
      "900 steps | score: [-0.0052442229352891445, 0.013827338814735413]\n",
      "1000 steps | score: [-0.01598678156733513, 0.029808655381202698]\n",
      "1100 steps | score: [0.12887537479400635, -0.28480297327041626]\n",
      "1200 steps | score: [0.16597461700439453, -0.390140175819397]\n",
      "1300 steps | score: [0.23588958382606506, -0.5410825610160828]\n",
      "1400 steps | score: [0.012579760514199734, -0.01740402728319168]\n",
      "1500 steps | score: [-0.0030413558706641197, -0.02429851144552231]\n",
      "1600 steps | score: [0.035994868725538254, -0.07217161357402802]\n",
      "1700 steps | score: [0.01126419473439455, -0.04199640452861786]\n",
      "1800 steps | score: [0.06130596622824669, -0.1262715756893158]\n",
      "1900 steps | score: [0.046360213309526443, -0.10459506511688232]\n",
      "2000 steps | score: [0.06497927755117416, -0.18407468497753143]\n",
      "2100 steps | score: [0.049942195415496826, -0.13535583019256592]\n",
      "2200 steps | score: [-0.026005258783698082, 0.03621942549943924]\n",
      "2300 steps | score: [0.05176706984639168, -0.14965108036994934]\n",
      "2400 steps | score: [-0.02931569144129753, 0.05433656647801399]\n",
      "2500 steps | score: [0.08962183445692062, -0.1972302943468094]\n",
      "unknown params:  tensor([ 0.2161,  0.4195, -0.0530,  0.1622,  0.5677,  0.1096])\n",
      "gt params:  tensor([ 0.2633,  0.4283, -0.0519,  0.1765,  0.5401,  0.0266])\n",
      "ols params:  tensor([ 0.1005,  0.1918, -0.0252,  0.0740,  0.2543,  2.8882])\n",
      "unknown mse:  tensor(0.0017)\n",
      "ols mse:  tensor(1.3941)\n",
      "gt params:  tensor([ 0.2839,  0.4181, -0.0431,  0.1755,  0.5694, -0.0017])\n",
      "0 steps | score: [0.3287186026573181]\n",
      "100 steps | score: [0.03982973098754883]\n",
      "200 steps | score: [-0.0061653293669223785]\n",
      "0 steps | score: [-0.004494155757129192, 0.47664588689804077]\n",
      "100 steps | score: [-0.20734688639640808, 0.7761282324790955]\n",
      "200 steps | score: [-0.3933386504650116, 1.0745623111724854]\n",
      "300 steps | score: [-0.27079543471336365, 0.7913298606872559]\n",
      "400 steps | score: [-0.3665435314178467, 0.9935235381126404]\n",
      "500 steps | score: [0.0013191323960199952, 0.18603572249412537]\n",
      "600 steps | score: [-0.00757500110194087, 0.19177275896072388]\n",
      "700 steps | score: [-0.07066552340984344, 0.3282005190849304]\n",
      "800 steps | score: [0.028698092326521873, 0.03537563979625702]\n",
      "900 steps | score: [0.07383778691291809, -0.0007667094469070435]\n",
      "1000 steps | score: [-0.2372269332408905, 0.7359349131584167]\n",
      "1100 steps | score: [-0.13253135979175568, 0.4979536533355713]\n",
      "1200 steps | score: [-0.23539982736110687, 0.6997385621070862]\n",
      "1300 steps | score: [0.06530331820249557, 0.014220446348190308]\n",
      "1400 steps | score: [-0.11507388204336166, 0.3766818046569824]\n",
      "1500 steps | score: [-0.11568930745124817, 0.41702061891555786]\n",
      "1600 steps | score: [0.0026141214184463024, 0.1412469744682312]\n",
      "1700 steps | score: [-0.14564073085784912, 0.5117158889770508]\n",
      "1800 steps | score: [-0.08305160701274872, 0.3506552577018738]\n",
      "1900 steps | score: [-0.1278952658176422, 0.48073074221611023]\n",
      "2000 steps | score: [-0.12928524613380432, 0.4545343220233917]\n",
      "2100 steps | score: [-0.11722969263792038, 0.4483048915863037]\n",
      "2200 steps | score: [-0.2053949385881424, 0.6261841058731079]\n",
      "2300 steps | score: [-0.12086044251918793, 0.4213283658027649]\n",
      "2400 steps | score: [-0.10377316921949387, 0.3930072486400604]\n",
      "2500 steps | score: [-0.12842333316802979, 0.46683111786842346]\n",
      "2600 steps | score: [-0.10685684531927109, 0.45356374979019165]\n",
      "2700 steps | score: [-0.14744320511817932, 0.5060559511184692]\n",
      "2800 steps | score: [-0.12090428173542023, 0.4665287733078003]\n",
      "2900 steps | score: [-0.1845593899488449, 0.5744413137435913]\n",
      "unknown params:  tensor([ 0.2324,  0.4103, -0.0202,  0.1854,  0.5577,  0.0828])\n",
      "gt params:  tensor([ 0.2839,  0.4181, -0.0431,  0.1755,  0.5694, -0.0017])\n",
      "ols params:  tensor([ 0.1073,  0.1845, -0.0098,  0.0865,  0.2450,  2.9885])\n",
      "unknown mse:  tensor(0.0018)\n",
      "ols mse:  tensor(1.5235)\n",
      "gt params:  tensor([ 0.2564,  0.4347, -0.0459,  0.1613,  0.5997,  0.0089])\n",
      "0 steps | score: [0.30920010805130005]\n",
      "100 steps | score: [-0.022431962192058563]\n",
      "200 steps | score: [-0.04245833307504654]\n",
      "300 steps | score: [-0.00693880021572113]\n",
      "0 steps | score: [0.11977065354585648, -0.03948604315519333]\n",
      "100 steps | score: [0.17245280742645264, -0.3067740797996521]\n",
      "200 steps | score: [-0.13593798875808716, 0.29137223958969116]\n",
      "300 steps | score: [-0.07322275638580322, 0.13790398836135864]\n",
      "400 steps | score: [-0.20903828740119934, 0.4121347665786743]\n",
      "500 steps | score: [0.00718441279605031, -0.03446723520755768]\n",
      "600 steps | score: [0.1212102472782135, -0.3625260293483734]\n",
      "700 steps | score: [-0.16675390303134918, 0.29714155197143555]\n",
      "800 steps | score: [-0.06064733862876892, 0.05306578427553177]\n",
      "900 steps | score: [-0.1256014108657837, 0.2097276896238327]\n",
      "1000 steps | score: [-0.0765252634882927, 0.12073971331119537]\n",
      "1100 steps | score: [0.06621134281158447, -0.22801892459392548]\n",
      "1200 steps | score: [-0.22007925808429718, 0.4022819399833679]\n",
      "1300 steps | score: [-0.06413602083921432, 0.04682604968547821]\n",
      "1400 steps | score: [-0.14449498057365417, 0.2619290053844452]\n",
      "1500 steps | score: [-0.020655710250139236, -0.0036603836342692375]\n",
      "1600 steps | score: [0.01640244573354721, -0.11186730116605759]\n",
      "1700 steps | score: [-0.13941590487957, 0.2387729287147522]\n",
      "1800 steps | score: [-0.06109565123915672, 0.05694658309221268]\n",
      "1900 steps | score: [-0.07154452800750732, 0.08225768059492111]\n",
      "2000 steps | score: [-0.0215214304625988, -0.003173667937517166]\n",
      "2100 steps | score: [-0.029344340786337852, 0.007831483148038387]\n",
      "2200 steps | score: [-0.1389421820640564, 0.24052801728248596]\n",
      "2300 steps | score: [-0.020453201606869698, -0.055613115429878235]\n",
      "2400 steps | score: [-0.06195645406842232, 0.08626055717468262]\n",
      "2500 steps | score: [-0.0418938584625721, 0.061132486909627914]\n",
      "unknown params:  tensor([ 0.2788,  0.4999, -0.0145,  0.2051,  0.6103, -0.1316])\n",
      "gt params:  tensor([ 0.2564,  0.4347, -0.0459,  0.1613,  0.5997,  0.0089])\n",
      "ols params:  tensor([ 0.1176,  0.2105, -0.0111,  0.0862,  0.2526,  3.0997])\n",
      "unknown mse:  tensor(0.0046)\n",
      "ols mse:  tensor(1.6250)\n",
      "gt params:  tensor([ 0.2687,  0.4199, -0.0448,  0.1631,  0.5620,  0.0296])\n",
      "0 steps | score: [0.24402964115142822]\n",
      "100 steps | score: [-0.08891812711954117]\n",
      "200 steps | score: [-0.04921741038560867]\n",
      "300 steps | score: [-0.10765711963176727]\n",
      "400 steps | score: [-0.08842159062623978]\n",
      "500 steps | score: [-0.03627566248178482]\n",
      "600 steps | score: [-0.09853532165288925]\n",
      "700 steps | score: [-0.058985210955142975]\n",
      "800 steps | score: [-0.09085409343242645]\n",
      "900 steps | score: [-0.09809261560440063]\n",
      "1000 steps | score: [-0.06782349199056625]\n",
      "1100 steps | score: [-0.06385752558708191]\n",
      "1200 steps | score: [-0.09778040647506714]\n",
      "1300 steps | score: [-0.0897003561258316]\n",
      "1400 steps | score: [-0.09631790220737457]\n",
      "1500 steps | score: [-0.0890098363161087]\n",
      "1600 steps | score: [-0.056292787194252014]\n",
      "1700 steps | score: [-0.09758731722831726]\n",
      "1800 steps | score: [-0.08047627657651901]\n",
      "1900 steps | score: [-0.06385399401187897]\n",
      "2000 steps | score: [-0.06554271280765533]\n",
      "2100 steps | score: [-0.06909069418907166]\n",
      "2200 steps | score: [-0.07483958452939987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300 steps | score: [-0.07729589194059372]\n",
      "2400 steps | score: [-0.08201916515827179]\n",
      "2500 steps | score: [-0.08270427584648132]\n",
      "0 steps | score: [0.3177477717399597, -0.4120291471481323]\n",
      "100 steps | score: [0.13266879320144653, -0.19804982841014862]\n",
      "200 steps | score: [0.4193126857280731, -0.8319915533065796]\n",
      "300 steps | score: [0.21514099836349487, -0.41274234652519226]\n",
      "400 steps | score: [0.08733316510915756, -0.16780447959899902]\n",
      "500 steps | score: [0.17253205180168152, -0.3601209223270416]\n",
      "600 steps | score: [0.13652212917804718, -0.3097996115684509]\n",
      "700 steps | score: [0.4031408727169037, -0.9067844748497009]\n",
      "800 steps | score: [0.06082550063729286, -0.14091980457305908]\n",
      "900 steps | score: [0.08269069343805313, -0.19112548232078552]\n",
      "1000 steps | score: [0.4180541932582855, -0.9057052135467529]\n",
      "1100 steps | score: [0.1549261212348938, -0.3137238025665283]\n",
      "1200 steps | score: [0.2737678587436676, -0.6110000014305115]\n",
      "1300 steps | score: [0.0859081819653511, -0.1696692705154419]\n",
      "1400 steps | score: [0.08826732635498047, -0.21349884569644928]\n",
      "1500 steps | score: [0.35289663076400757, -0.7723597288131714]\n",
      "1600 steps | score: [0.15346798300743103, -0.3361909091472626]\n",
      "1700 steps | score: [0.008557909168303013, -0.06034857779741287]\n",
      "1800 steps | score: [0.12008048593997955, -0.25412532687187195]\n",
      "1900 steps | score: [0.13504944741725922, -0.29136940836906433]\n",
      "2000 steps | score: [0.1875983625650406, -0.4320978820323944]\n",
      "2100 steps | score: [0.236506387591362, -0.512249231338501]\n",
      "2200 steps | score: [0.08840964734554291, -0.19010446965694427]\n",
      "2300 steps | score: [0.1613343358039856, -0.31884801387786865]\n",
      "2400 steps | score: [0.10741405189037323, -0.25080880522727966]\n",
      "2500 steps | score: [0.17076268792152405, -0.36179235577583313]\n",
      "unknown params:  tensor([ 0.3224,  0.4562, -0.0491,  0.1856,  0.5899,  0.0453])\n",
      "gt params:  tensor([ 0.2687,  0.4199, -0.0448,  0.1631,  0.5620,  0.0296])\n",
      "ols params:  tensor([ 0.1268,  0.1784, -0.0235,  0.0729,  0.2281,  3.2100])\n",
      "unknown mse:  tensor(0.0010)\n",
      "ols mse:  tensor(1.7189)\n",
      "gt params:  tensor([ 0.2708,  0.4106, -0.0328,  0.1776,  0.5860, -0.0206])\n",
      "0 steps | score: [0.36596253514289856]\n",
      "100 steps | score: [0.041090115904808044]\n",
      "200 steps | score: [-0.008117713034152985]\n",
      "0 steps | score: [0.08647289872169495, 0.1090768426656723]\n",
      "100 steps | score: [-0.1429300606250763, 0.45976004004478455]\n",
      "200 steps | score: [-0.24969246983528137, 0.5930423140525818]\n",
      "300 steps | score: [-0.07587583363056183, 0.2645888030529022]\n",
      "400 steps | score: [-0.28763288259506226, 0.6476202607154846]\n",
      "500 steps | score: [-0.12735846638679504, 0.326648473739624]\n",
      "600 steps | score: [-0.2464708685874939, 0.5731927752494812]\n",
      "700 steps | score: [-0.15647202730178833, 0.3648633658885956]\n",
      "800 steps | score: [-0.10764813423156738, 0.2878609895706177]\n",
      "900 steps | score: [0.06647167354822159, -0.10473360866308212]\n",
      "1000 steps | score: [0.0518619641661644, -0.11991430819034576]\n",
      "1100 steps | score: [-0.1569558084011078, 0.3750980794429779]\n",
      "1200 steps | score: [0.019113723188638687, -0.013135716319084167]\n",
      "1300 steps | score: [-0.05548691004514694, 0.144012451171875]\n",
      "1400 steps | score: [0.0434073731303215, -0.09220042079687119]\n",
      "1500 steps | score: [-0.04821721464395523, 0.12785303592681885]\n",
      "1600 steps | score: [-0.0978531539440155, 0.2554100751876831]\n",
      "1700 steps | score: [-0.030349858105182648, 0.08284863084554672]\n",
      "1800 steps | score: [-0.09584151208400726, 0.2257756143808365]\n",
      "1900 steps | score: [-0.033200204372406006, 0.10154236853122711]\n",
      "2000 steps | score: [-0.09149152785539627, 0.23508808016777039]\n",
      "2100 steps | score: [0.0019390973029658198, 0.021788910031318665]\n",
      "2200 steps | score: [-0.05427385866641998, 0.1618691086769104]\n",
      "2300 steps | score: [-0.041596680879592896, 0.1198984906077385]\n",
      "2400 steps | score: [-0.09389519691467285, 0.20332610607147217]\n",
      "2500 steps | score: [-0.053943805396556854, 0.13571348786354065]\n",
      "2600 steps | score: [-0.04681113362312317, 0.10645834356546402]\n",
      "2700 steps | score: [-0.04964178055524826, 0.1345563530921936]\n",
      "2800 steps | score: [0.009951818734407425, -8.041411638259888e-05]\n",
      "unknown params:  tensor([ 0.2635,  0.4247, -0.0090,  0.1829,  0.5958,  0.1441])\n",
      "gt params:  tensor([ 0.2708,  0.4106, -0.0328,  0.1776,  0.5860, -0.0206])\n",
      "ols params:  tensor([ 1.1505e-01,  1.8077e-01, -2.0405e-03,  7.8073e-02,  2.4574e-01,\n",
      "         3.3188e+00])\n",
      "unknown mse:  tensor(0.0047)\n",
      "ols mse:  tensor(1.8926)\n",
      "gt params:  tensor([ 0.2787,  0.4524, -0.0491,  0.1621,  0.5638,  0.0355])\n",
      "0 steps | score: [0.2303742915391922]\n",
      "100 steps | score: [-0.05147503688931465]\n",
      "200 steps | score: [-0.05413685366511345]\n",
      "300 steps | score: [-0.04857083410024643]\n",
      "400 steps | score: [-0.10669386386871338]\n",
      "500 steps | score: [-0.09202013909816742]\n",
      "600 steps | score: [-0.0734531357884407]\n",
      "700 steps | score: [-0.0753142237663269]\n",
      "800 steps | score: [-0.0443381741642952]\n",
      "900 steps | score: [-0.12967583537101746]\n",
      "1000 steps | score: [-0.11280165612697601]\n",
      "1100 steps | score: [-0.08290252834558487]\n",
      "1200 steps | score: [-0.07666846364736557]\n",
      "1300 steps | score: [-0.06541982293128967]\n",
      "1400 steps | score: [-0.11504713445901871]\n",
      "1500 steps | score: [-0.11726567894220352]\n",
      "1600 steps | score: [-0.10250800102949142]\n",
      "1700 steps | score: [-0.06139200180768967]\n",
      "1800 steps | score: [-0.06503765285015106]\n",
      "1900 steps | score: [-0.09449334442615509]\n",
      "2000 steps | score: [-0.05496485158801079]\n",
      "2100 steps | score: [-0.07179153710603714]\n",
      "2200 steps | score: [-0.047631409019231796]\n",
      "2300 steps | score: [-0.0830642506480217]\n",
      "2400 steps | score: [-0.07878392934799194]\n",
      "2500 steps | score: [-0.09722530096769333]\n",
      "0 steps | score: [0.241167813539505, -0.2689201831817627]\n",
      "100 steps | score: [0.3849434554576874, -0.6731473207473755]\n",
      "200 steps | score: [0.042309198528528214, -0.03180258348584175]\n",
      "300 steps | score: [0.0011883771512657404, 0.031825076788663864]\n",
      "400 steps | score: [0.13835273683071136, -0.2663169205188751]\n",
      "500 steps | score: [0.2989582121372223, -0.6235381960868835]\n",
      "600 steps | score: [0.013851922936737537, -0.01765686273574829]\n",
      "700 steps | score: [-0.09075702726840973, 0.20912937819957733]\n",
      "800 steps | score: [0.09806980192661285, -0.20181064307689667]\n",
      "900 steps | score: [0.0017980382544919848, -0.00373263843357563]\n",
      "unknown params:  tensor([ 0.2089,  0.3973, -0.0956,  0.1513,  0.4666,  0.1481])\n",
      "gt params:  tensor([ 0.2787,  0.4524, -0.0491,  0.1621,  0.5638,  0.0355])\n",
      "ols params:  tensor([ 0.0965,  0.1851, -0.0455,  0.0693,  0.2193,  3.3717])\n",
      "unknown mse:  tensor(0.0054)\n",
      "ols mse:  tensor(1.8938)\n",
      "gt params:  tensor([ 0.2840,  0.4161, -0.0390,  0.1619,  0.6034,  0.0901])\n",
      "0 steps | score: [0.23590190708637238]\n",
      "100 steps | score: [-0.057096365839242935]\n",
      "200 steps | score: [-0.054016195237636566]\n",
      "300 steps | score: [-0.10096589475870132]\n",
      "400 steps | score: [-0.07156601548194885]\n",
      "500 steps | score: [-0.07790196686983109]\n",
      "600 steps | score: [-0.07248864322900772]\n",
      "700 steps | score: [-0.057472728192806244]\n",
      "800 steps | score: [-0.11134199798107147]\n",
      "900 steps | score: [-0.11432336270809174]\n",
      "1000 steps | score: [-0.1036728248000145]\n",
      "1100 steps | score: [-0.08750580996274948]\n",
      "1200 steps | score: [-0.11285313963890076]\n",
      "1300 steps | score: [-0.11091632395982742]\n",
      "1400 steps | score: [-0.1365058273077011]\n",
      "1500 steps | score: [-0.10238185524940491]\n",
      "1600 steps | score: [-0.08664128929376602]\n",
      "1700 steps | score: [-0.08823325484991074]\n",
      "1800 steps | score: [-0.11201076209545135]\n",
      "1900 steps | score: [-0.12103719264268875]\n",
      "2000 steps | score: [-0.09859351813793182]\n",
      "2100 steps | score: [-0.10331571847200394]\n",
      "2200 steps | score: [-0.07769883424043655]\n",
      "2300 steps | score: [-0.08989384770393372]\n",
      "2400 steps | score: [-0.11400376260280609]\n",
      "2500 steps | score: [-0.11993809044361115]\n",
      "0 steps | score: [0.26120641827583313, -0.3982849419116974]\n",
      "100 steps | score: [0.15014949440956116, -0.2982017993927002]\n",
      "200 steps | score: [0.14788508415222168, -0.3703187108039856]\n",
      "300 steps | score: [0.06000553444027901, -0.19373618066310883]\n",
      "400 steps | score: [0.1465408354997635, -0.40678828954696655]\n",
      "500 steps | score: [0.08290325105190277, -0.2757365107536316]\n",
      "600 steps | score: [0.32304877042770386, -0.8333066701889038]\n",
      "700 steps | score: [0.14325670897960663, -0.4256388545036316]\n",
      "800 steps | score: [0.0761481299996376, -0.26393747329711914]\n",
      "900 steps | score: [0.19625283777713776, -0.5511404871940613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 steps | score: [0.06333982944488525, -0.2606605291366577]\n",
      "1100 steps | score: [0.11276634782552719, -0.3700977861881256]\n",
      "1200 steps | score: [0.048807013779878616, -0.21630656719207764]\n",
      "1300 steps | score: [-0.08407657593488693, 0.0660446286201477]\n",
      "1400 steps | score: [0.047352202236652374, -0.226785808801651]\n",
      "1500 steps | score: [0.2235891968011856, -0.5973505973815918]\n",
      "1600 steps | score: [0.06765084713697433, -0.2689547538757324]\n",
      "1700 steps | score: [0.07035155594348907, -0.25682759284973145]\n",
      "1800 steps | score: [0.05369190499186516, -0.2144806683063507]\n",
      "1900 steps | score: [0.041704025119543076, -0.22898107767105103]\n",
      "2000 steps | score: [0.04144195839762688, -0.22567836940288544]\n",
      "2100 steps | score: [0.053957778960466385, -0.2237766832113266]\n",
      "2200 steps | score: [0.0786672905087471, -0.2949220836162567]\n",
      "2300 steps | score: [0.08567488193511963, -0.3040352463722229]\n",
      "2400 steps | score: [0.06239721551537514, -0.2577037513256073]\n",
      "2500 steps | score: [0.020295195281505585, -0.16821210086345673]\n",
      "unknown params:  tensor([0.3185, 0.3731, 0.0015, 0.1961, 0.6755, 0.1189])\n",
      "gt params:  tensor([ 0.2840,  0.4161, -0.0390,  0.1619,  0.6034,  0.0901])\n",
      "ols params:  tensor([ 1.2577e-01,  1.4414e-01, -9.2444e-04,  7.8224e-02,  2.5685e-01,\n",
      "         3.4906e+00])\n",
      "unknown mse:  tensor(0.0020)\n",
      "ols mse:  tensor(1.9651)\n",
      "gt params:  tensor([ 0.2765,  0.4306, -0.0310,  0.1859,  0.5770,  0.0197])\n",
      "0 steps | score: [0.3246784806251526]\n",
      "100 steps | score: [-0.06257615983486176]\n",
      "200 steps | score: [0.016976989805698395]\n",
      "300 steps | score: [0.031310610473155975]\n",
      "400 steps | score: [0.06125825643539429]\n",
      "500 steps | score: [-0.06763933598995209]\n",
      "600 steps | score: [-0.01819729246199131]\n",
      "700 steps | score: [0.031194310635328293]\n",
      "800 steps | score: [0.05075244605541229]\n",
      "900 steps | score: [0.04885145649313927]\n",
      "1000 steps | score: [-0.019457338377833366]\n",
      "1100 steps | score: [-0.016138749197125435]\n",
      "1200 steps | score: [0.04127751290798187]\n",
      "1300 steps | score: [0.04514210671186447]\n",
      "1400 steps | score: [0.027647636830806732]\n",
      "1500 steps | score: [-0.03875604644417763]\n",
      "1600 steps | score: [0.008019588887691498]\n",
      "0 steps | score: [0.1715322881937027, 0.2415509670972824]\n",
      "100 steps | score: [-0.11037948727607727, 0.6503896713256836]\n",
      "200 steps | score: [0.02919541858136654, 0.3376292884349823]\n",
      "300 steps | score: [0.05138678103685379, 0.24427570402622223]\n",
      "400 steps | score: [0.0745028555393219, 0.21157866716384888]\n",
      "500 steps | score: [-0.11102764308452606, 0.528737485408783]\n",
      "600 steps | score: [-0.0763193666934967, 0.4887206554412842]\n",
      "700 steps | score: [0.056187704205513, 0.22793349623680115]\n",
      "800 steps | score: [0.0328487791121006, 0.2606637477874756]\n",
      "900 steps | score: [0.18245020508766174, -0.07147520035505295]\n",
      "1000 steps | score: [-0.15106453001499176, 0.6102241277694702]\n",
      "1100 steps | score: [-0.18684448301792145, 0.6962355375289917]\n",
      "1200 steps | score: [0.053617384284734726, 0.25503620505332947]\n",
      "1300 steps | score: [0.02906789630651474, 0.2504570484161377]\n",
      "1400 steps | score: [0.010660180822014809, 0.3071417212486267]\n",
      "1500 steps | score: [-0.27513909339904785, 0.8385955095291138]\n",
      "1600 steps | score: [-0.11340298503637314, 0.528393030166626]\n",
      "1700 steps | score: [-0.1006765067577362, 0.5447314381599426]\n",
      "1800 steps | score: [-0.02331286482512951, 0.35879549384117126]\n",
      "1900 steps | score: [-0.10370326787233353, 0.5198075175285339]\n",
      "2000 steps | score: [-0.14959508180618286, 0.6244978308677673]\n",
      "2100 steps | score: [-0.08697625249624252, 0.4947206974029541]\n",
      "2200 steps | score: [-0.0651284009218216, 0.4651046395301819]\n",
      "2300 steps | score: [-0.013406177051365376, 0.3525802493095398]\n",
      "2400 steps | score: [-0.01962997205555439, 0.3690788745880127]\n",
      "2500 steps | score: [-0.09180239588022232, 0.5282119512557983]\n",
      "unknown params:  tensor([ 0.2411,  0.4081, -0.0889,  0.1612,  0.5642, -0.3009])\n",
      "gt params:  tensor([ 0.2765,  0.4306, -0.0310,  0.1859,  0.5770,  0.0197])\n",
      "ols params:  tensor([ 0.0985,  0.1683, -0.0355,  0.0671,  0.2246,  3.5526])\n",
      "unknown mse:  tensor(0.0181)\n",
      "ols mse:  tensor(2.1201)\n",
      "gt params:  tensor([ 0.2659,  0.4296, -0.0491,  0.1473,  0.5698,  0.0501])\n",
      "0 steps | score: [0.410146564245224]\n",
      "100 steps | score: [0.1050955206155777]\n",
      "200 steps | score: [0.09781486541032791]\n",
      "300 steps | score: [0.08801251649856567]\n",
      "400 steps | score: [0.0914514809846878]\n",
      "500 steps | score: [0.11951346695423126]\n",
      "600 steps | score: [0.10346504300832748]\n",
      "700 steps | score: [0.09848608821630478]\n",
      "800 steps | score: [0.08800368010997772]\n",
      "900 steps | score: [0.06093470752239227]\n",
      "1000 steps | score: [0.06818365305662155]\n",
      "1100 steps | score: [0.09134574234485626]\n",
      "1200 steps | score: [0.0940951257944107]\n",
      "1300 steps | score: [0.08661087602376938]\n",
      "1400 steps | score: [0.061947111040353775]\n",
      "1500 steps | score: [0.06620775163173676]\n",
      "1600 steps | score: [0.10636288672685623]\n",
      "1700 steps | score: [0.09553837776184082]\n",
      "1800 steps | score: [0.08149752020835876]\n",
      "1900 steps | score: [0.09861408174037933]\n",
      "2000 steps | score: [0.07131921499967575]\n",
      "2100 steps | score: [0.05772223696112633]\n",
      "2200 steps | score: [0.08848979324102402]\n",
      "2300 steps | score: [0.07408678531646729]\n",
      "2400 steps | score: [0.0757349357008934]\n",
      "2500 steps | score: [0.0699324831366539]\n",
      "0 steps | score: [0.2497979700565338, -0.31619328260421753]\n",
      "100 steps | score: [-0.010442654602229595, 0.08396124094724655]\n",
      "200 steps | score: [-0.0692078098654747, 0.14225611090660095]\n",
      "300 steps | score: [0.09225325286388397, -0.18089015781879425]\n",
      "400 steps | score: [0.23823966085910797, -0.5045953989028931]\n",
      "500 steps | score: [0.10640893876552582, -0.24665650725364685]\n",
      "600 steps | score: [0.016397345811128616, -0.09252701699733734]\n",
      "700 steps | score: [0.3312113881111145, -0.7736377716064453]\n",
      "800 steps | score: [0.1666538566350937, -0.40297365188598633]\n",
      "900 steps | score: [0.00043423028546385467, -0.027777764946222305]\n",
      "1000 steps | score: [0.0966445729136467, -0.23624494671821594]\n",
      "1100 steps | score: [0.16420117020606995, -0.4045642912387848]\n",
      "1200 steps | score: [-0.03632916510105133, 0.03801221027970314]\n",
      "1300 steps | score: [0.008480015210807323, -0.08119216561317444]\n",
      "1400 steps | score: [-0.0007444241782650352, -0.05070560425519943]\n",
      "1500 steps | score: [0.08853521943092346, -0.26458871364593506]\n",
      "1600 steps | score: [0.173550084233284, -0.4470292925834656]\n",
      "1700 steps | score: [0.09692677855491638, -0.2559318244457245]\n",
      "1800 steps | score: [0.011753570288419724, -0.061662979423999786]\n",
      "1900 steps | score: [0.12148866802453995, -0.301535040140152]\n",
      "2000 steps | score: [0.06343628466129303, -0.20057442784309387]\n",
      "2100 steps | score: [0.04936716705560684, -0.18309462070465088]\n",
      "2200 steps | score: [0.1193571537733078, -0.2941335141658783]\n",
      "2300 steps | score: [0.09055963903665543, -0.24248933792114258]\n",
      "2400 steps | score: [0.11415278166532516, -0.2943282127380371]\n",
      "2500 steps | score: [0.001847360748797655, -0.04664367437362671]\n",
      "unknown params:  tensor([ 0.3121,  0.4785, -0.0882,  0.1401,  0.6697, -0.0474])\n",
      "gt params:  tensor([ 0.2659,  0.4296, -0.0491,  0.1473,  0.5698,  0.0501])\n",
      "ols params:  tensor([ 0.1121,  0.1685, -0.0355,  0.0544,  0.2354,  3.6698])\n",
      "unknown mse:  tensor(0.0043)\n",
      "ols mse:  tensor(2.2191)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/ee3692b6-22c4-4821-bc98-2645d625149c\n",
      "gt params:  tensor([ 0.0860, -0.0451, -0.3132, -0.5042, -0.3889, -0.7952])\n",
      "0 steps | score: [0.07354322820901871]\n",
      "100 steps | score: [-0.06533729285001755]\n",
      "200 steps | score: [-0.06966046988964081]\n",
      "300 steps | score: [-0.051854781806468964]\n",
      "400 steps | score: [-0.12870155274868011]\n",
      "500 steps | score: [-0.053889211267232895]\n",
      "600 steps | score: [-0.13187728822231293]\n",
      "700 steps | score: [-0.09189966320991516]\n",
      "800 steps | score: [-0.15195642411708832]\n",
      "900 steps | score: [-0.12208201736211777]\n",
      "1000 steps | score: [-0.09306669235229492]\n",
      "1100 steps | score: [-0.05362572520971298]\n",
      "1200 steps | score: [-0.16701239347457886]\n",
      "1300 steps | score: [-0.0927012488245964]\n",
      "1400 steps | score: [-0.0900336354970932]\n",
      "1500 steps | score: [-0.09214338660240173]\n",
      "1600 steps | score: [-0.1389978677034378]\n",
      "1700 steps | score: [-0.10459564626216888]\n",
      "1800 steps | score: [-0.09058080613613129]\n",
      "1900 steps | score: [-0.13114425539970398]\n",
      "2000 steps | score: [-0.11196374893188477]\n",
      "2100 steps | score: [-0.12176607549190521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200 steps | score: [-0.10620902478694916]\n",
      "2300 steps | score: [-0.15599307417869568]\n",
      "2400 steps | score: [-0.11514656990766525]\n",
      "2500 steps | score: [-0.1264059841632843]\n",
      "2600 steps | score: [-0.1104545071721077]\n",
      "0 steps | score: [0.19117794930934906, -0.19419288635253906]\n",
      "100 steps | score: [-0.16548322141170502, 0.47470027208328247]\n",
      "200 steps | score: [0.16697753965854645, -0.5239007472991943]\n",
      "300 steps | score: [0.480985164642334, -1.6151739358901978]\n",
      "400 steps | score: [0.072804294526577, -0.27737513184547424]\n",
      "500 steps | score: [-0.060334376990795135, 0.1310054063796997]\n",
      "600 steps | score: [-0.15015853941440582, 0.32005640864372253]\n",
      "700 steps | score: [0.03830971196293831, -0.20008745789527893]\n",
      "800 steps | score: [-0.10310882329940796, 0.17010283470153809]\n",
      "900 steps | score: [-0.0761183500289917, 0.16904456913471222]\n",
      "1000 steps | score: [0.11902183294296265, -0.4676989018917084]\n",
      "1100 steps | score: [0.18153485655784607, -0.6651415824890137]\n",
      "1200 steps | score: [-0.06062958389520645, 0.04680090397596359]\n",
      "1300 steps | score: [0.12742984294891357, -0.5169378519058228]\n",
      "1400 steps | score: [-0.1297827810049057, 0.268282413482666]\n",
      "1500 steps | score: [0.00197099638171494, -0.07518273591995239]\n",
      "1600 steps | score: [0.00873494055122137, -0.06906921416521072]\n",
      "1700 steps | score: [-0.09807531535625458, 0.15198303759098053]\n",
      "1800 steps | score: [0.09071953594684601, -0.36637577414512634]\n",
      "1900 steps | score: [-0.13781395554542542, 0.3014136254787445]\n",
      "2000 steps | score: [-0.0725928470492363, 0.12763606011867523]\n",
      "2100 steps | score: [-0.05577271804213524, 0.06499555706977844]\n",
      "2200 steps | score: [-0.017628004774451256, -0.05243302136659622]\n",
      "2300 steps | score: [-0.1362573355436325, 0.31028372049331665]\n",
      "2400 steps | score: [-0.09285831451416016, 0.12585151195526123]\n",
      "2500 steps | score: [-0.005431022960692644, -0.07306545227766037]\n",
      "2600 steps | score: [-0.03269850090146065, -0.021436505019664764]\n",
      "unknown params:  tensor([ 0.0930, -0.0479, -0.3136, -0.5084, -0.3896, -0.5250])\n",
      "gt params:  tensor([ 0.0860, -0.0451, -0.3132, -0.5042, -0.3889, -0.7952])\n",
      "ols params:  tensor([ 0.0622, -0.0308, -0.2128, -0.3281, -0.2587,  0.3007])\n",
      "unknown mse:  tensor(0.0122)\n",
      "ols mse:  tensor(0.2100)\n",
      "gt params:  tensor([ 0.0855, -0.0577, -0.3147, -0.5073, -0.3813, -0.7995])\n",
      "0 steps | score: [0.35690757632255554]\n",
      "100 steps | score: [0.06318283081054688]\n",
      "200 steps | score: [0.1799018532037735]\n",
      "300 steps | score: [0.10134260356426239]\n",
      "400 steps | score: [0.13837239146232605]\n",
      "500 steps | score: [0.04736919701099396]\n",
      "600 steps | score: [0.12494136393070221]\n",
      "700 steps | score: [0.11623597145080566]\n",
      "800 steps | score: [0.1170380711555481]\n",
      "900 steps | score: [0.0931166261434555]\n",
      "1000 steps | score: [0.12149196863174438]\n",
      "1100 steps | score: [0.0921483039855957]\n",
      "1200 steps | score: [0.07219588756561279]\n",
      "1300 steps | score: [0.10564885288476944]\n",
      "1400 steps | score: [0.10344408452510834]\n",
      "1500 steps | score: [0.052680712193250656]\n",
      "1600 steps | score: [0.08267281949520111]\n",
      "1700 steps | score: [0.095832459628582]\n",
      "1800 steps | score: [0.10513408482074738]\n",
      "1900 steps | score: [0.07572267949581146]\n",
      "2000 steps | score: [0.07171158492565155]\n",
      "2100 steps | score: [0.09622837603092194]\n",
      "2200 steps | score: [0.07478296756744385]\n",
      "2300 steps | score: [0.09657163918018341]\n",
      "2400 steps | score: [0.06657686829566956]\n",
      "2500 steps | score: [0.09256680309772491]\n",
      "2600 steps | score: [0.0854211300611496]\n",
      "0 steps | score: [0.36036333441734314, -0.5759870409965515]\n",
      "100 steps | score: [0.13271276652812958, -0.23203042149543762]\n",
      "200 steps | score: [0.2338251918554306, -0.5085192322731018]\n",
      "300 steps | score: [-0.02636547200381756, 0.03518692031502724]\n",
      "400 steps | score: [0.9024970531463623, -2.5665030479431152]\n",
      "500 steps | score: [-0.14793537557125092, 0.2764774262905121]\n",
      "600 steps | score: [0.1466500163078308, -0.34898635745048523]\n",
      "700 steps | score: [0.40299472212791443, -1.00336492061615]\n",
      "800 steps | score: [0.14023926854133606, -0.328973650932312]\n",
      "900 steps | score: [0.19733430445194244, -0.46243855357170105]\n",
      "1000 steps | score: [0.09614061564207077, -0.24294252693653107]\n",
      "1100 steps | score: [0.1037360429763794, -0.26361480355262756]\n",
      "1200 steps | score: [0.3362705707550049, -0.8256978988647461]\n",
      "1300 steps | score: [0.311061292886734, -0.7705191969871521]\n",
      "1400 steps | score: [0.21540968120098114, -0.5362128615379333]\n",
      "1500 steps | score: [0.061699800193309784, -0.18603186309337616]\n",
      "1600 steps | score: [0.12742993235588074, -0.34191450476646423]\n",
      "1700 steps | score: [0.2682124972343445, -0.6840972900390625]\n",
      "1800 steps | score: [0.09305748343467712, -0.23730002343654633]\n",
      "1900 steps | score: [0.07673227787017822, -0.2194993942975998]\n",
      "2000 steps | score: [0.10475093126296997, -0.3142060935497284]\n",
      "2100 steps | score: [0.16155856847763062, -0.4423898458480835]\n",
      "2200 steps | score: [0.05083373188972473, -0.1683184802532196]\n",
      "2300 steps | score: [0.1337537169456482, -0.36249664425849915]\n",
      "2400 steps | score: [0.12499501556158066, -0.35240256786346436]\n",
      "2500 steps | score: [0.12923797965049744, -0.34857890009880066]\n",
      "2600 steps | score: [0.13947097957134247, -0.3810887634754181]\n",
      "unknown params:  tensor([ 0.0796, -0.0461, -0.3055, -0.4825, -0.3670, -0.4768])\n",
      "gt params:  tensor([ 0.0855, -0.0577, -0.3147, -0.5073, -0.3813, -0.7995])\n",
      "ols params:  tensor([ 0.0457, -0.0283, -0.1810, -0.2761, -0.2122,  0.7662])\n",
      "unknown mse:  tensor(0.0175)\n",
      "ols mse:  tensor(0.4256)\n",
      "gt params:  tensor([ 0.0893, -0.0461, -0.2999, -0.5100, -0.3926, -0.8059])\n",
      "0 steps | score: [0.18536020815372467]\n",
      "100 steps | score: [-0.05027928948402405]\n",
      "200 steps | score: [0.0063737183809280396]\n",
      "0 steps | score: [0.5092030167579651, -0.6942095160484314]\n",
      "100 steps | score: [0.5477168560028076, -0.9425748586654663]\n",
      "200 steps | score: [0.5065708160400391, -0.9472587704658508]\n",
      "300 steps | score: [0.18790172040462494, -0.22539319097995758]\n",
      "400 steps | score: [0.2066369205713272, -0.3114290237426758]\n",
      "500 steps | score: [0.6892809867858887, -1.523031234741211]\n",
      "600 steps | score: [0.20028117299079895, -0.30331337451934814]\n",
      "700 steps | score: [0.22122320532798767, -0.2828228175640106]\n",
      "800 steps | score: [0.23645198345184326, -0.3431720733642578]\n",
      "900 steps | score: [0.34237080812454224, -0.6183208227157593]\n",
      "1000 steps | score: [0.24655281007289886, -0.4375576376914978]\n",
      "1100 steps | score: [0.22609014809131622, -0.34785133600234985]\n",
      "1200 steps | score: [0.22703856229782104, -0.339464008808136]\n",
      "1300 steps | score: [0.304965078830719, -0.5246008038520813]\n",
      "1400 steps | score: [0.25978079438209534, -0.4275020360946655]\n",
      "1500 steps | score: [0.255115807056427, -0.4112522602081299]\n",
      "1600 steps | score: [0.29842624068260193, -0.49541598558425903]\n",
      "1700 steps | score: [0.4575466513633728, -0.867512583732605]\n",
      "1800 steps | score: [0.2251971811056137, -0.3320373296737671]\n",
      "1900 steps | score: [0.35492709279060364, -0.6388953924179077]\n",
      "2000 steps | score: [0.28200826048851013, -0.4930958151817322]\n",
      "2100 steps | score: [0.4561668634414673, -0.8813365697860718]\n",
      "2200 steps | score: [0.3126413822174072, -0.5499362945556641]\n",
      "2300 steps | score: [0.31318897008895874, -0.5651191473007202]\n",
      "2400 steps | score: [0.2844148874282837, -0.48388272523880005]\n",
      "2500 steps | score: [0.3466113209724426, -0.6562768816947937]\n",
      "2600 steps | score: [0.31709644198417664, -0.5297271609306335]\n",
      "2700 steps | score: [0.28039607405662537, -0.4673718512058258]\n",
      "unknown params:  tensor([ 0.0969, -0.0563, -0.2712, -0.4628, -0.4013, -0.4033])\n",
      "gt params:  tensor([ 0.0893, -0.0461, -0.2999, -0.5100, -0.3926, -0.8059])\n",
      "ols params:  tensor([ 0.0502, -0.0304, -0.1442, -0.2364, -0.2092,  1.0729])\n",
      "unknown mse:  tensor(0.0276)\n",
      "ols mse:  tensor(0.6108)\n",
      "gt params:  tensor([ 0.0880, -0.0492, -0.3124, -0.5031, -0.3815, -0.7906])\n",
      "0 steps | score: [0.3532525897026062]\n",
      "100 steps | score: [0.024321172386407852]\n",
      "200 steps | score: [0.09028775990009308]\n",
      "300 steps | score: [0.0007562600076198578]\n",
      "0 steps | score: [0.19184669852256775, -0.045233480632305145]\n",
      "100 steps | score: [0.1647266000509262, -0.15233221650123596]\n",
      "200 steps | score: [0.5040944814682007, -1.2034536600112915]\n",
      "300 steps | score: [-0.15136122703552246, 0.4430478811264038]\n",
      "400 steps | score: [0.7098180055618286, -2.018681287765503]\n",
      "500 steps | score: [0.3292810022830963, -0.8007020950317383]\n",
      "600 steps | score: [0.014125565066933632, 0.03034667856991291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 steps | score: [0.14156778156757355, -0.2837655544281006]\n",
      "800 steps | score: [-0.09773772209882736, 0.3095642328262329]\n",
      "900 steps | score: [0.014373056590557098, 0.09085385501384735]\n",
      "1000 steps | score: [0.38884979486465454, -0.9902524948120117]\n",
      "1100 steps | score: [0.022639762610197067, 0.008306656032800674]\n",
      "1200 steps | score: [0.1164945438504219, -0.2063957303762436]\n",
      "1300 steps | score: [-0.0291147343814373, 0.11436735838651657]\n",
      "1400 steps | score: [0.2706047594547272, -0.6298215985298157]\n",
      "1500 steps | score: [0.05648330599069595, -0.07178828865289688]\n",
      "1600 steps | score: [0.010405723936855793, 0.06531811505556107]\n",
      "1700 steps | score: [0.1259964406490326, -0.2439206838607788]\n",
      "1800 steps | score: [0.2258969247341156, -0.5702498555183411]\n",
      "1900 steps | score: [0.07528366893529892, -0.13625547289848328]\n",
      "2000 steps | score: [0.004694917239248753, 0.04195244610309601]\n",
      "2100 steps | score: [0.10986712574958801, -0.1881038248538971]\n",
      "2200 steps | score: [0.1509191244840622, -0.316959023475647]\n",
      "2300 steps | score: [0.1652074009180069, -0.36093977093696594]\n",
      "2400 steps | score: [0.09133818745613098, -0.18043367564678192]\n",
      "2500 steps | score: [0.12659691274166107, -0.21202433109283447]\n",
      "2600 steps | score: [0.1507250815629959, -0.2636455297470093]\n",
      "2700 steps | score: [0.12707503139972687, -0.24881510436534882]\n",
      "unknown params:  tensor([ 0.0954, -0.0501, -0.3389, -0.5116, -0.4084, -0.3794])\n",
      "gt params:  tensor([ 0.0880, -0.0492, -0.3124, -0.5031, -0.3815, -0.7906])\n",
      "ols params:  tensor([ 0.0414, -0.0235, -0.1537, -0.2207, -0.1807,  1.3508])\n",
      "unknown mse:  tensor(0.0284)\n",
      "ols mse:  tensor(0.7890)\n",
      "gt params:  tensor([ 0.0994, -0.0506, -0.3086, -0.4902, -0.3905, -0.8098])\n",
      "0 steps | score: [0.2947048842906952]\n",
      "100 steps | score: [-0.014222264289855957]\n",
      "200 steps | score: [-0.024937523528933525]\n",
      "300 steps | score: [0.023974988609552383]\n",
      "400 steps | score: [0.012915162369608879]\n",
      "500 steps | score: [-0.02800089493393898]\n",
      "600 steps | score: [-0.037840716540813446]\n",
      "700 steps | score: [-0.008252590894699097]\n",
      "0 steps | score: [0.12281936407089233, 0.10247939825057983]\n",
      "100 steps | score: [0.04517512395977974, 0.10750699788331985]\n",
      "200 steps | score: [-0.28625595569610596, 0.7159140706062317]\n",
      "300 steps | score: [0.0858817771077156, -0.12292563915252686]\n",
      "400 steps | score: [0.12876760959625244, -0.21807768940925598]\n",
      "500 steps | score: [0.20741114020347595, -0.4213952422142029]\n",
      "600 steps | score: [0.004819250665605068, 0.09597565233707428]\n",
      "700 steps | score: [-0.03514714166522026, 0.16117489337921143]\n",
      "800 steps | score: [-0.22312797605991364, 0.558931827545166]\n",
      "900 steps | score: [0.11667890101671219, -0.23394903540611267]\n",
      "1000 steps | score: [-0.004797282163053751, 0.06799162179231644]\n",
      "1100 steps | score: [-0.1466393768787384, 0.368511438369751]\n",
      "1200 steps | score: [-0.2018495798110962, 0.5071974992752075]\n",
      "1300 steps | score: [0.07077144086360931, -0.09426688402891159]\n",
      "1400 steps | score: [-0.07880783081054688, 0.25193217396736145]\n",
      "1500 steps | score: [-0.12204781919717789, 0.33496275544166565]\n",
      "1600 steps | score: [-0.09668081998825073, 0.2788811922073364]\n",
      "1700 steps | score: [-0.08401352912187576, 0.2440418004989624]\n",
      "1800 steps | score: [-0.0660901814699173, 0.23328852653503418]\n",
      "1900 steps | score: [-0.06197364255785942, 0.21056897938251495]\n",
      "2000 steps | score: [-0.11387371271848679, 0.3103090226650238]\n",
      "2100 steps | score: [-0.07828935980796814, 0.23071257770061493]\n",
      "2200 steps | score: [-0.029107384383678436, 0.14102882146835327]\n",
      "2300 steps | score: [-0.0030153142288327217, 0.05269941687583923]\n",
      "2400 steps | score: [-0.1050766333937645, 0.3086879253387451]\n",
      "2500 steps | score: [-0.057847652584314346, 0.17415347695350647]\n",
      "2600 steps | score: [-0.02190900407731533, 0.1332390010356903]\n",
      "2700 steps | score: [-0.026897845789790154, 0.08062561601400375]\n",
      "unknown params:  tensor([ 0.1138, -0.0666, -0.3386, -0.4682, -0.4140, -0.3669])\n",
      "gt params:  tensor([ 0.0994, -0.0506, -0.3086, -0.4902, -0.3905, -0.8098])\n",
      "ols params:  tensor([ 0.0477, -0.0291, -0.1468, -0.1977, -0.1782,  1.5332])\n",
      "unknown mse:  tensor(0.0331)\n",
      "ols mse:  tensor(0.9416)\n",
      "gt params:  tensor([ 0.0903, -0.0482, -0.3078, -0.5063, -0.3948, -0.8298])\n",
      "0 steps | score: [0.34847569465637207]\n",
      "100 steps | score: [0.022986888885498047]\n",
      "200 steps | score: [-0.03846639394760132]\n",
      "300 steps | score: [0.03169021010398865]\n",
      "400 steps | score: [0.011799192056059837]\n",
      "500 steps | score: [0.01673336699604988]\n",
      "600 steps | score: [-0.001851007342338562]\n",
      "0 steps | score: [0.17399686574935913, -0.15854619443416595]\n",
      "100 steps | score: [0.16849973797798157, -0.28502702713012695]\n",
      "200 steps | score: [-0.04279510676860809, 0.09007412195205688]\n",
      "300 steps | score: [0.026052089408040047, -0.07949686050415039]\n",
      "400 steps | score: [0.05280200019478798, -0.199733167886734]\n",
      "500 steps | score: [0.028503471985459328, -0.1342591792345047]\n",
      "600 steps | score: [0.0034295846708118916, -0.0796673446893692]\n",
      "700 steps | score: [-0.03427599370479584, -0.019582897424697876]\n",
      "800 steps | score: [-0.03212481364607811, -0.02638605609536171]\n",
      "900 steps | score: [-0.17343451082706451, 0.29863160848617554]\n",
      "1000 steps | score: [0.09221145510673523, -0.23877793550491333]\n",
      "1100 steps | score: [-0.20425638556480408, 0.3472885191440582]\n",
      "1200 steps | score: [0.03785621002316475, -0.15692833065986633]\n",
      "1300 steps | score: [0.01953548565506935, -0.11031904816627502]\n",
      "1400 steps | score: [0.03987063840031624, -0.17735007405281067]\n",
      "1500 steps | score: [-0.10643840581178665, 0.13726048171520233]\n",
      "1600 steps | score: [-0.07513150572776794, 0.08173121511936188]\n",
      "1700 steps | score: [0.08238131552934647, -0.25106412172317505]\n",
      "1800 steps | score: [0.03230433166027069, -0.17258673906326294]\n",
      "1900 steps | score: [0.06439895927906036, -0.25359752774238586]\n",
      "2000 steps | score: [-0.008756856434047222, -0.04993855953216553]\n",
      "2100 steps | score: [0.05394135043025017, -0.21288257837295532]\n",
      "2200 steps | score: [0.019019117578864098, -0.13584953546524048]\n",
      "2300 steps | score: [0.08004088699817657, -0.26205307245254517]\n",
      "2400 steps | score: [-0.01968120038509369, -0.04437848553061485]\n",
      "2500 steps | score: [0.04580944404006004, -0.19730524718761444]\n",
      "2600 steps | score: [0.022778725251555443, -0.10308423638343811]\n",
      "2700 steps | score: [0.022173333913087845, -0.11036121845245361]\n",
      "unknown params:  tensor([ 0.0710, -0.0464, -0.3346, -0.5447, -0.4109, -0.3662])\n",
      "gt params:  tensor([ 0.0903, -0.0482, -0.3078, -0.5063, -0.3948, -0.8298])\n",
      "ols params:  tensor([ 0.0325, -0.0200, -0.1465, -0.2291, -0.1755,  1.7080])\n",
      "unknown mse:  tensor(0.0363)\n",
      "ols mse:  tensor(1.0993)\n",
      "gt params:  tensor([ 0.0837, -0.0533, -0.3258, -0.4992, -0.3845, -0.8039])\n",
      "0 steps | score: [0.3157203495502472]\n",
      "100 steps | score: [-0.030427997931838036]\n",
      "200 steps | score: [-0.0014635386178269982]\n",
      "0 steps | score: [0.0664362907409668, 0.10269477218389511]\n",
      "100 steps | score: [-0.1592993140220642, 0.37585222721099854]\n",
      "200 steps | score: [-0.05315236374735832, 0.11313150078058243]\n",
      "300 steps | score: [-0.303091436624527, 0.6117185354232788]\n",
      "400 steps | score: [-0.2725103795528412, 0.5394930839538574]\n",
      "500 steps | score: [-0.20156759023666382, 0.34166717529296875]\n",
      "600 steps | score: [0.2498927265405655, -0.7267642021179199]\n",
      "700 steps | score: [-0.042762283235788345, 0.06609781086444855]\n",
      "800 steps | score: [0.03942637890577316, -0.1461864560842514]\n",
      "900 steps | score: [-0.005866320338100195, -0.14508500695228577]\n",
      "1000 steps | score: [-0.2534710466861725, 0.4870152473449707]\n",
      "1100 steps | score: [-0.251812219619751, 0.5032450556755066]\n",
      "1200 steps | score: [-0.1551530808210373, 0.301466166973114]\n",
      "1300 steps | score: [-0.10987084358930588, 0.17446500062942505]\n",
      "1400 steps | score: [-0.25250840187072754, 0.47568655014038086]\n",
      "1500 steps | score: [-0.16939666867256165, 0.30779320001602173]\n",
      "1600 steps | score: [-0.1512819230556488, 0.2571847438812256]\n",
      "1700 steps | score: [0.12243732064962387, -0.43571770191192627]\n",
      "1800 steps | score: [-0.16873817145824432, 0.2847782373428345]\n",
      "1900 steps | score: [-0.18565154075622559, 0.3370498716831207]\n",
      "2000 steps | score: [-0.1391604095697403, 0.22662678360939026]\n",
      "2100 steps | score: [-0.08311863988637924, 0.07461744546890259]\n",
      "2200 steps | score: [-0.16237732768058777, 0.30182209610939026]\n",
      "2300 steps | score: [-0.09239262342453003, 0.13128995895385742]\n",
      "2400 steps | score: [-0.05069979652762413, 0.05863513797521591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 steps | score: [-0.11083157360553741, 0.17352211475372314]\n",
      "2600 steps | score: [-0.0810391902923584, 0.154762402176857]\n",
      "2700 steps | score: [-0.12193011492490768, 0.18633131682872772]\n",
      "2800 steps | score: [-0.15342676639556885, 0.2829659581184387]\n",
      "unknown params:  tensor([ 0.0834, -0.0718, -0.3269, -0.5138, -0.4292, -0.3607])\n",
      "gt params:  tensor([ 0.0837, -0.0533, -0.3258, -0.4992, -0.3845, -0.8039])\n",
      "ols params:  tensor([ 0.0322, -0.0327, -0.1401, -0.2111, -0.1779,  1.8567])\n",
      "unknown mse:  tensor(0.0332)\n",
      "ols mse:  tensor(1.2070)\n",
      "gt params:  tensor([ 0.0925, -0.0601, -0.3078, -0.5023, -0.4290, -0.8764])\n",
      "0 steps | score: [0.29299819469451904]\n",
      "100 steps | score: [-0.014320379123091698]\n",
      "200 steps | score: [0.020958222448825836]\n",
      "300 steps | score: [-0.026555459946393967]\n",
      "400 steps | score: [0.021025538444519043]\n",
      "500 steps | score: [-0.013086356222629547]\n",
      "600 steps | score: [0.01712943986058235]\n",
      "700 steps | score: [-0.0051993317902088165]\n",
      "0 steps | score: [0.2670142650604248, -0.2971467971801758]\n",
      "100 steps | score: [0.07510386407375336, -0.03749867528676987]\n",
      "200 steps | score: [-0.013167008757591248, 0.07119913399219513]\n",
      "300 steps | score: [-0.11158305406570435, 0.25935643911361694]\n",
      "400 steps | score: [0.06951270997524261, -0.12757863104343414]\n",
      "500 steps | score: [0.00421101925894618, 0.017462514340877533]\n",
      "600 steps | score: [0.04685766249895096, -0.07279664278030396]\n",
      "700 steps | score: [0.001719703315757215, -0.00047926604747772217]\n",
      "unknown params:  tensor([ 0.1296, -0.0256, -0.2663, -0.3867, -0.3642, -0.1913])\n",
      "gt params:  tensor([ 0.0925, -0.0601, -0.3078, -0.5023, -0.4290, -0.8764])\n",
      "ols params:  tensor([ 0.0543, -0.0064, -0.1248, -0.1870, -0.1670,  2.0647])\n",
      "unknown mse:  tensor(0.0819)\n",
      "ols mse:  tensor(1.4759)\n",
      "gt params:  tensor([ 0.0881, -0.0535, -0.2956, -0.4989, -0.3885, -0.7733])\n",
      "0 steps | score: [0.4634426236152649]\n",
      "100 steps | score: [0.09657317399978638]\n",
      "200 steps | score: [0.15768539905548096]\n",
      "300 steps | score: [0.11822305619716644]\n",
      "400 steps | score: [0.12167972326278687]\n",
      "500 steps | score: [0.07809890061616898]\n",
      "600 steps | score: [0.1264936625957489]\n",
      "700 steps | score: [0.11468163132667542]\n",
      "800 steps | score: [0.11901392042636871]\n",
      "900 steps | score: [0.10211896896362305]\n",
      "1000 steps | score: [0.1065390408039093]\n",
      "1100 steps | score: [0.11058726906776428]\n",
      "1200 steps | score: [0.11572659015655518]\n",
      "1300 steps | score: [0.1165197342634201]\n",
      "1400 steps | score: [0.07678412646055222]\n",
      "1500 steps | score: [0.12936905026435852]\n",
      "1600 steps | score: [0.12651783227920532]\n",
      "1700 steps | score: [0.11263398826122284]\n",
      "1800 steps | score: [0.08999095112085342]\n",
      "1900 steps | score: [0.07947373390197754]\n",
      "2000 steps | score: [0.11656197905540466]\n",
      "2100 steps | score: [0.12065471708774567]\n",
      "2200 steps | score: [0.12169669568538666]\n",
      "2300 steps | score: [0.09945869445800781]\n",
      "2400 steps | score: [0.11859659850597382]\n",
      "2500 steps | score: [0.10371506214141846]\n",
      "2600 steps | score: [0.09991000592708588]\n",
      "2700 steps | score: [0.07960186153650284]\n",
      "2800 steps | score: [0.10256870090961456]\n",
      "2900 steps | score: [0.14633296430110931]\n",
      "0 steps | score: [0.00378020410425961, 0.31556397676467896]\n",
      "100 steps | score: [-0.09530206024646759, 0.38113877177238464]\n",
      "200 steps | score: [0.04673117399215698, -0.04999857023358345]\n",
      "300 steps | score: [-0.2908255159854889, 0.6818157434463501]\n",
      "400 steps | score: [-0.23555737733840942, 0.5696606636047363]\n",
      "500 steps | score: [-0.25933167338371277, 0.5775646567344666]\n",
      "600 steps | score: [-0.021143004298210144, 0.0592961423099041]\n",
      "700 steps | score: [-0.2147439867258072, 0.5157768130302429]\n",
      "800 steps | score: [-0.34771230816841125, 0.7584435939788818]\n",
      "900 steps | score: [-0.22412632405757904, 0.506342887878418]\n",
      "1000 steps | score: [0.014298065565526485, -0.0425831638276577]\n",
      "1100 steps | score: [-0.2893223166465759, 0.6586117148399353]\n",
      "1200 steps | score: [-0.16245393455028534, 0.38719475269317627]\n",
      "1300 steps | score: [-0.038486629724502563, 0.07744674384593964]\n",
      "1400 steps | score: [-0.23601776361465454, 0.5518883466720581]\n",
      "1500 steps | score: [-0.1727202832698822, 0.3968851864337921]\n",
      "1600 steps | score: [-0.12484834343194962, 0.31601789593696594]\n",
      "1700 steps | score: [-0.1808917224407196, 0.4210965633392334]\n",
      "1800 steps | score: [-0.18777094781398773, 0.42054712772369385]\n",
      "1900 steps | score: [-0.28279560804367065, 0.6413301229476929]\n",
      "2000 steps | score: [-0.22213861346244812, 0.506413996219635]\n",
      "2100 steps | score: [-0.1819937378168106, 0.4360533356666565]\n",
      "2200 steps | score: [-0.28544437885284424, 0.6375596523284912]\n",
      "2300 steps | score: [-0.137089341878891, 0.321283757686615]\n",
      "2400 steps | score: [-0.2735569179058075, 0.6007814407348633]\n",
      "2500 steps | score: [-0.21877767145633698, 0.4917178750038147]\n",
      "2600 steps | score: [-0.1888190507888794, 0.4675103724002838]\n",
      "2700 steps | score: [-0.1173631027340889, 0.28231292963027954]\n",
      "2800 steps | score: [-0.22654475271701813, 0.49161243438720703]\n",
      "2900 steps | score: [-0.23902899026870728, 0.5470404028892517]\n",
      "unknown params:  tensor([ 0.0317, -0.0529, -0.2774, -0.5153, -0.3740, -0.3321])\n",
      "gt params:  tensor([ 0.0881, -0.0535, -0.2956, -0.4989, -0.3885, -0.7733])\n",
      "ols params:  tensor([ 0.0165, -0.0224, -0.1211, -0.2094, -0.1574,  2.1629])\n",
      "unknown mse:  tensor(0.0331)\n",
      "ols mse:  tensor(1.4658)\n",
      "gt params:  tensor([ 0.1151, -0.0425, -0.3194, -0.5111, -0.3891, -0.7916])\n",
      "0 steps | score: [0.29701000452041626]\n",
      "100 steps | score: [-0.058113157749176025]\n",
      "200 steps | score: [-0.034879326820373535]\n",
      "300 steps | score: [-0.050599098205566406]\n",
      "400 steps | score: [-0.08217071741819382]\n",
      "500 steps | score: [-0.07426221668720245]\n",
      "600 steps | score: [-0.06413204222917557]\n",
      "700 steps | score: [-0.017642132937908173]\n",
      "800 steps | score: [-0.04633574187755585]\n",
      "900 steps | score: [-0.03276403993368149]\n",
      "1000 steps | score: [-0.06745363771915436]\n",
      "1100 steps | score: [-0.045514486730098724]\n",
      "1200 steps | score: [-0.05086386948823929]\n",
      "1300 steps | score: [-0.025155864655971527]\n",
      "1400 steps | score: [-0.06800027936697006]\n",
      "1500 steps | score: [-0.06211560219526291]\n",
      "1600 steps | score: [-0.04141666740179062]\n",
      "1700 steps | score: [-0.06123019754886627]\n",
      "1800 steps | score: [-0.05850799381732941]\n",
      "1900 steps | score: [-0.056178148835897446]\n",
      "2000 steps | score: [-0.05745620280504227]\n",
      "2100 steps | score: [-0.07086798548698425]\n",
      "2200 steps | score: [-0.045074909925460815]\n",
      "2300 steps | score: [-0.06846509873867035]\n",
      "2400 steps | score: [-0.04543822258710861]\n",
      "2500 steps | score: [-0.05593764781951904]\n",
      "0 steps | score: [-0.0022779821883887053, 0.27857810258865356]\n",
      "100 steps | score: [-0.1098223403096199, 0.39151856303215027]\n",
      "200 steps | score: [-0.1866789311170578, 0.4860798120498657]\n",
      "300 steps | score: [-0.3315981924533844, 0.7557227611541748]\n",
      "400 steps | score: [-0.4245043694972992, 0.9160435199737549]\n",
      "500 steps | score: [-0.2166309505701065, 0.46328192949295044]\n",
      "600 steps | score: [-0.3210487365722656, 0.6943255662918091]\n",
      "700 steps | score: [-0.22744451463222504, 0.5263251066207886]\n",
      "800 steps | score: [-0.32285448908805847, 0.6808186769485474]\n",
      "900 steps | score: [-0.24009636044502258, 0.5194790363311768]\n",
      "1000 steps | score: [-0.15183530747890472, 0.37610170245170593]\n",
      "1100 steps | score: [-0.0334075465798378, 0.06737850606441498]\n",
      "1200 steps | score: [-0.04490169510245323, 0.0707615315914154]\n",
      "1300 steps | score: [-0.12872855365276337, 0.26465949416160583]\n",
      "1400 steps | score: [-0.3029760420322418, 0.6648474931716919]\n",
      "1500 steps | score: [-0.2587575316429138, 0.571347713470459]\n",
      "1600 steps | score: [-0.19977092742919922, 0.4277472198009491]\n",
      "1700 steps | score: [-0.18808308243751526, 0.39432433247566223]\n",
      "1800 steps | score: [-0.25422975420951843, 0.5243604183197021]\n",
      "1900 steps | score: [-0.08402101695537567, 0.19776736199855804]\n",
      "2000 steps | score: [-0.28424662351608276, 0.5882201790809631]\n",
      "2100 steps | score: [-0.2897077798843384, 0.6172062754631042]\n",
      "2200 steps | score: [-0.23362478613853455, 0.49324241280555725]\n",
      "2300 steps | score: [-0.18675591051578522, 0.4069560170173645]\n",
      "2400 steps | score: [-0.1388731151819229, 0.3031097650527954]\n",
      "2500 steps | score: [-0.1579812914133072, 0.33659595251083374]\n",
      "unknown params:  tensor([ 0.1295, -0.0214, -0.3273, -0.5153, -0.3917, -0.3000])\n",
      "gt params:  tensor([ 0.1151, -0.0425, -0.3194, -0.5111, -0.3891, -0.7916])\n",
      "ols params:  tensor([ 0.0527, -0.0094, -0.1356, -0.2053, -0.1576,  2.3155])\n",
      "unknown mse:  tensor(0.0404)\n",
      "ols mse:  tensor(1.6400)\n",
      "gt params:  tensor([ 0.0947, -0.0600, -0.3230, -0.5294, -0.3935, -0.8291])\n",
      "0 steps | score: [0.5551907420158386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [0.21883313357830048]\n",
      "200 steps | score: [0.20038539171218872]\n",
      "300 steps | score: [0.2057996392250061]\n",
      "400 steps | score: [0.18367049098014832]\n",
      "500 steps | score: [0.24417522549629211]\n",
      "600 steps | score: [0.21774402260780334]\n",
      "700 steps | score: [0.20505769550800323]\n",
      "800 steps | score: [0.21935798227787018]\n",
      "900 steps | score: [0.22657597064971924]\n",
      "1000 steps | score: [0.2151740938425064]\n",
      "1100 steps | score: [0.19795602560043335]\n",
      "1200 steps | score: [0.24086697399616241]\n",
      "1300 steps | score: [0.25071898102760315]\n",
      "1400 steps | score: [0.2562401294708252]\n",
      "1500 steps | score: [0.1594284623861313]\n",
      "1600 steps | score: [0.22841832041740417]\n",
      "1700 steps | score: [0.23434971272945404]\n",
      "1800 steps | score: [0.24072565138339996]\n",
      "1900 steps | score: [0.1863090991973877]\n",
      "2000 steps | score: [0.19703365862369537]\n",
      "2100 steps | score: [0.2286655455827713]\n",
      "2200 steps | score: [0.2062646746635437]\n",
      "2300 steps | score: [0.21692867577075958]\n",
      "2400 steps | score: [0.21850207448005676]\n",
      "2500 steps | score: [0.23733040690422058]\n",
      "0 steps | score: [-0.03527724742889404, 0.20918047428131104]\n",
      "100 steps | score: [0.043156325817108154, -0.08463746309280396]\n",
      "200 steps | score: [-0.41201505064964294, 0.7364062070846558]\n",
      "300 steps | score: [-0.19798588752746582, 0.27654123306274414]\n",
      "400 steps | score: [-0.36548763513565063, 0.6283079981803894]\n",
      "500 steps | score: [-0.29300782084465027, 0.48144298791885376]\n",
      "600 steps | score: [-0.2584872245788574, 0.42068514227867126]\n",
      "700 steps | score: [-0.1878291368484497, 0.24617569148540497]\n",
      "800 steps | score: [-0.32342293858528137, 0.5159608125686646]\n",
      "900 steps | score: [-0.16178438067436218, 0.16553691029548645]\n",
      "1000 steps | score: [-0.19603115320205688, 0.257312148809433]\n",
      "1100 steps | score: [-0.2641993463039398, 0.39244771003723145]\n",
      "1200 steps | score: [-0.2546265721321106, 0.3928331136703491]\n",
      "1300 steps | score: [-0.2637249529361725, 0.38801512122154236]\n",
      "1400 steps | score: [-0.22555603086948395, 0.31845399737358093]\n",
      "1500 steps | score: [-0.3457862138748169, 0.5686166882514954]\n",
      "1600 steps | score: [-0.1731676459312439, 0.15530675649642944]\n",
      "1700 steps | score: [-0.22201643884181976, 0.34160488843917847]\n",
      "1800 steps | score: [-0.14358288049697876, 0.1852896809577942]\n",
      "1900 steps | score: [-0.3774932324886322, 0.6350087523460388]\n",
      "2000 steps | score: [-0.1692814826965332, 0.19032076001167297]\n",
      "2100 steps | score: [-0.1360693722963333, 0.11510097980499268]\n",
      "2200 steps | score: [-0.24975302815437317, 0.35526809096336365]\n",
      "2300 steps | score: [-0.2889048159122467, 0.47884464263916016]\n",
      "2400 steps | score: [-0.2736513316631317, 0.42300546169281006]\n",
      "2500 steps | score: [-0.2344125211238861, 0.33980804681777954]\n",
      "unknown params:  tensor([ 0.0233, -0.0635, -0.3353, -0.5987, -0.3914, -0.4591])\n",
      "gt params:  tensor([ 0.0947, -0.0600, -0.3230, -0.5294, -0.3935, -0.8291])\n",
      "ols params:  tensor([ 0.0099, -0.0225, -0.1230, -0.2159, -0.1425,  2.4648])\n",
      "unknown mse:  tensor(0.0245)\n",
      "ols mse:  tensor(1.8433)\n",
      "gt params:  tensor([ 0.0806, -0.0351, -0.3236, -0.5198, -0.3800, -0.7873])\n",
      "0 steps | score: [0.28139427304267883]\n",
      "100 steps | score: [-0.09135892987251282]\n",
      "200 steps | score: [-0.038052767515182495]\n",
      "300 steps | score: [-0.08925016224384308]\n",
      "400 steps | score: [-0.06903615593910217]\n",
      "500 steps | score: [-0.12430242449045181]\n",
      "600 steps | score: [-0.07149168848991394]\n",
      "700 steps | score: [-0.05939517542719841]\n",
      "800 steps | score: [-0.10735727846622467]\n",
      "900 steps | score: [-0.08414307981729507]\n",
      "1000 steps | score: [-0.07723268121480942]\n",
      "1100 steps | score: [-0.09414042532444]\n",
      "1200 steps | score: [-0.10096484422683716]\n",
      "1300 steps | score: [-0.09831652790307999]\n",
      "1400 steps | score: [-0.09582814574241638]\n",
      "1500 steps | score: [-0.0830460637807846]\n",
      "1600 steps | score: [-0.0790223553776741]\n",
      "1700 steps | score: [-0.10108940303325653]\n",
      "1800 steps | score: [-0.091519296169281]\n",
      "1900 steps | score: [-0.06476493924856186]\n",
      "2000 steps | score: [-0.062434472143650055]\n",
      "2100 steps | score: [-0.07336278259754181]\n",
      "2200 steps | score: [-0.07251624017953873]\n",
      "2300 steps | score: [-0.1158217191696167]\n",
      "2400 steps | score: [-0.06353738903999329]\n",
      "2500 steps | score: [-0.10269611328840256]\n",
      "0 steps | score: [-0.12823453545570374, 0.413127064704895]\n",
      "100 steps | score: [0.02661861665546894, -0.11833438277244568]\n",
      "200 steps | score: [-0.232358917593956, 0.41977858543395996]\n",
      "300 steps | score: [-0.38845279812812805, 0.7042813897132874]\n",
      "400 steps | score: [-0.4533386528491974, 0.8199978470802307]\n",
      "500 steps | score: [-0.27586936950683594, 0.4374794065952301]\n",
      "600 steps | score: [-0.3833450973033905, 0.6531965136528015]\n",
      "700 steps | score: [-0.32791757583618164, 0.5488632917404175]\n",
      "800 steps | score: [-0.4658266007900238, 0.8189795613288879]\n",
      "900 steps | score: [-0.327065646648407, 0.5422074198722839]\n",
      "1000 steps | score: [-0.15137410163879395, 0.1077893003821373]\n",
      "1100 steps | score: [-0.41012057662010193, 0.7225067615509033]\n",
      "1200 steps | score: [-0.2582797110080719, 0.383617639541626]\n",
      "1300 steps | score: [-0.27931761741638184, 0.4345630705356598]\n",
      "1400 steps | score: [-0.2120465487241745, 0.297423779964447]\n",
      "1500 steps | score: [-0.42183321714401245, 0.7464825510978699]\n",
      "1600 steps | score: [-0.31938421726226807, 0.5158725380897522]\n",
      "1700 steps | score: [-0.29172828793525696, 0.46537715196609497]\n",
      "1800 steps | score: [-0.3684668242931366, 0.6227734684944153]\n",
      "1900 steps | score: [-0.2697850167751312, 0.40076056122779846]\n",
      "2000 steps | score: [-0.40516915917396545, 0.6870084404945374]\n",
      "2100 steps | score: [-0.3627202808856964, 0.6420100331306458]\n",
      "2200 steps | score: [-0.3787773549556732, 0.6409940719604492]\n",
      "2300 steps | score: [-0.23699557781219482, 0.35113513469696045]\n",
      "2400 steps | score: [-0.29613927006721497, 0.4927861988544464]\n",
      "2500 steps | score: [-0.3966495394706726, 0.6833866834640503]\n",
      "unknown params:  tensor([ 0.0883, -0.0727, -0.3278, -0.5516, -0.4046, -0.3684])\n",
      "gt params:  tensor([ 0.0806, -0.0351, -0.3236, -0.5198, -0.3800, -0.7873])\n",
      "ols params:  tensor([ 0.0320, -0.0256, -0.1208, -0.1951, -0.1446,  2.5208])\n",
      "unknown mse:  tensor(0.0298)\n",
      "ols mse:  tensor(1.8579)\n",
      "gt params:  tensor([ 0.0737, -0.0466, -0.3064, -0.5213, -0.3890, -0.8471])\n",
      "0 steps | score: [0.43139100074768066]\n",
      "100 steps | score: [0.040610481053590775]\n",
      "200 steps | score: [0.10078664124011993]\n",
      "300 steps | score: [0.1421898603439331]\n",
      "400 steps | score: [0.07982829213142395]\n",
      "500 steps | score: [0.04398442804813385]\n",
      "600 steps | score: [0.06274758279323578]\n",
      "700 steps | score: [0.08397133648395538]\n",
      "800 steps | score: [0.0878935158252716]\n",
      "900 steps | score: [0.09954188019037247]\n",
      "1000 steps | score: [0.05289025977253914]\n",
      "1100 steps | score: [0.061491403728723526]\n",
      "1200 steps | score: [0.07087236642837524]\n",
      "1300 steps | score: [0.07079493999481201]\n",
      "1400 steps | score: [0.07271643728017807]\n",
      "1500 steps | score: [0.0618944950401783]\n",
      "1600 steps | score: [0.06273533403873444]\n",
      "1700 steps | score: [0.0793677568435669]\n",
      "1800 steps | score: [0.04283449053764343]\n",
      "1900 steps | score: [0.07541460543870926]\n",
      "2000 steps | score: [0.08212396502494812]\n",
      "2100 steps | score: [0.06220147758722305]\n",
      "2200 steps | score: [0.04745129123330116]\n",
      "2300 steps | score: [0.0756223201751709]\n",
      "2400 steps | score: [0.08327920734882355]\n",
      "2500 steps | score: [0.08909869194030762]\n",
      "0 steps | score: [0.31315886974334717, -0.37334656715393066]\n",
      "100 steps | score: [-0.01879500225186348, 0.1391240805387497]\n",
      "200 steps | score: [0.4041828513145447, -0.8057764172554016]\n",
      "300 steps | score: [0.41954681277275085, -0.899692177772522]\n",
      "400 steps | score: [-0.01096276007592678, 0.05960546433925629]\n",
      "500 steps | score: [-0.09927668422460556, 0.20092059671878815]\n",
      "600 steps | score: [0.1714714765548706, -0.3888390064239502]\n",
      "700 steps | score: [0.5426079630851746, -1.2509753704071045]\n",
      "800 steps | score: [0.11725743860006332, -0.2534160017967224]\n",
      "900 steps | score: [0.0594988614320755, -0.13463130593299866]\n",
      "1000 steps | score: [0.03690746799111366, -0.06758992373943329]\n",
      "1100 steps | score: [0.11830155551433563, -0.2555910348892212]\n",
      "1200 steps | score: [-0.023894470185041428, 0.03786356747150421]\n",
      "1300 steps | score: [0.034534573554992676, -0.09943801164627075]\n",
      "1400 steps | score: [0.048539355397224426, -0.10719326138496399]\n",
      "1500 steps | score: [0.16147151589393616, -0.3597933351993561]\n",
      "1600 steps | score: [0.04486479610204697, -0.11393088102340698]\n",
      "1700 steps | score: [0.08074509352445602, -0.16508229076862335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 steps | score: [0.15322110056877136, -0.2989562153816223]\n",
      "1900 steps | score: [0.06197025999426842, -0.13906726241111755]\n",
      "2000 steps | score: [0.13713905215263367, -0.2625941038131714]\n",
      "2100 steps | score: [0.15770450234413147, -0.31305673718452454]\n",
      "2200 steps | score: [0.061123281717300415, -0.1182488352060318]\n",
      "2300 steps | score: [0.10227317363023758, -0.22625717520713806]\n",
      "2400 steps | score: [0.15989793837070465, -0.33898764848709106]\n",
      "2500 steps | score: [0.12289416044950485, -0.24510343372821808]\n",
      "unknown params:  tensor([ 0.0548, -0.0658, -0.3151, -0.5523, -0.4096, -0.3020])\n",
      "gt params:  tensor([ 0.0737, -0.0466, -0.3064, -0.5213, -0.3890, -0.8471])\n",
      "ols params:  tensor([ 0.0216, -0.0275, -0.1190, -0.2016, -0.1527,  2.6770])\n",
      "unknown mse:  tensor(0.0499)\n",
      "ols mse:  tensor(2.1026)\n",
      "gt params:  tensor([ 0.0629, -0.0355, -0.3279, -0.5034, -0.3892, -0.8117])\n",
      "0 steps | score: [0.4117089509963989]\n",
      "100 steps | score: [0.03206542134284973]\n",
      "200 steps | score: [0.08544526994228363]\n",
      "300 steps | score: [0.07613694667816162]\n",
      "400 steps | score: [0.08441512286663055]\n",
      "500 steps | score: [0.06698092818260193]\n",
      "600 steps | score: [0.09266363084316254]\n",
      "700 steps | score: [0.14219047129154205]\n",
      "800 steps | score: [0.09175129234790802]\n",
      "900 steps | score: [0.0820455327630043]\n",
      "1000 steps | score: [0.060790594667196274]\n",
      "1100 steps | score: [0.10352648794651031]\n",
      "1200 steps | score: [0.09333230555057526]\n",
      "1300 steps | score: [0.12184367328882217]\n",
      "1400 steps | score: [0.06459682434797287]\n",
      "1500 steps | score: [0.07616095244884491]\n",
      "1600 steps | score: [0.06931693106889725]\n",
      "1700 steps | score: [0.12207286804914474]\n",
      "1800 steps | score: [0.08414654433727264]\n",
      "1900 steps | score: [0.07945291697978973]\n",
      "2000 steps | score: [0.08588855713605881]\n",
      "2100 steps | score: [0.09806576371192932]\n",
      "2200 steps | score: [0.0842575952410698]\n",
      "2300 steps | score: [0.07660456746816635]\n",
      "2400 steps | score: [0.11193251609802246]\n",
      "2500 steps | score: [0.09126317501068115]\n",
      "0 steps | score: [0.10438524931669235, -0.08362022042274475]\n",
      "100 steps | score: [-0.20895814895629883, 0.3887394666671753]\n",
      "200 steps | score: [-0.13015307486057281, 0.1894051879644394]\n",
      "300 steps | score: [-0.1930072009563446, 0.275023877620697]\n",
      "400 steps | score: [-0.05552039295434952, 0.004291754215955734]\n",
      "500 steps | score: [-0.16748380661010742, 0.2037469893693924]\n",
      "600 steps | score: [0.10520080476999283, -0.3171406388282776]\n",
      "700 steps | score: [0.11273203790187836, -0.377903014421463]\n",
      "800 steps | score: [-0.010333742015063763, -0.12603481113910675]\n",
      "900 steps | score: [-0.11264429986476898, 0.07901746034622192]\n",
      "1000 steps | score: [-0.19772858917713165, 0.25081759691238403]\n",
      "1100 steps | score: [0.18551170825958252, -0.5859594941139221]\n",
      "1200 steps | score: [-0.02991170436143875, -0.09785798192024231]\n",
      "1300 steps | score: [-0.11935241520404816, 0.11884421855211258]\n",
      "1400 steps | score: [-0.12731899321079254, 0.12611284852027893]\n",
      "1500 steps | score: [0.027885857969522476, -0.24615882337093353]\n",
      "1600 steps | score: [-0.1673886626958847, 0.20061522722244263]\n",
      "1700 steps | score: [-0.05865863710641861, -0.004298632498830557]\n",
      "1800 steps | score: [-0.13738271594047546, 0.13393810391426086]\n",
      "1900 steps | score: [0.0005837237695232034, -0.1678106039762497]\n",
      "2000 steps | score: [-0.08609830588102341, 0.05157908424735069]\n",
      "2100 steps | score: [-0.12253852188587189, 0.12327757477760315]\n",
      "2200 steps | score: [-0.09003061801195145, 0.06412606686353683]\n",
      "2300 steps | score: [-0.11083514243364334, 0.09676484018564224]\n",
      "2400 steps | score: [-0.05345426872372627, -0.001557796262204647]\n",
      "2500 steps | score: [-0.12023155391216278, 0.10231311619281769]\n",
      "unknown params:  tensor([ 0.1191, -0.0040, -0.3680, -0.4831, -0.4447, -0.4453])\n",
      "gt params:  tensor([ 0.0629, -0.0355, -0.3279, -0.5034, -0.3892, -0.8117])\n",
      "ols params:  tensor([ 3.9798e-02,  9.4138e-04, -1.2907e-01, -1.6282e-01, -1.5126e-01,\n",
      "         2.7655e+00])\n",
      "unknown mse:  tensor(0.0239)\n",
      "ols mse:  tensor(2.1684)\n",
      "gt params:  tensor([ 0.0595, -0.0802, -0.3205, -0.5040, -0.3967, -0.7828])\n",
      "0 steps | score: [0.4718994200229645]\n",
      "100 steps | score: [0.11962733417749405]\n",
      "200 steps | score: [0.13335908949375153]\n",
      "300 steps | score: [0.11455583572387695]\n",
      "400 steps | score: [0.10685893893241882]\n",
      "500 steps | score: [0.0788760632276535]\n",
      "600 steps | score: [0.16545526683330536]\n",
      "700 steps | score: [0.16047771275043488]\n",
      "800 steps | score: [0.11165464669466019]\n",
      "900 steps | score: [0.13585929572582245]\n",
      "1000 steps | score: [0.11287751793861389]\n",
      "1100 steps | score: [0.1481882929801941]\n",
      "1200 steps | score: [0.11202837526798248]\n",
      "1300 steps | score: [0.15024644136428833]\n",
      "1400 steps | score: [0.1227429062128067]\n",
      "1500 steps | score: [0.13368874788284302]\n",
      "1600 steps | score: [0.12289959192276001]\n",
      "1700 steps | score: [0.14080077409744263]\n",
      "1800 steps | score: [0.11249226331710815]\n",
      "1900 steps | score: [0.134287029504776]\n",
      "2000 steps | score: [0.14715054631233215]\n",
      "2100 steps | score: [0.1439494788646698]\n",
      "2200 steps | score: [0.12752631306648254]\n",
      "2300 steps | score: [0.10496863722801208]\n",
      "2400 steps | score: [0.14922675490379333]\n",
      "2500 steps | score: [0.14878439903259277]\n",
      "0 steps | score: [0.23676203191280365, -0.18298658728599548]\n",
      "100 steps | score: [-0.08136371523141861, 0.2942274808883667]\n",
      "200 steps | score: [0.05529358983039856, -0.0170903280377388]\n",
      "300 steps | score: [0.30419477820396423, -0.6005789041519165]\n",
      "400 steps | score: [0.06483259797096252, -0.06013503670692444]\n",
      "500 steps | score: [-0.039298757910728455, 0.15154077112674713]\n",
      "600 steps | score: [-0.03367454931139946, 0.1060461774468422]\n",
      "700 steps | score: [-0.02801176719367504, 0.09704440087080002]\n",
      "800 steps | score: [-0.0516994409263134, 0.14337053894996643]\n",
      "900 steps | score: [0.0757916048169136, -0.12716037034988403]\n",
      "1000 steps | score: [0.05893652141094208, -0.10438723862171173]\n",
      "1100 steps | score: [0.06816636025905609, -0.13479559123516083]\n",
      "1200 steps | score: [0.12641121447086334, -0.20363575220108032]\n",
      "1300 steps | score: [0.15055124461650848, -0.25986453890800476]\n",
      "1400 steps | score: [0.07108443230390549, -0.1026282012462616]\n",
      "1500 steps | score: [0.10965343564748764, -0.17452949285507202]\n",
      "1600 steps | score: [0.058947015553712845, -0.07496766000986099]\n",
      "1700 steps | score: [0.13204917311668396, -0.2605997920036316]\n",
      "1800 steps | score: [-0.019386863335967064, 0.08140445500612259]\n",
      "1900 steps | score: [0.11228007078170776, -0.1894233375787735]\n",
      "2000 steps | score: [0.02956712804734707, -0.040818214416503906]\n",
      "2100 steps | score: [-0.033714067190885544, 0.1020176112651825]\n",
      "2200 steps | score: [0.15004760026931763, -0.26640695333480835]\n",
      "2300 steps | score: [0.0452292300760746, -0.08109769225120544]\n",
      "2400 steps | score: [0.06820900738239288, -0.12352906167507172]\n",
      "2500 steps | score: [0.049615588039159775, -0.05745900049805641]\n",
      "unknown params:  tensor([ 0.0032, -0.0603, -0.3658, -0.4915, -0.3719, -0.1196])\n",
      "gt params:  tensor([ 0.0595, -0.0802, -0.3205, -0.5040, -0.3967, -0.7828])\n",
      "ols params:  tensor([ 9.4661e-05, -2.4094e-02, -1.4104e-01, -1.8472e-01, -1.4216e-01,\n",
      "         2.8732e+00])\n",
      "unknown mse:  tensor(0.0744)\n",
      "ols mse:  tensor(2.2620)\n",
      "gt params:  tensor([ 0.0951, -0.0346, -0.3129, -0.5057, -0.3737, -0.7815])\n",
      "0 steps | score: [0.18971747159957886]\n",
      "100 steps | score: [-0.22875377535820007]\n",
      "200 steps | score: [-0.134688138961792]\n",
      "300 steps | score: [-0.18662963807582855]\n",
      "400 steps | score: [-0.1616673618555069]\n",
      "500 steps | score: [-0.18022483587265015]\n",
      "600 steps | score: [-0.18479275703430176]\n",
      "700 steps | score: [-0.18845953047275543]\n",
      "800 steps | score: [-0.164218470454216]\n",
      "900 steps | score: [-0.16294178366661072]\n",
      "1000 steps | score: [-0.19896037876605988]\n",
      "1100 steps | score: [-0.152206152677536]\n",
      "1200 steps | score: [-0.1760997772216797]\n",
      "1300 steps | score: [-0.15463706851005554]\n",
      "1400 steps | score: [-0.19060193002223969]\n",
      "1500 steps | score: [-0.1970488578081131]\n",
      "1600 steps | score: [-0.20858870446681976]\n",
      "1700 steps | score: [-0.17351138591766357]\n",
      "1800 steps | score: [-0.1862751543521881]\n",
      "1900 steps | score: [-0.18630234897136688]\n",
      "2000 steps | score: [-0.17654365301132202]\n",
      "2100 steps | score: [-0.17131899297237396]\n",
      "2200 steps | score: [-0.19337275624275208]\n",
      "2300 steps | score: [-0.18908573687076569]\n",
      "2400 steps | score: [-0.16754309833049774]\n",
      "2500 steps | score: [-0.18697910010814667]\n",
      "0 steps | score: [0.16148969531059265, -0.06376871466636658]\n",
      "100 steps | score: [-0.09474185854196548, 0.3319072723388672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [0.2795403003692627, -0.5716714859008789]\n",
      "300 steps | score: [-0.0340333916246891, 0.09774987399578094]\n",
      "400 steps | score: [0.06928163021802902, -0.14349526166915894]\n",
      "500 steps | score: [0.016208726912736893, -0.034304097294807434]\n",
      "600 steps | score: [-0.10723602026700974, 0.21177387237548828]\n",
      "700 steps | score: [0.04990703985095024, -0.08111433684825897]\n",
      "800 steps | score: [0.012175174430012703, -0.02408015727996826]\n",
      "900 steps | score: [0.004717113915830851, -0.019606955349445343]\n",
      "1000 steps | score: [0.11616155505180359, -0.2613111436367035]\n",
      "1100 steps | score: [-0.07592460513114929, 0.15603622794151306]\n",
      "1200 steps | score: [-0.014720556326210499, 0.014160409569740295]\n",
      "1300 steps | score: [0.02520410344004631, -0.06986866891384125]\n",
      "1400 steps | score: [-0.13892583549022675, 0.2903144359588623]\n",
      "1500 steps | score: [-0.10077471286058426, 0.19310367107391357]\n",
      "1600 steps | score: [-0.01783420518040657, 0.025875627994537354]\n",
      "1700 steps | score: [0.09613727778196335, -0.20573356747627258]\n",
      "1800 steps | score: [-0.11365988850593567, 0.22781558334827423]\n",
      "1900 steps | score: [0.06367671489715576, -0.16475500166416168]\n",
      "2000 steps | score: [0.056006867438554764, -0.09970981627702713]\n",
      "2100 steps | score: [0.020190617069602013, -0.06246957182884216]\n",
      "2200 steps | score: [-0.012465361505746841, 0.0277346670627594]\n",
      "2300 steps | score: [0.1599164456129074, -0.3610191345214844]\n",
      "2400 steps | score: [0.03526586666703224, -0.10944868624210358]\n",
      "2500 steps | score: [-0.020645875483751297, 0.037338510155677795]\n",
      "unknown params:  tensor([ 0.1268, -0.0296, -0.3092, -0.5330, -0.4091, -0.3838])\n",
      "gt params:  tensor([ 0.0951, -0.0346, -0.3129, -0.5057, -0.3737, -0.7815])\n",
      "ols params:  tensor([ 0.0503, -0.0150, -0.1175, -0.1998, -0.1536,  2.9851])\n",
      "unknown mse:  tensor(0.0269)\n",
      "ols mse:  tensor(2.3950)\n",
      "gt params:  tensor([ 0.1052, -0.0424, -0.3175, -0.4842, -0.4215, -0.7466])\n",
      "0 steps | score: [0.48340699076652527]\n",
      "100 steps | score: [0.1298886388540268]\n",
      "200 steps | score: [0.1736392378807068]\n",
      "300 steps | score: [0.117825947701931]\n",
      "400 steps | score: [0.08303731679916382]\n",
      "500 steps | score: [0.17541265487670898]\n",
      "600 steps | score: [0.13579311966896057]\n",
      "700 steps | score: [0.14743056893348694]\n",
      "800 steps | score: [0.10590028762817383]\n",
      "900 steps | score: [0.12450937926769257]\n",
      "1000 steps | score: [0.13709604740142822]\n",
      "1100 steps | score: [0.11308887600898743]\n",
      "1200 steps | score: [0.12681327760219574]\n",
      "1300 steps | score: [0.11625689268112183]\n",
      "1400 steps | score: [0.1642380952835083]\n",
      "1500 steps | score: [0.12723645567893982]\n",
      "1600 steps | score: [0.12765038013458252]\n",
      "1700 steps | score: [0.11901205033063889]\n",
      "1800 steps | score: [0.13654261827468872]\n",
      "1900 steps | score: [0.12500762939453125]\n",
      "2000 steps | score: [0.12671272456645966]\n",
      "2100 steps | score: [0.12190482765436172]\n",
      "2200 steps | score: [0.11776776611804962]\n",
      "2300 steps | score: [0.13709624111652374]\n",
      "2400 steps | score: [0.12753625214099884]\n",
      "2500 steps | score: [0.15076659619808197]\n",
      "2600 steps | score: [0.12467040866613388]\n",
      "0 steps | score: [0.2530381977558136, -0.25506970286369324]\n",
      "100 steps | score: [-0.03764073923230171, 0.17686553299427032]\n",
      "200 steps | score: [0.035605672746896744, -0.00837547704577446]\n",
      "300 steps | score: [0.025962213054299355, -0.0033232010900974274]\n",
      "400 steps | score: [0.007833728566765785, 0.03393549844622612]\n",
      "500 steps | score: [0.15443941950798035, -0.31145331263542175]\n",
      "600 steps | score: [0.16293726861476898, -0.3169228136539459]\n",
      "700 steps | score: [0.20175683498382568, -0.4047184884548187]\n",
      "800 steps | score: [0.020017052069306374, -0.007738973945379257]\n",
      "900 steps | score: [0.08212769776582718, -0.18310996890068054]\n",
      "1000 steps | score: [0.02698465995490551, -0.06590038537979126]\n",
      "1100 steps | score: [-0.03106130100786686, 0.0557466484606266]\n",
      "1200 steps | score: [0.008027116768062115, -0.009647484868764877]\n",
      "unknown params:  tensor([ 0.1037, -0.0894, -0.2678, -0.4046, -0.3704, -0.1359])\n",
      "gt params:  tensor([ 0.1052, -0.0424, -0.3175, -0.4842, -0.4215, -0.7466])\n",
      "ols params:  tensor([ 0.0388, -0.0348, -0.1202, -0.1755, -0.1539,  3.1111])\n",
      "unknown mse:  tensor(0.0644)\n",
      "ols mse:  tensor(2.5154)\n",
      "gt params:  tensor([ 0.0848, -0.0514, -0.3099, -0.5019, -0.3830, -0.8245])\n",
      "0 steps | score: [0.45001471042633057]\n",
      "100 steps | score: [0.06260570883750916]\n",
      "200 steps | score: [0.153691828250885]\n",
      "300 steps | score: [0.12991133332252502]\n",
      "400 steps | score: [0.07352668792009354]\n",
      "500 steps | score: [0.06967589259147644]\n",
      "600 steps | score: [0.08226849138736725]\n",
      "700 steps | score: [0.10333731770515442]\n",
      "800 steps | score: [0.07833095639944077]\n",
      "900 steps | score: [0.09826791286468506]\n",
      "1000 steps | score: [0.07213491201400757]\n",
      "1100 steps | score: [0.12032702565193176]\n",
      "1200 steps | score: [0.07309818267822266]\n",
      "1300 steps | score: [0.07291150838136673]\n",
      "1400 steps | score: [0.0862262025475502]\n",
      "1500 steps | score: [0.08583183586597443]\n",
      "1600 steps | score: [0.09648336470127106]\n",
      "1700 steps | score: [0.07816466689109802]\n",
      "1800 steps | score: [0.100339874625206]\n",
      "1900 steps | score: [0.09690558910369873]\n",
      "2000 steps | score: [0.11033572256565094]\n",
      "2100 steps | score: [0.10985919088125229]\n",
      "2200 steps | score: [0.0839771032333374]\n",
      "2300 steps | score: [0.09462882578372955]\n",
      "2400 steps | score: [0.10089635848999023]\n",
      "2500 steps | score: [0.09136621654033661]\n",
      "0 steps | score: [0.24850185215473175, -0.06408384442329407]\n",
      "100 steps | score: [0.010085751302540302, 0.2720608711242676]\n",
      "200 steps | score: [0.3153848946094513, -0.4204085171222687]\n",
      "300 steps | score: [0.1767653375864029, -0.13900133967399597]\n",
      "400 steps | score: [-0.07406637072563171, 0.33043012022972107]\n",
      "500 steps | score: [0.037086889147758484, 0.09430130571126938]\n",
      "600 steps | score: [0.051116038113832474, 0.10078144818544388]\n",
      "700 steps | score: [-0.010395707562565804, 0.19442081451416016]\n",
      "800 steps | score: [0.019253546372056007, 0.16439610719680786]\n",
      "900 steps | score: [0.5322847366333008, -1.1968367099761963]\n",
      "1000 steps | score: [-0.09472830593585968, 0.3625592589378357]\n",
      "1100 steps | score: [0.14403031766414642, -0.1378372311592102]\n",
      "1200 steps | score: [-0.08865507692098618, 0.3507031798362732]\n",
      "1300 steps | score: [0.1919863075017929, -0.2233549952507019]\n",
      "1400 steps | score: [0.10805775225162506, -0.057232558727264404]\n",
      "1500 steps | score: [0.05177655443549156, 0.10877882689237595]\n",
      "1600 steps | score: [0.04950086399912834, 0.06852749735116959]\n",
      "1700 steps | score: [0.12635274231433868, -0.11106187850236893]\n",
      "1800 steps | score: [0.0008431520545855165, 0.16340693831443787]\n",
      "1900 steps | score: [0.3156132400035858, -0.5532000064849854]\n",
      "2000 steps | score: [0.06643263250589371, 0.019470982253551483]\n",
      "2100 steps | score: [0.09914546459913254, -0.03525809943675995]\n",
      "2200 steps | score: [0.04852144792675972, 0.06814206391572952]\n",
      "2300 steps | score: [0.05074283853173256, 0.07022680342197418]\n",
      "2400 steps | score: [0.197946697473526, -0.2586425840854645]\n",
      "2500 steps | score: [0.0700075700879097, 0.015201762318611145]\n",
      "unknown params:  tensor([ 0.0684, -0.0642, -0.3154, -0.5089, -0.3897, -0.2943])\n",
      "gt params:  tensor([ 0.0848, -0.0514, -0.3099, -0.5019, -0.3830, -0.8245])\n",
      "ols params:  tensor([ 0.0264, -0.0284, -0.1206, -0.1883, -0.1494,  3.1483])\n",
      "unknown mse:  tensor(0.0469)\n",
      "ols mse:  tensor(2.6626)\n",
      "gt params:  tensor([ 0.0890, -0.0450, -0.3113, -0.4795, -0.4025, -0.7621])\n",
      "0 steps | score: [0.21067754924297333]\n",
      "100 steps | score: [-0.16861502826213837]\n",
      "200 steps | score: [-0.17384541034698486]\n",
      "300 steps | score: [-0.16370832920074463]\n",
      "400 steps | score: [-0.150756374001503]\n",
      "500 steps | score: [-0.12427136301994324]\n",
      "600 steps | score: [-0.18078631162643433]\n",
      "700 steps | score: [-0.13924777507781982]\n",
      "800 steps | score: [-0.1239456906914711]\n",
      "900 steps | score: [-0.1443512886762619]\n",
      "1000 steps | score: [-0.16290828585624695]\n",
      "1100 steps | score: [-0.13141338527202606]\n",
      "1200 steps | score: [-0.1538587063550949]\n",
      "1300 steps | score: [-0.14050377905368805]\n",
      "1400 steps | score: [-0.12403148412704468]\n",
      "1500 steps | score: [-0.1273757517337799]\n",
      "1600 steps | score: [-0.13233445584774017]\n",
      "1700 steps | score: [-0.14731135964393616]\n",
      "1800 steps | score: [-0.12674623727798462]\n",
      "1900 steps | score: [-0.14491935074329376]\n",
      "2000 steps | score: [-0.16640102863311768]\n",
      "2100 steps | score: [-0.12053612619638443]\n",
      "2200 steps | score: [-0.14504018425941467]\n",
      "2300 steps | score: [-0.13145922124385834]\n",
      "2400 steps | score: [-0.1405467987060547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 steps | score: [-0.14215190708637238]\n",
      "2600 steps | score: [-0.15838144719600677]\n",
      "0 steps | score: [0.059494588524103165, 0.33539894223213196]\n",
      "100 steps | score: [-0.23117707669734955, 0.780375063419342]\n",
      "200 steps | score: [-0.07428661733865738, 0.41848433017730713]\n",
      "300 steps | score: [-0.21221786737442017, 0.6589434146881104]\n",
      "400 steps | score: [-0.3222753703594208, 0.8681634068489075]\n",
      "500 steps | score: [-0.27425500750541687, 0.735633909702301]\n",
      "600 steps | score: [0.011631791479885578, 0.16068170964717865]\n",
      "700 steps | score: [-0.19029846787452698, 0.5578135848045349]\n",
      "800 steps | score: [-0.06477039307355881, 0.3254588842391968]\n",
      "900 steps | score: [-0.1940777748823166, 0.5828405618667603]\n",
      "1000 steps | score: [-0.1726289689540863, 0.5202035903930664]\n",
      "1100 steps | score: [-0.04228046536445618, 0.2721388041973114]\n",
      "1200 steps | score: [-0.2522968649864197, 0.7077868580818176]\n",
      "1300 steps | score: [-0.10761585831642151, 0.4225163459777832]\n",
      "1400 steps | score: [-0.14079061150550842, 0.465797483921051]\n",
      "1500 steps | score: [-0.15281569957733154, 0.5049152374267578]\n",
      "1600 steps | score: [-0.1950445920228958, 0.5739941596984863]\n",
      "1700 steps | score: [-0.10856325179338455, 0.39242953062057495]\n",
      "1800 steps | score: [-0.021670641377568245, 0.1886521875858307]\n",
      "1900 steps | score: [-0.20871466398239136, 0.6090936660766602]\n",
      "2000 steps | score: [-0.07847300916910172, 0.3185034990310669]\n",
      "2100 steps | score: [-0.03937932476401329, 0.25798967480659485]\n",
      "2200 steps | score: [-0.09866377711296082, 0.37790271639823914]\n",
      "2300 steps | score: [-0.19138029217720032, 0.5878210067749023]\n",
      "2400 steps | score: [-0.10765174776315689, 0.3825433552265167]\n",
      "2500 steps | score: [-0.12367111444473267, 0.45294448733329773]\n",
      "2600 steps | score: [-0.06109190732240677, 0.26939937472343445]\n",
      "unknown params:  tensor([ 0.1088, -0.0552, -0.3057, -0.4864, -0.4123, -0.2196])\n",
      "gt params:  tensor([ 0.0890, -0.0450, -0.3113, -0.4795, -0.4025, -0.7621])\n",
      "ols params:  tensor([ 0.0380, -0.0185, -0.1101, -0.1776, -0.1549,  3.2502])\n",
      "unknown mse:  tensor(0.0492)\n",
      "ols mse:  tensor(2.7159)\n",
      "gt params:  tensor([ 0.0830, -0.0823, -0.3130, -0.5042, -0.3780, -0.7738])\n",
      "0 steps | score: [0.49682748317718506]\n",
      "100 steps | score: [0.16060912609100342]\n",
      "200 steps | score: [0.13540756702423096]\n",
      "300 steps | score: [0.16854022443294525]\n",
      "400 steps | score: [0.12332281470298767]\n",
      "500 steps | score: [0.16284839808940887]\n",
      "600 steps | score: [0.12539565563201904]\n",
      "700 steps | score: [0.18773368000984192]\n",
      "800 steps | score: [0.16018737852573395]\n",
      "900 steps | score: [0.09840323776006699]\n",
      "1000 steps | score: [0.13131579756736755]\n",
      "1100 steps | score: [0.15186624228954315]\n",
      "1200 steps | score: [0.1453275978565216]\n",
      "1300 steps | score: [0.1175088956952095]\n",
      "1400 steps | score: [0.14184080064296722]\n",
      "1500 steps | score: [0.15342022478580475]\n",
      "1600 steps | score: [0.16032467782497406]\n",
      "1700 steps | score: [0.13437405228614807]\n",
      "1800 steps | score: [0.13475364446640015]\n",
      "1900 steps | score: [0.14942701160907745]\n",
      "2000 steps | score: [0.16221444308757782]\n",
      "2100 steps | score: [0.15049393475055695]\n",
      "2200 steps | score: [0.12997043132781982]\n",
      "2300 steps | score: [0.1360800713300705]\n",
      "2400 steps | score: [0.12863276898860931]\n",
      "2500 steps | score: [0.1572027951478958]\n",
      "2600 steps | score: [0.13792867958545685]\n",
      "0 steps | score: [0.058418985456228256, 0.0734555721282959]\n",
      "100 steps | score: [0.039728254079818726, 0.02965518832206726]\n",
      "200 steps | score: [0.005418781656771898, 0.021261438727378845]\n",
      "300 steps | score: [-0.31979626417160034, 0.5735811591148376]\n",
      "400 steps | score: [-0.30644676089286804, 0.5666495561599731]\n",
      "500 steps | score: [-0.03123430721461773, 0.03705394268035889]\n",
      "600 steps | score: [-0.2812018394470215, 0.5104532837867737]\n",
      "700 steps | score: [-0.12514908611774445, 0.19195020198822021]\n",
      "800 steps | score: [0.03405012562870979, -0.13597387075424194]\n",
      "900 steps | score: [-0.2795180678367615, 0.5023384690284729]\n",
      "1000 steps | score: [-0.20328739285469055, 0.38133832812309265]\n",
      "1100 steps | score: [-0.17916351556777954, 0.33028292655944824]\n",
      "1200 steps | score: [-0.01840452291071415, -0.04415208846330643]\n",
      "1300 steps | score: [-0.2076578140258789, 0.37511229515075684]\n",
      "1400 steps | score: [-0.16126634180545807, 0.3056597113609314]\n",
      "1500 steps | score: [-0.17551277577877045, 0.29349857568740845]\n",
      "1600 steps | score: [-0.1778707504272461, 0.30102330446243286]\n",
      "1700 steps | score: [-0.20879098773002625, 0.38074421882629395]\n",
      "1800 steps | score: [-0.22093985974788666, 0.38490036129951477]\n",
      "1900 steps | score: [-0.14779894053936005, 0.23699423670768738]\n",
      "2000 steps | score: [0.12016620486974716, -0.3813309371471405]\n",
      "2100 steps | score: [-0.1754074990749359, 0.2825145125389099]\n",
      "2200 steps | score: [-0.13236768543720245, 0.23107926547527313]\n",
      "2300 steps | score: [-0.18704354763031006, 0.29721948504447937]\n",
      "2400 steps | score: [-0.12341049313545227, 0.19729144871234894]\n",
      "2500 steps | score: [-0.15877912938594818, 0.28033366799354553]\n",
      "2600 steps | score: [-0.207802414894104, 0.3602467477321625]\n",
      "unknown params:  tensor([ 0.0531, -0.0803, -0.2924, -0.4648, -0.3437, -0.1692])\n",
      "gt params:  tensor([ 0.0830, -0.0823, -0.3130, -0.5042, -0.3780, -0.7738])\n",
      "ols params:  tensor([ 0.0194, -0.0334, -0.1139, -0.1724, -0.1329,  3.4060])\n",
      "unknown mse:  tensor(0.0616)\n",
      "ols mse:  tensor(2.9478)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/c739fe51-f1a4-49e0-a60b-1b06d01e0dbd\n",
      "gt params:  tensor([-0.9908, -0.0816, -0.6203,  0.5639,  0.0426,  0.0538])\n",
      "0 steps | score: [0.0908314436674118]\n",
      "100 steps | score: [-0.12529556453227997]\n",
      "200 steps | score: [0.007652420550584793]\n",
      "0 steps | score: [0.20315085351467133, 0.06677627563476562]\n",
      "100 steps | score: [-1.7806463241577148, 5.456932067871094]\n",
      "200 steps | score: [0.17405404150485992, 1.3406527042388916]\n",
      "300 steps | score: [-0.3453241288661957, 2.4473929405212402]\n",
      "400 steps | score: [-0.7623863816261292, 3.4646730422973633]\n",
      "500 steps | score: [-1.033895492553711, 4.159825325012207]\n",
      "600 steps | score: [-2.773524284362793, 6.123386383056641]\n",
      "700 steps | score: [0.27811700105667114, 0.3505433201789856]\n",
      "800 steps | score: [2.6461946964263916, -13.495400428771973]\n",
      "900 steps | score: [-0.5810034871101379, 2.7390024662017822]\n",
      "1000 steps | score: [0.19308198988437653, -0.12400509417057037]\n",
      "1100 steps | score: [-0.04623587056994438, 0.7348341345787048]\n",
      "1200 steps | score: [0.07138477265834808, 0.2285514771938324]\n",
      "1300 steps | score: [-0.05486335605382919, 0.6688961386680603]\n",
      "1400 steps | score: [-0.09507513046264648, 0.870959997177124]\n",
      "1500 steps | score: [0.7176695466041565, -2.8959786891937256]\n",
      "1600 steps | score: [-0.09386493265628815, 0.8769724369049072]\n",
      "1700 steps | score: [-0.15432491898536682, 1.0703327655792236]\n",
      "1800 steps | score: [-0.08329158276319504, 0.7647672891616821]\n",
      "1900 steps | score: [0.034958366304636, 0.32991522550582886]\n",
      "2000 steps | score: [0.04395132139325142, 0.35090869665145874]\n",
      "2100 steps | score: [0.028605353087186813, 0.33740031719207764]\n",
      "2200 steps | score: [-0.07840409874916077, 0.726747989654541]\n",
      "2300 steps | score: [0.1327410638332367, -0.11973059177398682]\n",
      "2400 steps | score: [0.2782990336418152, -0.7549256086349487]\n",
      "2500 steps | score: [-0.0349181592464447, 0.5741538405418396]\n",
      "unknown params:  tensor([-1.0150, -0.0861, -0.6395,  0.5878,  0.0565, -0.0013])\n",
      "gt params:  tensor([-0.9908, -0.0816, -0.6203,  0.5639,  0.0426,  0.0538])\n",
      "ols params:  tensor([-0.8812, -0.0738, -0.5578,  0.5090,  0.0437,  0.5468])\n",
      "unknown mse:  tensor(0.0008)\n",
      "ols mse:  tensor(0.0437)\n",
      "gt params:  tensor([-0.9970, -0.0789, -0.6225,  0.5635,  0.0399,  0.0590])\n",
      "0 steps | score: [0.2032579481601715]\n",
      "100 steps | score: [0.0547766238451004]\n",
      "200 steps | score: [0.04001011699438095]\n",
      "300 steps | score: [0.002084985375404358]\n",
      "0 steps | score: [0.08357369899749756, 0.39785125851631165]\n",
      "100 steps | score: [-0.2565535604953766, 1.239341139793396]\n",
      "200 steps | score: [0.07893714308738708, -0.12044970691204071]\n",
      "300 steps | score: [0.31899920105934143, -1.1110254526138306]\n",
      "400 steps | score: [-0.08146385848522186, 0.5721930265426636]\n",
      "500 steps | score: [0.27557820081710815, -0.9917532801628113]\n",
      "600 steps | score: [-0.07326862215995789, 0.4280831813812256]\n",
      "700 steps | score: [0.21321342885494232, -0.7932741045951843]\n",
      "800 steps | score: [-0.20183582603931427, 1.0040959119796753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 steps | score: [-0.20369277894496918, 1.0157160758972168]\n",
      "1000 steps | score: [0.13560046255588531, -0.432913213968277]\n",
      "1100 steps | score: [0.15616483986377716, -0.5546653866767883]\n",
      "1200 steps | score: [-0.10036556422710419, 0.49566158652305603]\n",
      "1300 steps | score: [-0.1612781584262848, 0.7544025182723999]\n",
      "1400 steps | score: [-0.08687650412321091, 0.575509786605835]\n",
      "1500 steps | score: [-0.056333087384700775, 0.3943864405155182]\n",
      "1600 steps | score: [-0.12875594198703766, 0.6712859869003296]\n",
      "1700 steps | score: [-0.0824640616774559, 0.42028340697288513]\n",
      "1800 steps | score: [0.07771875709295273, -0.13774025440216064]\n",
      "1900 steps | score: [0.12271807342767715, -0.4218088984489441]\n",
      "2000 steps | score: [0.038832079619169235, 0.020111126825213432]\n",
      "2100 steps | score: [-0.0864049419760704, 0.565759003162384]\n",
      "2200 steps | score: [-0.1697787642478943, 0.7563260197639465]\n",
      "2300 steps | score: [-0.056279074400663376, 0.3562423884868622]\n",
      "2400 steps | score: [0.07074498385190964, -0.14076530933380127]\n",
      "2500 steps | score: [0.061839520931243896, -0.11525894701480865]\n",
      "unknown params:  tensor([-1.0200, -0.0788, -0.6338,  0.5733,  0.0380,  0.0676])\n",
      "gt params:  tensor([-0.9970, -0.0789, -0.6225,  0.5635,  0.0399,  0.0590])\n",
      "ols params:  tensor([-0.8037, -0.0587, -0.5112,  0.4648,  0.0292,  0.9764])\n",
      "unknown mse:  tensor(0.0001)\n",
      "ols mse:  tensor(0.1503)\n",
      "gt params:  tensor([-0.9961, -0.0950, -0.6250,  0.5557,  0.0330,  0.0597])\n",
      "0 steps | score: [0.4693858325481415]\n",
      "100 steps | score: [0.42134636640548706]\n",
      "200 steps | score: [0.3777995705604553]\n",
      "300 steps | score: [0.27116507291793823]\n",
      "400 steps | score: [0.319550484418869]\n",
      "500 steps | score: [0.2546812891960144]\n",
      "600 steps | score: [0.3550294041633606]\n",
      "700 steps | score: [0.36467835307121277]\n",
      "800 steps | score: [0.26957979798316956]\n",
      "900 steps | score: [0.27808189392089844]\n",
      "1000 steps | score: [0.28347399830818176]\n",
      "1100 steps | score: [0.2580660283565521]\n",
      "1200 steps | score: [0.31410691142082214]\n",
      "1300 steps | score: [0.25311610102653503]\n",
      "1400 steps | score: [0.30135729908943176]\n",
      "1500 steps | score: [0.24942819774150848]\n",
      "1600 steps | score: [0.28788986802101135]\n",
      "1700 steps | score: [0.316129595041275]\n",
      "1800 steps | score: [0.27569395303726196]\n",
      "1900 steps | score: [0.27861565351486206]\n",
      "2000 steps | score: [0.262228786945343]\n",
      "2100 steps | score: [0.2849770784378052]\n",
      "2200 steps | score: [0.288375586271286]\n",
      "2300 steps | score: [0.28388503193855286]\n",
      "2400 steps | score: [0.28599393367767334]\n",
      "2500 steps | score: [0.2864864766597748]\n",
      "0 steps | score: [-0.11426220089197159, 0.8070427179336548]\n",
      "100 steps | score: [0.210658460855484, -0.7187364101409912]\n",
      "200 steps | score: [-0.07255444675683975, 0.23028390109539032]\n",
      "300 steps | score: [-0.2949173152446747, 1.005884051322937]\n",
      "400 steps | score: [-0.025220632553100586, -0.0013564229011535645]\n",
      "500 steps | score: [-0.4455220103263855, 1.4725900888442993]\n",
      "600 steps | score: [-0.03769317641854286, 0.03903765231370926]\n",
      "700 steps | score: [-0.08288317918777466, 0.1850958913564682]\n",
      "800 steps | score: [-0.296529620885849, 0.932745099067688]\n",
      "900 steps | score: [-0.35725346207618713, 1.1654682159423828]\n",
      "1000 steps | score: [-0.07397861033678055, 0.08506470173597336]\n",
      "1100 steps | score: [-0.30843573808670044, 0.9883008003234863]\n",
      "1200 steps | score: [-0.1077037826180458, 0.3069950342178345]\n",
      "1300 steps | score: [-0.20965246856212616, 0.6199772357940674]\n",
      "1400 steps | score: [-0.26083171367645264, 0.8685993552207947]\n",
      "1500 steps | score: [-0.2127625048160553, 0.6376452445983887]\n",
      "1600 steps | score: [-0.14525821805000305, 0.42455965280532837]\n",
      "1700 steps | score: [-0.13813790678977966, 0.3789670467376709]\n",
      "1800 steps | score: [-0.3196648955345154, 1.0358878374099731]\n",
      "1900 steps | score: [-0.07223339378833771, 0.12129813432693481]\n",
      "2000 steps | score: [-0.3194314241409302, 0.9965071678161621]\n",
      "2100 steps | score: [-0.17790882289409637, 0.5673763751983643]\n",
      "2200 steps | score: [-0.1385936737060547, 0.41281023621559143]\n",
      "2300 steps | score: [-0.3015801012516022, 1.0045145750045776]\n",
      "2400 steps | score: [-0.21050986647605896, 0.6875187158584595]\n",
      "2500 steps | score: [-0.28032487630844116, 0.9118495583534241]\n",
      "unknown params:  tensor([-1.0039, -0.0964, -0.6264,  0.5624,  0.0315,  0.0435])\n",
      "gt params:  tensor([-0.9961, -0.0950, -0.6250,  0.5557,  0.0330,  0.0597])\n",
      "ols params:  tensor([-0.7482, -0.0747, -0.4787,  0.4360,  0.0256,  1.2797])\n",
      "unknown mse:  tensor(6.1923e-05)\n",
      "ols mse:  tensor(0.2643)\n",
      "gt params:  tensor([-0.9921, -0.0861, -0.6230,  0.5581,  0.0454,  0.0115])\n",
      "0 steps | score: [0.09584105014801025]\n",
      "100 steps | score: [-0.08562968671321869]\n",
      "200 steps | score: [-0.12825818359851837]\n",
      "300 steps | score: [-0.0588250458240509]\n",
      "400 steps | score: [-0.025126446038484573]\n",
      "500 steps | score: [-0.13759443163871765]\n",
      "600 steps | score: [-0.10913720726966858]\n",
      "700 steps | score: [-0.14951542019844055]\n",
      "800 steps | score: [-0.08910085260868073]\n",
      "900 steps | score: [-0.09568335115909576]\n",
      "1000 steps | score: [-0.11402412503957748]\n",
      "1100 steps | score: [-0.10739752650260925]\n",
      "1200 steps | score: [-0.16032500565052032]\n",
      "1300 steps | score: [-0.08074630051851273]\n",
      "1400 steps | score: [-0.0951695591211319]\n",
      "1500 steps | score: [-0.09858813881874084]\n",
      "1600 steps | score: [-0.11639861762523651]\n",
      "1700 steps | score: [-0.14288848638534546]\n",
      "1800 steps | score: [-0.10432621836662292]\n",
      "1900 steps | score: [-0.10597773641347885]\n",
      "2000 steps | score: [-0.10829748213291168]\n",
      "2100 steps | score: [-0.14146122336387634]\n",
      "2200 steps | score: [-0.13803841173648834]\n",
      "2300 steps | score: [-0.1104963943362236]\n",
      "2400 steps | score: [-0.11185066401958466]\n",
      "2500 steps | score: [-0.11157341301441193]\n",
      "0 steps | score: [0.07187233120203018, -0.02852218598127365]\n",
      "100 steps | score: [0.5930501818656921, -1.9447892904281616]\n",
      "200 steps | score: [-0.16971677541732788, 0.39538323879241943]\n",
      "300 steps | score: [-0.19050006568431854, 0.4610150456428528]\n",
      "400 steps | score: [0.20973064005374908, -0.8058730363845825]\n",
      "500 steps | score: [-0.09521838277578354, 0.1378445327281952]\n",
      "600 steps | score: [-0.16507764160633087, 0.3277389705181122]\n",
      "700 steps | score: [-0.11728198826313019, 0.21821537613868713]\n",
      "800 steps | score: [-0.04379571974277496, 0.02830154448747635]\n",
      "900 steps | score: [-0.00290152826346457, -0.11953231692314148]\n",
      "1000 steps | score: [-0.07967878878116608, 0.13989859819412231]\n",
      "1100 steps | score: [-0.16412769258022308, 0.3159438669681549]\n",
      "1200 steps | score: [-0.12670044600963593, 0.25330957770347595]\n",
      "1300 steps | score: [-0.09643962234258652, 0.13061153888702393]\n",
      "1400 steps | score: [0.058346670120954514, -0.30063843727111816]\n",
      "1500 steps | score: [-0.07581134140491486, 0.06861423701047897]\n",
      "1600 steps | score: [-0.09422415494918823, 0.1625450849533081]\n",
      "1700 steps | score: [-0.16244997084140778, 0.30736374855041504]\n",
      "1800 steps | score: [0.0024516929406672716, -0.12439143657684326]\n",
      "1900 steps | score: [-0.027616050094366074, -0.036819349974393845]\n",
      "2000 steps | score: [-0.06166601926088333, 0.032687075436115265]\n",
      "2100 steps | score: [-0.03953472524881363, -0.039542797952890396]\n",
      "2200 steps | score: [-0.18369093537330627, 0.37404805421829224]\n",
      "2300 steps | score: [-0.016655219718813896, -0.10443643480539322]\n",
      "2400 steps | score: [-0.02441146969795227, -0.09195522964000702]\n",
      "2500 steps | score: [-0.11086198687553406, 0.1718120276927948]\n",
      "unknown params:  tensor([-0.9623, -0.0868, -0.6167,  0.5594,  0.0492, -0.0330])\n",
      "gt params:  tensor([-0.9921, -0.0861, -0.6230,  0.5581,  0.0454,  0.0115])\n",
      "ols params:  tensor([-0.6855, -0.0631, -0.4509,  0.4118,  0.0371,  1.5136])\n",
      "unknown mse:  tensor(0.0005)\n",
      "ols mse:  tensor(0.4003)\n",
      "gt params:  tensor([-0.9966, -0.0970, -0.6274,  0.5557,  0.0480,  0.0271])\n",
      "0 steps | score: [0.2549848258495331]\n",
      "100 steps | score: [0.126508429646492]\n",
      "200 steps | score: [0.1078566461801529]\n",
      "300 steps | score: [0.09985534846782684]\n",
      "400 steps | score: [-0.026755670085549355]\n",
      "500 steps | score: [0.030612315982580185]\n",
      "600 steps | score: [0.09654001146554947]\n",
      "700 steps | score: [0.0813642293214798]\n",
      "800 steps | score: [0.08361846208572388]\n",
      "900 steps | score: [0.0006096754223108292]\n",
      "0 steps | score: [0.26939857006073, -0.19445165991783142]\n",
      "100 steps | score: [0.16508133709430695, -0.1698964238166809]\n",
      "200 steps | score: [0.722527027130127, -2.1156325340270996]\n",
      "300 steps | score: [0.12312237173318863, -0.15666337311267853]\n",
      "400 steps | score: [0.44749584794044495, -1.2476508617401123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [0.15212680399417877, -0.251525342464447]\n",
      "600 steps | score: [0.21012483537197113, -0.4198676347732544]\n",
      "700 steps | score: [0.38605573773384094, -1.0181093215942383]\n",
      "800 steps | score: [0.13172902166843414, -0.17946770787239075]\n",
      "900 steps | score: [0.23787502944469452, -0.49252963066101074]\n",
      "1000 steps | score: [0.09226509183645248, -0.07243847846984863]\n",
      "1100 steps | score: [0.20782078802585602, -0.42573869228363037]\n",
      "1200 steps | score: [0.281890332698822, -0.6366552710533142]\n",
      "1300 steps | score: [0.1783858835697174, -0.3311192989349365]\n",
      "1400 steps | score: [0.059262409806251526, -0.024739950895309448]\n",
      "1500 steps | score: [0.08222748339176178, -0.06737817823886871]\n",
      "1600 steps | score: [0.2252727597951889, -0.5098603963851929]\n",
      "1700 steps | score: [0.23301191627979279, -0.46050572395324707]\n",
      "1800 steps | score: [0.1548653095960617, -0.2202933132648468]\n",
      "1900 steps | score: [0.03691565990447998, 0.07415471225976944]\n",
      "2000 steps | score: [0.06677787005901337, -0.02736193686723709]\n",
      "2100 steps | score: [0.23216699063777924, -0.4973119795322418]\n",
      "2200 steps | score: [0.20378638803958893, -0.4167514443397522]\n",
      "2300 steps | score: [0.18037918210029602, -0.2892613708972931]\n",
      "2400 steps | score: [-0.0210722666233778, 0.24176427721977234]\n",
      "2500 steps | score: [0.05807572230696678, 0.03288400173187256]\n",
      "unknown params:  tensor([-0.9799, -0.1111, -0.6088,  0.5472,  0.0481, -0.0170])\n",
      "gt params:  tensor([-0.9966, -0.0970, -0.6274,  0.5557,  0.0480,  0.0271])\n",
      "ols params:  tensor([-0.6641, -0.0754, -0.4284,  0.3872,  0.0353,  1.7362])\n",
      "unknown mse:  tensor(0.0005)\n",
      "ols mse:  tensor(0.5167)\n",
      "gt params:  tensor([-0.9923, -0.0984, -0.6041,  0.5515,  0.0396,  0.0430])\n",
      "0 steps | score: [0.12308139353990555]\n",
      "100 steps | score: [-0.018242768943309784]\n",
      "200 steps | score: [-0.09274983406066895]\n",
      "300 steps | score: [-0.10859253257513046]\n",
      "400 steps | score: [-0.08429914712905884]\n",
      "500 steps | score: [-0.04328770563006401]\n",
      "600 steps | score: [-0.07181384414434433]\n",
      "700 steps | score: [-0.060997188091278076]\n",
      "800 steps | score: [-0.07355284690856934]\n",
      "900 steps | score: [-0.10196605324745178]\n",
      "1000 steps | score: [-0.04409258812665939]\n",
      "1100 steps | score: [-0.09555336833000183]\n",
      "1200 steps | score: [-0.10786852240562439]\n",
      "1300 steps | score: [-0.07105635106563568]\n",
      "1400 steps | score: [-0.12128722667694092]\n",
      "1500 steps | score: [-0.05035989731550217]\n",
      "1600 steps | score: [-0.09470324218273163]\n",
      "1700 steps | score: [-0.0931057333946228]\n",
      "1800 steps | score: [-0.06814074516296387]\n",
      "1900 steps | score: [-0.09986872971057892]\n",
      "2000 steps | score: [-0.047300539910793304]\n",
      "2100 steps | score: [-0.10666284710168839]\n",
      "2200 steps | score: [-0.08315760642290115]\n",
      "2300 steps | score: [-0.06988408416509628]\n",
      "2400 steps | score: [-0.08393766731023788]\n",
      "2500 steps | score: [-0.0709601566195488]\n",
      "2600 steps | score: [-0.09268894791603088]\n",
      "2700 steps | score: [-0.07529108226299286]\n",
      "2800 steps | score: [-0.0618661567568779]\n",
      "2900 steps | score: [-0.08122114837169647]\n",
      "0 steps | score: [0.15846316516399384, -0.06331300735473633]\n",
      "100 steps | score: [0.004177889786660671, 0.11791577190160751]\n",
      "200 steps | score: [-0.25446584820747375, 0.7207577228546143]\n",
      "300 steps | score: [0.03407079726457596, -0.11141350120306015]\n",
      "400 steps | score: [-0.02735511027276516, 0.09052227437496185]\n",
      "500 steps | score: [0.1911005973815918, -0.5648943781852722]\n",
      "600 steps | score: [-0.0073900469578802586, 0.01682928577065468]\n",
      "700 steps | score: [-0.1716729700565338, 0.48378869891166687]\n",
      "800 steps | score: [0.03130842372775078, -0.08959173411130905]\n",
      "900 steps | score: [-0.06620075553655624, 0.16665871441364288]\n",
      "1000 steps | score: [0.29277458786964417, -0.9089853167533875]\n",
      "1100 steps | score: [-0.082052081823349, 0.19495883584022522]\n",
      "1200 steps | score: [-0.1188763976097107, 0.28406620025634766]\n",
      "1300 steps | score: [0.03699894994497299, -0.12256225943565369]\n",
      "1400 steps | score: [-0.061502523720264435, 0.13284453749656677]\n",
      "1500 steps | score: [0.23405957221984863, -0.7446274161338806]\n",
      "1600 steps | score: [-0.043945323675870895, 0.07770045101642609]\n",
      "1700 steps | score: [-0.00907265767455101, 0.01520572043955326]\n",
      "1800 steps | score: [0.01795794628560543, -0.048517510294914246]\n",
      "1900 steps | score: [-0.03552483022212982, 0.06960819661617279]\n",
      "2000 steps | score: [0.09376245737075806, -0.31641530990600586]\n",
      "2100 steps | score: [-0.00997560378164053, -0.023613225668668747]\n",
      "2200 steps | score: [-0.07476568967103958, 0.12813922762870789]\n",
      "2300 steps | score: [0.07845383882522583, -0.23278552293777466]\n",
      "2400 steps | score: [-0.05695800855755806, 0.13249611854553223]\n",
      "2500 steps | score: [0.062062643468379974, -0.22539396584033966]\n",
      "2600 steps | score: [-0.017466016113758087, 0.016963379457592964]\n",
      "2700 steps | score: [-0.04124189168214798, 0.06865398585796356]\n",
      "2800 steps | score: [0.04646242782473564, -0.17131705582141876]\n",
      "2900 steps | score: [-0.06747326254844666, 0.165912464261055]\n",
      "unknown params:  tensor([-1.0115, -0.1058, -0.6235,  0.5645,  0.0290,  0.0340])\n",
      "gt params:  tensor([-0.9923, -0.0984, -0.6041,  0.5515,  0.0396,  0.0430])\n",
      "ols params:  tensor([-0.6272, -0.0692, -0.4039,  0.3665,  0.0181,  1.9839])\n",
      "unknown mse:  tensor(0.0002)\n",
      "ols mse:  tensor(0.6627)\n",
      "gt params:  tensor([-0.9977, -0.0716, -0.6103,  0.5475,  0.0535,  0.0453])\n",
      "0 steps | score: [0.2826656699180603]\n",
      "100 steps | score: [0.1766107827425003]\n",
      "200 steps | score: [0.0803544744849205]\n",
      "300 steps | score: [0.11843127012252808]\n",
      "400 steps | score: [0.06331896781921387]\n",
      "500 steps | score: [0.0807274878025055]\n",
      "600 steps | score: [0.10897444188594818]\n",
      "700 steps | score: [0.07193921506404877]\n",
      "800 steps | score: [0.1487465649843216]\n",
      "900 steps | score: [0.025716610252857208]\n",
      "1000 steps | score: [0.09671994298696518]\n",
      "1100 steps | score: [0.06869585812091827]\n",
      "1200 steps | score: [0.08132234960794449]\n",
      "1300 steps | score: [0.12323326617479324]\n",
      "1400 steps | score: [0.05822009593248367]\n",
      "1500 steps | score: [0.059717729687690735]\n",
      "1600 steps | score: [0.08068692684173584]\n",
      "1700 steps | score: [0.08543497323989868]\n",
      "1800 steps | score: [0.11576902866363525]\n",
      "1900 steps | score: [0.07758723944425583]\n",
      "2000 steps | score: [0.07261446863412857]\n",
      "2100 steps | score: [0.06521645188331604]\n",
      "2200 steps | score: [0.09077603369951248]\n",
      "2300 steps | score: [0.10720713436603546]\n",
      "2400 steps | score: [0.1137237399816513]\n",
      "2500 steps | score: [0.07232017070055008]\n",
      "0 steps | score: [0.052698682993650436, 0.05214425176382065]\n",
      "100 steps | score: [0.21367384493350983, -0.6173418164253235]\n",
      "200 steps | score: [-0.07773939520120621, 0.0884997621178627]\n",
      "300 steps | score: [-0.22654962539672852, 0.4629538655281067]\n",
      "400 steps | score: [-0.17475004494190216, 0.33327215909957886]\n",
      "500 steps | score: [-0.24664948880672455, 0.4759223759174347]\n",
      "600 steps | score: [-0.11765986680984497, 0.1795903444290161]\n",
      "700 steps | score: [-0.16557350754737854, 0.25281718373298645]\n",
      "800 steps | score: [-0.037129953503608704, -0.012388922274112701]\n",
      "900 steps | score: [-0.3595890998840332, 0.7990100979804993]\n",
      "1000 steps | score: [-0.0634579285979271, 0.04866570979356766]\n",
      "1100 steps | score: [-0.027623120695352554, -0.05828335881233215]\n",
      "1200 steps | score: [-0.23149828612804413, 0.43630078434944153]\n",
      "1300 steps | score: [-0.07009860128164291, 0.06910400092601776]\n",
      "1400 steps | score: [-0.03581552952528, -0.024955198168754578]\n",
      "1500 steps | score: [-0.0030823240522295237, -0.16339968144893646]\n",
      "1600 steps | score: [-0.0735684409737587, 0.08802791684865952]\n",
      "1700 steps | score: [-0.16480544209480286, 0.2906554937362671]\n",
      "1800 steps | score: [-0.10055139660835266, 0.11139100044965744]\n",
      "1900 steps | score: [-0.1331131011247635, 0.2025885283946991]\n",
      "2000 steps | score: [-0.11884403973817825, 0.16872987151145935]\n",
      "2100 steps | score: [-0.029968440532684326, -0.09027545154094696]\n",
      "2200 steps | score: [-0.14370106160640717, 0.2612844705581665]\n",
      "2300 steps | score: [-0.08796694129705429, 0.07283388078212738]\n",
      "2400 steps | score: [-0.15989740192890167, 0.25133758783340454]\n",
      "2500 steps | score: [-0.13514581322669983, 0.23755492269992828]\n",
      "unknown params:  tensor([-1.0238, -0.0932, -0.6517,  0.5761,  0.0393,  0.0130])\n",
      "gt params:  tensor([-0.9977, -0.0716, -0.6103,  0.5475,  0.0535,  0.0453])\n",
      "ols params:  tensor([-0.5926, -0.0532, -0.3958,  0.3501,  0.0245,  2.1758])\n",
      "unknown mse:  tensor(0.0008)\n",
      "ols mse:  tensor(0.7982)\n",
      "gt params:  tensor([-0.9942, -0.0740, -0.6155,  0.5578,  0.0355,  0.1047])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 steps | score: [0.07206196337938309]\n",
      "100 steps | score: [-0.16156962513923645]\n",
      "200 steps | score: [-0.024557605385780334]\n",
      "300 steps | score: [-0.0943504273891449]\n",
      "400 steps | score: [-0.16761335730552673]\n",
      "500 steps | score: [-0.0890311449766159]\n",
      "600 steps | score: [-0.1503511667251587]\n",
      "700 steps | score: [-0.057819753885269165]\n",
      "800 steps | score: [-0.19489142298698425]\n",
      "900 steps | score: [-0.12878477573394775]\n",
      "1000 steps | score: [-0.11176525801420212]\n",
      "1100 steps | score: [-0.11078232526779175]\n",
      "1200 steps | score: [-0.15499922633171082]\n",
      "1300 steps | score: [-0.17254382371902466]\n",
      "1400 steps | score: [-0.11250025033950806]\n",
      "1500 steps | score: [-0.15453758835792542]\n",
      "1600 steps | score: [-0.098486989736557]\n",
      "1700 steps | score: [-0.14306852221488953]\n",
      "1800 steps | score: [-0.1590292751789093]\n",
      "1900 steps | score: [-0.12225103378295898]\n",
      "2000 steps | score: [-0.14956486225128174]\n",
      "2100 steps | score: [-0.1270660012960434]\n",
      "2200 steps | score: [-0.14995555579662323]\n",
      "2300 steps | score: [-0.1615496128797531]\n",
      "2400 steps | score: [-0.1324349045753479]\n",
      "2500 steps | score: [-0.15580298006534576]\n",
      "0 steps | score: [0.12143106013536453, 0.12138061970472336]\n",
      "100 steps | score: [0.022443998605012894, 0.21085397899150848]\n",
      "200 steps | score: [0.5776386260986328, -1.5318971872329712]\n",
      "300 steps | score: [0.08790181577205658, -0.03937360271811485]\n",
      "400 steps | score: [-0.11257036030292511, 0.4244937598705292]\n",
      "500 steps | score: [0.000799692643340677, 0.1299859881401062]\n",
      "600 steps | score: [-0.15467387437820435, 0.5731918215751648]\n",
      "700 steps | score: [0.2211778312921524, -0.4393394887447357]\n",
      "800 steps | score: [0.16039562225341797, -0.3237471282482147]\n",
      "900 steps | score: [0.08845232427120209, -0.12276433408260345]\n",
      "1000 steps | score: [0.1723128706216812, -0.3669417202472687]\n",
      "1100 steps | score: [0.015071814879775047, 0.10064634680747986]\n",
      "1200 steps | score: [0.19962206482887268, -0.47851094603538513]\n",
      "1300 steps | score: [-0.055810291320085526, 0.292864054441452]\n",
      "1400 steps | score: [-0.1678282469511032, 0.56805419921875]\n",
      "1500 steps | score: [0.018755892291665077, 0.04679146036505699]\n",
      "1600 steps | score: [0.046424899250268936, 0.012839198112487793]\n",
      "1700 steps | score: [-0.05848259478807449, 0.2781279683113098]\n",
      "1800 steps | score: [-0.054996661841869354, 0.2629971206188202]\n",
      "1900 steps | score: [-0.09145942330360413, 0.3209610879421234]\n",
      "2000 steps | score: [-0.041490551084280014, 0.2092088758945465]\n",
      "2100 steps | score: [-0.09683214873075485, 0.3709363639354706]\n",
      "2200 steps | score: [-0.08582068979740143, 0.37291431427001953]\n",
      "2300 steps | score: [-0.10002472251653671, 0.3592107594013214]\n",
      "2400 steps | score: [0.006642106920480728, 0.09229698032140732]\n",
      "2500 steps | score: [-0.010728694498538971, 0.17741137742996216]\n",
      "unknown params:  tensor([-1.0472, -0.0812, -0.6540,  0.5754,  0.0359,  0.1685])\n",
      "gt params:  tensor([-0.9942, -0.0740, -0.6155,  0.5578,  0.0355,  0.1047])\n",
      "ols params:  tensor([-0.5859, -0.0447, -0.3805,  0.3401,  0.0241,  2.3892])\n",
      "unknown mse:  tensor(0.0015)\n",
      "ols mse:  tensor(0.9149)\n",
      "gt params:  tensor([-0.9817, -0.0735, -0.6052,  0.5752,  0.0496,  0.0184])\n",
      "0 steps | score: [0.23154225945472717]\n",
      "100 steps | score: [0.012827269732952118]\n",
      "200 steps | score: [0.07144962251186371]\n",
      "300 steps | score: [0.013047153130173683]\n",
      "400 steps | score: [-0.02408885769546032]\n",
      "500 steps | score: [0.018805745989084244]\n",
      "600 steps | score: [-0.0004325937479734421]\n",
      "0 steps | score: [0.03452308475971222, 0.18107247352600098]\n",
      "100 steps | score: [-0.12952294945716858, 0.43893977999687195]\n",
      "200 steps | score: [0.0972813069820404, -0.2033120095729828]\n",
      "300 steps | score: [-0.1649097204208374, 0.4251309931278229]\n",
      "400 steps | score: [-0.25349828600883484, 0.6580963134765625]\n",
      "500 steps | score: [0.021316858008503914, -0.061553142964839935]\n",
      "600 steps | score: [-0.23321101069450378, 0.5398916006088257]\n",
      "700 steps | score: [-0.10901953279972076, 0.282508909702301]\n",
      "800 steps | score: [-0.11760576069355011, 0.29636889696121216]\n",
      "900 steps | score: [-0.3007047176361084, 0.7290861010551453]\n",
      "1000 steps | score: [0.23274436593055725, -0.7008029222488403]\n",
      "1100 steps | score: [-0.1618247926235199, 0.4269721508026123]\n",
      "1200 steps | score: [0.046629663556814194, -0.1320430487394333]\n",
      "1300 steps | score: [-0.023349015042185783, 0.019048787653446198]\n",
      "1400 steps | score: [-0.07388397306203842, 0.17307817935943604]\n",
      "1500 steps | score: [0.03279488906264305, -0.07480351626873016]\n",
      "1600 steps | score: [-0.09230630844831467, 0.19576552510261536]\n",
      "1700 steps | score: [-0.018718507140874863, 0.040086910128593445]\n",
      "1800 steps | score: [-0.039603568613529205, 0.1204809844493866]\n",
      "1900 steps | score: [-0.09311125427484512, 0.2414294183254242]\n",
      "2000 steps | score: [-0.04238231107592583, 0.07091347873210907]\n",
      "2100 steps | score: [-0.1392255574464798, 0.3630460798740387]\n",
      "2200 steps | score: [-0.04418611526489258, 0.11702154576778412]\n",
      "2300 steps | score: [-0.12089541554450989, 0.28753232955932617]\n",
      "2400 steps | score: [-0.08079944550991058, 0.19635945558547974]\n",
      "2500 steps | score: [-0.07882334291934967, 0.2029503881931305]\n",
      "unknown params:  tensor([-1.0486, -0.0657, -0.6435,  0.5963,  0.0395,  0.1202])\n",
      "gt params:  tensor([-0.9817, -0.0735, -0.6052,  0.5752,  0.0496,  0.0184])\n",
      "ols params:  tensor([-0.5537, -0.0355, -0.3550,  0.3312,  0.0228,  2.4898])\n",
      "unknown mse:  tensor(0.0028)\n",
      "ols mse:  tensor(1.0692)\n",
      "gt params:  tensor([-0.9926, -0.0829, -0.6212,  0.5684,  0.0357,  0.0278])\n",
      "0 steps | score: [0.23654329776763916]\n",
      "100 steps | score: [0.03048841282725334]\n",
      "200 steps | score: [0.014340829104185104]\n",
      "300 steps | score: [0.010581519454717636]\n",
      "400 steps | score: [-0.01622641459107399]\n",
      "500 steps | score: [-0.02701990306377411]\n",
      "600 steps | score: [-0.018738923594355583]\n",
      "700 steps | score: [-0.03251936659216881]\n",
      "800 steps | score: [-0.011461709626019001]\n",
      "900 steps | score: [-0.017474113032221794]\n",
      "1000 steps | score: [-0.04088323563337326]\n",
      "1100 steps | score: [-0.015667453408241272]\n",
      "1200 steps | score: [-0.003460776060819626]\n",
      "0 steps | score: [0.26957958936691284, -0.30399370193481445]\n",
      "100 steps | score: [0.046433787792921066, 0.008247502148151398]\n",
      "200 steps | score: [0.08775772154331207, -0.11511833220720291]\n",
      "300 steps | score: [0.25015854835510254, -0.5290309190750122]\n",
      "400 steps | score: [0.012288997881114483, 0.022056270390748978]\n",
      "500 steps | score: [-0.03832538425922394, 0.12109465897083282]\n",
      "600 steps | score: [0.13805252313613892, -0.28041714429855347]\n",
      "700 steps | score: [0.07071809470653534, -0.14872200787067413]\n",
      "800 steps | score: [0.20958660542964935, -0.448157399892807]\n",
      "900 steps | score: [0.11368496716022491, -0.21652886271476746]\n",
      "1000 steps | score: [0.04696826636791229, -0.0929175540804863]\n",
      "1100 steps | score: [0.11350664496421814, -0.2621772289276123]\n",
      "1200 steps | score: [0.06466639041900635, -0.16755464673042297]\n",
      "1300 steps | score: [0.1617928147315979, -0.37036171555519104]\n",
      "1400 steps | score: [0.08861109614372253, -0.22127681970596313]\n",
      "1500 steps | score: [0.10272225737571716, -0.23711007833480835]\n",
      "1600 steps | score: [0.14017418026924133, -0.35236209630966187]\n",
      "1700 steps | score: [0.14257383346557617, -0.2937823235988617]\n",
      "1800 steps | score: [0.12338520586490631, -0.2616625428199768]\n",
      "1900 steps | score: [0.11221079528331757, -0.2489849328994751]\n",
      "2000 steps | score: [0.1386578381061554, -0.2898322641849518]\n",
      "2100 steps | score: [0.10967348515987396, -0.2539139986038208]\n",
      "2200 steps | score: [0.1268600970506668, -0.23808102309703827]\n",
      "2300 steps | score: [0.07943938672542572, -0.17922665178775787]\n",
      "2400 steps | score: [0.106301449239254, -0.2105860412120819]\n",
      "2500 steps | score: [0.1137012168765068, -0.25150641798973083]\n",
      "unknown params:  tensor([-1.0306, -0.0640, -0.6428,  0.5939,  0.0302,  0.0563])\n",
      "gt params:  tensor([-0.9926, -0.0829, -0.6212,  0.5684,  0.0357,  0.0278])\n",
      "ols params:  tensor([-0.5466, -0.0347, -0.3580,  0.3313,  0.0159,  2.6617])\n",
      "unknown mse:  tensor(0.0006)\n",
      "ols mse:  tensor(1.2107)\n",
      "gt params:  tensor([-0.9894, -0.0806, -0.6150,  0.5554,  0.0510,  0.0406])\n",
      "0 steps | score: [0.3049851655960083]\n",
      "100 steps | score: [0.08774473518133163]\n",
      "200 steps | score: [0.1192583441734314]\n",
      "300 steps | score: [0.0526958703994751]\n",
      "400 steps | score: [0.0644148513674736]\n",
      "500 steps | score: [0.043912190943956375]\n",
      "600 steps | score: [0.04869132488965988]\n",
      "700 steps | score: [0.05477714538574219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 steps | score: [0.06462211906909943]\n",
      "900 steps | score: [-0.010840924456715584]\n",
      "1000 steps | score: [0.03930971771478653]\n",
      "1100 steps | score: [0.044303543865680695]\n",
      "1200 steps | score: [0.05755176395177841]\n",
      "1300 steps | score: [0.03768496960401535]\n",
      "1400 steps | score: [0.013078456744551659]\n",
      "1500 steps | score: [0.0752636268734932]\n",
      "1600 steps | score: [0.05257662385702133]\n",
      "1700 steps | score: [0.0328705795109272]\n",
      "1800 steps | score: [0.014507024548947811]\n",
      "1900 steps | score: [0.008772497996687889]\n",
      "0 steps | score: [0.18316611647605896, 0.07446952909231186]\n",
      "100 steps | score: [0.09249719232320786, 0.16304215788841248]\n",
      "200 steps | score: [0.2191208153963089, -0.25225263833999634]\n",
      "300 steps | score: [-0.1772211492061615, 0.6578150987625122]\n",
      "400 steps | score: [0.3195217251777649, -0.5986766815185547]\n",
      "500 steps | score: [-0.17432621121406555, 0.5900968313217163]\n",
      "600 steps | score: [-0.03707040473818779, 0.31644678115844727]\n",
      "700 steps | score: [0.23241528868675232, -0.3770207166671753]\n",
      "800 steps | score: [-0.04147768393158913, 0.30407291650772095]\n",
      "900 steps | score: [-0.024344656616449356, 0.25731897354125977]\n",
      "1000 steps | score: [-0.01571151614189148, 0.27718156576156616]\n",
      "1100 steps | score: [0.1650846004486084, -0.19196707010269165]\n",
      "1200 steps | score: [-0.08317479491233826, 0.42543932795524597]\n",
      "1300 steps | score: [0.10420630872249603, -0.036314062774181366]\n",
      "1400 steps | score: [-0.08186129480600357, 0.39482152462005615]\n",
      "1500 steps | score: [0.08645056188106537, 0.03214119374752045]\n",
      "1600 steps | score: [-0.0011378340423107147, 0.2471085488796234]\n",
      "1700 steps | score: [-0.0350535586476326, 0.3087129592895508]\n",
      "1800 steps | score: [0.094278484582901, -0.005068667232990265]\n",
      "1900 steps | score: [0.005825727712363005, 0.2034842073917389]\n",
      "2000 steps | score: [0.08938071131706238, -0.0032666921615600586]\n",
      "2100 steps | score: [-0.008766133338212967, 0.23505602777004242]\n",
      "2200 steps | score: [-0.051382746547460556, 0.336791068315506]\n",
      "2300 steps | score: [0.016946904361248016, 0.20125845074653625]\n",
      "2400 steps | score: [-0.03411886841058731, 0.28368064761161804]\n",
      "2500 steps | score: [0.09187512844800949, 0.017250001430511475]\n",
      "unknown params:  tensor([-1.0069, -0.0637, -0.6391,  0.5718,  0.0742, -0.0843])\n",
      "gt params:  tensor([-0.9894, -0.0806, -0.6150,  0.5554,  0.0510,  0.0406])\n",
      "ols params:  tensor([-0.5224, -0.0352, -0.3495,  0.3131,  0.0404,  2.7468])\n",
      "unknown mse:  tensor(0.0029)\n",
      "ols mse:  tensor(1.2788)\n",
      "gt params:  tensor([-0.9976, -0.0852, -0.5987,  0.5455,  0.0424,  0.0113])\n",
      "0 steps | score: [0.251802921295166]\n",
      "100 steps | score: [0.09196393191814423]\n",
      "200 steps | score: [-0.018869472667574883]\n",
      "300 steps | score: [-0.01315632089972496]\n",
      "400 steps | score: [-0.0583144873380661]\n",
      "500 steps | score: [-0.03889576345682144]\n",
      "600 steps | score: [0.05639735609292984]\n",
      "700 steps | score: [-0.003026362508535385]\n",
      "0 steps | score: [0.04767320677638054, 0.009582296013832092]\n",
      "100 steps | score: [0.14777888357639313, -0.36962586641311646]\n",
      "200 steps | score: [-0.22038383781909943, 0.4309372901916504]\n",
      "300 steps | score: [-0.21826890110969543, 0.38447660207748413]\n",
      "400 steps | score: [-0.2661105990409851, 0.4491311311721802]\n",
      "500 steps | score: [-0.2767564058303833, 0.5131702423095703]\n",
      "600 steps | score: [0.0860213190317154, -0.3639914393424988]\n",
      "700 steps | score: [-0.20063570141792297, 0.3155675530433655]\n",
      "800 steps | score: [-0.1358785480260849, 0.16273364424705505]\n",
      "900 steps | score: [-0.25366804003715515, 0.42327356338500977]\n",
      "1000 steps | score: [-0.23297590017318726, 0.40230637788772583]\n",
      "1100 steps | score: [0.06592214852571487, -0.3625258803367615]\n",
      "1200 steps | score: [-0.14943087100982666, 0.22749848663806915]\n",
      "1300 steps | score: [-0.14263765513896942, 0.20173761248588562]\n",
      "1400 steps | score: [-0.20581522583961487, 0.31488555669784546]\n",
      "1500 steps | score: [-0.19354374706745148, 0.3022822141647339]\n",
      "1600 steps | score: [0.023791084066033363, -0.20188069343566895]\n",
      "1700 steps | score: [-0.14996297657489777, 0.18552474677562714]\n",
      "1800 steps | score: [-0.08582814782857895, 0.02958589792251587]\n",
      "1900 steps | score: [-0.20529790222644806, 0.307071328163147]\n",
      "2000 steps | score: [-0.202531099319458, 0.32200151681900024]\n",
      "2100 steps | score: [0.024542314931750298, -0.20998910069465637]\n",
      "2200 steps | score: [-0.09945998340845108, 0.10571461915969849]\n",
      "2300 steps | score: [-0.1257639229297638, 0.12811210751533508]\n",
      "2400 steps | score: [-0.1561352014541626, 0.191407710313797]\n",
      "2500 steps | score: [-0.16349096596240997, 0.22422169148921967]\n",
      "unknown params:  tensor([-0.9574, -0.0835, -0.5343,  0.5105,  0.0459, -0.0072])\n",
      "gt params:  tensor([-0.9976, -0.0852, -0.5987,  0.5455,  0.0424,  0.0113])\n",
      "ols params:  tensor([-0.5208, -0.0484, -0.3105,  0.2976,  0.0293,  2.9091])\n",
      "unknown mse:  tensor(0.0012)\n",
      "ols mse:  tensor(1.4618)\n",
      "gt params:  tensor([-1.0078, -0.0906, -0.6094,  0.5654,  0.0289,  0.0212])\n",
      "0 steps | score: [0.4076407849788666]\n",
      "100 steps | score: [0.13952140510082245]\n",
      "200 steps | score: [0.12400931119918823]\n",
      "300 steps | score: [0.19806118309497833]\n",
      "400 steps | score: [0.08494016528129578]\n",
      "500 steps | score: [0.13496634364128113]\n",
      "600 steps | score: [0.12321042269468307]\n",
      "700 steps | score: [0.09989166259765625]\n",
      "800 steps | score: [0.15369659662246704]\n",
      "900 steps | score: [0.11215120553970337]\n",
      "1000 steps | score: [0.10946294665336609]\n",
      "1100 steps | score: [0.10682522505521774]\n",
      "1200 steps | score: [0.09621559828519821]\n",
      "1300 steps | score: [0.1601426601409912]\n",
      "1400 steps | score: [0.12250973284244537]\n",
      "1500 steps | score: [0.11464395374059677]\n",
      "1600 steps | score: [0.10588851571083069]\n",
      "1700 steps | score: [0.1051129624247551]\n",
      "1800 steps | score: [0.10882172733545303]\n",
      "1900 steps | score: [0.10101988911628723]\n",
      "2000 steps | score: [0.12376204133033752]\n",
      "2100 steps | score: [0.11103156954050064]\n",
      "2200 steps | score: [0.10285256803035736]\n",
      "2300 steps | score: [0.13123145699501038]\n",
      "2400 steps | score: [0.10009860247373581]\n",
      "2500 steps | score: [0.10771168768405914]\n",
      "0 steps | score: [0.2895992398262024, -0.5547171235084534]\n",
      "100 steps | score: [0.1290259063243866, -0.36206692457199097]\n",
      "200 steps | score: [0.27007997035980225, -0.7709317207336426]\n",
      "300 steps | score: [0.32879137992858887, -0.9709553718566895]\n",
      "400 steps | score: [0.10155496746301651, -0.40245696902275085]\n",
      "500 steps | score: [0.16723451018333435, -0.552611768245697]\n",
      "600 steps | score: [0.23531772196292877, -0.745302140712738]\n",
      "700 steps | score: [0.05584317445755005, -0.3243963122367859]\n",
      "800 steps | score: [0.17989268898963928, -0.6269894242286682]\n",
      "900 steps | score: [0.3405005633831024, -1.04781174659729]\n",
      "1000 steps | score: [0.17706799507141113, -0.603567898273468]\n",
      "1100 steps | score: [0.10820578783750534, -0.43266791105270386]\n",
      "1200 steps | score: [0.051310691982507706, -0.304556280374527]\n",
      "1300 steps | score: [0.1336609423160553, -0.5106002688407898]\n",
      "1400 steps | score: [0.1557561606168747, -0.5448970198631287]\n",
      "1500 steps | score: [0.07311616092920303, -0.3392541706562042]\n",
      "1600 steps | score: [0.044718630611896515, -0.30494675040245056]\n",
      "1700 steps | score: [0.11135523021221161, -0.4405231475830078]\n",
      "1800 steps | score: [0.17409445345401764, -0.6345785856246948]\n",
      "1900 steps | score: [0.0361095666885376, -0.267228901386261]\n",
      "2000 steps | score: [0.08429838716983795, -0.37474656105041504]\n",
      "2100 steps | score: [0.07631751149892807, -0.3716387152671814]\n",
      "2200 steps | score: [0.14907467365264893, -0.5472050905227661]\n",
      "2300 steps | score: [0.12819157540798187, -0.49639883637428284]\n",
      "2400 steps | score: [0.01685277186334133, -0.22630904614925385]\n",
      "2500 steps | score: [0.1147734597325325, -0.48457467555999756]\n",
      "unknown params:  tensor([-0.9954, -0.0639, -0.5969,  0.5568,  0.0030, -0.0328])\n",
      "gt params:  tensor([-1.0078, -0.0906, -0.6094,  0.5654,  0.0289,  0.0212])\n",
      "ols params:  tensor([-5.1588e-01, -3.6963e-02, -3.2608e-01,  3.0464e-01,  2.6322e-03,\n",
      "         3.0078e+00])\n",
      "unknown mse:  tensor(0.0008)\n",
      "ols mse:  tensor(1.5523)\n",
      "gt params:  tensor([-0.9845, -0.0737, -0.6189,  0.5525,  0.0282,  0.0549])\n",
      "0 steps | score: [0.3658616244792938]\n",
      "100 steps | score: [0.15479427576065063]\n",
      "200 steps | score: [0.12448522448539734]\n",
      "300 steps | score: [0.10896458476781845]\n",
      "400 steps | score: [0.12298494577407837]\n",
      "500 steps | score: [0.21834272146224976]\n",
      "600 steps | score: [0.12659192085266113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 steps | score: [0.14728230237960815]\n",
      "800 steps | score: [0.14868244528770447]\n",
      "900 steps | score: [0.12467072904109955]\n",
      "1000 steps | score: [0.17343682050704956]\n",
      "1100 steps | score: [0.1519487202167511]\n",
      "1200 steps | score: [0.15423281490802765]\n",
      "1300 steps | score: [0.1546512097120285]\n",
      "1400 steps | score: [0.10681061446666718]\n",
      "1500 steps | score: [0.16010943055152893]\n",
      "1600 steps | score: [0.13510408997535706]\n",
      "1700 steps | score: [0.15341860055923462]\n",
      "1800 steps | score: [0.15970993041992188]\n",
      "1900 steps | score: [0.11298731714487076]\n",
      "2000 steps | score: [0.13354535400867462]\n",
      "2100 steps | score: [0.1236908882856369]\n",
      "2200 steps | score: [0.13078060746192932]\n",
      "2300 steps | score: [0.15219621360301971]\n",
      "2400 steps | score: [0.14498284459114075]\n",
      "2500 steps | score: [0.10737448930740356]\n",
      "0 steps | score: [0.22934293746948242, -0.18036824464797974]\n",
      "100 steps | score: [0.06361926347017288, 0.010130807757377625]\n",
      "200 steps | score: [-0.039959866553545, 0.1877124011516571]\n",
      "300 steps | score: [-0.08323173969984055, 0.28132307529449463]\n",
      "400 steps | score: [-0.03288770094513893, 0.1728685349225998]\n",
      "500 steps | score: [0.01122805941849947, 0.046327702701091766]\n",
      "600 steps | score: [0.08434802293777466, -0.1171342134475708]\n",
      "700 steps | score: [0.05300239846110344, -0.02703195810317993]\n",
      "800 steps | score: [-0.05717465281486511, 0.20644524693489075]\n",
      "900 steps | score: [-0.049022987484931946, 0.16804467141628265]\n",
      "1000 steps | score: [0.1615854650735855, -0.3129895031452179]\n",
      "1100 steps | score: [0.0016337494598701596, 0.0650753527879715]\n",
      "1200 steps | score: [0.1302378624677658, -0.28460073471069336]\n",
      "1300 steps | score: [-0.004092865623533726, 0.06561653316020966]\n",
      "1400 steps | score: [0.05416623130440712, -0.07840168476104736]\n",
      "1500 steps | score: [0.05176026374101639, -0.04685091972351074]\n",
      "1600 steps | score: [0.10312288254499435, -0.17424273490905762]\n",
      "1700 steps | score: [0.1075899675488472, -0.15324892103672028]\n",
      "1800 steps | score: [0.000624250911641866, 0.04731530696153641]\n",
      "1900 steps | score: [0.0056740473955869675, 0.06949086487293243]\n",
      "2000 steps | score: [0.14152827858924866, -0.2777571380138397]\n",
      "2100 steps | score: [0.0887189656496048, -0.11211957782506943]\n",
      "2200 steps | score: [0.0009949880186468363, 0.03052772581577301]\n",
      "2300 steps | score: [0.0689208135008812, -0.06636199355125427]\n",
      "2400 steps | score: [-0.004080912563949823, 0.051122091710567474]\n",
      "2500 steps | score: [0.09185484796762466, -0.12620879709720612]\n",
      "unknown params:  tensor([-0.9730, -0.0550, -0.6393,  0.5553,  0.0513,  0.2030])\n",
      "gt params:  tensor([-0.9845, -0.0737, -0.6189,  0.5525,  0.0282,  0.0549])\n",
      "ols params:  tensor([-0.4836, -0.0276, -0.3298,  0.2937,  0.0274,  3.1732])\n",
      "unknown mse:  tensor(0.0039)\n",
      "ols mse:  tensor(1.6879)\n",
      "gt params:  tensor([-0.9981, -0.0952, -0.6116,  0.5879,  0.0585,  0.0982])\n",
      "0 steps | score: [0.44046109914779663]\n",
      "100 steps | score: [0.2844650149345398]\n",
      "200 steps | score: [0.17537204921245575]\n",
      "300 steps | score: [0.21885842084884644]\n",
      "400 steps | score: [0.13957828283309937]\n",
      "500 steps | score: [0.1942845582962036]\n",
      "600 steps | score: [0.2095383107662201]\n",
      "700 steps | score: [0.1505247801542282]\n",
      "800 steps | score: [0.1618354320526123]\n",
      "900 steps | score: [0.135586217045784]\n",
      "1000 steps | score: [0.15655234456062317]\n",
      "1100 steps | score: [0.162826806306839]\n",
      "1200 steps | score: [0.16283100843429565]\n",
      "1300 steps | score: [0.1750636100769043]\n",
      "1400 steps | score: [0.12447145581245422]\n",
      "1500 steps | score: [0.16235192120075226]\n",
      "1600 steps | score: [0.1583310067653656]\n",
      "1700 steps | score: [0.20882385969161987]\n",
      "1800 steps | score: [0.14216047525405884]\n",
      "1900 steps | score: [0.1218012347817421]\n",
      "2000 steps | score: [0.16887006163597107]\n",
      "2100 steps | score: [0.16243907809257507]\n",
      "2200 steps | score: [0.1690153181552887]\n",
      "2300 steps | score: [0.1660565733909607]\n",
      "2400 steps | score: [0.13715271651744843]\n",
      "2500 steps | score: [0.17103561758995056]\n",
      "0 steps | score: [0.45595213770866394, -0.5465056896209717]\n",
      "100 steps | score: [0.7211673259735107, -1.3059126138687134]\n",
      "200 steps | score: [0.46114668250083923, -0.7848806381225586]\n",
      "300 steps | score: [0.34706416726112366, -0.5209586024284363]\n",
      "400 steps | score: [0.32106634974479675, -0.47582346200942993]\n",
      "500 steps | score: [0.3490859568119049, -0.5166304111480713]\n",
      "600 steps | score: [0.38298162817955017, -0.6475266218185425]\n",
      "700 steps | score: [0.08835919201374054, -0.014636527746915817]\n",
      "800 steps | score: [0.2673986256122589, -0.38095882534980774]\n",
      "900 steps | score: [0.2206963300704956, -0.2822436988353729]\n",
      "1000 steps | score: [0.3356524407863617, -0.5348899364471436]\n",
      "1100 steps | score: [0.23105445504188538, -0.30874574184417725]\n",
      "1200 steps | score: [0.08609730005264282, -0.009284738451242447]\n",
      "1300 steps | score: [0.32038214802742004, -0.5157560110092163]\n",
      "1400 steps | score: [0.12623190879821777, -0.08363126963376999]\n",
      "1500 steps | score: [0.28380587697029114, -0.40702253580093384]\n",
      "1600 steps | score: [0.22033028304576874, -0.2691482603549957]\n",
      "1700 steps | score: [0.24784623086452484, -0.33726033568382263]\n",
      "1800 steps | score: [0.2688639760017395, -0.39263150095939636]\n",
      "1900 steps | score: [0.15155525505542755, -0.15677763521671295]\n",
      "2000 steps | score: [0.33345046639442444, -0.517776608467102]\n",
      "2100 steps | score: [0.2751792371273041, -0.3918036222457886]\n",
      "2200 steps | score: [0.30470168590545654, -0.4826439619064331]\n",
      "2300 steps | score: [0.25969091057777405, -0.382487028837204]\n",
      "2400 steps | score: [0.14942888915538788, -0.13703511655330658]\n",
      "2500 steps | score: [0.24102135002613068, -0.33067557215690613]\n",
      "unknown params:  tensor([-0.9880, -0.1094, -0.6176,  0.6076,  0.0192,  0.1205])\n",
      "gt params:  tensor([-0.9981, -0.0952, -0.6116,  0.5879,  0.0585,  0.0982])\n",
      "ols params:  tensor([-0.4868, -0.0548, -0.3165,  0.3128,  0.0129,  3.3408])\n",
      "unknown mse:  tensor(0.0005)\n",
      "ols mse:  tensor(1.8238)\n",
      "gt params:  tensor([-0.9643, -0.0957, -0.6094,  0.5663,  0.0440,  0.0763])\n",
      "0 steps | score: [0.2637612223625183]\n",
      "100 steps | score: [0.06561879068613052]\n",
      "200 steps | score: [0.040062159299850464]\n",
      "300 steps | score: [0.0011150166392326355]\n",
      "0 steps | score: [0.17915858328342438, -0.19546769559383392]\n",
      "100 steps | score: [0.35542821884155273, -0.796198844909668]\n",
      "200 steps | score: [-0.004824993200600147, -0.010975092649459839]\n",
      "300 steps | score: [-0.14648498594760895, 0.26273199915885925]\n",
      "400 steps | score: [0.17441493272781372, -0.43228620290756226]\n",
      "500 steps | score: [-0.10596010833978653, 0.17364972829818726]\n",
      "600 steps | score: [0.03390480577945709, -0.13768313825130463]\n",
      "700 steps | score: [-0.09624545276165009, 0.13307949900627136]\n",
      "800 steps | score: [0.23631028831005096, -0.6743380427360535]\n",
      "900 steps | score: [-0.10381437093019485, 0.13580527901649475]\n",
      "1000 steps | score: [-0.11027373373508453, 0.212009996175766]\n",
      "1100 steps | score: [0.00984521210193634, -0.11650155484676361]\n",
      "1200 steps | score: [-0.06208229064941406, 0.06173499673604965]\n",
      "1300 steps | score: [0.10885600745677948, -0.3217088580131531]\n",
      "1400 steps | score: [-0.037468887865543365, 0.024799220263957977]\n",
      "1500 steps | score: [-0.06407836824655533, 0.07117899507284164]\n",
      "1600 steps | score: [0.07157844305038452, -0.23106759786605835]\n",
      "1700 steps | score: [0.008135396055877209, -0.09288178384304047]\n",
      "1800 steps | score: [-0.01471269503235817, -0.04303599148988724]\n",
      "1900 steps | score: [-0.006842595525085926, -0.06119971722364426]\n",
      "2000 steps | score: [-0.025894958525896072, -0.023982688784599304]\n",
      "2100 steps | score: [0.1393563449382782, -0.37862634658813477]\n",
      "2200 steps | score: [0.08978134393692017, -0.3019179701805115]\n",
      "2300 steps | score: [-0.12024860084056854, 0.19019082188606262]\n",
      "2400 steps | score: [-0.006039896979928017, -0.09302714467048645]\n",
      "2500 steps | score: [0.008378486149013042, -0.1012752503156662]\n",
      "unknown params:  tensor([-0.8812, -0.1050, -0.5564,  0.5030, -0.0049,  0.2874])\n",
      "gt params:  tensor([-0.9643, -0.0957, -0.6094,  0.5663,  0.0440,  0.0763])\n",
      "ols params:  tensor([-4.6534e-01, -5.6030e-02, -3.0447e-01,  2.7721e-01,  2.9526e-03,\n",
      "         3.4208e+00])\n",
      "unknown mse:  tensor(0.0101)\n",
      "ols mse:  tensor(1.9358)\n",
      "gt params:  tensor([-0.9685, -0.0836, -0.6154,  0.5713,  0.0438,  0.0857])\n",
      "0 steps | score: [0.1858235001564026]\n",
      "100 steps | score: [-0.08738052845001221]\n",
      "200 steps | score: [-0.0594022236764431]\n",
      "300 steps | score: [-0.10159654915332794]\n",
      "400 steps | score: [-0.1029200628399849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [-0.12008602172136307]\n",
      "600 steps | score: [-0.10388768464326859]\n",
      "700 steps | score: [-0.06470166146755219]\n",
      "800 steps | score: [-0.055585943162441254]\n",
      "900 steps | score: [-0.0871802419424057]\n",
      "1000 steps | score: [-0.141184002161026]\n",
      "1100 steps | score: [-0.10922117531299591]\n",
      "1200 steps | score: [-0.08428069949150085]\n",
      "1300 steps | score: [-0.06789474934339523]\n",
      "1400 steps | score: [-0.10739173740148544]\n",
      "1500 steps | score: [-0.12770971655845642]\n",
      "1600 steps | score: [-0.11340253055095673]\n",
      "1700 steps | score: [-0.07765129208564758]\n",
      "1800 steps | score: [-0.06926417350769043]\n",
      "1900 steps | score: [-0.09892538189888]\n",
      "2000 steps | score: [-0.10396440327167511]\n",
      "2100 steps | score: [-0.09479488432407379]\n",
      "2200 steps | score: [-0.09410049766302109]\n",
      "2300 steps | score: [-0.1006506010890007]\n",
      "2400 steps | score: [-0.09326177090406418]\n",
      "2500 steps | score: [-0.0907396599650383]\n",
      "0 steps | score: [0.1530352681875229, -0.2097705602645874]\n",
      "100 steps | score: [-0.08971679955720901, 0.16389788687229156]\n",
      "200 steps | score: [-0.07406247407197952, 0.09785067290067673]\n",
      "300 steps | score: [-0.26202356815338135, 0.4202278256416321]\n",
      "400 steps | score: [-0.17728623747825623, 0.2424468845129013]\n",
      "500 steps | score: [0.07995965331792831, -0.3097074031829834]\n",
      "600 steps | score: [-0.0942232683300972, 0.06817435473203659]\n",
      "700 steps | score: [-0.06516963243484497, 0.030417099595069885]\n",
      "800 steps | score: [-0.00517137348651886, -0.16076651215553284]\n",
      "900 steps | score: [-0.055852822959423065, -0.017061203718185425]\n",
      "1000 steps | score: [-0.06038127839565277, 0.009918123483657837]\n",
      "1100 steps | score: [-0.1729949712753296, 0.2343720644712448]\n",
      "1200 steps | score: [-0.0510779432952404, -0.052573397755622864]\n",
      "1300 steps | score: [0.10820498317480087, -0.3962451219558716]\n",
      "1400 steps | score: [-0.0911291316151619, 0.07781954109668732]\n",
      "1500 steps | score: [-0.11287093907594681, 0.13592572510242462]\n",
      "1600 steps | score: [-0.08367954194545746, 0.009128332138061523]\n",
      "1700 steps | score: [-0.004017458762973547, -0.14543749392032623]\n",
      "1800 steps | score: [-0.027050167322158813, -0.058946847915649414]\n",
      "1900 steps | score: [-0.12319445610046387, 0.10266605019569397]\n",
      "2000 steps | score: [-0.06653037667274475, -0.036075159907341]\n",
      "2100 steps | score: [0.03975272923707962, -0.2298734486103058]\n",
      "2200 steps | score: [-0.018619131296873093, -0.09627670049667358]\n",
      "2300 steps | score: [0.03564322739839554, -0.20803996920585632]\n",
      "2400 steps | score: [-0.0380064882338047, -0.06582741439342499]\n",
      "2500 steps | score: [-0.05682458356022835, -0.019913718104362488]\n",
      "unknown params:  tensor([-0.9420, -0.0914, -0.6121,  0.5433,  0.0439,  0.1270])\n",
      "gt params:  tensor([-0.9685, -0.0836, -0.6154,  0.5713,  0.0438,  0.0857])\n",
      "ols params:  tensor([-0.4722, -0.0440, -0.3192,  0.2850,  0.0237,  3.4638])\n",
      "unknown mse:  tensor(0.0005)\n",
      "ols mse:  tensor(1.9715)\n",
      "gt params:  tensor([-0.9980, -0.0767, -0.6189,  0.5732,  0.0302,  0.1134])\n",
      "0 steps | score: [0.4535694718360901]\n",
      "100 steps | score: [0.13363151252269745]\n",
      "200 steps | score: [0.18057465553283691]\n",
      "300 steps | score: [0.19006755948066711]\n",
      "400 steps | score: [0.13443523645401]\n",
      "500 steps | score: [0.16498112678527832]\n",
      "600 steps | score: [0.11985316127538681]\n",
      "700 steps | score: [0.1642242670059204]\n",
      "800 steps | score: [0.2089122235774994]\n",
      "900 steps | score: [0.143777996301651]\n",
      "1000 steps | score: [0.15378576517105103]\n",
      "1100 steps | score: [0.13453145325183868]\n",
      "1200 steps | score: [0.16197091341018677]\n",
      "1300 steps | score: [0.1746455430984497]\n",
      "1400 steps | score: [0.1591080278158188]\n",
      "1500 steps | score: [0.15163829922676086]\n",
      "1600 steps | score: [0.12769021093845367]\n",
      "1700 steps | score: [0.1428682506084442]\n",
      "1800 steps | score: [0.16404405236244202]\n",
      "1900 steps | score: [0.1432511955499649]\n",
      "2000 steps | score: [0.14133763313293457]\n",
      "2100 steps | score: [0.12982085347175598]\n",
      "2200 steps | score: [0.13206233084201813]\n",
      "2300 steps | score: [0.1416170299053192]\n",
      "2400 steps | score: [0.1433674395084381]\n",
      "2500 steps | score: [0.14194470643997192]\n",
      "0 steps | score: [0.2346065640449524, -0.18844950199127197]\n",
      "100 steps | score: [0.10736037790775299, -0.06753622740507126]\n",
      "200 steps | score: [-0.04954436421394348, 0.206941157579422]\n",
      "300 steps | score: [-0.1690269559621811, 0.4376260042190552]\n",
      "400 steps | score: [-0.07340193539857864, 0.2537601590156555]\n",
      "500 steps | score: [-0.02869393490254879, 0.151694655418396]\n",
      "600 steps | score: [-0.18256285786628723, 0.4591159224510193]\n",
      "700 steps | score: [0.09313595294952393, -0.1751570850610733]\n",
      "800 steps | score: [0.19473856687545776, -0.3766568601131439]\n",
      "900 steps | score: [-0.018129244446754456, 0.11373522877693176]\n",
      "1000 steps | score: [0.2360294610261917, -0.49186649918556213]\n",
      "1100 steps | score: [0.08321289718151093, -0.1690315455198288]\n",
      "1200 steps | score: [0.1326793134212494, -0.24052295088768005]\n",
      "1300 steps | score: [0.2087382823228836, -0.4290282428264618]\n",
      "1400 steps | score: [0.03492969647049904, -0.02545969933271408]\n",
      "1500 steps | score: [0.04875671863555908, -0.052548885345458984]\n",
      "1600 steps | score: [0.09090490639209747, -0.1508445143699646]\n",
      "1700 steps | score: [0.241648331284523, -0.515099287033081]\n",
      "1800 steps | score: [0.12327088415622711, -0.23574143648147583]\n",
      "1900 steps | score: [-0.004650976974517107, 0.07765168696641922]\n",
      "2000 steps | score: [0.035565976053476334, -0.0069643668830394745]\n",
      "2100 steps | score: [-0.02705320715904236, 0.10874171555042267]\n",
      "2200 steps | score: [0.10876533389091492, -0.23633570969104767]\n",
      "2300 steps | score: [0.10533549636602402, -0.22024735808372498]\n",
      "2400 steps | score: [0.06318493187427521, -0.06978332251310349]\n",
      "2500 steps | score: [0.1234314888715744, -0.2417580783367157]\n",
      "unknown params:  tensor([-1.0747, -0.0842, -0.6842,  0.5701, -0.0088,  0.0612])\n",
      "gt params:  tensor([-0.9980, -0.0767, -0.6189,  0.5732,  0.0302,  0.1134])\n",
      "ols params:  tensor([-4.9729e-01, -3.4868e-02, -3.2771e-01,  2.7528e-01, -2.4519e-03,\n",
      "         3.5779e+00])\n",
      "unknown mse:  tensor(0.0024)\n",
      "ols mse:  tensor(2.0716)\n",
      "gt params:  tensor([-0.9931, -0.1023, -0.6426,  0.5695,  0.0360,  0.0366])\n",
      "0 steps | score: [0.023659635335206985]\n",
      "100 steps | score: [-0.21291503310203552]\n",
      "200 steps | score: [-0.2782953977584839]\n",
      "300 steps | score: [-0.1985107660293579]\n",
      "400 steps | score: [-0.287423312664032]\n",
      "500 steps | score: [-0.22938022017478943]\n",
      "600 steps | score: [-0.20507588982582092]\n",
      "700 steps | score: [-0.253068745136261]\n",
      "800 steps | score: [-0.23235201835632324]\n",
      "900 steps | score: [-0.24742180109024048]\n",
      "1000 steps | score: [-0.2487441450357437]\n",
      "1100 steps | score: [-0.20843225717544556]\n",
      "1200 steps | score: [-0.2033773958683014]\n",
      "1300 steps | score: [-0.2318682074546814]\n",
      "1400 steps | score: [-0.23475946485996246]\n",
      "1500 steps | score: [-0.2300662398338318]\n",
      "1600 steps | score: [-0.2063821405172348]\n",
      "1700 steps | score: [-0.18746712803840637]\n",
      "1800 steps | score: [-0.19610384106636047]\n",
      "1900 steps | score: [-0.21433299779891968]\n",
      "2000 steps | score: [-0.23393863439559937]\n",
      "2100 steps | score: [-0.23745422065258026]\n",
      "2200 steps | score: [-0.22157244384288788]\n",
      "2300 steps | score: [-0.20739227533340454]\n",
      "2400 steps | score: [-0.2342248409986496]\n",
      "2500 steps | score: [-0.24180498719215393]\n",
      "0 steps | score: [0.16322197020053864, -0.22356843948364258]\n",
      "100 steps | score: [0.22828219830989838, -0.5245636105537415]\n",
      "200 steps | score: [-0.22625350952148438, 0.39835238456726074]\n",
      "300 steps | score: [0.29123738408088684, -0.7712557315826416]\n",
      "400 steps | score: [-0.160349041223526, 0.19826562702655792]\n",
      "500 steps | score: [0.2096801996231079, -0.6938427686691284]\n",
      "600 steps | score: [-0.10356823354959488, 0.11491992324590683]\n",
      "700 steps | score: [-0.15381121635437012, 0.2240467369556427]\n",
      "800 steps | score: [-0.052289124578237534, 0.015389040112495422]\n",
      "900 steps | score: [-0.058916401118040085, -0.00885055959224701]\n",
      "1000 steps | score: [0.05095039680600166, -0.26168209314346313]\n",
      "1100 steps | score: [-0.09660593420267105, 0.0801093727350235]\n",
      "1200 steps | score: [-0.19087320566177368, 0.2728196382522583]\n",
      "1300 steps | score: [-0.088752880692482, 0.059574857354164124]\n",
      "1400 steps | score: [-0.07723933458328247, 0.028520837426185608]\n",
      "1500 steps | score: [0.01658172346651554, -0.160100519657135]\n",
      "1600 steps | score: [0.03493890166282654, -0.21752846240997314]\n",
      "1700 steps | score: [0.01945943757891655, -0.15921863913536072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 steps | score: [-0.06319602578878403, -0.006088078022003174]\n",
      "1900 steps | score: [-0.039908986538648605, -0.04227939248085022]\n",
      "2000 steps | score: [-0.0741553008556366, 0.03181026875972748]\n",
      "2100 steps | score: [0.06537695974111557, -0.287549763917923]\n",
      "2200 steps | score: [0.06558287143707275, -0.2701713442802429]\n",
      "2300 steps | score: [0.011284571141004562, -0.18256458640098572]\n",
      "2400 steps | score: [-0.10824133455753326, 0.11591454595327377]\n",
      "2500 steps | score: [-0.07051841169595718, 0.008719339966773987]\n",
      "unknown params:  tensor([-0.9592, -0.1277, -0.6119,  0.5182,  0.0604,  0.0260])\n",
      "gt params:  tensor([-0.9931, -0.1023, -0.6426,  0.5695,  0.0360,  0.0366])\n",
      "ols params:  tensor([-0.4634, -0.0619, -0.3039,  0.2588,  0.0303,  3.6727])\n",
      "unknown mse:  tensor(0.0010)\n",
      "ols mse:  tensor(2.2858)\n",
      "gt params:  tensor([-1.0058, -0.0938, -0.6266,  0.5658,  0.0670,  0.0517])\n",
      "0 steps | score: [0.36870524287223816]\n",
      "100 steps | score: [0.021333809942007065]\n",
      "200 steps | score: [0.13589055836200714]\n",
      "300 steps | score: [0.07870166003704071]\n",
      "400 steps | score: [0.09881877154111862]\n",
      "500 steps | score: [0.11948446929454803]\n",
      "600 steps | score: [0.008949525654315948]\n",
      "0 steps | score: [0.044492777436971664, 0.032468028366565704]\n",
      "100 steps | score: [-0.3057907521724701, 0.6130995154380798]\n",
      "200 steps | score: [0.06263691931962967, -0.22261783480644226]\n",
      "300 steps | score: [-0.1355160027742386, 0.2251916527748108]\n",
      "400 steps | score: [0.0742669627070427, -0.31967222690582275]\n",
      "500 steps | score: [0.0860351175069809, -0.3469608724117279]\n",
      "600 steps | score: [-0.35626551508903503, 0.6431397199630737]\n",
      "700 steps | score: [-0.05330629274249077, -0.008758915588259697]\n",
      "800 steps | score: [0.02287391386926174, -0.1900353878736496]\n",
      "900 steps | score: [-0.09012363106012344, 0.07213263213634491]\n",
      "1000 steps | score: [0.017163589596748352, -0.192697212100029]\n",
      "1100 steps | score: [-0.32415658235549927, 0.5718223452568054]\n",
      "1200 steps | score: [0.08038213104009628, -0.33008769154548645]\n",
      "1300 steps | score: [-0.0399937778711319, -0.033549319952726364]\n",
      "1400 steps | score: [-0.019756408408284187, -0.08991005271673203]\n",
      "1500 steps | score: [-0.1549793779850006, 0.22306077182292938]\n",
      "1600 steps | score: [-0.1512366533279419, 0.2079380750656128]\n",
      "1700 steps | score: [0.12756061553955078, -0.4578312933444977]\n",
      "1800 steps | score: [-0.11131949722766876, 0.11179250478744507]\n",
      "1900 steps | score: [-0.11848927289247513, 0.13467726111412048]\n",
      "2000 steps | score: [-0.11456072330474854, 0.13265761733055115]\n",
      "2100 steps | score: [-0.18870237469673157, 0.2769864797592163]\n",
      "2200 steps | score: [0.023274194449186325, -0.19355005025863647]\n",
      "2300 steps | score: [-0.09730778634548187, 0.0871378630399704]\n",
      "2400 steps | score: [-0.09119231253862381, 0.059256263077259064]\n",
      "2500 steps | score: [-0.13507960736751556, 0.16644050180912018]\n",
      "2600 steps | score: [-0.15593886375427246, 0.21543097496032715]\n",
      "2700 steps | score: [-0.025915518403053284, -0.11594083905220032]\n",
      "2800 steps | score: [-0.12864375114440918, 0.1621648520231247]\n",
      "2900 steps | score: [-0.096677765250206, 0.07980455458164215]\n",
      "unknown params:  tensor([-0.9713, -0.0868, -0.5754,  0.5220,  0.0675,  0.3817])\n",
      "gt params:  tensor([-1.0058, -0.0938, -0.6266,  0.5658,  0.0670,  0.0517])\n",
      "ols params:  tensor([-0.4814, -0.0429, -0.2966,  0.2720,  0.0379,  3.8423])\n",
      "unknown mse:  tensor(0.0191)\n",
      "ols mse:  tensor(2.4738)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/6c63cf1b-3a31-4b8f-a015-8223e751428f\n",
      "gt params:  tensor([-0.9462, -0.9822,  0.9219,  0.7921, -0.4619, -0.3079])\n",
      "0 steps | score: [-0.059692710638046265]\n",
      "100 steps | score: [-0.16081103682518005]\n",
      "200 steps | score: [-0.10202433168888092]\n",
      "300 steps | score: [-0.1875918060541153]\n",
      "400 steps | score: [-0.07176151126623154]\n",
      "500 steps | score: [-0.1369258016347885]\n",
      "600 steps | score: [-0.11973775178194046]\n",
      "700 steps | score: [-0.11559762060642242]\n",
      "800 steps | score: [-0.10500426590442657]\n",
      "900 steps | score: [-0.19491057097911835]\n",
      "1000 steps | score: [-0.15787982940673828]\n",
      "1100 steps | score: [-0.2530795633792877]\n",
      "1200 steps | score: [-0.08638864010572433]\n",
      "1300 steps | score: [-0.14343246817588806]\n",
      "1400 steps | score: [-0.1599999964237213]\n",
      "1500 steps | score: [-0.19439317286014557]\n",
      "1600 steps | score: [-0.16761180758476257]\n",
      "1700 steps | score: [-0.16852107644081116]\n",
      "1800 steps | score: [-0.16653403639793396]\n",
      "1900 steps | score: [-0.15109984576702118]\n",
      "2000 steps | score: [-0.18015703558921814]\n",
      "2100 steps | score: [-0.18172863125801086]\n",
      "2200 steps | score: [-0.19085848331451416]\n",
      "2300 steps | score: [-0.14040738344192505]\n",
      "2400 steps | score: [-0.16263647377490997]\n",
      "2500 steps | score: [-0.2069171667098999]\n",
      "2600 steps | score: [-0.140634223818779]\n",
      "2700 steps | score: [-0.14829662442207336]\n",
      "2800 steps | score: [-0.1552087813615799]\n",
      "0 steps | score: [0.1966944932937622, -0.5335927605628967]\n",
      "100 steps | score: [1.27388334274292, -2.039295196533203]\n",
      "200 steps | score: [-3.9786159992218018, 13.68408203125]\n",
      "300 steps | score: [-3.978616237640381, 13.68408203125]\n",
      "400 steps | score: [3.4641189575195312, -15.280284881591797]\n",
      "500 steps | score: [-1.9545459747314453, 11.26290225982666]\n",
      "600 steps | score: [-2.6437666416168213, 12.545187950134277]\n",
      "700 steps | score: [3.8269104957580566, -22.935983657836914]\n",
      "800 steps | score: [0.07153987884521484, 4.136745452880859]\n",
      "900 steps | score: [0.20407399535179138, 3.5103538036346436]\n",
      "1000 steps | score: [0.8145153522491455, -1.1327873468399048]\n",
      "1100 steps | score: [1.0725435018539429, -5.029392242431641]\n",
      "1200 steps | score: [1.3242765665054321, -8.311140060424805]\n",
      "1300 steps | score: [0.9101592302322388, -5.786580562591553]\n",
      "1400 steps | score: [0.1956411600112915, -0.7509438991546631]\n",
      "1500 steps | score: [0.5133284330368042, -3.2350411415100098]\n",
      "1600 steps | score: [1.1347706317901611, -8.537969589233398]\n",
      "1700 steps | score: [0.12124845385551453, -0.31895917654037476]\n",
      "1800 steps | score: [-0.1265772432088852, 1.2454580068588257]\n",
      "1900 steps | score: [0.1844772845506668, -0.9333165884017944]\n",
      "2000 steps | score: [0.1615925133228302, -0.8142766952514648]\n",
      "2100 steps | score: [0.010851743631064892, 0.4036155343055725]\n",
      "2200 steps | score: [0.3851795196533203, -2.266110420227051]\n",
      "2300 steps | score: [-0.01979984901845455, 0.4959881007671356]\n",
      "2400 steps | score: [0.04925812408328056, 0.17590531706809998]\n",
      "2500 steps | score: [-0.015283691696822643, 0.43445372581481934]\n",
      "2600 steps | score: [0.141966313123703, -0.6883531808853149]\n",
      "2700 steps | score: [0.2900291383266449, -1.7823913097381592]\n",
      "2800 steps | score: [0.12693698704242706, -0.34189000725746155]\n",
      "unknown params:  tensor([-0.9073, -0.9429,  0.9020,  0.7860, -0.4583, -0.1652])\n",
      "gt params:  tensor([-0.9462, -0.9822,  0.9219,  0.7921, -0.4619, -0.3079])\n",
      "ols params:  tensor([-0.8883, -0.9210,  0.8597,  0.7450, -0.4391,  0.1221])\n",
      "unknown mse:  tensor(0.0040)\n",
      "ols mse:  tensor(0.0331)\n",
      "gt params:  tensor([-0.9469, -0.9758,  0.9171,  0.7971, -0.4658, -0.2942])\n",
      "0 steps | score: [0.2606423497200012]\n",
      "100 steps | score: [0.11258521676063538]\n",
      "200 steps | score: [0.26398664712905884]\n",
      "300 steps | score: [0.03988088667392731]\n",
      "400 steps | score: [0.12175815552473068]\n",
      "500 steps | score: [0.06824293732643127]\n",
      "600 steps | score: [0.13401386141777039]\n",
      "700 steps | score: [0.14733614027500153]\n",
      "800 steps | score: [-0.008167900145053864]\n",
      "0 steps | score: [-0.1543852835893631, 0.7322220802307129]\n",
      "100 steps | score: [-0.5881392955780029, 2.5708580017089844]\n",
      "200 steps | score: [1.0640983581542969, -6.479327201843262]\n",
      "300 steps | score: [-0.002955966629087925, -0.42908307909965515]\n",
      "400 steps | score: [-1.1002683639526367, 4.533771991729736]\n",
      "500 steps | score: [-0.10956444591283798, 0.18843087553977966]\n",
      "600 steps | score: [-0.6150659322738647, 2.507937431335449]\n",
      "700 steps | score: [-0.2998069226741791, 1.1447116136550903]\n",
      "800 steps | score: [-0.5963151454925537, 2.3731460571289062]\n",
      "900 steps | score: [-0.23842978477478027, 0.7109432220458984]\n",
      "1000 steps | score: [0.31191712617874146, -2.1158313751220703]\n",
      "1100 steps | score: [-0.21781118214130402, 0.5877217650413513]\n",
      "1200 steps | score: [-0.3355765640735626, 1.2359734773635864]\n",
      "1300 steps | score: [-0.16262462735176086, 0.2771945595741272]\n",
      "1400 steps | score: [-0.32116037607192993, 1.1444510221481323]\n",
      "1500 steps | score: [-0.22973738610744476, 0.6593062877655029]\n",
      "1600 steps | score: [-0.45573827624320984, 1.7349579334259033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 steps | score: [-0.3376999497413635, 1.1900904178619385]\n",
      "1800 steps | score: [-0.2700469493865967, 0.9051325917243958]\n",
      "1900 steps | score: [-0.16106539964675903, 0.3467634916305542]\n",
      "2000 steps | score: [-0.2063187062740326, 0.4817369878292084]\n",
      "2100 steps | score: [-0.27506881952285767, 0.849052906036377]\n",
      "2200 steps | score: [-0.27605387568473816, 0.9637645483016968]\n",
      "2300 steps | score: [-0.14974674582481384, 0.29412373900413513]\n",
      "2400 steps | score: [-0.31790319085121155, 1.1208817958831787]\n",
      "2500 steps | score: [-0.19700202345848083, 0.4761456847190857]\n",
      "2600 steps | score: [-0.23793894052505493, 0.6821841597557068]\n",
      "2700 steps | score: [-0.3649488687515259, 1.3395781517028809]\n",
      "2800 steps | score: [-0.2336290031671524, 0.6145528554916382]\n",
      "unknown params:  tensor([-0.9379, -0.9598,  0.9053,  0.7894, -0.4518, -0.2345])\n",
      "gt params:  tensor([-0.9469, -0.9758,  0.9171,  0.7971, -0.4658, -0.2942])\n",
      "ols params:  tensor([-0.8437, -0.8654,  0.8102,  0.7092, -0.4092,  0.5197])\n",
      "unknown mse:  tensor(0.0007)\n",
      "ols mse:  tensor(0.1180)\n",
      "gt params:  tensor([-0.9453, -0.9893,  0.9157,  0.7914, -0.4577, -0.3026])\n",
      "0 steps | score: [0.08945482969284058]\n",
      "100 steps | score: [0.011429427191615105]\n",
      "200 steps | score: [-0.014734527096152306]\n",
      "300 steps | score: [-0.12748335301876068]\n",
      "400 steps | score: [-0.04866431653499603]\n",
      "500 steps | score: [0.061457011848688126]\n",
      "600 steps | score: [0.04693685472011566]\n",
      "700 steps | score: [0.002163715660572052]\n",
      "0 steps | score: [-0.020023642107844353, 0.11034538596868515]\n",
      "100 steps | score: [-0.456455796957016, 1.9439172744750977]\n",
      "200 steps | score: [0.25742319226264954, -0.191223606467247]\n",
      "300 steps | score: [-0.43282943964004517, 1.8592885732650757]\n",
      "400 steps | score: [-0.21143200993537903, 0.6199788451194763]\n",
      "500 steps | score: [-0.16801227629184723, 0.13757139444351196]\n",
      "600 steps | score: [-0.24335457384586334, 0.41910845041275024]\n",
      "700 steps | score: [0.06724922358989716, -1.004622220993042]\n",
      "800 steps | score: [-0.1363053172826767, -0.028913840651512146]\n",
      "900 steps | score: [-0.2504802644252777, 0.5441245436668396]\n",
      "1000 steps | score: [-0.26022472977638245, 0.43708470463752747]\n",
      "1100 steps | score: [-0.030134964734315872, -0.6359304189682007]\n",
      "1200 steps | score: [0.04134528338909149, -1.025283932685852]\n",
      "1300 steps | score: [-0.28250497579574585, 0.6254433393478394]\n",
      "1400 steps | score: [-0.0058547803200781345, -0.7248875498771667]\n",
      "1500 steps | score: [-0.13729745149612427, -0.10792338103055954]\n",
      "1600 steps | score: [-0.22401869297027588, 0.2806698679924011]\n",
      "1700 steps | score: [-0.1007910668849945, -0.24982094764709473]\n",
      "1800 steps | score: [-0.16367724537849426, -0.04013526439666748]\n",
      "1900 steps | score: [-0.1206461563706398, -0.1686825156211853]\n",
      "2000 steps | score: [-0.2067578285932541, 0.2388509064912796]\n",
      "2100 steps | score: [-0.16896139085292816, 0.04262326657772064]\n",
      "2200 steps | score: [-0.18379786610603333, 0.07897835224866867]\n",
      "2300 steps | score: [-0.11400406807661057, -0.22330504655838013]\n",
      "2400 steps | score: [-0.07791169732809067, -0.3963494598865509]\n",
      "2500 steps | score: [-0.1409355103969574, 0.01233605295419693]\n",
      "2600 steps | score: [-0.11962205171585083, -0.21326503157615662]\n",
      "2700 steps | score: [-0.23372335731983185, 0.2948581874370575]\n",
      "2800 steps | score: [-0.10303322225809097, -0.2593382000923157]\n",
      "unknown params:  tensor([-0.9931, -1.0159,  0.9395,  0.8162, -0.4772, -0.3509])\n",
      "gt params:  tensor([-0.9453, -0.9893,  0.9157,  0.7914, -0.4577, -0.3026])\n",
      "ols params:  tensor([-0.8205, -0.8422,  0.7818,  0.6805, -0.3954,  0.7395])\n",
      "unknown mse:  tensor(0.0011)\n",
      "ols mse:  tensor(0.1929)\n",
      "gt params:  tensor([-0.9552, -0.9885,  0.9097,  0.7884, -0.4552, -0.2949])\n",
      "0 steps | score: [-0.06105971336364746]\n",
      "100 steps | score: [-0.12241175770759583]\n",
      "200 steps | score: [-0.12265921384096146]\n",
      "300 steps | score: [-0.14602679014205933]\n",
      "400 steps | score: [-0.24903151392936707]\n",
      "500 steps | score: [-0.15846291184425354]\n",
      "600 steps | score: [-0.21348977088928223]\n",
      "700 steps | score: [-0.26051050424575806]\n",
      "800 steps | score: [-0.19368445873260498]\n",
      "900 steps | score: [-0.21398881077766418]\n",
      "1000 steps | score: [-0.18259495496749878]\n",
      "1100 steps | score: [-0.2084171324968338]\n",
      "1200 steps | score: [-0.26810121536254883]\n",
      "1300 steps | score: [-0.20375171303749084]\n",
      "1400 steps | score: [-0.20854830741882324]\n",
      "1500 steps | score: [-0.16790176928043365]\n",
      "1600 steps | score: [-0.23396486043930054]\n",
      "1700 steps | score: [-0.21416449546813965]\n",
      "1800 steps | score: [-0.18419808149337769]\n",
      "1900 steps | score: [-0.18340957164764404]\n",
      "2000 steps | score: [-0.16216230392456055]\n",
      "2100 steps | score: [-0.18495824933052063]\n",
      "2200 steps | score: [-0.1812935471534729]\n",
      "2300 steps | score: [-0.22278983891010284]\n",
      "2400 steps | score: [-0.20790961384773254]\n",
      "2500 steps | score: [-0.1954696923494339]\n",
      "2600 steps | score: [-0.18564057350158691]\n",
      "2700 steps | score: [-0.19954945147037506]\n",
      "2800 steps | score: [-0.1996869444847107]\n",
      "0 steps | score: [0.12274973094463348, -0.04794354736804962]\n",
      "100 steps | score: [-0.33546772599220276, 1.3259516954421997]\n",
      "200 steps | score: [-0.10584453493356705, 0.5354792475700378]\n",
      "300 steps | score: [0.1452576071023941, -0.5797553658485413]\n",
      "400 steps | score: [-0.22902025282382965, 0.7884335517883301]\n",
      "500 steps | score: [-0.10686542093753815, 0.3973863124847412]\n",
      "600 steps | score: [-0.15694716572761536, 0.483923077583313]\n",
      "700 steps | score: [-0.3823219835758209, 1.3397632837295532]\n",
      "800 steps | score: [-0.23620955646038055, 0.7936190962791443]\n",
      "900 steps | score: [-0.012243123725056648, 0.04803360253572464]\n",
      "1000 steps | score: [-0.011101084761321545, 0.0088396817445755]\n",
      "1100 steps | score: [-0.1958095282316208, 0.6756964921951294]\n",
      "1200 steps | score: [-0.1313200742006302, 0.4561534523963928]\n",
      "1300 steps | score: [-0.3070913851261139, 1.1220604181289673]\n",
      "1400 steps | score: [-0.21949678659439087, 0.8087571263313293]\n",
      "1500 steps | score: [-0.17719072103500366, 0.649638295173645]\n",
      "1600 steps | score: [-0.10377249121665955, 0.31930336356163025]\n",
      "1700 steps | score: [0.2850284278392792, -1.2362874746322632]\n",
      "1800 steps | score: [-0.009505645371973515, -0.028951160609722137]\n",
      "1900 steps | score: [0.01219354197382927, -0.08912821859121323]\n",
      "2000 steps | score: [0.09958790987730026, -0.4459686577320099]\n",
      "2100 steps | score: [0.07046699523925781, -0.34171104431152344]\n",
      "2200 steps | score: [0.015454228036105633, -0.1063021570444107]\n",
      "2300 steps | score: [-0.15831121802330017, 0.5388922691345215]\n",
      "2400 steps | score: [-0.00776986638084054, -0.039154138416051865]\n",
      "2500 steps | score: [-0.04629848524928093, 0.13557471334934235]\n",
      "2600 steps | score: [0.009237993508577347, -0.12506207823753357]\n",
      "2700 steps | score: [0.10798247158527374, -0.47182372212409973]\n",
      "2800 steps | score: [0.025541260838508606, -0.1927749067544937]\n",
      "unknown params:  tensor([-0.9721, -1.0001,  0.9189,  0.7799, -0.4598, -0.1781])\n",
      "gt params:  tensor([-0.9552, -0.9885,  0.9097,  0.7884, -0.4552, -0.2949])\n",
      "ols params:  tensor([-0.7758, -0.7985,  0.7381,  0.6313, -0.3685,  1.0952])\n",
      "unknown mse:  tensor(0.0024)\n",
      "ols mse:  tensor(0.3437)\n",
      "gt params:  tensor([-0.9643, -0.9921,  0.9177,  0.8013, -0.4498, -0.2883])\n",
      "0 steps | score: [-0.09800693392753601]\n",
      "100 steps | score: [-0.3712955415248871]\n",
      "200 steps | score: [-0.19308151304721832]\n",
      "300 steps | score: [-0.11437241733074188]\n",
      "400 steps | score: [-0.18187466263771057]\n",
      "500 steps | score: [-0.31441250443458557]\n",
      "600 steps | score: [-0.27415233850479126]\n",
      "700 steps | score: [-0.27652284502983093]\n",
      "800 steps | score: [-0.18714767694473267]\n",
      "900 steps | score: [-0.2518561780452728]\n",
      "1000 steps | score: [-0.25577038526535034]\n",
      "1100 steps | score: [-0.34357312321662903]\n",
      "1200 steps | score: [-0.26524704694747925]\n",
      "1300 steps | score: [-0.24359886348247528]\n",
      "1400 steps | score: [-0.2157088816165924]\n",
      "1500 steps | score: [-0.26391246914863586]\n",
      "1600 steps | score: [-0.3078871965408325]\n",
      "1700 steps | score: [-0.25796645879745483]\n",
      "1800 steps | score: [-0.21458859741687775]\n",
      "1900 steps | score: [-0.24878253042697906]\n",
      "2000 steps | score: [-0.3093850016593933]\n",
      "2100 steps | score: [-0.2545793652534485]\n",
      "2200 steps | score: [-0.2616457939147949]\n",
      "2300 steps | score: [-0.20511013269424438]\n",
      "2400 steps | score: [-0.25902894139289856]\n",
      "2500 steps | score: [-0.27502161264419556]\n",
      "2600 steps | score: [-0.2524808645248413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 steps | score: [-0.25202885270118713]\n",
      "2800 steps | score: [-0.2522158920764923]\n",
      "0 steps | score: [-0.09304314851760864, 1.065331220626831]\n",
      "100 steps | score: [-0.3299729824066162, 1.5816365480422974]\n",
      "200 steps | score: [-0.09332377463579178, 0.6828495264053345]\n",
      "300 steps | score: [0.6227282285690308, -2.105764865875244]\n",
      "400 steps | score: [-0.09074045717716217, 0.6442878842353821]\n",
      "500 steps | score: [-0.48195919394493103, 2.0178170204162598]\n",
      "600 steps | score: [-0.32329443097114563, 1.4940948486328125]\n",
      "700 steps | score: [-0.22655777633190155, 1.103819727897644]\n",
      "800 steps | score: [-0.1269816756248474, 0.8279461860656738]\n",
      "900 steps | score: [-0.19364593923091888, 1.006534457206726]\n",
      "1000 steps | score: [-0.24625185132026672, 1.1982706785202026]\n",
      "1100 steps | score: [-0.4035196602344513, 1.7514981031417847]\n",
      "1200 steps | score: [-0.35410428047180176, 1.575718641281128]\n",
      "1300 steps | score: [-0.4235604703426361, 1.7963136434555054]\n",
      "1400 steps | score: [-0.1578657180070877, 0.908814549446106]\n",
      "1500 steps | score: [-0.27880439162254333, 1.275094747543335]\n",
      "1600 steps | score: [-0.3331359028816223, 1.4510760307312012]\n",
      "1700 steps | score: [-0.2657299339771271, 1.248840093612671]\n",
      "1800 steps | score: [-0.11960641294717789, 0.7569906115531921]\n",
      "1900 steps | score: [-0.26324087381362915, 1.2668509483337402]\n",
      "2000 steps | score: [-0.38405147194862366, 1.6495836973190308]\n",
      "2100 steps | score: [-0.10253453254699707, 0.6612087488174438]\n",
      "2200 steps | score: [-0.04671743884682655, 0.509425163269043]\n",
      "2300 steps | score: [-0.12168681621551514, 0.7893690466880798]\n",
      "2400 steps | score: [-0.27946725487709045, 1.2995980978012085]\n",
      "2500 steps | score: [-0.23715540766716003, 1.1587008237838745]\n",
      "2600 steps | score: [-0.23593130707740784, 1.1440647840499878]\n",
      "2700 steps | score: [-0.135319322347641, 0.7960336208343506]\n",
      "2800 steps | score: [-0.2716434895992279, 1.2938861846923828]\n",
      "unknown params:  tensor([-0.9465, -0.9702,  0.8810,  0.7791, -0.4492, -0.1759])\n",
      "gt params:  tensor([-0.9643, -0.9921,  0.9177,  0.8013, -0.4498, -0.2883])\n",
      "ols params:  tensor([-0.7558, -0.7758,  0.7061,  0.6300, -0.3602,  1.3179])\n",
      "unknown mse:  tensor(0.0025)\n",
      "ols mse:  tensor(0.4587)\n",
      "gt params:  tensor([-0.9530, -0.9782,  0.9240,  0.7837, -0.4456, -0.3096])\n",
      "0 steps | score: [0.2093012034893036]\n",
      "100 steps | score: [0.09837089478969574]\n",
      "200 steps | score: [0.05661257728934288]\n",
      "300 steps | score: [0.11373859643936157]\n",
      "400 steps | score: [0.05680015683174133]\n",
      "500 steps | score: [0.08802066743373871]\n",
      "600 steps | score: [-0.0018340246751904488]\n",
      "0 steps | score: [0.2780895233154297, -0.33869633078575134]\n",
      "100 steps | score: [0.3641452193260193, -0.9603496789932251]\n",
      "200 steps | score: [0.46629002690315247, -1.6061543226242065]\n",
      "300 steps | score: [0.4245166480541229, -1.4673728942871094]\n",
      "400 steps | score: [0.21651950478553772, -0.619306743144989]\n",
      "500 steps | score: [0.14309285581111908, -0.27288663387298584]\n",
      "600 steps | score: [-0.12474191188812256, 0.6290578842163086]\n",
      "700 steps | score: [0.1311115026473999, -0.36315906047821045]\n",
      "800 steps | score: [-0.0017204786418005824, 0.1298108994960785]\n",
      "900 steps | score: [-0.11314636468887329, 0.5107584595680237]\n",
      "1000 steps | score: [0.06542602181434631, -0.05825847387313843]\n",
      "1100 steps | score: [0.3853680193424225, -1.239533543586731]\n",
      "1200 steps | score: [0.23846855759620667, -0.6921283602714539]\n",
      "1300 steps | score: [0.026465214788913727, 0.09578125178813934]\n",
      "1400 steps | score: [0.21605542302131653, -0.6237821578979492]\n",
      "1500 steps | score: [0.14957912266254425, -0.38268396258354187]\n",
      "1600 steps | score: [0.14950117468833923, -0.36118024587631226]\n",
      "1700 steps | score: [0.292197048664093, -0.8708767294883728]\n",
      "1800 steps | score: [0.3154054880142212, -0.9245188236236572]\n",
      "1900 steps | score: [0.05357182398438454, -0.0020086467266082764]\n",
      "2000 steps | score: [0.11994389444589615, -0.21690312027931213]\n",
      "2100 steps | score: [0.12863582372665405, -0.3061016798019409]\n",
      "2200 steps | score: [0.2161700278520584, -0.6149670481681824]\n",
      "2300 steps | score: [0.1480274200439453, -0.3978654444217682]\n",
      "2400 steps | score: [0.09629452228546143, -0.2023126482963562]\n",
      "2500 steps | score: [0.12203013896942139, -0.3238862454891205]\n",
      "2600 steps | score: [0.13853111863136292, -0.34688693284988403]\n",
      "2700 steps | score: [0.10557019710540771, -0.25861573219299316]\n",
      "2800 steps | score: [0.0657060518860817, -0.08199569582939148]\n",
      "unknown params:  tensor([-0.9598, -0.9859,  0.9270,  0.7836, -0.4491, -0.2773])\n",
      "gt params:  tensor([-0.9530, -0.9782,  0.9240,  0.7837, -0.4456, -0.3096])\n",
      "ols params:  tensor([-0.7316, -0.7467,  0.7050,  0.6047, -0.3447,  1.4949])\n",
      "unknown mse:  tensor(0.0002)\n",
      "ols mse:  tensor(0.5749)\n",
      "gt params:  tensor([-0.9696, -0.9891,  0.9140,  0.7849, -0.4400, -0.3013])\n",
      "0 steps | score: [0.252751886844635]\n",
      "100 steps | score: [0.19224892556667328]\n",
      "200 steps | score: [0.09031730890274048]\n",
      "300 steps | score: [0.04845026880502701]\n",
      "400 steps | score: [0.06063539534807205]\n",
      "500 steps | score: [0.1844693273305893]\n",
      "600 steps | score: [0.10076545923948288]\n",
      "700 steps | score: [0.208921879529953]\n",
      "800 steps | score: [0.07335174828767776]\n",
      "900 steps | score: [0.08889082074165344]\n",
      "1000 steps | score: [0.11496084928512573]\n",
      "1100 steps | score: [0.06750468164682388]\n",
      "1200 steps | score: [0.10906721651554108]\n",
      "1300 steps | score: [0.05418387055397034]\n",
      "1400 steps | score: [0.1272529661655426]\n",
      "1500 steps | score: [0.1445431113243103]\n",
      "1600 steps | score: [0.10941105335950851]\n",
      "1700 steps | score: [0.12926042079925537]\n",
      "1800 steps | score: [0.08739307522773743]\n",
      "1900 steps | score: [0.11466214805841446]\n",
      "2000 steps | score: [0.1338731348514557]\n",
      "2100 steps | score: [0.10628066956996918]\n",
      "2200 steps | score: [0.08225452899932861]\n",
      "2300 steps | score: [0.101414754986763]\n",
      "2400 steps | score: [0.13188017904758453]\n",
      "2500 steps | score: [0.12693002820014954]\n",
      "2600 steps | score: [0.1334913671016693]\n",
      "2700 steps | score: [0.09085725992918015]\n",
      "2800 steps | score: [0.08668048679828644]\n",
      "0 steps | score: [0.16878120601177216, 0.030675843358039856]\n",
      "100 steps | score: [-0.09228653460741043, 0.6215677857398987]\n",
      "200 steps | score: [-0.07540173083543777, 0.43369826674461365]\n",
      "300 steps | score: [0.33815184235572815, -1.09523606300354]\n",
      "400 steps | score: [0.2316836714744568, -0.6081005334854126]\n",
      "500 steps | score: [0.012836317531764507, 0.1981501281261444]\n",
      "600 steps | score: [-0.05678664892911911, 0.3492606282234192]\n",
      "700 steps | score: [0.15917867422103882, -0.39440226554870605]\n",
      "800 steps | score: [0.13674870133399963, -0.44289594888687134]\n",
      "900 steps | score: [-0.12419550120830536, 0.5805007219314575]\n",
      "1000 steps | score: [0.1535855233669281, -0.31054380536079407]\n",
      "1100 steps | score: [-0.06763432919979095, 0.37661808729171753]\n",
      "1200 steps | score: [0.14818175137043, -0.35358554124832153]\n",
      "1300 steps | score: [-0.10995223373174667, 0.5283961892127991]\n",
      "1400 steps | score: [0.15930664539337158, -0.4050114154815674]\n",
      "1500 steps | score: [0.11353959143161774, -0.22532755136489868]\n",
      "1600 steps | score: [0.10752369463443756, -0.24139025807380676]\n",
      "1700 steps | score: [-0.026085080578923225, 0.2354092001914978]\n",
      "1800 steps | score: [-0.01869862899184227, 0.20581971108913422]\n",
      "1900 steps | score: [0.1971779465675354, -0.5576425790786743]\n",
      "2000 steps | score: [0.13034147024154663, -0.2771376073360443]\n",
      "2100 steps | score: [0.024826588109135628, 0.03526027500629425]\n",
      "2200 steps | score: [-0.030968209728598595, 0.2590204179286957]\n",
      "2300 steps | score: [0.0030763496179133654, 0.14980179071426392]\n",
      "2400 steps | score: [0.13340124487876892, -0.3198179602622986]\n",
      "2500 steps | score: [0.03906319662928581, 0.002570927143096924]\n",
      "2600 steps | score: [0.20510531961917877, -0.6019964218139648]\n",
      "2700 steps | score: [0.015665384009480476, 0.10429857671260834]\n",
      "2800 steps | score: [-0.02290906012058258, 0.2281327247619629]\n",
      "unknown params:  tensor([-1.0028, -1.0143,  0.9302,  0.8112, -0.4616, -0.2046])\n",
      "gt params:  tensor([-0.9696, -0.9891,  0.9140,  0.7849, -0.4400, -0.3013])\n",
      "ols params:  tensor([-0.7139, -0.7174,  0.6698,  0.5821, -0.3340,  1.7340])\n",
      "unknown mse:  tensor(0.0021)\n",
      "ols mse:  tensor(0.7323)\n",
      "gt params:  tensor([-0.9654, -0.9840,  0.8964,  0.7889, -0.4577, -0.3072])\n",
      "0 steps | score: [-0.03982581943273544]\n",
      "100 steps | score: [-0.1496686041355133]\n",
      "200 steps | score: [-0.2095998376607895]\n",
      "300 steps | score: [-0.270489901304245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 steps | score: [-0.31070923805236816]\n",
      "500 steps | score: [-0.22553278505802155]\n",
      "600 steps | score: [-0.23146356642246246]\n",
      "700 steps | score: [-0.20924033224582672]\n",
      "800 steps | score: [-0.20906050503253937]\n",
      "900 steps | score: [-0.21931125223636627]\n",
      "1000 steps | score: [-0.1851348727941513]\n",
      "1100 steps | score: [-0.2230284959077835]\n",
      "1200 steps | score: [-0.23021693527698517]\n",
      "1300 steps | score: [-0.20566746592521667]\n",
      "1400 steps | score: [-0.2560948133468628]\n",
      "1500 steps | score: [-0.23122785985469818]\n",
      "1600 steps | score: [-0.21411123871803284]\n",
      "1700 steps | score: [-0.19965192675590515]\n",
      "1800 steps | score: [-0.22630657255649567]\n",
      "1900 steps | score: [-0.2686234414577484]\n",
      "2000 steps | score: [-0.22885538637638092]\n",
      "2100 steps | score: [-0.2082437127828598]\n",
      "2200 steps | score: [-0.2453918755054474]\n",
      "2300 steps | score: [-0.23022425174713135]\n",
      "2400 steps | score: [-0.22673630714416504]\n",
      "2500 steps | score: [-0.2088042050600052]\n",
      "2600 steps | score: [-0.18081121146678925]\n",
      "2700 steps | score: [-0.23618552088737488]\n",
      "2800 steps | score: [-0.2149781435728073]\n",
      "0 steps | score: [0.13867421448230743, 0.02367916889488697]\n",
      "100 steps | score: [-0.15149427950382233, 0.5735162496566772]\n",
      "200 steps | score: [-0.158765509724617, 0.4964761734008789]\n",
      "300 steps | score: [-0.09248040616512299, 0.31982749700546265]\n",
      "400 steps | score: [-0.1833960860967636, 0.5667446851730347]\n",
      "500 steps | score: [-0.0355718769133091, 0.10671569406986237]\n",
      "600 steps | score: [-0.20279249548912048, 0.6326080560684204]\n",
      "700 steps | score: [-0.03856273368000984, 0.1967550814151764]\n",
      "800 steps | score: [0.2137809693813324, -0.7285151481628418]\n",
      "900 steps | score: [-0.02001454308629036, 0.033514153212308884]\n",
      "1000 steps | score: [0.024512602016329765, -0.053310249000787735]\n",
      "1100 steps | score: [-0.011173480190336704, 0.04809129610657692]\n",
      "1200 steps | score: [-0.11732516437768936, 0.3807452321052551]\n",
      "1300 steps | score: [0.2077120691537857, -0.6767681837081909]\n",
      "1400 steps | score: [-0.17047061026096344, 0.48214054107666016]\n",
      "1500 steps | score: [-0.10055287927389145, 0.300275593996048]\n",
      "1600 steps | score: [-0.09992042183876038, 0.3045019209384918]\n",
      "1700 steps | score: [-0.00961157027631998, 0.03693709522485733]\n",
      "1800 steps | score: [-0.07589000463485718, 0.24921882152557373]\n",
      "1900 steps | score: [-0.14013834297657013, 0.4003809690475464]\n",
      "2000 steps | score: [0.008913499303162098, -0.04055482894182205]\n",
      "2100 steps | score: [-0.0428285226225853, 0.1148993968963623]\n",
      "2200 steps | score: [-0.06044755131006241, 0.15931524336338043]\n",
      "2300 steps | score: [-0.03540708124637604, 0.07923012226819992]\n",
      "2400 steps | score: [-0.034372083842754364, 0.06912508606910706]\n",
      "2500 steps | score: [-0.04736312851309776, 0.1252327263355255]\n",
      "2600 steps | score: [-0.04807780310511589, 0.12131825089454651]\n",
      "2700 steps | score: [-0.055503860116004944, 0.1442369669675827]\n",
      "2800 steps | score: [-0.017819492146372795, 0.04706638678908348]\n",
      "unknown params:  tensor([-0.9636, -0.9905,  0.8620,  0.7986, -0.4634, -0.2197])\n",
      "gt params:  tensor([-0.9654, -0.9840,  0.8964,  0.7889, -0.4577, -0.3072])\n",
      "ols params:  tensor([-0.6942, -0.7100,  0.6259,  0.5755, -0.3358,  1.8849])\n",
      "unknown mse:  tensor(0.0015)\n",
      "ols mse:  tensor(0.8479)\n",
      "gt params:  tensor([-0.9524, -0.9829,  0.9097,  0.8003, -0.4681, -0.2862])\n",
      "0 steps | score: [-0.016809679567813873]\n",
      "100 steps | score: [-0.22926975786685944]\n",
      "200 steps | score: [-0.27548980712890625]\n",
      "300 steps | score: [-0.17762325704097748]\n",
      "400 steps | score: [-0.1294439435005188]\n",
      "500 steps | score: [-0.11196557432413101]\n",
      "600 steps | score: [-0.19414366781711578]\n",
      "700 steps | score: [-0.18001867830753326]\n",
      "800 steps | score: [-0.22099906206130981]\n",
      "900 steps | score: [-0.1884644776582718]\n",
      "1000 steps | score: [-0.14197753369808197]\n",
      "1100 steps | score: [-0.16994677484035492]\n",
      "1200 steps | score: [-0.20028044283390045]\n",
      "1300 steps | score: [-0.21876180171966553]\n",
      "1400 steps | score: [-0.18766523897647858]\n",
      "1500 steps | score: [-0.19147838652133942]\n",
      "1600 steps | score: [-0.19095733761787415]\n",
      "1700 steps | score: [-0.1862570196390152]\n",
      "1800 steps | score: [-0.2298050820827484]\n",
      "1900 steps | score: [-0.20265492796897888]\n",
      "2000 steps | score: [-0.20128785073757172]\n",
      "2100 steps | score: [-0.19614911079406738]\n",
      "2200 steps | score: [-0.21562090516090393]\n",
      "2300 steps | score: [-0.21555155515670776]\n",
      "2400 steps | score: [-0.17713618278503418]\n",
      "2500 steps | score: [-0.2148628532886505]\n",
      "2600 steps | score: [-0.20442508161067963]\n",
      "2700 steps | score: [-0.17913617193698883]\n",
      "2800 steps | score: [-0.21799644827842712]\n",
      "0 steps | score: [0.1715625673532486, -0.09784234315156937]\n",
      "100 steps | score: [0.17487733066082, -0.38299480080604553]\n",
      "200 steps | score: [-0.10536539554595947, 0.36896926164627075]\n",
      "300 steps | score: [0.18706807494163513, -0.46948209404945374]\n",
      "400 steps | score: [0.29154083132743835, -0.8044478297233582]\n",
      "500 steps | score: [0.20894522964954376, -0.5990905165672302]\n",
      "600 steps | score: [-0.09309259057044983, 0.27989864349365234]\n",
      "700 steps | score: [0.13165532052516937, -0.36241117119789124]\n",
      "800 steps | score: [0.005580587778240442, 0.014206983149051666]\n",
      "900 steps | score: [-0.014216313138604164, 0.10457008332014084]\n",
      "1000 steps | score: [0.14812174439430237, -0.37175261974334717]\n",
      "1100 steps | score: [0.06012064218521118, -0.16809168457984924]\n",
      "1200 steps | score: [-0.06257955729961395, 0.1934375762939453]\n",
      "1300 steps | score: [0.05094446986913681, -0.09562777727842331]\n",
      "1400 steps | score: [-0.03830192983150482, 0.13204964995384216]\n",
      "1500 steps | score: [0.006100165657699108, 0.008450061082839966]\n",
      "unknown params:  tensor([-0.9314, -0.9500,  0.9042,  0.7926, -0.4796, -0.2269])\n",
      "gt params:  tensor([-0.9524, -0.9829,  0.9097,  0.8003, -0.4681, -0.2862])\n",
      "ols params:  tensor([-0.6420, -0.6531,  0.6244,  0.5541, -0.3326,  2.1584])\n",
      "unknown mse:  tensor(0.0009)\n",
      "ols mse:  tensor(1.0569)\n",
      "gt params:  tensor([-0.9622, -0.9684,  0.9190,  0.7742, -0.4457, -0.3052])\n",
      "0 steps | score: [0.25054529309272766]\n",
      "100 steps | score: [0.12789931893348694]\n",
      "200 steps | score: [0.05069776624441147]\n",
      "300 steps | score: [0.04728836938738823]\n",
      "400 steps | score: [0.01723399944603443]\n",
      "500 steps | score: [0.017010027542710304]\n",
      "600 steps | score: [0.13188159465789795]\n",
      "700 steps | score: [0.11262434720993042]\n",
      "800 steps | score: [0.001609109342098236]\n",
      "0 steps | score: [0.08950218558311462, -0.039377711713314056]\n",
      "100 steps | score: [-0.20641611516475677, 0.5323061347007751]\n",
      "200 steps | score: [-0.0469302162528038, 0.022884249687194824]\n",
      "300 steps | score: [-0.21783746778964996, 0.40080663561820984]\n",
      "400 steps | score: [-0.110243059694767, 0.15135736763477325]\n",
      "500 steps | score: [-0.07672490924596786, 0.06206359714269638]\n",
      "600 steps | score: [-0.19154900312423706, 0.36218637228012085]\n",
      "700 steps | score: [-0.11310629546642303, 0.14215481281280518]\n",
      "800 steps | score: [-0.1703309416770935, 0.2948859930038452]\n",
      "900 steps | score: [-0.007527580950409174, -0.1216617077589035]\n",
      "1000 steps | score: [0.07242994010448456, -0.41551733016967773]\n",
      "1100 steps | score: [-0.10575028508901596, 0.12487613409757614]\n",
      "1200 steps | score: [-0.17424121499061584, 0.276006281375885]\n",
      "1300 steps | score: [-0.1896923929452896, 0.3565148115158081]\n",
      "1400 steps | score: [0.0192958265542984, -0.21806588768959045]\n",
      "1500 steps | score: [-0.11597487330436707, 0.1272893249988556]\n",
      "1600 steps | score: [0.018372585996985435, -0.22988063097000122]\n",
      "1700 steps | score: [-0.1898343861103058, 0.3126908540725708]\n",
      "1800 steps | score: [-0.19455137848854065, 0.4026890695095062]\n",
      "1900 steps | score: [-0.07203960418701172, 0.04321376979351044]\n",
      "2000 steps | score: [-0.05881042405962944, -0.00942021980881691]\n",
      "2100 steps | score: [-0.03365124389529228, -0.056324828416109085]\n",
      "2200 steps | score: [-0.0992918461561203, 0.10270730406045914]\n",
      "2300 steps | score: [-0.13616855442523956, 0.21384969353675842]\n",
      "2400 steps | score: [-0.15633976459503174, 0.24900010228157043]\n",
      "2500 steps | score: [-0.12114012986421585, 0.13819769024848938]\n",
      "2600 steps | score: [-0.06756668537855148, 0.010880909860134125]\n",
      "2700 steps | score: [-0.11096654832363129, 0.07589322328567505]\n",
      "2800 steps | score: [-0.09265349805355072, 0.09598430246114731]\n",
      "unknown params:  tensor([-0.9754, -0.9731,  0.9241,  0.7744, -0.4574, -0.2050])\n",
      "gt params:  tensor([-0.9622, -0.9684,  0.9190,  0.7742, -0.4457, -0.3052])\n",
      "ols params:  tensor([-0.6494, -0.6408,  0.6180,  0.5194, -0.3036,  2.2991])\n",
      "unknown mse:  tensor(0.0017)\n",
      "ols mse:  tensor(1.1939)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt params:  tensor([-0.9434, -0.9871,  0.9002,  0.7958, -0.4467, -0.2766])\n",
      "0 steps | score: [-0.09389717131853104]\n",
      "100 steps | score: [-0.25303226709365845]\n",
      "200 steps | score: [-0.2622428834438324]\n",
      "300 steps | score: [-0.28529447317123413]\n",
      "400 steps | score: [-0.33188337087631226]\n",
      "500 steps | score: [-0.29061803221702576]\n",
      "600 steps | score: [-0.2549353539943695]\n",
      "700 steps | score: [-0.340344101190567]\n",
      "800 steps | score: [-0.3231605291366577]\n",
      "900 steps | score: [-0.3016374707221985]\n",
      "1000 steps | score: [-0.2756235599517822]\n",
      "1100 steps | score: [-0.30035844445228577]\n",
      "1200 steps | score: [-0.326508104801178]\n",
      "1300 steps | score: [-0.285338819026947]\n",
      "1400 steps | score: [-0.31723740696907043]\n",
      "1500 steps | score: [-0.30357423424720764]\n",
      "1600 steps | score: [-0.29888254404067993]\n",
      "1700 steps | score: [-0.30440402030944824]\n",
      "1800 steps | score: [-0.3263043165206909]\n",
      "1900 steps | score: [-0.33123624324798584]\n",
      "2000 steps | score: [-0.3265708386898041]\n",
      "2100 steps | score: [-0.2756311297416687]\n",
      "2200 steps | score: [-0.2925192415714264]\n",
      "2300 steps | score: [-0.3370242118835449]\n",
      "2400 steps | score: [-0.32334381341934204]\n",
      "2500 steps | score: [-0.31394532322883606]\n",
      "2600 steps | score: [-0.29134854674339294]\n",
      "2700 steps | score: [-0.2814159095287323]\n",
      "2800 steps | score: [-0.28489261865615845]\n",
      "2900 steps | score: [-0.3186487555503845]\n",
      "0 steps | score: [0.11572575569152832, -0.24501070380210876]\n",
      "100 steps | score: [-0.13217106461524963, 0.18083322048187256]\n",
      "200 steps | score: [0.2812804877758026, -0.9982693195343018]\n",
      "300 steps | score: [0.6017290949821472, -2.1164681911468506]\n",
      "400 steps | score: [-0.1602976769208908, 0.16458499431610107]\n",
      "500 steps | score: [-0.14211232960224152, 0.17558255791664124]\n",
      "600 steps | score: [-0.16024817526340485, 0.18293052911758423]\n",
      "700 steps | score: [-0.2195316106081009, 0.3651326894760132]\n",
      "800 steps | score: [-0.1309574544429779, 0.10830619931221008]\n",
      "900 steps | score: [-0.09634668380022049, 0.013259321451187134]\n",
      "1000 steps | score: [0.08149252086877823, -0.4894895553588867]\n",
      "1100 steps | score: [-0.07977671921253204, -0.022847160696983337]\n",
      "1200 steps | score: [0.14537030458450317, -0.6590592861175537]\n",
      "1300 steps | score: [0.09335500001907349, -0.5243480801582336]\n",
      "1400 steps | score: [0.006586796138435602, -0.28753596544265747]\n",
      "1500 steps | score: [-0.2147628664970398, 0.2794906497001648]\n",
      "1600 steps | score: [-0.0735778659582138, -0.078682079911232]\n",
      "1700 steps | score: [0.005464922171086073, -0.24389106035232544]\n",
      "1800 steps | score: [-0.131845623254776, 0.11652418971061707]\n",
      "1900 steps | score: [-0.07456439733505249, -0.06653033196926117]\n",
      "2000 steps | score: [-0.11689765751361847, 0.056786030530929565]\n",
      "2100 steps | score: [-0.030977291986346245, -0.16902399063110352]\n",
      "2200 steps | score: [0.10315027832984924, -0.564141035079956]\n",
      "2300 steps | score: [-0.11927253007888794, 0.09748160094022751]\n",
      "2400 steps | score: [-0.07859397679567337, -0.05766063928604126]\n",
      "2500 steps | score: [0.07447906583547592, -0.5136935710906982]\n",
      "2600 steps | score: [0.030238648876547813, -0.36711835861206055]\n",
      "2700 steps | score: [-0.05224662646651268, -0.13153746724128723]\n",
      "2800 steps | score: [-0.07610825449228287, -0.006800249218940735]\n",
      "2900 steps | score: [-0.07669011503458023, -0.05360967665910721]\n",
      "unknown params:  tensor([-0.9746, -0.9956,  0.9022,  0.8045, -0.4901, -0.1100])\n",
      "gt params:  tensor([-0.9434, -0.9871,  0.9002,  0.7958, -0.4467, -0.2766])\n",
      "ols params:  tensor([-0.6073, -0.6287,  0.5764,  0.5077, -0.3073,  2.4695])\n",
      "unknown mse:  tensor(0.0051)\n",
      "ols mse:  tensor(1.3316)\n",
      "gt params:  tensor([-0.9536, -0.9685,  0.9032,  0.8072, -0.4334, -0.2867])\n",
      "0 steps | score: [0.3263263702392578]\n",
      "100 steps | score: [0.07174018770456314]\n",
      "200 steps | score: [0.06831866502761841]\n",
      "300 steps | score: [0.15756827592849731]\n",
      "400 steps | score: [0.03219781816005707]\n",
      "500 steps | score: [0.10706596076488495]\n",
      "600 steps | score: [0.05183788388967514]\n",
      "700 steps | score: [0.08775278925895691]\n",
      "800 steps | score: [0.0853385180234909]\n",
      "900 steps | score: [0.018346969038248062]\n",
      "1000 steps | score: [0.10669363290071487]\n",
      "1100 steps | score: [0.08552540838718414]\n",
      "1200 steps | score: [0.08552713692188263]\n",
      "1300 steps | score: [0.10379402339458466]\n",
      "1400 steps | score: [0.032013677060604095]\n",
      "1500 steps | score: [0.1099507212638855]\n",
      "1600 steps | score: [0.11431902647018433]\n",
      "1700 steps | score: [0.07025571912527084]\n",
      "1800 steps | score: [0.10519754886627197]\n",
      "1900 steps | score: [0.05402801185846329]\n",
      "2000 steps | score: [0.07716083526611328]\n",
      "2100 steps | score: [0.07136091589927673]\n",
      "2200 steps | score: [0.06250692158937454]\n",
      "2300 steps | score: [0.08700048923492432]\n",
      "2400 steps | score: [0.062019653618335724]\n",
      "2500 steps | score: [0.06593047082424164]\n",
      "2600 steps | score: [0.056104350835084915]\n",
      "2700 steps | score: [0.06918507814407349]\n",
      "2800 steps | score: [0.08485199511051178]\n",
      "0 steps | score: [0.09446249157190323, 0.02025531604886055]\n",
      "100 steps | score: [-0.12662342190742493, 0.3867502212524414]\n",
      "200 steps | score: [0.11442135274410248, -0.3420286774635315]\n",
      "300 steps | score: [0.2583286464214325, -0.8132505416870117]\n",
      "400 steps | score: [-0.027575340121984482, 0.050941210240125656]\n",
      "500 steps | score: [0.1936625838279724, -0.5624245405197144]\n",
      "600 steps | score: [-0.28508666157722473, 0.7013311982154846]\n",
      "700 steps | score: [-0.04033864289522171, 0.043414004147052765]\n",
      "800 steps | score: [-0.06936091929674149, 0.17228581011295319]\n",
      "900 steps | score: [-0.055209897458553314, 0.11152368038892746]\n",
      "1000 steps | score: [0.22489674389362335, -0.7595207691192627]\n",
      "1100 steps | score: [-0.04972783848643303, 0.06308890879154205]\n",
      "1200 steps | score: [-0.03536485135555267, 0.03849116712808609]\n",
      "1300 steps | score: [-0.04802146181464195, 0.04584541916847229]\n",
      "1400 steps | score: [-0.15258793532848358, 0.36558595299720764]\n",
      "1500 steps | score: [-0.12600800395011902, 0.2679187059402466]\n",
      "1600 steps | score: [-0.02388382889330387, -0.049214933067560196]\n",
      "1700 steps | score: [-0.061911921948194504, 0.11537609249353409]\n",
      "1800 steps | score: [0.013008049689233303, -0.07330843806266785]\n",
      "1900 steps | score: [-0.03934289142489433, 0.05058152973651886]\n",
      "2000 steps | score: [-0.11618005484342575, 0.238128662109375]\n",
      "2100 steps | score: [-0.12586678564548492, 0.2711329162120819]\n",
      "2200 steps | score: [-0.06984207779169083, 0.1271144300699234]\n",
      "2300 steps | score: [-0.16286073625087738, 0.34579381346702576]\n",
      "2400 steps | score: [-0.13153941929340363, 0.32268041372299194]\n",
      "2500 steps | score: [-0.13947761058807373, 0.27073904871940613]\n",
      "2600 steps | score: [-0.09563849121332169, 0.2087465524673462]\n",
      "2700 steps | score: [-0.08793933689594269, 0.17586515843868256]\n",
      "2800 steps | score: [-0.14698442816734314, 0.32989466190338135]\n",
      "unknown params:  tensor([-0.8955, -0.9247,  0.8466,  0.7295, -0.4009, -0.0197])\n",
      "gt params:  tensor([-0.9536, -0.9685,  0.9032,  0.8072, -0.4334, -0.2867])\n",
      "ols params:  tensor([-0.5966, -0.6166,  0.5692,  0.4926, -0.2715,  2.6467])\n",
      "unknown mse:  tensor(0.0145)\n",
      "ols mse:  tensor(1.5155)\n",
      "gt params:  tensor([-0.9660, -0.9835,  0.9209,  0.8284, -0.4573, -0.2597])\n",
      "0 steps | score: [0.17769524455070496]\n",
      "100 steps | score: [0.032073602080345154]\n",
      "200 steps | score: [-0.036089349538087845]\n",
      "300 steps | score: [-0.10201746970415115]\n",
      "400 steps | score: [-0.013625264167785645]\n",
      "500 steps | score: [-0.022989589720964432]\n",
      "600 steps | score: [-0.07493747770786285]\n",
      "700 steps | score: [-0.08597102016210556]\n",
      "800 steps | score: [-0.07541298866271973]\n",
      "900 steps | score: [-0.04374194145202637]\n",
      "1000 steps | score: [0.01065150648355484]\n",
      "1100 steps | score: [-0.07640007138252258]\n",
      "1200 steps | score: [-0.01584669202566147]\n",
      "1300 steps | score: [-0.04610135406255722]\n",
      "1400 steps | score: [-0.009197626262903214]\n",
      "0 steps | score: [0.26913708448410034, -0.22638341784477234]\n",
      "100 steps | score: [0.3563631474971771, -0.6535854339599609]\n",
      "200 steps | score: [-0.010174370370805264, 0.19638392329216003]\n",
      "300 steps | score: [-0.09227336198091507, 0.401494562625885]\n",
      "400 steps | score: [0.17012706398963928, -0.1925971359014511]\n",
      "500 steps | score: [-0.04267782345414162, 0.2647572159767151]\n",
      "600 steps | score: [0.07201693952083588, 0.005538418889045715]\n",
      "700 steps | score: [-0.1709309071302414, 0.5396312475204468]\n",
      "800 steps | score: [0.19821304082870483, -0.3504451513290405]\n",
      "900 steps | score: [0.1674443483352661, -0.26705819368362427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 steps | score: [0.2505079209804535, -0.4983188509941101]\n",
      "1100 steps | score: [0.1279723346233368, -0.16138090193271637]\n",
      "1200 steps | score: [0.25493577122688293, -0.5056037306785583]\n",
      "1300 steps | score: [0.12021743506193161, -0.15902087092399597]\n",
      "1400 steps | score: [0.2953665852546692, -0.6815047860145569]\n",
      "1500 steps | score: [0.1937679648399353, -0.2691054344177246]\n",
      "1600 steps | score: [0.3240984380245209, -0.7274237871170044]\n",
      "1700 steps | score: [0.06101885065436363, 0.021739289164543152]\n",
      "1800 steps | score: [0.12648139894008636, -0.1460641622543335]\n",
      "1900 steps | score: [0.13899284601211548, -0.19064421951770782]\n",
      "2000 steps | score: [0.1226997822523117, -0.18167629837989807]\n",
      "2100 steps | score: [0.0924609899520874, -0.06788961589336395]\n",
      "2200 steps | score: [0.023368190973997116, 0.10838644206523895]\n",
      "2300 steps | score: [0.07954569905996323, -0.02652004361152649]\n",
      "2400 steps | score: [0.12734732031822205, -0.16828516125679016]\n",
      "2500 steps | score: [-0.005992453079670668, 0.14267277717590332]\n",
      "2600 steps | score: [0.07027139514684677, -0.019065916538238525]\n",
      "2700 steps | score: [0.014143818989396095, 0.1197139099240303]\n",
      "2800 steps | score: [0.03168917074799538, 0.05385226756334305]\n",
      "unknown params:  tensor([-1.0305, -0.9911,  0.9663,  0.8530, -0.4645, -0.1516])\n",
      "gt params:  tensor([-0.9660, -0.9835,  0.9209,  0.8284, -0.4573, -0.2597])\n",
      "ols params:  tensor([-0.6427, -0.6136,  0.6061,  0.5307, -0.2927,  2.7010])\n",
      "unknown mse:  tensor(0.0031)\n",
      "ols mse:  tensor(1.5370)\n",
      "gt params:  tensor([-0.9644, -0.9745,  0.9227,  0.8170, -0.4677, -0.3008])\n",
      "0 steps | score: [0.2274005115032196]\n",
      "100 steps | score: [0.06501087546348572]\n",
      "200 steps | score: [0.028432462364435196]\n",
      "300 steps | score: [-0.03720768541097641]\n",
      "400 steps | score: [0.01835143193602562]\n",
      "500 steps | score: [0.07420387864112854]\n",
      "600 steps | score: [0.01069498062133789]\n",
      "700 steps | score: [-0.025846488773822784]\n",
      "800 steps | score: [-0.05623500049114227]\n",
      "900 steps | score: [-0.01620517298579216]\n",
      "1000 steps | score: [0.02290036529302597]\n",
      "1100 steps | score: [0.004117738455533981]\n",
      "0 steps | score: [0.26890966296195984, -0.2000635713338852]\n",
      "100 steps | score: [0.3686474859714508, -0.6272574663162231]\n",
      "200 steps | score: [0.19221770763397217, -0.21797171235084534]\n",
      "300 steps | score: [-0.21327686309814453, 0.661309003829956]\n",
      "400 steps | score: [0.19723691046237946, -0.29258665442466736]\n",
      "500 steps | score: [0.6627933979034424, -1.7052456140518188]\n",
      "600 steps | score: [0.08813993632793427, -0.012838728725910187]\n",
      "700 steps | score: [0.1054898351430893, -0.07440902292728424]\n",
      "800 steps | score: [0.13310492038726807, -0.13904622197151184]\n",
      "900 steps | score: [0.15862707793712616, -0.2503427267074585]\n",
      "1000 steps | score: [0.11863581091165543, -0.13512441515922546]\n",
      "1100 steps | score: [-0.042012449353933334, 0.2938649654388428]\n",
      "1200 steps | score: [0.17994609475135803, -0.2999676465988159]\n",
      "1300 steps | score: [0.15345342457294464, -0.18721531331539154]\n",
      "1400 steps | score: [0.12089937925338745, -0.1504300981760025]\n",
      "1500 steps | score: [-0.003586381208151579, 0.13950036466121674]\n",
      "1600 steps | score: [-0.03300458937883377, 0.25060707330703735]\n",
      "1700 steps | score: [0.11759635806083679, -0.14239469170570374]\n",
      "1800 steps | score: [0.15336692333221436, -0.18879082798957825]\n",
      "1900 steps | score: [0.062487415969371796, 0.009442046284675598]\n",
      "2000 steps | score: [0.11652974784374237, -0.07946181297302246]\n",
      "2100 steps | score: [0.1309172511100769, -0.13488924503326416]\n",
      "2200 steps | score: [0.06718941032886505, -0.014870241284370422]\n",
      "2300 steps | score: [0.10098346322774887, -0.07312533259391785]\n",
      "2400 steps | score: [0.12683002650737762, -0.14955002069473267]\n",
      "2500 steps | score: [0.12545089423656464, -0.1329532414674759]\n",
      "2600 steps | score: [0.09503740817308426, -0.0324145182967186]\n",
      "2700 steps | score: [-0.00018375032232142985, 0.16325658559799194]\n",
      "2800 steps | score: [0.08953475207090378, -0.05631895363330841]\n",
      "unknown params:  tensor([-0.9417, -0.9597,  0.8996,  0.8362, -0.4128,  0.0321])\n",
      "gt params:  tensor([-0.9644, -0.9745,  0.9227,  0.8170, -0.4677, -0.3008])\n",
      "ols params:  tensor([-0.5898, -0.5982,  0.5677,  0.5242, -0.2653,  2.9037])\n",
      "unknown mse:  tensor(0.0192)\n",
      "ols mse:  tensor(1.8005)\n",
      "gt params:  tensor([-0.9116, -0.9627,  0.9255,  0.7971, -0.4522, -0.3194])\n",
      "0 steps | score: [0.2616887092590332]\n",
      "100 steps | score: [0.028666045516729355]\n",
      "200 steps | score: [0.07349137961864471]\n",
      "300 steps | score: [0.0034555327147245407]\n",
      "0 steps | score: [0.17783057689666748, 0.060066111385822296]\n",
      "100 steps | score: [0.2701464891433716, -0.33837226033210754]\n",
      "200 steps | score: [0.22729460895061493, -0.3035998046398163]\n",
      "300 steps | score: [0.155315101146698, -0.19466042518615723]\n",
      "400 steps | score: [-0.09317154437303543, 0.44733738899230957]\n",
      "500 steps | score: [0.07723022252321243, 0.03954019770026207]\n",
      "600 steps | score: [-0.04172448813915253, 0.2781676948070526]\n",
      "700 steps | score: [-0.046371862292289734, 0.2936508059501648]\n",
      "800 steps | score: [0.20038582384586334, -0.2994118332862854]\n",
      "900 steps | score: [-0.054868150502443314, 0.34180721640586853]\n",
      "1000 steps | score: [0.009514335542917252, 0.19075167179107666]\n",
      "1100 steps | score: [0.06861654669046402, -0.030521243810653687]\n",
      "1200 steps | score: [-0.08322057873010635, 0.3373376131057739]\n",
      "1300 steps | score: [0.14270639419555664, -0.15871918201446533]\n",
      "1400 steps | score: [0.07955280691385269, -0.01830465719103813]\n",
      "1500 steps | score: [-0.062044497579336166, 0.3454780876636505]\n",
      "1600 steps | score: [0.00801199208945036, 0.17925754189491272]\n",
      "1700 steps | score: [-0.08586553484201431, 0.37448129057884216]\n",
      "1800 steps | score: [0.01152961328625679, 0.11000770330429077]\n",
      "1900 steps | score: [-0.031669724732637405, 0.2640702426433563]\n",
      "2000 steps | score: [-0.011181832291185856, 0.2453605979681015]\n",
      "2100 steps | score: [0.016345832496881485, 0.1534770131111145]\n",
      "2200 steps | score: [-0.04858636483550072, 0.2989955544471741]\n",
      "2300 steps | score: [0.09212402254343033, -0.039102330803871155]\n",
      "2400 steps | score: [0.006430767010897398, 0.18842971324920654]\n",
      "2500 steps | score: [-0.03975038602948189, 0.24734680354595184]\n",
      "2600 steps | score: [-0.020194169133901596, 0.23548291623592377]\n",
      "2700 steps | score: [-0.01083031203597784, 0.219380185008049]\n",
      "2800 steps | score: [-0.01764322817325592, 0.20399512350559235]\n",
      "unknown params:  tensor([-0.9069, -0.9547,  0.9218,  0.7505, -0.4644, -0.0639])\n",
      "gt params:  tensor([-0.9116, -0.9627,  0.9255,  0.7971, -0.4522, -0.3194])\n",
      "ols params:  tensor([-0.5520, -0.5802,  0.5626,  0.4714, -0.2852,  2.9703])\n",
      "unknown mse:  tensor(0.0113)\n",
      "ols mse:  tensor(1.8939)\n",
      "gt params:  tensor([-0.9492, -0.9627,  0.9032,  0.7984, -0.4648, -0.3509])\n",
      "0 steps | score: [0.412153035402298]\n",
      "100 steps | score: [0.25499284267425537]\n",
      "200 steps | score: [0.0604008287191391]\n",
      "300 steps | score: [0.19141872227191925]\n",
      "400 steps | score: [0.20069581270217896]\n",
      "500 steps | score: [0.18607348203659058]\n",
      "600 steps | score: [0.14350946247577667]\n",
      "700 steps | score: [0.14770931005477905]\n",
      "800 steps | score: [0.1899433135986328]\n",
      "900 steps | score: [0.1999877244234085]\n",
      "1000 steps | score: [0.18135231733322144]\n",
      "1100 steps | score: [0.17684154212474823]\n",
      "1200 steps | score: [0.14887069165706635]\n",
      "1300 steps | score: [0.19915641844272614]\n",
      "1400 steps | score: [0.20549911260604858]\n",
      "1500 steps | score: [0.1929735392332077]\n",
      "1600 steps | score: [0.20269109308719635]\n",
      "1700 steps | score: [0.18957561254501343]\n",
      "1800 steps | score: [0.193937286734581]\n",
      "1900 steps | score: [0.18427366018295288]\n",
      "2000 steps | score: [0.20912639796733856]\n",
      "2100 steps | score: [0.17638225853443146]\n",
      "2200 steps | score: [0.17418532073497772]\n",
      "2300 steps | score: [0.1727440506219864]\n",
      "2400 steps | score: [0.16095378994941711]\n",
      "2500 steps | score: [0.19316503405570984]\n",
      "2600 steps | score: [0.17594191431999207]\n",
      "2700 steps | score: [0.1729218065738678]\n",
      "2800 steps | score: [0.1803974062204361]\n",
      "0 steps | score: [0.06719532608985901, -0.0022190622985363007]\n",
      "100 steps | score: [-0.058445438742637634, 0.1452212929725647]\n",
      "200 steps | score: [-0.3173218071460724, 0.7092981934547424]\n",
      "300 steps | score: [-0.2771490812301636, 0.5738087892532349]\n",
      "400 steps | score: [0.013218788430094719, -0.14981171488761902]\n",
      "500 steps | score: [0.20224536955356598, -0.7288556098937988]\n",
      "600 steps | score: [-0.33968299627304077, 0.7234716415405273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 steps | score: [0.09934413433074951, -0.44595426321029663]\n",
      "800 steps | score: [0.0911356583237648, -0.39288246631622314]\n",
      "900 steps | score: [0.06366145610809326, -0.29337117075920105]\n",
      "1000 steps | score: [-0.17015288770198822, 0.29881981015205383]\n",
      "1100 steps | score: [-0.08903881162405014, 0.13384433090686798]\n",
      "1200 steps | score: [-0.12099820375442505, 0.17577767372131348]\n",
      "1300 steps | score: [-0.11985268443822861, 0.15705052018165588]\n",
      "1400 steps | score: [0.08840565383434296, -0.38531258702278137]\n",
      "1500 steps | score: [0.07970470935106277, -0.3520621061325073]\n",
      "1600 steps | score: [-0.019172320142388344, -0.09885555505752563]\n",
      "1700 steps | score: [0.10924799740314484, -0.4308266043663025]\n",
      "1800 steps | score: [0.13381220400333405, -0.5153338313102722]\n",
      "1900 steps | score: [-0.12025054544210434, 0.17080429196357727]\n",
      "2000 steps | score: [-0.06963224709033966, 0.026566606014966965]\n",
      "2100 steps | score: [-0.15463906526565552, 0.27117544412612915]\n",
      "2200 steps | score: [-0.06146220117807388, 0.02498624660074711]\n",
      "2300 steps | score: [-0.0994325652718544, 0.11669080704450607]\n",
      "2400 steps | score: [-0.05464164912700653, 5.352869629859924e-05]\n",
      "2500 steps | score: [-0.01647138223052025, -0.08943089842796326]\n",
      "2600 steps | score: [-0.06326071172952652, 0.006915563717484474]\n",
      "2700 steps | score: [-0.034798502922058105, -0.020001748576760292]\n",
      "2800 steps | score: [-0.038045648485422134, -0.05523775517940521]\n",
      "unknown params:  tensor([-0.9810, -0.9420,  0.9287,  0.8011, -0.4830, -0.1025])\n",
      "gt params:  tensor([-0.9492, -0.9627,  0.9032,  0.7984, -0.4648, -0.3509])\n",
      "ols params:  tensor([-0.5804, -0.5571,  0.5530,  0.4764, -0.2910,  3.0987])\n",
      "unknown mse:  tensor(0.0107)\n",
      "ols mse:  tensor(2.0761)\n",
      "gt params:  tensor([-0.9405, -0.9740,  0.9054,  0.7745, -0.4476, -0.2918])\n",
      "0 steps | score: [0.30479392409324646]\n",
      "100 steps | score: [0.047527216374874115]\n",
      "200 steps | score: [0.04585474729537964]\n",
      "300 steps | score: [-0.04236776754260063]\n",
      "400 steps | score: [0.04292282834649086]\n",
      "500 steps | score: [0.09060588479042053]\n",
      "600 steps | score: [0.024208612740039825]\n",
      "700 steps | score: [-0.007966730743646622]\n",
      "0 steps | score: [0.22475896775722504, 0.039110422134399414]\n",
      "100 steps | score: [0.5243856310844421, -1.138450264930725]\n",
      "200 steps | score: [0.11941736191511154, 0.006330519914627075]\n",
      "300 steps | score: [0.09512319415807724, 0.027729429304599762]\n",
      "400 steps | score: [0.38578373193740845, -0.867355227470398]\n",
      "500 steps | score: [0.20409782230854034, -0.27193233370780945]\n",
      "600 steps | score: [0.4127272963523865, -1.0073699951171875]\n",
      "700 steps | score: [-0.06764309108257294, 0.45592132210731506]\n",
      "800 steps | score: [0.057733312249183655, 0.09866810590028763]\n",
      "900 steps | score: [0.11417923122644424, -0.009984172880649567]\n",
      "1000 steps | score: [0.13691851496696472, -0.13546152412891388]\n",
      "1100 steps | score: [-0.08417895436286926, 0.4449247717857361]\n",
      "1200 steps | score: [0.18068647384643555, -0.22036537528038025]\n",
      "1300 steps | score: [0.025980133563280106, 0.1971445232629776]\n",
      "1400 steps | score: [0.12023697048425674, -0.05864003300666809]\n",
      "1500 steps | score: [0.2177479863166809, -0.35749000310897827]\n",
      "1600 steps | score: [0.055214665830135345, 0.08128928393125534]\n",
      "1700 steps | score: [0.07383254915475845, 0.09684520959854126]\n",
      "1800 steps | score: [-0.10663712024688721, 0.5086814761161804]\n",
      "1900 steps | score: [0.06365480273962021, 0.09945493191480637]\n",
      "2000 steps | score: [0.15039800107479095, -0.16448259353637695]\n",
      "2100 steps | score: [0.07468067854642868, 0.032061509788036346]\n",
      "2200 steps | score: [-0.00725237000733614, 0.2579202651977539]\n",
      "2300 steps | score: [-0.04610643908381462, 0.37741076946258545]\n",
      "2400 steps | score: [0.09308856725692749, -0.004291802644729614]\n",
      "2500 steps | score: [0.16020545363426208, -0.2227497100830078]\n",
      "2600 steps | score: [0.05159170553088188, 0.08632126450538635]\n",
      "2700 steps | score: [0.08775029331445694, 0.027786798775196075]\n",
      "2800 steps | score: [0.1027660220861435, -0.030071668326854706]\n",
      "unknown params:  tensor([-1.0167, -1.0124,  0.9358,  0.8079, -0.4496, -0.0611])\n",
      "gt params:  tensor([-0.9405, -0.9740,  0.9054,  0.7745, -0.4476, -0.2918])\n",
      "ols params:  tensor([-0.5766, -0.5769,  0.5366,  0.4674, -0.2588,  3.1608])\n",
      "unknown mse:  tensor(0.0104)\n",
      "ols mse:  tensor(2.0793)\n",
      "gt params:  tensor([-0.9667, -0.9819,  0.8914,  0.8025, -0.4869, -0.3107])\n",
      "0 steps | score: [0.33023613691329956]\n",
      "100 steps | score: [0.1335650533437729]\n",
      "200 steps | score: [0.0748659074306488]\n",
      "300 steps | score: [0.07503211498260498]\n",
      "400 steps | score: [0.07391797751188278]\n",
      "500 steps | score: [0.07015211880207062]\n",
      "600 steps | score: [0.0871712788939476]\n",
      "700 steps | score: [0.06028664857149124]\n",
      "800 steps | score: [0.07343094050884247]\n",
      "900 steps | score: [0.06820404529571533]\n",
      "1000 steps | score: [0.09279559552669525]\n",
      "1100 steps | score: [0.041696108877658844]\n",
      "1200 steps | score: [0.07569806277751923]\n",
      "1300 steps | score: [0.07542778551578522]\n",
      "1400 steps | score: [0.1021445170044899]\n",
      "1500 steps | score: [0.07909888029098511]\n",
      "1600 steps | score: [0.051243044435977936]\n",
      "1700 steps | score: [0.08322955667972565]\n",
      "1800 steps | score: [0.0894063264131546]\n",
      "1900 steps | score: [0.05969208478927612]\n",
      "2000 steps | score: [0.06892045587301254]\n",
      "2100 steps | score: [0.06015971675515175]\n",
      "2200 steps | score: [0.07844629138708115]\n",
      "2300 steps | score: [0.09060442447662354]\n",
      "2400 steps | score: [0.0443551167845726]\n",
      "2500 steps | score: [0.05814523249864578]\n",
      "2600 steps | score: [0.09874442219734192]\n",
      "2700 steps | score: [0.08244368433952332]\n",
      "2800 steps | score: [0.0911884754896164]\n",
      "0 steps | score: [0.38210195302963257, -0.37429729104042053]\n",
      "100 steps | score: [0.23794128000736237, -0.2755802869796753]\n",
      "200 steps | score: [0.1096121296286583, -0.034869465976953506]\n",
      "300 steps | score: [0.5930323600769043, -1.329766035079956]\n",
      "400 steps | score: [0.13488824665546417, -0.05751471221446991]\n",
      "500 steps | score: [0.21825025975704193, -0.3198776841163635]\n",
      "600 steps | score: [0.05036485195159912, 0.07273445278406143]\n",
      "700 steps | score: [0.23569612205028534, -0.3213687539100647]\n",
      "800 steps | score: [0.10599055141210556, -0.03983099013566971]\n",
      "900 steps | score: [0.22330205142498016, -0.2923562526702881]\n",
      "1000 steps | score: [0.2139902561903, -0.2965833842754364]\n",
      "1100 steps | score: [-0.019028322771191597, 0.19967234134674072]\n",
      "1200 steps | score: [0.22150053083896637, -0.3253999948501587]\n",
      "1300 steps | score: [0.2205619066953659, -0.3021542429924011]\n",
      "1400 steps | score: [0.2790687382221222, -0.45107734203338623]\n",
      "1500 steps | score: [0.10733890533447266, -0.05472385883331299]\n",
      "1600 steps | score: [0.08932530879974365, -0.04852042347192764]\n",
      "1700 steps | score: [0.21655705571174622, -0.29749614000320435]\n",
      "1800 steps | score: [0.18579652905464172, -0.22069872915744781]\n",
      "1900 steps | score: [0.08043097704648972, 0.0008661635220050812]\n",
      "2000 steps | score: [0.1497393250465393, -0.1413707584142685]\n",
      "2100 steps | score: [0.18826159834861755, -0.24257761240005493]\n",
      "2200 steps | score: [0.20417748391628265, -0.2738352119922638]\n",
      "2300 steps | score: [0.18323230743408203, -0.21642307937145233]\n",
      "2400 steps | score: [0.2102440446615219, -0.28424137830734253]\n",
      "2500 steps | score: [0.22516337037086487, -0.3092797100543976]\n",
      "2600 steps | score: [0.1260000467300415, -0.0809994637966156]\n",
      "2700 steps | score: [0.1752644032239914, -0.21814613044261932]\n",
      "2800 steps | score: [0.12079184502363205, -0.1261073648929596]\n",
      "unknown params:  tensor([-0.9076, -0.9536,  0.9031,  0.7854, -0.4889, -0.1248])\n",
      "gt params:  tensor([-0.9667, -0.9819,  0.8914,  0.8025, -0.4869, -0.3107])\n",
      "ols params:  tensor([-0.5448, -0.5669,  0.5416,  0.4718, -0.2931,  3.3019])\n",
      "unknown mse:  tensor(0.0065)\n",
      "ols mse:  tensor(2.2784)\n",
      "gt params:  tensor([-0.9507, -0.9929,  0.8948,  0.7917, -0.4371, -0.2976])\n",
      "0 steps | score: [0.07437610626220703]\n",
      "100 steps | score: [-0.1625235676765442]\n",
      "200 steps | score: [-0.19853144884109497]\n",
      "300 steps | score: [-0.1801663339138031]\n",
      "400 steps | score: [-0.10308272391557693]\n",
      "500 steps | score: [-0.10374744981527328]\n",
      "600 steps | score: [-0.0935640037059784]\n",
      "700 steps | score: [-0.15215982496738434]\n",
      "800 steps | score: [-0.16417914628982544]\n",
      "900 steps | score: [-0.15321139991283417]\n",
      "1000 steps | score: [-0.12069328874349594]\n",
      "1100 steps | score: [-0.12909331917762756]\n",
      "1200 steps | score: [-0.14205676317214966]\n",
      "1300 steps | score: [-0.1525050699710846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 steps | score: [-0.13068045675754547]\n",
      "1500 steps | score: [-0.09981688857078552]\n",
      "1600 steps | score: [-0.1570807546377182]\n",
      "1700 steps | score: [-0.11364957690238953]\n",
      "1800 steps | score: [-0.11526407301425934]\n",
      "1900 steps | score: [-0.14361336827278137]\n",
      "2000 steps | score: [-0.09679029881954193]\n",
      "2100 steps | score: [-0.15941986441612244]\n",
      "2200 steps | score: [-0.12183524668216705]\n",
      "2300 steps | score: [-0.13400179147720337]\n",
      "2400 steps | score: [-0.11428488045930862]\n",
      "2500 steps | score: [-0.12744659185409546]\n",
      "2600 steps | score: [-0.1580158770084381]\n",
      "2700 steps | score: [-0.13921420276165009]\n",
      "2800 steps | score: [-0.14647729694843292]\n",
      "0 steps | score: [0.21982082724571228, 0.15533244609832764]\n",
      "100 steps | score: [-0.005619336385279894, 0.5294227004051208]\n",
      "200 steps | score: [-0.13242711126804352, 0.6730794906616211]\n",
      "300 steps | score: [0.05990172177553177, 0.23053650557994843]\n",
      "400 steps | score: [0.010257872752845287, 0.3304409980773926]\n",
      "500 steps | score: [0.1963672935962677, -0.09314880520105362]\n",
      "600 steps | score: [0.12696097791194916, 0.12026488780975342]\n",
      "700 steps | score: [-0.04035478085279465, 0.419170618057251]\n",
      "800 steps | score: [0.06608011573553085, 0.17288289964199066]\n",
      "900 steps | score: [0.0018698605708777905, 0.31682780385017395]\n",
      "1000 steps | score: [0.0230091605335474, 0.29969125986099243]\n",
      "1100 steps | score: [-0.0300743468105793, 0.4013071358203888]\n",
      "1200 steps | score: [0.13170985877513885, 0.039141178131103516]\n",
      "1300 steps | score: [0.23829534649848938, -0.26076024770736694]\n",
      "1400 steps | score: [0.10865501314401627, 0.10479538142681122]\n",
      "1500 steps | score: [0.02195695787668228, 0.344882607460022]\n",
      "1600 steps | score: [-0.07675261050462723, 0.5239435434341431]\n",
      "1700 steps | score: [0.131041020154953, -0.005917716771364212]\n",
      "1800 steps | score: [0.10386700928211212, 0.10554033517837524]\n",
      "1900 steps | score: [0.0006424813764169812, 0.34896254539489746]\n",
      "2000 steps | score: [-0.0015273152384907007, 0.3509683310985565]\n",
      "2100 steps | score: [0.0025117211043834686, 0.3495503067970276]\n",
      "2200 steps | score: [-0.09288287907838821, 0.5538989901542664]\n",
      "2300 steps | score: [0.054441556334495544, 0.1814936250448227]\n",
      "2400 steps | score: [-0.010049376636743546, 0.35885879397392273]\n",
      "2500 steps | score: [0.042133741080760956, 0.264771968126297]\n",
      "2600 steps | score: [0.07429371774196625, 0.17143777012825012]\n",
      "2700 steps | score: [-0.022710217162966728, 0.4049392640590668]\n",
      "2800 steps | score: [0.06362142413854599, 0.19819693267345428]\n",
      "unknown params:  tensor([-0.9682, -1.0338,  0.9248,  0.7796, -0.4410, -0.2524])\n",
      "gt params:  tensor([-0.9507, -0.9929,  0.8948,  0.7917, -0.4371, -0.2976])\n",
      "ols params:  tensor([-0.5411, -0.5730,  0.5200,  0.4360, -0.2516,  3.4691])\n",
      "unknown mse:  tensor(0.0008)\n",
      "ols mse:  tensor(2.4722)\n",
      "gt params:  tensor([-0.9523, -0.9954,  0.9295,  0.8202, -0.4739, -0.3349])\n",
      "0 steps | score: [0.25416821241378784]\n",
      "100 steps | score: [0.0035235341638326645]\n",
      "0 steps | score: [0.1178145706653595, -0.2616354525089264]\n",
      "100 steps | score: [-0.22184723615646362, 0.3480810225009918]\n",
      "200 steps | score: [0.029358958825469017, -0.2705221474170685]\n",
      "300 steps | score: [-0.011859185062348843, -0.1921008825302124]\n",
      "400 steps | score: [-0.2815348505973816, 0.3931635618209839]\n",
      "500 steps | score: [-0.2780168354511261, 0.38576072454452515]\n",
      "600 steps | score: [0.021126728504896164, -0.31877943873405457]\n",
      "700 steps | score: [-0.038937415927648544, -0.15070652961730957]\n",
      "800 steps | score: [-0.33317357301712036, 0.4664321839809418]\n",
      "900 steps | score: [-0.2313263863325119, 0.27551671862602234]\n",
      "1000 steps | score: [0.11329182982444763, -0.5417706966400146]\n",
      "1100 steps | score: [0.010237417183816433, -0.2892574369907379]\n",
      "1200 steps | score: [-0.12260262668132782, 0.032454997301101685]\n",
      "1300 steps | score: [-0.10335640609264374, -0.02093106135725975]\n",
      "1400 steps | score: [-0.04998284950852394, -0.14459826052188873]\n",
      "1500 steps | score: [0.004854510072618723, -0.2730412483215332]\n",
      "1600 steps | score: [0.07420021295547485, -0.43318015336990356]\n",
      "1700 steps | score: [-0.06876176595687866, -0.0650625228881836]\n",
      "1800 steps | score: [-0.02938767708837986, -0.18300694227218628]\n",
      "1900 steps | score: [-0.05828682705760002, -0.1169617772102356]\n",
      "2000 steps | score: [0.0006611935095861554, -0.24904941022396088]\n",
      "2100 steps | score: [0.06995952129364014, -0.4506963789463043]\n",
      "2200 steps | score: [-0.08522569388151169, -0.05639202147722244]\n",
      "2300 steps | score: [-0.03913275897502899, -0.16378335654735565]\n",
      "2400 steps | score: [-0.11897816509008408, 0.014775976538658142]\n",
      "2500 steps | score: [-0.03869176656007767, -0.18116936087608337]\n",
      "2600 steps | score: [-0.04447516053915024, -0.1627541184425354]\n",
      "2700 steps | score: [-0.07845407724380493, -0.08772827684879303]\n",
      "2800 steps | score: [-0.13826662302017212, 0.04758328199386597]\n",
      "unknown params:  tensor([-0.9800, -0.9542,  0.9420,  0.8493, -0.4544, -0.2615])\n",
      "gt params:  tensor([-0.9523, -0.9954,  0.9295,  0.8202, -0.4739, -0.3349])\n",
      "ols params:  tensor([-0.5585, -0.5413,  0.5398,  0.4895, -0.2694,  3.4318])\n",
      "unknown mse:  tensor(0.0015)\n",
      "ols mse:  tensor(2.4754)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/ce4dacd5-ea9d-4df2-b532-332a21ddeb8c\n",
      "gt params:  tensor([-0.7220, -0.5706, -0.7659,  0.5827, -0.6880,  0.5430])\n",
      "0 steps | score: [0.08640173077583313]\n",
      "100 steps | score: [-0.02733130007982254]\n",
      "200 steps | score: [-0.06979809701442719]\n",
      "300 steps | score: [0.02872198447585106]\n",
      "400 steps | score: [0.003749050199985504]\n",
      "0 steps | score: [-0.14226147532463074, 0.9191461801528931]\n",
      "100 steps | score: [-0.9223980903625488, 7.936737537384033]\n",
      "200 steps | score: [-2.634075403213501, 12.69168758392334]\n",
      "300 steps | score: [-4.451297760009766, 14.704733848571777]\n",
      "400 steps | score: [0.21288564801216125, 3.1104986667633057]\n",
      "500 steps | score: [-1.6017310619354248, 9.812895774841309]\n",
      "600 steps | score: [-0.14552277326583862, 4.15003776550293]\n",
      "700 steps | score: [-1.9032347202301025, 10.773336410522461]\n",
      "800 steps | score: [-4.451298236846924, 14.704733848571777]\n",
      "900 steps | score: [-0.3230713903903961, 4.445471286773682]\n",
      "1000 steps | score: [-0.677120566368103, 4.97847318649292]\n",
      "1100 steps | score: [0.14610326290130615, -0.7885347604751587]\n",
      "1200 steps | score: [0.09610159695148468, -0.945001482963562]\n",
      "1300 steps | score: [-0.5857110619544983, 3.264235734939575]\n",
      "1400 steps | score: [-0.412593811750412, 2.3053488731384277]\n",
      "1500 steps | score: [-0.3048226535320282, 1.5832592248916626]\n",
      "1600 steps | score: [-0.45453906059265137, 2.3532602787017822]\n",
      "1700 steps | score: [-0.31109297275543213, 1.4466159343719482]\n",
      "1800 steps | score: [-0.23054258525371552, 0.8864722847938538]\n",
      "1900 steps | score: [-0.16166794300079346, 0.5378837585449219]\n",
      "2000 steps | score: [-0.308610200881958, 1.43632972240448]\n",
      "2100 steps | score: [-0.13151974976062775, 0.24467402696609497]\n",
      "2200 steps | score: [-0.34940245747566223, 1.5825166702270508]\n",
      "2300 steps | score: [-0.16567471623420715, 0.5047329664230347]\n",
      "2400 steps | score: [-0.1992338001728058, 0.5562902092933655]\n",
      "2500 steps | score: [-0.256795197725296, 1.0282577276229858]\n",
      "2600 steps | score: [-0.3131066560745239, 1.4729678630828857]\n",
      "2700 steps | score: [-0.2865913510322571, 1.2013660669326782]\n",
      "unknown params:  tensor([-0.6899, -0.5396, -0.7298,  0.5812, -0.6582,  0.2675])\n",
      "gt params:  tensor([-0.7220, -0.5706, -0.7659,  0.5827, -0.6880,  0.5430])\n",
      "ols params:  tensor([-0.6715, -0.5248, -0.7101,  0.5466, -0.6415,  0.9062])\n",
      "unknown mse:  tensor(0.0133)\n",
      "ols mse:  tensor(0.0239)\n",
      "gt params:  tensor([-0.7266, -0.5702, -0.7686,  0.5744, -0.6839,  0.5660])\n",
      "0 steps | score: [0.04522578418254852]\n",
      "100 steps | score: [-0.06510397791862488]\n",
      "200 steps | score: [0.010231554508209229]\n",
      "300 steps | score: [-0.05860188603401184]\n",
      "400 steps | score: [-0.11072823405265808]\n",
      "500 steps | score: [0.03437672555446625]\n",
      "600 steps | score: [-0.09452302008867264]\n",
      "700 steps | score: [-0.019426248967647552]\n",
      "800 steps | score: [-0.13818809390068054]\n",
      "900 steps | score: [-0.06310918927192688]\n",
      "1000 steps | score: [0.0029919445514678955]\n",
      "0 steps | score: [0.1038069874048233, -0.2872200608253479]\n",
      "100 steps | score: [0.7925683856010437, -4.284846782684326]\n",
      "200 steps | score: [0.13794171810150146, -0.652240514755249]\n",
      "300 steps | score: [0.37196084856987, -1.9955692291259766]\n",
      "400 steps | score: [0.34459003806114197, -2.038158416748047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [-0.11866164952516556, 0.2230929434299469]\n",
      "600 steps | score: [-0.4125727713108063, 1.6177054643630981]\n",
      "700 steps | score: [-0.08996455371379852, 0.14799562096595764]\n",
      "800 steps | score: [-0.388654500246048, 1.4906572103500366]\n",
      "900 steps | score: [0.009325197897851467, -0.3725774884223938]\n",
      "1000 steps | score: [0.2600334882736206, -1.5483192205429077]\n",
      "1100 steps | score: [-0.22355158627033234, 0.7861864566802979]\n",
      "1200 steps | score: [-0.055016692727804184, -0.030510757118463516]\n",
      "1300 steps | score: [-0.2926502525806427, 1.1099790334701538]\n",
      "1400 steps | score: [0.18050691485404968, -1.1957061290740967]\n",
      "1500 steps | score: [-0.061747997999191284, -0.009056739509105682]\n",
      "1600 steps | score: [0.014390370808541775, -0.3921302258968353]\n",
      "1700 steps | score: [-0.1466251015663147, 0.39673250913619995]\n",
      "1800 steps | score: [0.07903310656547546, -0.6765581965446472]\n",
      "1900 steps | score: [-0.03955838829278946, -0.1393459141254425]\n",
      "2000 steps | score: [0.2138766646385193, -1.3129075765609741]\n",
      "2100 steps | score: [0.21662431955337524, -1.4065001010894775]\n",
      "2200 steps | score: [0.05452367290854454, -0.5398623943328857]\n",
      "2300 steps | score: [-0.007532578893005848, -0.2917354702949524]\n",
      "2400 steps | score: [-0.04874658212065697, -0.0557873398065567]\n",
      "2500 steps | score: [0.20802700519561768, -1.2845062017440796]\n",
      "2600 steps | score: [-0.020053274929523468, -0.2195548117160797]\n",
      "2700 steps | score: [0.08671870082616806, -0.7068396806716919]\n",
      "unknown params:  tensor([-0.6920, -0.5542, -0.7260,  0.5471, -0.6514,  0.4976])\n",
      "gt params:  tensor([-0.7266, -0.5702, -0.7686,  0.5744, -0.6839,  0.5660])\n",
      "ols params:  tensor([-0.6279, -0.5028, -0.6570,  0.4971, -0.5906,  1.2833])\n",
      "unknown mse:  tensor(0.0016)\n",
      "ols mse:  tensor(0.0927)\n",
      "gt params:  tensor([-0.7219, -0.5783, -0.7646,  0.5805, -0.6926,  0.5487])\n",
      "0 steps | score: [0.13599331676959991]\n",
      "100 steps | score: [0.059131547808647156]\n",
      "200 steps | score: [-0.002803947776556015]\n",
      "0 steps | score: [0.19089052081108093, -0.21502134203910828]\n",
      "100 steps | score: [1.4858201742172241, -7.00661563873291]\n",
      "200 steps | score: [0.7634965777397156, -3.237917184829712]\n",
      "300 steps | score: [-0.25396883487701416, 0.9655002355575562]\n",
      "400 steps | score: [-0.17107439041137695, 0.7287099361419678]\n",
      "500 steps | score: [0.3697221279144287, -1.4413928985595703]\n",
      "600 steps | score: [0.2810412645339966, -1.0658427476882935]\n",
      "700 steps | score: [0.5173209309577942, -2.1330742835998535]\n",
      "800 steps | score: [0.13096582889556885, -0.4181012213230133]\n",
      "900 steps | score: [-0.04468864947557449, 0.22492825984954834]\n",
      "1000 steps | score: [0.05992879346013069, -0.14265413582324982]\n",
      "1100 steps | score: [-0.07448992878198624, 0.3546296954154968]\n",
      "1200 steps | score: [0.5762821435928345, -2.427978277206421]\n",
      "1300 steps | score: [0.18630649149417877, -0.6714687347412109]\n",
      "1400 steps | score: [0.05468205735087395, -0.17917779088020325]\n",
      "1500 steps | score: [0.06225776672363281, -0.18930847942829132]\n",
      "1600 steps | score: [0.1837960183620453, -0.6839202046394348]\n",
      "1700 steps | score: [0.14735637605190277, -0.4740437865257263]\n",
      "1800 steps | score: [0.11642608791589737, -0.37944495677948]\n",
      "1900 steps | score: [0.06520168483257294, -0.22482749819755554]\n",
      "2000 steps | score: [-0.010773804970085621, 0.05423417687416077]\n",
      "2100 steps | score: [0.07320725172758102, -0.2691907584667206]\n",
      "2200 steps | score: [-0.012690023519098759, 0.09427270293235779]\n",
      "2300 steps | score: [0.24304918944835663, -0.9473674297332764]\n",
      "2400 steps | score: [0.08093670010566711, -0.272682785987854]\n",
      "2500 steps | score: [0.028522923588752747, -0.04167155921459198]\n",
      "2600 steps | score: [0.08700701594352722, -0.29928094148635864]\n",
      "2700 steps | score: [0.07385682314634323, -0.27949392795562744]\n",
      "unknown params:  tensor([-0.7129, -0.5716, -0.7437,  0.5733, -0.6813,  0.4067])\n",
      "gt params:  tensor([-0.7219, -0.5783, -0.7646,  0.5805, -0.6926,  0.5487])\n",
      "ols params:  tensor([-0.5975, -0.4813, -0.6242,  0.4828, -0.5709,  1.5090])\n",
      "unknown mse:  tensor(0.0035)\n",
      "ols mse:  tensor(0.1652)\n",
      "gt params:  tensor([-0.7187, -0.5768, -0.7620,  0.5702, -0.6914,  0.5407])\n",
      "0 steps | score: [0.26853516697883606]\n",
      "100 steps | score: [0.05337031930685043]\n",
      "200 steps | score: [0.18831893801689148]\n",
      "300 steps | score: [0.1693337857723236]\n",
      "400 steps | score: [0.09588321298360825]\n",
      "500 steps | score: [0.07857143133878708]\n",
      "600 steps | score: [0.07273192703723907]\n",
      "700 steps | score: [0.06096795201301575]\n",
      "800 steps | score: [0.07144874334335327]\n",
      "900 steps | score: [0.15531110763549805]\n",
      "1000 steps | score: [0.07828778028488159]\n",
      "1100 steps | score: [0.08743235468864441]\n",
      "1200 steps | score: [0.07173461467027664]\n",
      "1300 steps | score: [0.10714393854141235]\n",
      "1400 steps | score: [0.15461809933185577]\n",
      "1500 steps | score: [0.12494993209838867]\n",
      "1600 steps | score: [0.11431329697370529]\n",
      "1700 steps | score: [0.08185157179832458]\n",
      "1800 steps | score: [0.10504281520843506]\n",
      "1900 steps | score: [0.1347428262233734]\n",
      "2000 steps | score: [0.12429516017436981]\n",
      "2100 steps | score: [0.11078640073537827]\n",
      "2200 steps | score: [0.10237547010183334]\n",
      "2300 steps | score: [0.05619557201862335]\n",
      "2400 steps | score: [0.06610134243965149]\n",
      "2500 steps | score: [0.1302887201309204]\n",
      "2600 steps | score: [0.09659763425588608]\n",
      "2700 steps | score: [0.07696858793497086]\n",
      "0 steps | score: [0.27049553394317627, -0.5806871652603149]\n",
      "100 steps | score: [-0.11489710956811905, 0.44279658794403076]\n",
      "200 steps | score: [0.553585946559906, -2.0087854862213135]\n",
      "300 steps | score: [0.07971173524856567, -0.2000119686126709]\n",
      "400 steps | score: [-0.03189920634031296, 0.09677129983901978]\n",
      "500 steps | score: [0.24732470512390137, -0.8361047506332397]\n",
      "600 steps | score: [0.26336297392845154, -0.9079902768135071]\n",
      "700 steps | score: [0.4341026842594147, -1.585638165473938]\n",
      "800 steps | score: [0.3600004315376282, -1.3434131145477295]\n",
      "900 steps | score: [0.1771049201488495, -0.6083493232727051]\n",
      "1000 steps | score: [0.08693713694810867, -0.3198910057544708]\n",
      "1100 steps | score: [0.09745056182146072, -0.32119351625442505]\n",
      "1200 steps | score: [0.06239276006817818, -0.2183079868555069]\n",
      "1300 steps | score: [0.10781583189964294, -0.40269163250923157]\n",
      "1400 steps | score: [0.40974122285842896, -1.4568500518798828]\n",
      "1500 steps | score: [0.10089612752199173, -0.35421401262283325]\n",
      "1600 steps | score: [0.027031149715185165, -0.059538163244724274]\n",
      "1700 steps | score: [0.18837685883045197, -0.6834636330604553]\n",
      "1800 steps | score: [0.18137328326702118, -0.657997727394104]\n",
      "1900 steps | score: [0.29282960295677185, -1.0714770555496216]\n",
      "2000 steps | score: [0.13642188906669617, -0.48815640807151794]\n",
      "2100 steps | score: [0.1102614551782608, -0.3952118754386902]\n",
      "2200 steps | score: [0.19706517457962036, -0.6685205101966858]\n",
      "2300 steps | score: [0.054246969521045685, -0.20733460783958435]\n",
      "2400 steps | score: [0.09020832926034927, -0.3428266644477844]\n",
      "2500 steps | score: [0.2520347237586975, -0.8693536520004272]\n",
      "2600 steps | score: [0.1545780748128891, -0.5532008409500122]\n",
      "2700 steps | score: [0.025063294917345047, -0.10409005731344223]\n",
      "unknown params:  tensor([-0.6992, -0.5411, -0.7317,  0.5302, -0.6636,  0.4340])\n",
      "gt params:  tensor([-0.7187, -0.5768, -0.7620,  0.5702, -0.6914,  0.5407])\n",
      "ols params:  tensor([-0.5743, -0.4470, -0.5973,  0.4416, -0.5419,  1.7741])\n",
      "unknown mse:  tensor(0.0027)\n",
      "ols mse:  tensor(0.2708)\n",
      "gt params:  tensor([-0.7323, -0.5789, -0.7703,  0.5844, -0.6943,  0.5373])\n",
      "0 steps | score: [0.140943244099617]\n",
      "100 steps | score: [-0.011943187564611435]\n",
      "200 steps | score: [-0.006427835673093796]\n",
      "0 steps | score: [0.1822195202112198, -0.4438275098800659]\n",
      "100 steps | score: [0.015376060269773006, -0.07443337887525558]\n",
      "200 steps | score: [-0.07164718955755234, 0.09494400024414062]\n",
      "300 steps | score: [0.017541587352752686, -0.24836070835590363]\n",
      "400 steps | score: [0.2944119870662689, -1.144930362701416]\n",
      "500 steps | score: [-0.06847011297941208, -0.01094791293144226]\n",
      "600 steps | score: [-0.2661038041114807, 0.5326487421989441]\n",
      "700 steps | score: [0.1450309455394745, -0.6133629083633423]\n",
      "800 steps | score: [0.07202164083719254, -0.4383319318294525]\n",
      "900 steps | score: [0.15298762917518616, -0.6838991641998291]\n",
      "1000 steps | score: [0.12439142912626266, -0.5971485376358032]\n",
      "1100 steps | score: [0.1627672016620636, -0.8136157989501953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 steps | score: [-0.07680685073137283, 0.042987652122974396]\n",
      "1300 steps | score: [0.3272792398929596, -1.3314563035964966]\n",
      "1400 steps | score: [-0.03519641235470772, -0.09802079200744629]\n",
      "1500 steps | score: [-0.10930551588535309, 0.13912449777126312]\n",
      "1600 steps | score: [0.1142519935965538, -0.5369963645935059]\n",
      "1700 steps | score: [0.125667005777359, -0.5921831130981445]\n",
      "1800 steps | score: [0.1878223866224289, -0.8220523595809937]\n",
      "1900 steps | score: [0.08753615617752075, -0.5434795618057251]\n",
      "2000 steps | score: [0.19235701858997345, -0.8195673227310181]\n",
      "2100 steps | score: [0.06252793222665787, -0.49096018075942993]\n",
      "2200 steps | score: [0.050738375633955, -0.40495437383651733]\n",
      "2300 steps | score: [0.02623070403933525, -0.29427027702331543]\n",
      "2400 steps | score: [0.11780399084091187, -0.54404217004776]\n",
      "2500 steps | score: [0.01893136464059353, -0.2554361820220947]\n",
      "2600 steps | score: [-0.006549057550728321, -0.21115230023860931]\n",
      "2700 steps | score: [0.031235044822096825, -0.2913358211517334]\n",
      "unknown params:  tensor([-0.7092, -0.5750, -0.7489,  0.5626, -0.6750,  0.3557])\n",
      "gt params:  tensor([-0.7323, -0.5789, -0.7703,  0.5844, -0.6943,  0.5373])\n",
      "ols params:  tensor([-0.5522, -0.4510, -0.5796,  0.4388, -0.5203,  1.9437])\n",
      "unknown mse:  tensor(0.0058)\n",
      "ols mse:  tensor(0.3525)\n",
      "gt params:  tensor([-0.7294, -0.5702, -0.7609,  0.5855, -0.6785,  0.5405])\n",
      "0 steps | score: [0.004579838365316391]\n",
      "100 steps | score: [-0.161068394780159]\n",
      "200 steps | score: [-0.11996619403362274]\n",
      "300 steps | score: [-0.11715497076511383]\n",
      "400 steps | score: [-0.16361317038536072]\n",
      "500 steps | score: [-0.11780238151550293]\n",
      "600 steps | score: [-0.1386634260416031]\n",
      "700 steps | score: [-0.14695805311203003]\n",
      "800 steps | score: [-0.10990176349878311]\n",
      "900 steps | score: [-0.16532213985919952]\n",
      "1000 steps | score: [-0.10156052559614182]\n",
      "1100 steps | score: [-0.1633003056049347]\n",
      "1200 steps | score: [-0.17646896839141846]\n",
      "1300 steps | score: [-0.1494848132133484]\n",
      "1400 steps | score: [-0.1570899486541748]\n",
      "1500 steps | score: [-0.14614680409431458]\n",
      "1600 steps | score: [-0.12085825204849243]\n",
      "1700 steps | score: [-0.165943905711174]\n",
      "1800 steps | score: [-0.14608748257160187]\n",
      "1900 steps | score: [-0.15730071067810059]\n",
      "2000 steps | score: [-0.14074933528900146]\n",
      "2100 steps | score: [-0.15308062732219696]\n",
      "2200 steps | score: [-0.1646718680858612]\n",
      "2300 steps | score: [-0.16570480167865753]\n",
      "2400 steps | score: [-0.1606888324022293]\n",
      "2500 steps | score: [-0.15301311016082764]\n",
      "2600 steps | score: [-0.13655608892440796]\n",
      "2700 steps | score: [-0.1256166398525238]\n",
      "0 steps | score: [0.003977363929152489, 0.1913132518529892]\n",
      "100 steps | score: [0.018102774396538734, -0.13653378188610077]\n",
      "200 steps | score: [-0.15626104176044464, 0.44542810320854187]\n",
      "300 steps | score: [-0.3137357831001282, 0.809230387210846]\n",
      "400 steps | score: [-0.10396929085254669, 0.13574551045894623]\n",
      "500 steps | score: [0.039454810321331024, -0.31519702076911926]\n",
      "600 steps | score: [-0.20397838950157166, 0.46382224559783936]\n",
      "700 steps | score: [-0.24179670214653015, 0.6013799905776978]\n",
      "800 steps | score: [-0.16793355345726013, 0.41231226921081543]\n",
      "900 steps | score: [-0.03622832149267197, -0.0913359671831131]\n",
      "1000 steps | score: [0.2881225645542145, -1.2223267555236816]\n",
      "1100 steps | score: [-0.31653088331222534, 0.8030014634132385]\n",
      "1200 steps | score: [-0.11490722000598907, 0.18791550397872925]\n",
      "1300 steps | score: [-0.06542934477329254, 0.04348289966583252]\n",
      "1400 steps | score: [-0.0860365778207779, 0.09093933552503586]\n",
      "1500 steps | score: [-0.11958639323711395, 0.2617669701576233]\n",
      "1600 steps | score: [-0.0388176292181015, -0.02314905822277069]\n",
      "1700 steps | score: [-0.15324121713638306, 0.3035493791103363]\n",
      "1800 steps | score: [-0.17897911369800568, 0.3635292947292328]\n",
      "1900 steps | score: [-0.08713796734809875, 0.1095929890871048]\n",
      "2000 steps | score: [-0.05930154025554657, 0.0200251042842865]\n",
      "2100 steps | score: [-0.14585040509700775, 0.2503036856651306]\n",
      "2200 steps | score: [-0.23412030935287476, 0.5621005892753601]\n",
      "2300 steps | score: [-0.058927565813064575, -0.03629465773701668]\n",
      "2400 steps | score: [0.004317773040384054, -0.16628801822662354]\n",
      "2500 steps | score: [-0.17865291237831116, 0.38007694482803345]\n",
      "2600 steps | score: [-0.06471186876296997, -0.014350097626447678]\n",
      "2700 steps | score: [-0.08441299945116043, 0.061136096715927124]\n",
      "unknown params:  tensor([-0.7060, -0.5753, -0.7890,  0.5953, -0.6719,  0.4032])\n",
      "gt params:  tensor([-0.7294, -0.5702, -0.7609,  0.5855, -0.6785,  0.5405])\n",
      "ols params:  tensor([-0.5063, -0.4137, -0.5607,  0.4242, -0.4819,  2.1830])\n",
      "unknown mse:  tensor(0.0034)\n",
      "ols mse:  tensor(0.4795)\n",
      "gt params:  tensor([-0.7176, -0.5748, -0.7766,  0.5754, -0.6802,  0.5934])\n",
      "0 steps | score: [0.23167040944099426]\n",
      "100 steps | score: [-0.02024909481406212]\n",
      "200 steps | score: [0.09429478645324707]\n",
      "300 steps | score: [0.0009327121078968048]\n",
      "0 steps | score: [-0.03607061505317688, 0.48364636301994324]\n",
      "100 steps | score: [-0.3462933897972107, 1.0654984712600708]\n",
      "200 steps | score: [-0.10978449136018753, 0.32265645265579224]\n",
      "300 steps | score: [-0.22567588090896606, 0.6307857632637024]\n",
      "400 steps | score: [-0.04154287651181221, 0.16383567452430725]\n",
      "500 steps | score: [-0.31432971358299255, 0.9124802947044373]\n",
      "600 steps | score: [-0.27030399441719055, 0.7769926190376282]\n",
      "700 steps | score: [-0.2845805883407593, 0.8185762166976929]\n",
      "800 steps | score: [-0.27159538865089417, 0.7429718971252441]\n",
      "900 steps | score: [-0.310779333114624, 0.8686403036117554]\n",
      "1000 steps | score: [-0.2761722207069397, 0.7977805137634277]\n",
      "1100 steps | score: [-0.2544584572315216, 0.7559919953346252]\n",
      "1200 steps | score: [-0.3253857493400574, 0.942929208278656]\n",
      "1300 steps | score: [-0.22216574847698212, 0.6024249792098999]\n",
      "1400 steps | score: [-0.0342765673995018, 0.1277366727590561]\n",
      "1500 steps | score: [-0.2986471354961395, 0.8705820441246033]\n",
      "1600 steps | score: [-0.2428918480873108, 0.6676801443099976]\n",
      "1700 steps | score: [-0.24874171614646912, 0.7325494289398193]\n",
      "1800 steps | score: [-0.3039945662021637, 0.8552292585372925]\n",
      "1900 steps | score: [-0.2825562655925751, 0.7782706022262573]\n",
      "2000 steps | score: [-0.21789711713790894, 0.6309812068939209]\n",
      "2100 steps | score: [-0.20295099914073944, 0.6465762257575989]\n",
      "2200 steps | score: [-0.22364568710327148, 0.692596435546875]\n",
      "2300 steps | score: [-0.2959613502025604, 0.824398398399353]\n",
      "2400 steps | score: [-0.23697444796562195, 0.6731120944023132]\n",
      "2500 steps | score: [-0.20966820418834686, 0.5779542922973633]\n",
      "2600 steps | score: [-0.268000990152359, 0.7659080028533936]\n",
      "2700 steps | score: [-0.20103277266025543, 0.5871715545654297]\n",
      "unknown params:  tensor([-0.7410, -0.6101, -0.8094,  0.5769, -0.7175,  0.3424])\n",
      "gt params:  tensor([-0.7176, -0.5748, -0.7766,  0.5754, -0.6802,  0.5934])\n",
      "ols params:  tensor([-0.5171, -0.4211, -0.5615,  0.4054, -0.5022,  2.2900])\n",
      "unknown mse:  tensor(0.0112)\n",
      "ols mse:  tensor(0.5082)\n",
      "gt params:  tensor([-0.7360, -0.5809, -0.7466,  0.5955, -0.6820,  0.5555])\n",
      "0 steps | score: [0.08528974652290344]\n",
      "100 steps | score: [-0.15544989705085754]\n",
      "200 steps | score: [-0.15619400143623352]\n",
      "300 steps | score: [-0.0844067633152008]\n",
      "400 steps | score: [-0.023640647530555725]\n",
      "500 steps | score: [-0.1354554444551468]\n",
      "600 steps | score: [-0.10123187303543091]\n",
      "700 steps | score: [-0.14418399333953857]\n",
      "800 steps | score: [-0.13618417084217072]\n",
      "900 steps | score: [-0.08698485046625137]\n",
      "1000 steps | score: [-0.10115684568881989]\n",
      "1100 steps | score: [-0.11854390054941177]\n",
      "1200 steps | score: [-0.13164165616035461]\n",
      "1300 steps | score: [-0.07475975900888443]\n",
      "1400 steps | score: [-0.09983962029218674]\n",
      "1500 steps | score: [-0.08915132284164429]\n",
      "1600 steps | score: [-0.09728787839412689]\n",
      "1700 steps | score: [-0.14132101833820343]\n",
      "1800 steps | score: [-0.11555991321802139]\n",
      "1900 steps | score: [-0.10438201576471329]\n",
      "2000 steps | score: [-0.09841155260801315]\n",
      "2100 steps | score: [-0.09605889767408371]\n",
      "2200 steps | score: [-0.07671355456113815]\n",
      "2300 steps | score: [-0.13131923973560333]\n",
      "2400 steps | score: [-0.11254335194826126]\n",
      "2500 steps | score: [-0.11376050114631653]\n",
      "2600 steps | score: [-0.10753189027309418]\n",
      "0 steps | score: [0.1518106609582901, -0.22392110526561737]\n",
      "100 steps | score: [-0.0534193255007267, 0.11012600362300873]\n",
      "200 steps | score: [-0.17619140446186066, 0.3434049189090729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 steps | score: [1.0310720205307007, -3.4616024494171143]\n",
      "400 steps | score: [-0.03477912396192551, -0.003680933266878128]\n",
      "500 steps | score: [-0.3171887695789337, 0.6536029577255249]\n",
      "600 steps | score: [-0.1002984568476677, 0.17094101011753082]\n",
      "700 steps | score: [-0.07000155001878738, 0.10092753916978836]\n",
      "800 steps | score: [-0.031110035255551338, -0.01445162296295166]\n",
      "900 steps | score: [0.16232408583164215, -0.5188583731651306]\n",
      "1000 steps | score: [0.004830323625355959, -0.09897160530090332]\n",
      "1100 steps | score: [-0.02149929851293564, -0.03736412152647972]\n",
      "1200 steps | score: [-0.06114381551742554, 0.04534382373094559]\n",
      "1300 steps | score: [0.026587925851345062, -0.13222116231918335]\n",
      "1400 steps | score: [0.07614922523498535, -0.3033476769924164]\n",
      "1500 steps | score: [-0.14999203383922577, 0.26480090618133545]\n",
      "1600 steps | score: [0.015009359456598759, -0.11751629412174225]\n",
      "1700 steps | score: [-0.19428683817386627, 0.33888229727745056]\n",
      "1800 steps | score: [-0.037152249366045, -0.01649344339966774]\n",
      "1900 steps | score: [-0.0635637566447258, 0.07109568268060684]\n",
      "2000 steps | score: [-0.051743652671575546, 0.02274141274392605]\n",
      "2100 steps | score: [0.0255203228443861, -0.1489335298538208]\n",
      "2200 steps | score: [0.013637617230415344, -0.1197945699095726]\n",
      "2300 steps | score: [0.021664226427674294, -0.15496551990509033]\n",
      "2400 steps | score: [-0.05955759063363075, 0.08091370761394501]\n",
      "2500 steps | score: [-0.018505990505218506, -0.03692822530865669]\n",
      "2600 steps | score: [-0.09294822812080383, 0.1127459704875946]\n",
      "unknown params:  tensor([-0.7339, -0.5729, -0.7154,  0.5771, -0.6538,  0.4326])\n",
      "gt params:  tensor([-0.7360, -0.5809, -0.7466,  0.5955, -0.6820,  0.5555])\n",
      "ols params:  tensor([-0.5074, -0.3973, -0.4918,  0.3991, -0.4523,  2.5587])\n",
      "unknown mse:  tensor(0.0029)\n",
      "ols mse:  tensor(0.7092)\n",
      "gt params:  tensor([-0.7254, -0.5888, -0.7591,  0.5844, -0.6813,  0.5235])\n",
      "0 steps | score: [0.3542889654636383]\n",
      "100 steps | score: [0.21999885141849518]\n",
      "200 steps | score: [0.17678675055503845]\n",
      "300 steps | score: [0.15086179971694946]\n",
      "400 steps | score: [0.13902921974658966]\n",
      "500 steps | score: [0.23598109185695648]\n",
      "600 steps | score: [0.16446320712566376]\n",
      "700 steps | score: [0.16792912781238556]\n",
      "800 steps | score: [0.15623660385608673]\n",
      "900 steps | score: [0.17989511787891388]\n",
      "1000 steps | score: [0.21374893188476562]\n",
      "1100 steps | score: [0.21282194554805756]\n",
      "1200 steps | score: [0.17337104678153992]\n",
      "1300 steps | score: [0.18092550337314606]\n",
      "1400 steps | score: [0.12703897058963776]\n",
      "1500 steps | score: [0.18787971138954163]\n",
      "1600 steps | score: [0.2200891077518463]\n",
      "1700 steps | score: [0.14733554422855377]\n",
      "1800 steps | score: [0.16544562578201294]\n",
      "1900 steps | score: [0.18916431069374084]\n",
      "2000 steps | score: [0.17479851841926575]\n",
      "2100 steps | score: [0.19870540499687195]\n",
      "2200 steps | score: [0.18350407481193542]\n",
      "2300 steps | score: [0.20571264624595642]\n",
      "2400 steps | score: [0.18445347249507904]\n",
      "2500 steps | score: [0.15168723464012146]\n",
      "2600 steps | score: [0.1819920837879181]\n",
      "0 steps | score: [0.19048303365707397, -0.2837778329849243]\n",
      "100 steps | score: [0.036853037774562836, -0.09521134942770004]\n",
      "200 steps | score: [0.08828436583280563, -0.2614193558692932]\n",
      "300 steps | score: [0.09357281774282455, -0.3249528110027313]\n",
      "400 steps | score: [-0.09843996912240982, 0.1480737328529358]\n",
      "500 steps | score: [0.3263130187988281, -1.0602871179580688]\n",
      "600 steps | score: [-0.1674700826406479, 0.3015832304954529]\n",
      "700 steps | score: [-0.18272273242473602, 0.3495470881462097]\n",
      "800 steps | score: [-0.0633949562907219, 0.04441112279891968]\n",
      "900 steps | score: [-0.02760896272957325, -0.03432122617959976]\n",
      "1000 steps | score: [0.02662721462547779, -0.21914273500442505]\n",
      "1100 steps | score: [-0.028939124196767807, -0.06368596851825714]\n",
      "1200 steps | score: [-0.027038710191845894, -0.07211628556251526]\n",
      "1300 steps | score: [0.027015799656510353, -0.15902067720890045]\n",
      "1400 steps | score: [-0.1824585348367691, 0.32996705174446106]\n",
      "1500 steps | score: [0.0808536484837532, -0.3289816975593567]\n",
      "1600 steps | score: [-0.04012829810380936, -0.037019480019807816]\n",
      "1700 steps | score: [-0.130245640873909, 0.19108478724956512]\n",
      "1800 steps | score: [-0.07453812658786774, 0.08920538425445557]\n",
      "1900 steps | score: [-0.021082183346152306, -0.06801427900791168]\n",
      "2000 steps | score: [-0.05838979780673981, 0.03640986233949661]\n",
      "2100 steps | score: [0.08632279932498932, -0.391875684261322]\n",
      "2200 steps | score: [0.035287562757730484, -0.1783658266067505]\n",
      "2300 steps | score: [0.040162257850170135, -0.25108832120895386]\n",
      "2400 steps | score: [-0.03447379916906357, -0.039738595485687256]\n",
      "2500 steps | score: [-0.08464550226926804, 0.06428582221269608]\n",
      "2600 steps | score: [0.06327201426029205, -0.27558961510658264]\n",
      "unknown params:  tensor([-0.7166, -0.6026, -0.7595,  0.5757, -0.6890,  0.4348])\n",
      "gt params:  tensor([-0.7254, -0.5888, -0.7591,  0.5844, -0.6813,  0.5235])\n",
      "ols params:  tensor([-0.4603, -0.3835, -0.4865,  0.3693, -0.4389,  2.7403])\n",
      "unknown mse:  tensor(0.0014)\n",
      "ols mse:  tensor(0.8676)\n",
      "gt params:  tensor([-0.7110, -0.5788, -0.7628,  0.5990, -0.7012,  0.5431])\n",
      "0 steps | score: [0.3666609227657318]\n",
      "100 steps | score: [0.16498181223869324]\n",
      "200 steps | score: [0.12722359597682953]\n",
      "300 steps | score: [0.1692257821559906]\n",
      "400 steps | score: [0.17979222536087036]\n",
      "500 steps | score: [0.13643547892570496]\n",
      "600 steps | score: [0.12282374501228333]\n",
      "700 steps | score: [0.1451341062784195]\n",
      "800 steps | score: [0.253196656703949]\n",
      "900 steps | score: [0.20409026741981506]\n",
      "1000 steps | score: [0.1309386044740677]\n",
      "1100 steps | score: [0.12662500143051147]\n",
      "1200 steps | score: [0.13864323496818542]\n",
      "1300 steps | score: [0.15406030416488647]\n",
      "1400 steps | score: [0.1470814347267151]\n",
      "1500 steps | score: [0.14745190739631653]\n",
      "1600 steps | score: [0.13082465529441833]\n",
      "1700 steps | score: [0.16138999164104462]\n",
      "1800 steps | score: [0.1498841941356659]\n",
      "1900 steps | score: [0.17549774050712585]\n",
      "2000 steps | score: [0.16322080790996552]\n",
      "2100 steps | score: [0.12539903819561005]\n",
      "2200 steps | score: [0.12955453991889954]\n",
      "2300 steps | score: [0.1449141800403595]\n",
      "2400 steps | score: [0.1520717889070511]\n",
      "2500 steps | score: [0.16417263448238373]\n",
      "2600 steps | score: [0.1645953357219696]\n",
      "0 steps | score: [-0.09865297377109528, 0.17329972982406616]\n",
      "100 steps | score: [-0.32209911942481995, 0.5718308091163635]\n",
      "200 steps | score: [-0.11697264760732651, -0.08662605285644531]\n",
      "300 steps | score: [-0.17804211378097534, 0.08702705800533295]\n",
      "400 steps | score: [-0.44602885842323303, 0.7934143543243408]\n",
      "500 steps | score: [0.03923512622714043, -0.6425668001174927]\n",
      "600 steps | score: [-0.38925039768218994, 0.5907794833183289]\n",
      "700 steps | score: [-0.17756707966327667, 0.028405718505382538]\n",
      "800 steps | score: [-0.006849297322332859, -0.4836438000202179]\n",
      "900 steps | score: [-0.3046145439147949, 0.4207809269428253]\n",
      "1000 steps | score: [-0.17578493058681488, 0.03068394958972931]\n",
      "1100 steps | score: [-0.2164517492055893, 0.1580025553703308]\n",
      "1200 steps | score: [-0.2960810363292694, 0.41745543479919434]\n",
      "1300 steps | score: [-0.24542522430419922, 0.2150745391845703]\n",
      "1400 steps | score: [-0.3009750247001648, 0.34512752294540405]\n",
      "1500 steps | score: [-0.3237157464027405, 0.42177197337150574]\n",
      "1600 steps | score: [-0.23945507407188416, 0.1771998107433319]\n",
      "1700 steps | score: [-0.25421759486198425, 0.23943255841732025]\n",
      "1800 steps | score: [-0.2318243533372879, 0.1823633313179016]\n",
      "1900 steps | score: [-0.1216224953532219, -0.11362946778535843]\n",
      "2000 steps | score: [-0.09105904400348663, -0.25009679794311523]\n",
      "2100 steps | score: [-0.2658382058143616, 0.2581021785736084]\n",
      "2200 steps | score: [-0.1577291190624237, -0.08391470462083817]\n",
      "2300 steps | score: [-0.24599237740039825, 0.21184185147285461]\n",
      "2400 steps | score: [-0.14407972991466522, -0.018586643040180206]\n",
      "2500 steps | score: [-0.030116192996501923, -0.41958093643188477]\n",
      "2600 steps | score: [-0.21371452510356903, 0.1520112156867981]\n",
      "unknown params:  tensor([-0.7377, -0.5714, -0.7312,  0.5927, -0.6845,  0.3717])\n",
      "gt params:  tensor([-0.7110, -0.5788, -0.7628,  0.5990, -0.7012,  0.5431])\n",
      "ols params:  tensor([-0.4799, -0.3796, -0.4789,  0.3876, -0.4470,  2.8290])\n",
      "unknown mse:  tensor(0.0052)\n",
      "ols mse:  tensor(0.9180)\n",
      "gt params:  tensor([-0.7332, -0.5632, -0.7706,  0.5541, -0.6972,  0.5159])\n",
      "0 steps | score: [0.2802678346633911]\n",
      "100 steps | score: [-0.04819406941533089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [0.04176074266433716]\n",
      "300 steps | score: [0.05652488023042679]\n",
      "400 steps | score: [0.01821933314204216]\n",
      "500 steps | score: [0.03259837254881859]\n",
      "600 steps | score: [0.0705818384885788]\n",
      "700 steps | score: [0.08406908065080643]\n",
      "800 steps | score: [0.11868112534284592]\n",
      "900 steps | score: [0.013394685462117195]\n",
      "1000 steps | score: [0.0405680388212204]\n",
      "1100 steps | score: [0.07882005721330643]\n",
      "1200 steps | score: [0.05723310634493828]\n",
      "1300 steps | score: [0.12960313260555267]\n",
      "1400 steps | score: [0.11782928556203842]\n",
      "1500 steps | score: [0.03257906809449196]\n",
      "1600 steps | score: [0.07953661680221558]\n",
      "1700 steps | score: [0.03790653496980667]\n",
      "1800 steps | score: [0.09607788920402527]\n",
      "1900 steps | score: [0.07617321610450745]\n",
      "2000 steps | score: [0.04691742733120918]\n",
      "2100 steps | score: [0.0546417273581028]\n",
      "2200 steps | score: [0.0726168155670166]\n",
      "2300 steps | score: [0.047033924609422684]\n",
      "2400 steps | score: [0.1049969345331192]\n",
      "2500 steps | score: [0.06637492775917053]\n",
      "2600 steps | score: [0.0928923487663269]\n",
      "0 steps | score: [0.07545878738164902, 0.24676179885864258]\n",
      "100 steps | score: [-0.30024921894073486, 0.9267784357070923]\n",
      "200 steps | score: [-0.2639465630054474, 0.8547382354736328]\n",
      "300 steps | score: [0.5437370538711548, -1.4908058643341064]\n",
      "400 steps | score: [-0.21274501085281372, 0.6744924187660217]\n",
      "500 steps | score: [-0.18487448990345, 0.5540626645088196]\n",
      "600 steps | score: [-0.00422279117628932, 0.09230025112628937]\n",
      "700 steps | score: [-0.12906727194786072, 0.44597917795181274]\n",
      "800 steps | score: [-0.2301381528377533, 0.7231597900390625]\n",
      "900 steps | score: [-0.21977664530277252, 0.6944254636764526]\n",
      "1000 steps | score: [-0.21570411324501038, 0.644878089427948]\n",
      "1100 steps | score: [-0.1825285404920578, 0.577829122543335]\n",
      "1200 steps | score: [-0.12392953783273697, 0.4341418743133545]\n",
      "1300 steps | score: [0.06174652650952339, -0.042608827352523804]\n",
      "1400 steps | score: [-0.009864095598459244, 0.17327211797237396]\n",
      "1500 steps | score: [-0.225192129611969, 0.6731322407722473]\n",
      "1600 steps | score: [0.011030694469809532, 0.06668949127197266]\n",
      "1700 steps | score: [-0.08312716335058212, 0.3312988877296448]\n",
      "1800 steps | score: [-0.07223059237003326, 0.3347781300544739]\n",
      "1900 steps | score: [-0.16789376735687256, 0.5287947058677673]\n",
      "2000 steps | score: [-0.14858336746692657, 0.5059357285499573]\n",
      "2100 steps | score: [-0.14540915191173553, 0.5019654035568237]\n",
      "2200 steps | score: [-0.12356674671173096, 0.40871086716651917]\n",
      "2300 steps | score: [-0.11556374281644821, 0.4159126877784729]\n",
      "2400 steps | score: [-0.02585638500750065, 0.18768072128295898]\n",
      "2500 steps | score: [-0.1762094497680664, 0.5632734894752502]\n",
      "2600 steps | score: [-0.15050862729549408, 0.49660125374794006]\n",
      "unknown params:  tensor([-0.7553, -0.5866, -0.8250,  0.6108, -0.7411,  0.3454])\n",
      "gt params:  tensor([-0.7332, -0.5632, -0.7706,  0.5541, -0.6972,  0.5159])\n",
      "ols params:  tensor([-0.4418, -0.3439, -0.4772,  0.3560, -0.4261,  2.9758])\n",
      "unknown mse:  tensor(0.0064)\n",
      "ols mse:  tensor(1.0638)\n",
      "gt params:  tensor([-0.7351, -0.5530, -0.7721,  0.5753, -0.6825,  0.5517])\n",
      "0 steps | score: [0.025659527629613876]\n",
      "100 steps | score: [-0.2510899007320404]\n",
      "200 steps | score: [-0.17796605825424194]\n",
      "300 steps | score: [-0.1744578331708908]\n",
      "400 steps | score: [-0.25321921706199646]\n",
      "500 steps | score: [-0.23252904415130615]\n",
      "600 steps | score: [-0.18995076417922974]\n",
      "700 steps | score: [-0.16459834575653076]\n",
      "800 steps | score: [-0.13640660047531128]\n",
      "900 steps | score: [-0.19699740409851074]\n",
      "1000 steps | score: [-0.18373319506645203]\n",
      "1100 steps | score: [-0.22240319848060608]\n",
      "1200 steps | score: [-0.2529439330101013]\n",
      "1300 steps | score: [-0.1994112879037857]\n",
      "1400 steps | score: [-0.1864875853061676]\n",
      "1500 steps | score: [-0.22119884192943573]\n",
      "1600 steps | score: [-0.22733110189437866]\n",
      "1700 steps | score: [-0.21640938520431519]\n",
      "1800 steps | score: [-0.2157784104347229]\n",
      "1900 steps | score: [-0.1985337734222412]\n",
      "2000 steps | score: [-0.19822129607200623]\n",
      "2100 steps | score: [-0.20376044511795044]\n",
      "2200 steps | score: [-0.21184863150119781]\n",
      "2300 steps | score: [-0.24823495745658875]\n",
      "2400 steps | score: [-0.22220589220523834]\n",
      "2500 steps | score: [-0.21106627583503723]\n",
      "2600 steps | score: [-0.23107892274856567]\n",
      "2700 steps | score: [-0.23920121788978577]\n",
      "0 steps | score: [0.2231438010931015, -0.29768645763397217]\n",
      "100 steps | score: [0.30850285291671753, -0.7632291913032532]\n",
      "200 steps | score: [0.16150698065757751, -0.40796172618865967]\n",
      "300 steps | score: [-0.006291407160460949, -0.006874192506074905]\n",
      "unknown params:  tensor([-0.6703, -0.4798, -0.6859,  0.5294, -0.6108,  0.7562])\n",
      "gt params:  tensor([-0.7351, -0.5530, -0.7721,  0.5753, -0.6825,  0.5517])\n",
      "ols params:  tensor([-0.4559, -0.3330, -0.4636,  0.3640, -0.4263,  3.0588])\n",
      "unknown mse:  tensor(0.0110)\n",
      "ols mse:  tensor(1.1028)\n",
      "gt params:  tensor([-0.7144, -0.5839, -0.7587,  0.5691, -0.6877,  0.5275])\n",
      "0 steps | score: [0.18837933242321014]\n",
      "100 steps | score: [-0.07092277705669403]\n",
      "200 steps | score: [-0.07379326224327087]\n",
      "300 steps | score: [-0.06088763102889061]\n",
      "400 steps | score: [-0.05403709411621094]\n",
      "500 steps | score: [-0.031175468116998672]\n",
      "600 steps | score: [-0.07300258427858353]\n",
      "700 steps | score: [-0.04684055596590042]\n",
      "800 steps | score: [-0.0019141249358654022]\n",
      "0 steps | score: [0.19759759306907654, 0.12258458882570267]\n",
      "100 steps | score: [0.12184832245111465, 0.08901675045490265]\n",
      "200 steps | score: [-0.05315825343132019, 0.4480760097503662]\n",
      "300 steps | score: [0.24136421084403992, -0.3496643006801605]\n",
      "400 steps | score: [0.20238801836967468, -0.2701309323310852]\n",
      "500 steps | score: [0.360528826713562, -0.7188925743103027]\n",
      "600 steps | score: [-0.120262011885643, 0.6156768798828125]\n",
      "700 steps | score: [0.07992521673440933, 0.056848183274269104]\n",
      "800 steps | score: [0.1993313729763031, -0.28980353474617004]\n",
      "900 steps | score: [0.03383515030145645, 0.21545515954494476]\n",
      "1000 steps | score: [0.012201814912259579, 0.27977097034454346]\n",
      "1100 steps | score: [0.10265347361564636, 0.019699588418006897]\n",
      "1200 steps | score: [0.2274138331413269, -0.37718188762664795]\n",
      "1300 steps | score: [0.060642778873443604, 0.10926751792430878]\n",
      "1400 steps | score: [0.14424392580986023, -0.10325115919113159]\n",
      "1500 steps | score: [0.03183503448963165, 0.1681569218635559]\n",
      "1600 steps | score: [0.09248708188533783, 0.038704514503479004]\n",
      "1700 steps | score: [0.09894346445798874, 0.013355851173400879]\n",
      "1800 steps | score: [0.03296854719519615, 0.17878173291683197]\n",
      "1900 steps | score: [0.025600550696253777, 0.1893160045146942]\n",
      "2000 steps | score: [0.022743312641978264, 0.20104922354221344]\n",
      "2100 steps | score: [0.03005312941968441, 0.17770454287528992]\n",
      "2200 steps | score: [0.0211824718862772, 0.26841896772384644]\n",
      "2300 steps | score: [0.16195626556873322, -0.1908477246761322]\n",
      "2400 steps | score: [0.10513852536678314, 0.007610410451889038]\n",
      "2500 steps | score: [0.07959426939487457, 0.06375420093536377]\n",
      "2600 steps | score: [0.11295891553163528, -0.07132501900196075]\n",
      "2700 steps | score: [0.0658521056175232, 0.08440709114074707]\n",
      "unknown params:  tensor([-0.7059, -0.5774, -0.7554,  0.5457, -0.6626,  0.3922])\n",
      "gt params:  tensor([-0.7144, -0.5839, -0.7587,  0.5691, -0.6877,  0.5275])\n",
      "ols params:  tensor([-0.4179, -0.3435, -0.4445,  0.3210, -0.3906,  3.2513])\n",
      "unknown mse:  tensor(0.0033)\n",
      "ols mse:  tensor(1.3022)\n",
      "gt params:  tensor([-0.7334, -0.5908, -0.7593,  0.5958, -0.6742,  0.5455])\n",
      "0 steps | score: [0.2574822008609772]\n",
      "100 steps | score: [0.08081094920635223]\n",
      "200 steps | score: [0.03741778805851936]\n",
      "300 steps | score: [-0.006802605465054512]\n",
      "0 steps | score: [-0.002361413324251771, 0.2014048546552658]\n",
      "100 steps | score: [-0.14805449545383453, 0.349267840385437]\n",
      "200 steps | score: [-0.1175791472196579, 0.161662757396698]\n",
      "300 steps | score: [-0.2538175880908966, 0.5425209999084473]\n",
      "400 steps | score: [-0.1832994669675827, 0.37904733419418335]\n",
      "500 steps | score: [-0.2712422311306, 0.5453352332115173]\n",
      "600 steps | score: [0.34824424982070923, -1.2995753288269043]\n",
      "700 steps | score: [-0.17550426721572876, 0.2967727780342102]\n",
      "800 steps | score: [-0.006237989291548729, -0.15012219548225403]\n",
      "900 steps | score: [-0.1482277810573578, 0.2616601586341858]\n",
      "1000 steps | score: [-0.13970565795898438, 0.19244565069675446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 steps | score: [0.008970431983470917, -0.18463751673698425]\n",
      "1200 steps | score: [-0.22801755368709564, 0.4355529248714447]\n",
      "1300 steps | score: [0.07629728317260742, -0.42726629972457886]\n",
      "1400 steps | score: [-0.21263284981250763, 0.4192228317260742]\n",
      "1500 steps | score: [-0.23377491533756256, 0.4788282513618469]\n",
      "1600 steps | score: [-0.20700158178806305, 0.3887205719947815]\n",
      "1700 steps | score: [-0.09293104708194733, 0.04417509585618973]\n",
      "1800 steps | score: [-0.07985260337591171, 0.058802880346775055]\n",
      "1900 steps | score: [-0.056298062205314636, -0.002022393047809601]\n",
      "2000 steps | score: [-0.17074300348758698, 0.3129092752933502]\n",
      "2100 steps | score: [-0.11445366591215134, 0.11367816478013992]\n",
      "2200 steps | score: [-0.19925567507743835, 0.37715771794319153]\n",
      "2300 steps | score: [-0.034542493522167206, -0.10773701965808868]\n",
      "2400 steps | score: [-0.11713326722383499, 0.14468011260032654]\n",
      "2500 steps | score: [-0.12616302073001862, 0.19541575014591217]\n",
      "2600 steps | score: [-0.15015754103660583, 0.25365960597991943]\n",
      "unknown params:  tensor([-0.6872, -0.5185, -0.7099,  0.5812, -0.6587,  0.4082])\n",
      "gt params:  tensor([-0.7334, -0.5908, -0.7593,  0.5958, -0.6742,  0.5455])\n",
      "ols params:  tensor([-0.4253, -0.3272, -0.4385,  0.3631, -0.4089,  3.3710])\n",
      "unknown mse:  tensor(0.0049)\n",
      "ols mse:  tensor(1.3959)\n",
      "gt params:  tensor([-0.7262, -0.5813, -0.7561,  0.6050, -0.7033,  0.5227])\n",
      "0 steps | score: [0.230901837348938]\n",
      "100 steps | score: [-0.022603312507271767]\n",
      "200 steps | score: [0.026660166680812836]\n",
      "300 steps | score: [0.019207218661904335]\n",
      "400 steps | score: [0.06280425935983658]\n",
      "500 steps | score: [0.05529296398162842]\n",
      "600 steps | score: [-0.01685205101966858]\n",
      "700 steps | score: [0.051219530403614044]\n",
      "800 steps | score: [0.01876000501215458]\n",
      "900 steps | score: [-0.00078619085252285]\n",
      "0 steps | score: [0.1333225667476654, -0.2639850676059723]\n",
      "100 steps | score: [-0.1980568915605545, 0.34296324849128723]\n",
      "200 steps | score: [-0.20126549899578094, 0.27325817942619324]\n",
      "300 steps | score: [-0.08295826613903046, -0.013152815401554108]\n",
      "400 steps | score: [-0.06929158419370651, -0.052741147577762604]\n",
      "500 steps | score: [0.31068259477615356, -1.011997103691101]\n",
      "600 steps | score: [-0.1507091075181961, 0.1692168265581131]\n",
      "700 steps | score: [-0.006519023794680834, -0.18483194708824158]\n",
      "800 steps | score: [-0.06832176446914673, -0.0811368077993393]\n",
      "900 steps | score: [-0.11584610491991043, 0.03185819461941719]\n",
      "1000 steps | score: [-0.05178370326757431, -0.11547806113958359]\n",
      "1100 steps | score: [-0.10510466992855072, 0.05039306357502937]\n",
      "1200 steps | score: [0.02311466448009014, -0.25561800599098206]\n",
      "1300 steps | score: [-0.027136562392115593, -0.14736047387123108]\n",
      "1400 steps | score: [-0.06732787191867828, -0.06364596635103226]\n",
      "1500 steps | score: [-0.15934555232524872, 0.1483972817659378]\n",
      "1600 steps | score: [0.012149390764534473, -0.26578289270401]\n",
      "1700 steps | score: [-0.058057136833667755, -0.09308138489723206]\n",
      "1800 steps | score: [0.07444649934768677, -0.4384324550628662]\n",
      "1900 steps | score: [0.08520534634590149, -0.41565343737602234]\n",
      "2000 steps | score: [-0.058521512895822525, -0.11164459586143494]\n",
      "2100 steps | score: [-0.047150611877441406, -0.09222972393035889]\n",
      "2200 steps | score: [-0.05876068398356438, -0.09476930648088455]\n",
      "2300 steps | score: [-0.048923712223768234, -0.1131022498011589]\n",
      "2400 steps | score: [-0.07677816599607468, -0.052949193865060806]\n",
      "2500 steps | score: [-0.06127152591943741, -0.0583004355430603]\n",
      "2600 steps | score: [-0.09464653581380844, -0.009019576013088226]\n",
      "unknown params:  tensor([-0.7615, -0.5561, -0.7602,  0.5684, -0.7168,  0.3970])\n",
      "gt params:  tensor([-0.7262, -0.5813, -0.7561,  0.6050, -0.7033,  0.5227])\n",
      "ols params:  tensor([-0.4358, -0.3251, -0.4370,  0.3304, -0.4079,  3.4499])\n",
      "unknown mse:  tensor(0.0032)\n",
      "ols mse:  tensor(1.4972)\n",
      "gt params:  tensor([-0.7294, -0.5552, -0.7260,  0.5698, -0.6754,  0.5723])\n",
      "0 steps | score: [0.31358498334884644]\n",
      "100 steps | score: [0.05573173239827156]\n",
      "200 steps | score: [0.08632650226354599]\n",
      "300 steps | score: [0.05374392122030258]\n",
      "400 steps | score: [0.07508876174688339]\n",
      "500 steps | score: [0.041449032723903656]\n",
      "600 steps | score: [0.13014648854732513]\n",
      "700 steps | score: [0.06243394315242767]\n",
      "800 steps | score: [0.046568721532821655]\n",
      "900 steps | score: [0.1271088421344757]\n",
      "1000 steps | score: [0.05529925227165222]\n",
      "1100 steps | score: [0.11154135316610336]\n",
      "1200 steps | score: [0.10593121498823166]\n",
      "1300 steps | score: [0.12243503332138062]\n",
      "1400 steps | score: [0.10262131690979004]\n",
      "1500 steps | score: [0.10733045637607574]\n",
      "1600 steps | score: [0.08560065925121307]\n",
      "1700 steps | score: [0.13792496919631958]\n",
      "1800 steps | score: [0.09016764909029007]\n",
      "1900 steps | score: [0.109656423330307]\n",
      "2000 steps | score: [0.09268233925104141]\n",
      "2100 steps | score: [0.062956802546978]\n",
      "2200 steps | score: [0.10018454492092133]\n",
      "2300 steps | score: [0.12110474705696106]\n",
      "2400 steps | score: [0.10934807360172272]\n",
      "2500 steps | score: [0.09144468605518341]\n",
      "2600 steps | score: [0.0857037752866745]\n",
      "0 steps | score: [0.11536160111427307, 0.1273745596408844]\n",
      "100 steps | score: [-0.03307902067899704, 0.3054812550544739]\n",
      "200 steps | score: [0.4181941747665405, -0.9463266730308533]\n",
      "300 steps | score: [0.19973525404930115, -0.3778255581855774]\n",
      "400 steps | score: [-0.21083694696426392, 0.590968132019043]\n",
      "500 steps | score: [0.021135928109288216, 0.06648363918066025]\n",
      "600 steps | score: [0.16280440986156464, -0.3204856514930725]\n",
      "700 steps | score: [-0.23688797652721405, 0.6447612643241882]\n",
      "800 steps | score: [-0.300591379404068, 0.7842149138450623]\n",
      "900 steps | score: [0.062038879841566086, -0.0655071884393692]\n",
      "1000 steps | score: [-0.07237724959850311, 0.26588502526283264]\n",
      "1100 steps | score: [0.0757003054022789, -0.06624250113964081]\n",
      "1200 steps | score: [-0.02162603847682476, 0.1813535839319229]\n",
      "1300 steps | score: [-0.061243314296007156, 0.2551465928554535]\n",
      "1400 steps | score: [0.17562459409236908, -0.368583619594574]\n",
      "1500 steps | score: [-0.002443104749545455, 0.11604367196559906]\n",
      "1600 steps | score: [-0.06504581868648529, 0.24456843733787537]\n",
      "1700 steps | score: [0.07320872694253922, -0.10093994438648224]\n",
      "1800 steps | score: [-0.06048882007598877, 0.23446597158908844]\n",
      "1900 steps | score: [-0.10760960727930069, 0.3422805070877075]\n",
      "2000 steps | score: [-0.15317659080028534, 0.4425816535949707]\n",
      "2100 steps | score: [-0.11155910789966583, 0.35011783242225647]\n",
      "2200 steps | score: [0.023092610761523247, 0.03659042716026306]\n",
      "2300 steps | score: [-0.04410598427057266, 0.21657639741897583]\n",
      "2400 steps | score: [0.035143472254276276, 0.014329344034194946]\n",
      "2500 steps | score: [0.029720302671194077, 0.05871155112981796]\n",
      "2600 steps | score: [-0.09406591951847076, 0.32628363370895386]\n",
      "unknown params:  tensor([-0.6584, -0.5373, -0.7251,  0.5638, -0.6589,  0.4375])\n",
      "gt params:  tensor([-0.7294, -0.5552, -0.7260,  0.5698, -0.6754,  0.5723])\n",
      "ols params:  tensor([-0.3787, -0.3172, -0.4193,  0.3302, -0.3826,  3.5775])\n",
      "unknown mse:  tensor(0.0040)\n",
      "ols mse:  tensor(1.5747)\n",
      "gt params:  tensor([-0.6865, -0.5841, -0.7800,  0.5896, -0.6853,  0.5671])\n",
      "0 steps | score: [0.2548331916332245]\n",
      "100 steps | score: [0.13373231887817383]\n",
      "200 steps | score: [-0.007749419659376144]\n",
      "0 steps | score: [0.10528687387704849, 0.3064161241054535]\n",
      "100 steps | score: [0.015620417892932892, 0.3445533514022827]\n",
      "200 steps | score: [-0.18839819729328156, 0.7503904700279236]\n",
      "300 steps | score: [-0.0779419094324112, 0.4721815586090088]\n",
      "400 steps | score: [-0.14098922908306122, 0.5724517107009888]\n",
      "500 steps | score: [-0.21912868320941925, 0.7461881637573242]\n",
      "600 steps | score: [0.0363115631043911, 0.2028597742319107]\n",
      "700 steps | score: [-0.09691470116376877, 0.47360455989837646]\n",
      "800 steps | score: [-0.05901242047548294, 0.40228626132011414]\n",
      "900 steps | score: [-0.12209470570087433, 0.5405426621437073]\n",
      "1000 steps | score: [-0.15514132380485535, 0.6009075045585632]\n",
      "1100 steps | score: [-0.15705358982086182, 0.6074313521385193]\n",
      "1200 steps | score: [-0.1546923816204071, 0.6326515078544617]\n",
      "1300 steps | score: [-0.1726633459329605, 0.6488991975784302]\n",
      "1400 steps | score: [-0.007123165298253298, 0.2577112317085266]\n",
      "1500 steps | score: [0.012994051910936832, 0.22685444355010986]\n",
      "1600 steps | score: [-0.06573891639709473, 0.3666234016418457]\n",
      "1700 steps | score: [0.007458453997969627, 0.2163211852312088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 steps | score: [-0.03964206203818321, 0.33762869238853455]\n",
      "1900 steps | score: [-0.1306801587343216, 0.5405369997024536]\n",
      "2000 steps | score: [-0.16534310579299927, 0.624645471572876]\n",
      "2100 steps | score: [-0.09778187423944473, 0.4596070647239685]\n",
      "2200 steps | score: [-0.12443240731954575, 0.5435709357261658]\n",
      "2300 steps | score: [-0.07061012834310532, 0.41212838888168335]\n",
      "2400 steps | score: [-0.11251406371593475, 0.5237221121788025]\n",
      "2500 steps | score: [-0.04662352800369263, 0.39015281200408936]\n",
      "2600 steps | score: [-0.07366973161697388, 0.44159719347953796]\n",
      "unknown params:  tensor([-0.7013, -0.6046, -0.7997,  0.5885, -0.6885,  0.2144])\n",
      "gt params:  tensor([-0.6865, -0.5841, -0.7800,  0.5896, -0.6853,  0.5671])\n",
      "ols params:  tensor([-0.3840, -0.3344, -0.4373,  0.3263, -0.3742,  3.6581])\n",
      "unknown mse:  tensor(0.0209)\n",
      "ols mse:  tensor(1.6652)\n",
      "gt params:  tensor([-0.7376, -0.5543, -0.7468,  0.5906, -0.6723,  0.5669])\n",
      "0 steps | score: [0.16850146651268005]\n",
      "100 steps | score: [0.03626890107989311]\n",
      "200 steps | score: [-0.10892853140830994]\n",
      "300 steps | score: [-0.06395307928323746]\n",
      "400 steps | score: [-0.11595478653907776]\n",
      "500 steps | score: [-0.10226482897996902]\n",
      "600 steps | score: [-0.07605551183223724]\n",
      "700 steps | score: [-0.08463341742753983]\n",
      "800 steps | score: [-0.11014100909233093]\n",
      "900 steps | score: [-0.10793332755565643]\n",
      "1000 steps | score: [-0.09594467282295227]\n",
      "1100 steps | score: [-0.10792384296655655]\n",
      "1200 steps | score: [-0.057918570935726166]\n",
      "1300 steps | score: [-0.11889943480491638]\n",
      "1400 steps | score: [-0.09900175034999847]\n",
      "1500 steps | score: [-0.1001339852809906]\n",
      "1600 steps | score: [-0.0976467952132225]\n",
      "1700 steps | score: [-0.09129882603883743]\n",
      "1800 steps | score: [-0.050642021000385284]\n",
      "1900 steps | score: [-0.09001436084508896]\n",
      "2000 steps | score: [-0.12948524951934814]\n",
      "2100 steps | score: [-0.11315563321113586]\n",
      "2200 steps | score: [-0.11084902286529541]\n",
      "2300 steps | score: [-0.09709188342094421]\n",
      "2400 steps | score: [-0.09330238401889801]\n",
      "2500 steps | score: [-0.12150775641202927]\n",
      "2600 steps | score: [-0.12587523460388184]\n",
      "2700 steps | score: [-0.10123772919178009]\n",
      "0 steps | score: [0.3190768361091614, -0.32526782155036926]\n",
      "100 steps | score: [0.13037775456905365, -0.04544520378112793]\n",
      "200 steps | score: [0.35593757033348083, -0.7057317495346069]\n",
      "300 steps | score: [0.24781453609466553, -0.44293493032455444]\n",
      "400 steps | score: [0.24301789700984955, -0.4458719491958618]\n",
      "500 steps | score: [0.10524702072143555, -0.14124031364917755]\n",
      "600 steps | score: [0.12522822618484497, -0.16679513454437256]\n",
      "700 steps | score: [0.07988908141851425, -0.03184311091899872]\n",
      "800 steps | score: [0.3065953254699707, -0.6322422623634338]\n",
      "900 steps | score: [0.07342907041311264, -0.050036631524562836]\n",
      "1000 steps | score: [0.19105064868927002, -0.38658690452575684]\n",
      "1100 steps | score: [-0.006509178318083286, 0.12813220918178558]\n",
      "1200 steps | score: [0.118415467441082, -0.12462910264730453]\n",
      "1300 steps | score: [-0.004639502614736557, 0.12864811718463898]\n",
      "1400 steps | score: [0.11872778832912445, -0.1507350504398346]\n",
      "1500 steps | score: [0.17098146677017212, -0.28100618720054626]\n",
      "1600 steps | score: [0.15329967439174652, -0.2729097008705139]\n",
      "1700 steps | score: [0.19113726913928986, -0.36919695138931274]\n",
      "1800 steps | score: [0.2248889058828354, -0.4182157516479492]\n",
      "1900 steps | score: [0.1329602301120758, -0.1682794690132141]\n",
      "2000 steps | score: [0.09148277342319489, -0.09034274518489838]\n",
      "2100 steps | score: [0.16993138194084167, -0.27185413241386414]\n",
      "2200 steps | score: [0.15703096985816956, -0.25749558210372925]\n",
      "2300 steps | score: [0.2383388727903366, -0.43423858284950256]\n",
      "2400 steps | score: [0.13945749402046204, -0.22021259367465973]\n",
      "2500 steps | score: [0.14622972905635834, -0.23263320326805115]\n",
      "2600 steps | score: [0.22639869153499603, -0.4387299716472626]\n",
      "2700 steps | score: [0.11835256218910217, -0.17521634697914124]\n",
      "unknown params:  tensor([-0.7390, -0.5489, -0.7117,  0.5546, -0.6185,  0.3204])\n",
      "gt params:  tensor([-0.7376, -0.5543, -0.7468,  0.5906, -0.6723,  0.5669])\n",
      "ols params:  tensor([-0.4099, -0.3095, -0.3974,  0.3107, -0.3501,  3.8080])\n",
      "unknown mse:  tensor(0.0110)\n",
      "ols mse:  tensor(1.8295)\n",
      "gt params:  tensor([-0.7074, -0.5584, -0.7381,  0.5358, -0.6642,  0.5564])\n",
      "0 steps | score: [0.2757439613342285]\n",
      "100 steps | score: [0.0082955127581954]\n",
      "0 steps | score: [0.2866480052471161, -0.3494531512260437]\n",
      "100 steps | score: [0.08066180348396301, -0.05974534526467323]\n",
      "200 steps | score: [0.2778201103210449, -0.5259619951248169]\n",
      "300 steps | score: [-0.20870664715766907, 0.45985379815101624]\n",
      "400 steps | score: [-0.16373534500598907, 0.37598586082458496]\n",
      "500 steps | score: [-0.06561052799224854, 0.15292847156524658]\n",
      "600 steps | score: [0.10218265652656555, -0.16267237067222595]\n",
      "700 steps | score: [0.29397737979888916, -0.675767183303833]\n",
      "800 steps | score: [-0.04081397503614426, 0.13864827156066895]\n",
      "900 steps | score: [-0.02824436128139496, 0.08806648850440979]\n",
      "1000 steps | score: [0.08290242403745651, -0.16586081683635712]\n",
      "1100 steps | score: [0.17576704919338226, -0.34051260352134705]\n",
      "1200 steps | score: [-0.017408302053809166, 0.06346401572227478]\n",
      "1300 steps | score: [0.09352083504199982, -0.19251850247383118]\n",
      "1400 steps | score: [0.04975414276123047, -0.08637186884880066]\n",
      "1500 steps | score: [0.1029939129948616, -0.20535750687122345]\n",
      "1600 steps | score: [0.11527509242296219, -0.24731962382793427]\n",
      "1700 steps | score: [0.14122958481311798, -0.27884146571159363]\n",
      "1800 steps | score: [0.06749481707811356, -0.1393522024154663]\n",
      "1900 steps | score: [-0.030229659751057625, 0.0734771117568016]\n",
      "2000 steps | score: [0.024279871955513954, -0.03568089008331299]\n",
      "2100 steps | score: [0.002337909070774913, 0.018114302307367325]\n",
      "2200 steps | score: [0.08799552172422409, -0.18612167239189148]\n",
      "2300 steps | score: [0.12407668679952621, -0.2494034469127655]\n",
      "2400 steps | score: [0.11929992586374283, -0.2505483627319336]\n",
      "2500 steps | score: [0.002049187198281288, 0.02400495857000351]\n",
      "2600 steps | score: [0.07905546575784683, -0.16266441345214844]\n",
      "unknown params:  tensor([-0.7284, -0.6132, -0.7664,  0.5339, -0.6441,  0.2225])\n",
      "gt params:  tensor([-0.7074, -0.5584, -0.7381,  0.5358, -0.6642,  0.5564])\n",
      "ols params:  tensor([-0.3941, -0.3356, -0.4102,  0.2942, -0.3517,  3.8431])\n",
      "unknown mse:  tensor(0.0194)\n",
      "ols mse:  tensor(1.8690)\n",
      "gt params:  tensor([-0.7226, -0.5569, -0.7555,  0.5774, -0.7021,  0.5381])\n",
      "0 steps | score: [0.3033955991268158]\n",
      "100 steps | score: [0.08129607886075974]\n",
      "200 steps | score: [0.05888126790523529]\n",
      "300 steps | score: [0.05359944328665733]\n",
      "400 steps | score: [0.05360615253448486]\n",
      "500 steps | score: [0.04561486840248108]\n",
      "600 steps | score: [0.01628851890563965]\n",
      "700 steps | score: [0.0199727863073349]\n",
      "800 steps | score: [0.11015769094228745]\n",
      "900 steps | score: [0.02134033292531967]\n",
      "1000 steps | score: [0.01708364486694336]\n",
      "1100 steps | score: [0.02604895830154419]\n",
      "1200 steps | score: [0.027505580335855484]\n",
      "1300 steps | score: [0.08003382384777069]\n",
      "1400 steps | score: [0.021015428006649017]\n",
      "1500 steps | score: [0.04461279511451721]\n",
      "1600 steps | score: [0.035455431789159775]\n",
      "1700 steps | score: [0.051621586084365845]\n",
      "1800 steps | score: [0.0541248694062233]\n",
      "1900 steps | score: [0.06694084405899048]\n",
      "2000 steps | score: [0.0632004365324974]\n",
      "2100 steps | score: [0.06439855694770813]\n",
      "2200 steps | score: [0.020191214978694916]\n",
      "2300 steps | score: [0.052386924624443054]\n",
      "2400 steps | score: [0.04169829189777374]\n",
      "2500 steps | score: [0.05161313712596893]\n",
      "2600 steps | score: [0.047237370163202286]\n",
      "0 steps | score: [0.16637356579303741, -0.04723618924617767]\n",
      "100 steps | score: [0.1784292608499527, -0.24036209285259247]\n",
      "200 steps | score: [0.2152133285999298, -0.3407663106918335]\n",
      "300 steps | score: [-0.06767532974481583, 0.27452999353408813]\n",
      "400 steps | score: [0.07638463377952576, -0.09507139772176743]\n",
      "500 steps | score: [0.012109760195016861, 0.025219671428203583]\n",
      "600 steps | score: [0.14772279560565948, -0.280987411737442]\n",
      "700 steps | score: [0.01995616964995861, 0.040296077728271484]\n",
      "800 steps | score: [0.3567512631416321, -0.7831579446792603]\n",
      "900 steps | score: [0.04235276207327843, -0.0248740091919899]\n",
      "1000 steps | score: [-0.10234063118696213, 0.32560867071151733]\n",
      "1100 steps | score: [-0.08998273313045502, 0.2744531035423279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 steps | score: [-0.06464829295873642, 0.21371962130069733]\n",
      "1300 steps | score: [0.006860456895083189, 0.0607411190867424]\n",
      "1400 steps | score: [-0.1552344113588333, 0.43401721119880676]\n",
      "1500 steps | score: [0.00972219742834568, 0.06687270104885101]\n",
      "1600 steps | score: [0.01643255352973938, 0.04161129146814346]\n",
      "1700 steps | score: [0.058365579694509506, -0.07524437457323074]\n",
      "1800 steps | score: [-0.012670631520450115, 0.10005133599042892]\n",
      "1900 steps | score: [-0.01620744727551937, 0.13373565673828125]\n",
      "2000 steps | score: [0.04657154902815819, -0.03537657484412193]\n",
      "2100 steps | score: [0.07222035527229309, -0.1253553032875061]\n",
      "2200 steps | score: [-0.008085554465651512, 0.1063135415315628]\n",
      "2300 steps | score: [0.03386392071843147, -0.009025633335113525]\n",
      "2400 steps | score: [0.09904757887125015, -0.19540315866470337]\n",
      "2500 steps | score: [-0.028540534898638725, 0.1539207100868225]\n",
      "2600 steps | score: [-0.04764226824045181, 0.17017704248428345]\n",
      "unknown params:  tensor([-0.7748, -0.5298, -0.7636,  0.5706, -0.7137,  0.3720])\n",
      "gt params:  tensor([-0.7226, -0.5569, -0.7555,  0.5774, -0.7021,  0.5381])\n",
      "ols params:  tensor([-0.4024, -0.2814, -0.4005,  0.2984, -0.3743,  4.0005])\n",
      "unknown mse:  tensor(0.0052)\n",
      "ols mse:  tensor(2.0797)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/a4d942ff-475c-4381-9eab-7422b988f989\n",
      "gt params:  tensor([ 0.6746, -0.3268,  0.6565,  0.6138, -0.0626, -0.1078])\n",
      "0 steps | score: [0.004622284322977066]\n",
      "100 steps | score: [-0.2585614025592804]\n",
      "200 steps | score: [-0.0965815931558609]\n",
      "300 steps | score: [-0.08629412949085236]\n",
      "400 steps | score: [-0.1317121535539627]\n",
      "500 steps | score: [-0.13924401998519897]\n",
      "600 steps | score: [-0.23792563378810883]\n",
      "700 steps | score: [-0.10444648563861847]\n",
      "800 steps | score: [-0.09964191913604736]\n",
      "900 steps | score: [-0.12258276343345642]\n",
      "1000 steps | score: [-0.13329218327999115]\n",
      "1100 steps | score: [-0.18781469762325287]\n",
      "1200 steps | score: [-0.14148034155368805]\n",
      "1300 steps | score: [-0.12864388525485992]\n",
      "1400 steps | score: [-0.1471305638551712]\n",
      "1500 steps | score: [-0.09858256578445435]\n",
      "1600 steps | score: [-0.13732019066810608]\n",
      "1700 steps | score: [-0.11307520419359207]\n",
      "1800 steps | score: [-0.11862564831972122]\n",
      "1900 steps | score: [-0.12232200801372528]\n",
      "2000 steps | score: [-0.09097128361463547]\n",
      "2100 steps | score: [-0.15773950517177582]\n",
      "2200 steps | score: [-0.13377989828586578]\n",
      "2300 steps | score: [-0.10580875724554062]\n",
      "2400 steps | score: [-0.11359043419361115]\n",
      "2500 steps | score: [-0.15161707997322083]\n",
      "2600 steps | score: [-0.14927449822425842]\n",
      "2700 steps | score: [-0.17551259696483612]\n",
      "2800 steps | score: [-0.1210445910692215]\n",
      "2900 steps | score: [-0.13130877912044525]\n",
      "0 steps | score: [0.005021711811423302, 0.3531724214553833]\n",
      "100 steps | score: [-0.929299533367157, 3.5276732444763184]\n",
      "200 steps | score: [0.4571384787559509, -2.2122416496276855]\n",
      "300 steps | score: [-0.10679243505001068, 0.5635610222816467]\n",
      "400 steps | score: [-0.3843090832233429, 1.626523733139038]\n",
      "500 steps | score: [-0.4430433213710785, 1.8025084733963013]\n",
      "600 steps | score: [-0.49894896149635315, 1.879523515701294]\n",
      "700 steps | score: [0.34932154417037964, -2.0633912086486816]\n",
      "800 steps | score: [-0.49588462710380554, 1.9844189882278442]\n",
      "900 steps | score: [-0.1412937194108963, 0.46324944496154785]\n",
      "1000 steps | score: [-0.03751092031598091, -0.05486265942454338]\n",
      "1100 steps | score: [-0.19762323796749115, 0.6229890584945679]\n",
      "1200 steps | score: [-0.08067844063043594, 0.06458373367786407]\n",
      "1300 steps | score: [-0.09315992891788483, 0.1833559274673462]\n",
      "1400 steps | score: [-0.12669390439987183, 0.3249734342098236]\n",
      "1500 steps | score: [-0.13577508926391602, 0.44010013341903687]\n",
      "1600 steps | score: [-0.18511664867401123, 0.5844994187355042]\n",
      "1700 steps | score: [0.055857013911008835, -0.6270332336425781]\n",
      "1800 steps | score: [-0.18625004589557648, 0.5776001214981079]\n",
      "1900 steps | score: [0.049731913954019547, -0.44586119055747986]\n",
      "2000 steps | score: [-0.16033302247524261, 0.5049496293067932]\n",
      "2100 steps | score: [-0.1916780024766922, 0.694348156452179]\n",
      "2200 steps | score: [-0.08669984340667725, 0.08091054856777191]\n",
      "2300 steps | score: [-0.11724983900785446, 0.2817526161670685]\n",
      "2400 steps | score: [0.059861548244953156, -0.48844605684280396]\n",
      "2500 steps | score: [-0.18196135759353638, 0.5326409935951233]\n",
      "2600 steps | score: [-0.2663291096687317, 0.9795889258384705]\n",
      "2700 steps | score: [-0.05135399103164673, -0.0283108651638031]\n",
      "2800 steps | score: [-0.10661030560731888, 0.2915639579296112]\n",
      "2900 steps | score: [-0.04387510195374489, -0.1397276222705841]\n",
      "unknown params:  tensor([ 0.6694, -0.3235,  0.6504,  0.6132, -0.0690, -0.1161])\n",
      "gt params:  tensor([ 0.6746, -0.3268,  0.6565,  0.6138, -0.0626, -0.1078])\n",
      "ols params:  tensor([ 0.5847, -0.2875,  0.5709,  0.5355, -0.0577,  0.4587])\n",
      "unknown mse:  tensor(3.0702e-05)\n",
      "ols mse:  tensor(0.0573)\n",
      "gt params:  tensor([ 0.6791, -0.3250,  0.6706,  0.6144, -0.0721, -0.0961])\n",
      "0 steps | score: [0.1709747314453125]\n",
      "100 steps | score: [0.03205246850848198]\n",
      "200 steps | score: [-0.033129509538412094]\n",
      "300 steps | score: [0.18323081731796265]\n",
      "400 steps | score: [-0.051808953285217285]\n",
      "500 steps | score: [-0.04437786340713501]\n",
      "600 steps | score: [-0.043652161955833435]\n",
      "700 steps | score: [-0.007726121693849564]\n",
      "0 steps | score: [0.36383306980133057, -0.6128150820732117]\n",
      "100 steps | score: [-0.16267429292201996, 0.7351853251457214]\n",
      "200 steps | score: [0.12344043701887131, -0.19575299322605133]\n",
      "300 steps | score: [0.5768955945968628, -1.8372496366500854]\n",
      "400 steps | score: [0.3104948103427887, -0.8816676735877991]\n",
      "500 steps | score: [0.10497847944498062, -0.18105337023735046]\n",
      "600 steps | score: [0.00703771784901619, 0.10320839285850525]\n",
      "700 steps | score: [0.20006035268306732, -0.4759633541107178]\n",
      "800 steps | score: [0.15418389439582825, -0.32692280411720276]\n",
      "900 steps | score: [0.35157066583633423, -1.0407297611236572]\n",
      "1000 steps | score: [0.03420817106962204, 0.018494606018066406]\n",
      "1100 steps | score: [0.3740747570991516, -1.1252405643463135]\n",
      "1200 steps | score: [0.28499072790145874, -0.774150013923645]\n",
      "1300 steps | score: [0.21371883153915405, -0.5589134693145752]\n",
      "1400 steps | score: [0.2448122203350067, -0.6173401474952698]\n",
      "1500 steps | score: [0.07417377829551697, -0.10131499171257019]\n",
      "1600 steps | score: [0.21548648178577423, -0.6150943636894226]\n",
      "1700 steps | score: [0.19538013637065887, -0.528654932975769]\n",
      "1800 steps | score: [0.26714903116226196, -0.726575493812561]\n",
      "1900 steps | score: [0.19258002936840057, -0.5050477385520935]\n",
      "2000 steps | score: [0.108244888484478, -0.22740289568901062]\n",
      "2100 steps | score: [0.19023439288139343, -0.4941175580024719]\n",
      "2200 steps | score: [0.17227619886398315, -0.4405933618545532]\n",
      "2300 steps | score: [0.18584832549095154, -0.4615272581577301]\n",
      "2400 steps | score: [0.18260101974010468, -0.4864080548286438]\n",
      "2500 steps | score: [0.14619170129299164, -0.35960590839385986]\n",
      "2600 steps | score: [0.1630210280418396, -0.44968533515930176]\n",
      "2700 steps | score: [0.15264074504375458, -0.3635130524635315]\n",
      "2800 steps | score: [0.1773100048303604, -0.474541038274765]\n",
      "2900 steps | score: [0.24877683818340302, -0.6640408039093018]\n",
      "unknown params:  tensor([ 0.6671, -0.3161,  0.6620,  0.6067, -0.0800, -0.0105])\n",
      "gt params:  tensor([ 0.6791, -0.3250,  0.6706,  0.6144, -0.0721, -0.0961])\n",
      "ols params:  tensor([ 0.5238, -0.2531,  0.5193,  0.4783, -0.0604,  0.9375])\n",
      "unknown mse:  tensor(0.0013)\n",
      "ols mse:  tensor(0.1899)\n",
      "gt params:  tensor([ 0.6695, -0.3250,  0.6674,  0.6063, -0.0807, -0.1079])\n",
      "0 steps | score: [0.28877174854278564]\n",
      "100 steps | score: [0.013079274445772171]\n",
      "200 steps | score: [0.09218914806842804]\n",
      "300 steps | score: [0.10777966678142548]\n",
      "400 steps | score: [0.03321140632033348]\n",
      "500 steps | score: [0.12660421431064606]\n",
      "600 steps | score: [0.05362493917346001]\n",
      "700 steps | score: [0.11093930900096893]\n",
      "800 steps | score: [0.061384715139865875]\n",
      "900 steps | score: [0.08692923188209534]\n",
      "1000 steps | score: [0.10431107878684998]\n",
      "1100 steps | score: [0.04983311519026756]\n",
      "1200 steps | score: [0.11673417687416077]\n",
      "1300 steps | score: [0.09681280702352524]\n",
      "1400 steps | score: [0.08164697885513306]\n",
      "1500 steps | score: [0.11766771972179413]\n",
      "1600 steps | score: [0.07481255382299423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 steps | score: [0.09134408831596375]\n",
      "1800 steps | score: [0.07798430323600769]\n",
      "1900 steps | score: [0.12385174632072449]\n",
      "2000 steps | score: [0.09455074369907379]\n",
      "2100 steps | score: [0.08701328188180923]\n",
      "2200 steps | score: [0.12175367772579193]\n",
      "2300 steps | score: [0.10182394832372665]\n",
      "2400 steps | score: [0.08427564799785614]\n",
      "2500 steps | score: [0.1078108549118042]\n",
      "2600 steps | score: [0.08175741136074066]\n",
      "2700 steps | score: [0.07956485450267792]\n",
      "2800 steps | score: [0.07249222695827484]\n",
      "2900 steps | score: [0.10585645586252213]\n",
      "0 steps | score: [-0.02616828866302967, 0.38264548778533936]\n",
      "100 steps | score: [-0.20306777954101562, 0.70256507396698]\n",
      "200 steps | score: [-0.2117883265018463, 0.665002703666687]\n",
      "300 steps | score: [-0.1866806447505951, 0.5474919080734253]\n",
      "400 steps | score: [-0.32634711265563965, 0.9843765497207642]\n",
      "500 steps | score: [0.02159014716744423, -0.04570874571800232]\n",
      "600 steps | score: [-0.013945491053164005, 0.05508981645107269]\n",
      "700 steps | score: [-0.2558023929595947, 0.7270364165306091]\n",
      "800 steps | score: [-0.1466020941734314, 0.4377187192440033]\n",
      "900 steps | score: [-0.10048481076955795, 0.2589623034000397]\n",
      "1000 steps | score: [-0.24743279814720154, 0.702897310256958]\n",
      "1100 steps | score: [-0.33946654200553894, 0.946443498134613]\n",
      "1200 steps | score: [-0.02338443137705326, 0.0787055566906929]\n",
      "1300 steps | score: [-0.16757360100746155, 0.4607577919960022]\n",
      "1400 steps | score: [-0.2788933217525482, 0.7724064588546753]\n",
      "1500 steps | score: [-0.11128868907690048, 0.34421807527542114]\n",
      "1600 steps | score: [-0.1252538412809372, 0.36314406991004944]\n",
      "1700 steps | score: [-0.18741855025291443, 0.5712632536888123]\n",
      "1800 steps | score: [-0.19106043875217438, 0.5541906952857971]\n",
      "1900 steps | score: [-0.11548427492380142, 0.338300496339798]\n",
      "2000 steps | score: [-0.19619807600975037, 0.6010985374450684]\n",
      "2100 steps | score: [-0.10468653589487076, 0.25882476568222046]\n",
      "2200 steps | score: [-0.09980258345603943, 0.31155925989151]\n",
      "2300 steps | score: [-0.25223639607429504, 0.7384955286979675]\n",
      "2400 steps | score: [-0.12383393943309784, 0.3877015709877014]\n",
      "2500 steps | score: [-0.1914992779493332, 0.5735815167427063]\n",
      "2600 steps | score: [-0.20333370566368103, 0.6072067022323608]\n",
      "2700 steps | score: [-0.2051467001438141, 0.5765682458877563]\n",
      "2800 steps | score: [-0.20359744131565094, 0.6126609444618225]\n",
      "2900 steps | score: [-0.12090088427066803, 0.37152299284935]\n",
      "unknown params:  tensor([ 0.6722, -0.3072,  0.6578,  0.6153, -0.0763, -0.0782])\n",
      "gt params:  tensor([ 0.6695, -0.3250,  0.6674,  0.6063, -0.0807, -0.1079])\n",
      "ols params:  tensor([ 0.4886, -0.2311,  0.4757,  0.4431, -0.0530,  1.2246])\n",
      "unknown mse:  tensor(0.0002)\n",
      "ols mse:  tensor(0.3135)\n",
      "gt params:  tensor([ 0.6839, -0.3237,  0.6611,  0.6256, -0.0734, -0.1029])\n",
      "0 steps | score: [0.07946453988552094]\n",
      "100 steps | score: [-0.19183993339538574]\n",
      "200 steps | score: [-0.055936358869075775]\n",
      "300 steps | score: [-0.06509518623352051]\n",
      "400 steps | score: [-0.059815868735313416]\n",
      "500 steps | score: [-0.11354675143957138]\n",
      "600 steps | score: [-0.1897776573896408]\n",
      "700 steps | score: [-0.04553217068314552]\n",
      "800 steps | score: [-0.1416047215461731]\n",
      "900 steps | score: [-0.0695909708738327]\n",
      "1000 steps | score: [-0.11206155270338058]\n",
      "1100 steps | score: [-0.1556072235107422]\n",
      "1200 steps | score: [-0.11458656191825867]\n",
      "1300 steps | score: [-0.10791667550802231]\n",
      "1400 steps | score: [-0.1159389466047287]\n",
      "1500 steps | score: [-0.10914245247840881]\n",
      "1600 steps | score: [-0.14658276736736298]\n",
      "1700 steps | score: [-0.11569304764270782]\n",
      "1800 steps | score: [-0.12660373747348785]\n",
      "1900 steps | score: [-0.09121370315551758]\n",
      "2000 steps | score: [-0.12244316935539246]\n",
      "2100 steps | score: [-0.1387750804424286]\n",
      "2200 steps | score: [-0.09262371063232422]\n",
      "2300 steps | score: [-0.1100572720170021]\n",
      "2400 steps | score: [-0.1009252741932869]\n",
      "2500 steps | score: [-0.10889486968517303]\n",
      "2600 steps | score: [-0.11162915825843811]\n",
      "2700 steps | score: [-0.10971041023731232]\n",
      "2800 steps | score: [-0.10998991131782532]\n",
      "2900 steps | score: [-0.09183067083358765]\n",
      "0 steps | score: [0.022410957142710686, -0.008996397256851196]\n",
      "100 steps | score: [-0.2841150760650635, 0.6077460050582886]\n",
      "200 steps | score: [-0.17176824808120728, 0.2264065444469452]\n",
      "300 steps | score: [-0.02784803882241249, -0.19906675815582275]\n",
      "400 steps | score: [0.05549308657646179, -0.38169604539871216]\n",
      "500 steps | score: [-0.0654488354921341, -0.09752024710178375]\n",
      "600 steps | score: [-0.25802484154701233, 0.44664624333381653]\n",
      "700 steps | score: [0.012544834986329079, -0.4024330675601959]\n",
      "800 steps | score: [-0.22228574752807617, 0.32439225912094116]\n",
      "900 steps | score: [-0.02027035318315029, -0.20469416677951813]\n",
      "1000 steps | score: [-0.2441859096288681, 0.39450111985206604]\n",
      "1100 steps | score: [-0.1979629099369049, 0.20820704102516174]\n",
      "1200 steps | score: [-0.19164933264255524, 0.2082524597644806]\n",
      "1300 steps | score: [-0.14269192516803741, 0.10949097573757172]\n",
      "1400 steps | score: [-0.1391882300376892, 0.06820838153362274]\n",
      "1500 steps | score: [-0.2695505917072296, 0.42761996388435364]\n",
      "1600 steps | score: [-0.12075315415859222, 0.0009582936763763428]\n",
      "1700 steps | score: [-0.11516954749822617, 0.019621334969997406]\n",
      "1800 steps | score: [-0.21650943160057068, 0.3236124813556671]\n",
      "1900 steps | score: [-0.11234907060861588, 0.039321787655353546]\n",
      "2000 steps | score: [-0.20321549475193024, 0.30302920937538147]\n",
      "2100 steps | score: [-0.09341628849506378, -0.029256679117679596]\n",
      "2200 steps | score: [-0.09575612097978592, -0.058333635330200195]\n",
      "2300 steps | score: [-0.21360190212726593, 0.26837629079818726]\n",
      "2400 steps | score: [-0.10599124431610107, 0.034072522073984146]\n",
      "2500 steps | score: [-0.19954213500022888, 0.22302936017513275]\n",
      "2600 steps | score: [-0.07245134562253952, -0.0718999132514]\n",
      "2700 steps | score: [-0.10783669352531433, 0.006059285253286362]\n",
      "2800 steps | score: [-0.17802956700325012, 0.1781860888004303]\n",
      "2900 steps | score: [-0.09553983062505722, -0.045284807682037354]\n",
      "unknown params:  tensor([ 0.7017, -0.3230,  0.6681,  0.6691, -0.0646, -0.0696])\n",
      "gt params:  tensor([ 0.6839, -0.3237,  0.6611,  0.6256, -0.0734, -0.1029])\n",
      "ols params:  tensor([ 0.4682, -0.2212,  0.4466,  0.4441, -0.0450,  1.4808])\n",
      "unknown mse:  tensor(0.0006)\n",
      "ols mse:  tensor(0.4408)\n",
      "gt params:  tensor([ 0.6846, -0.3273,  0.6600,  0.6092, -0.0755, -0.0757])\n",
      "0 steps | score: [0.34774041175842285]\n",
      "100 steps | score: [0.11316584795713425]\n",
      "200 steps | score: [0.2926889955997467]\n",
      "300 steps | score: [0.22108836472034454]\n",
      "400 steps | score: [0.1456250548362732]\n",
      "500 steps | score: [0.21599657833576202]\n",
      "600 steps | score: [0.13507425785064697]\n",
      "700 steps | score: [0.27632343769073486]\n",
      "800 steps | score: [0.22803367674350739]\n",
      "900 steps | score: [0.12523439526557922]\n",
      "1000 steps | score: [0.14528387784957886]\n",
      "1100 steps | score: [0.15626773238182068]\n",
      "1200 steps | score: [0.21517494320869446]\n",
      "1300 steps | score: [0.20474576950073242]\n",
      "1400 steps | score: [0.19373182952404022]\n",
      "1500 steps | score: [0.1579776108264923]\n",
      "1600 steps | score: [0.14564789831638336]\n",
      "1700 steps | score: [0.17056486010551453]\n",
      "1800 steps | score: [0.18568548560142517]\n",
      "1900 steps | score: [0.16135665774345398]\n",
      "2000 steps | score: [0.15999141335487366]\n",
      "2100 steps | score: [0.14980116486549377]\n",
      "2200 steps | score: [0.17476946115493774]\n",
      "2300 steps | score: [0.20101973414421082]\n",
      "2400 steps | score: [0.1469367891550064]\n",
      "2500 steps | score: [0.1604921668767929]\n",
      "2600 steps | score: [0.15563002228736877]\n",
      "2700 steps | score: [0.17073550820350647]\n",
      "2800 steps | score: [0.17476342618465424]\n",
      "2900 steps | score: [0.16443468630313873]\n",
      "0 steps | score: [-0.18721841275691986, 0.7052655220031738]\n",
      "100 steps | score: [-0.4534545838832855, 1.2179081439971924]\n",
      "200 steps | score: [-0.14886106550693512, 0.29120397567749023]\n",
      "300 steps | score: [-0.2791959047317505, 0.667242705821991]\n",
      "400 steps | score: [-0.24632583558559418, 0.5967233180999756]\n",
      "500 steps | score: [0.44753241539001465, -2.217364549636841]\n",
      "600 steps | score: [-0.3590357303619385, 0.8625137209892273]\n",
      "700 steps | score: [0.030666029080748558, -0.40909188985824585]\n",
      "800 steps | score: [0.08513522148132324, -0.5573259592056274]\n",
      "900 steps | score: [-0.4485416114330292, 1.1733587980270386]\n",
      "1000 steps | score: [-0.16569717228412628, 0.16855785250663757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 steps | score: [-0.1501416563987732, 0.17321760952472687]\n",
      "1200 steps | score: [-0.3722655475139618, 0.8325812816619873]\n",
      "1300 steps | score: [-0.12800174951553345, 0.122830331325531]\n",
      "1400 steps | score: [0.019124846905469894, -0.3837493658065796]\n",
      "1500 steps | score: [-0.32126542925834656, 0.6708269715309143]\n",
      "1600 steps | score: [-0.1659121960401535, 0.18965300917625427]\n",
      "1700 steps | score: [-0.18561403453350067, 0.269747793674469]\n",
      "1800 steps | score: [-0.10332117974758148, 0.010553104802966118]\n",
      "1900 steps | score: [-0.29320287704467773, 0.6445987820625305]\n",
      "2000 steps | score: [-0.31780704855918884, 0.6693478226661682]\n",
      "2100 steps | score: [-0.22381103038787842, 0.36670982837677]\n",
      "2200 steps | score: [-0.2703026235103607, 0.5188199877738953]\n",
      "2300 steps | score: [-0.08042076230049133, -0.09330041706562042]\n",
      "2400 steps | score: [-0.25613319873809814, 0.5199633240699768]\n",
      "2500 steps | score: [-0.3053082227706909, 0.6691965460777283]\n",
      "2600 steps | score: [-0.2261994630098343, 0.39434611797332764]\n",
      "2700 steps | score: [-0.19940350949764252, 0.3520587384700775]\n",
      "2800 steps | score: [-0.036467090249061584, -0.2445465624332428]\n",
      "2900 steps | score: [-0.2588486969470978, 0.532498300075531]\n",
      "unknown params:  tensor([ 0.7098, -0.3446,  0.6689,  0.6278, -0.0846, -0.0190])\n",
      "gt params:  tensor([ 0.6846, -0.3273,  0.6600,  0.6092, -0.0755, -0.0757])\n",
      "ols params:  tensor([ 0.4395, -0.2169,  0.4155,  0.3886, -0.0515,  1.7508])\n",
      "unknown mse:  tensor(0.0008)\n",
      "ols mse:  tensor(0.5862)\n",
      "gt params:  tensor([ 0.6609, -0.3385,  0.6576,  0.6108, -0.0590, -0.1072])\n",
      "0 steps | score: [0.003641832619905472]\n",
      "100 steps | score: [-0.1523304134607315]\n",
      "200 steps | score: [-0.25095242261886597]\n",
      "300 steps | score: [-0.19382469356060028]\n",
      "400 steps | score: [-0.24120822548866272]\n",
      "500 steps | score: [-0.23518435657024384]\n",
      "600 steps | score: [-0.18570634722709656]\n",
      "700 steps | score: [-0.21623247861862183]\n",
      "800 steps | score: [-0.22131913900375366]\n",
      "900 steps | score: [-0.24159017205238342]\n",
      "1000 steps | score: [-0.2531140148639679]\n",
      "1100 steps | score: [-0.24618247151374817]\n",
      "1200 steps | score: [-0.20702549815177917]\n",
      "1300 steps | score: [-0.23344218730926514]\n",
      "1400 steps | score: [-0.2282760888338089]\n",
      "1500 steps | score: [-0.2615075409412384]\n",
      "1600 steps | score: [-0.22464069724082947]\n",
      "1700 steps | score: [-0.20985662937164307]\n",
      "1800 steps | score: [-0.2193363606929779]\n",
      "1900 steps | score: [-0.23097443580627441]\n",
      "2000 steps | score: [-0.2621265649795532]\n",
      "2100 steps | score: [-0.2629301846027374]\n",
      "2200 steps | score: [-0.23786123096942902]\n",
      "2300 steps | score: [-0.23755377531051636]\n",
      "2400 steps | score: [-0.21973660588264465]\n",
      "2500 steps | score: [-0.229487806558609]\n",
      "2600 steps | score: [-0.2312236726284027]\n",
      "2700 steps | score: [-0.23631252348423004]\n",
      "2800 steps | score: [-0.24357075989246368]\n",
      "2900 steps | score: [-0.23377397656440735]\n",
      "0 steps | score: [0.42271846532821655, -0.8205015063285828]\n",
      "100 steps | score: [0.5324223637580872, -1.4072916507720947]\n",
      "200 steps | score: [0.184672549366951, -0.5086164474487305]\n",
      "300 steps | score: [0.2363746166229248, -0.6080292463302612]\n",
      "400 steps | score: [0.29776740074157715, -0.8585718274116516]\n",
      "500 steps | score: [0.14925992488861084, -0.43999773263931274]\n",
      "600 steps | score: [0.25309163331985474, -0.6738850474357605]\n",
      "700 steps | score: [0.33419740200042725, -0.9340394735336304]\n",
      "800 steps | score: [0.2903980016708374, -0.8218295574188232]\n",
      "900 steps | score: [0.3543184995651245, -1.0496269464492798]\n",
      "1000 steps | score: [0.1424551159143448, -0.42406269907951355]\n",
      "1100 steps | score: [0.19202308356761932, -0.5724687576293945]\n",
      "1200 steps | score: [0.471395879983902, -1.3402119874954224]\n",
      "1300 steps | score: [0.12209860980510712, -0.3976072072982788]\n",
      "1400 steps | score: [0.23572807013988495, -0.698712944984436]\n",
      "1500 steps | score: [0.26546910405158997, -0.7802291512489319]\n",
      "1600 steps | score: [0.34488534927368164, -0.9668485522270203]\n",
      "1700 steps | score: [0.337941974401474, -0.9431283473968506]\n",
      "1800 steps | score: [0.29055124521255493, -0.8146841526031494]\n",
      "1900 steps | score: [0.3023560345172882, -0.9011967778205872]\n",
      "2000 steps | score: [0.2671258747577667, -0.7346676588058472]\n",
      "2100 steps | score: [0.24259592592716217, -0.707784116268158]\n",
      "2200 steps | score: [0.3001989424228668, -0.8983251452445984]\n",
      "2300 steps | score: [0.2921816110610962, -0.8303644061088562]\n",
      "2400 steps | score: [0.2793721556663513, -0.8010677099227905]\n",
      "2500 steps | score: [0.3333791494369507, -1.0018589496612549]\n",
      "2600 steps | score: [0.32913559675216675, -0.956812858581543]\n",
      "2700 steps | score: [0.38486728072166443, -1.112729787826538]\n",
      "2800 steps | score: [0.28633588552474976, -0.814239501953125]\n",
      "2900 steps | score: [0.30854520201683044, -0.8917859792709351]\n",
      "unknown params:  tensor([ 0.6736, -0.3520,  0.6722,  0.6078, -0.0566, -0.0496])\n",
      "gt params:  tensor([ 0.6609, -0.3385,  0.6576,  0.6108, -0.0590, -0.1072])\n",
      "ols params:  tensor([ 0.4095, -0.2198,  0.4110,  0.3703, -0.0340,  1.9093])\n",
      "unknown mse:  tensor(0.0006)\n",
      "ols mse:  tensor(0.7104)\n",
      "gt params:  tensor([ 0.6686, -0.3313,  0.6458,  0.6159, -0.0585, -0.0859])\n",
      "0 steps | score: [0.21673616766929626]\n",
      "100 steps | score: [0.06339925527572632]\n",
      "200 steps | score: [0.05760667473077774]\n",
      "300 steps | score: [-0.03143984451889992]\n",
      "400 steps | score: [-0.029036663472652435]\n",
      "500 steps | score: [-0.036166053265333176]\n",
      "600 steps | score: [0.01567741483449936]\n",
      "700 steps | score: [-0.025694750249385834]\n",
      "800 steps | score: [-0.05061076581478119]\n",
      "900 steps | score: [-0.011400289833545685]\n",
      "1000 steps | score: [-0.007038678973913193]\n",
      "0 steps | score: [0.2067117989063263, 0.05866950750350952]\n",
      "100 steps | score: [0.27244865894317627, -0.29063645005226135]\n",
      "200 steps | score: [0.30823782086372375, -0.4653337597846985]\n",
      "300 steps | score: [0.09008251875638962, 0.06535046547651291]\n",
      "400 steps | score: [-0.19574664533138275, 0.7077847719192505]\n",
      "500 steps | score: [0.07839062809944153, 0.0884043276309967]\n",
      "600 steps | score: [-0.026946229860186577, 0.33731508255004883]\n",
      "700 steps | score: [0.0014150821371003985, 0.28311875462532043]\n",
      "800 steps | score: [0.13040408492088318, -0.04781857132911682]\n",
      "900 steps | score: [-0.07882094383239746, 0.4608079195022583]\n",
      "1000 steps | score: [0.09114263206720352, 0.011357381939888]\n",
      "1100 steps | score: [0.07616081833839417, 0.10348183661699295]\n",
      "1200 steps | score: [-0.039151549339294434, 0.36203813552856445]\n",
      "1300 steps | score: [0.042991749942302704, 0.12746456265449524]\n",
      "1400 steps | score: [-0.021514181047677994, 0.3267011344432831]\n",
      "1500 steps | score: [0.10920742899179459, -0.003505140542984009]\n",
      "1600 steps | score: [0.02591315098106861, 0.21975097060203552]\n",
      "1700 steps | score: [-0.03428018465638161, 0.35064274072647095]\n",
      "1800 steps | score: [0.03100535273551941, 0.1907448023557663]\n",
      "1900 steps | score: [0.12067689001560211, -0.05002951622009277]\n",
      "2000 steps | score: [0.016629835590720177, 0.2351190149784088]\n",
      "2100 steps | score: [-0.022234834730625153, 0.2990867495536804]\n",
      "2200 steps | score: [-0.04923998564481735, 0.35700517892837524]\n",
      "2300 steps | score: [0.03349798917770386, 0.19034990668296814]\n",
      "2400 steps | score: [0.08150927722454071, 0.08515923470258713]\n",
      "2500 steps | score: [0.00572800962254405, 0.23954269289970398]\n",
      "2600 steps | score: [-0.023977069184184074, 0.2829703986644745]\n",
      "2700 steps | score: [-0.011143739335238934, 0.2960170805454254]\n",
      "2800 steps | score: [0.012441545724868774, 0.17262020707130432]\n",
      "2900 steps | score: [0.03298244997859001, 0.13542698323726654]\n",
      "unknown params:  tensor([ 0.6764, -0.3458,  0.6688,  0.5958, -0.0485, -0.0489])\n",
      "gt params:  tensor([ 0.6686, -0.3313,  0.6458,  0.6159, -0.0585, -0.0859])\n",
      "ols params:  tensor([ 0.3974, -0.2091,  0.3888,  0.3526, -0.0292,  2.1278])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(0.8542)\n",
      "gt params:  tensor([ 0.6824, -0.3151,  0.6550,  0.6031, -0.0745, -0.0842])\n",
      "0 steps | score: [0.2517637014389038]\n",
      "100 steps | score: [0.0547885037958622]\n",
      "200 steps | score: [-0.002802681177854538]\n",
      "0 steps | score: [0.12692636251449585, -0.1581713706254959]\n",
      "100 steps | score: [0.10312510281801224, -0.24110640585422516]\n",
      "200 steps | score: [0.03208717331290245, -0.14614619314670563]\n",
      "300 steps | score: [0.05078669637441635, -0.22253867983818054]\n",
      "400 steps | score: [0.13622340559959412, -0.47827598452568054]\n",
      "500 steps | score: [0.07746962457895279, -0.29448211193084717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 steps | score: [-0.12004455178976059, 0.1970595121383667]\n",
      "700 steps | score: [-0.11649519950151443, 0.14880290627479553]\n",
      "800 steps | score: [0.04050946608185768, -0.21830016374588013]\n",
      "900 steps | score: [0.03074011020362377, -0.2355181723833084]\n",
      "1000 steps | score: [0.10024918615818024, -0.34881165623664856]\n",
      "1100 steps | score: [0.09492472559213638, -0.3269633650779724]\n",
      "1200 steps | score: [-0.16803382337093353, 0.24192480742931366]\n",
      "1300 steps | score: [0.1006641685962677, -0.38125061988830566]\n",
      "1400 steps | score: [-0.10607624053955078, 0.11704578995704651]\n",
      "1500 steps | score: [0.039617761969566345, -0.21294352412223816]\n",
      "1600 steps | score: [-0.014760683290660381, -0.06763750314712524]\n",
      "1700 steps | score: [-0.07169724255800247, 0.03810727596282959]\n",
      "1800 steps | score: [0.13584916293621063, -0.47616714239120483]\n",
      "1900 steps | score: [-0.04488496854901314, -0.034604888409376144]\n",
      "2000 steps | score: [-0.009573187679052353, -0.12491704523563385]\n",
      "2100 steps | score: [-0.05107741802930832, -0.0042034536600112915]\n",
      "2200 steps | score: [-0.029691964387893677, -0.04296940937638283]\n",
      "2300 steps | score: [0.038469914346933365, -0.21263879537582397]\n",
      "2400 steps | score: [-0.002110287779942155, -0.12026574462652206]\n",
      "2500 steps | score: [-0.03393753618001938, -0.03527761995792389]\n",
      "2600 steps | score: [-0.056954920291900635, -0.007324308156967163]\n",
      "2700 steps | score: [-0.006488753482699394, -0.10697798430919647]\n",
      "2800 steps | score: [0.0289591234177351, -0.1839599460363388]\n",
      "2900 steps | score: [-0.019903315231204033, -0.07782931625843048]\n",
      "unknown params:  tensor([ 0.6979, -0.3195,  0.6583,  0.5600, -0.0547,  0.0593])\n",
      "gt params:  tensor([ 0.6824, -0.3151,  0.6550,  0.6031, -0.0745, -0.0842])\n",
      "ols params:  tensor([ 0.3884, -0.1848,  0.3675,  0.3161, -0.0297,  2.3050])\n",
      "unknown mse:  tensor(0.0039)\n",
      "ols mse:  tensor(0.9965)\n",
      "gt params:  tensor([ 0.6968, -0.3244,  0.6691,  0.6182, -0.0596, -0.0992])\n",
      "0 steps | score: [0.14216619729995728]\n",
      "100 steps | score: [-0.05720328539609909]\n",
      "200 steps | score: [-0.11403743922710419]\n",
      "300 steps | score: [-0.06485999375581741]\n",
      "400 steps | score: [-0.06989987194538116]\n",
      "500 steps | score: [-0.04513201117515564]\n",
      "600 steps | score: [-0.03178964555263519]\n",
      "700 steps | score: [-0.08519332110881805]\n",
      "800 steps | score: [-0.05855242908000946]\n",
      "900 steps | score: [-0.10147171467542648]\n",
      "1000 steps | score: [-0.03983272984623909]\n",
      "1100 steps | score: [-0.010996714234352112]\n",
      "1200 steps | score: [-0.042799338698387146]\n",
      "1300 steps | score: [-0.07008866965770721]\n",
      "1400 steps | score: [-0.07745449244976044]\n",
      "1500 steps | score: [-0.07117078453302383]\n",
      "1600 steps | score: [-0.010456661693751812]\n",
      "1700 steps | score: [-0.04493306577205658]\n",
      "1800 steps | score: [-0.08432967215776443]\n",
      "1900 steps | score: [-0.07515927404165268]\n",
      "2000 steps | score: [-0.06473112106323242]\n",
      "2100 steps | score: [-0.031935036182403564]\n",
      "2200 steps | score: [-0.055029965937137604]\n",
      "2300 steps | score: [-0.07405083626508713]\n",
      "2400 steps | score: [-0.06798853725194931]\n",
      "2500 steps | score: [-0.056356944143772125]\n",
      "2600 steps | score: [-0.04190004616975784]\n",
      "2700 steps | score: [-0.062034934759140015]\n",
      "2800 steps | score: [-0.06670528650283813]\n",
      "2900 steps | score: [-0.040971480309963226]\n",
      "0 steps | score: [0.08645359426736832, 0.0535886324942112]\n",
      "100 steps | score: [-0.22963204979896545, 0.598624587059021]\n",
      "200 steps | score: [-0.2563389539718628, 0.5992686748504639]\n",
      "300 steps | score: [-0.06146816909313202, 0.15145735442638397]\n",
      "400 steps | score: [-0.21642497181892395, 0.4726981818675995]\n",
      "500 steps | score: [-0.5680044889450073, 1.2505497932434082]\n",
      "600 steps | score: [-0.08563316613435745, 0.19279342889785767]\n",
      "700 steps | score: [-0.09767703711986542, 0.21163177490234375]\n",
      "800 steps | score: [0.03991279378533363, -0.11026141047477722]\n",
      "900 steps | score: [-0.06944635510444641, 0.14536595344543457]\n",
      "1000 steps | score: [0.014269196428358555, -0.09142772853374481]\n",
      "1100 steps | score: [-0.03699878603219986, 0.04784426838159561]\n",
      "1200 steps | score: [-0.0741422176361084, 0.1519702821969986]\n",
      "1300 steps | score: [-0.06938397139310837, 0.1486813724040985]\n",
      "1400 steps | score: [-0.12323169410228729, 0.2504505217075348]\n",
      "1500 steps | score: [0.09771180152893066, -0.2907269597053528]\n",
      "1600 steps | score: [-0.010921891778707504, -0.021990135312080383]\n",
      "1700 steps | score: [-0.031829044222831726, 0.017354745417833328]\n",
      "1800 steps | score: [-0.07342102378606796, 0.14124618470668793]\n",
      "1900 steps | score: [-0.11381886154413223, 0.21836845576763153]\n",
      "2000 steps | score: [0.06630776822566986, -0.25387945771217346]\n",
      "2100 steps | score: [-0.07217574864625931, 0.10482548177242279]\n",
      "2200 steps | score: [-0.03753689303994179, 0.04644061625003815]\n",
      "2300 steps | score: [-0.05940552055835724, 0.08453692495822906]\n",
      "2400 steps | score: [-0.07012888044118881, 0.09901151061058044]\n",
      "2500 steps | score: [0.01213640347123146, -0.09671353548765182]\n",
      "2600 steps | score: [0.016643108800053596, -0.09998424351215363]\n",
      "2700 steps | score: [0.018806446343660355, -0.09655947983264923]\n",
      "2800 steps | score: [-0.08175544440746307, 0.13856764137744904]\n",
      "2900 steps | score: [-0.03882097452878952, 0.04640316963195801]\n",
      "unknown params:  tensor([ 0.7342, -0.3153,  0.7235,  0.6812, -0.0456,  0.0925])\n",
      "gt params:  tensor([ 0.6968, -0.3244,  0.6691,  0.6182, -0.0596, -0.0992])\n",
      "ols params:  tensor([ 0.3733, -0.1743,  0.3699,  0.3457, -0.0206,  2.4629])\n",
      "unknown mse:  tensor(0.0076)\n",
      "ols mse:  tensor(1.1428)\n",
      "gt params:  tensor([ 0.6637, -0.3258,  0.6675,  0.6054, -0.0464, -0.0049])\n",
      "0 steps | score: [0.3409360349178314]\n",
      "100 steps | score: [0.14120203256607056]\n",
      "200 steps | score: [0.051819488406181335]\n",
      "300 steps | score: [0.07253314554691315]\n",
      "400 steps | score: [0.06548095494508743]\n",
      "500 steps | score: [0.012433411553502083]\n",
      "600 steps | score: [0.1107870414853096]\n",
      "700 steps | score: [0.04654739797115326]\n",
      "800 steps | score: [0.0751146599650383]\n",
      "900 steps | score: [0.07691459357738495]\n",
      "1000 steps | score: [0.049250032752752304]\n",
      "1100 steps | score: [0.0831359252333641]\n",
      "1200 steps | score: [0.05854969471693039]\n",
      "1300 steps | score: [0.06354652345180511]\n",
      "1400 steps | score: [0.06381812691688538]\n",
      "1500 steps | score: [0.07373087108135223]\n",
      "1600 steps | score: [0.07535260170698166]\n",
      "1700 steps | score: [0.049252741038799286]\n",
      "1800 steps | score: [0.043107111006975174]\n",
      "1900 steps | score: [0.08506814390420914]\n",
      "2000 steps | score: [0.08665076643228531]\n",
      "2100 steps | score: [0.06967181712388992]\n",
      "2200 steps | score: [0.07478901743888855]\n",
      "2300 steps | score: [0.056753113865852356]\n",
      "2400 steps | score: [0.06460309028625488]\n",
      "2500 steps | score: [0.08673933148384094]\n",
      "0 steps | score: [-0.012155594304203987, 0.563437819480896]\n",
      "100 steps | score: [0.2654741406440735, -0.34400299191474915]\n",
      "200 steps | score: [-0.44744357466697693, 1.252234935760498]\n",
      "300 steps | score: [0.04648440703749657, 0.07426238059997559]\n",
      "400 steps | score: [-0.26445436477661133, 0.8514133095741272]\n",
      "500 steps | score: [-0.245860755443573, 0.8283267021179199]\n",
      "600 steps | score: [-0.2188548594713211, 0.7784683108329773]\n",
      "700 steps | score: [-0.3070712387561798, 0.9146487712860107]\n",
      "800 steps | score: [-0.18739110231399536, 0.6942391991615295]\n",
      "900 steps | score: [-0.1880110204219818, 0.6957035660743713]\n",
      "1000 steps | score: [-0.3161424398422241, 0.9686816930770874]\n",
      "1100 steps | score: [-0.1519826352596283, 0.636200487613678]\n",
      "1200 steps | score: [-0.27420955896377563, 0.8474919199943542]\n",
      "1300 steps | score: [-0.27721157670021057, 0.8801432847976685]\n",
      "1400 steps | score: [-0.20867858827114105, 0.7410308122634888]\n",
      "1500 steps | score: [-0.26969000697135925, 0.8526506423950195]\n",
      "1600 steps | score: [-0.09429749846458435, 0.4737128019332886]\n",
      "1700 steps | score: [-0.28470340371131897, 0.9155086874961853]\n",
      "1800 steps | score: [-0.21736721694469452, 0.760462760925293]\n",
      "1900 steps | score: [-0.23431316018104553, 0.8030705451965332]\n",
      "2000 steps | score: [-0.1602911353111267, 0.6570995450019836]\n",
      "2100 steps | score: [-0.13217182457447052, 0.5416427850723267]\n",
      "2200 steps | score: [-0.2114913910627365, 0.732622504234314]\n",
      "2300 steps | score: [-0.25560903549194336, 0.791660726070404]\n",
      "2400 steps | score: [-0.13492485880851746, 0.5740789175033569]\n",
      "2500 steps | score: [-0.19100506603717804, 0.6767244935035706]\n",
      "unknown params:  tensor([ 0.5883, -0.3091,  0.6555,  0.5763, -0.0326, -0.0023])\n",
      "gt params:  tensor([ 0.6637, -0.3258,  0.6675,  0.6054, -0.0464, -0.0049])\n",
      "ols params:  tensor([ 0.3316, -0.1793,  0.3680,  0.3241, -0.0165,  2.6274])\n",
      "unknown mse:  tensor(0.0012)\n",
      "ols mse:  tensor(1.2050)\n",
      "gt params:  tensor([ 0.6982, -0.3258,  0.6421,  0.6025, -0.0737, -0.1198])\n",
      "0 steps | score: [0.4070925712585449]\n",
      "100 steps | score: [0.16995418071746826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [0.12695148587226868]\n",
      "300 steps | score: [0.1938069760799408]\n",
      "400 steps | score: [0.1729017049074173]\n",
      "500 steps | score: [0.09165775775909424]\n",
      "600 steps | score: [0.11345990002155304]\n",
      "700 steps | score: [0.07519648224115372]\n",
      "800 steps | score: [0.1563146412372589]\n",
      "900 steps | score: [0.13469845056533813]\n",
      "1000 steps | score: [0.08995422720909119]\n",
      "1100 steps | score: [0.07898540049791336]\n",
      "1200 steps | score: [0.10147686302661896]\n",
      "1300 steps | score: [0.1430230438709259]\n",
      "1400 steps | score: [0.12275602668523788]\n",
      "1500 steps | score: [0.0841941237449646]\n",
      "1600 steps | score: [0.0899602398276329]\n",
      "1700 steps | score: [0.1104041188955307]\n",
      "1800 steps | score: [0.12223710864782333]\n",
      "1900 steps | score: [0.12086908519268036]\n",
      "2000 steps | score: [0.10574910789728165]\n",
      "2100 steps | score: [0.10757950693368912]\n",
      "2200 steps | score: [0.11765696108341217]\n",
      "2300 steps | score: [0.09858988225460052]\n",
      "2400 steps | score: [0.11598483473062515]\n",
      "2500 steps | score: [0.11841747909784317]\n",
      "2600 steps | score: [0.10439500212669373]\n",
      "2700 steps | score: [0.1184735968708992]\n",
      "2800 steps | score: [0.10875402390956879]\n",
      "2900 steps | score: [0.1036229208111763]\n",
      "0 steps | score: [0.16941538453102112, -0.3476455509662628]\n",
      "100 steps | score: [0.1459883749485016, -0.47303807735443115]\n",
      "200 steps | score: [-0.07819230854511261, 0.013139724731445312]\n",
      "300 steps | score: [0.19585281610488892, -0.7182345390319824]\n",
      "400 steps | score: [0.2867606282234192, -0.917497992515564]\n",
      "500 steps | score: [-0.08531644940376282, -0.036299608647823334]\n",
      "600 steps | score: [-0.07207747548818588, -0.10509597510099411]\n",
      "700 steps | score: [0.23859798908233643, -0.8458536863327026]\n",
      "800 steps | score: [0.24965080618858337, -0.8619805574417114]\n",
      "900 steps | score: [0.07081671059131622, -0.43463289737701416]\n",
      "1000 steps | score: [-0.1346283257007599, 0.049593403935432434]\n",
      "1100 steps | score: [-0.1092248484492302, 0.04408859834074974]\n",
      "1200 steps | score: [0.14960706233978271, -0.5867229104042053]\n",
      "1300 steps | score: [0.08512235432863235, -0.4622069001197815]\n",
      "1400 steps | score: [0.07475835829973221, -0.43316394090652466]\n",
      "1500 steps | score: [-0.11714017391204834, 0.033709581941366196]\n",
      "1600 steps | score: [-0.04343272000551224, -0.14723460376262665]\n",
      "1700 steps | score: [0.11973001062870026, -0.5145189166069031]\n",
      "1800 steps | score: [0.03562794625759125, -0.30992722511291504]\n",
      "1900 steps | score: [0.060384880751371384, -0.3716628849506378]\n",
      "2000 steps | score: [-0.15015219151973724, 0.11055789887905121]\n",
      "2100 steps | score: [0.002979242242872715, -0.27953171730041504]\n",
      "2200 steps | score: [0.04678060859441757, -0.3307419717311859]\n",
      "2300 steps | score: [0.005554208066314459, -0.22697636485099792]\n",
      "2400 steps | score: [0.06254520267248154, -0.3850504159927368]\n",
      "2500 steps | score: [-0.03595050051808357, -0.14559361338615417]\n",
      "2600 steps | score: [0.09156733751296997, -0.4335114359855652]\n",
      "2700 steps | score: [0.09458865970373154, -0.4777045249938965]\n",
      "2800 steps | score: [-0.0017987610772252083, -0.23880314826965332]\n",
      "2900 steps | score: [0.03563971817493439, -0.3398732542991638]\n",
      "unknown params:  tensor([ 0.7071, -0.3040,  0.6271,  0.5963, -0.0610, -0.0391])\n",
      "gt params:  tensor([ 0.6982, -0.3258,  0.6421,  0.6025, -0.0737, -0.1198])\n",
      "ols params:  tensor([ 0.3829, -0.1728,  0.3464,  0.3287, -0.0330,  2.6441])\n",
      "unknown mse:  tensor(0.0012)\n",
      "ols mse:  tensor(1.3210)\n",
      "gt params:  tensor([ 0.6974, -0.3348,  0.6572,  0.6101, -0.0783, -0.1115])\n",
      "0 steps | score: [0.1637747585773468]\n",
      "100 steps | score: [-0.138249933719635]\n",
      "200 steps | score: [-0.15892228484153748]\n",
      "300 steps | score: [-0.08676541596651077]\n",
      "400 steps | score: [-0.0936131477355957]\n",
      "500 steps | score: [-0.05565548315644264]\n",
      "600 steps | score: [-0.13114005327224731]\n",
      "700 steps | score: [-0.121355339884758]\n",
      "800 steps | score: [-0.09054359048604965]\n",
      "900 steps | score: [-0.11690948158502579]\n",
      "1000 steps | score: [-0.07523955404758453]\n",
      "1100 steps | score: [-0.09733743965625763]\n",
      "1200 steps | score: [-0.09031804651021957]\n",
      "1300 steps | score: [-0.10128697752952576]\n",
      "1400 steps | score: [-0.07677804678678513]\n",
      "1500 steps | score: [-0.07284897565841675]\n",
      "1600 steps | score: [-0.07976236939430237]\n",
      "1700 steps | score: [-0.09459979832172394]\n",
      "1800 steps | score: [-0.09018070995807648]\n",
      "1900 steps | score: [-0.06454562395811081]\n",
      "2000 steps | score: [-0.085523322224617]\n",
      "2100 steps | score: [-0.10575889050960541]\n",
      "2200 steps | score: [-0.09276675432920456]\n",
      "2300 steps | score: [-0.10075263679027557]\n",
      "2400 steps | score: [-0.0965394377708435]\n",
      "2500 steps | score: [-0.09049206972122192]\n",
      "2600 steps | score: [-0.10547196865081787]\n",
      "2700 steps | score: [-0.08789638429880142]\n",
      "2800 steps | score: [-0.09155698120594025]\n",
      "2900 steps | score: [-0.08448071777820587]\n",
      "0 steps | score: [0.20968590676784515, -0.009119901806116104]\n",
      "100 steps | score: [-0.23011602461338043, 0.7061163783073425]\n",
      "200 steps | score: [-0.19879521429538727, 0.6247329115867615]\n",
      "300 steps | score: [0.07550164312124252, -0.06082719564437866]\n",
      "400 steps | score: [-0.043558184057474136, 0.24856922030448914]\n",
      "500 steps | score: [0.041626811027526855, 0.08601517975330353]\n",
      "600 steps | score: [-0.16356663405895233, 0.5310183763504028]\n",
      "700 steps | score: [0.06019372120499611, 0.04615427181124687]\n",
      "800 steps | score: [0.11334966868162155, -0.19706879556179047]\n",
      "900 steps | score: [-0.04127940535545349, 0.2446536421775818]\n",
      "1000 steps | score: [0.083529993891716, -0.030198633670806885]\n",
      "1100 steps | score: [-0.16232910752296448, 0.533259391784668]\n",
      "1200 steps | score: [0.029086800292134285, 0.0639360249042511]\n",
      "1300 steps | score: [0.060266271233558655, -0.02018783986568451]\n",
      "1400 steps | score: [-0.05724824219942093, 0.27116498351097107]\n",
      "1500 steps | score: [0.13106556236743927, -0.16161403059959412]\n",
      "1600 steps | score: [-0.1142277643084526, 0.4111410081386566]\n",
      "1700 steps | score: [0.05327202379703522, -0.010320227593183517]\n",
      "1800 steps | score: [0.1438312828540802, -0.21165591478347778]\n",
      "1900 steps | score: [-0.0018954775296151638, 0.14075464010238647]\n",
      "2000 steps | score: [0.09020505100488663, -0.05733324587345123]\n",
      "2100 steps | score: [-0.07320571690797806, 0.3185558617115021]\n",
      "2200 steps | score: [0.025539644062519073, 0.0908198431134224]\n",
      "2300 steps | score: [0.07842635363340378, -0.04935583844780922]\n",
      "2400 steps | score: [-0.039958175271749496, 0.20872169733047485]\n",
      "2500 steps | score: [0.0517328716814518, 0.013528916984796524]\n",
      "2600 steps | score: [-0.032971665263175964, 0.2493225485086441]\n",
      "2700 steps | score: [0.017416778951883316, 0.10085132718086243]\n",
      "2800 steps | score: [0.04524703696370125, 0.010645000264048576]\n",
      "2900 steps | score: [0.026194635778665543, 0.0856269970536232]\n",
      "unknown params:  tensor([ 0.7507, -0.3351,  0.7306,  0.6256, -0.0789, -0.2248])\n",
      "gt params:  tensor([ 0.6974, -0.3348,  0.6572,  0.6101, -0.0783, -0.1115])\n",
      "ols params:  tensor([ 0.3587, -0.1684,  0.3490,  0.3054, -0.0359,  2.8030])\n",
      "unknown mse:  tensor(0.0035)\n",
      "ols mse:  tensor(1.4711)\n",
      "gt params:  tensor([ 0.6753, -0.3140,  0.6437,  0.5934, -0.0638, -0.1495])\n",
      "0 steps | score: [0.2531719207763672]\n",
      "100 steps | score: [-0.06003749370574951]\n",
      "200 steps | score: [-0.0239609032869339]\n",
      "300 steps | score: [0.04066465049982071]\n",
      "400 steps | score: [-0.011112278327345848]\n",
      "500 steps | score: [0.0395418256521225]\n",
      "600 steps | score: [-0.05379702150821686]\n",
      "700 steps | score: [0.0320640504360199]\n",
      "800 steps | score: [0.03230113536119461]\n",
      "900 steps | score: [-0.011262062937021255]\n",
      "1000 steps | score: [0.030996864661574364]\n",
      "1100 steps | score: [-0.03641785681247711]\n",
      "1200 steps | score: [0.02484111487865448]\n",
      "1300 steps | score: [0.03564191609621048]\n",
      "1400 steps | score: [0.027742838487029076]\n",
      "1500 steps | score: [-0.011394183151423931]\n",
      "1600 steps | score: [-0.006240016780793667]\n",
      "0 steps | score: [0.3300425708293915, -0.5241498947143555]\n",
      "100 steps | score: [0.10042257606983185, -0.2089499533176422]\n",
      "200 steps | score: [-0.014515789225697517, 0.009557098150253296]\n",
      "300 steps | score: [0.3445292115211487, -0.831904947757721]\n",
      "400 steps | score: [0.2344725877046585, -0.5659060478210449]\n",
      "500 steps | score: [0.20662645995616913, -0.5607215762138367]\n",
      "600 steps | score: [0.04925728216767311, -0.18934977054595947]\n",
      "700 steps | score: [0.4011290371417999, -1.0492515563964844]\n",
      "800 steps | score: [0.12246335297822952, -0.3411095142364502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 steps | score: [0.012904367409646511, -0.0973268449306488]\n",
      "1000 steps | score: [0.03168555349111557, -0.14504918456077576]\n",
      "1100 steps | score: [0.14128190279006958, -0.38863605260849]\n",
      "1200 steps | score: [0.19075725972652435, -0.5092478394508362]\n",
      "1300 steps | score: [0.24707633256912231, -0.6519837379455566]\n",
      "1400 steps | score: [0.18498270213603973, -0.49788564443588257]\n",
      "1500 steps | score: [-0.061889760196208954, 0.036777861416339874]\n",
      "1600 steps | score: [0.20161539316177368, -0.5378129482269287]\n",
      "1700 steps | score: [0.10907967388629913, -0.3238789737224579]\n",
      "1800 steps | score: [0.27829664945602417, -0.7298568487167358]\n",
      "1900 steps | score: [0.11304982006549835, -0.30448034405708313]\n",
      "2000 steps | score: [0.11485731601715088, -0.32760685682296753]\n",
      "2100 steps | score: [0.17972005903720856, -0.48763424158096313]\n",
      "2200 steps | score: [0.13782057166099548, -0.3905915319919586]\n",
      "2300 steps | score: [0.22484266757965088, -0.603445291519165]\n",
      "2400 steps | score: [0.11427295207977295, -0.3388427495956421]\n",
      "2500 steps | score: [0.1395723521709442, -0.3975405693054199]\n",
      "2600 steps | score: [0.18983164429664612, -0.5530515909194946]\n",
      "2700 steps | score: [0.14045065641403198, -0.3849427103996277]\n",
      "2800 steps | score: [0.2995239496231079, -0.7872515916824341]\n",
      "2900 steps | score: [0.19666291773319244, -0.5100101232528687]\n",
      "unknown params:  tensor([ 0.6735, -0.2901,  0.6628,  0.6106, -0.0507,  0.0698])\n",
      "gt params:  tensor([ 0.6753, -0.3140,  0.6437,  0.5934, -0.0638, -0.1495])\n",
      "ols params:  tensor([ 0.3375, -0.1441,  0.3245,  0.3007, -0.0258,  3.0047])\n",
      "unknown mse:  tensor(0.0082)\n",
      "ols mse:  tensor(1.7135)\n",
      "gt params:  tensor([ 0.6790, -0.3305,  0.6741,  0.6112, -0.0685, -0.1220])\n",
      "0 steps | score: [0.13094447553157806]\n",
      "100 steps | score: [-0.06660951673984528]\n",
      "200 steps | score: [-0.11940905451774597]\n",
      "300 steps | score: [-0.12291295826435089]\n",
      "400 steps | score: [-0.14024555683135986]\n",
      "500 steps | score: [-0.12230823934078217]\n",
      "600 steps | score: [-0.1074368804693222]\n",
      "700 steps | score: [-0.1315237432718277]\n",
      "800 steps | score: [-0.13391728699207306]\n",
      "900 steps | score: [-0.156437486410141]\n",
      "1000 steps | score: [-0.1266995668411255]\n",
      "1100 steps | score: [-0.12278083711862564]\n",
      "1200 steps | score: [-0.10456444323062897]\n",
      "1300 steps | score: [-0.0897439494729042]\n",
      "1400 steps | score: [-0.12606944143772125]\n",
      "1500 steps | score: [-0.1097002699971199]\n",
      "1600 steps | score: [-0.12731902301311493]\n",
      "1700 steps | score: [-0.11374033242464066]\n",
      "1800 steps | score: [-0.09004787355661392]\n",
      "1900 steps | score: [-0.14084920287132263]\n",
      "2000 steps | score: [-0.1085483580827713]\n",
      "2100 steps | score: [-0.11290790885686874]\n",
      "2200 steps | score: [-0.09789928048849106]\n",
      "2300 steps | score: [-0.12350527942180634]\n",
      "2400 steps | score: [-0.10761382430791855]\n",
      "2500 steps | score: [-0.10696806013584137]\n",
      "2600 steps | score: [-0.12132638692855835]\n",
      "2700 steps | score: [-0.07020542770624161]\n",
      "2800 steps | score: [-0.07617704570293427]\n",
      "2900 steps | score: [-0.13544079661369324]\n",
      "0 steps | score: [0.19419598579406738, -0.11226030439138412]\n",
      "100 steps | score: [0.10831324011087418, -0.07235006988048553]\n",
      "200 steps | score: [-0.04436001181602478, 0.16769367456436157]\n",
      "300 steps | score: [0.0889648050069809, -0.1928282380104065]\n",
      "400 steps | score: [0.06752876192331314, -0.1176140233874321]\n",
      "500 steps | score: [0.01613595522940159, 0.02605448104441166]\n",
      "600 steps | score: [0.05857043340802193, -0.0704202875494957]\n",
      "700 steps | score: [-0.1179734319448471, 0.2941173315048218]\n",
      "800 steps | score: [-0.11623787879943848, 0.27342209219932556]\n",
      "900 steps | score: [-0.016892293468117714, 0.07441741228103638]\n",
      "1000 steps | score: [-0.02934335358440876, 0.06608881801366806]\n",
      "1100 steps | score: [0.007731007412075996, 0.027509594336152077]\n",
      "1200 steps | score: [0.10091406852006912, -0.18151862919330597]\n",
      "1300 steps | score: [0.027840234339237213, -0.07326893508434296]\n",
      "1400 steps | score: [-0.03891816735267639, 0.1391071379184723]\n",
      "1500 steps | score: [-0.01834084652364254, 0.04959851875901222]\n",
      "1600 steps | score: [0.009051455184817314, 0.014193926937878132]\n",
      "1700 steps | score: [-0.012314745225012302, 0.07318943738937378]\n",
      "1800 steps | score: [-0.05864037945866585, 0.1511940360069275]\n",
      "1900 steps | score: [-0.07031907886266708, 0.1980692744255066]\n",
      "2000 steps | score: [0.02847234532237053, -0.02671356126666069]\n",
      "2100 steps | score: [0.039158083498477936, -0.05556740611791611]\n",
      "2200 steps | score: [-0.044425323605537415, 0.12095656991004944]\n",
      "2300 steps | score: [-0.011644191108644009, 0.04710656404495239]\n",
      "2400 steps | score: [-0.06979675590991974, 0.17476707696914673]\n",
      "2500 steps | score: [0.06089436635375023, -0.11436968296766281]\n",
      "2600 steps | score: [0.05488920956850052, -0.07744818925857544]\n",
      "2700 steps | score: [-0.04074960574507713, 0.10482460260391235]\n",
      "2800 steps | score: [0.023888805881142616, -0.008980946615338326]\n",
      "2900 steps | score: [-0.06210138648748398, 0.1467469334602356]\n",
      "unknown params:  tensor([ 0.7070, -0.3180,  0.6770,  0.6204, -0.0484, -0.1516])\n",
      "gt params:  tensor([ 0.6790, -0.3305,  0.6741,  0.6112, -0.0685, -0.1220])\n",
      "ols params:  tensor([ 0.3440, -0.1629,  0.3286,  0.2990, -0.0226,  3.0616])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(1.7492)\n",
      "gt params:  tensor([ 0.6653, -0.3526,  0.6420,  0.6249, -0.0602, -0.1752])\n",
      "0 steps | score: [0.2564737796783447]\n",
      "100 steps | score: [0.012883685529232025]\n",
      "200 steps | score: [0.007958220317959785]\n",
      "0 steps | score: [0.3129519820213318, -0.3189142644405365]\n",
      "100 steps | score: [0.2906630039215088, -0.37580713629722595]\n",
      "200 steps | score: [0.07452092319726944, -0.030545130372047424]\n",
      "300 steps | score: [0.17976799607276917, -0.2862726151943207]\n",
      "400 steps | score: [0.009644917212426662, 0.07589054107666016]\n",
      "500 steps | score: [-0.041915345937013626, 0.17045575380325317]\n",
      "600 steps | score: [0.2896890640258789, -0.503544807434082]\n",
      "700 steps | score: [0.08386056870222092, -0.1062324196100235]\n",
      "800 steps | score: [0.14725275337696075, -0.24074864387512207]\n",
      "900 steps | score: [0.16847990453243256, -0.26708099246025085]\n",
      "1000 steps | score: [0.1049732118844986, -0.14589843153953552]\n",
      "1100 steps | score: [0.1336153894662857, -0.1698109358549118]\n",
      "1200 steps | score: [0.18288767337799072, -0.28452393412590027]\n",
      "1300 steps | score: [0.14689983427524567, -0.21433398127555847]\n",
      "1400 steps | score: [0.23785996437072754, -0.4406941533088684]\n",
      "1500 steps | score: [0.04242592677474022, -0.03538702428340912]\n",
      "1600 steps | score: [0.14044198393821716, -0.21782457828521729]\n",
      "1700 steps | score: [0.07940389215946198, -0.07796225696802139]\n",
      "1800 steps | score: [0.1598610132932663, -0.2396010011434555]\n",
      "1900 steps | score: [0.13542434573173523, -0.22111588716506958]\n",
      "2000 steps | score: [0.1203874871134758, -0.17941801249980927]\n",
      "2100 steps | score: [0.1744322031736374, -0.2940569519996643]\n",
      "2200 steps | score: [0.13362334668636322, -0.19502128660678864]\n",
      "2300 steps | score: [0.23648762702941895, -0.45034050941467285]\n",
      "2400 steps | score: [0.1130223423242569, -0.14589157700538635]\n",
      "2500 steps | score: [0.17917656898498535, -0.33394163846969604]\n",
      "2600 steps | score: [0.12567557394504547, -0.17319418489933014]\n",
      "2700 steps | score: [0.12301721423864365, -0.18645185232162476]\n",
      "2800 steps | score: [0.19617198407649994, -0.3438718318939209]\n",
      "2900 steps | score: [0.11882209032773972, -0.18771745264530182]\n",
      "unknown params:  tensor([ 0.6717, -0.3262,  0.6255,  0.5804, -0.0778, -0.1872])\n",
      "gt params:  tensor([ 0.6653, -0.3526,  0.6420,  0.6249, -0.0602, -0.1752])\n",
      "ols params:  tensor([ 0.3371, -0.1677,  0.3167,  0.2913, -0.0391,  3.1917])\n",
      "unknown mse:  tensor(0.0006)\n",
      "ols mse:  tensor(1.9493)\n",
      "gt params:  tensor([ 0.6721, -0.3318,  0.6511,  0.6225, -0.0862, -0.1900])\n",
      "0 steps | score: [0.28242868185043335]\n",
      "100 steps | score: [0.10289357602596283]\n",
      "200 steps | score: [-0.01892741397023201]\n",
      "300 steps | score: [0.018399234861135483]\n",
      "400 steps | score: [-0.022679951041936874]\n",
      "500 steps | score: [-0.035048987716436386]\n",
      "600 steps | score: [0.04167339578270912]\n",
      "700 steps | score: [-0.027988240122795105]\n",
      "800 steps | score: [-0.011564429849386215]\n",
      "900 steps | score: [-0.011001359671354294]\n",
      "1000 steps | score: [-0.04063766077160835]\n",
      "1100 steps | score: [0.02054698020219803]\n",
      "1200 steps | score: [-0.03478466719388962]\n",
      "1300 steps | score: [-0.014957627281546593]\n",
      "1400 steps | score: [-0.00374453142285347]\n",
      "0 steps | score: [0.4042550027370453, -0.6889976263046265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [0.5386261343955994, -1.1224004030227661]\n",
      "200 steps | score: [0.0669558122754097, -0.1665385365486145]\n",
      "300 steps | score: [0.2756383717060089, -0.6677203178405762]\n",
      "400 steps | score: [0.11945395171642303, -0.3205600380897522]\n",
      "500 steps | score: [0.002286718226969242, -0.06276574730873108]\n",
      "600 steps | score: [0.40624022483825684, -0.9856203198432922]\n",
      "700 steps | score: [-0.0009092222317121923, -0.08320463448762894]\n",
      "800 steps | score: [0.13296160101890564, -0.37184369564056396]\n",
      "900 steps | score: [0.3824025094509125, -0.9583332538604736]\n",
      "1000 steps | score: [0.26939940452575684, -0.6855784058570862]\n",
      "1100 steps | score: [0.4649776220321655, -1.1625548601150513]\n",
      "1200 steps | score: [0.2069709300994873, -0.493001788854599]\n",
      "1300 steps | score: [0.335896372795105, -0.8179711103439331]\n",
      "1400 steps | score: [0.13592694699764252, -0.4032119810581207]\n",
      "1500 steps | score: [0.28263723850250244, -0.7185580730438232]\n",
      "1600 steps | score: [0.36548274755477905, -0.9125531911849976]\n",
      "1700 steps | score: [0.13408270478248596, -0.3595629930496216]\n",
      "1800 steps | score: [0.27752000093460083, -0.7129996418952942]\n",
      "1900 steps | score: [0.23559458553791046, -0.5801117420196533]\n",
      "2000 steps | score: [0.26974424719810486, -0.6991485357284546]\n",
      "2100 steps | score: [0.3540392518043518, -0.8869771361351013]\n",
      "2200 steps | score: [0.16611185669898987, -0.43752527236938477]\n",
      "2300 steps | score: [0.3269617259502411, -0.8145344257354736]\n",
      "2400 steps | score: [0.22522784769535065, -0.5666412115097046]\n",
      "2500 steps | score: [0.26490283012390137, -0.6793253421783447]\n",
      "2600 steps | score: [0.2801304757595062, -0.6962484121322632]\n",
      "2700 steps | score: [0.20302090048789978, -0.5372638702392578]\n",
      "2800 steps | score: [0.31293219327926636, -0.8067136406898499]\n",
      "2900 steps | score: [0.20932263135910034, -0.5369671583175659]\n",
      "unknown params:  tensor([ 0.6607, -0.3431,  0.6735,  0.6336, -0.1353, -0.1397])\n",
      "gt params:  tensor([ 0.6721, -0.3318,  0.6511,  0.6225, -0.0862, -0.1900])\n",
      "ols params:  tensor([ 0.3132, -0.1652,  0.3173,  0.3008, -0.0634,  3.2079])\n",
      "unknown mse:  tensor(0.0010)\n",
      "ols mse:  tensor(1.9863)\n",
      "gt params:  tensor([ 0.6852, -0.3137,  0.6626,  0.5917, -0.0730, -0.0507])\n",
      "0 steps | score: [0.19246286153793335]\n",
      "100 steps | score: [-0.12307718396186829]\n",
      "200 steps | score: [-0.06007086858153343]\n",
      "300 steps | score: [-0.06214217469096184]\n",
      "400 steps | score: [-0.13866226375102997]\n",
      "500 steps | score: [-0.14030271768569946]\n",
      "600 steps | score: [-0.14707359671592712]\n",
      "700 steps | score: [-0.08774903416633606]\n",
      "800 steps | score: [-0.08620825409889221]\n",
      "900 steps | score: [-0.11015576869249344]\n",
      "1000 steps | score: [-0.1367088407278061]\n",
      "1100 steps | score: [-0.12717309594154358]\n",
      "1200 steps | score: [-0.13347597420215607]\n",
      "1300 steps | score: [-0.10115065425634384]\n",
      "1400 steps | score: [-0.09779092669487]\n",
      "1500 steps | score: [-0.12216128408908844]\n",
      "1600 steps | score: [-0.12403877079486847]\n",
      "1700 steps | score: [-0.12580199539661407]\n",
      "1800 steps | score: [-0.09926653653383255]\n",
      "1900 steps | score: [-0.09807078540325165]\n",
      "2000 steps | score: [-0.11030462384223938]\n",
      "2100 steps | score: [-0.1322973072528839]\n",
      "2200 steps | score: [-0.1156323030591011]\n",
      "2300 steps | score: [-0.0970332995057106]\n",
      "2400 steps | score: [-0.10004764795303345]\n",
      "2500 steps | score: [-0.11514865607023239]\n",
      "2600 steps | score: [-0.1120195984840393]\n",
      "2700 steps | score: [-0.10853374004364014]\n",
      "2800 steps | score: [-0.12398188561201096]\n",
      "2900 steps | score: [-0.09206566959619522]\n",
      "0 steps | score: [0.03124024160206318, 0.37335073947906494]\n",
      "100 steps | score: [0.04790573567152023, 0.1648595780134201]\n",
      "200 steps | score: [0.4825839698314667, -1.081581473350525]\n",
      "300 steps | score: [0.10968904197216034, -0.07104945182800293]\n",
      "400 steps | score: [-0.287273108959198, 0.8288233280181885]\n",
      "500 steps | score: [-0.40559253096580505, 1.0462641716003418]\n",
      "600 steps | score: [-0.4436022639274597, 1.0999033451080322]\n",
      "700 steps | score: [-0.10229317098855972, 0.37344861030578613]\n",
      "800 steps | score: [0.16998723149299622, -0.2935864329338074]\n",
      "900 steps | score: [-0.1957683563232422, 0.6103981137275696]\n",
      "1000 steps | score: [-0.15397584438323975, 0.5036506652832031]\n",
      "1100 steps | score: [-0.31759360432624817, 0.8467282056808472]\n",
      "1200 steps | score: [-0.23068954050540924, 0.7067569494247437]\n",
      "1300 steps | score: [0.05092298239469528, 0.0206681489944458]\n",
      "1400 steps | score: [-0.14239856600761414, 0.47794684767723083]\n",
      "1500 steps | score: [-0.16585509479045868, 0.5523114204406738]\n",
      "1600 steps | score: [-0.2521055042743683, 0.7374540567398071]\n",
      "1700 steps | score: [-0.1457766592502594, 0.5074388980865479]\n",
      "1800 steps | score: [-0.02467546984553337, 0.2134096622467041]\n",
      "1900 steps | score: [-0.09007883071899414, 0.37503713369369507]\n",
      "2000 steps | score: [-0.08867698907852173, 0.34275346994400024]\n",
      "2100 steps | score: [-0.23307451605796814, 0.6725565791130066]\n",
      "2200 steps | score: [-0.09225478768348694, 0.3499058485031128]\n",
      "2300 steps | score: [-0.01904677413403988, 0.19734664261341095]\n",
      "2400 steps | score: [-0.06789448112249374, 0.31618601083755493]\n",
      "2500 steps | score: [-0.13820573687553406, 0.4447318911552429]\n",
      "2600 steps | score: [-0.13023893535137177, 0.47548627853393555]\n",
      "2700 steps | score: [-0.09381216019392014, 0.3625008761882782]\n",
      "2800 steps | score: [-0.016049019992351532, 0.21152007579803467]\n",
      "2900 steps | score: [-0.01868041418492794, 0.211595356464386]\n",
      "unknown params:  tensor([ 0.6628, -0.3042,  0.6814,  0.6112, -0.0515, -0.1453])\n",
      "gt params:  tensor([ 0.6852, -0.3137,  0.6626,  0.5917, -0.0730, -0.0507])\n",
      "ols params:  tensor([ 0.3161, -0.1495,  0.3245,  0.2933, -0.0273,  3.3694])\n",
      "unknown mse:  tensor(0.0018)\n",
      "ols mse:  tensor(2.0110)\n",
      "gt params:  tensor([ 0.6689, -0.3262,  0.6866,  0.6006, -0.0628, -0.2020])\n",
      "0 steps | score: [0.36782485246658325]\n",
      "100 steps | score: [0.1150231659412384]\n",
      "200 steps | score: [0.14352822303771973]\n",
      "300 steps | score: [0.0565013587474823]\n",
      "400 steps | score: [0.005446983501315117]\n",
      "0 steps | score: [0.0982091873884201, 0.17477625608444214]\n",
      "100 steps | score: [-0.01673951745033264, 0.29326245188713074]\n",
      "200 steps | score: [0.185100257396698, -0.21428102254867554]\n",
      "300 steps | score: [-0.2030111849308014, 0.5787175893783569]\n",
      "400 steps | score: [-0.27037689089775085, 0.6962740421295166]\n",
      "500 steps | score: [-0.24730564653873444, 0.6355581283569336]\n",
      "600 steps | score: [-0.2411518692970276, 0.6548631191253662]\n",
      "700 steps | score: [-0.056972306221723557, 0.26873981952667236]\n",
      "800 steps | score: [-0.04468612000346184, 0.24007858335971832]\n",
      "900 steps | score: [-0.20236016809940338, 0.5690655708312988]\n",
      "1000 steps | score: [-0.17350395023822784, 0.5021066665649414]\n",
      "1100 steps | score: [-0.09573260694742203, 0.3804338276386261]\n",
      "1200 steps | score: [-0.10525989532470703, 0.3502141833305359]\n",
      "1300 steps | score: [-0.12270879000425339, 0.39350625872612]\n",
      "1400 steps | score: [-0.17384684085845947, 0.4968007802963257]\n",
      "1500 steps | score: [-0.06299253553152084, 0.2635543942451477]\n",
      "1600 steps | score: [-0.004348190035670996, 0.12835220992565155]\n",
      "1700 steps | score: [-0.11627041548490524, 0.35995760560035706]\n",
      "1800 steps | score: [-0.1544780135154724, 0.4556226432323456]\n",
      "1900 steps | score: [-0.13977095484733582, 0.43315207958221436]\n",
      "2000 steps | score: [-0.05025254562497139, 0.2529791593551636]\n",
      "2100 steps | score: [-0.07134561985731125, 0.3137286603450775]\n",
      "2200 steps | score: [-0.10822766274213791, 0.36023402214050293]\n",
      "2300 steps | score: [-0.12780244648456573, 0.41700026392936707]\n",
      "2400 steps | score: [-0.0560375414788723, 0.26180657744407654]\n",
      "2500 steps | score: [-0.08633515238761902, 0.3186672031879425]\n",
      "2600 steps | score: [-0.095728799700737, 0.32921141386032104]\n",
      "2700 steps | score: [-0.06229258328676224, 0.2816582918167114]\n",
      "2800 steps | score: [-0.1629103124141693, 0.47397956252098083]\n",
      "2900 steps | score: [-0.08729451149702072, 0.32244956493377686]\n",
      "unknown params:  tensor([ 0.6574, -0.2946,  0.6240,  0.5547, -0.0415,  0.1686])\n",
      "gt params:  tensor([ 0.6689, -0.3262,  0.6866,  0.6006, -0.0628, -0.2020])\n",
      "ols params:  tensor([ 0.3168, -0.1480,  0.3057,  0.2710, -0.0211,  3.5004])\n",
      "unknown mse:  tensor(0.0241)\n",
      "ols mse:  tensor(2.3531)\n",
      "gt params:  tensor([ 0.7038, -0.3393,  0.6428,  0.6250, -0.0736, -0.0439])\n",
      "0 steps | score: [0.19609755277633667]\n",
      "100 steps | score: [-0.04507920891046524]\n",
      "200 steps | score: [-0.07234854996204376]\n",
      "300 steps | score: [-0.05543302372097969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 steps | score: [-0.08394234627485275]\n",
      "500 steps | score: [-0.04673312231898308]\n",
      "600 steps | score: [-0.08039496839046478]\n",
      "700 steps | score: [-0.06659802794456482]\n",
      "800 steps | score: [-0.052991077303886414]\n",
      "900 steps | score: [-0.10279466956853867]\n",
      "1000 steps | score: [-0.05545388162136078]\n",
      "1100 steps | score: [-0.09249664098024368]\n",
      "1200 steps | score: [-0.038427285850048065]\n",
      "1300 steps | score: [-0.06014539673924446]\n",
      "1400 steps | score: [-0.11878448724746704]\n",
      "1500 steps | score: [-0.06273627281188965]\n",
      "1600 steps | score: [-0.09668316692113876]\n",
      "1700 steps | score: [-0.06724211573600769]\n",
      "1800 steps | score: [-0.05891970545053482]\n",
      "1900 steps | score: [-0.09915585815906525]\n",
      "2000 steps | score: [-0.055077917873859406]\n",
      "2100 steps | score: [-0.09385474771261215]\n",
      "2200 steps | score: [-0.04755110293626785]\n",
      "2300 steps | score: [-0.051834721118211746]\n",
      "2400 steps | score: [-0.0781383216381073]\n",
      "2500 steps | score: [-0.043027184903621674]\n",
      "0 steps | score: [0.2146638184785843, -0.31635165214538574]\n",
      "100 steps | score: [0.10324379056692123, -0.2437511682510376]\n",
      "200 steps | score: [-0.20626412332057953, 0.32806631922721863]\n",
      "300 steps | score: [-0.003891122294589877, -0.08305530250072479]\n",
      "400 steps | score: [0.25856706500053406, -0.723594069480896]\n",
      "500 steps | score: [0.037366271018981934, -0.24709689617156982]\n",
      "600 steps | score: [0.07289426028728485, -0.33837419748306274]\n",
      "700 steps | score: [-0.1568577140569687, 0.19297020137310028]\n",
      "800 steps | score: [-0.0013546572299674153, -0.11316189914941788]\n",
      "900 steps | score: [-0.011465090326964855, -0.12959805130958557]\n",
      "1000 steps | score: [0.08038900047540665, -0.3181079626083374]\n",
      "1100 steps | score: [0.03148186206817627, -0.21661527454853058]\n",
      "1200 steps | score: [-0.0043357680551707745, -0.11279277503490448]\n",
      "1300 steps | score: [0.19964438676834106, -0.5954890847206116]\n",
      "1400 steps | score: [-0.1201707273721695, 0.11852052807807922]\n",
      "1500 steps | score: [0.030960913747549057, -0.23627915978431702]\n",
      "1600 steps | score: [-0.04575258493423462, -0.04063302278518677]\n",
      "1700 steps | score: [0.20128777623176575, -0.6299733519554138]\n",
      "1800 steps | score: [0.07424797117710114, -0.28324270248413086]\n",
      "1900 steps | score: [-0.020360805094242096, -0.08380188047885895]\n",
      "2000 steps | score: [0.14811477065086365, -0.5140321850776672]\n",
      "2100 steps | score: [-0.008839134126901627, -0.12495765089988708]\n",
      "2200 steps | score: [0.1372290551662445, -0.45614418387413025]\n",
      "2300 steps | score: [0.02991412580013275, -0.18373332917690277]\n",
      "2400 steps | score: [0.013781210407614708, -0.17998415231704712]\n",
      "2500 steps | score: [0.1263132095336914, -0.4763418436050415]\n",
      "unknown params:  tensor([ 0.7431, -0.4003,  0.6967,  0.6554, -0.0872, -0.0110])\n",
      "gt params:  tensor([ 0.7038, -0.3393,  0.6428,  0.6250, -0.0736, -0.0439])\n",
      "ols params:  tensor([ 0.3359, -0.1849,  0.3195,  0.2997, -0.0373,  3.5719])\n",
      "unknown mse:  tensor(0.0017)\n",
      "ols mse:  tensor(2.2408)\n",
      "gt params:  tensor([ 0.6866, -0.3406,  0.6601,  0.6037, -0.0826, -0.0688])\n",
      "0 steps | score: [0.32617637515068054]\n",
      "100 steps | score: [0.02138177864253521]\n",
      "200 steps | score: [-0.021994542330503464]\n",
      "300 steps | score: [-0.009135637432336807]\n",
      "0 steps | score: [-0.01036890409886837, 0.41169893741607666]\n",
      "100 steps | score: [-0.09941022843122482, 0.45226824283599854]\n",
      "200 steps | score: [-0.22713401913642883, 0.6593696475028992]\n",
      "300 steps | score: [-0.4512229263782501, 1.0602774620056152]\n",
      "400 steps | score: [-0.03928784653544426, 0.21059109270572662]\n",
      "500 steps | score: [-0.07460018992424011, 0.27878668904304504]\n",
      "600 steps | score: [-0.06310251355171204, 0.2573756277561188]\n",
      "700 steps | score: [-0.2866978347301483, 0.7539868950843811]\n",
      "800 steps | score: [-0.30293580889701843, 0.7503102421760559]\n",
      "900 steps | score: [-0.1818612664937973, 0.4931057095527649]\n",
      "1000 steps | score: [-0.2250649780035019, 0.5912948846817017]\n",
      "1100 steps | score: [-0.2401670664548874, 0.6461871862411499]\n",
      "1200 steps | score: [-0.3622828423976898, 0.9222124218940735]\n",
      "1300 steps | score: [-0.2619416117668152, 0.664628803730011]\n",
      "1400 steps | score: [-0.2655473053455353, 0.6926956176757812]\n",
      "1500 steps | score: [-0.12276604026556015, 0.3321995139122009]\n",
      "1600 steps | score: [-0.2680813670158386, 0.6643091440200806]\n",
      "1700 steps | score: [-0.2923351228237152, 0.7624894380569458]\n",
      "1800 steps | score: [-0.2649224102497101, 0.6935686469078064]\n",
      "1900 steps | score: [-0.20558284223079681, 0.5381252765655518]\n",
      "2000 steps | score: [-0.09446296095848083, 0.3234170079231262]\n",
      "2100 steps | score: [-0.13582418859004974, 0.3872356414794922]\n",
      "2200 steps | score: [-0.2569153308868408, 0.6639854907989502]\n",
      "2300 steps | score: [-0.15831616520881653, 0.42085400223731995]\n",
      "2400 steps | score: [-0.21901042759418488, 0.5568742156028748]\n",
      "2500 steps | score: [-0.10890308767557144, 0.3672168254852295]\n",
      "unknown params:  tensor([ 0.7454, -0.4223,  0.6639,  0.6545, -0.0797, -0.0425])\n",
      "gt params:  tensor([ 0.6866, -0.3406,  0.6601,  0.6037, -0.0826, -0.0688])\n",
      "ols params:  tensor([ 0.3226, -0.1860,  0.2871,  0.2848, -0.0321,  3.6284])\n",
      "unknown mse:  tensor(0.0022)\n",
      "ols mse:  tensor(2.3447)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/ed818b24-6d37-40d7-9938-aaf60c414d13\n",
      "gt params:  tensor([-0.9228, -0.3708,  0.6402, -0.4103,  0.9594,  0.8428])\n",
      "0 steps | score: [0.2062152922153473]\n",
      "100 steps | score: [0.07250979542732239]\n",
      "200 steps | score: [0.11703789234161377]\n",
      "300 steps | score: [0.23476797342300415]\n",
      "400 steps | score: [0.10809477418661118]\n",
      "500 steps | score: [0.15094834566116333]\n",
      "600 steps | score: [0.11975343525409698]\n",
      "700 steps | score: [0.1013408824801445]\n",
      "800 steps | score: [0.19504886865615845]\n",
      "900 steps | score: [0.12755656242370605]\n",
      "1000 steps | score: [0.09019484370946884]\n",
      "1100 steps | score: [0.0803864598274231]\n",
      "1200 steps | score: [0.08732366561889648]\n",
      "1300 steps | score: [0.16225744783878326]\n",
      "1400 steps | score: [0.14762429893016815]\n",
      "1500 steps | score: [0.1453407108783722]\n",
      "1600 steps | score: [0.15735359489917755]\n",
      "1700 steps | score: [0.11670776456594467]\n",
      "1800 steps | score: [0.06270158290863037]\n",
      "1900 steps | score: [0.17246447503566742]\n",
      "2000 steps | score: [0.1733814924955368]\n",
      "2100 steps | score: [0.13311588764190674]\n",
      "2200 steps | score: [0.1337326616048813]\n",
      "2300 steps | score: [0.12882566452026367]\n",
      "2400 steps | score: [0.12285894900560379]\n",
      "2500 steps | score: [0.1504262387752533]\n",
      "2600 steps | score: [0.15820147097110748]\n",
      "2700 steps | score: [0.13759757578372955]\n",
      "2800 steps | score: [0.13262201845645905]\n",
      "0 steps | score: [-0.10853633284568787, 1.644597053527832]\n",
      "100 steps | score: [-0.7733691930770874, 8.263781547546387]\n",
      "200 steps | score: [0.6273136138916016, 1.6188946962356567]\n",
      "300 steps | score: [-1.6166702508926392, 10.95979118347168]\n",
      "400 steps | score: [-0.5543078184127808, 6.412351608276367]\n",
      "500 steps | score: [-0.7603629231452942, 7.450493335723877]\n",
      "600 steps | score: [-2.8277246952056885, 13.89909553527832]\n",
      "700 steps | score: [-4.469235420227051, 15.63885498046875]\n",
      "800 steps | score: [1.1871883869171143, -2.1285243034362793]\n",
      "900 steps | score: [-0.37960463762283325, 5.641785621643066]\n",
      "1000 steps | score: [1.9684761762619019, -10.935251235961914]\n",
      "1100 steps | score: [0.10022920370101929, 1.2235429286956787]\n",
      "1200 steps | score: [-0.12360183894634247, 4.056346893310547]\n",
      "1300 steps | score: [0.3117363154888153, 0.5952893495559692]\n",
      "1400 steps | score: [-0.03370365872979164, 1.9882956743240356]\n",
      "1500 steps | score: [0.23399618268013, -0.20727016031742096]\n",
      "1600 steps | score: [-0.26223990321159363, 2.6661996841430664]\n",
      "1700 steps | score: [-0.330576092004776, 2.8301784992218018]\n",
      "1800 steps | score: [-0.5361410975456238, 3.860262870788574]\n",
      "1900 steps | score: [0.49068644642829895, -2.9582135677337646]\n",
      "2000 steps | score: [0.0598861388862133, 0.07195058465003967]\n",
      "2100 steps | score: [0.20081855356693268, -0.6841830015182495]\n",
      "2200 steps | score: [-0.031538691371679306, 0.7208127379417419]\n",
      "2300 steps | score: [-0.18357223272323608, 1.6161091327667236]\n",
      "2400 steps | score: [-0.10128047317266464, 1.0214134454727173]\n",
      "2500 steps | score: [-0.07880046218633652, 0.9507707357406616]\n",
      "2600 steps | score: [-0.03750187158584595, 0.620385468006134]\n",
      "2700 steps | score: [-0.15109783411026, 1.3730239868164062]\n",
      "2800 steps | score: [-0.16752327978610992, 1.5722615718841553]\n",
      "unknown params:  tensor([-0.9721, -0.4360,  0.6582, -0.4749,  0.9720,  0.4282])\n",
      "gt params:  tensor([-0.9228, -0.3708,  0.6402, -0.4103,  0.9594,  0.8428])\n",
      "ols params:  tensor([-0.8664, -0.3468,  0.5993, -0.3851,  0.8998,  1.1732])\n",
      "unknown mse:  tensor(0.0305)\n",
      "ols mse:  tensor(0.0198)\n",
      "gt params:  tensor([-0.9225, -0.3689,  0.6358, -0.4112,  0.9548,  0.8256])\n",
      "0 steps | score: [0.1609019637107849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [0.017005104571580887]\n",
      "200 steps | score: [0.0999617651104927]\n",
      "300 steps | score: [0.024133967235684395]\n",
      "400 steps | score: [0.040765367448329926]\n",
      "500 steps | score: [0.04821174591779709]\n",
      "600 steps | score: [0.07143072783946991]\n",
      "700 steps | score: [0.07657641917467117]\n",
      "800 steps | score: [0.06967462599277496]\n",
      "900 steps | score: [-0.02354903519153595]\n",
      "1000 steps | score: [0.023814614862203598]\n",
      "1100 steps | score: [-0.011428888887166977]\n",
      "1200 steps | score: [0.0434708334505558]\n",
      "1300 steps | score: [0.041514649987220764]\n",
      "1400 steps | score: [0.0603543259203434]\n",
      "1500 steps | score: [0.04354463145136833]\n",
      "1600 steps | score: [-0.03242120146751404]\n",
      "1700 steps | score: [0.06863613426685333]\n",
      "1800 steps | score: [0.05127311497926712]\n",
      "1900 steps | score: [0.06817810237407684]\n",
      "2000 steps | score: [0.03344860300421715]\n",
      "2100 steps | score: [0.03075195476412773]\n",
      "2200 steps | score: [0.006649155169725418]\n",
      "0 steps | score: [0.18462881445884705, -0.7623481750488281]\n",
      "100 steps | score: [-1.7962270975112915, 5.18001127243042]\n",
      "200 steps | score: [-0.3090497851371765, 1.7070435285568237]\n",
      "300 steps | score: [-2.918158769607544, 6.024062633514404]\n",
      "400 steps | score: [0.0017322913045063615, 0.3228898048400879]\n",
      "500 steps | score: [0.10646605491638184, -0.5001769065856934]\n",
      "600 steps | score: [-0.17361333966255188, 0.580546498298645]\n",
      "700 steps | score: [0.1237810030579567, -0.6724666953086853]\n",
      "800 steps | score: [0.04399535804986954, -0.39090442657470703]\n",
      "900 steps | score: [0.06636745482683182, -0.555160403251648]\n",
      "1000 steps | score: [0.19519023597240448, -1.1628921031951904]\n",
      "1100 steps | score: [-0.038546495139598846, -0.18767285346984863]\n",
      "1200 steps | score: [-0.041692014783620834, -0.1006091833114624]\n",
      "1300 steps | score: [0.03779476135969162, -0.47189563512802124]\n",
      "1400 steps | score: [0.11221705377101898, -0.7392045259475708]\n",
      "1500 steps | score: [0.017839523032307625, -0.3757114112377167]\n",
      "1600 steps | score: [-0.1162804514169693, 0.21999108791351318]\n",
      "1700 steps | score: [0.18290236592292786, -1.0834965705871582]\n",
      "1800 steps | score: [0.2548069357872009, -1.5027035474777222]\n",
      "1900 steps | score: [0.06499321013689041, -0.5599811673164368]\n",
      "2000 steps | score: [-0.06503600627183914, 0.04185885190963745]\n",
      "2100 steps | score: [0.16113407909870148, -0.9966630935668945]\n",
      "2200 steps | score: [0.09414244443178177, -0.7395669221878052]\n",
      "2300 steps | score: [0.0512254424393177, -0.5152014493942261]\n",
      "2400 steps | score: [0.07959917932748795, -0.6898024678230286]\n",
      "2500 steps | score: [0.033814504742622375, -0.4374347925186157]\n",
      "2600 steps | score: [0.10538379102945328, -0.7764376997947693]\n",
      "2700 steps | score: [-0.015559280291199684, -0.18315839767456055]\n",
      "2800 steps | score: [0.08400160819292068, -0.7509793043136597]\n",
      "unknown params:  tensor([-0.9403, -0.3786,  0.6435, -0.4249,  0.9703,  0.5364])\n",
      "gt params:  tensor([-0.9225, -0.3689,  0.6358, -0.4112,  0.9548,  0.8256])\n",
      "ols params:  tensor([-0.8167, -0.3318,  0.5625, -0.3709,  0.8444,  1.4526])\n",
      "unknown mse:  tensor(0.0141)\n",
      "ols mse:  tensor(0.0708)\n",
      "gt params:  tensor([-0.9193, -0.3740,  0.6524, -0.4149,  0.9591,  0.8259])\n",
      "0 steps | score: [0.074095219373703]\n",
      "100 steps | score: [-0.04086639732122421]\n",
      "200 steps | score: [-0.055965691804885864]\n",
      "300 steps | score: [-0.1008220762014389]\n",
      "400 steps | score: [-0.004640035331249237]\n",
      "0 steps | score: [-0.0046514240093529224, 0.35564517974853516]\n",
      "100 steps | score: [-0.0002960966376122087, 0.038310736417770386]\n",
      "200 steps | score: [-0.004985503386706114, -0.08098277449607849]\n",
      "300 steps | score: [0.30415353178977966, -1.304324984550476]\n",
      "400 steps | score: [0.141251340508461, -0.6086986064910889]\n",
      "500 steps | score: [0.1548498570919037, -0.7581976652145386]\n",
      "600 steps | score: [-0.10855965316295624, 0.300337016582489]\n",
      "700 steps | score: [-0.04559573531150818, 0.058899372816085815]\n",
      "800 steps | score: [-0.2649306654930115, 0.908287525177002]\n",
      "900 steps | score: [-0.021885572001338005, -0.13045760989189148]\n",
      "1000 steps | score: [-0.21659646928310394, 0.773402750492096]\n",
      "1100 steps | score: [-0.0735979825258255, 0.08840370178222656]\n",
      "1200 steps | score: [0.12364520132541656, -0.6475270986557007]\n",
      "1300 steps | score: [-0.21824955940246582, 0.7772709131240845]\n",
      "1400 steps | score: [-0.16456453502178192, 0.5604156851768494]\n",
      "1500 steps | score: [-0.16367895901203156, 0.5274088382720947]\n",
      "1600 steps | score: [-0.2503296732902527, 0.8717869520187378]\n",
      "1700 steps | score: [-0.06471001356840134, 0.099476158618927]\n",
      "1800 steps | score: [-0.000207206976483576, -0.1617252230644226]\n",
      "1900 steps | score: [0.027485636994242668, -0.25677502155303955]\n",
      "2000 steps | score: [-0.1644124835729599, 0.4828276038169861]\n",
      "2100 steps | score: [-0.16246439516544342, 0.4547349810600281]\n",
      "2200 steps | score: [-0.1871442347764969, 0.6367555260658264]\n",
      "2300 steps | score: [-0.14635120332241058, 0.3874254524707794]\n",
      "2400 steps | score: [-0.20174935460090637, 0.6863182783126831]\n",
      "2500 steps | score: [-0.1777973175048828, 0.5955100059509277]\n",
      "2600 steps | score: [-0.08767461031675339, 0.2416202276945114]\n",
      "2700 steps | score: [-0.17055538296699524, 0.5273122787475586]\n",
      "2800 steps | score: [-0.1943719983100891, 0.6464362740516663]\n",
      "unknown params:  tensor([-0.9246, -0.3834,  0.6569, -0.4111,  0.9739,  0.6763])\n",
      "gt params:  tensor([-0.9193, -0.3740,  0.6524, -0.4149,  0.9591,  0.8259])\n",
      "ols params:  tensor([-0.7696, -0.3211,  0.5506, -0.3467,  0.8094,  1.7048])\n",
      "unknown mse:  tensor(0.0038)\n",
      "ols mse:  tensor(0.1392)\n",
      "gt params:  tensor([-0.9243, -0.3592,  0.6468, -0.4211,  0.9688,  0.8203])\n",
      "0 steps | score: [0.26949945092201233]\n",
      "100 steps | score: [0.1008310616016388]\n",
      "200 steps | score: [0.10825293511152267]\n",
      "300 steps | score: [0.15105462074279785]\n",
      "400 steps | score: [0.006939556449651718]\n",
      "0 steps | score: [0.2506192624568939, -0.6507054567337036]\n",
      "100 steps | score: [-0.2610176205635071, 0.8314242959022522]\n",
      "200 steps | score: [0.15238112211227417, -0.6621271371841431]\n",
      "300 steps | score: [-0.11550755053758621, 0.26618024706840515]\n",
      "400 steps | score: [0.10029324889183044, -0.5391543507575989]\n",
      "500 steps | score: [0.09802288562059402, -0.5511922836303711]\n",
      "600 steps | score: [0.058223139494657516, -0.33917275071144104]\n",
      "700 steps | score: [-0.049765877425670624, 0.11616551876068115]\n",
      "800 steps | score: [0.22706100344657898, -0.9946320056915283]\n",
      "900 steps | score: [0.1549629122018814, -0.7698838710784912]\n",
      "1000 steps | score: [0.07255454361438751, -0.4700896739959717]\n",
      "1100 steps | score: [0.35877525806427, -1.5244460105895996]\n",
      "1200 steps | score: [0.3072930574417114, -1.331297755241394]\n",
      "1300 steps | score: [-0.02115599438548088, -0.13350608944892883]\n",
      "1400 steps | score: [0.24223926663398743, -1.129562258720398]\n",
      "1500 steps | score: [0.11626314371824265, -0.5810885429382324]\n",
      "1600 steps | score: [0.043113380670547485, -0.3276043236255646]\n",
      "1700 steps | score: [-0.0028149199206382036, -0.17849016189575195]\n",
      "1800 steps | score: [0.2307010442018509, -1.0977108478546143]\n",
      "1900 steps | score: [0.13986247777938843, -0.7502830028533936]\n",
      "2000 steps | score: [0.11776413768529892, -0.6703194379806519]\n",
      "2100 steps | score: [0.16446222364902496, -0.8127097487449646]\n",
      "2200 steps | score: [0.24182626605033875, -1.1252906322479248]\n",
      "2300 steps | score: [0.10170571506023407, -0.5851852893829346]\n",
      "2400 steps | score: [0.2419891059398651, -1.0840704441070557]\n",
      "2500 steps | score: [0.1812019795179367, -0.8381599187850952]\n",
      "2600 steps | score: [0.10239238291978836, -0.5975019931793213]\n",
      "2700 steps | score: [0.15327057242393494, -0.7874022126197815]\n",
      "2800 steps | score: [0.22397375106811523, -1.0504252910614014]\n",
      "unknown params:  tensor([-0.9338, -0.3544,  0.6509, -0.4239,  0.9966,  0.6108])\n",
      "gt params:  tensor([-0.9243, -0.3592,  0.6468, -0.4211,  0.9688,  0.8203])\n",
      "ols params:  tensor([-0.7400, -0.2859,  0.5215, -0.3465,  0.7906,  1.9259])\n",
      "unknown mse:  tensor(0.0075)\n",
      "ols mse:  tensor(0.2191)\n",
      "gt params:  tensor([-0.9210, -0.3596,  0.6465, -0.4179,  0.9500,  0.8173])\n",
      "0 steps | score: [0.24780960381031036]\n",
      "100 steps | score: [0.13618800044059753]\n",
      "200 steps | score: [0.19773299992084503]\n",
      "300 steps | score: [0.20881009101867676]\n",
      "400 steps | score: [0.14954213798046112]\n",
      "500 steps | score: [0.0830347090959549]\n",
      "600 steps | score: [0.12485771626234055]\n",
      "700 steps | score: [0.1325613409280777]\n",
      "800 steps | score: [0.15536190569400787]\n",
      "900 steps | score: [0.11134073883295059]\n",
      "1000 steps | score: [0.1261061429977417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 steps | score: [0.1373813897371292]\n",
      "1200 steps | score: [0.12776364386081696]\n",
      "1300 steps | score: [0.11998578906059265]\n",
      "1400 steps | score: [0.16746509075164795]\n",
      "1500 steps | score: [0.1331360787153244]\n",
      "1600 steps | score: [0.09565499424934387]\n",
      "1700 steps | score: [0.12208034098148346]\n",
      "1800 steps | score: [0.15073363482952118]\n",
      "1900 steps | score: [0.15710638463497162]\n",
      "2000 steps | score: [0.1611553430557251]\n",
      "2100 steps | score: [0.10368918627500534]\n",
      "2200 steps | score: [0.09421248733997345]\n",
      "2300 steps | score: [0.12153967469930649]\n",
      "2400 steps | score: [0.14771679043769836]\n",
      "2500 steps | score: [0.1724049299955368]\n",
      "2600 steps | score: [0.12706871330738068]\n",
      "2700 steps | score: [0.12084194272756577]\n",
      "2800 steps | score: [0.11449918150901794]\n",
      "0 steps | score: [0.07008644938468933, 0.12633639574050903]\n",
      "100 steps | score: [-0.3703068196773529, 1.2046459913253784]\n",
      "200 steps | score: [-0.1967308074235916, 0.6622090339660645]\n",
      "300 steps | score: [-0.06400470435619354, 0.30273985862731934]\n",
      "400 steps | score: [0.5340234041213989, -1.829386830329895]\n",
      "500 steps | score: [-0.007874737493693829, 0.07322247326374054]\n",
      "600 steps | score: [-0.15784932672977448, 0.5449439287185669]\n",
      "700 steps | score: [-0.09141745418310165, 0.3455328345298767]\n",
      "800 steps | score: [-0.011504864320158958, 0.06807948648929596]\n",
      "900 steps | score: [-0.26960933208465576, 0.8986716866493225]\n",
      "1000 steps | score: [-0.09379687160253525, 0.3637552559375763]\n",
      "1100 steps | score: [-0.061794035136699677, 0.24475708603858948]\n",
      "1200 steps | score: [0.035776287317276, -0.058045290410518646]\n",
      "1300 steps | score: [-0.1845245063304901, 0.6214119791984558]\n",
      "1400 steps | score: [-0.19522862136363983, 0.6579961180686951]\n",
      "1500 steps | score: [0.0814003050327301, -0.28594696521759033]\n",
      "1600 steps | score: [-0.16911382973194122, 0.5283926725387573]\n",
      "1700 steps | score: [0.03394294157624245, -0.07505611330270767]\n",
      "1800 steps | score: [0.15028934180736542, -0.474750816822052]\n",
      "1900 steps | score: [-0.05644276738166809, 0.22991715371608734]\n",
      "2000 steps | score: [-0.029845107346773148, 0.12026596069335938]\n",
      "2100 steps | score: [-0.14612789452075958, 0.46969079971313477]\n",
      "2200 steps | score: [-0.08429218828678131, 0.30205315351486206]\n",
      "2300 steps | score: [-0.11802777647972107, 0.4186343550682068]\n",
      "2400 steps | score: [-0.12706907093524933, 0.42325156927108765]\n",
      "2500 steps | score: [-0.07174786180257797, 0.2395780086517334]\n",
      "2600 steps | score: [-0.20379559695720673, 0.6445980072021484]\n",
      "2700 steps | score: [-0.1066400408744812, 0.3769837021827698]\n",
      "2800 steps | score: [-0.05853644758462906, 0.21895374357700348]\n",
      "unknown params:  tensor([-0.8909, -0.3286,  0.6278, -0.3994,  0.9223,  0.7528])\n",
      "gt params:  tensor([-0.9210, -0.3596,  0.6465, -0.4179,  0.9500,  0.8173])\n",
      "ols params:  tensor([-0.6965, -0.2626,  0.4982, -0.3189,  0.7209,  2.1813])\n",
      "unknown mse:  tensor(0.0012)\n",
      "ols mse:  tensor(0.3341)\n",
      "gt params:  tensor([-0.9235, -0.3623,  0.6439, -0.4359,  0.9632,  0.8211])\n",
      "0 steps | score: [0.15971608459949493]\n",
      "100 steps | score: [0.0013844221830368042]\n",
      "0 steps | score: [0.08268111944198608, 0.13863493502140045]\n",
      "100 steps | score: [-0.30578354001045227, 1.0385158061981201]\n",
      "200 steps | score: [-0.10717746615409851, 0.42336010932922363]\n",
      "300 steps | score: [0.2898271381855011, -0.891425609588623]\n",
      "400 steps | score: [-0.3300468623638153, 1.00466787815094]\n",
      "500 steps | score: [0.17180082201957703, -0.5336686372756958]\n",
      "600 steps | score: [-0.07907344400882721, 0.2515765428543091]\n",
      "700 steps | score: [-0.14513647556304932, 0.5106478333473206]\n",
      "800 steps | score: [0.09761437773704529, -0.27659791707992554]\n",
      "900 steps | score: [0.07558514177799225, -0.1847761571407318]\n",
      "1000 steps | score: [-0.09326992928981781, 0.3408161401748657]\n",
      "1100 steps | score: [-0.12129396945238113, 0.42194148898124695]\n",
      "1200 steps | score: [-0.16522549092769623, 0.5332331657409668]\n",
      "1300 steps | score: [-0.06238391622900963, 0.23480084538459778]\n",
      "1400 steps | score: [-0.11108534038066864, 0.41286852955818176]\n",
      "1500 steps | score: [-0.049349844455718994, 0.20439517498016357]\n",
      "1600 steps | score: [-0.0059246183373034, 0.0138653963804245]\n",
      "1700 steps | score: [-0.09856380522251129, 0.3614010214805603]\n",
      "1800 steps | score: [0.019078237935900688, -0.027364596724510193]\n",
      "1900 steps | score: [-0.07706242799758911, 0.3214547336101532]\n",
      "2000 steps | score: [-0.08451691269874573, 0.2871983051300049]\n",
      "2100 steps | score: [-0.08293287456035614, 0.3097954988479614]\n",
      "2200 steps | score: [-0.026153426617383957, 0.13983316719532013]\n",
      "2300 steps | score: [-0.08098556101322174, 0.31641194224357605]\n",
      "2400 steps | score: [-0.040146343410015106, 0.19921258091926575]\n",
      "2500 steps | score: [-0.05706578120589256, 0.2640689015388489]\n",
      "2600 steps | score: [-0.14908719062805176, 0.4901554584503174]\n",
      "2700 steps | score: [-0.13463149964809418, 0.46188274025917053]\n",
      "2800 steps | score: [-0.00824231281876564, 0.05656598508358002]\n",
      "unknown params:  tensor([-0.9079, -0.3656,  0.6428, -0.4339,  0.9575,  0.7136])\n",
      "gt params:  tensor([-0.9235, -0.3623,  0.6439, -0.4359,  0.9632,  0.8211])\n",
      "ols params:  tensor([-0.6755, -0.2764,  0.4781, -0.3295,  0.7088,  2.3721])\n",
      "unknown mse:  tensor(0.0020)\n",
      "ols mse:  tensor(0.4297)\n",
      "gt params:  tensor([-0.9293, -0.3755,  0.6424, -0.3920,  0.9553,  0.8007])\n",
      "0 steps | score: [0.19451843202114105]\n",
      "100 steps | score: [-0.06222270429134369]\n",
      "200 steps | score: [0.046722911298274994]\n",
      "300 steps | score: [0.03280126675963402]\n",
      "400 steps | score: [0.08175881206989288]\n",
      "500 steps | score: [-0.012631341814994812]\n",
      "600 steps | score: [-0.03959609940648079]\n",
      "700 steps | score: [0.005010619759559631]\n",
      "0 steps | score: [0.3580879867076874, -0.454453706741333]\n",
      "100 steps | score: [-0.05329934507608414, 0.36230355501174927]\n",
      "200 steps | score: [0.1835549771785736, -0.24186141788959503]\n",
      "300 steps | score: [0.12842361629009247, -0.10316665470600128]\n",
      "400 steps | score: [0.3280075490474701, -0.6085309982299805]\n",
      "500 steps | score: [0.14482532441616058, -0.15882185101509094]\n",
      "600 steps | score: [0.14339451491832733, -0.14406123757362366]\n",
      "700 steps | score: [0.06581766903400421, 0.015165001153945923]\n",
      "800 steps | score: [0.15102478861808777, -0.16692416369915009]\n",
      "900 steps | score: [0.02448847144842148, 0.12044839560985565]\n",
      "1000 steps | score: [0.14889973402023315, -0.13536101579666138]\n",
      "1100 steps | score: [0.32521769404411316, -0.6582942605018616]\n",
      "1200 steps | score: [0.13356830179691315, -0.14332395792007446]\n",
      "1300 steps | score: [0.16739165782928467, -0.26631635427474976]\n",
      "1400 steps | score: [0.09461463987827301, -0.03608937934041023]\n",
      "1500 steps | score: [0.12198860943317413, -0.06334339082241058]\n",
      "1600 steps | score: [0.1493445336818695, -0.1614755392074585]\n",
      "1700 steps | score: [0.09965290874242783, -0.06449444591999054]\n",
      "1800 steps | score: [0.17782443761825562, -0.2179465889930725]\n",
      "1900 steps | score: [0.2513238191604614, -0.45145997405052185]\n",
      "2000 steps | score: [0.14160284399986267, -0.1976778209209442]\n",
      "2100 steps | score: [0.23246827721595764, -0.4171031713485718]\n",
      "2200 steps | score: [0.18941986560821533, -0.2673787772655487]\n",
      "2300 steps | score: [0.19349084794521332, -0.2987133264541626]\n",
      "2400 steps | score: [0.21631141006946564, -0.36123067140579224]\n",
      "2500 steps | score: [0.19132986664772034, -0.2795090973377228]\n",
      "2600 steps | score: [0.1653263121843338, -0.2040213942527771]\n",
      "2700 steps | score: [0.15356574952602386, -0.1868583709001541]\n",
      "unknown params:  tensor([-0.9116, -0.3792,  0.6120, -0.3938,  0.9316,  0.6092])\n",
      "gt params:  tensor([-0.9293, -0.3755,  0.6424, -0.3920,  0.9553,  0.8007])\n",
      "ols params:  tensor([-0.6620, -0.2753,  0.4538, -0.2884,  0.6772,  2.5118])\n",
      "unknown mse:  tensor(0.0064)\n",
      "ols mse:  tensor(0.5221)\n",
      "gt params:  tensor([-0.9258, -0.3629,  0.6374, -0.4070,  0.9500,  0.8326])\n",
      "0 steps | score: [0.24753296375274658]\n",
      "100 steps | score: [-0.0043260483071208]\n",
      "0 steps | score: [0.2673856019973755, -0.35269778966903687]\n",
      "100 steps | score: [0.051412757486104965, 0.01662963256239891]\n",
      "200 steps | score: [0.1696581393480301, -0.30546021461486816]\n",
      "300 steps | score: [-0.1579342633485794, 0.5122075080871582]\n",
      "400 steps | score: [-0.0005827558343298733, 0.11789850145578384]\n",
      "500 steps | score: [0.13704542815685272, -0.27240151166915894]\n",
      "600 steps | score: [0.22580009698867798, -0.5852062106132507]\n",
      "700 steps | score: [0.08333641290664673, -0.11796961724758148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 steps | score: [0.26549941301345825, -0.6708447933197021]\n",
      "900 steps | score: [0.3629169166088104, -0.9525409936904907]\n",
      "1000 steps | score: [0.37654635310173035, -1.0699950456619263]\n",
      "1100 steps | score: [0.33418405055999756, -0.8835664391517639]\n",
      "1200 steps | score: [-0.0044541447423398495, 0.04089424014091492]\n",
      "1300 steps | score: [0.15989331901073456, -0.36893022060394287]\n",
      "1400 steps | score: [0.29064103960990906, -0.7534950971603394]\n",
      "1500 steps | score: [0.019561538472771645, 0.04265526309609413]\n",
      "1600 steps | score: [-0.002973958384245634, 0.05714722350239754]\n",
      "1700 steps | score: [0.14053869247436523, -0.3293350040912628]\n",
      "1800 steps | score: [0.17469361424446106, -0.4462856352329254]\n",
      "1900 steps | score: [0.14980578422546387, -0.33187296986579895]\n",
      "2000 steps | score: [0.17916928231716156, -0.4101352095603943]\n",
      "2100 steps | score: [-0.05049261078238487, 0.20336486399173737]\n",
      "2200 steps | score: [0.13359934091567993, -0.262098103761673]\n",
      "2300 steps | score: [0.08902734518051147, -0.1673915982246399]\n",
      "2400 steps | score: [0.039858974516391754, -0.04487151652574539]\n",
      "2500 steps | score: [0.27987444400787354, -0.718612790107727]\n",
      "2600 steps | score: [0.1698647290468216, -0.4012075662612915]\n",
      "2700 steps | score: [0.15511110424995422, -0.3643966317176819]\n",
      "2800 steps | score: [0.16107474267482758, -0.3811853528022766]\n",
      "unknown params:  tensor([-0.9204, -0.3639,  0.6085, -0.4234,  0.9509,  0.7781])\n",
      "gt params:  tensor([-0.9258, -0.3629,  0.6374, -0.4070,  0.9500,  0.8326])\n",
      "ols params:  tensor([-0.6315, -0.2500,  0.4222, -0.2948,  0.6497,  2.7161])\n",
      "unknown mse:  tensor(0.0007)\n",
      "ols mse:  tensor(0.6327)\n",
      "gt params:  tensor([-0.9207, -0.3757,  0.6436, -0.4189,  0.9690,  0.7761])\n",
      "0 steps | score: [0.27061375975608826]\n",
      "100 steps | score: [0.05377424135804176]\n",
      "200 steps | score: [0.11571703106164932]\n",
      "300 steps | score: [0.12792693078517914]\n",
      "400 steps | score: [0.12264484167098999]\n",
      "500 steps | score: [0.12790820002555847]\n",
      "600 steps | score: [0.11211665719747543]\n",
      "700 steps | score: [0.11960629373788834]\n",
      "800 steps | score: [0.0736132264137268]\n",
      "900 steps | score: [0.12906940281391144]\n",
      "1000 steps | score: [0.0646447166800499]\n",
      "1100 steps | score: [0.12284401059150696]\n",
      "1200 steps | score: [0.12195231020450592]\n",
      "1300 steps | score: [0.14293698966503143]\n",
      "1400 steps | score: [0.12169750034809113]\n",
      "1500 steps | score: [0.13736069202423096]\n",
      "1600 steps | score: [0.09203070402145386]\n",
      "1700 steps | score: [0.11125724762678146]\n",
      "1800 steps | score: [0.1427823007106781]\n",
      "1900 steps | score: [0.10263121873140335]\n",
      "2000 steps | score: [0.16193929314613342]\n",
      "2100 steps | score: [0.13499407470226288]\n",
      "2200 steps | score: [0.13804452121257782]\n",
      "2300 steps | score: [0.10423538833856583]\n",
      "2400 steps | score: [0.12065818905830383]\n",
      "2500 steps | score: [0.11947423964738846]\n",
      "2600 steps | score: [0.13458561897277832]\n",
      "2700 steps | score: [0.12203682959079742]\n",
      "0 steps | score: [0.249271959066391, -0.4181789457798004]\n",
      "100 steps | score: [0.059845421463251114, -0.16899360716342926]\n",
      "200 steps | score: [-0.08031900972127914, 0.1412562131881714]\n",
      "300 steps | score: [0.4796288311481476, -1.398051142692566]\n",
      "400 steps | score: [-0.05220893397927284, 0.12705813348293304]\n",
      "500 steps | score: [0.13030540943145752, -0.35672444105148315]\n",
      "600 steps | score: [0.39200419187545776, -1.1042450666427612]\n",
      "700 steps | score: [0.07773344218730927, -0.27716052532196045]\n",
      "800 steps | score: [0.0036493486259132624, -0.09253381192684174]\n",
      "900 steps | score: [0.019690655171871185, -0.10799232125282288]\n",
      "1000 steps | score: [0.001251181005500257, -0.06907995790243149]\n",
      "1100 steps | score: [0.04755212366580963, -0.1613435447216034]\n",
      "1200 steps | score: [0.059516970068216324, -0.2455531358718872]\n",
      "1300 steps | score: [0.2840157151222229, -0.8241314888000488]\n",
      "1400 steps | score: [0.14654949307441711, -0.4151424169540405]\n",
      "1500 steps | score: [0.09564290940761566, -0.3106946349143982]\n",
      "1600 steps | score: [0.08043524622917175, -0.25474315881729126]\n",
      "1700 steps | score: [0.020244508981704712, -0.1252768337726593]\n",
      "1800 steps | score: [0.03122374415397644, -0.11839871108531952]\n",
      "1900 steps | score: [0.09709257632493973, -0.2600969672203064]\n",
      "2000 steps | score: [0.17032580077648163, -0.498601496219635]\n",
      "2100 steps | score: [0.013524750247597694, -0.10008295625448227]\n",
      "2200 steps | score: [0.10550717264413834, -0.30072158575057983]\n",
      "2300 steps | score: [0.010159475728869438, -0.12006961554288864]\n",
      "2400 steps | score: [0.10669039189815521, -0.33364784717559814]\n",
      "2500 steps | score: [0.05508352816104889, -0.21297454833984375]\n",
      "2600 steps | score: [0.052318282425403595, -0.2088797688484192]\n",
      "2700 steps | score: [0.06155432015657425, -0.20531293749809265]\n",
      "unknown params:  tensor([-0.8828, -0.3855,  0.6324, -0.4003,  0.9168,  0.5983])\n",
      "gt params:  tensor([-0.9207, -0.3757,  0.6436, -0.4189,  0.9690,  0.7761])\n",
      "ols params:  tensor([-0.6136, -0.2699,  0.4470, -0.2870,  0.6348,  2.8367])\n",
      "unknown mse:  tensor(0.0061)\n",
      "ols mse:  tensor(0.7532)\n",
      "gt params:  tensor([-0.9365, -0.3643,  0.6500, -0.4033,  0.9667,  0.7549])\n",
      "0 steps | score: [0.22822582721710205]\n",
      "100 steps | score: [0.0494539812207222]\n",
      "200 steps | score: [0.013745218515396118]\n",
      "300 steps | score: [0.04110529273748398]\n",
      "400 steps | score: [-0.0002385452389717102]\n",
      "0 steps | score: [0.1509728878736496, -0.18454775214195251]\n",
      "100 steps | score: [0.15411566197872162, -0.4597852826118469]\n",
      "200 steps | score: [-0.14677757024765015, 0.2961605191230774]\n",
      "300 steps | score: [-0.12146018445491791, 0.15915006399154663]\n",
      "400 steps | score: [-0.06699070334434509, -0.001182064414024353]\n",
      "500 steps | score: [-0.10222335904836655, 0.10347019135951996]\n",
      "600 steps | score: [0.03161225840449333, -0.25946542620658875]\n",
      "700 steps | score: [0.004286466632038355, -0.1812940239906311]\n",
      "800 steps | score: [-0.02535315975546837, -0.0555553138256073]\n",
      "900 steps | score: [0.07782556861639023, -0.3936595916748047]\n",
      "1000 steps | score: [-0.15846358239650726, 0.24221110343933105]\n",
      "1100 steps | score: [0.24387799203395844, -0.8957012891769409]\n",
      "1200 steps | score: [-0.01905989646911621, -0.138101726770401]\n",
      "1300 steps | score: [-0.06168307363986969, 0.011820301413536072]\n",
      "1400 steps | score: [-0.027702391147613525, -0.11907407641410828]\n",
      "1500 steps | score: [0.010364962741732597, -0.18607473373413086]\n",
      "1600 steps | score: [-0.019513212144374847, -0.13528162240982056]\n",
      "1700 steps | score: [-0.08463909476995468, 0.05115918070077896]\n",
      "1800 steps | score: [-0.03568074479699135, -0.07681016623973846]\n",
      "1900 steps | score: [-0.05812820419669151, -0.045527324080467224]\n",
      "2000 steps | score: [-0.005924100987613201, -0.1796789914369583]\n",
      "2100 steps | score: [0.002261073561385274, -0.20156599581241608]\n",
      "2200 steps | score: [-0.05284468084573746, -0.05434459447860718]\n",
      "2300 steps | score: [-0.06818224489688873, -0.012580357491970062]\n",
      "2400 steps | score: [-0.023425763472914696, -0.12293138355016708]\n",
      "2500 steps | score: [0.026856953278183937, -0.2265569120645523]\n",
      "2600 steps | score: [-0.07632298022508621, 0.020482070744037628]\n",
      "2700 steps | score: [-0.054548293352127075, -0.021632999181747437]\n",
      "unknown params:  tensor([-0.9768, -0.3982,  0.6702, -0.4199,  1.0135,  0.2834])\n",
      "gt params:  tensor([-0.9365, -0.3643,  0.6500, -0.4033,  0.9667,  0.7549])\n",
      "ols params:  tensor([-0.6113, -0.2496,  0.4289, -0.2705,  0.6420,  2.9264])\n",
      "unknown mse:  tensor(0.0380)\n",
      "ols mse:  tensor(0.8344)\n",
      "gt params:  tensor([-0.9241, -0.3723,  0.6529, -0.4064,  0.9580,  0.8526])\n",
      "0 steps | score: [0.2600437104701996]\n",
      "100 steps | score: [-0.018923034891486168]\n",
      "200 steps | score: [0.052108414471149445]\n",
      "300 steps | score: [0.07977146655321121]\n",
      "400 steps | score: [0.05820436030626297]\n",
      "500 steps | score: [0.0961814597249031]\n",
      "600 steps | score: [0.06463240832090378]\n",
      "700 steps | score: [0.04829315468668938]\n",
      "800 steps | score: [0.027796411886811256]\n",
      "900 steps | score: [0.09065628051757812]\n",
      "1000 steps | score: [0.0718129575252533]\n",
      "1100 steps | score: [0.034051939845085144]\n",
      "1200 steps | score: [0.059657711535692215]\n",
      "1300 steps | score: [0.04112672805786133]\n",
      "1400 steps | score: [0.04318498447537422]\n",
      "1500 steps | score: [0.07848994433879852]\n",
      "1600 steps | score: [0.045503076165914536]\n",
      "1700 steps | score: [0.012070219032466412]\n",
      "1800 steps | score: [0.040844544768333435]\n",
      "1900 steps | score: [0.03213447332382202]\n",
      "2000 steps | score: [0.03249282017350197]\n",
      "2100 steps | score: [0.06138112023472786]\n",
      "2200 steps | score: [0.04933921992778778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300 steps | score: [0.05225657671689987]\n",
      "2400 steps | score: [0.0684860348701477]\n",
      "2500 steps | score: [0.01949889585375786]\n",
      "2600 steps | score: [0.03522110730409622]\n",
      "2700 steps | score: [0.05239713937044144]\n",
      "2800 steps | score: [0.05358617752790451]\n",
      "0 steps | score: [0.08615316450595856, -0.05992009863257408]\n",
      "100 steps | score: [-0.2159929871559143, 0.5249412655830383]\n",
      "200 steps | score: [-0.18916009366512299, 0.34975317120552063]\n",
      "300 steps | score: [-0.19259369373321533, 0.39458250999450684]\n",
      "400 steps | score: [-0.030698208138346672, -0.11577419191598892]\n",
      "500 steps | score: [0.06867494434118271, -0.3805115818977356]\n",
      "600 steps | score: [0.06447358429431915, -0.3728029131889343]\n",
      "700 steps | score: [-0.20986026525497437, 0.4001379609107971]\n",
      "800 steps | score: [-0.10964243859052658, 0.1063157245516777]\n",
      "900 steps | score: [-0.11408067494630814, 0.08630441129207611]\n",
      "1000 steps | score: [0.019422393292188644, -0.18448173999786377]\n",
      "1100 steps | score: [-0.15830890834331512, 0.22091618180274963]\n",
      "1200 steps | score: [-0.0826011672616005, 0.06929036974906921]\n",
      "1300 steps | score: [-0.26429352164268494, 0.5134560465812683]\n",
      "1400 steps | score: [-0.22522494196891785, 0.40837037563323975]\n",
      "1500 steps | score: [-0.10156749188899994, 0.15268847346305847]\n",
      "1600 steps | score: [-0.02694649249315262, -0.11509378999471664]\n",
      "1700 steps | score: [-0.14325663447380066, 0.22882752120494843]\n",
      "1800 steps | score: [0.03421270474791527, -0.28941112756729126]\n",
      "1900 steps | score: [-0.05564160272479057, -0.04200896620750427]\n",
      "2000 steps | score: [-0.10458607971668243, 0.12989531457424164]\n",
      "2100 steps | score: [-0.06262198835611343, 0.01752794161438942]\n",
      "2200 steps | score: [-0.05938311666250229, -0.056327637284994125]\n",
      "2300 steps | score: [-0.0732392892241478, 0.03392842411994934]\n",
      "2400 steps | score: [-0.02362261526286602, -0.10185011476278305]\n",
      "2500 steps | score: [0.013851865194737911, -0.25971102714538574]\n",
      "2600 steps | score: [-0.03749105706810951, -0.0757761001586914]\n",
      "2700 steps | score: [-0.10229318588972092, 0.10143614560365677]\n",
      "2800 steps | score: [-0.12699788808822632, 0.17495283484458923]\n",
      "unknown params:  tensor([-0.9250, -0.3854,  0.6036, -0.3644,  0.9568,  0.5692])\n",
      "gt params:  tensor([-0.9241, -0.3723,  0.6529, -0.4064,  0.9580,  0.8526])\n",
      "ols params:  tensor([-0.6052, -0.2558,  0.4098, -0.2466,  0.6287,  3.1057])\n",
      "unknown mse:  tensor(0.0141)\n",
      "ols mse:  tensor(0.8975)\n",
      "gt params:  tensor([-0.9387, -0.3493,  0.6395, -0.4256,  0.9818,  0.7685])\n",
      "0 steps | score: [0.2362733781337738]\n",
      "100 steps | score: [0.013596944510936737]\n",
      "200 steps | score: [0.09198388457298279]\n",
      "300 steps | score: [0.014317192137241364]\n",
      "400 steps | score: [0.06860506534576416]\n",
      "500 steps | score: [0.0341901034116745]\n",
      "600 steps | score: [0.042528633028268814]\n",
      "700 steps | score: [-0.038738444447517395]\n",
      "800 steps | score: [0.14962849020957947]\n",
      "900 steps | score: [0.10132134705781937]\n",
      "1000 steps | score: [0.06421442329883575]\n",
      "1100 steps | score: [0.008519265800714493]\n",
      "0 steps | score: [0.4416904151439667, -0.648297905921936]\n",
      "100 steps | score: [0.3288338780403137, -0.49253278970718384]\n",
      "200 steps | score: [0.02820008620619774, 0.07858564704656601]\n",
      "300 steps | score: [0.25606128573417664, -0.4256960153579712]\n",
      "400 steps | score: [0.2724189758300781, -0.4797898530960083]\n",
      "500 steps | score: [0.22200506925582886, -0.35432136058807373]\n",
      "600 steps | score: [0.17906023561954498, -0.29277560114860535]\n",
      "700 steps | score: [0.17934930324554443, -0.2828340530395508]\n",
      "800 steps | score: [0.18227247893810272, -0.2911641001701355]\n",
      "900 steps | score: [0.30530229210853577, -0.5495314598083496]\n",
      "1000 steps | score: [0.15809033811092377, -0.23126980662345886]\n",
      "1100 steps | score: [0.26607823371887207, -0.47072672843933105]\n",
      "1200 steps | score: [0.05272502079606056, 0.010124966502189636]\n",
      "1300 steps | score: [0.29194700717926025, -0.5564253330230713]\n",
      "1400 steps | score: [0.3225140869617462, -0.6189915537834167]\n",
      "1500 steps | score: [0.15874631702899933, -0.22279556095600128]\n",
      "1600 steps | score: [0.23768632113933563, -0.40282267332077026]\n",
      "1700 steps | score: [0.27513694763183594, -0.5200508832931519]\n",
      "1800 steps | score: [0.07800482958555222, -0.061749495565891266]\n",
      "1900 steps | score: [0.47604429721832275, -1.021997332572937]\n",
      "2000 steps | score: [0.34553882479667664, -0.6730208396911621]\n",
      "2100 steps | score: [0.18748903274536133, -0.29821377992630005]\n",
      "2200 steps | score: [0.14577914774417877, -0.206217959523201]\n",
      "2300 steps | score: [0.244546040892601, -0.44604432582855225]\n",
      "2400 steps | score: [0.19915534555912018, -0.33441439270973206]\n",
      "2500 steps | score: [0.28762051463127136, -0.5398799777030945]\n",
      "2600 steps | score: [0.2823268175125122, -0.5217750668525696]\n",
      "2700 steps | score: [0.33178597688674927, -0.6430312395095825]\n",
      "unknown params:  tensor([-0.9302, -0.3296,  0.6163, -0.4207,  0.9581,  0.4513])\n",
      "gt params:  tensor([-0.9387, -0.3493,  0.6395, -0.4256,  0.9818,  0.7685])\n",
      "ols params:  tensor([-0.5808, -0.2069,  0.3946, -0.2667,  0.5950,  3.2618])\n",
      "unknown mse:  tensor(0.0170)\n",
      "ols mse:  tensor(1.1000)\n",
      "gt params:  tensor([-0.9260, -0.3623,  0.6679, -0.4053,  0.9647,  0.8572])\n",
      "0 steps | score: [0.2413226217031479]\n",
      "100 steps | score: [-0.012083006091415882]\n",
      "200 steps | score: [0.03541168197989464]\n",
      "300 steps | score: [0.006727313622832298]\n",
      "0 steps | score: [0.20048782229423523, -0.0926501527428627]\n",
      "100 steps | score: [-0.1801041215658188, 0.6339755058288574]\n",
      "200 steps | score: [-0.013985239900648594, 0.13421222567558289]\n",
      "300 steps | score: [0.12322156876325607, -0.21437400579452515]\n",
      "400 steps | score: [0.5238320231437683, -1.421837568283081]\n",
      "500 steps | score: [-0.2204424887895584, 0.6239680051803589]\n",
      "600 steps | score: [-0.09364983439445496, 0.3380790054798126]\n",
      "700 steps | score: [-0.06673851609230042, 0.24070605635643005]\n",
      "800 steps | score: [-0.15814577043056488, 0.4723049998283386]\n",
      "900 steps | score: [0.008217010647058487, 0.08484027534723282]\n",
      "1000 steps | score: [-0.12180880457162857, 0.4076266884803772]\n",
      "1100 steps | score: [-0.010878545232117176, 0.14751923084259033]\n",
      "1200 steps | score: [0.03480232134461403, 0.03541058301925659]\n",
      "1300 steps | score: [0.167199045419693, -0.338758647441864]\n",
      "1400 steps | score: [0.1803233027458191, -0.3793003559112549]\n",
      "1500 steps | score: [-0.09922502189874649, 0.310872346162796]\n",
      "1600 steps | score: [0.021103236824274063, 0.04058600962162018]\n",
      "1700 steps | score: [-0.045617587864398956, 0.15773864090442657]\n",
      "1800 steps | score: [-0.09287179261445999, 0.31912943720817566]\n",
      "1900 steps | score: [-0.07868397235870361, 0.2801247537136078]\n",
      "2000 steps | score: [0.13337460160255432, -0.28623083233833313]\n",
      "2100 steps | score: [0.040379151701927185, -0.005913174711167812]\n",
      "2200 steps | score: [-0.052379295229911804, 0.2069719284772873]\n",
      "2300 steps | score: [0.07904726266860962, -0.10539256781339645]\n",
      "2400 steps | score: [0.09911103546619415, -0.15283305943012238]\n",
      "2500 steps | score: [-0.10678712278604507, 0.3421187102794647]\n",
      "2600 steps | score: [-0.08132444322109222, 0.2876552939414978]\n",
      "2700 steps | score: [-0.047627490013837814, 0.19452843070030212]\n",
      "unknown params:  tensor([-0.9221, -0.3427,  0.6483, -0.4098,  0.9513,  0.6193])\n",
      "gt params:  tensor([-0.9260, -0.3623,  0.6679, -0.4053,  0.9647,  0.8572])\n",
      "ols params:  tensor([-0.5889, -0.2225,  0.4233, -0.2640,  0.6050,  3.3351])\n",
      "unknown mse:  tensor(0.0096)\n",
      "ols mse:  tensor(1.0804)\n",
      "gt params:  tensor([-0.9029, -0.3688,  0.6560, -0.4118,  0.9578,  0.8706])\n",
      "0 steps | score: [0.2169705629348755]\n",
      "100 steps | score: [0.06260521709918976]\n",
      "200 steps | score: [0.01377934031188488]\n",
      "300 steps | score: [-0.07866467535495758]\n",
      "400 steps | score: [-0.0665987879037857]\n",
      "500 steps | score: [0.0010176971554756165]\n",
      "0 steps | score: [0.2818950116634369, -0.34973418712615967]\n",
      "100 steps | score: [0.2161480188369751, -0.33063772320747375]\n",
      "200 steps | score: [0.5063714981079102, -1.2045592069625854]\n",
      "300 steps | score: [-0.1524805873632431, 0.40464842319488525]\n",
      "400 steps | score: [0.14943595230579376, -0.3485971689224243]\n",
      "500 steps | score: [0.14691005647182465, -0.25302037596702576]\n",
      "600 steps | score: [0.37023046612739563, -0.8652012944221497]\n",
      "700 steps | score: [0.2499503791332245, -0.5236742496490479]\n",
      "800 steps | score: [0.22564451396465302, -0.5021677613258362]\n",
      "900 steps | score: [-0.03157578781247139, 0.11513913422822952]\n",
      "1000 steps | score: [-0.04579786956310272, 0.17664462327957153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 steps | score: [0.06424401700496674, -0.0835234522819519]\n",
      "1200 steps | score: [0.10480973869562149, -0.18287444114685059]\n",
      "1300 steps | score: [0.12308883666992188, -0.23568320274353027]\n",
      "1400 steps | score: [0.09208054095506668, -0.15204286575317383]\n",
      "1500 steps | score: [0.002099044155329466, 0.049041956663131714]\n",
      "1600 steps | score: [0.1775457262992859, -0.36206308007240295]\n",
      "1700 steps | score: [0.057473573833703995, -0.07264679670333862]\n",
      "1800 steps | score: [0.23092159628868103, -0.5090346336364746]\n",
      "1900 steps | score: [0.30135414004325867, -0.6611329913139343]\n",
      "2000 steps | score: [0.07832766324281693, -0.15984392166137695]\n",
      "2100 steps | score: [0.08339140564203262, -0.14391908049583435]\n",
      "2200 steps | score: [0.10952095687389374, -0.22948819398880005]\n",
      "2300 steps | score: [0.19495968520641327, -0.3967941701412201]\n",
      "2400 steps | score: [0.11213991791009903, -0.2018778920173645]\n",
      "2500 steps | score: [0.16701370477676392, -0.37171441316604614]\n",
      "2600 steps | score: [0.12419211864471436, -0.2423023283481598]\n",
      "2700 steps | score: [0.049466535449028015, -0.07141120731830597]\n",
      "2800 steps | score: [0.26041269302368164, -0.6048777103424072]\n",
      "unknown params:  tensor([-0.9835, -0.4245,  0.7287, -0.4640,  1.0444,  0.5647])\n",
      "gt params:  tensor([-0.9029, -0.3688,  0.6560, -0.4118,  0.9578,  0.8706])\n",
      "ols params:  tensor([-0.5431, -0.2419,  0.4116, -0.2621,  0.5804,  3.4781])\n",
      "unknown mse:  tensor(0.0198)\n",
      "ols mse:  tensor(1.1949)\n",
      "gt params:  tensor([-0.9346, -0.3626,  0.6501, -0.4153,  0.9469,  0.8516])\n",
      "0 steps | score: [0.09253670275211334]\n",
      "100 steps | score: [-0.07813430577516556]\n",
      "200 steps | score: [-0.020548470318317413]\n",
      "300 steps | score: [-0.08542004972696304]\n",
      "400 steps | score: [-0.07971585541963577]\n",
      "500 steps | score: [-0.17188595235347748]\n",
      "600 steps | score: [-0.14015159010887146]\n",
      "700 steps | score: [-0.12616416811943054]\n",
      "800 steps | score: [-0.11736103892326355]\n",
      "900 steps | score: [-0.1276014745235443]\n",
      "1000 steps | score: [-0.16964730620384216]\n",
      "1100 steps | score: [-0.12781888246536255]\n",
      "1200 steps | score: [-0.11374811828136444]\n",
      "1300 steps | score: [-0.09392818808555603]\n",
      "1400 steps | score: [-0.15288741886615753]\n",
      "1500 steps | score: [-0.0986466333270073]\n",
      "1600 steps | score: [-0.17687806487083435]\n",
      "1700 steps | score: [-0.1171807050704956]\n",
      "1800 steps | score: [-0.11677023023366928]\n",
      "1900 steps | score: [-0.11268444359302521]\n",
      "2000 steps | score: [-0.1289355456829071]\n",
      "2100 steps | score: [-0.12178237736225128]\n",
      "2200 steps | score: [-0.14880797266960144]\n",
      "2300 steps | score: [-0.11849827319383621]\n",
      "2400 steps | score: [-0.11941784620285034]\n",
      "2500 steps | score: [-0.11025312542915344]\n",
      "2600 steps | score: [-0.1386181116104126]\n",
      "2700 steps | score: [-0.1212414801120758]\n",
      "0 steps | score: [0.12733320891857147, 0.05973856523633003]\n",
      "100 steps | score: [0.13422052562236786, -0.07292987406253815]\n",
      "200 steps | score: [0.12497173994779587, -0.1643488109111786]\n",
      "300 steps | score: [0.16153283417224884, -0.3033830523490906]\n",
      "400 steps | score: [-0.13424040377140045, 0.4466158449649811]\n",
      "500 steps | score: [0.005326352547854185, 0.09153936803340912]\n",
      "600 steps | score: [-0.01730576530098915, 0.16784027218818665]\n",
      "700 steps | score: [-0.061278801411390305, 0.3015573024749756]\n",
      "800 steps | score: [-0.03380772843956947, 0.22035129368305206]\n",
      "900 steps | score: [0.14624077081680298, -0.2394883781671524]\n",
      "1000 steps | score: [-0.08517203480005264, 0.33263981342315674]\n",
      "1100 steps | score: [0.04953980818390846, 0.002170022577047348]\n",
      "1200 steps | score: [0.054683029651641846, -0.027913428843021393]\n",
      "1300 steps | score: [0.2752126157283783, -0.6128413677215576]\n",
      "1400 steps | score: [-0.08795855939388275, 0.31596115231513977]\n",
      "1500 steps | score: [0.1662365347146988, -0.33693188428878784]\n",
      "1600 steps | score: [-0.13097365200519562, 0.43083155155181885]\n",
      "1700 steps | score: [0.07123368233442307, -0.052351776510477066]\n",
      "1800 steps | score: [-0.07473230361938477, 0.2857547998428345]\n",
      "1900 steps | score: [-0.06703223288059235, 0.2685239315032959]\n",
      "2000 steps | score: [-0.013707535341382027, 0.1555628627538681]\n",
      "2100 steps | score: [-0.05524342879652977, 0.25316834449768066]\n",
      "2200 steps | score: [-0.018228108063340187, 0.17038671672344208]\n",
      "2300 steps | score: [0.0816698893904686, -0.09049814939498901]\n",
      "2400 steps | score: [-7.093472231645137e-05, 0.11915957182645798]\n",
      "2500 steps | score: [-0.0354667492210865, 0.2183440774679184]\n",
      "2600 steps | score: [-0.030426351353526115, 0.1961348056793213]\n",
      "2700 steps | score: [-0.041834767907857895, 0.22115889191627502]\n",
      "unknown params:  tensor([-0.9072, -0.3448,  0.6309, -0.4214,  0.9119,  0.5745])\n",
      "gt params:  tensor([-0.9346, -0.3626,  0.6501, -0.4153,  0.9469,  0.8516])\n",
      "ols params:  tensor([-0.5370, -0.2065,  0.3819, -0.2589,  0.5434,  3.6822])\n",
      "unknown mse:  tensor(0.0132)\n",
      "ols mse:  tensor(1.4090)\n",
      "gt params:  tensor([-0.9514, -0.3805,  0.6475, -0.4196,  0.9511,  0.7768])\n",
      "0 steps | score: [0.164202481508255]\n",
      "100 steps | score: [-0.05587751045823097]\n",
      "200 steps | score: [-0.011918272823095322]\n",
      "300 steps | score: [-0.018689915537834167]\n",
      "400 steps | score: [-0.04690836742520332]\n",
      "500 steps | score: [-0.09022877365350723]\n",
      "600 steps | score: [-0.0336637981235981]\n",
      "700 steps | score: [-0.05077790096402168]\n",
      "800 steps | score: [-0.062137920409440994]\n",
      "900 steps | score: [-0.041943080723285675]\n",
      "1000 steps | score: [-0.04219561815261841]\n",
      "1100 steps | score: [0.0037968307733535767]\n",
      "0 steps | score: [0.20996159315109253, -0.17017762362957]\n",
      "100 steps | score: [0.1756957322359085, -0.28583192825317383]\n",
      "200 steps | score: [0.08923863619565964, -0.07520557940006256]\n",
      "300 steps | score: [-0.11282786726951599, 0.34993869066238403]\n",
      "400 steps | score: [-0.034751228988170624, 0.050949543714523315]\n",
      "500 steps | score: [0.053713563829660416, -0.12416403740644455]\n",
      "600 steps | score: [0.18676340579986572, -0.5437271595001221]\n",
      "700 steps | score: [0.05216432362794876, -0.08532199263572693]\n",
      "800 steps | score: [0.04385431110858917, -0.07411041110754013]\n",
      "900 steps | score: [0.02384127490222454, -0.04372180253267288]\n",
      "1000 steps | score: [0.03524944931268692, -0.09531193971633911]\n",
      "1100 steps | score: [0.3291313946247101, -0.9637420177459717]\n",
      "1200 steps | score: [0.039209991693496704, -0.09321130067110062]\n",
      "1300 steps | score: [0.04755270853638649, -0.09769316017627716]\n",
      "1400 steps | score: [0.25950202345848083, -0.708943247795105]\n",
      "1500 steps | score: [0.09850054979324341, -0.25494977831840515]\n",
      "1600 steps | score: [0.06350167840719223, -0.20729300379753113]\n",
      "1700 steps | score: [0.09794531017541885, -0.2853345274925232]\n",
      "1800 steps | score: [0.15237446129322052, -0.4055028259754181]\n",
      "1900 steps | score: [0.08866763114929199, -0.1996532678604126]\n",
      "2000 steps | score: [0.1978795826435089, -0.5128229856491089]\n",
      "2100 steps | score: [0.11034760624170303, -0.2776431739330292]\n",
      "2200 steps | score: [0.16877661645412445, -0.4257645606994629]\n",
      "2300 steps | score: [-0.006838428787887096, -0.01155695877969265]\n",
      "2400 steps | score: [0.08288776874542236, -0.18760359287261963]\n",
      "2500 steps | score: [0.1809007227420807, -0.4884437024593353]\n",
      "2600 steps | score: [0.22905419766902924, -0.6084161996841431]\n",
      "2700 steps | score: [0.03976491093635559, -0.09929167479276657]\n",
      "unknown params:  tensor([-1.0132, -0.4353,  0.6977, -0.4111,  0.9786,  0.4459])\n",
      "gt params:  tensor([-0.9514, -0.3805,  0.6475, -0.4196,  0.9511,  0.7768])\n",
      "ols params:  tensor([-0.5593, -0.2414,  0.3925, -0.2324,  0.5461,  3.6761])\n",
      "unknown mse:  tensor(0.0200)\n",
      "ols mse:  tensor(1.4739)\n",
      "gt params:  tensor([-0.9253, -0.3507,  0.6484, -0.3955,  0.9552,  0.8190])\n",
      "0 steps | score: [0.18036919832229614]\n",
      "100 steps | score: [-9.644404053688049e-05]\n",
      "0 steps | score: [0.20986509323120117, -0.25842976570129395]\n",
      "100 steps | score: [0.07644554227590561, -0.1146978884935379]\n",
      "200 steps | score: [0.5572792887687683, -1.5552465915679932]\n",
      "300 steps | score: [0.11721858382225037, -0.30526524782180786]\n",
      "400 steps | score: [-0.036856383085250854, 0.04683130234479904]\n",
      "500 steps | score: [0.05190741643309593, -0.18815597891807556]\n",
      "600 steps | score: [-0.009295054711401463, -0.05149126052856445]\n",
      "700 steps | score: [0.052706874907016754, -0.1866512894630432]\n",
      "800 steps | score: [0.03635241463780403, -0.16114488244056702]\n",
      "900 steps | score: [0.03142645210027695, -0.15288391709327698]\n",
      "1000 steps | score: [-0.047751713544130325, 0.049654748290777206]\n",
      "1100 steps | score: [-0.014301981776952744, -0.01681438274681568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 steps | score: [0.0755983516573906, -0.23122400045394897]\n",
      "1300 steps | score: [0.15983422100543976, -0.46612855792045593]\n",
      "1400 steps | score: [-0.03637577220797539, 0.008625313639640808]\n",
      "1500 steps | score: [-0.029557229951024055, 0.025185346603393555]\n",
      "1600 steps | score: [-0.03519769757986069, -0.0019669197499752045]\n",
      "1700 steps | score: [0.004985629115253687, -0.07234255224466324]\n",
      "1800 steps | score: [-0.014078320004045963, -0.035039760172367096]\n",
      "1900 steps | score: [0.025869810953736305, -0.08799983561038971]\n",
      "2000 steps | score: [0.058710817247629166, -0.20998740196228027]\n",
      "2100 steps | score: [0.02244986966252327, -0.08773861825466156]\n",
      "2200 steps | score: [0.012618282809853554, -0.10033124685287476]\n",
      "2300 steps | score: [0.038429029285907745, -0.18737980723381042]\n",
      "2400 steps | score: [0.07894524931907654, -0.27805665135383606]\n",
      "2500 steps | score: [0.03854886442422867, -0.1602196991443634]\n",
      "2600 steps | score: [0.03905871510505676, -0.1596534550189972]\n",
      "2700 steps | score: [-0.010091299191117287, -0.03034769743680954]\n",
      "unknown params:  tensor([-0.8980, -0.2909,  0.6330, -0.3747,  0.9104,  0.6395])\n",
      "gt params:  tensor([-0.9253, -0.3507,  0.6484, -0.3955,  0.9552,  0.8190])\n",
      "ols params:  tensor([-0.5384, -0.1809,  0.3876, -0.2322,  0.5444,  3.7765])\n",
      "unknown mse:  tensor(0.0065)\n",
      "ols mse:  tensor(1.5314)\n",
      "gt params:  tensor([-0.9138, -0.3640,  0.6430, -0.3883,  0.9639,  0.8505])\n",
      "0 steps | score: [0.3037298023700714]\n",
      "100 steps | score: [0.12060435861349106]\n",
      "200 steps | score: [0.049349140375852585]\n",
      "300 steps | score: [0.11194644868373871]\n",
      "400 steps | score: [0.08254340291023254]\n",
      "500 steps | score: [0.07041437923908234]\n",
      "600 steps | score: [0.07337591052055359]\n",
      "700 steps | score: [0.050460703670978546]\n",
      "800 steps | score: [0.14648756384849548]\n",
      "900 steps | score: [0.0897190123796463]\n",
      "1000 steps | score: [0.10066980123519897]\n",
      "1100 steps | score: [0.07819810509681702]\n",
      "1200 steps | score: [0.0941665917634964]\n",
      "1300 steps | score: [0.07687675952911377]\n",
      "1400 steps | score: [0.07664812356233597]\n",
      "1500 steps | score: [0.05904502421617508]\n",
      "1600 steps | score: [0.06159646064043045]\n",
      "1700 steps | score: [0.06355450302362442]\n",
      "1800 steps | score: [0.09499970823526382]\n",
      "1900 steps | score: [0.09012093394994736]\n",
      "2000 steps | score: [0.09659527242183685]\n",
      "2100 steps | score: [0.0953398272395134]\n",
      "2200 steps | score: [0.08587372303009033]\n",
      "2300 steps | score: [0.06689701229333878]\n",
      "2400 steps | score: [0.0847368836402893]\n",
      "2500 steps | score: [0.06124257296323776]\n",
      "2600 steps | score: [0.04098258540034294]\n",
      "2700 steps | score: [0.08731164038181305]\n",
      "0 steps | score: [0.08228550106287003, -0.16318964958190918]\n",
      "100 steps | score: [0.023770291358232498, -0.15903881192207336]\n",
      "200 steps | score: [-0.1358179748058319, 0.13938960433006287]\n",
      "300 steps | score: [0.3845730423927307, -1.290441632270813]\n",
      "400 steps | score: [0.1491977572441101, -0.601132869720459]\n",
      "500 steps | score: [0.1397324800491333, -0.5867860913276672]\n",
      "600 steps | score: [-0.12344566732645035, 0.07817649841308594]\n",
      "700 steps | score: [0.0034160534851253033, -0.2535041272640228]\n",
      "800 steps | score: [0.024432091042399406, -0.30958807468414307]\n",
      "900 steps | score: [-0.051043469458818436, -0.08567403256893158]\n",
      "1000 steps | score: [-0.07236729562282562, -0.013422362506389618]\n",
      "1100 steps | score: [-0.09069265425205231, 0.002091381698846817]\n",
      "1200 steps | score: [0.16348913311958313, -0.6307478547096252]\n",
      "1300 steps | score: [-0.11031550168991089, 0.026621170341968536]\n",
      "1400 steps | score: [-0.107449010014534, 0.03380047157406807]\n",
      "1500 steps | score: [-0.06949419528245926, -0.05109385401010513]\n",
      "1600 steps | score: [-0.038209185004234314, -0.1418084353208542]\n",
      "1700 steps | score: [-0.036364320665597916, -0.18548886477947235]\n",
      "1800 steps | score: [-0.18103253841400146, 0.19719351828098297]\n",
      "1900 steps | score: [-0.04157031327486038, -0.11891238391399384]\n",
      "2000 steps | score: [0.007246396038681269, -0.27533382177352905]\n",
      "2100 steps | score: [-0.10127513110637665, 0.003580201417207718]\n",
      "2200 steps | score: [-0.09182874113321304, -0.04111749678850174]\n",
      "2300 steps | score: [-0.0612005889415741, -0.1045490950345993]\n",
      "2400 steps | score: [-0.04257394000887871, -0.13487333059310913]\n",
      "2500 steps | score: [-0.04829714819788933, -0.12718096375465393]\n",
      "2600 steps | score: [-0.0487152636051178, -0.1276656538248062]\n",
      "2700 steps | score: [-0.08223868906497955, -0.04754214733839035]\n",
      "unknown params:  tensor([-0.8895, -0.3848,  0.6453, -0.3947,  0.8792,  0.6973])\n",
      "gt params:  tensor([-0.9138, -0.3640,  0.6430, -0.3883,  0.9639,  0.8505])\n",
      "ols params:  tensor([-0.5205, -0.2266,  0.3833, -0.2365,  0.5162,  3.9490])\n",
      "unknown mse:  tensor(0.0053)\n",
      "ols mse:  tensor(1.6776)\n",
      "gt params:  tensor([-0.9438, -0.3825,  0.6370, -0.4031,  0.9584,  0.8261])\n",
      "0 steps | score: [0.30557313561439514]\n",
      "100 steps | score: [0.07371396571397781]\n",
      "200 steps | score: [0.12610787153244019]\n",
      "300 steps | score: [-0.001857704482972622]\n",
      "0 steps | score: [0.22154687345027924, -0.20954380929470062]\n",
      "100 steps | score: [0.23186153173446655, -0.38479873538017273]\n",
      "200 steps | score: [0.03299391269683838, 0.027256391942501068]\n",
      "300 steps | score: [-0.11425475776195526, 0.2848438620567322]\n",
      "400 steps | score: [0.023323480039834976, -0.025090254843235016]\n",
      "500 steps | score: [0.3077032268047333, -0.7993353605270386]\n",
      "600 steps | score: [-0.001065307529643178, -0.0038053803145885468]\n",
      "unknown params:  tensor([-0.8694, -0.3772,  0.5913, -0.4083,  0.8874,  0.5274])\n",
      "gt params:  tensor([-0.9438, -0.3825,  0.6370, -0.4031,  0.9584,  0.8261])\n",
      "ols params:  tensor([-0.5237, -0.2237,  0.3514, -0.2448,  0.5292,  3.9843])\n",
      "unknown mse:  tensor(0.0170)\n",
      "ols mse:  tensor(1.7444)\n",
      "gt params:  tensor([-0.9260, -0.3581,  0.6196, -0.4072,  0.9223,  0.7914])\n",
      "0 steps | score: [0.15691247582435608]\n",
      "100 steps | score: [-0.13204947113990784]\n",
      "200 steps | score: [0.0022121965885162354]\n",
      "0 steps | score: [0.18466204404830933, -0.22029566764831543]\n",
      "100 steps | score: [-0.1377641260623932, 0.30439215898513794]\n",
      "200 steps | score: [-0.04386594146490097, 0.05264213681221008]\n",
      "300 steps | score: [0.3342038094997406, -0.91756272315979]\n",
      "400 steps | score: [-0.11036459356546402, 0.18671724200248718]\n",
      "500 steps | score: [-0.06715913861989975, 0.09817039221525192]\n",
      "600 steps | score: [-0.08518200367689133, 0.09896235913038254]\n",
      "700 steps | score: [-0.06448962539434433, 0.060618236660957336]\n",
      "800 steps | score: [-0.11240534484386444, 0.16316728293895721]\n",
      "900 steps | score: [-0.1912868469953537, 0.3422192335128784]\n",
      "1000 steps | score: [0.16612417995929718, -0.48321568965911865]\n",
      "1100 steps | score: [-0.1890508234500885, 0.34739017486572266]\n",
      "1200 steps | score: [-0.13790814578533173, 0.22608071565628052]\n",
      "1300 steps | score: [0.04013025760650635, -0.17578108608722687]\n",
      "1400 steps | score: [0.09227460622787476, -0.2843022048473358]\n",
      "1500 steps | score: [-0.04841918498277664, 0.00679469108581543]\n",
      "1600 steps | score: [0.006112959235906601, -0.07184572517871857]\n",
      "1700 steps | score: [0.06367317587137222, -0.2425953447818756]\n",
      "1800 steps | score: [0.033755574375391006, -0.1902569979429245]\n",
      "1900 steps | score: [-0.0350738987326622, -0.019922196865081787]\n",
      "2000 steps | score: [-0.10277736932039261, 0.12174411118030548]\n",
      "2100 steps | score: [0.09821069985628128, -0.36060574650764465]\n",
      "2200 steps | score: [-0.09264128655195236, 0.1313566416501999]\n",
      "2300 steps | score: [-0.07062201201915741, 0.08579244464635849]\n",
      "2400 steps | score: [0.09798634797334671, -0.3594590425491333]\n",
      "2500 steps | score: [0.08140189945697784, -0.2600599527359009]\n",
      "2600 steps | score: [-0.011240608058869839, -0.03737109899520874]\n",
      "2700 steps | score: [-0.03156917169690132, -0.030633747577667236]\n",
      "unknown params:  tensor([-0.8863, -0.3264,  0.6211, -0.4034,  0.9160,  0.6336])\n",
      "gt params:  tensor([-0.9260, -0.3581,  0.6196, -0.4072,  0.9223,  0.7914])\n",
      "ols params:  tensor([-0.4994, -0.1845,  0.3539, -0.2274,  0.5144,  4.1084])\n",
      "unknown mse:  tensor(0.0046)\n",
      "ols mse:  tensor(1.9140)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/61355d46-6fde-4a24-8dc6-cbca8d329f7e\n",
      "gt params:  tensor([ 0.3266,  0.6874, -0.2585, -0.7524,  0.5861, -0.1506])\n",
      "0 steps | score: [0.1810576617717743]\n",
      "100 steps | score: [0.0627819150686264]\n",
      "200 steps | score: [0.1225777193903923]\n",
      "300 steps | score: [0.01786491461098194]\n",
      "400 steps | score: [-0.030387194827198982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [0.12854377925395966]\n",
      "600 steps | score: [-0.017709581181406975]\n",
      "700 steps | score: [0.03821013122797012]\n",
      "800 steps | score: [0.08829572796821594]\n",
      "900 steps | score: [0.054712921380996704]\n",
      "1000 steps | score: [0.08105377107858658]\n",
      "1100 steps | score: [0.052265044301748276]\n",
      "1200 steps | score: [0.05228783190250397]\n",
      "1300 steps | score: [0.06493695080280304]\n",
      "1400 steps | score: [0.0447578951716423]\n",
      "1500 steps | score: [0.09392387419939041]\n",
      "1600 steps | score: [0.02282313071191311]\n",
      "1700 steps | score: [0.05875100940465927]\n",
      "1800 steps | score: [0.06458157300949097]\n",
      "1900 steps | score: [0.01250971108675003]\n",
      "2000 steps | score: [0.12289392203092575]\n",
      "2100 steps | score: [0.056317009031772614]\n",
      "2200 steps | score: [0.07625877857208252]\n",
      "2300 steps | score: [0.053687579929828644]\n",
      "2400 steps | score: [0.04505489021539688]\n",
      "2500 steps | score: [0.06061025708913803]\n",
      "2600 steps | score: [0.04774380475282669]\n",
      "2700 steps | score: [0.04847778007388115]\n",
      "2800 steps | score: [0.06115426495671272]\n",
      "0 steps | score: [-0.03398749604821205, 0.6104609966278076]\n",
      "100 steps | score: [-3.0287930965423584, 7.714588642120361]\n",
      "200 steps | score: [-1.6027393341064453, 6.323238849639893]\n",
      "300 steps | score: [-2.0944089889526367, 7.104704856872559]\n",
      "400 steps | score: [-1.281630039215088, 5.666009902954102]\n",
      "500 steps | score: [-1.3850080966949463, 5.937655448913574]\n",
      "600 steps | score: [0.15653614699840546, 1.1057851314544678]\n",
      "700 steps | score: [-0.6937631964683533, 3.7416560649871826]\n",
      "800 steps | score: [0.8423047661781311, -4.321418762207031]\n",
      "900 steps | score: [-0.5548712611198425, 2.748115301132202]\n",
      "1000 steps | score: [-0.15846151113510132, 1.0050315856933594]\n",
      "1100 steps | score: [-0.137861967086792, 0.8603668212890625]\n",
      "1200 steps | score: [-0.37742912769317627, 1.8660966157913208]\n",
      "1300 steps | score: [0.2459913194179535, -1.3490945100784302]\n",
      "1400 steps | score: [-0.4037034809589386, 1.8883270025253296]\n",
      "1500 steps | score: [0.09641623497009277, -0.5236431360244751]\n",
      "1600 steps | score: [0.007501691579818726, -0.07494679093360901]\n",
      "1700 steps | score: [-0.2872503697872162, 1.3845828771591187]\n",
      "1800 steps | score: [-0.024747515097260475, 0.16551057994365692]\n",
      "1900 steps | score: [-0.09762684255838394, 0.42160463333129883]\n",
      "2000 steps | score: [0.07198404520750046, -0.480853408575058]\n",
      "2100 steps | score: [0.08639974892139435, -0.4661317765712738]\n",
      "2200 steps | score: [-0.12530367076396942, 0.47821569442749023]\n",
      "2300 steps | score: [-0.15510068833827972, 0.7551189661026001]\n",
      "2400 steps | score: [-0.3311227560043335, 1.4918205738067627]\n",
      "2500 steps | score: [-0.16470301151275635, 0.6483305096626282]\n",
      "2600 steps | score: [-0.02544601634144783, -0.01146361231803894]\n",
      "2700 steps | score: [-0.18101054430007935, 0.7885736227035522]\n",
      "2800 steps | score: [-0.1126171350479126, 0.47468486428260803]\n",
      "unknown params:  tensor([ 0.3157,  0.6742, -0.2595, -0.7390,  0.5753, -0.1387])\n",
      "gt params:  tensor([ 0.3266,  0.6874, -0.2585, -0.7524,  0.5861, -0.1506])\n",
      "ols params:  tensor([ 0.2899,  0.6112, -0.2333, -0.6675,  0.5205,  0.3775])\n",
      "unknown mse:  tensor(0.0001)\n",
      "ols mse:  tensor(0.0497)\n",
      "gt params:  tensor([ 0.3179,  0.6811, -0.2618, -0.7620,  0.5876, -0.1397])\n",
      "0 steps | score: [0.19007742404937744]\n",
      "100 steps | score: [0.05887984856963158]\n",
      "200 steps | score: [0.009706735610961914]\n",
      "0 steps | score: [0.16444525122642517, -0.13100063800811768]\n",
      "100 steps | score: [0.08394908905029297, -0.047024115920066833]\n",
      "200 steps | score: [0.04038452357053757, 0.0056442394852638245]\n",
      "300 steps | score: [-0.22539173066616058, 0.8486826419830322]\n",
      "400 steps | score: [-0.40191352367401123, 1.322741150856018]\n",
      "500 steps | score: [0.05391167476773262, -0.18775556981563568]\n",
      "600 steps | score: [0.34352919459342957, -1.217000961303711]\n",
      "700 steps | score: [0.25016510486602783, -0.8932481408119202]\n",
      "800 steps | score: [0.16687865555286407, -0.5787849426269531]\n",
      "900 steps | score: [0.20829923450946808, -0.6887314319610596]\n",
      "1000 steps | score: [0.047381818294525146, -0.2028506100177765]\n",
      "1100 steps | score: [-0.17789782583713531, 0.5967006683349609]\n",
      "1200 steps | score: [0.21004389226436615, -0.7558161616325378]\n",
      "1300 steps | score: [-0.09374390542507172, 0.29362887144088745]\n",
      "1400 steps | score: [-0.0353793241083622, 0.16026565432548523]\n",
      "1500 steps | score: [0.003101478097960353, 0.04786781966686249]\n",
      "1600 steps | score: [-0.0476263128221035, 0.16068293154239655]\n",
      "1700 steps | score: [0.01240383367985487, -0.028028488159179688]\n",
      "1800 steps | score: [0.031253788620233536, -0.06669148802757263]\n",
      "1900 steps | score: [0.09574510157108307, -0.32994407415390015]\n",
      "2000 steps | score: [0.004564713686704636, 0.043784864246845245]\n",
      "2100 steps | score: [0.006463170517235994, -0.030548550188541412]\n",
      "2200 steps | score: [-0.07563158124685287, 0.25477278232574463]\n",
      "2300 steps | score: [0.0003615199530031532, -0.013014078140258789]\n",
      "2400 steps | score: [0.03786081820726395, -0.16024570167064667]\n",
      "2500 steps | score: [0.05535632744431496, -0.16892023384571075]\n",
      "2600 steps | score: [0.034863974899053574, -0.1328836977481842]\n",
      "2700 steps | score: [0.028193093836307526, -0.11144090443849564]\n",
      "2800 steps | score: [0.006593827623873949, -0.00410684198141098]\n",
      "unknown params:  tensor([ 0.3079,  0.6769, -0.2640, -0.7441,  0.5794, -0.0988])\n",
      "gt params:  tensor([ 0.3179,  0.6811, -0.2618, -0.7620,  0.5876, -0.1397])\n",
      "ols params:  tensor([ 0.2524,  0.5489, -0.2136, -0.6011,  0.4721,  0.8331])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(0.1683)\n",
      "gt params:  tensor([ 0.3244,  0.6913, -0.2599, -0.7622,  0.5935, -0.1552])\n",
      "0 steps | score: [0.24306294322013855]\n",
      "100 steps | score: [0.04412019997835159]\n",
      "200 steps | score: [0.08977796137332916]\n",
      "300 steps | score: [0.02713831141591072]\n",
      "400 steps | score: [0.0035015642642974854]\n",
      "0 steps | score: [0.1399369239807129, 0.1363692581653595]\n",
      "100 steps | score: [-0.04654601216316223, 0.4794834852218628]\n",
      "200 steps | score: [0.054867006838321686, -0.020327895879745483]\n",
      "300 steps | score: [-0.203634575009346, 0.8146436214447021]\n",
      "400 steps | score: [-0.14490404725074768, 0.6946167945861816]\n",
      "500 steps | score: [0.031231071799993515, 0.06256338953971863]\n",
      "600 steps | score: [-0.15962545573711395, 0.6838645339012146]\n",
      "700 steps | score: [-0.20530739426612854, 0.7947243452072144]\n",
      "800 steps | score: [0.11780001223087311, -0.31573745608329773]\n",
      "900 steps | score: [0.1408654749393463, -0.31263643503189087]\n",
      "1000 steps | score: [0.22876374423503876, -0.7294159531593323]\n",
      "1100 steps | score: [0.13125576078891754, -0.3441068232059479]\n",
      "1200 steps | score: [0.19609132409095764, -0.5588032603263855]\n",
      "1300 steps | score: [0.04948670044541359, 0.002743437886238098]\n",
      "1400 steps | score: [0.16919797658920288, -0.4831646978855133]\n",
      "1500 steps | score: [0.16426560282707214, -0.4910314977169037]\n",
      "1600 steps | score: [-0.068974070250988, 0.376285582780838]\n",
      "1700 steps | score: [-0.09400641918182373, 0.4322121739387512]\n",
      "1800 steps | score: [0.007450147531926632, 0.13694433867931366]\n",
      "1900 steps | score: [-0.0003365916491020471, 0.14030985534191132]\n",
      "2000 steps | score: [0.04246095195412636, -0.011633321642875671]\n",
      "2100 steps | score: [0.11846155673265457, -0.308117151260376]\n",
      "2200 steps | score: [-0.008767346851527691, 0.09324567019939423]\n",
      "2300 steps | score: [-0.12638966739177704, 0.5192544460296631]\n",
      "2400 steps | score: [-0.05365166813135147, 0.269509881734848]\n",
      "2500 steps | score: [-0.011471066623926163, 0.1847730129957199]\n",
      "2600 steps | score: [-0.013039648532867432, 0.1831986904144287]\n",
      "2700 steps | score: [-0.0066508143208920956, 0.11821933090686798]\n",
      "2800 steps | score: [-0.02947377786040306, 0.23330216109752655]\n",
      "unknown params:  tensor([ 0.3372,  0.6948, -0.2674, -0.7810,  0.6057, -0.1464])\n",
      "gt params:  tensor([ 0.3244,  0.6913, -0.2599, -0.7622,  0.5935, -0.1552])\n",
      "ols params:  tensor([ 0.2485,  0.5043, -0.1929, -0.5605,  0.4387,  1.1560])\n",
      "unknown mse:  tensor(0.0001)\n",
      "ols mse:  tensor(0.3049)\n",
      "gt params:  tensor([ 0.3285,  0.6735, -0.2510, -0.7449,  0.5875, -0.1612])\n",
      "0 steps | score: [0.24664533138275146]\n",
      "100 steps | score: [0.09894871711730957]\n",
      "200 steps | score: [0.057728566229343414]\n",
      "300 steps | score: [0.023874556645751]\n",
      "400 steps | score: [0.04444052278995514]\n",
      "500 steps | score: [0.006426632404327393]\n",
      "0 steps | score: [0.3473629951477051, -0.3477286100387573]\n",
      "100 steps | score: [0.9650784730911255, -2.699157238006592]\n",
      "200 steps | score: [0.2846882939338684, -0.47788119316101074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 steps | score: [0.46859902143478394, -1.1264172792434692]\n",
      "400 steps | score: [0.4409352242946625, -1.0118610858917236]\n",
      "500 steps | score: [0.2391534000635147, -0.37014663219451904]\n",
      "600 steps | score: [0.4635164141654968, -1.097344994544983]\n",
      "700 steps | score: [0.327241450548172, -0.6620295643806458]\n",
      "800 steps | score: [0.19787128269672394, -0.2652146518230438]\n",
      "900 steps | score: [0.28334471583366394, -0.5025492310523987]\n",
      "1000 steps | score: [0.3923638164997101, -0.9170949459075928]\n",
      "1100 steps | score: [0.19025498628616333, -0.23525984585285187]\n",
      "1200 steps | score: [-0.016000252217054367, 0.32067209482192993]\n",
      "1300 steps | score: [0.21163912117481232, -0.3512646555900574]\n",
      "1400 steps | score: [0.0760536715388298, 0.06481859087944031]\n",
      "1500 steps | score: [0.14437304437160492, -0.12657304108142853]\n",
      "1600 steps | score: [0.2957930564880371, -0.6097968220710754]\n",
      "1700 steps | score: [0.345009982585907, -0.7376365661621094]\n",
      "1800 steps | score: [0.20645056664943695, -0.3042023777961731]\n",
      "1900 steps | score: [0.24726524949073792, -0.41489148139953613]\n",
      "2000 steps | score: [0.21820107102394104, -0.34814152121543884]\n",
      "2100 steps | score: [0.2554490268230438, -0.44343870878219604]\n",
      "2200 steps | score: [0.13646766543388367, -0.12874719500541687]\n",
      "2300 steps | score: [0.3509218692779541, -0.72758948802948]\n",
      "2400 steps | score: [0.21761353313922882, -0.3461438715457916]\n",
      "2500 steps | score: [0.2054332047700882, -0.326712429523468]\n",
      "2600 steps | score: [0.16636215150356293, -0.20680826902389526]\n",
      "2700 steps | score: [0.1421203911304474, -0.13832440972328186]\n",
      "2800 steps | score: [0.23105162382125854, -0.37399357557296753]\n",
      "unknown params:  tensor([ 0.3301,  0.6715, -0.2563, -0.7290,  0.5768, -0.0091])\n",
      "gt params:  tensor([ 0.3285,  0.6735, -0.2510, -0.7449,  0.5875, -0.1612])\n",
      "ols params:  tensor([ 0.2323,  0.4698, -0.1782, -0.5065,  0.4021,  1.4376])\n",
      "unknown mse:  tensor(0.0039)\n",
      "ols mse:  tensor(0.4505)\n",
      "gt params:  tensor([ 0.3336,  0.6860, -0.2596, -0.7456,  0.5773, -0.1050])\n",
      "0 steps | score: [0.17390140891075134]\n",
      "100 steps | score: [0.012286033481359482]\n",
      "200 steps | score: [-0.013834008947014809]\n",
      "300 steps | score: [-0.028092797845602036]\n",
      "400 steps | score: [-0.05166078358888626]\n",
      "500 steps | score: [-0.01976224221289158]\n",
      "600 steps | score: [0.025520198047161102]\n",
      "700 steps | score: [0.010889861732721329]\n",
      "800 steps | score: [-0.026986349374055862]\n",
      "900 steps | score: [-0.040408872067928314]\n",
      "1000 steps | score: [0.02291703224182129]\n",
      "1100 steps | score: [0.03590419888496399]\n",
      "1200 steps | score: [0.006832696497440338]\n",
      "0 steps | score: [0.31836584210395813, -0.7212673425674438]\n",
      "100 steps | score: [0.124384306371212, -0.38596734404563904]\n",
      "200 steps | score: [0.37610578536987305, -1.1529030799865723]\n",
      "300 steps | score: [0.07130613923072815, -0.3578862249851227]\n",
      "400 steps | score: [0.03327380493283272, -0.25938302278518677]\n",
      "500 steps | score: [0.2540122866630554, -0.886195957660675]\n",
      "600 steps | score: [0.21933405101299286, -0.7164217233657837]\n",
      "700 steps | score: [0.2620568573474884, -0.857993483543396]\n",
      "800 steps | score: [0.18297819793224335, -0.7460434436798096]\n",
      "900 steps | score: [0.2619321346282959, -0.8947473764419556]\n",
      "1000 steps | score: [0.3587898015975952, -1.1832987070083618]\n",
      "1100 steps | score: [0.12940579652786255, -0.5092387199401855]\n",
      "1200 steps | score: [0.20817740261554718, -0.7293455004692078]\n",
      "1300 steps | score: [0.18408244848251343, -0.6848559379577637]\n",
      "1400 steps | score: [0.20942197740077972, -0.7331371903419495]\n",
      "1500 steps | score: [0.0793532282114029, -0.3831172585487366]\n",
      "1600 steps | score: [0.13694638013839722, -0.5375940799713135]\n",
      "1700 steps | score: [0.22571112215518951, -0.8026394844055176]\n",
      "1800 steps | score: [0.177917942404747, -0.6506451368331909]\n",
      "1900 steps | score: [0.20755451917648315, -0.782657265663147]\n",
      "2000 steps | score: [0.14790455996990204, -0.6260805726051331]\n",
      "2100 steps | score: [0.18739572167396545, -0.6839975118637085]\n",
      "2200 steps | score: [0.21815846860408783, -0.7691161036491394]\n",
      "2300 steps | score: [0.08944106847047806, -0.42614829540252686]\n",
      "2400 steps | score: [0.3094237148761749, -1.0317522287368774]\n",
      "2500 steps | score: [0.1399662047624588, -0.5919452905654907]\n",
      "2600 steps | score: [0.3006998598575592, -0.970393180847168]\n",
      "2700 steps | score: [0.15134406089782715, -0.6261099576950073]\n",
      "2800 steps | score: [0.08134853094816208, -0.44317030906677246]\n",
      "2900 steps | score: [0.2808036804199219, -0.9381409883499146]\n",
      "unknown params:  tensor([ 0.3102,  0.6716, -0.2546, -0.7136,  0.5582,  0.0335])\n",
      "gt params:  tensor([ 0.3336,  0.6860, -0.2596, -0.7456,  0.5773, -0.1050])\n",
      "ols params:  tensor([ 0.2083,  0.4426, -0.1705, -0.4683,  0.3711,  1.7749])\n",
      "unknown mse:  tensor(0.0036)\n",
      "ols mse:  tensor(0.6227)\n",
      "gt params:  tensor([ 0.3317,  0.6729, -0.2456, -0.7549,  0.5899, -0.1360])\n",
      "0 steps | score: [0.13473668694496155]\n",
      "100 steps | score: [0.003707870841026306]\n",
      "0 steps | score: [0.3485466241836548, -0.6714578866958618]\n",
      "100 steps | score: [0.3333461880683899, -0.8907137513160706]\n",
      "200 steps | score: [0.35247236490249634, -0.9944588541984558]\n",
      "300 steps | score: [0.19293801486492157, -0.5610880255699158]\n",
      "400 steps | score: [0.2536783814430237, -0.7937854528427124]\n",
      "500 steps | score: [0.04968194290995598, -0.18353109061717987]\n",
      "600 steps | score: [-0.042908843606710434, 0.021352633833885193]\n",
      "700 steps | score: [0.08315625041723251, -0.28461307287216187]\n",
      "800 steps | score: [-0.024285636842250824, -0.013773970305919647]\n",
      "900 steps | score: [0.30446118116378784, -0.9157842993736267]\n",
      "1000 steps | score: [0.11522780358791351, -0.38903987407684326]\n",
      "1100 steps | score: [0.1692812740802765, -0.5824123024940491]\n",
      "1200 steps | score: [0.16150164604187012, -0.5298643112182617]\n",
      "1300 steps | score: [0.07989992201328278, -0.3269302248954773]\n",
      "1400 steps | score: [0.007388330530375242, -0.1568203568458557]\n",
      "1500 steps | score: [0.31735819578170776, -0.9849667549133301]\n",
      "1600 steps | score: [0.29086822271347046, -0.8919216990470886]\n",
      "1700 steps | score: [0.2704491913318634, -0.8329691886901855]\n",
      "1800 steps | score: [0.12237411737442017, -0.44617903232574463]\n",
      "1900 steps | score: [0.23018516600131989, -0.6849000453948975]\n",
      "2000 steps | score: [0.19336716830730438, -0.5955113768577576]\n",
      "2100 steps | score: [0.14905135333538055, -0.501126766204834]\n",
      "2200 steps | score: [0.1949339210987091, -0.5971301794052124]\n",
      "2300 steps | score: [0.19596010446548462, -0.638858437538147]\n",
      "2400 steps | score: [0.22298049926757812, -0.7360243797302246]\n",
      "2500 steps | score: [0.2508668899536133, -0.7554787397384644]\n",
      "2600 steps | score: [0.11619363725185394, -0.44245144724845886]\n",
      "2700 steps | score: [0.14400893449783325, -0.4928026795387268]\n",
      "2800 steps | score: [0.1578509509563446, -0.511894702911377]\n",
      "2900 steps | score: [0.16206948459148407, -0.5359548330307007]\n",
      "unknown params:  tensor([ 0.3337,  0.6901, -0.2550, -0.7837,  0.5895, -0.1283])\n",
      "gt params:  tensor([ 0.3317,  0.6729, -0.2456, -0.7549,  0.5899, -0.1360])\n",
      "ols params:  tensor([ 0.2134,  0.4280, -0.1582, -0.4836,  0.3679,  1.8868])\n",
      "unknown mse:  tensor(0.0002)\n",
      "ols mse:  tensor(0.7160)\n",
      "gt params:  tensor([ 0.3377,  0.6926, -0.2507, -0.7563,  0.5831, -0.1558])\n",
      "0 steps | score: [-0.03984590619802475]\n",
      "100 steps | score: [-0.18195700645446777]\n",
      "200 steps | score: [-0.24524803459644318]\n",
      "300 steps | score: [-0.2097504585981369]\n",
      "400 steps | score: [-0.2518272399902344]\n",
      "500 steps | score: [-0.2609522342681885]\n",
      "600 steps | score: [-0.2622931897640228]\n",
      "700 steps | score: [-0.32108044624328613]\n",
      "800 steps | score: [-0.23960427939891815]\n",
      "900 steps | score: [-0.2508094906806946]\n",
      "1000 steps | score: [-0.26621735095977783]\n",
      "1100 steps | score: [-0.23929733037948608]\n",
      "1200 steps | score: [-0.3216187655925751]\n",
      "1300 steps | score: [-0.2632805109024048]\n",
      "1400 steps | score: [-0.2296983152627945]\n",
      "1500 steps | score: [-0.25513193011283875]\n",
      "1600 steps | score: [-0.2711246907711029]\n",
      "1700 steps | score: [-0.2947017252445221]\n",
      "1800 steps | score: [-0.26531827449798584]\n",
      "1900 steps | score: [-0.23220665752887726]\n",
      "2000 steps | score: [-0.23687684535980225]\n",
      "2100 steps | score: [-0.26362305879592896]\n",
      "2200 steps | score: [-0.28689974546432495]\n",
      "2300 steps | score: [-0.25197815895080566]\n",
      "2400 steps | score: [-0.2412077635526657]\n",
      "2500 steps | score: [-0.2566790282726288]\n",
      "2600 steps | score: [-0.27334433794021606]\n",
      "2700 steps | score: [-0.27638331055641174]\n",
      "2800 steps | score: [-0.26459330320358276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900 steps | score: [-0.2716510593891144]\n",
      "0 steps | score: [0.02110367827117443, 0.17001301050186157]\n",
      "100 steps | score: [0.023306192830204964, -0.014748454093933105]\n",
      "200 steps | score: [-0.33424675464630127, 0.7572599053382874]\n",
      "300 steps | score: [-0.044650010764598846, -0.02531568706035614]\n",
      "400 steps | score: [0.07147277146577835, -0.36598700284957886]\n",
      "500 steps | score: [0.13350029289722443, -0.5086430311203003]\n",
      "600 steps | score: [-0.2317718118429184, 0.5324835777282715]\n",
      "700 steps | score: [-0.2962487041950226, 0.6210539937019348]\n",
      "800 steps | score: [-0.13239328563213348, 0.23480165004730225]\n",
      "900 steps | score: [-0.08191803097724915, 0.06683845818042755]\n",
      "1000 steps | score: [0.11594294011592865, -0.5380101203918457]\n",
      "1100 steps | score: [-0.01390092819929123, -0.11586998403072357]\n",
      "1200 steps | score: [-0.2621558606624603, 0.5507973432540894]\n",
      "1300 steps | score: [-0.13483916223049164, 0.2164091020822525]\n",
      "1400 steps | score: [-0.14514252543449402, 0.28844213485717773]\n",
      "1500 steps | score: [-0.19218692183494568, 0.35466498136520386]\n",
      "1600 steps | score: [-0.185777485370636, 0.397755891084671]\n",
      "1700 steps | score: [-0.15780189633369446, 0.2781747877597809]\n",
      "1800 steps | score: [-0.16241109371185303, 0.2607060968875885]\n",
      "1900 steps | score: [-0.09172112494707108, 0.054867178201675415]\n",
      "2000 steps | score: [-0.12904013693332672, 0.19287462532520294]\n",
      "2100 steps | score: [-0.11465320736169815, 0.15268293023109436]\n",
      "2200 steps | score: [-0.08243853598833084, 0.05462765693664551]\n",
      "2300 steps | score: [-0.044216256588697433, -0.04784978926181793]\n",
      "2400 steps | score: [-0.13035711646080017, 0.18455591797828674]\n",
      "2500 steps | score: [-0.0925319716334343, 0.07998158037662506]\n",
      "2600 steps | score: [-0.134786456823349, 0.21719592809677124]\n",
      "2700 steps | score: [-0.10470779985189438, 0.1247013658285141]\n",
      "2800 steps | score: [-0.11619874089956284, 0.15667474269866943]\n",
      "2900 steps | score: [-0.11189772933721542, 0.17591722309589386]\n",
      "unknown params:  tensor([ 0.3199,  0.6605, -0.2381, -0.7671,  0.5792, -0.1556])\n",
      "gt params:  tensor([ 0.3377,  0.6926, -0.2507, -0.7563,  0.5831, -0.1558])\n",
      "ols params:  tensor([ 0.2001,  0.4030, -0.1491, -0.4653,  0.3582,  2.0597])\n",
      "unknown mse:  tensor(0.0003)\n",
      "ols mse:  tensor(0.8595)\n",
      "gt params:  tensor([ 0.2973,  0.6875, -0.2423, -0.7380,  0.6140, -0.1301])\n",
      "0 steps | score: [0.309500515460968]\n",
      "100 steps | score: [0.21339192986488342]\n",
      "200 steps | score: [0.05214165151119232]\n",
      "300 steps | score: [0.09535693377256393]\n",
      "400 steps | score: [0.09788496047258377]\n",
      "500 steps | score: [0.061035916209220886]\n",
      "600 steps | score: [0.14373086392879486]\n",
      "700 steps | score: [0.0890815407037735]\n",
      "800 steps | score: [0.09442374855279922]\n",
      "900 steps | score: [0.0907907634973526]\n",
      "1000 steps | score: [0.07692520320415497]\n",
      "1100 steps | score: [0.15146666765213013]\n",
      "1200 steps | score: [0.09223086386919022]\n",
      "1300 steps | score: [0.06188288331031799]\n",
      "1400 steps | score: [0.06619101017713547]\n",
      "1500 steps | score: [0.07330472767353058]\n",
      "1600 steps | score: [0.11330530047416687]\n",
      "1700 steps | score: [0.111663319170475]\n",
      "1800 steps | score: [0.08866840600967407]\n",
      "1900 steps | score: [0.056944966316223145]\n",
      "2000 steps | score: [0.04619750380516052]\n",
      "2100 steps | score: [0.09024595469236374]\n",
      "2200 steps | score: [0.08900994807481766]\n",
      "2300 steps | score: [0.08258423209190369]\n",
      "2400 steps | score: [0.06764713674783707]\n",
      "2500 steps | score: [0.052450962364673615]\n",
      "2600 steps | score: [0.08889390528202057]\n",
      "2700 steps | score: [0.09832894802093506]\n",
      "2800 steps | score: [0.0575433075428009]\n",
      "2900 steps | score: [0.06418994069099426]\n",
      "0 steps | score: [0.22668737173080444, -0.08042821288108826]\n",
      "100 steps | score: [0.07635831087827682, 0.07158178091049194]\n",
      "200 steps | score: [-0.047830432653427124, 0.26364174485206604]\n",
      "300 steps | score: [-0.015814388170838356, 0.2154131829738617]\n",
      "400 steps | score: [0.06427496671676636, 0.021871715784072876]\n",
      "500 steps | score: [-0.13526390492916107, 0.4823383688926697]\n",
      "600 steps | score: [-0.06814110279083252, 0.3031057119369507]\n",
      "700 steps | score: [0.07823186367750168, -0.06380517780780792]\n",
      "800 steps | score: [0.12106317281723022, -0.1508878767490387]\n",
      "900 steps | score: [0.10366041213274002, -0.11144006252288818]\n",
      "1000 steps | score: [-0.10533992946147919, 0.38544657826423645]\n",
      "1100 steps | score: [0.18303196132183075, -0.31213098764419556]\n",
      "1200 steps | score: [0.15367209911346436, -0.29555386304855347]\n",
      "1300 steps | score: [-0.016495754942297935, 0.1919240951538086]\n",
      "1400 steps | score: [-0.116555355489254, 0.3935697078704834]\n",
      "1500 steps | score: [-0.04683671519160271, 0.24927163124084473]\n",
      "1600 steps | score: [0.06694093346595764, -0.04258371889591217]\n",
      "1700 steps | score: [0.015015900135040283, 0.08325335383415222]\n",
      "1800 steps | score: [0.07539986073970795, -0.04513540863990784]\n",
      "1900 steps | score: [-0.08371421694755554, 0.30811887979507446]\n",
      "2000 steps | score: [-0.0020502584520727396, 0.11974568665027618]\n",
      "2100 steps | score: [0.09511271119117737, -0.06552489101886749]\n",
      "2200 steps | score: [0.058827005326747894, 0.0037832558155059814]\n",
      "2300 steps | score: [-0.019068188965320587, 0.19503188133239746]\n",
      "2400 steps | score: [0.06252466887235641, -0.0321221649646759]\n",
      "2500 steps | score: [0.0978727862238884, -0.10818661749362946]\n",
      "2600 steps | score: [0.02600538358092308, 0.06658342480659485]\n",
      "2700 steps | score: [0.07868851721286774, -0.06974673271179199]\n",
      "2800 steps | score: [0.016811484470963478, 0.11575908213853836]\n",
      "2900 steps | score: [0.04680925980210304, -0.0008523315191268921]\n",
      "unknown params:  tensor([ 0.3067,  0.6715, -0.2576, -0.7208,  0.5975, -0.0025])\n",
      "gt params:  tensor([ 0.2973,  0.6875, -0.2423, -0.7380,  0.6140, -0.1301])\n",
      "ols params:  tensor([ 0.1818,  0.3922, -0.1538, -0.4219,  0.3483,  2.2623])\n",
      "unknown mse:  tensor(0.0029)\n",
      "ols mse:  tensor(1.0004)\n",
      "gt params:  tensor([ 0.3325,  0.6810, -0.2536, -0.7432,  0.5887, -0.1447])\n",
      "0 steps | score: [0.4175857901573181]\n",
      "100 steps | score: [0.15459837019443512]\n",
      "200 steps | score: [0.1597370207309723]\n",
      "300 steps | score: [0.16613462567329407]\n",
      "400 steps | score: [0.19132116436958313]\n",
      "500 steps | score: [0.13761794567108154]\n",
      "600 steps | score: [0.11391367018222809]\n",
      "700 steps | score: [0.07888488471508026]\n",
      "800 steps | score: [0.12915699183940887]\n",
      "900 steps | score: [0.13242943584918976]\n",
      "1000 steps | score: [0.134037584066391]\n",
      "1100 steps | score: [0.11944101750850677]\n",
      "1200 steps | score: [0.09799964725971222]\n",
      "1300 steps | score: [0.07816555351018906]\n",
      "1400 steps | score: [0.09858877956867218]\n",
      "1500 steps | score: [0.13114020228385925]\n",
      "1600 steps | score: [0.1214405968785286]\n",
      "1700 steps | score: [0.11009149253368378]\n",
      "1800 steps | score: [0.10966597497463226]\n",
      "1900 steps | score: [0.08796186745166779]\n",
      "2000 steps | score: [0.14555573463439941]\n",
      "2100 steps | score: [0.12579555809497833]\n",
      "2200 steps | score: [0.08074381947517395]\n",
      "2300 steps | score: [0.12507528066635132]\n",
      "2400 steps | score: [0.11390931904315948]\n",
      "2500 steps | score: [0.09856174141168594]\n",
      "2600 steps | score: [0.10838518291711807]\n",
      "2700 steps | score: [0.10643521696329117]\n",
      "2800 steps | score: [0.10404262691736221]\n",
      "2900 steps | score: [0.14517885446548462]\n",
      "0 steps | score: [0.2712865471839905, -0.29863935708999634]\n",
      "100 steps | score: [0.24469223618507385, -0.4652195870876312]\n",
      "200 steps | score: [0.1266559362411499, -0.23448997735977173]\n",
      "300 steps | score: [0.1954268366098404, -0.4050661027431488]\n",
      "400 steps | score: [0.1785046011209488, -0.3727118968963623]\n",
      "500 steps | score: [0.018519852310419083, 0.012306787073612213]\n",
      "600 steps | score: [-0.15719258785247803, 0.35059767961502075]\n",
      "700 steps | score: [0.03592505306005478, -0.06066199392080307]\n",
      "800 steps | score: [-0.07263241708278656, 0.1769324690103531]\n",
      "900 steps | score: [-0.09396877139806747, 0.24134787917137146]\n",
      "1000 steps | score: [0.19760920107364655, -0.4237617552280426]\n",
      "1100 steps | score: [-0.056942008435726166, 0.13852520287036896]\n",
      "1200 steps | score: [0.05473463237285614, -0.08210235834121704]\n",
      "1300 steps | score: [0.030008314177393913, -0.05220629274845123]\n",
      "1400 steps | score: [-0.09266974031925201, 0.20914486050605774]\n",
      "1500 steps | score: [0.09323855489492416, -0.1779562532901764]\n",
      "1600 steps | score: [0.039592236280441284, -0.06660734117031097]\n",
      "1700 steps | score: [0.026866735890507698, -0.05665658414363861]\n",
      "1800 steps | score: [0.02008720114827156, -0.010068997740745544]\n",
      "1900 steps | score: [-0.07406705617904663, 0.18400916457176208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 steps | score: [0.2050735354423523, -0.4745107889175415]\n",
      "2100 steps | score: [0.04887007921934128, -0.11003671586513519]\n",
      "2200 steps | score: [-0.033257439732551575, 0.07141454517841339]\n",
      "2300 steps | score: [-0.006769726984202862, 0.022423699498176575]\n",
      "2400 steps | score: [0.05341699719429016, -0.09191329032182693]\n",
      "2500 steps | score: [0.0766107439994812, -0.12898334860801697]\n",
      "2600 steps | score: [0.007337318267673254, -0.014186158776283264]\n",
      "2700 steps | score: [0.08435806632041931, -0.17462077736854553]\n",
      "2800 steps | score: [0.07393841445446014, -0.16066907346248627]\n",
      "2900 steps | score: [0.025713663548231125, -0.055216796696186066]\n",
      "unknown params:  tensor([ 0.3370,  0.6705, -0.2344, -0.6971,  0.5973, -0.0942])\n",
      "gt params:  tensor([ 0.3325,  0.6810, -0.2536, -0.7432,  0.5887, -0.1447])\n",
      "ols params:  tensor([ 0.1970,  0.3841, -0.1371, -0.4026,  0.3454,  2.4039])\n",
      "unknown mse:  tensor(0.0009)\n",
      "ols mse:  tensor(1.1318)\n",
      "gt params:  tensor([ 0.3285,  0.6780, -0.2596, -0.7597,  0.6088, -0.0943])\n",
      "0 steps | score: [0.2996232509613037]\n",
      "100 steps | score: [0.010255418717861176]\n",
      "200 steps | score: [0.060908883810043335]\n",
      "300 steps | score: [0.0811249315738678]\n",
      "400 steps | score: [0.03773074597120285]\n",
      "500 steps | score: [-0.014084553346037865]\n",
      "600 steps | score: [-0.0073143355548381805]\n",
      "0 steps | score: [0.142067089676857, -0.026595592498779297]\n",
      "100 steps | score: [-0.05259275808930397, 0.23132827877998352]\n",
      "200 steps | score: [0.025955449789762497, -0.018227338790893555]\n",
      "300 steps | score: [-0.11432889103889465, 0.34694528579711914]\n",
      "400 steps | score: [-0.01395588181912899, 0.10257770121097565]\n",
      "500 steps | score: [0.002274095546454191, 0.03401676565408707]\n",
      "600 steps | score: [0.015137484297156334, -0.040040887892246246]\n",
      "700 steps | score: [-0.09649208188056946, 0.242580384016037]\n",
      "800 steps | score: [0.06049330532550812, -0.11204057931900024]\n",
      "900 steps | score: [-0.11521529406309128, 0.2968587279319763]\n",
      "1000 steps | score: [0.13814720511436462, -0.298210084438324]\n",
      "1100 steps | score: [-0.09315048158168793, 0.24397124350070953]\n",
      "1200 steps | score: [0.020665017887949944, -0.03692781180143356]\n",
      "1300 steps | score: [-0.05610094591975212, 0.16536831855773926]\n",
      "1400 steps | score: [-0.07468286156654358, 0.22541998326778412]\n",
      "1500 steps | score: [0.0022924270015209913, 0.05149316042661667]\n",
      "1600 steps | score: [-0.04916534200310707, 0.1730463206768036]\n",
      "1700 steps | score: [0.1192266047000885, -0.27202820777893066]\n",
      "1800 steps | score: [0.06594773381948471, -0.14055104553699493]\n",
      "1900 steps | score: [-0.06376832723617554, 0.17223632335662842]\n",
      "2000 steps | score: [-0.057733047753572464, 0.1576954573392868]\n",
      "2100 steps | score: [-0.14171287417411804, 0.35130277276039124]\n",
      "2200 steps | score: [-0.013850260525941849, 0.025062642991542816]\n",
      "2300 steps | score: [0.003376100677996874, -0.022572152316570282]\n",
      "2400 steps | score: [-0.05779832601547241, 0.1794007122516632]\n",
      "2500 steps | score: [-0.007611473090946674, 0.06220719963312149]\n",
      "2600 steps | score: [-0.07174961268901825, 0.16173484921455383]\n",
      "2700 steps | score: [0.0141215268522501, -0.022329092025756836]\n",
      "2800 steps | score: [0.03670921549201012, -0.06016012653708458]\n",
      "2900 steps | score: [-0.018286054953932762, 0.09426078200340271]\n",
      "unknown params:  tensor([ 0.2934,  0.6229, -0.2389, -0.7431,  0.5736, -0.0414])\n",
      "gt params:  tensor([ 0.3285,  0.6780, -0.2596, -0.7597,  0.6088, -0.0943])\n",
      "ols params:  tensor([ 0.1782,  0.3649, -0.1425, -0.4324,  0.3409,  2.5765])\n",
      "unknown mse:  tensor(0.0015)\n",
      "ols mse:  tensor(1.2411)\n",
      "gt params:  tensor([ 0.2972,  0.6757, -0.2526, -0.7468,  0.5913, -0.2071])\n",
      "0 steps | score: [0.3216571509838104]\n",
      "100 steps | score: [0.10468612611293793]\n",
      "200 steps | score: [0.15888120234012604]\n",
      "300 steps | score: [0.08521702140569687]\n",
      "400 steps | score: [0.032012730836868286]\n",
      "500 steps | score: [0.10387156903743744]\n",
      "600 steps | score: [0.11626770347356796]\n",
      "700 steps | score: [0.13548918068408966]\n",
      "800 steps | score: [0.11603730916976929]\n",
      "900 steps | score: [0.0668310672044754]\n",
      "1000 steps | score: [0.09890414029359818]\n",
      "1100 steps | score: [0.13354799151420593]\n",
      "1200 steps | score: [0.10620328783988953]\n",
      "1300 steps | score: [0.12447814643383026]\n",
      "1400 steps | score: [0.0892442911863327]\n",
      "1500 steps | score: [0.08991815149784088]\n",
      "1600 steps | score: [0.10248542577028275]\n",
      "1700 steps | score: [0.08623643219470978]\n",
      "1800 steps | score: [0.10386912524700165]\n",
      "1900 steps | score: [0.09222303330898285]\n",
      "2000 steps | score: [0.10423855483531952]\n",
      "2100 steps | score: [0.11351792514324188]\n",
      "2200 steps | score: [0.10728217661380768]\n",
      "2300 steps | score: [0.07325246930122375]\n",
      "2400 steps | score: [0.08710229396820068]\n",
      "2500 steps | score: [0.094345822930336]\n",
      "2600 steps | score: [0.11443522572517395]\n",
      "2700 steps | score: [0.11346584558486938]\n",
      "2800 steps | score: [0.08101646602153778]\n",
      "0 steps | score: [-0.0006894395337440073, 0.35490500926971436]\n",
      "100 steps | score: [-0.14637181162834167, 0.5124073028564453]\n",
      "200 steps | score: [0.007230805698782206, 0.08603397011756897]\n",
      "300 steps | score: [-0.4145625829696655, 0.9783587455749512]\n",
      "400 steps | score: [-0.16279619932174683, 0.4793925881385803]\n",
      "500 steps | score: [-0.030655303969979286, 0.10990577936172485]\n",
      "600 steps | score: [0.0016028338577598333, 0.04372069239616394]\n",
      "700 steps | score: [-0.2003270834684372, 0.5465308427810669]\n",
      "800 steps | score: [-0.06762712448835373, 0.21294045448303223]\n",
      "900 steps | score: [-0.21400225162506104, 0.6092566847801208]\n",
      "1000 steps | score: [-0.10010066628456116, 0.29707619547843933]\n",
      "1100 steps | score: [-0.24064844846725464, 0.6228107213973999]\n",
      "1200 steps | score: [-0.1214025691151619, 0.3357055187225342]\n",
      "1300 steps | score: [-0.144294872879982, 0.40866851806640625]\n",
      "1400 steps | score: [-0.18233294785022736, 0.4997437596321106]\n",
      "1500 steps | score: [-0.19763892889022827, 0.5268277525901794]\n",
      "1600 steps | score: [-0.16121353209018707, 0.44447651505470276]\n",
      "1700 steps | score: [-0.13120491802692413, 0.3806993067264557]\n",
      "1800 steps | score: [-0.23272749781608582, 0.6240248680114746]\n",
      "1900 steps | score: [-0.27660733461380005, 0.6842340230941772]\n",
      "2000 steps | score: [-0.1482425034046173, 0.4052785634994507]\n",
      "2100 steps | score: [-0.1372229903936386, 0.3673824965953827]\n",
      "2200 steps | score: [-0.13741564750671387, 0.38480135798454285]\n",
      "2300 steps | score: [-0.30364397168159485, 0.7684755921363831]\n",
      "2400 steps | score: [-0.1899196356534958, 0.4831825792789459]\n",
      "2500 steps | score: [-0.10566149652004242, 0.3122556209564209]\n",
      "2600 steps | score: [-0.10035941749811172, 0.2967737913131714]\n",
      "2700 steps | score: [-0.17923203110694885, 0.49517208337783813]\n",
      "2800 steps | score: [-0.2134242206811905, 0.5395630598068237]\n",
      "unknown params:  tensor([ 0.2667,  0.6158, -0.2501, -0.6812,  0.5825, -0.0576])\n",
      "gt params:  tensor([ 0.2972,  0.6757, -0.2526, -0.7468,  0.5913, -0.2071])\n",
      "ols params:  tensor([ 0.1489,  0.3346, -0.1383, -0.3717,  0.3183,  2.7116])\n",
      "unknown mse:  tensor(0.0052)\n",
      "ols mse:  tensor(1.4809)\n",
      "gt params:  tensor([ 0.3193,  0.6839, -0.2791, -0.7357,  0.5867, -0.1257])\n",
      "0 steps | score: [0.40425071120262146]\n",
      "100 steps | score: [0.1494220644235611]\n",
      "200 steps | score: [0.13875505328178406]\n",
      "300 steps | score: [0.10213517397642136]\n",
      "400 steps | score: [0.0912211686372757]\n",
      "500 steps | score: [0.1353662610054016]\n",
      "600 steps | score: [0.11885854601860046]\n",
      "700 steps | score: [0.1350168138742447]\n",
      "800 steps | score: [0.09900828450918198]\n",
      "900 steps | score: [0.10193847864866257]\n",
      "1000 steps | score: [0.11908406764268875]\n",
      "1100 steps | score: [0.16848313808441162]\n",
      "1200 steps | score: [0.12261434644460678]\n",
      "1300 steps | score: [0.10423582792282104]\n",
      "1400 steps | score: [0.11682995408773422]\n",
      "1500 steps | score: [0.10611307621002197]\n",
      "1600 steps | score: [0.1085183322429657]\n",
      "1700 steps | score: [0.09050317108631134]\n",
      "1800 steps | score: [0.10638060420751572]\n",
      "1900 steps | score: [0.10606721043586731]\n",
      "2000 steps | score: [0.12190794199705124]\n",
      "2100 steps | score: [0.12938150763511658]\n",
      "2200 steps | score: [0.10223036259412766]\n",
      "2300 steps | score: [0.11066211014986038]\n",
      "2400 steps | score: [0.11356934905052185]\n",
      "2500 steps | score: [0.12764836847782135]\n",
      "2600 steps | score: [0.11611656099557877]\n",
      "2700 steps | score: [0.11151860654354095]\n",
      "2800 steps | score: [0.11744172871112823]\n",
      "2900 steps | score: [0.11051236838102341]\n",
      "0 steps | score: [0.004131407011300325, 0.2986132502555847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [-0.2779638469219208, 0.7606427669525146]\n",
      "200 steps | score: [-0.2934780716896057, 0.7848926186561584]\n",
      "300 steps | score: [-0.2763324975967407, 0.7159693241119385]\n",
      "400 steps | score: [-0.1410638391971588, 0.37568485736846924]\n",
      "500 steps | score: [-0.21255815029144287, 0.5210314393043518]\n",
      "600 steps | score: [-0.13883157074451447, 0.3206193745136261]\n",
      "700 steps | score: [-0.05709327012300491, 0.13559868931770325]\n",
      "800 steps | score: [-0.22655530273914337, 0.5717434883117676]\n",
      "900 steps | score: [0.011542738415300846, -0.07681230455636978]\n",
      "1000 steps | score: [-0.11627646535634995, 0.23145970702171326]\n",
      "1100 steps | score: [0.055226683616638184, -0.20011001825332642]\n",
      "1200 steps | score: [-0.1853242665529251, 0.42536893486976624]\n",
      "1300 steps | score: [0.14907799661159515, -0.45216548442840576]\n",
      "1400 steps | score: [-0.15279048681259155, 0.3722148835659027]\n",
      "1500 steps | score: [-0.2061230093240738, 0.5108932256698608]\n",
      "1600 steps | score: [-0.23467819392681122, 0.5633442997932434]\n",
      "1700 steps | score: [-0.27525946497917175, 0.6742796897888184]\n",
      "1800 steps | score: [0.007634398061782122, -0.04728201404213905]\n",
      "1900 steps | score: [-0.11508287489414215, 0.2873024344444275]\n",
      "2000 steps | score: [-0.04643859714269638, 0.13301627337932587]\n",
      "2100 steps | score: [-0.13082806766033173, 0.3113594353199005]\n",
      "2200 steps | score: [-0.1477184146642685, 0.3573737144470215]\n",
      "2300 steps | score: [0.05566198751330376, -0.22655576467514038]\n",
      "2400 steps | score: [-0.1599542200565338, 0.3829324543476105]\n",
      "2500 steps | score: [-0.08140134066343307, 0.18737684190273285]\n",
      "2600 steps | score: [-0.12927933037281036, 0.30511224269866943]\n",
      "2700 steps | score: [-0.15689538419246674, 0.3866172134876251]\n",
      "2800 steps | score: [-0.06434374302625656, 0.15772905945777893]\n",
      "2900 steps | score: [-0.08443035185337067, 0.14459970593452454]\n",
      "unknown params:  tensor([ 0.3763,  0.7149, -0.3413, -0.7509,  0.5713,  0.0324])\n",
      "gt params:  tensor([ 0.3193,  0.6839, -0.2791, -0.7357,  0.5867, -0.1257])\n",
      "ols params:  tensor([ 0.1980,  0.3642, -0.1784, -0.3847,  0.2942,  2.8304])\n",
      "unknown mse:  tensor(0.0056)\n",
      "ols mse:  tensor(1.5124)\n",
      "gt params:  tensor([ 0.3519,  0.6968, -0.2695, -0.7659,  0.5918, -0.1398])\n",
      "0 steps | score: [0.3472825288772583]\n",
      "100 steps | score: [0.06914778053760529]\n",
      "200 steps | score: [0.1092895045876503]\n",
      "300 steps | score: [0.1000438928604126]\n",
      "400 steps | score: [0.07660966366529465]\n",
      "500 steps | score: [0.1370125114917755]\n",
      "600 steps | score: [0.06128326430916786]\n",
      "700 steps | score: [0.11142291873693466]\n",
      "800 steps | score: [0.09914303570985794]\n",
      "900 steps | score: [0.10923366993665695]\n",
      "1000 steps | score: [0.06835805624723434]\n",
      "1100 steps | score: [0.0712224617600441]\n",
      "1200 steps | score: [0.12423769384622574]\n",
      "1300 steps | score: [0.1165294274687767]\n",
      "1400 steps | score: [0.09551101177930832]\n",
      "1500 steps | score: [0.08541572093963623]\n",
      "1600 steps | score: [0.07875733077526093]\n",
      "1700 steps | score: [0.11907899379730225]\n",
      "1800 steps | score: [0.1086769849061966]\n",
      "1900 steps | score: [0.1040850579738617]\n",
      "2000 steps | score: [0.1089431643486023]\n",
      "2100 steps | score: [0.09429849684238434]\n",
      "2200 steps | score: [0.0824226513504982]\n",
      "2300 steps | score: [0.11539284884929657]\n",
      "2400 steps | score: [0.1102101281285286]\n",
      "2500 steps | score: [0.09179918467998505]\n",
      "2600 steps | score: [0.08685024827718735]\n",
      "2700 steps | score: [0.10694026201963425]\n",
      "2800 steps | score: [0.09179975837469101]\n",
      "2900 steps | score: [0.12177806347608566]\n",
      "0 steps | score: [0.2916117012500763, -0.40537959337234497]\n",
      "100 steps | score: [0.07011107355356216, -0.09654755890369415]\n",
      "200 steps | score: [0.37942832708358765, -0.8548240065574646]\n",
      "300 steps | score: [0.31547415256500244, -0.7644252777099609]\n",
      "400 steps | score: [0.10200972855091095, -0.21836239099502563]\n",
      "500 steps | score: [0.40866896510124207, -1.0689241886138916]\n",
      "600 steps | score: [0.0886700302362442, -0.24544504284858704]\n",
      "700 steps | score: [0.19729197025299072, -0.4787285327911377]\n",
      "800 steps | score: [0.10725829750299454, -0.2762383818626404]\n",
      "900 steps | score: [0.1059432253241539, -0.3109120726585388]\n",
      "1000 steps | score: [-0.05321540683507919, 0.08381123095750809]\n",
      "1100 steps | score: [0.10576711595058441, -0.30592572689056396]\n",
      "1200 steps | score: [0.4541736841201782, -1.224916696548462]\n",
      "1300 steps | score: [0.0733504593372345, -0.20958182215690613]\n",
      "1400 steps | score: [0.12369386851787567, -0.31297919154167175]\n",
      "1500 steps | score: [0.003477036254480481, -0.0163382887840271]\n",
      "1600 steps | score: [0.2060752809047699, -0.5351318717002869]\n",
      "1700 steps | score: [0.12983301281929016, -0.3390287160873413]\n",
      "1800 steps | score: [0.0777590423822403, -0.23353615403175354]\n",
      "1900 steps | score: [0.2208002507686615, -0.565474808216095]\n",
      "2000 steps | score: [0.1536923497915268, -0.3923630714416504]\n",
      "2100 steps | score: [0.09732145816087723, -0.22464226186275482]\n",
      "2200 steps | score: [0.03291505575180054, -0.10479120910167694]\n",
      "2300 steps | score: [0.06902261823415756, -0.1692752242088318]\n",
      "2400 steps | score: [0.13176171481609344, -0.34570011496543884]\n",
      "2500 steps | score: [0.10653369128704071, -0.27098286151885986]\n",
      "2600 steps | score: [0.09412474185228348, -0.2372838705778122]\n",
      "2700 steps | score: [0.13332276046276093, -0.3345004618167877]\n",
      "2800 steps | score: [0.09687232971191406, -0.24782533943653107]\n",
      "2900 steps | score: [0.17355230450630188, -0.461378812789917]\n",
      "unknown params:  tensor([ 0.3912,  0.6928, -0.2870, -0.7691,  0.6185, -0.0513])\n",
      "gt params:  tensor([ 0.3519,  0.6968, -0.2695, -0.7659,  0.5918, -0.1398])\n",
      "ols params:  tensor([ 0.2067,  0.3597, -0.1488, -0.3956,  0.3212,  2.9563])\n",
      "unknown mse:  tensor(0.0017)\n",
      "ols mse:  tensor(1.6576)\n",
      "gt params:  tensor([ 0.3304,  0.6749, -0.2689, -0.7626,  0.5963, -0.1348])\n",
      "0 steps | score: [0.3081584572792053]\n",
      "100 steps | score: [0.1170119121670723]\n",
      "200 steps | score: [0.028234615921974182]\n",
      "300 steps | score: [0.041002582758665085]\n",
      "400 steps | score: [0.0909532979130745]\n",
      "500 steps | score: [0.044326815754175186]\n",
      "600 steps | score: [0.09085453301668167]\n",
      "700 steps | score: [0.039812687784433365]\n",
      "800 steps | score: [0.07235635071992874]\n",
      "900 steps | score: [0.04230349138379097]\n",
      "1000 steps | score: [-0.004744220525026321]\n",
      "0 steps | score: [0.10093680024147034, 0.09519871324300766]\n",
      "100 steps | score: [0.174320250749588, -0.24388808012008667]\n",
      "200 steps | score: [-0.10975231975317001, 0.3213428258895874]\n",
      "300 steps | score: [-0.07351868599653244, 0.2252536565065384]\n",
      "400 steps | score: [-0.17901788651943207, 0.4079707860946655]\n",
      "500 steps | score: [-0.20015817880630493, 0.4493461549282074]\n",
      "600 steps | score: [0.12760230898857117, -0.31728607416152954]\n",
      "700 steps | score: [-0.0767810195684433, 0.1698254644870758]\n",
      "800 steps | score: [0.006356094032526016, -0.03767798840999603]\n",
      "900 steps | score: [-0.09432253241539001, 0.22363798320293427]\n",
      "1000 steps | score: [-0.1546769142150879, 0.3719354569911957]\n",
      "1100 steps | score: [-0.1550319641828537, 0.3514218330383301]\n",
      "1200 steps | score: [-0.04585452005267143, 0.11347287148237228]\n",
      "1300 steps | score: [-0.1813686490058899, 0.4266049563884735]\n",
      "1400 steps | score: [-0.13881289958953857, 0.33351096510887146]\n",
      "1500 steps | score: [-0.058430012315511703, 0.0869111567735672]\n",
      "1600 steps | score: [-0.1955270618200302, 0.427607923746109]\n",
      "1700 steps | score: [-0.07617092877626419, 0.2018355280160904]\n",
      "1800 steps | score: [-0.12093695253133774, 0.2945355772972107]\n",
      "1900 steps | score: [-0.18313910067081451, 0.4023667871952057]\n",
      "2000 steps | score: [-0.12148215621709824, 0.3130307197570801]\n",
      "2100 steps | score: [-0.14588625729084015, 0.38721203804016113]\n",
      "2200 steps | score: [-0.1522165834903717, 0.3304848372936249]\n",
      "2300 steps | score: [-0.11105197668075562, 0.25555282831192017]\n",
      "2400 steps | score: [-0.15936057269573212, 0.37997400760650635]\n",
      "2500 steps | score: [-0.09690164029598236, 0.22531341016292572]\n",
      "2600 steps | score: [-0.18583005666732788, 0.3834662437438965]\n",
      "2700 steps | score: [-0.14528416097164154, 0.34005099534988403]\n",
      "2800 steps | score: [-0.13310319185256958, 0.3180178105831146]\n",
      "2900 steps | score: [-0.1697394698858261, 0.37141555547714233]\n",
      "unknown params:  tensor([ 0.2923,  0.7118, -0.2971, -0.8084,  0.6120, -0.2414])\n",
      "gt params:  tensor([ 0.3304,  0.6749, -0.2689, -0.7626,  0.5963, -0.1348])\n",
      "ols params:  tensor([ 0.1513,  0.3563, -0.1508, -0.3999,  0.3080,  3.0347])\n",
      "unknown mse:  tensor(0.0029)\n",
      "ols mse:  tensor(1.7346)\n",
      "gt params:  tensor([ 0.3345,  0.6755, -0.2362, -0.7642,  0.5761, -0.1672])\n",
      "0 steps | score: [0.34100261330604553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [0.032778300344944]\n",
      "200 steps | score: [0.02811497077345848]\n",
      "300 steps | score: [0.10015441477298737]\n",
      "400 steps | score: [0.09750145673751831]\n",
      "500 steps | score: [0.06359292566776276]\n",
      "600 steps | score: [0.04902727156877518]\n",
      "700 steps | score: [0.09698347747325897]\n",
      "800 steps | score: [0.0449509471654892]\n",
      "900 steps | score: [0.06047442927956581]\n",
      "1000 steps | score: [0.05946153402328491]\n",
      "1100 steps | score: [0.03062862530350685]\n",
      "1200 steps | score: [0.03374890983104706]\n",
      "1300 steps | score: [0.04771764203906059]\n",
      "1400 steps | score: [0.05888349562883377]\n",
      "1500 steps | score: [0.0268924068659544]\n",
      "1600 steps | score: [0.02500121481716633]\n",
      "1700 steps | score: [0.049640994518995285]\n",
      "1800 steps | score: [0.07712389528751373]\n",
      "1900 steps | score: [0.07049430161714554]\n",
      "2000 steps | score: [0.05951564759016037]\n",
      "2100 steps | score: [0.04335849732160568]\n",
      "2200 steps | score: [0.06188115105032921]\n",
      "2300 steps | score: [0.05284707993268967]\n",
      "2400 steps | score: [0.05388668179512024]\n",
      "2500 steps | score: [0.042649365961551666]\n",
      "2600 steps | score: [0.046213336288928986]\n",
      "2700 steps | score: [0.04072718322277069]\n",
      "2800 steps | score: [0.07589200884103775]\n",
      "2900 steps | score: [0.06400936841964722]\n",
      "0 steps | score: [0.2682023048400879, -0.37971973419189453]\n",
      "100 steps | score: [0.1225462406873703, -0.2553231120109558]\n",
      "200 steps | score: [0.004044142086058855, -0.02492598257958889]\n",
      "300 steps | score: [0.08131125569343567, -0.22427257895469666]\n",
      "400 steps | score: [0.12263179570436478, -0.3311701714992523]\n",
      "500 steps | score: [-0.06719833612442017, 0.06647688150405884]\n",
      "600 steps | score: [0.10978418588638306, -0.36177557706832886]\n",
      "700 steps | score: [0.19794435799121857, -0.54385906457901]\n",
      "800 steps | score: [-0.0471491776406765, 0.030656900256872177]\n",
      "900 steps | score: [-0.021463705226778984, 0.021450575441122055]\n",
      "1000 steps | score: [0.054306481033563614, -0.15891475975513458]\n",
      "1100 steps | score: [-0.07455713301897049, 0.08640396595001221]\n",
      "1200 steps | score: [0.1353112757205963, -0.3649021089076996]\n",
      "1300 steps | score: [0.09432205557823181, -0.2863825857639313]\n",
      "1400 steps | score: [0.04902494698762894, -0.16469420492649078]\n",
      "1500 steps | score: [-0.005368133075535297, -0.04444143921136856]\n",
      "1600 steps | score: [0.06699291616678238, -0.23375444114208221]\n",
      "1700 steps | score: [0.14760863780975342, -0.4426760971546173]\n",
      "1800 steps | score: [0.16722571849822998, -0.49841028451919556]\n",
      "1900 steps | score: [0.1527719497680664, -0.4529556632041931]\n",
      "2000 steps | score: [0.1112159937620163, -0.33651307225227356]\n",
      "2100 steps | score: [0.0368632897734642, -0.14627400040626526]\n",
      "2200 steps | score: [0.1618443727493286, -0.441915899515152]\n",
      "2300 steps | score: [0.06470393389463425, -0.2135140299797058]\n",
      "2400 steps | score: [0.086362324655056, -0.30136868357658386]\n",
      "2500 steps | score: [0.0794195905327797, -0.24542690813541412]\n",
      "2600 steps | score: [0.10712224990129471, -0.32717055082321167]\n",
      "2700 steps | score: [0.05702793970704079, -0.2021423876285553]\n",
      "2800 steps | score: [0.08249591290950775, -0.26254725456237793]\n",
      "2900 steps | score: [0.07461994886398315, -0.24133038520812988]\n",
      "unknown params:  tensor([ 0.3373,  0.6584, -0.2574, -0.8391,  0.5957,  0.0239])\n",
      "gt params:  tensor([ 0.3345,  0.6755, -0.2362, -0.7642,  0.5761, -0.1672])\n",
      "ols params:  tensor([ 0.1690,  0.3254, -0.1288, -0.4083,  0.2970,  3.1534])\n",
      "unknown mse:  tensor(0.0072)\n",
      "ols mse:  tensor(1.8988)\n",
      "gt params:  tensor([ 0.3384,  0.6839, -0.2483, -0.7494,  0.6056, -0.1818])\n",
      "0 steps | score: [0.3686099350452423]\n",
      "100 steps | score: [0.15862888097763062]\n",
      "200 steps | score: [0.0941082239151001]\n",
      "300 steps | score: [0.13363388180732727]\n",
      "400 steps | score: [0.08350574225187302]\n",
      "500 steps | score: [0.0665067806839943]\n",
      "600 steps | score: [0.08576061576604843]\n",
      "700 steps | score: [0.06276706606149673]\n",
      "800 steps | score: [0.09967614710330963]\n",
      "900 steps | score: [0.05675722658634186]\n",
      "1000 steps | score: [0.06387916952371597]\n",
      "1100 steps | score: [0.06815303862094879]\n",
      "1200 steps | score: [0.02339773252606392]\n",
      "1300 steps | score: [0.06871946901082993]\n",
      "1400 steps | score: [0.07663995772600174]\n",
      "1500 steps | score: [0.04427104443311691]\n",
      "1600 steps | score: [0.03185317665338516]\n",
      "1700 steps | score: [0.0013759862631559372]\n",
      "0 steps | score: [0.02236115373671055, 0.037104301154613495]\n",
      "100 steps | score: [0.40812045335769653, -1.0868306159973145]\n",
      "200 steps | score: [-0.06920058280229568, -0.022750429809093475]\n",
      "300 steps | score: [0.19950105249881744, -0.7296614646911621]\n",
      "400 steps | score: [-0.138464093208313, 0.14848792552947998]\n",
      "500 steps | score: [-0.23703117668628693, 0.330604612827301]\n",
      "600 steps | score: [0.032593436539173126, -0.27644407749176025]\n",
      "700 steps | score: [-0.023072682321071625, -0.19466719031333923]\n",
      "800 steps | score: [-0.2110753208398819, 0.24766534566879272]\n",
      "900 steps | score: [-0.14132186770439148, 0.15008175373077393]\n",
      "1000 steps | score: [-0.2203087955713272, 0.30409911274909973]\n",
      "1100 steps | score: [-0.18350917100906372, 0.22397148609161377]\n",
      "1200 steps | score: [-0.25633934140205383, 0.3707335591316223]\n",
      "1300 steps | score: [-0.2482067197561264, 0.3425014019012451]\n",
      "1400 steps | score: [-0.09722890704870224, 0.03510836511850357]\n",
      "1500 steps | score: [-0.26412463188171387, 0.3843143582344055]\n",
      "1600 steps | score: [-0.21292614936828613, 0.27321410179138184]\n",
      "1700 steps | score: [-0.25242242217063904, 0.36826997995376587]\n",
      "1800 steps | score: [-0.1656920611858368, 0.17252829670906067]\n",
      "1900 steps | score: [-0.16264639794826508, 0.18016967177391052]\n",
      "2000 steps | score: [-0.11481271684169769, 0.06994546949863434]\n",
      "2100 steps | score: [-0.1616060584783554, 0.1684715300798416]\n",
      "2200 steps | score: [-0.154712975025177, 0.13641488552093506]\n",
      "2300 steps | score: [-0.2002486288547516, 0.2665436267852783]\n",
      "2400 steps | score: [-0.11987036466598511, 0.0546913668513298]\n",
      "2500 steps | score: [-0.16095685958862305, 0.1519252061843872]\n",
      "2600 steps | score: [-0.1941949725151062, 0.23558196425437927]\n",
      "2700 steps | score: [-0.14090384542942047, 0.12359403073787689]\n",
      "2800 steps | score: [-0.14730311930179596, 0.11241444945335388]\n",
      "2900 steps | score: [-0.1069343239068985, 0.029800720512866974]\n",
      "unknown params:  tensor([ 0.3363,  0.7167, -0.2346, -0.7392,  0.5702, -0.0378])\n",
      "gt params:  tensor([ 0.3384,  0.6839, -0.2483, -0.7494,  0.6056, -0.1818])\n",
      "ols params:  tensor([ 0.1661,  0.3493, -0.1174, -0.3586,  0.2806,  3.2542])\n",
      "unknown mse:  tensor(0.0039)\n",
      "ols mse:  tensor(2.0372)\n",
      "gt params:  tensor([ 0.2994,  0.7054, -0.2405, -0.7638,  0.5892, -0.1364])\n",
      "0 steps | score: [0.31114259362220764]\n",
      "100 steps | score: [-0.017299823462963104]\n",
      "200 steps | score: [0.005997709929943085]\n",
      "0 steps | score: [0.08667562901973724, 0.12575271725654602]\n",
      "100 steps | score: [-0.32010242342948914, 0.7507044672966003]\n",
      "200 steps | score: [-0.302864670753479, 0.689225971698761]\n",
      "300 steps | score: [-0.15923644602298737, 0.38846394419670105]\n",
      "400 steps | score: [-0.03324545547366142, 0.1483592391014099]\n",
      "500 steps | score: [-0.26005399227142334, 0.6067978143692017]\n",
      "600 steps | score: [-0.020377611741423607, 0.1041494756937027]\n",
      "700 steps | score: [0.006496940273791552, 0.015405528247356415]\n",
      "800 steps | score: [-0.09524063766002655, 0.2557796239852905]\n",
      "900 steps | score: [-0.1948813945055008, 0.48451709747314453]\n",
      "1000 steps | score: [-0.14681336283683777, 0.3595339357852936]\n",
      "1100 steps | score: [-0.1900283396244049, 0.46063995361328125]\n",
      "1200 steps | score: [-0.02321718819439411, 0.10657006502151489]\n",
      "1300 steps | score: [-0.19325438141822815, 0.4714788496494293]\n",
      "1400 steps | score: [-0.08460283279418945, 0.23410016298294067]\n",
      "1500 steps | score: [-0.03538618981838226, 0.12705597281455994]\n",
      "1600 steps | score: [-0.19460423290729523, 0.45427578687667847]\n",
      "1700 steps | score: [-0.13905556499958038, 0.3151201009750366]\n",
      "1800 steps | score: [-0.11126268655061722, 0.28694167733192444]\n",
      "1900 steps | score: [-0.1272459179162979, 0.3412546217441559]\n",
      "2000 steps | score: [-0.09501409530639648, 0.27062684297561646]\n",
      "2100 steps | score: [-0.14160363376140594, 0.35692405700683594]\n",
      "2200 steps | score: [-0.08043844997882843, 0.20974573493003845]\n",
      "2300 steps | score: [-0.12250487506389618, 0.3054628372192383]\n",
      "2400 steps | score: [-0.13618145883083344, 0.33146384358406067]\n",
      "2500 steps | score: [-0.12241591513156891, 0.31373730301856995]\n",
      "2600 steps | score: [-0.15666179358959198, 0.37875258922576904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 steps | score: [-0.13276231288909912, 0.3191535770893097]\n",
      "2800 steps | score: [-0.08359893411397934, 0.2239048331975937]\n",
      "2900 steps | score: [-0.1316687911748886, 0.3467586934566498]\n",
      "unknown params:  tensor([ 0.2962,  0.7441, -0.2262, -0.7881,  0.5906, -0.1253])\n",
      "gt params:  tensor([ 0.2994,  0.7054, -0.2405, -0.7638,  0.5892, -0.1364])\n",
      "ols params:  tensor([ 0.1473,  0.3576, -0.1125, -0.3814,  0.2899,  3.3419])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(2.0825)\n",
      "gt params:  tensor([ 0.3346,  0.7048, -0.2501, -0.7522,  0.6042, -0.1456])\n",
      "0 steps | score: [0.45816943049430847]\n",
      "100 steps | score: [0.14867454767227173]\n",
      "200 steps | score: [0.1625090092420578]\n",
      "300 steps | score: [0.18263718485832214]\n",
      "400 steps | score: [0.18921223282814026]\n",
      "500 steps | score: [0.1712416708469391]\n",
      "600 steps | score: [0.11611496657133102]\n",
      "700 steps | score: [0.16614659130573273]\n",
      "800 steps | score: [0.18445605039596558]\n",
      "900 steps | score: [0.18080753087997437]\n",
      "1000 steps | score: [0.16343414783477783]\n",
      "1100 steps | score: [0.15223531424999237]\n",
      "1200 steps | score: [0.14615398645401]\n",
      "1300 steps | score: [0.17987200617790222]\n",
      "1400 steps | score: [0.1856975555419922]\n",
      "1500 steps | score: [0.18731960654258728]\n",
      "1600 steps | score: [0.16322541236877441]\n",
      "1700 steps | score: [0.14572782814502716]\n",
      "1800 steps | score: [0.17725351452827454]\n",
      "1900 steps | score: [0.16362880170345306]\n",
      "2000 steps | score: [0.17273619771003723]\n",
      "2100 steps | score: [0.17089834809303284]\n",
      "2200 steps | score: [0.1832384467124939]\n",
      "2300 steps | score: [0.16782104969024658]\n",
      "2400 steps | score: [0.17056460678577423]\n",
      "2500 steps | score: [0.1735857129096985]\n",
      "2600 steps | score: [0.11626055836677551]\n",
      "2700 steps | score: [0.17130695283412933]\n",
      "2800 steps | score: [0.18549737334251404]\n",
      "2900 steps | score: [0.15344572067260742]\n",
      "0 steps | score: [0.15486690402030945, -0.16377009451389313]\n",
      "100 steps | score: [0.06507077068090439, -0.11328846216201782]\n",
      "200 steps | score: [0.0929652601480484, -0.2570401430130005]\n",
      "300 steps | score: [0.0667392835021019, -0.2051568180322647]\n",
      "400 steps | score: [0.07952004671096802, -0.26887789368629456]\n",
      "500 steps | score: [-0.06102929636836052, 0.05371193587779999]\n",
      "600 steps | score: [-0.1524454951286316, 0.26665595173835754]\n",
      "700 steps | score: [-0.0995422750711441, 0.1612696796655655]\n",
      "800 steps | score: [0.1895255595445633, -0.5616556406021118]\n",
      "900 steps | score: [0.1277656853199005, -0.3382306694984436]\n",
      "1000 steps | score: [-0.05811677128076553, 0.04809187352657318]\n",
      "1100 steps | score: [-0.04925302416086197, -0.0007390975952148438]\n",
      "1200 steps | score: [-0.07413987815380096, 0.06385551393032074]\n",
      "1300 steps | score: [0.03148474171757698, -0.16408610343933105]\n",
      "1400 steps | score: [0.048034802079200745, -0.19466538727283478]\n",
      "1500 steps | score: [0.05245935544371605, -0.20481926202774048]\n",
      "1600 steps | score: [-0.14740122854709625, 0.23830546438694]\n",
      "1700 steps | score: [-0.11935106664896011, 0.2005930244922638]\n",
      "1800 steps | score: [-0.02544885128736496, -0.044384151697158813]\n",
      "1900 steps | score: [-0.02845444343984127, -0.021568194031715393]\n",
      "2000 steps | score: [0.10439874231815338, -0.3539254665374756]\n",
      "2100 steps | score: [-0.11852667480707169, 0.16182303428649902]\n",
      "2200 steps | score: [-0.13200770318508148, 0.19141334295272827]\n",
      "2300 steps | score: [0.02622584067285061, -0.14864501357078552]\n",
      "2400 steps | score: [-0.10272741317749023, 0.1108875721693039]\n",
      "2500 steps | score: [0.030109504237771034, -0.16844050586223602]\n",
      "2600 steps | score: [-0.09708049148321152, 0.11187736690044403]\n",
      "2700 steps | score: [-0.11520767956972122, 0.13281120359897614]\n",
      "2800 steps | score: [-0.0076665389351546764, -0.06312891840934753]\n",
      "2900 steps | score: [-0.024864889681339264, -0.028784096240997314]\n",
      "unknown params:  tensor([ 0.4025,  0.6596, -0.2255, -0.7280,  0.5951, -0.0533])\n",
      "gt params:  tensor([ 0.3346,  0.7048, -0.2501, -0.7522,  0.6042, -0.1456])\n",
      "ols params:  tensor([ 0.1964,  0.3172, -0.1106, -0.3515,  0.2917,  3.4590])\n",
      "unknown mse:  tensor(0.0027)\n",
      "ols mse:  tensor(2.2401)\n",
      "gt params:  tensor([ 0.3521,  0.6826, -0.2937, -0.7589,  0.5860, -0.1033])\n",
      "0 steps | score: [0.26522284746170044]\n",
      "100 steps | score: [-0.011989131569862366]\n",
      "200 steps | score: [0.04139366000890732]\n",
      "300 steps | score: [-0.012251075357198715]\n",
      "400 steps | score: [-0.02846008539199829]\n",
      "500 steps | score: [0.011303329840302467]\n",
      "600 steps | score: [-0.027617011219263077]\n",
      "700 steps | score: [-0.006706060376018286]\n",
      "0 steps | score: [0.30416038632392883, -0.37860018014907837]\n",
      "100 steps | score: [0.4062705934047699, -0.777336835861206]\n",
      "200 steps | score: [0.31739941239356995, -0.6049041748046875]\n",
      "300 steps | score: [0.278751403093338, -0.5868170261383057]\n",
      "400 steps | score: [0.20049554109573364, -0.37360429763793945]\n",
      "500 steps | score: [0.6112600564956665, -1.485695242881775]\n",
      "600 steps | score: [0.03627222031354904, -0.015406042337417603]\n",
      "700 steps | score: [-0.02966121770441532, 0.09512989223003387]\n",
      "800 steps | score: [0.1436198204755783, -0.2947205901145935]\n",
      "900 steps | score: [-0.036448076367378235, 0.12705159187316895]\n",
      "1000 steps | score: [0.08713356405496597, -0.13885498046875]\n",
      "1100 steps | score: [-0.014153099618852139, 0.05644060671329498]\n",
      "1200 steps | score: [0.11214176565408707, -0.234180748462677]\n",
      "1300 steps | score: [-0.006303311325609684, 0.05888237804174423]\n",
      "1400 steps | score: [0.054643385112285614, -0.08866799622774124]\n",
      "1500 steps | score: [0.13038665056228638, -0.2549617886543274]\n",
      "1600 steps | score: [0.08291620761156082, -0.16693194210529327]\n",
      "1700 steps | score: [0.10826457291841507, -0.20328806340694427]\n",
      "1800 steps | score: [0.1527549773454666, -0.309346079826355]\n",
      "1900 steps | score: [0.07402431219816208, -0.13405349850654602]\n",
      "2000 steps | score: [0.22403529286384583, -0.46473392844200134]\n",
      "2100 steps | score: [0.23274476826190948, -0.5048239827156067]\n",
      "2200 steps | score: [0.10459482669830322, -0.1954537332057953]\n",
      "2300 steps | score: [0.12160991132259369, -0.2158680409193039]\n",
      "2400 steps | score: [0.118993379175663, -0.22846150398254395]\n",
      "2500 steps | score: [0.1906365603208542, -0.3909458518028259]\n",
      "2600 steps | score: [0.3564203977584839, -0.7753633856773376]\n",
      "2700 steps | score: [0.15401820838451385, -0.3160492479801178]\n",
      "2800 steps | score: [0.15916642546653748, -0.3181474208831787]\n",
      "2900 steps | score: [0.14396679401397705, -0.27403736114501953]\n",
      "unknown params:  tensor([ 0.2766,  0.6700, -0.2767, -0.7969,  0.6282, -0.0403])\n",
      "gt params:  tensor([ 0.3521,  0.6826, -0.2937, -0.7589,  0.5860, -0.1033])\n",
      "ols params:  tensor([ 0.1392,  0.3228, -0.1344, -0.3820,  0.3016,  3.5929])\n",
      "unknown mse:  tensor(0.0022)\n",
      "ols mse:  tensor(2.3474)\n",
      "gt params:  tensor([ 0.3380,  0.6649, -0.2625, -0.7668,  0.5782, -0.2053])\n",
      "0 steps | score: [0.3436651825904846]\n",
      "100 steps | score: [0.08548390865325928]\n",
      "200 steps | score: [0.03562339022755623]\n",
      "300 steps | score: [0.09513632953166962]\n",
      "400 steps | score: [0.04457729309797287]\n",
      "500 steps | score: [0.04396798089146614]\n",
      "600 steps | score: [0.048018164932727814]\n",
      "700 steps | score: [0.047997068613767624]\n",
      "800 steps | score: [0.055658191442489624]\n",
      "900 steps | score: [0.0682314783334732]\n",
      "1000 steps | score: [0.07566004991531372]\n",
      "1100 steps | score: [0.031672220677137375]\n",
      "1200 steps | score: [0.02407318353652954]\n",
      "1300 steps | score: [0.05487341061234474]\n",
      "1400 steps | score: [0.061343349516391754]\n",
      "1500 steps | score: [0.03808986768126488]\n",
      "1600 steps | score: [0.06813514977693558]\n",
      "1700 steps | score: [0.029214326292276382]\n",
      "1800 steps | score: [0.06317585706710815]\n",
      "1900 steps | score: [0.05033578723669052]\n",
      "2000 steps | score: [0.04263390973210335]\n",
      "2100 steps | score: [0.049771998077631]\n",
      "2200 steps | score: [0.03887062519788742]\n",
      "2300 steps | score: [0.06958421319723129]\n",
      "2400 steps | score: [0.08553943783044815]\n",
      "2500 steps | score: [0.040652692317962646]\n",
      "2600 steps | score: [0.059425536543130875]\n",
      "2700 steps | score: [0.044554904103279114]\n",
      "2800 steps | score: [0.061900194734334946]\n",
      "0 steps | score: [0.3276202976703644, -0.2986270487308502]\n",
      "100 steps | score: [0.381491482257843, -0.557481586933136]\n",
      "200 steps | score: [0.15989843010902405, -0.14382320642471313]\n",
      "300 steps | score: [0.22183898091316223, -0.3129706084728241]\n",
      "400 steps | score: [0.03016648255288601, 0.08426373451948166]\n",
      "500 steps | score: [0.0955304503440857, -0.07522213459014893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 steps | score: [0.25905656814575195, -0.42308393120765686]\n",
      "700 steps | score: [0.312822163105011, -0.5246176719665527]\n",
      "800 steps | score: [0.022750943899154663, 0.09524960815906525]\n",
      "900 steps | score: [0.43941372632980347, -0.9048718214035034]\n",
      "1000 steps | score: [0.13286595046520233, -0.1487482488155365]\n",
      "1100 steps | score: [0.11202650517225266, -0.10320596396923065]\n",
      "1200 steps | score: [0.2339407503604889, -0.4005052149295807]\n",
      "1300 steps | score: [0.3157478868961334, -0.5811071395874023]\n",
      "1400 steps | score: [0.24028107523918152, -0.3732665181159973]\n",
      "1500 steps | score: [0.09101656824350357, -0.06192450225353241]\n",
      "1600 steps | score: [0.19447235763072968, -0.3200724720954895]\n",
      "1700 steps | score: [0.0595284029841423, 0.004501335322856903]\n",
      "1800 steps | score: [0.22484132647514343, -0.3612440526485443]\n",
      "1900 steps | score: [0.26505324244499207, -0.45069169998168945]\n",
      "2000 steps | score: [0.22008728981018066, -0.34113800525665283]\n",
      "2100 steps | score: [0.15272924304008484, -0.18383583426475525]\n",
      "2200 steps | score: [0.15388964116573334, -0.2038382738828659]\n",
      "2300 steps | score: [0.2115294337272644, -0.3044441342353821]\n",
      "2400 steps | score: [0.19713997840881348, -0.3188421130180359]\n",
      "2500 steps | score: [0.16461002826690674, -0.2223450094461441]\n",
      "2600 steps | score: [0.12070827931165695, -0.1272733211517334]\n",
      "2700 steps | score: [0.1413593739271164, -0.1746017336845398]\n",
      "2800 steps | score: [0.16705173254013062, -0.2519629895687103]\n",
      "unknown params:  tensor([ 0.3625,  0.6375, -0.2727, -0.7539,  0.5697,  0.0266])\n",
      "gt params:  tensor([ 0.3380,  0.6649, -0.2625, -0.7668,  0.5782, -0.2053])\n",
      "ols params:  tensor([ 0.1752,  0.3026, -0.1316, -0.3562,  0.2724,  3.7135])\n",
      "unknown mse:  tensor(0.0092)\n",
      "ols mse:  tensor(2.6324)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/99fa9c81-d885-4051-8fdb-f7aa430ca172\n",
      "gt params:  tensor([ 0.3708, -0.9543, -0.8473, -0.3539, -0.2556,  0.9037])\n",
      "0 steps | score: [0.1836824268102646]\n",
      "100 steps | score: [-0.011546574532985687]\n",
      "200 steps | score: [0.15932713449001312]\n",
      "300 steps | score: [0.13641734421253204]\n",
      "400 steps | score: [0.06701474636793137]\n",
      "500 steps | score: [0.025580229237675667]\n",
      "600 steps | score: [0.024352416396141052]\n",
      "700 steps | score: [0.045806143432855606]\n",
      "800 steps | score: [0.18755753338336945]\n",
      "900 steps | score: [0.1109149232506752]\n",
      "1000 steps | score: [0.06324939429759979]\n",
      "1100 steps | score: [0.02612905763089657]\n",
      "1200 steps | score: [0.10483141243457794]\n",
      "1300 steps | score: [0.11415930837392807]\n",
      "1400 steps | score: [0.15003959834575653]\n",
      "1500 steps | score: [0.08648037910461426]\n",
      "1600 steps | score: [0.1278483122587204]\n",
      "1700 steps | score: [0.10254664719104767]\n",
      "1800 steps | score: [0.09440886974334717]\n",
      "1900 steps | score: [0.06940300017595291]\n",
      "2000 steps | score: [0.1107955053448677]\n",
      "2100 steps | score: [0.1055818498134613]\n",
      "2200 steps | score: [0.08050265908241272]\n",
      "2300 steps | score: [0.08915378898382187]\n",
      "2400 steps | score: [0.0805022120475769]\n",
      "2500 steps | score: [0.09797951579093933]\n",
      "2600 steps | score: [0.09218285977840424]\n",
      "2700 steps | score: [0.11326166242361069]\n",
      "2800 steps | score: [0.10033934563398361]\n",
      "2900 steps | score: [0.10457508265972137]\n",
      "0 steps | score: [0.06039931997656822, 0.24254217743873596]\n",
      "100 steps | score: [-1.534560203552246, 8.192216873168945]\n",
      "200 steps | score: [1.7539429664611816, -7.080386161804199]\n",
      "300 steps | score: [-3.134298086166382, 11.100554466247559]\n",
      "400 steps | score: [0.2982409596443176, 1.0068373680114746]\n",
      "500 steps | score: [-1.055735468864441, 6.8379998207092285]\n",
      "600 steps | score: [0.2548329532146454, 1.6747288703918457]\n",
      "700 steps | score: [0.08738841861486435, 1.0823523998260498]\n",
      "800 steps | score: [1.0356954336166382, -5.299067974090576]\n",
      "900 steps | score: [0.05881091579794884, 0.15140914916992188]\n",
      "1000 steps | score: [-0.17421843111515045, 1.375916838645935]\n",
      "1100 steps | score: [0.1835302859544754, -0.9414515495300293]\n",
      "1200 steps | score: [0.16894347965717316, -0.7241792678833008]\n",
      "1300 steps | score: [0.2445676177740097, -1.4228816032409668]\n",
      "1400 steps | score: [-0.005572317633777857, 0.12909665703773499]\n",
      "1500 steps | score: [-0.2580115497112274, 1.6164069175720215]\n",
      "1600 steps | score: [0.2935495972633362, -1.5733031034469604]\n",
      "1700 steps | score: [-0.22235769033432007, 1.4851229190826416]\n",
      "1800 steps | score: [0.1692906618118286, -1.0368564128875732]\n",
      "1900 steps | score: [-0.21141855418682098, 1.1749420166015625]\n",
      "2000 steps | score: [-0.10387420654296875, 0.6507365703582764]\n",
      "2100 steps | score: [0.12999247014522552, -0.6594007015228271]\n",
      "2200 steps | score: [-0.09865371137857437, 0.5896434783935547]\n",
      "2300 steps | score: [0.08673687279224396, -0.5034173727035522]\n",
      "2400 steps | score: [-0.12275666743516922, 0.6586096286773682]\n",
      "2500 steps | score: [0.1264796108007431, -0.779760479927063]\n",
      "2600 steps | score: [0.023197107017040253, -0.04986441135406494]\n",
      "2700 steps | score: [0.07911007106304169, -0.351541668176651]\n",
      "2800 steps | score: [0.025577152147889137, -0.03693729639053345]\n",
      "2900 steps | score: [-0.05390964448451996, 0.2251354455947876]\n",
      "unknown params:  tensor([ 0.3597, -0.9138, -0.8087, -0.3438, -0.2469,  0.5870])\n",
      "gt params:  tensor([ 0.3708, -0.9543, -0.8473, -0.3539, -0.2556,  0.9037])\n",
      "ols params:  tensor([ 0.3461, -0.8789, -0.7798, -0.3286, -0.2372,  1.2636])\n",
      "unknown mse:  tensor(0.0173)\n",
      "ols mse:  tensor(0.0236)\n",
      "gt params:  tensor([ 0.3679, -0.9453, -0.8542, -0.3559, -0.2554,  0.8787])\n",
      "0 steps | score: [0.267598956823349]\n",
      "100 steps | score: [0.1852162480354309]\n",
      "200 steps | score: [0.2894664406776428]\n",
      "300 steps | score: [0.15377919375896454]\n",
      "400 steps | score: [0.11195944994688034]\n",
      "500 steps | score: [0.06468687951564789]\n",
      "600 steps | score: [0.16398370265960693]\n",
      "700 steps | score: [0.0848202258348465]\n",
      "800 steps | score: [0.15952356159687042]\n",
      "900 steps | score: [0.19491301476955414]\n",
      "1000 steps | score: [0.16199345886707306]\n",
      "1100 steps | score: [0.07002770900726318]\n",
      "1200 steps | score: [0.16465431451797485]\n",
      "1300 steps | score: [0.1475909948348999]\n",
      "1400 steps | score: [0.14708176255226135]\n",
      "1500 steps | score: [0.1500503122806549]\n",
      "1600 steps | score: [0.1440865695476532]\n",
      "1700 steps | score: [0.13056308031082153]\n",
      "1800 steps | score: [0.14963823556900024]\n",
      "1900 steps | score: [0.12601283192634583]\n",
      "2000 steps | score: [0.16112329065799713]\n",
      "2100 steps | score: [0.13112053275108337]\n",
      "2200 steps | score: [0.19652241468429565]\n",
      "2300 steps | score: [0.12926137447357178]\n",
      "2400 steps | score: [0.1428738236427307]\n",
      "2500 steps | score: [0.1264013946056366]\n",
      "2600 steps | score: [0.15489442646503448]\n",
      "2700 steps | score: [0.1407785266637802]\n",
      "2800 steps | score: [0.142010897397995]\n",
      "2900 steps | score: [0.13056789338588715]\n",
      "0 steps | score: [0.31065598130226135, -0.7176947593688965]\n",
      "100 steps | score: [0.9620710611343384, -3.7744948863983154]\n",
      "200 steps | score: [0.23013588786125183, -0.5235307216644287]\n",
      "300 steps | score: [0.1944803148508072, -0.4919511079788208]\n",
      "400 steps | score: [0.3500320017337799, -1.1759955883026123]\n",
      "500 steps | score: [0.8948147296905518, -3.705247402191162]\n",
      "600 steps | score: [-0.03846125677227974, 0.282772421836853]\n",
      "700 steps | score: [0.12507475912570953, -0.3372787833213806]\n",
      "800 steps | score: [0.2636767029762268, -0.8306378126144409]\n",
      "900 steps | score: [0.17158342897891998, -0.46278607845306396]\n",
      "1000 steps | score: [0.13355708122253418, -0.38465407490730286]\n",
      "1100 steps | score: [-0.002161596901714802, 0.11031374335289001]\n",
      "1200 steps | score: [0.5854087471961975, -2.191488265991211]\n",
      "1300 steps | score: [0.2474697083234787, -0.7998567223548889]\n",
      "1400 steps | score: [0.16146323084831238, -0.45176681876182556]\n",
      "1500 steps | score: [0.1395970582962036, -0.39902782440185547]\n",
      "1600 steps | score: [0.12936419248580933, -0.34887009859085083]\n",
      "1700 steps | score: [0.05445469915866852, -0.0764390379190445]\n",
      "1800 steps | score: [0.33814549446105957, -1.1377074718475342]\n",
      "1900 steps | score: [0.2048589587211609, -0.6131632328033447]\n",
      "2000 steps | score: [0.15327464044094086, -0.44066905975341797]\n",
      "2100 steps | score: [0.15583911538124084, -0.444871187210083]\n",
      "2200 steps | score: [0.26425641775131226, -0.8661820292472839]\n",
      "2300 steps | score: [0.12467987090349197, -0.3425180912017822]\n",
      "2400 steps | score: [0.11177146434783936, -0.3205892741680145]\n",
      "2500 steps | score: [0.05933894217014313, -0.09175869822502136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600 steps | score: [0.35396480560302734, -1.2135939598083496]\n",
      "2700 steps | score: [0.17184360325336456, -0.5147801637649536]\n",
      "2800 steps | score: [0.15140271186828613, -0.46477019786834717]\n",
      "2900 steps | score: [0.12025579810142517, -0.3153214454650879]\n",
      "unknown params:  tensor([ 0.3519, -0.9216, -0.8317, -0.3428, -0.2531,  0.8229])\n",
      "gt params:  tensor([ 0.3679, -0.9453, -0.8542, -0.3559, -0.2554,  0.8787])\n",
      "ols params:  tensor([ 0.3108, -0.8076, -0.7332, -0.3042, -0.2223,  1.5508])\n",
      "unknown mse:  tensor(0.0008)\n",
      "ols mse:  tensor(0.0821)\n",
      "gt params:  tensor([ 0.3641, -0.9570, -0.8383, -0.3453, -0.2624,  0.8912])\n",
      "0 steps | score: [-0.041252851486206055]\n",
      "100 steps | score: [-0.08736367523670197]\n",
      "200 steps | score: [-0.15821006894111633]\n",
      "300 steps | score: [-0.09917061030864716]\n",
      "400 steps | score: [-0.08011315762996674]\n",
      "500 steps | score: [-0.2436819076538086]\n",
      "600 steps | score: [-0.14248962700366974]\n",
      "700 steps | score: [-0.20549775660037994]\n",
      "800 steps | score: [-0.13427141308784485]\n",
      "900 steps | score: [-0.1305314153432846]\n",
      "1000 steps | score: [-0.1529037058353424]\n",
      "1100 steps | score: [-0.193756103515625]\n",
      "1200 steps | score: [-0.12937471270561218]\n",
      "1300 steps | score: [-0.15569724142551422]\n",
      "1400 steps | score: [-0.15636160969734192]\n",
      "1500 steps | score: [-0.12880979478359222]\n",
      "1600 steps | score: [-0.16646230220794678]\n",
      "1700 steps | score: [-0.14839237928390503]\n",
      "1800 steps | score: [-0.1469145566225052]\n",
      "1900 steps | score: [-0.15637730062007904]\n",
      "2000 steps | score: [-0.15870869159698486]\n",
      "2100 steps | score: [-0.14772778749465942]\n",
      "2200 steps | score: [-0.10921791195869446]\n",
      "2300 steps | score: [-0.1539161205291748]\n",
      "2400 steps | score: [-0.14767691493034363]\n",
      "2500 steps | score: [-0.16693565249443054]\n",
      "2600 steps | score: [-0.16082270443439484]\n",
      "2700 steps | score: [-0.1467207372188568]\n",
      "2800 steps | score: [-0.15607285499572754]\n",
      "2900 steps | score: [-0.15929503738880157]\n",
      "0 steps | score: [0.05594700947403908, 0.39437001943588257]\n",
      "100 steps | score: [-0.24841071665287018, 1.233657717704773]\n",
      "200 steps | score: [-0.039897069334983826, 0.3661939203739166]\n",
      "300 steps | score: [-0.26972439885139465, 1.0931737422943115]\n",
      "400 steps | score: [0.05467706173658371, 0.06140941381454468]\n",
      "500 steps | score: [-0.39145427942276, 1.5498491525650024]\n",
      "600 steps | score: [0.059202149510383606, 0.004520684480667114]\n",
      "700 steps | score: [-0.048471901565790176, 0.3784545063972473]\n",
      "800 steps | score: [0.01268805842846632, 0.1369991898536682]\n",
      "900 steps | score: [-0.06811030954122543, 0.35936498641967773]\n",
      "1000 steps | score: [-0.05302523449063301, 0.35366547107696533]\n",
      "1100 steps | score: [-0.11949930340051651, 0.6459686756134033]\n",
      "1200 steps | score: [0.03804590180516243, 0.1299457848072052]\n",
      "1300 steps | score: [-0.06693780422210693, 0.482840895652771]\n",
      "1400 steps | score: [-0.09097295254468918, 0.49638986587524414]\n",
      "1500 steps | score: [-0.03191492334008217, 0.30153197050094604]\n",
      "1600 steps | score: [-0.12033748626708984, 0.6126366853713989]\n",
      "1700 steps | score: [-0.2237597405910492, 0.9217201471328735]\n",
      "1800 steps | score: [-0.0673331767320633, 0.45433753728866577]\n",
      "1900 steps | score: [-0.029800590127706528, 0.35654181241989136]\n",
      "2000 steps | score: [-0.16515667736530304, 0.7411525845527649]\n",
      "2100 steps | score: [-0.18130764365196228, 0.8109347820281982]\n",
      "2200 steps | score: [-0.08033707737922668, 0.45403754711151123]\n",
      "2300 steps | score: [-0.12260880321264267, 0.611962080001831]\n",
      "2400 steps | score: [-0.10151368379592896, 0.5871328115463257]\n",
      "2500 steps | score: [-0.2088857740163803, 0.9221032857894897]\n",
      "2600 steps | score: [-0.14751282334327698, 0.6724504232406616]\n",
      "2700 steps | score: [-0.12158545106649399, 0.55662602186203]\n",
      "2800 steps | score: [-0.1271519809961319, 0.6529273390769958]\n",
      "2900 steps | score: [-0.17660820484161377, 0.7921603918075562]\n",
      "unknown params:  tensor([ 0.3610, -0.9388, -0.8459, -0.3219, -0.2617,  0.7972])\n",
      "gt params:  tensor([ 0.3641, -0.9570, -0.8383, -0.3453, -0.2624,  0.8912])\n",
      "ols params:  tensor([ 0.2983, -0.7614, -0.6889, -0.2693, -0.2127,  1.8266])\n",
      "unknown mse:  tensor(0.0016)\n",
      "ols mse:  tensor(0.1580)\n",
      "gt params:  tensor([ 0.3680, -0.9453, -0.8361, -0.3542, -0.2547,  0.8719])\n",
      "0 steps | score: [0.3419508934020996]\n",
      "100 steps | score: [0.23276133835315704]\n",
      "200 steps | score: [0.144950270652771]\n",
      "300 steps | score: [0.2233726680278778]\n",
      "400 steps | score: [0.20110271871089935]\n",
      "500 steps | score: [0.14768661558628082]\n",
      "600 steps | score: [0.06769644469022751]\n",
      "700 steps | score: [0.23272013664245605]\n",
      "800 steps | score: [0.1805824339389801]\n",
      "900 steps | score: [0.1352178156375885]\n",
      "1000 steps | score: [0.18918298184871674]\n",
      "1100 steps | score: [0.1637372076511383]\n",
      "1200 steps | score: [0.1630692332983017]\n",
      "1300 steps | score: [0.21418067812919617]\n",
      "1400 steps | score: [0.22443294525146484]\n",
      "1500 steps | score: [0.17571456730365753]\n",
      "1600 steps | score: [0.17816200852394104]\n",
      "1700 steps | score: [0.1736695021390915]\n",
      "1800 steps | score: [0.1544652134180069]\n",
      "1900 steps | score: [0.1978209763765335]\n",
      "2000 steps | score: [0.19263477623462677]\n",
      "2100 steps | score: [0.17216873168945312]\n",
      "2200 steps | score: [0.1884659230709076]\n",
      "2300 steps | score: [0.15484553575515747]\n",
      "2400 steps | score: [0.17682456970214844]\n",
      "2500 steps | score: [0.17057611048221588]\n",
      "2600 steps | score: [0.18759596347808838]\n",
      "2700 steps | score: [0.17943239212036133]\n",
      "2800 steps | score: [0.16868607699871063]\n",
      "0 steps | score: [0.2727254033088684, -0.44392263889312744]\n",
      "100 steps | score: [1.210023045539856, -4.610278129577637]\n",
      "200 steps | score: [-0.13148550689220428, 0.45787137746810913]\n",
      "300 steps | score: [0.6117469668388367, -2.1995270252227783]\n",
      "400 steps | score: [0.2679164707660675, -0.8919386863708496]\n",
      "500 steps | score: [-0.07238642871379852, 0.18747524917125702]\n",
      "600 steps | score: [-0.21688221395015717, 0.6639755964279175]\n",
      "700 steps | score: [0.5798449516296387, -2.1001999378204346]\n",
      "800 steps | score: [0.1429005116224289, -0.5174596309661865]\n",
      "900 steps | score: [-0.23119087517261505, 0.7164222002029419]\n",
      "1000 steps | score: [0.12746213376522064, -0.33726778626441956]\n",
      "1100 steps | score: [0.07174086570739746, -0.20169878005981445]\n",
      "1200 steps | score: [0.2217957079410553, -0.7249180674552917]\n",
      "1300 steps | score: [0.07836626470088959, -0.21590594947338104]\n",
      "1400 steps | score: [0.45004668831825256, -1.5491284132003784]\n",
      "1500 steps | score: [0.14874018728733063, -0.4880428910255432]\n",
      "1600 steps | score: [0.0015218077460303903, 0.002374514937400818]\n",
      "unknown params:  tensor([ 0.3535, -0.8900, -0.8049, -0.3341, -0.2251,  0.7139])\n",
      "gt params:  tensor([ 0.3680, -0.9453, -0.8361, -0.3542, -0.2547,  0.8719])\n",
      "ols params:  tensor([ 0.2889, -0.7192, -0.6523, -0.2794, -0.1885,  2.0500])\n",
      "unknown mse:  tensor(0.0051)\n",
      "ols mse:  tensor(0.2482)\n",
      "gt params:  tensor([ 0.3826, -0.9534, -0.8490, -0.3521, -0.2716,  0.8613])\n",
      "0 steps | score: [0.2272077202796936]\n",
      "100 steps | score: [0.10951121151447296]\n",
      "200 steps | score: [0.13097506761550903]\n",
      "300 steps | score: [0.08025848865509033]\n",
      "400 steps | score: [0.10394798219203949]\n",
      "500 steps | score: [0.08438175171613693]\n",
      "600 steps | score: [0.14780016243457794]\n",
      "700 steps | score: [0.1670244038105011]\n",
      "800 steps | score: [0.13921129703521729]\n",
      "900 steps | score: [0.12378419935703278]\n",
      "1000 steps | score: [0.12258961796760559]\n",
      "1100 steps | score: [0.055533044040203094]\n",
      "1200 steps | score: [0.021409183740615845]\n",
      "1300 steps | score: [0.11234232038259506]\n",
      "1400 steps | score: [0.1652798354625702]\n",
      "1500 steps | score: [0.1124214380979538]\n",
      "1600 steps | score: [0.09670073539018631]\n",
      "1700 steps | score: [0.08362976461648941]\n",
      "1800 steps | score: [0.07724165916442871]\n",
      "1900 steps | score: [0.13414227962493896]\n",
      "2000 steps | score: [0.10896150022745132]\n",
      "2100 steps | score: [0.09991125762462616]\n",
      "2200 steps | score: [0.10259051620960236]\n",
      "2300 steps | score: [0.09031780809164047]\n",
      "2400 steps | score: [0.10510386526584625]\n",
      "2500 steps | score: [0.11788623034954071]\n",
      "2600 steps | score: [0.11996340751647949]\n",
      "2700 steps | score: [0.09033475071191788]\n",
      "2800 steps | score: [0.09726666659116745]\n",
      "0 steps | score: [0.06068442761898041, 0.32126951217651367]\n",
      "100 steps | score: [0.07903671264648438, -0.0410584956407547]\n",
      "200 steps | score: [-0.2153373658657074, 0.7841751575469971]\n",
      "300 steps | score: [0.5393895506858826, -1.8178821802139282]\n",
      "400 steps | score: [-0.2837473452091217, 0.9577550292015076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [0.02042882889509201, 0.02706051990389824]\n",
      "600 steps | score: [0.042612314224243164, -0.061421655118465424]\n",
      "700 steps | score: [0.09852784126996994, -0.2161639928817749]\n",
      "800 steps | score: [0.013607613742351532, 0.06445393711328506]\n",
      "900 steps | score: [-0.014058605767786503, 0.12204986810684204]\n",
      "1000 steps | score: [-0.09620563685894012, 0.3628784120082855]\n",
      "1100 steps | score: [-0.18161873519420624, 0.6316624879837036]\n",
      "1200 steps | score: [-0.2382180392742157, 0.8311804533004761]\n",
      "1300 steps | score: [0.05365385115146637, -0.08250802755355835]\n",
      "1400 steps | score: [-0.141095370054245, 0.5267990231513977]\n",
      "1500 steps | score: [-0.0793643370270729, 0.3033979833126068]\n",
      "1600 steps | score: [-0.08021795004606247, 0.3358727693557739]\n",
      "1700 steps | score: [-0.0981430932879448, 0.4167949855327606]\n",
      "1800 steps | score: [-0.05912266671657562, 0.2329750955104828]\n",
      "1900 steps | score: [0.004110986366868019, 0.06298963725566864]\n",
      "2000 steps | score: [-0.17035126686096191, 0.607864260673523]\n",
      "2100 steps | score: [-0.07530993223190308, 0.28984126448631287]\n",
      "2200 steps | score: [-0.06266666203737259, 0.26553770899772644]\n",
      "2300 steps | score: [-0.035919614136219025, 0.19645646214485168]\n",
      "2400 steps | score: [-0.04488586261868477, 0.18710657954216003]\n",
      "2500 steps | score: [-0.07026857882738113, 0.2925190031528473]\n",
      "2600 steps | score: [-0.10935875028371811, 0.44461649656295776]\n",
      "2700 steps | score: [-0.08213962614536285, 0.36218881607055664]\n",
      "2800 steps | score: [-0.17085155844688416, 0.5878919363021851]\n",
      "unknown params:  tensor([ 0.3688, -0.9041, -0.8131, -0.3352, -0.2388,  0.7357])\n",
      "gt params:  tensor([ 0.3826, -0.9534, -0.8490, -0.3521, -0.2716,  0.8613])\n",
      "ols params:  tensor([ 0.2857, -0.6921, -0.6266, -0.2615, -0.1887,  2.2581])\n",
      "unknown mse:  tensor(0.0035)\n",
      "ols mse:  tensor(0.3489)\n",
      "gt params:  tensor([ 0.3608, -0.9562, -0.8522, -0.3353, -0.2578,  0.8609])\n",
      "0 steps | score: [0.15497353672981262]\n",
      "100 steps | score: [0.008701208978891373]\n",
      "0 steps | score: [-0.050572123378515244, 0.32925543189048767]\n",
      "100 steps | score: [-0.28239336609840393, 0.7820541858673096]\n",
      "200 steps | score: [-0.17855702340602875, 0.5033723711967468]\n",
      "300 steps | score: [-0.26983585953712463, 0.7564449906349182]\n",
      "400 steps | score: [-0.33624202013015747, 0.857159435749054]\n",
      "500 steps | score: [0.2626943290233612, -1.1167289018630981]\n",
      "600 steps | score: [-0.339388370513916, 0.8875657320022583]\n",
      "700 steps | score: [0.009623738937079906, -0.24937494099140167]\n",
      "800 steps | score: [-0.19809219241142273, 0.48221588134765625]\n",
      "900 steps | score: [0.3103084862232208, -1.3293741941452026]\n",
      "1000 steps | score: [-0.07089913636445999, 0.010072775185108185]\n",
      "1100 steps | score: [-0.08751565963029861, 0.07675090432167053]\n",
      "1200 steps | score: [-0.10268543660640717, 0.15156207978725433]\n",
      "1300 steps | score: [-0.220758855342865, 0.556649386882782]\n",
      "1400 steps | score: [-0.30478382110595703, 0.7646778225898743]\n",
      "1500 steps | score: [0.09950617700815201, -0.5085102319717407]\n",
      "1600 steps | score: [-0.31467878818511963, 0.8259252905845642]\n",
      "1700 steps | score: [-0.2241031378507614, 0.5438937544822693]\n",
      "1800 steps | score: [-0.2171775996685028, 0.4958544671535492]\n",
      "1900 steps | score: [-0.3057210147380829, 0.7953420281410217]\n",
      "2000 steps | score: [-0.28531837463378906, 0.730583131313324]\n",
      "2100 steps | score: [-0.19312883913516998, 0.37728267908096313]\n",
      "2200 steps | score: [-0.22350133955478668, 0.5221202373504639]\n",
      "2300 steps | score: [-0.14055398106575012, 0.2260620892047882]\n",
      "2400 steps | score: [-0.0921483039855957, 0.0736386775970459]\n",
      "2500 steps | score: [-0.07855678349733353, 0.06272636353969574]\n",
      "2600 steps | score: [-0.12060455232858658, 0.18934117257595062]\n",
      "2700 steps | score: [-0.15311299264431, 0.2909044325351715]\n",
      "2800 steps | score: [-0.2057638019323349, 0.46628060936927795]\n",
      "unknown params:  tensor([ 0.3632, -0.9587, -0.8343, -0.3281, -0.2579,  0.7392])\n",
      "gt params:  tensor([ 0.3608, -0.9562, -0.8522, -0.3353, -0.2578,  0.8609])\n",
      "ols params:  tensor([ 0.2630, -0.6732, -0.5926, -0.2377, -0.1825,  2.4309])\n",
      "unknown mse:  tensor(0.0025)\n",
      "ols mse:  tensor(0.4395)\n",
      "gt params:  tensor([ 0.3721, -0.9490, -0.8308, -0.3563, -0.2561,  0.9014])\n",
      "0 steps | score: [0.2773841917514801]\n",
      "100 steps | score: [0.23429518938064575]\n",
      "200 steps | score: [0.1963549703359604]\n",
      "300 steps | score: [0.06533418595790863]\n",
      "400 steps | score: [0.1288025826215744]\n",
      "500 steps | score: [0.1611892580986023]\n",
      "600 steps | score: [0.10613113641738892]\n",
      "700 steps | score: [0.20601552724838257]\n",
      "800 steps | score: [0.1587996929883957]\n",
      "900 steps | score: [0.09633413702249527]\n",
      "1000 steps | score: [0.13683384656906128]\n",
      "1100 steps | score: [0.10621073842048645]\n",
      "1200 steps | score: [0.18035410344600677]\n",
      "1300 steps | score: [0.16918355226516724]\n",
      "1400 steps | score: [0.1498102843761444]\n",
      "1500 steps | score: [0.09107045829296112]\n",
      "1600 steps | score: [0.12365596741437912]\n",
      "1700 steps | score: [0.08763077110052109]\n",
      "1800 steps | score: [0.1379588395357132]\n",
      "1900 steps | score: [0.1426248699426651]\n",
      "2000 steps | score: [0.17960041761398315]\n",
      "2100 steps | score: [0.11592386662960052]\n",
      "2200 steps | score: [0.15102913975715637]\n",
      "2300 steps | score: [0.12265220284461975]\n",
      "2400 steps | score: [0.17018625140190125]\n",
      "2500 steps | score: [0.14590588212013245]\n",
      "2600 steps | score: [0.15603558719158173]\n",
      "2700 steps | score: [0.13458342850208282]\n",
      "2800 steps | score: [0.15718434751033783]\n",
      "0 steps | score: [0.5532658100128174, -1.3195717334747314]\n",
      "100 steps | score: [0.6051068902015686, -1.6459707021713257]\n",
      "200 steps | score: [0.7180980443954468, -2.2324185371398926]\n",
      "300 steps | score: [0.11983926594257355, -0.4474363327026367]\n",
      "400 steps | score: [0.3508652150630951, -1.0508558750152588]\n",
      "500 steps | score: [0.45834168791770935, -1.3767311573028564]\n",
      "600 steps | score: [0.6446597576141357, -1.93886137008667]\n",
      "700 steps | score: [0.4521794021129608, -1.3696154356002808]\n",
      "800 steps | score: [0.3604279160499573, -1.0963280200958252]\n",
      "900 steps | score: [0.3713386654853821, -1.1156052350997925]\n",
      "1000 steps | score: [0.41771483421325684, -1.2461674213409424]\n",
      "1100 steps | score: [0.33126285672187805, -1.0446231365203857]\n",
      "1200 steps | score: [0.4890162944793701, -1.4913638830184937]\n",
      "1300 steps | score: [0.26634302735328674, -0.8851265907287598]\n",
      "1400 steps | score: [0.27546021342277527, -0.8580352067947388]\n",
      "1500 steps | score: [0.3178112208843231, -0.9462733864784241]\n",
      "1600 steps | score: [0.30394917726516724, -0.9558996558189392]\n",
      "1700 steps | score: [0.30024412274360657, -0.9580315351486206]\n",
      "1800 steps | score: [0.3222063481807709, -0.9834327697753906]\n",
      "1900 steps | score: [0.4025765657424927, -1.2458770275115967]\n",
      "2000 steps | score: [0.40408340096473694, -1.2325705289840698]\n",
      "2100 steps | score: [0.28672564029693604, -0.9231096506118774]\n",
      "2200 steps | score: [0.4557175934314728, -1.3400309085845947]\n",
      "2300 steps | score: [0.3657350540161133, -1.1221351623535156]\n",
      "2400 steps | score: [0.4888617992401123, -1.4861459732055664]\n",
      "2500 steps | score: [0.5266168713569641, -1.5812280178070068]\n",
      "2600 steps | score: [0.35093843936920166, -1.095107078552246]\n",
      "2700 steps | score: [0.37531778216362, -1.139089584350586]\n",
      "2800 steps | score: [0.41370993852615356, -1.2818522453308105]\n",
      "unknown params:  tensor([ 0.3931, -0.9495, -0.8393, -0.3807, -0.2400,  0.6320])\n",
      "gt params:  tensor([ 0.3721, -0.9490, -0.8308, -0.3563, -0.2561,  0.9014])\n",
      "ols params:  tensor([ 0.2710, -0.6434, -0.5729, -0.2585, -0.1664,  2.5916])\n",
      "unknown mse:  tensor(0.0123)\n",
      "ols mse:  tensor(0.5074)\n",
      "gt params:  tensor([ 0.3826, -0.9567, -0.8501, -0.3602, -0.2341,  0.8417])\n",
      "0 steps | score: [0.2587381899356842]\n",
      "100 steps | score: [0.08862970769405365]\n",
      "200 steps | score: [0.1209062933921814]\n",
      "300 steps | score: [0.13474556803703308]\n",
      "400 steps | score: [0.05815583094954491]\n",
      "500 steps | score: [0.1007690578699112]\n",
      "600 steps | score: [0.06245357543230057]\n",
      "700 steps | score: [0.053265757858753204]\n",
      "800 steps | score: [0.055037930607795715]\n",
      "900 steps | score: [0.045712534338235855]\n",
      "1000 steps | score: [0.05883779004216194]\n",
      "1100 steps | score: [0.053047582507133484]\n",
      "1200 steps | score: [0.0539737306535244]\n",
      "1300 steps | score: [0.07259222120046616]\n",
      "1400 steps | score: [0.03880257532000542]\n",
      "1500 steps | score: [0.04879394546151161]\n",
      "1600 steps | score: [0.05648764967918396]\n",
      "1700 steps | score: [0.023654699325561523]\n",
      "1800 steps | score: [0.06721682846546173]\n",
      "1900 steps | score: [0.052462298423051834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 steps | score: [0.0774160623550415]\n",
      "2100 steps | score: [0.056134894490242004]\n",
      "2200 steps | score: [0.08356457948684692]\n",
      "2300 steps | score: [0.04832936078310013]\n",
      "2400 steps | score: [0.058409638702869415]\n",
      "2500 steps | score: [0.06084524840116501]\n",
      "2600 steps | score: [0.06893083453178406]\n",
      "2700 steps | score: [0.05956359952688217]\n",
      "2800 steps | score: [0.05270535871386528]\n",
      "0 steps | score: [0.3096820116043091, -0.4538673460483551]\n",
      "100 steps | score: [0.21500559151172638, -0.4141405522823334]\n",
      "200 steps | score: [0.3542318642139435, -0.814397931098938]\n",
      "300 steps | score: [0.15825340151786804, -0.32620367407798767]\n",
      "400 steps | score: [0.11180140823125839, -0.265521377325058]\n",
      "500 steps | score: [0.3801238536834717, -0.9946126341819763]\n",
      "600 steps | score: [0.03286585584282875, -0.05875026434659958]\n",
      "700 steps | score: [0.19370147585868835, -0.409892201423645]\n",
      "800 steps | score: [0.2414054572582245, -0.5617004632949829]\n",
      "900 steps | score: [0.021208366379141808, 0.011044614017009735]\n",
      "1000 steps | score: [-0.044426124542951584, 0.14886750280857086]\n",
      "1100 steps | score: [0.23329848051071167, -0.5963696241378784]\n",
      "1200 steps | score: [0.07194240391254425, -0.14476332068443298]\n",
      "1300 steps | score: [0.14415916800498962, -0.3128238618373871]\n",
      "1400 steps | score: [0.32155483961105347, -0.8454629778862]\n",
      "1500 steps | score: [0.12473661452531815, -0.27577006816864014]\n",
      "1600 steps | score: [0.24389635026454926, -0.6096311807632446]\n",
      "1700 steps | score: [0.061427321285009384, -0.13516846299171448]\n",
      "1800 steps | score: [0.21916981041431427, -0.5495898127555847]\n",
      "1900 steps | score: [0.1741521656513214, -0.40004637837409973]\n",
      "2000 steps | score: [0.20669551193714142, -0.4734742343425751]\n",
      "2100 steps | score: [0.14827550947666168, -0.3508012890815735]\n",
      "2200 steps | score: [0.1960013061761856, -0.5092483162879944]\n",
      "2300 steps | score: [0.13800737261772156, -0.31875336170196533]\n",
      "2400 steps | score: [0.1839582771062851, -0.4673301577568054]\n",
      "2500 steps | score: [0.11935100704431534, -0.26842200756073]\n",
      "2600 steps | score: [0.14714586734771729, -0.31990790367126465]\n",
      "2700 steps | score: [0.15258151292800903, -0.3513246774673462]\n",
      "2800 steps | score: [0.14234983921051025, -0.36760833859443665]\n",
      "unknown params:  tensor([ 0.3723, -0.9140, -0.8154, -0.3478, -0.2241,  0.6350])\n",
      "gt params:  tensor([ 0.3826, -0.9567, -0.8501, -0.3602, -0.2341,  0.8417])\n",
      "ols params:  tensor([ 0.2614, -0.6186, -0.5599, -0.2390, -0.1529,  2.7591])\n",
      "unknown mse:  tensor(0.0077)\n",
      "ols mse:  tensor(0.6518)\n",
      "gt params:  tensor([ 0.3707, -0.9377, -0.8516, -0.3556, -0.2469,  0.8991])\n",
      "0 steps | score: [0.2930043637752533]\n",
      "100 steps | score: [0.012581922113895416]\n",
      "200 steps | score: [0.056596539914608]\n",
      "300 steps | score: [0.07263871282339096]\n",
      "400 steps | score: [0.07710789144039154]\n",
      "500 steps | score: [0.07460236549377441]\n",
      "600 steps | score: [0.01445680484175682]\n",
      "700 steps | score: [0.047058988362550735]\n",
      "800 steps | score: [0.0480564720928669]\n",
      "900 steps | score: [0.06451457738876343]\n",
      "1000 steps | score: [0.11083340644836426]\n",
      "1100 steps | score: [0.03347852826118469]\n",
      "1200 steps | score: [0.02676204964518547]\n",
      "1300 steps | score: [0.018993549048900604]\n",
      "1400 steps | score: [0.05234041437506676]\n",
      "1500 steps | score: [0.028188295662403107]\n",
      "1600 steps | score: [0.06244432553648949]\n",
      "1700 steps | score: [0.03678396716713905]\n",
      "1800 steps | score: [0.02989659458398819]\n",
      "1900 steps | score: [0.00547279417514801]\n",
      "0 steps | score: [0.37056952714920044, -0.6441763043403625]\n",
      "100 steps | score: [0.030960440635681152, -0.01514427363872528]\n",
      "200 steps | score: [-0.027967261150479317, 0.036744892597198486]\n",
      "300 steps | score: [0.11986398696899414, -0.2847144901752472]\n",
      "400 steps | score: [0.2587721347808838, -0.7316596508026123]\n",
      "500 steps | score: [0.30429258942604065, -0.7678016424179077]\n",
      "600 steps | score: [0.2116970717906952, -0.555557131767273]\n",
      "700 steps | score: [0.4222548007965088, -1.1476081609725952]\n",
      "800 steps | score: [0.10051608085632324, -0.3020540177822113]\n",
      "900 steps | score: [0.2102934867143631, -0.5480233430862427]\n",
      "1000 steps | score: [0.2383459508419037, -0.6882306933403015]\n",
      "1100 steps | score: [0.2525210678577423, -0.6900882720947266]\n",
      "1200 steps | score: [0.2521858811378479, -0.6523734331130981]\n",
      "1300 steps | score: [0.29060718417167664, -0.8130263090133667]\n",
      "1400 steps | score: [0.26975274085998535, -0.7820227146148682]\n",
      "1500 steps | score: [0.11900285631418228, -0.3303213119506836]\n",
      "1600 steps | score: [0.2602181136608124, -0.7018709182739258]\n",
      "1700 steps | score: [0.17056025564670563, -0.4749215841293335]\n",
      "1800 steps | score: [0.17374329268932343, -0.4636472165584564]\n",
      "1900 steps | score: [0.26766717433929443, -0.7449215650558472]\n",
      "2000 steps | score: [0.1637147068977356, -0.4249458611011505]\n",
      "2100 steps | score: [0.23471307754516602, -0.6392653584480286]\n",
      "2200 steps | score: [0.3015258014202118, -0.8356106877326965]\n",
      "2300 steps | score: [0.13545802235603333, -0.3751070201396942]\n",
      "2400 steps | score: [0.16057339310646057, -0.40293800830841064]\n",
      "2500 steps | score: [0.2195121794939041, -0.57439786195755]\n",
      "2600 steps | score: [0.240544393658638, -0.6299464106559753]\n",
      "2700 steps | score: [0.2893452048301697, -0.7791139483451843]\n",
      "2800 steps | score: [0.1757235825061798, -0.4710918068885803]\n",
      "unknown params:  tensor([ 0.3852, -0.8787, -0.8257, -0.3237, -0.2565,  0.5332])\n",
      "gt params:  tensor([ 0.3707, -0.9377, -0.8516, -0.3556, -0.2469,  0.8991])\n",
      "ols params:  tensor([ 0.2684, -0.5943, -0.5630, -0.2277, -0.1735,  2.8589])\n",
      "unknown mse:  tensor(0.0232)\n",
      "ols mse:  tensor(0.6790)\n",
      "gt params:  tensor([ 0.3743, -0.9573, -0.8685, -0.3487, -0.2784,  0.9164])\n",
      "0 steps | score: [-0.034676648676395416]\n",
      "100 steps | score: [-0.33406132459640503]\n",
      "200 steps | score: [-0.31465333700180054]\n",
      "300 steps | score: [-0.1962805837392807]\n",
      "400 steps | score: [-0.26783326268196106]\n",
      "500 steps | score: [-0.2447710484266281]\n",
      "600 steps | score: [-0.1671639084815979]\n",
      "700 steps | score: [-0.30297666788101196]\n",
      "800 steps | score: [-0.2594584822654724]\n",
      "900 steps | score: [-0.20477834343910217]\n",
      "1000 steps | score: [-0.22701680660247803]\n",
      "1100 steps | score: [-0.18759196996688843]\n",
      "1200 steps | score: [-0.19188737869262695]\n",
      "1300 steps | score: [-0.2528861165046692]\n",
      "1400 steps | score: [-0.2304876148700714]\n",
      "1500 steps | score: [-0.2015206664800644]\n",
      "1600 steps | score: [-0.20489029586315155]\n",
      "1700 steps | score: [-0.20059749484062195]\n",
      "1800 steps | score: [-0.2526489496231079]\n",
      "1900 steps | score: [-0.241263747215271]\n",
      "2000 steps | score: [-0.20940335094928741]\n",
      "2100 steps | score: [-0.20242446660995483]\n",
      "2200 steps | score: [-0.21670663356781006]\n",
      "2300 steps | score: [-0.1937953233718872]\n",
      "2400 steps | score: [-0.2285652458667755]\n",
      "2500 steps | score: [-0.23142214119434357]\n",
      "2600 steps | score: [-0.19871604442596436]\n",
      "2700 steps | score: [-0.20240575075149536]\n",
      "2800 steps | score: [-0.19157621264457703]\n",
      "0 steps | score: [0.3007243573665619, -0.2171539068222046]\n",
      "100 steps | score: [-0.012057287618517876, 0.30744603276252747]\n",
      "200 steps | score: [-0.062452901154756546, 0.3920079171657562]\n",
      "300 steps | score: [-0.026190297678112984, 0.3377871811389923]\n",
      "400 steps | score: [0.0964934378862381, 0.08486513048410416]\n",
      "500 steps | score: [0.023883139714598656, 0.19908979535102844]\n",
      "600 steps | score: [0.38113582134246826, -0.7379759550094604]\n",
      "700 steps | score: [0.04816380515694618, 0.1199953556060791]\n",
      "800 steps | score: [-0.059689342975616455, 0.3715724050998688]\n",
      "900 steps | score: [-0.0924651101231575, 0.4538898468017578]\n",
      "1000 steps | score: [0.17331182956695557, -0.1591433584690094]\n",
      "1100 steps | score: [0.03677601367235184, 0.15619361400604248]\n",
      "1200 steps | score: [0.14390502870082855, -0.12823858857154846]\n",
      "1300 steps | score: [0.16210250556468964, -0.13811010122299194]\n",
      "1400 steps | score: [-0.0078889150172472, 0.2620943486690521]\n",
      "1500 steps | score: [0.02425551973283291, 0.1850559115409851]\n",
      "1600 steps | score: [0.17079783976078033, -0.1645704209804535]\n",
      "1700 steps | score: [0.07682622224092484, 0.05939803272485733]\n",
      "1800 steps | score: [-0.0589921735227108, 0.3719051480293274]\n",
      "1900 steps | score: [-0.025873800739645958, 0.27343857288360596]\n",
      "2000 steps | score: [0.101993128657341, -0.0004721134901046753]\n",
      "2100 steps | score: [0.022434912621974945, 0.1931551694869995]\n",
      "2200 steps | score: [0.11799410730600357, -0.018756665289402008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300 steps | score: [0.11253729462623596, -0.037447527050971985]\n",
      "2400 steps | score: [0.052556972950696945, 0.1282755434513092]\n",
      "2500 steps | score: [0.0461583249270916, 0.11120344698429108]\n",
      "2600 steps | score: [0.1018899530172348, -0.015196353197097778]\n",
      "2700 steps | score: [0.088033027946949, 0.0338173508644104]\n",
      "2800 steps | score: [0.15528661012649536, -0.13522717356681824]\n",
      "unknown params:  tensor([ 0.3498, -0.9595, -0.8570, -0.3063, -0.2645,  0.7148])\n",
      "gt params:  tensor([ 0.3743, -0.9573, -0.8685, -0.3487, -0.2784,  0.9164])\n",
      "ols params:  tensor([ 0.2330, -0.6109, -0.5518, -0.2028, -0.1732,  3.0804])\n",
      "unknown mse:  tensor(0.0072)\n",
      "ols mse:  tensor(0.8259)\n",
      "gt params:  tensor([ 0.3750, -0.9432, -0.8584, -0.3499, -0.2632,  0.9004])\n",
      "0 steps | score: [0.30271658301353455]\n",
      "100 steps | score: [0.11207480728626251]\n",
      "200 steps | score: [0.0926964059472084]\n",
      "300 steps | score: [0.012127073481678963]\n",
      "400 steps | score: [0.07077477872371674]\n",
      "500 steps | score: [0.05357866361737251]\n",
      "600 steps | score: [0.07839769124984741]\n",
      "700 steps | score: [0.03785257041454315]\n",
      "800 steps | score: [0.12876121699810028]\n",
      "900 steps | score: [0.03777473047375679]\n",
      "1000 steps | score: [0.06651347130537033]\n",
      "1100 steps | score: [0.046951912343502045]\n",
      "1200 steps | score: [0.073819600045681]\n",
      "1300 steps | score: [0.032718226313591]\n",
      "1400 steps | score: [0.05711346119642258]\n",
      "1500 steps | score: [0.03965035080909729]\n",
      "1600 steps | score: [0.051044270396232605]\n",
      "1700 steps | score: [0.0543421171605587]\n",
      "1800 steps | score: [0.07877703756093979]\n",
      "1900 steps | score: [0.09495445340871811]\n",
      "2000 steps | score: [0.05506940186023712]\n",
      "2100 steps | score: [0.019458167254924774]\n",
      "2200 steps | score: [0.0339055210351944]\n",
      "2300 steps | score: [0.08329299837350845]\n",
      "2400 steps | score: [0.06719488650560379]\n",
      "2500 steps | score: [0.07541504502296448]\n",
      "2600 steps | score: [0.04819613695144653]\n",
      "2700 steps | score: [0.06943288445472717]\n",
      "2800 steps | score: [0.04197343811392784]\n",
      "0 steps | score: [0.24535015225410461, -0.236184760928154]\n",
      "100 steps | score: [0.012826242484152317, 0.14262402057647705]\n",
      "200 steps | score: [0.08232853561639786, -0.038445524871349335]\n",
      "300 steps | score: [0.02229466289281845, 0.0608629435300827]\n",
      "400 steps | score: [0.16494105756282806, -0.31132858991622925]\n",
      "500 steps | score: [0.07651994377374649, -0.09134149551391602]\n",
      "600 steps | score: [0.014514314942061901, 0.08011189103126526]\n",
      "700 steps | score: [-0.061109937727451324, 0.259443074464798]\n",
      "800 steps | score: [0.36535075306892395, -0.8481257557868958]\n",
      "900 steps | score: [0.2585609555244446, -0.6059836149215698]\n",
      "1000 steps | score: [0.10931531339883804, -0.21539676189422607]\n",
      "1100 steps | score: [0.2062089592218399, -0.40948355197906494]\n",
      "1200 steps | score: [0.06147771701216698, -0.10802158713340759]\n",
      "1300 steps | score: [-0.07234852015972137, 0.26326099038124084]\n",
      "1400 steps | score: [0.02324387989938259, 0.0679103434085846]\n",
      "1500 steps | score: [-0.0195212010294199, 0.14871874451637268]\n",
      "1600 steps | score: [0.09544315934181213, -0.20423009991645813]\n",
      "1700 steps | score: [0.054394837468862534, -0.05755297839641571]\n",
      "1800 steps | score: [0.04172033071517944, -0.017165519297122955]\n",
      "1900 steps | score: [0.1545318365097046, -0.28715720772743225]\n",
      "2000 steps | score: [0.06052200496196747, -0.07558690011501312]\n",
      "2100 steps | score: [0.03312986344099045, -0.024864330887794495]\n",
      "2200 steps | score: [0.0993666872382164, -0.17257072031497955]\n",
      "2300 steps | score: [0.20602577924728394, -0.4658367335796356]\n",
      "2400 steps | score: [0.1287068873643875, -0.2530265152454376]\n",
      "2500 steps | score: [0.04750138521194458, -0.025210581719875336]\n",
      "2600 steps | score: [0.012838124297559261, 0.054049886763095856]\n",
      "2700 steps | score: [0.11527755111455917, -0.22761397063732147]\n",
      "2800 steps | score: [0.13793572783470154, -0.2726411819458008]\n",
      "unknown params:  tensor([ 0.3630, -1.0020, -0.9226, -0.3761, -0.2783,  0.6730])\n",
      "gt params:  tensor([ 0.3750, -0.9432, -0.8584, -0.3499, -0.2632,  0.9004])\n",
      "ols params:  tensor([ 0.2203, -0.5684, -0.5244, -0.2242, -0.1588,  3.1807])\n",
      "unknown mse:  tensor(0.0101)\n",
      "ols mse:  tensor(0.9171)\n",
      "gt params:  tensor([ 0.3643, -0.9776, -0.8391, -0.3621, -0.2498,  0.9096])\n",
      "0 steps | score: [0.26906082034111023]\n",
      "100 steps | score: [0.14324995875358582]\n",
      "200 steps | score: [3.8790516555309296e-05]\n",
      "0 steps | score: [0.35881853103637695, -0.5333898067474365]\n",
      "100 steps | score: [0.6012625694274902, -1.4461333751678467]\n",
      "200 steps | score: [0.48186853528022766, -1.2191790342330933]\n",
      "300 steps | score: [0.2235838621854782, -0.4535536766052246]\n",
      "400 steps | score: [0.7257895469665527, -1.9555027484893799]\n",
      "500 steps | score: [0.03634525462985039, -0.05006417632102966]\n",
      "600 steps | score: [0.21370458602905273, -0.47459542751312256]\n",
      "700 steps | score: [0.13572712242603302, -0.28423187136650085]\n",
      "800 steps | score: [0.24614855647087097, -0.5413721203804016]\n",
      "900 steps | score: [0.3471316993236542, -0.8125542402267456]\n",
      "1000 steps | score: [0.09958280622959137, -0.18409141898155212]\n",
      "1100 steps | score: [0.4796314835548401, -1.233277678489685]\n",
      "1200 steps | score: [0.20591160655021667, -0.4523555040359497]\n",
      "1300 steps | score: [0.021799853071570396, -0.0036116987466812134]\n",
      "1400 steps | score: [0.20721358060836792, -0.4566960036754608]\n",
      "1500 steps | score: [0.17457737028598785, -0.35071176290512085]\n",
      "1600 steps | score: [0.18276531994342804, -0.34836870431900024]\n",
      "1700 steps | score: [0.201186403632164, -0.4249535799026489]\n",
      "1800 steps | score: [0.27761080861091614, -0.6776326894760132]\n",
      "1900 steps | score: [0.08971492201089859, -0.17795763909816742]\n",
      "2000 steps | score: [0.20249344408512115, -0.4420432150363922]\n",
      "2100 steps | score: [0.24925531446933746, -0.5788376331329346]\n",
      "2200 steps | score: [0.25857964158058167, -0.5750442147254944]\n",
      "2300 steps | score: [0.317975252866745, -0.7649738192558289]\n",
      "2400 steps | score: [0.10965526103973389, -0.22700214385986328]\n",
      "2500 steps | score: [0.12884695827960968, -0.2814400792121887]\n",
      "2600 steps | score: [0.2835804522037506, -0.6410011053085327]\n",
      "2700 steps | score: [0.16527211666107178, -0.3496239483356476]\n",
      "2800 steps | score: [0.2522521913051605, -0.5767117142677307]\n",
      "unknown params:  tensor([ 0.3816, -1.0085, -0.8461, -0.4064, -0.2897,  0.5577])\n",
      "gt params:  tensor([ 0.3643, -0.9776, -0.8391, -0.3621, -0.2498,  0.9096])\n",
      "ols params:  tensor([ 0.2305, -0.5760, -0.4913, -0.2448, -0.1679,  3.3153])\n",
      "unknown mse:  tensor(0.0214)\n",
      "ols mse:  tensor(1.0180)\n",
      "gt params:  tensor([ 0.3426, -0.9323, -0.8342, -0.3594, -0.2737,  0.8395])\n",
      "0 steps | score: [0.2434380203485489]\n",
      "100 steps | score: [0.0147384162992239]\n",
      "200 steps | score: [0.05014368146657944]\n",
      "300 steps | score: [0.02030821330845356]\n",
      "400 steps | score: [0.040775515139102936]\n",
      "500 steps | score: [-0.03361762315034866]\n",
      "600 steps | score: [0.02401641011238098]\n",
      "700 steps | score: [0.0560363307595253]\n",
      "800 steps | score: [0.0061242058873176575]\n",
      "0 steps | score: [-0.17283332347869873, 0.47070762515068054]\n",
      "100 steps | score: [-0.05725135654211044, 0.05212296545505524]\n",
      "200 steps | score: [-0.3836691975593567, 0.7842932343482971]\n",
      "300 steps | score: [-0.24839404225349426, 0.46548008918762207]\n",
      "400 steps | score: [-0.015039697289466858, -0.24542593955993652]\n",
      "500 steps | score: [-0.4380083978176117, 0.8228471279144287]\n",
      "600 steps | score: [-0.3180747628211975, 0.5743488073348999]\n",
      "700 steps | score: [-0.11712665110826492, 0.06810326874256134]\n",
      "800 steps | score: [-0.44597017765045166, 0.9094530940055847]\n",
      "900 steps | score: [-0.19735944271087646, 0.2118610143661499]\n",
      "1000 steps | score: [-0.15626871585845947, 0.13972516357898712]\n",
      "1100 steps | score: [-0.2045610249042511, 0.28132036328315735]\n",
      "1200 steps | score: [-0.20746223628520966, 0.28171223402023315]\n",
      "1300 steps | score: [-0.3051106929779053, 0.5669208765029907]\n",
      "1400 steps | score: [-0.36783090233802795, 0.6886432766914368]\n",
      "1500 steps | score: [-0.19302113354206085, 0.2314917892217636]\n",
      "1600 steps | score: [-0.33667057752609253, 0.6269193887710571]\n",
      "1700 steps | score: [-0.38618406653404236, 0.7143283486366272]\n",
      "1800 steps | score: [-0.2494736909866333, 0.41604313254356384]\n",
      "1900 steps | score: [-0.3740502893924713, 0.7056525349617004]\n",
      "2000 steps | score: [-0.25515320897102356, 0.4167063534259796]\n",
      "2100 steps | score: [-0.2879045903682709, 0.5029208660125732]\n",
      "2200 steps | score: [-0.3177502751350403, 0.5491952300071716]\n",
      "2300 steps | score: [-0.34939348697662354, 0.6364399194717407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 steps | score: [-0.30804386734962463, 0.5328172445297241]\n",
      "2500 steps | score: [-0.29953163862228394, 0.5325466990470886]\n",
      "2600 steps | score: [-0.34543123841285706, 0.6244907379150391]\n",
      "2700 steps | score: [-0.25139060616493225, 0.3956768810749054]\n",
      "2800 steps | score: [-0.20609883964061737, 0.2667974829673767]\n",
      "unknown params:  tensor([ 0.3429, -0.9910, -0.8819, -0.3577, -0.3305,  0.6031])\n",
      "gt params:  tensor([ 0.3426, -0.9323, -0.8342, -0.3594, -0.2737,  0.8395])\n",
      "ols params:  tensor([ 0.1944, -0.5438, -0.4939, -0.2068, -0.1842,  3.3832])\n",
      "unknown mse:  tensor(0.0108)\n",
      "ols mse:  tensor(1.1317)\n",
      "gt params:  tensor([ 0.3724, -0.9275, -0.8278, -0.3786, -0.2455,  0.8764])\n",
      "0 steps | score: [0.09112637490034103]\n",
      "100 steps | score: [-0.09566488862037659]\n",
      "200 steps | score: [-0.15080496668815613]\n",
      "300 steps | score: [-0.18747244775295258]\n",
      "400 steps | score: [-0.07560919970273972]\n",
      "500 steps | score: [-0.150931254029274]\n",
      "600 steps | score: [-0.16591036319732666]\n",
      "700 steps | score: [-0.17696590721607208]\n",
      "800 steps | score: [-0.14059580862522125]\n",
      "900 steps | score: [-0.1359591782093048]\n",
      "1000 steps | score: [-0.15267929434776306]\n",
      "1100 steps | score: [-0.15661638975143433]\n",
      "1200 steps | score: [-0.1912890374660492]\n",
      "1300 steps | score: [-0.13897061347961426]\n",
      "1400 steps | score: [-0.16091486811637878]\n",
      "1500 steps | score: [-0.1382424235343933]\n",
      "1600 steps | score: [-0.15136435627937317]\n",
      "1700 steps | score: [-0.14012965559959412]\n",
      "1800 steps | score: [-0.13069914281368256]\n",
      "1900 steps | score: [-0.16743457317352295]\n",
      "2000 steps | score: [-0.15367990732192993]\n",
      "2100 steps | score: [-0.13898295164108276]\n",
      "2200 steps | score: [-0.14765551686286926]\n",
      "2300 steps | score: [-0.15638640522956848]\n",
      "2400 steps | score: [-0.16361166536808014]\n",
      "2500 steps | score: [-0.16106590628623962]\n",
      "2600 steps | score: [-0.1463383138179779]\n",
      "2700 steps | score: [-0.13862517476081848]\n",
      "2800 steps | score: [-0.15292876958847046]\n",
      "0 steps | score: [0.09361988306045532, 0.3243056535720825]\n",
      "100 steps | score: [-0.01256141159683466, 0.42251139879226685]\n",
      "200 steps | score: [-0.24315206706523895, 0.8670850992202759]\n",
      "300 steps | score: [-0.17607048153877258, 0.7223368883132935]\n",
      "400 steps | score: [0.023351406678557396, 0.2334541380405426]\n",
      "500 steps | score: [-0.1555285006761551, 0.6457069516181946]\n",
      "600 steps | score: [-0.06707983464002609, 0.48144832253456116]\n",
      "700 steps | score: [-0.13236328959465027, 0.5898950695991516]\n",
      "800 steps | score: [-0.09366190433502197, 0.49807310104370117]\n",
      "900 steps | score: [-0.12542398273944855, 0.5911176204681396]\n",
      "1000 steps | score: [-0.12703602015972137, 0.5569677352905273]\n",
      "1100 steps | score: [-0.1709488332271576, 0.6934348940849304]\n",
      "1200 steps | score: [-0.03612169250845909, 0.35997655987739563]\n",
      "1300 steps | score: [-0.10329804569482803, 0.5362846851348877]\n",
      "1400 steps | score: [-0.23554068803787231, 0.8133429884910583]\n",
      "1500 steps | score: [-0.03651702031493187, 0.36887696385383606]\n",
      "1600 steps | score: [0.07138565182685852, 0.11746300756931305]\n",
      "1700 steps | score: [-0.10292206704616547, 0.5362613201141357]\n",
      "1800 steps | score: [0.04283588007092476, 0.16519096493721008]\n",
      "1900 steps | score: [-0.07825524359941483, 0.4543178081512451]\n",
      "2000 steps | score: [-0.10172706842422485, 0.5418701171875]\n",
      "2100 steps | score: [0.007702361326664686, 0.25159719586372375]\n",
      "2200 steps | score: [-0.08317563682794571, 0.4535142779350281]\n",
      "2300 steps | score: [-0.11563383787870407, 0.5437203645706177]\n",
      "2400 steps | score: [-0.04833875969052315, 0.4007539749145508]\n",
      "2500 steps | score: [-0.059118811041116714, 0.403870552778244]\n",
      "2600 steps | score: [-0.04160282015800476, 0.3836953043937683]\n",
      "2700 steps | score: [-0.022084776312112808, 0.3057902455329895]\n",
      "2800 steps | score: [-0.06534169614315033, 0.43162453174591064]\n",
      "unknown params:  tensor([ 0.3635, -0.8798, -0.8284, -0.4105, -0.2322,  0.5027])\n",
      "gt params:  tensor([ 0.3724, -0.9275, -0.8278, -0.3786, -0.2455,  0.8764])\n",
      "ols params:  tensor([ 0.2145, -0.5042, -0.4827, -0.2407, -0.1361,  3.4972])\n",
      "unknown mse:  tensor(0.0239)\n",
      "ols mse:  tensor(1.2038)\n",
      "gt params:  tensor([ 0.3692, -0.9754, -0.8605, -0.3634, -0.2683,  0.9172])\n",
      "0 steps | score: [0.34104570746421814]\n",
      "100 steps | score: [0.1581132709980011]\n",
      "200 steps | score: [0.16391213238239288]\n",
      "300 steps | score: [0.14841200411319733]\n",
      "400 steps | score: [0.15481480956077576]\n",
      "500 steps | score: [0.13699130713939667]\n",
      "600 steps | score: [0.06878983974456787]\n",
      "700 steps | score: [0.09478458762168884]\n",
      "800 steps | score: [0.11933371424674988]\n",
      "900 steps | score: [0.09057053923606873]\n",
      "1000 steps | score: [0.1321241408586502]\n",
      "1100 steps | score: [0.09828035533428192]\n",
      "1200 steps | score: [0.05999453365802765]\n",
      "1300 steps | score: [0.10584405064582825]\n",
      "1400 steps | score: [0.08472532778978348]\n",
      "1500 steps | score: [0.0568278431892395]\n",
      "1600 steps | score: [0.09539277851581573]\n",
      "1700 steps | score: [0.08865382522344589]\n",
      "1800 steps | score: [0.0926319807767868]\n",
      "1900 steps | score: [0.1273484081029892]\n",
      "2000 steps | score: [0.13714221119880676]\n",
      "2100 steps | score: [0.12170010060071945]\n",
      "2200 steps | score: [0.10144048184156418]\n",
      "2300 steps | score: [0.07582424581050873]\n",
      "2400 steps | score: [0.11167815327644348]\n",
      "2500 steps | score: [0.0931210070848465]\n",
      "2600 steps | score: [0.09419446438550949]\n",
      "2700 steps | score: [0.09986307471990585]\n",
      "2800 steps | score: [0.08930621296167374]\n",
      "0 steps | score: [0.17210844159126282, -0.18190181255340576]\n",
      "100 steps | score: [0.4453662037849426, -1.0545125007629395]\n",
      "200 steps | score: [-0.03409697860479355, 0.1120963990688324]\n",
      "300 steps | score: [0.17464742064476013, -0.47962209582328796]\n",
      "400 steps | score: [0.0966518223285675, -0.2744562029838562]\n",
      "500 steps | score: [0.035687707364559174, -0.09725087881088257]\n",
      "600 steps | score: [0.28465625643730164, -0.7419640421867371]\n",
      "700 steps | score: [0.11976223438978195, -0.26264360547065735]\n",
      "800 steps | score: [-0.018366722390055656, 0.01078929752111435]\n",
      "900 steps | score: [-0.07092361152172089, 0.11839161068201065]\n",
      "1000 steps | score: [0.07991816103458405, -0.25165969133377075]\n",
      "1100 steps | score: [-0.08541107177734375, 0.15364189445972443]\n",
      "1200 steps | score: [-0.11559417098760605, 0.25644367933273315]\n",
      "1300 steps | score: [-0.08792662620544434, 0.20319288969039917]\n",
      "1400 steps | score: [0.14867082238197327, -0.409983366727829]\n",
      "1500 steps | score: [-0.0881602093577385, 0.19155722856521606]\n",
      "1600 steps | score: [0.011959787458181381, -0.07212696969509125]\n",
      "1700 steps | score: [-0.09388667345046997, 0.18419063091278076]\n",
      "1800 steps | score: [0.016093578189611435, -0.05455402284860611]\n",
      "1900 steps | score: [0.02815059944987297, -0.09108586609363556]\n",
      "2000 steps | score: [0.09646634012460709, -0.2839055359363556]\n",
      "2100 steps | score: [0.09261306375265121, -0.2762954831123352]\n",
      "2200 steps | score: [0.06318057328462601, -0.20570135116577148]\n",
      "2300 steps | score: [-0.03659169003367424, 0.04944363608956337]\n",
      "2400 steps | score: [0.10116240382194519, -0.2682179808616638]\n",
      "2500 steps | score: [0.00528545631095767, -0.026259619742631912]\n",
      "2600 steps | score: [0.08200248330831528, -0.28567713499069214]\n",
      "2700 steps | score: [0.04471615329384804, -0.12019559741020203]\n",
      "2800 steps | score: [0.01273353211581707, -0.08098537474870682]\n",
      "unknown params:  tensor([ 0.3710, -0.9687, -0.8266, -0.3574, -0.2770,  0.5786])\n",
      "gt params:  tensor([ 0.3692, -0.9754, -0.8605, -0.3634, -0.2683,  0.9172])\n",
      "ols params:  tensor([ 0.2206, -0.5571, -0.4834, -0.2150, -0.1618,  3.6584])\n",
      "unknown mse:  tensor(0.0193)\n",
      "ols mse:  tensor(1.3144)\n",
      "gt params:  tensor([ 0.3364, -0.9420, -0.8467, -0.3288, -0.2469,  0.9223])\n",
      "0 steps | score: [0.20137488842010498]\n",
      "100 steps | score: [-0.03503260016441345]\n",
      "200 steps | score: [-0.01451040804386139]\n",
      "300 steps | score: [-0.021676205098628998]\n",
      "400 steps | score: [-0.07480578124523163]\n",
      "500 steps | score: [-0.14620450139045715]\n",
      "600 steps | score: [-0.04391536861658096]\n",
      "700 steps | score: [-0.013364434242248535]\n",
      "800 steps | score: [-0.07411917299032211]\n",
      "900 steps | score: [-0.07360274344682693]\n",
      "1000 steps | score: [-0.07247790694236755]\n",
      "1100 steps | score: [-0.09584127366542816]\n",
      "1200 steps | score: [-0.09068670868873596]\n",
      "1300 steps | score: [-0.04194296896457672]\n",
      "1400 steps | score: [-0.08656711876392365]\n",
      "1500 steps | score: [-0.08490055054426193]\n",
      "1600 steps | score: [-0.07583396136760712]\n",
      "1700 steps | score: [-0.08447982370853424]\n",
      "1800 steps | score: [-0.0405643954873085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [-0.07001802325248718]\n",
      "2000 steps | score: [-0.08303152024745941]\n",
      "2100 steps | score: [-0.0842604860663414]\n",
      "2200 steps | score: [-0.09017588198184967]\n",
      "2300 steps | score: [-0.09542407840490341]\n",
      "2400 steps | score: [-0.04922967404127121]\n",
      "2500 steps | score: [-0.059788018465042114]\n",
      "2600 steps | score: [-0.0700799822807312]\n",
      "2700 steps | score: [-0.07267415523529053]\n",
      "2800 steps | score: [-0.08535127341747284]\n",
      "0 steps | score: [0.22418248653411865, -0.15094375610351562]\n",
      "100 steps | score: [-0.04778318852186203, 0.2705339789390564]\n",
      "200 steps | score: [0.176625594496727, -0.2881240248680115]\n",
      "300 steps | score: [0.2921164631843567, -0.6117229461669922]\n",
      "400 steps | score: [-0.08328896760940552, 0.2917650043964386]\n",
      "500 steps | score: [-0.21006420254707336, 0.5300893783569336]\n",
      "600 steps | score: [0.036596305668354034, 0.03318437933921814]\n",
      "700 steps | score: [0.12738114595413208, -0.16988593339920044]\n",
      "800 steps | score: [0.0661015436053276, -0.0501367449760437]\n",
      "900 steps | score: [-0.0018779549282044172, 0.10216984897851944]\n",
      "1000 steps | score: [0.08534227311611176, -0.09825366735458374]\n",
      "1100 steps | score: [0.08037799596786499, -0.05665922164916992]\n",
      "1200 steps | score: [-0.027368271723389626, 0.16201680898666382]\n",
      "1300 steps | score: [0.06155608594417572, -0.04870692640542984]\n",
      "1400 steps | score: [0.09023530036211014, -0.0996149331331253]\n",
      "1500 steps | score: [-0.010320832021534443, 0.10606781393289566]\n",
      "1600 steps | score: [-0.00837551336735487, 0.11888070404529572]\n",
      "1700 steps | score: [0.03463814780116081, -0.014434143900871277]\n",
      "1800 steps | score: [0.040733400732278824, 0.024047333747148514]\n",
      "1900 steps | score: [0.05678355321288109, -0.011198192834854126]\n",
      "2000 steps | score: [-0.02728314884006977, 0.13086913526058197]\n",
      "2100 steps | score: [0.01636505499482155, 0.048948872834444046]\n",
      "2200 steps | score: [-0.06812144070863724, 0.2351141721010208]\n",
      "2300 steps | score: [0.07166139781475067, -0.06698623299598694]\n",
      "2400 steps | score: [0.06532564759254456, -0.06895031780004501]\n",
      "2500 steps | score: [0.06175631284713745, -0.0267682783305645]\n",
      "2600 steps | score: [0.015215807594358921, 0.03717869147658348]\n",
      "2700 steps | score: [0.008526425808668137, 0.07498835027217865]\n",
      "2800 steps | score: [0.06076205521821976, -0.0519285723567009]\n",
      "unknown params:  tensor([ 0.3525, -0.9868, -0.8999, -0.3367, -0.2308,  0.4764])\n",
      "gt params:  tensor([ 0.3364, -0.9420, -0.8467, -0.3288, -0.2469,  0.9223])\n",
      "ols params:  tensor([ 0.1957, -0.5236, -0.4818, -0.1873, -0.1297,  3.7416])\n",
      "unknown mse:  tensor(0.0340)\n",
      "ols mse:  tensor(1.3850)\n",
      "gt params:  tensor([ 0.3487, -0.9350, -0.8354, -0.3607, -0.2650,  0.8072])\n",
      "0 steps | score: [0.28678250312805176]\n",
      "100 steps | score: [0.02097613736987114]\n",
      "200 steps | score: [0.021424179896712303]\n",
      "300 steps | score: [0.02911958657205105]\n",
      "400 steps | score: [0.07926356792449951]\n",
      "500 steps | score: [0.043740592896938324]\n",
      "600 steps | score: [0.0487956702709198]\n",
      "700 steps | score: [0.06775966286659241]\n",
      "800 steps | score: [0.026621518656611443]\n",
      "900 steps | score: [0.033621326088905334]\n",
      "1000 steps | score: [0.009645000100135803]\n",
      "0 steps | score: [0.25555017590522766, -0.397030234336853]\n",
      "100 steps | score: [-0.0606285035610199, 0.08900553733110428]\n",
      "200 steps | score: [0.053225867450237274, -0.19410686194896698]\n",
      "300 steps | score: [-0.10442174971103668, 0.13546624779701233]\n",
      "400 steps | score: [0.028876110911369324, -0.12428699433803558]\n",
      "500 steps | score: [0.06730340421199799, -0.24567021429538727]\n",
      "600 steps | score: [0.21315577626228333, -0.6084798574447632]\n",
      "700 steps | score: [0.13610978424549103, -0.4030686914920807]\n",
      "800 steps | score: [-0.1145142987370491, 0.1529948115348816]\n",
      "900 steps | score: [-0.04347959905862808, -0.007882773876190186]\n",
      "1000 steps | score: [-0.09301774203777313, 0.10839234292507172]\n",
      "1100 steps | score: [0.14351022243499756, -0.4343903064727783]\n",
      "1200 steps | score: [0.010286523960530758, -0.1051289439201355]\n",
      "1300 steps | score: [0.05624857544898987, -0.1998644471168518]\n",
      "1400 steps | score: [0.11462020874023438, -0.35109472274780273]\n",
      "1500 steps | score: [0.25960683822631836, -0.744430661201477]\n",
      "1600 steps | score: [0.006117158103734255, -0.11886902898550034]\n",
      "1700 steps | score: [0.039174843579530716, -0.1963985562324524]\n",
      "1800 steps | score: [0.06008826941251755, -0.23121580481529236]\n",
      "1900 steps | score: [0.1366351842880249, -0.4272119402885437]\n",
      "2000 steps | score: [0.07174552232027054, -0.26694032549858093]\n",
      "2100 steps | score: [0.06667774170637131, -0.25511306524276733]\n",
      "2200 steps | score: [0.038066137582063675, -0.16250333189964294]\n",
      "2300 steps | score: [0.10235244035720825, -0.3260626196861267]\n",
      "2400 steps | score: [0.037040941417217255, -0.18436448276042938]\n",
      "2500 steps | score: [-0.007483456749469042, -0.08596394211053848]\n",
      "2600 steps | score: [0.06984320282936096, -0.2689412832260132]\n",
      "2700 steps | score: [0.09748909622430801, -0.35123705863952637]\n",
      "unknown params:  tensor([ 0.3599, -0.9520, -0.8939, -0.3705, -0.3048,  0.3413])\n",
      "gt params:  tensor([ 0.3487, -0.9350, -0.8354, -0.3607, -0.2650,  0.8072])\n",
      "ols params:  tensor([ 0.1988, -0.5058, -0.4787, -0.2030, -0.1639,  3.7583])\n",
      "unknown mse:  tensor(0.0371)\n",
      "ols mse:  tensor(1.5130)\n",
      "gt params:  tensor([ 0.3501, -0.9648, -0.8412, -0.3801, -0.2612,  0.8526])\n",
      "0 steps | score: [0.14778071641921997]\n",
      "100 steps | score: [-0.12165728956460953]\n",
      "200 steps | score: [-0.16902239620685577]\n",
      "300 steps | score: [-0.06920234858989716]\n",
      "400 steps | score: [-0.14563001692295074]\n",
      "500 steps | score: [-0.16823500394821167]\n",
      "600 steps | score: [-0.10721434652805328]\n",
      "700 steps | score: [-0.09993437677621841]\n",
      "800 steps | score: [-0.14788968861103058]\n",
      "900 steps | score: [-0.0846373662352562]\n",
      "1000 steps | score: [-0.1617693305015564]\n",
      "1100 steps | score: [-0.15081878006458282]\n",
      "1200 steps | score: [-0.12456006556749344]\n",
      "1300 steps | score: [-0.10677388310432434]\n",
      "1400 steps | score: [-0.09427531808614731]\n",
      "1500 steps | score: [-0.098485566675663]\n",
      "1600 steps | score: [-0.13557793200016022]\n",
      "1700 steps | score: [-0.121493399143219]\n",
      "1800 steps | score: [-0.1202399805188179]\n",
      "1900 steps | score: [-0.12667138874530792]\n",
      "2000 steps | score: [-0.09405846148729324]\n",
      "2100 steps | score: [-0.12358428537845612]\n",
      "2200 steps | score: [-0.12771382927894592]\n",
      "2300 steps | score: [-0.16707727313041687]\n",
      "2400 steps | score: [-0.11820348352193832]\n",
      "2500 steps | score: [-0.14408057928085327]\n",
      "2600 steps | score: [-0.10864020884037018]\n",
      "2700 steps | score: [-0.11092135310173035]\n",
      "0 steps | score: [-0.14826393127441406, 0.7606964111328125]\n",
      "100 steps | score: [-0.04130375385284424, 0.335700124502182]\n",
      "200 steps | score: [-0.5489028692245483, 1.4174190759658813]\n",
      "300 steps | score: [-0.4837852120399475, 1.2946147918701172]\n",
      "400 steps | score: [-0.4207179844379425, 1.1322181224822998]\n",
      "500 steps | score: [-0.31883305311203003, 0.9005842208862305]\n",
      "600 steps | score: [-0.441713809967041, 1.179644227027893]\n",
      "700 steps | score: [-0.3864883482456207, 1.0427132844924927]\n",
      "800 steps | score: [-0.3784388601779938, 1.0100411176681519]\n",
      "900 steps | score: [-0.17644347250461578, 0.546862006187439]\n",
      "1000 steps | score: [-0.317649781703949, 0.8904147744178772]\n",
      "1100 steps | score: [-0.30587849020957947, 0.8152643442153931]\n",
      "1200 steps | score: [-0.2856532335281372, 0.7852832078933716]\n",
      "1300 steps | score: [-0.27024516463279724, 0.7453062534332275]\n",
      "1400 steps | score: [-0.04095761105418205, 0.2087842971086502]\n",
      "1500 steps | score: [-0.3127589821815491, 0.844031810760498]\n",
      "1600 steps | score: [-0.2899761497974396, 0.8146779537200928]\n",
      "1700 steps | score: [-0.3470076322555542, 0.9552366137504578]\n",
      "1800 steps | score: [-0.2178749293088913, 0.6185675263404846]\n",
      "1900 steps | score: [-0.3708004951477051, 1.0049874782562256]\n",
      "2000 steps | score: [-0.21805056929588318, 0.6158967018127441]\n",
      "2100 steps | score: [-0.3546653091907501, 0.9328749179840088]\n",
      "2200 steps | score: [-0.1812409609556198, 0.5508835911750793]\n",
      "2300 steps | score: [-0.318986177444458, 0.8876707553863525]\n",
      "2400 steps | score: [-0.2016446888446808, 0.5737726092338562]\n",
      "2500 steps | score: [-0.345226526260376, 0.9485487937927246]\n",
      "2600 steps | score: [-0.22137215733528137, 0.6252412796020508]\n",
      "2700 steps | score: [-0.2559984624385834, 0.7378241419792175]\n",
      "unknown params:  tensor([ 0.3309, -0.9010, -0.8258, -0.3846, -0.2419,  0.4841])\n",
      "gt params:  tensor([ 0.3501, -0.9648, -0.8412, -0.3801, -0.2612,  0.8526])\n",
      "ols params:  tensor([ 0.1883, -0.4989, -0.4601, -0.2209, -0.1339,  3.9417])\n",
      "unknown mse:  tensor(0.0235)\n",
      "ols mse:  tensor(1.6621)\n",
      "gt params:  tensor([ 0.3499, -0.9480, -0.8509, -0.3721, -0.2612,  0.8436])\n",
      "0 steps | score: [0.47663596272468567]\n",
      "100 steps | score: [0.24174168705940247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [0.20836688578128815]\n",
      "300 steps | score: [0.26255255937576294]\n",
      "400 steps | score: [0.22051261365413666]\n",
      "500 steps | score: [0.2231293022632599]\n",
      "600 steps | score: [0.19887417554855347]\n",
      "700 steps | score: [0.21005529165267944]\n",
      "800 steps | score: [0.23161089420318604]\n",
      "900 steps | score: [0.20108674466609955]\n",
      "1000 steps | score: [0.21345265209674835]\n",
      "1100 steps | score: [0.17444732785224915]\n",
      "1200 steps | score: [0.2193075567483902]\n",
      "1300 steps | score: [0.1945035606622696]\n",
      "1400 steps | score: [0.22032183408737183]\n",
      "1500 steps | score: [0.1940331906080246]\n",
      "1600 steps | score: [0.21147692203521729]\n",
      "1700 steps | score: [0.13945600390434265]\n",
      "1800 steps | score: [0.17111079394817352]\n",
      "1900 steps | score: [0.17720729112625122]\n",
      "2000 steps | score: [0.2029532939195633]\n",
      "2100 steps | score: [0.20599591732025146]\n",
      "2200 steps | score: [0.1996331512928009]\n",
      "2300 steps | score: [0.18689389526844025]\n",
      "2400 steps | score: [0.20304197072982788]\n",
      "2500 steps | score: [0.2048519253730774]\n",
      "2600 steps | score: [0.20245730876922607]\n",
      "2700 steps | score: [0.21291513741016388]\n",
      "0 steps | score: [0.07715350389480591, 0.1555526852607727]\n",
      "100 steps | score: [-0.216643288731575, 0.6565467715263367]\n",
      "200 steps | score: [-0.14306305348873138, 0.42857468128204346]\n",
      "300 steps | score: [-0.037084050476551056, 0.19903172552585602]\n",
      "400 steps | score: [0.19795078039169312, -0.4288526177406311]\n",
      "500 steps | score: [-0.19887293875217438, 0.5283628702163696]\n",
      "600 steps | score: [-0.030141953378915787, 0.1181003749370575]\n",
      "700 steps | score: [-0.0369134247303009, 0.11061480641365051]\n",
      "800 steps | score: [0.02294760011136532, -0.029691673815250397]\n",
      "900 steps | score: [-0.07449062168598175, 0.23147471249103546]\n",
      "1000 steps | score: [0.15783195197582245, -0.3524893522262573]\n",
      "1100 steps | score: [-0.05461150035262108, 0.1817229986190796]\n",
      "1200 steps | score: [-0.05402703210711479, 0.1323021650314331]\n",
      "1300 steps | score: [-0.1260349601507187, 0.35968148708343506]\n",
      "1400 steps | score: [-0.06107419356703758, 0.16874657571315765]\n",
      "1500 steps | score: [-0.16688229143619537, 0.45054781436920166]\n",
      "1600 steps | score: [-0.06474625319242477, 0.1934119462966919]\n",
      "1700 steps | score: [-0.04641319438815117, 0.14072860777378082]\n",
      "1800 steps | score: [-0.1012844443321228, 0.3379595875740051]\n",
      "1900 steps | score: [-0.048180077224969864, 0.17479826509952545]\n",
      "2000 steps | score: [-0.15126539766788483, 0.4008822441101074]\n",
      "2100 steps | score: [-0.022319450974464417, 0.1562761813402176]\n",
      "2200 steps | score: [-0.18117879331111908, 0.46871069073677063]\n",
      "2300 steps | score: [-0.11016778647899628, 0.3131628632545471]\n",
      "2400 steps | score: [-0.07308589667081833, 0.2475171536207199]\n",
      "2500 steps | score: [-0.09485971182584763, 0.2977105975151062]\n",
      "2600 steps | score: [-0.07277459651231766, 0.18235866725444794]\n",
      "2700 steps | score: [-0.053870491683483124, 0.15639255940914154]\n",
      "unknown params:  tensor([ 0.3284, -0.9467, -0.8277, -0.3578, -0.2706,  0.3284])\n",
      "gt params:  tensor([ 0.3499, -0.9480, -0.8509, -0.3721, -0.2612,  0.8436])\n",
      "ols params:  tensor([ 0.1860, -0.5173, -0.4613, -0.2042, -0.1519,  4.0380])\n",
      "unknown mse:  tensor(0.0445)\n",
      "ols mse:  tensor(1.7680)\n",
      "gt params:  tensor([ 0.3611, -0.9511, -0.8249, -0.3510, -0.2532,  0.9823])\n",
      "0 steps | score: [0.0935455709695816]\n",
      "100 steps | score: [-0.1011778712272644]\n",
      "200 steps | score: [-0.1627076268196106]\n",
      "300 steps | score: [-0.14281529188156128]\n",
      "400 steps | score: [-0.1696309745311737]\n",
      "500 steps | score: [-0.20564988255500793]\n",
      "600 steps | score: [-0.16461677849292755]\n",
      "700 steps | score: [-0.1657688319683075]\n",
      "800 steps | score: [-0.13336032629013062]\n",
      "900 steps | score: [-0.06765864044427872]\n",
      "1000 steps | score: [-0.19025066494941711]\n",
      "1100 steps | score: [-0.19951806962490082]\n",
      "1200 steps | score: [-0.11621558666229248]\n",
      "1300 steps | score: [-0.10815756022930145]\n",
      "1400 steps | score: [-0.12554511427879333]\n",
      "1500 steps | score: [-0.07862348854541779]\n",
      "1600 steps | score: [-0.19521960616111755]\n",
      "1700 steps | score: [-0.15453484654426575]\n",
      "1800 steps | score: [-0.11785899102687836]\n",
      "1900 steps | score: [-0.1261657029390335]\n",
      "2000 steps | score: [-0.14755597710609436]\n",
      "2100 steps | score: [-0.14557190239429474]\n",
      "2200 steps | score: [-0.16226151585578918]\n",
      "2300 steps | score: [-0.1500920057296753]\n",
      "2400 steps | score: [-0.14675459265708923]\n",
      "2500 steps | score: [-0.11077088117599487]\n",
      "2600 steps | score: [-0.15594613552093506]\n",
      "2700 steps | score: [-0.16000458598136902]\n",
      "2800 steps | score: [-0.1458827257156372]\n",
      "0 steps | score: [0.3057938814163208, -0.3683532178401947]\n",
      "100 steps | score: [0.20889869332313538, -0.27583178877830505]\n",
      "200 steps | score: [0.18584953248500824, -0.27869871258735657]\n",
      "300 steps | score: [0.2674565017223358, -0.5169249773025513]\n",
      "400 steps | score: [-0.1070592999458313, 0.28744617104530334]\n",
      "500 steps | score: [0.12425029277801514, -0.23201245069503784]\n",
      "600 steps | score: [0.007345832884311676, 0.03640097379684448]\n",
      "700 steps | score: [0.060061316937208176, -0.0677402913570404]\n",
      "800 steps | score: [0.12362563610076904, -0.19289426505565643]\n",
      "900 steps | score: [0.21148881316184998, -0.39283809065818787]\n",
      "1000 steps | score: [0.02836206741631031, 0.0018364861607551575]\n",
      "1100 steps | score: [0.06482817977666855, -0.07758235186338425]\n",
      "1200 steps | score: [0.20160724222660065, -0.3992341458797455]\n",
      "1300 steps | score: [0.1242915540933609, -0.22094756364822388]\n",
      "1400 steps | score: [-0.006671189796179533, 0.07630868256092072]\n",
      "1500 steps | score: [0.16972099244594574, -0.30392712354660034]\n",
      "1600 steps | score: [-0.0046868217177689075, 0.04370522499084473]\n",
      "1700 steps | score: [0.15799573063850403, -0.28239285945892334]\n",
      "1800 steps | score: [0.1738818883895874, -0.31067654490470886]\n",
      "1900 steps | score: [0.04335838556289673, -0.03677530586719513]\n",
      "2000 steps | score: [0.17216074466705322, -0.31419235467910767]\n",
      "2100 steps | score: [0.11159797012805939, -0.16715843975543976]\n",
      "2200 steps | score: [0.12593397498130798, -0.20677097141742706]\n",
      "2300 steps | score: [0.10374029725790024, -0.19828014075756073]\n",
      "2400 steps | score: [0.16914348304271698, -0.31319674849510193]\n",
      "2500 steps | score: [0.15253768861293793, -0.2598124146461487]\n",
      "2600 steps | score: [0.18086548149585724, -0.3495643138885498]\n",
      "2700 steps | score: [0.07749862223863602, -0.12086351215839386]\n",
      "2800 steps | score: [0.14611442387104034, -0.2909226715564728]\n",
      "unknown params:  tensor([ 0.3977, -0.9575, -0.8161, -0.3351, -0.2661,  0.5993])\n",
      "gt params:  tensor([ 0.3611, -0.9511, -0.8249, -0.3510, -0.2532,  0.9823])\n",
      "ols params:  tensor([ 0.2093, -0.4864, -0.4223, -0.1784, -0.1374,  4.1333])\n",
      "unknown mse:  tensor(0.0248)\n",
      "ols mse:  tensor(1.7288)\n",
      "Logging in: /home/gridsan/stefanou/Regression/Checking Something 5_/0570a864-b845-479e-aa3c-ab9f2546909e\n",
      "gt params:  tensor([-0.8856,  0.9148, -0.2396, -0.1514,  0.4123, -0.4847])\n",
      "0 steps | score: [0.22743652760982513]\n",
      "100 steps | score: [0.23428945243358612]\n",
      "200 steps | score: [0.1276521384716034]\n",
      "300 steps | score: [0.12774235010147095]\n",
      "400 steps | score: [0.019828617572784424]\n",
      "500 steps | score: [0.014312833547592163]\n",
      "600 steps | score: [0.06474165618419647]\n",
      "700 steps | score: [0.18054382503032684]\n",
      "800 steps | score: [0.13340424001216888]\n",
      "900 steps | score: [0.00847412645816803]\n",
      "0 steps | score: [0.022556578740477562, 0.7914546132087708]\n",
      "100 steps | score: [0.31778016686439514, -1.177097201347351]\n",
      "200 steps | score: [1.3663026094436646, -8.733942031860352]\n",
      "300 steps | score: [-1.0456126928329468, 5.746764183044434]\n",
      "400 steps | score: [-0.2943824529647827, 2.0061047077178955]\n",
      "500 steps | score: [-0.6089218854904175, 3.6048929691314697]\n",
      "600 steps | score: [-0.43284672498703003, 2.5940465927124023]\n",
      "700 steps | score: [-0.2396552711725235, 1.844974160194397]\n",
      "800 steps | score: [0.5313891768455505, -3.12577223777771]\n",
      "900 steps | score: [-0.42916908860206604, 2.586150646209717]\n",
      "1000 steps | score: [-0.01942325010895729, 0.24379506707191467]\n",
      "1100 steps | score: [-0.17644141614437103, 1.146643042564392]\n",
      "1200 steps | score: [-0.08271384984254837, 0.7095305323600769]\n",
      "1300 steps | score: [-0.31829023361206055, 2.033921241760254]\n",
      "1400 steps | score: [-0.054792821407318115, 0.4575042128562927]\n",
      "1500 steps | score: [-0.22109396755695343, 1.3257473707199097]\n",
      "1600 steps | score: [-0.028824815526604652, 0.2711593508720398]\n",
      "1700 steps | score: [-0.16009172797203064, 1.1771336793899536]\n",
      "1800 steps | score: [-0.13693127036094666, 1.0061408281326294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [-0.11063508689403534, 0.7563678622245789]\n",
      "2000 steps | score: [-0.15777090191841125, 1.0609482526779175]\n",
      "2100 steps | score: [-0.08316068351268768, 0.6338857412338257]\n",
      "2200 steps | score: [-0.060284655541181564, 0.4643181264400482]\n",
      "2300 steps | score: [-0.10981420427560806, 0.7837980389595032]\n",
      "2400 steps | score: [-0.0427623949944973, 0.38482677936553955]\n",
      "2500 steps | score: [0.10418732464313507, -0.568126380443573]\n",
      "2600 steps | score: [-0.09259950369596481, 0.8309486508369446]\n",
      "2700 steps | score: [-0.20743045210838318, 1.2490984201431274]\n",
      "unknown params:  tensor([-0.8756,  0.9241, -0.2380, -0.1583,  0.4110, -0.3916])\n",
      "gt params:  tensor([-0.8856,  0.9148, -0.2396, -0.1514,  0.4123, -0.4847])\n",
      "ols params:  tensor([-0.7797,  0.8190, -0.2113, -0.1391,  0.3670,  0.1006])\n",
      "unknown mse:  tensor(0.0015)\n",
      "ols mse:  tensor(0.0610)\n",
      "gt params:  tensor([-0.8944,  0.9171, -0.2401, -0.1476,  0.4095, -0.4560])\n",
      "0 steps | score: [0.0802408754825592]\n",
      "100 steps | score: [-0.035068292170763016]\n",
      "200 steps | score: [0.04609238728880882]\n",
      "300 steps | score: [-0.04567787051200867]\n",
      "400 steps | score: [-0.028294946998357773]\n",
      "500 steps | score: [0.007502632215619087]\n",
      "0 steps | score: [0.07109106332063675, 0.27477920055389404]\n",
      "100 steps | score: [-0.3050988018512726, 1.3048821687698364]\n",
      "200 steps | score: [0.7033865451812744, -3.041055202484131]\n",
      "300 steps | score: [-0.3631347417831421, 1.500589370727539]\n",
      "400 steps | score: [-0.08067764341831207, 0.4914686679840088]\n",
      "500 steps | score: [0.21653103828430176, -0.7729030847549438]\n",
      "600 steps | score: [-0.046538688242435455, 0.2396111637353897]\n",
      "700 steps | score: [-0.3253515362739563, 1.302733302116394]\n",
      "800 steps | score: [-0.2620607614517212, 1.0950387716293335]\n",
      "900 steps | score: [0.049303360283374786, -0.0982324481010437]\n",
      "1000 steps | score: [-0.13648323714733124, 0.6533176898956299]\n",
      "1100 steps | score: [-0.08882934600114822, 0.3920723795890808]\n",
      "1200 steps | score: [0.036976393312215805, -0.06987185776233673]\n",
      "1300 steps | score: [-0.10076931864023209, 0.4591737985610962]\n",
      "1400 steps | score: [0.10435748845338821, -0.2921820878982544]\n",
      "1500 steps | score: [-0.16545720398426056, 0.766056478023529]\n",
      "1600 steps | score: [0.19887803494930267, -0.7556065320968628]\n",
      "1700 steps | score: [-0.0823541134595871, 0.3237021267414093]\n",
      "1800 steps | score: [-0.035999201238155365, 0.24545429646968842]\n",
      "1900 steps | score: [-0.06031046807765961, 0.28661075234413147]\n",
      "2000 steps | score: [0.2078678458929062, -0.7904807329177856]\n",
      "2100 steps | score: [-0.0298907570540905, 0.2605295181274414]\n",
      "2200 steps | score: [-0.03708341345191002, 0.24139361083507538]\n",
      "2300 steps | score: [0.02578161284327507, 0.019306570291519165]\n",
      "2400 steps | score: [-0.06410566717386246, 0.3369768559932709]\n",
      "2500 steps | score: [-0.00423003826290369, 0.04427559673786163]\n",
      "2600 steps | score: [-0.07056665420532227, 0.355903297662735]\n",
      "2700 steps | score: [-0.06266528367996216, 0.3266860842704773]\n",
      "unknown params:  tensor([-0.9031,  0.9079, -0.2343, -0.1424,  0.4148, -0.3417])\n",
      "gt params:  tensor([-0.8944,  0.9171, -0.2401, -0.1476,  0.4095, -0.4560])\n",
      "ols params:  tensor([-0.7270,  0.7375, -0.1936, -0.1180,  0.3400,  0.5694])\n",
      "unknown mse:  tensor(0.0022)\n",
      "ols mse:  tensor(0.1866)\n",
      "gt params:  tensor([-0.8853,  0.9252, -0.2447, -0.1555,  0.4117, -0.4867])\n",
      "0 steps | score: [0.10292383283376694]\n",
      "100 steps | score: [-0.041039153933525085]\n",
      "200 steps | score: [-0.04435833916068077]\n",
      "300 steps | score: [-0.16241635382175446]\n",
      "400 steps | score: [0.007050829939544201]\n",
      "0 steps | score: [0.05537298694252968, 0.08610516786575317]\n",
      "100 steps | score: [-0.12304344028234482, 0.3572961091995239]\n",
      "200 steps | score: [-0.06375156342983246, 0.10384706407785416]\n",
      "300 steps | score: [-0.412411093711853, 1.1614181995391846]\n",
      "400 steps | score: [-0.1705223172903061, 0.3812233507633209]\n",
      "500 steps | score: [-0.0007938024355098605, -0.2175663709640503]\n",
      "600 steps | score: [-0.255546510219574, 0.607467532157898]\n",
      "700 steps | score: [-0.06412556767463684, 0.08535779267549515]\n",
      "800 steps | score: [-0.08754648268222809, 0.11971987783908844]\n",
      "900 steps | score: [0.2081345170736313, -0.9588301777839661]\n",
      "1000 steps | score: [-0.3118043839931488, 0.8020619750022888]\n",
      "1100 steps | score: [-0.14793571829795837, 0.337768018245697]\n",
      "1200 steps | score: [-0.2995695471763611, 0.7551591396331787]\n",
      "1300 steps | score: [-0.026461098343133926, -0.1439487785100937]\n",
      "1400 steps | score: [-0.14374586939811707, 0.24233132600784302]\n",
      "1500 steps | score: [-0.251335471868515, 0.661067545413971]\n",
      "1600 steps | score: [-0.2610844075679779, 0.6509574055671692]\n",
      "1700 steps | score: [-0.020017560571432114, -0.14258402585983276]\n",
      "1800 steps | score: [-0.17473262548446655, 0.37345993518829346]\n",
      "1900 steps | score: [-0.19358757138252258, 0.4087495505809784]\n",
      "2000 steps | score: [-0.057874128222465515, -0.019174426794052124]\n",
      "2100 steps | score: [-0.2761947810649872, 0.648509681224823]\n",
      "2200 steps | score: [0.062230534851551056, -0.43049073219299316]\n",
      "2300 steps | score: [-0.17123886942863464, 0.29919832944869995]\n",
      "2400 steps | score: [-0.17516900599002838, 0.36280620098114014]\n",
      "2500 steps | score: [-0.20317929983139038, 0.4370994567871094]\n",
      "2600 steps | score: [-0.06601070612668991, -0.005127087235450745]\n",
      "2700 steps | score: [-0.1546834409236908, 0.2812674045562744]\n",
      "unknown params:  tensor([-0.8846,  0.9316, -0.2487, -0.1481,  0.4266, -0.3129])\n",
      "gt params:  tensor([-0.8853,  0.9252, -0.2447, -0.1555,  0.4117, -0.4867])\n",
      "ols params:  tensor([-0.6553,  0.6877, -0.1865, -0.1124,  0.3185,  0.9288])\n",
      "unknown mse:  tensor(0.0051)\n",
      "ols mse:  tensor(0.3545)\n",
      "gt params:  tensor([-0.8826,  0.9029, -0.2458, -0.1579,  0.4177, -0.4732])\n",
      "0 steps | score: [0.14291912317276]\n",
      "100 steps | score: [-0.01810409501194954]\n",
      "200 steps | score: [-0.1409938931465149]\n",
      "300 steps | score: [-0.13503128290176392]\n",
      "400 steps | score: [-0.008952369913458824]\n",
      "0 steps | score: [0.3550228774547577, -0.5422466993331909]\n",
      "100 steps | score: [0.2731495499610901, -0.6061274409294128]\n",
      "200 steps | score: [0.14280720055103302, -0.29129958152770996]\n",
      "300 steps | score: [0.05978811904788017, -0.026432305574417114]\n",
      "400 steps | score: [0.5576256513595581, -1.5753886699676514]\n",
      "500 steps | score: [0.021709585562348366, -0.01291472464799881]\n",
      "600 steps | score: [0.2689691185951233, -0.7487562298774719]\n",
      "700 steps | score: [0.13875818252563477, -0.353370726108551]\n",
      "800 steps | score: [0.34225788712501526, -0.9266237616539001]\n",
      "900 steps | score: [0.02389148622751236, 0.005208700895309448]\n",
      "1000 steps | score: [0.34092977643013, -0.9460022449493408]\n",
      "1100 steps | score: [0.07826852053403854, -0.16640914976596832]\n",
      "1200 steps | score: [0.16605544090270996, -0.37646183371543884]\n",
      "1300 steps | score: [0.1589404195547104, -0.37926262617111206]\n",
      "1400 steps | score: [0.17055849730968475, -0.4251932203769684]\n",
      "1500 steps | score: [0.13741034269332886, -0.35057851672172546]\n",
      "1600 steps | score: [0.16141630709171295, -0.3809977173805237]\n",
      "1700 steps | score: [0.26949772238731384, -0.6810692548751831]\n",
      "1800 steps | score: [0.143600195646286, -0.2773129343986511]\n",
      "1900 steps | score: [0.18513964116573334, -0.45828977227211]\n",
      "2000 steps | score: [0.1478578746318817, -0.3598921597003937]\n",
      "2100 steps | score: [0.12537293136119843, -0.3330269157886505]\n",
      "2200 steps | score: [0.16279466450214386, -0.3664931058883667]\n",
      "2300 steps | score: [0.12862272560596466, -0.2741236984729767]\n",
      "2400 steps | score: [0.14329592883586884, -0.35149437189102173]\n",
      "2500 steps | score: [0.15069811046123505, -0.38737282156944275]\n",
      "2600 steps | score: [0.10146275162696838, -0.26802003383636475]\n",
      "2700 steps | score: [0.20326179265975952, -0.5275798439979553]\n",
      "unknown params:  tensor([-0.9109,  0.9209, -0.2247, -0.1650,  0.4349, -0.4475])\n",
      "gt params:  tensor([-0.8826,  0.9029, -0.2458, -0.1579,  0.4177, -0.4732])\n",
      "ols params:  tensor([-0.6264,  0.6337, -0.1605, -0.1183,  0.3062,  1.1906])\n",
      "unknown mse:  tensor(0.0004)\n",
      "ols mse:  tensor(0.4880)\n",
      "gt params:  tensor([-0.8776,  0.9116, -0.2377, -0.1497,  0.4273, -0.4609])\n",
      "0 steps | score: [0.18496304750442505]\n",
      "100 steps | score: [0.028424842283129692]\n",
      "200 steps | score: [-0.056616950780153275]\n",
      "300 steps | score: [0.05156589299440384]\n",
      "400 steps | score: [0.03569544106721878]\n",
      "500 steps | score: [-0.024324972182512283]\n",
      "600 steps | score: [0.014545246958732605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 steps | score: [-0.06274279952049255]\n",
      "800 steps | score: [0.06156793236732483]\n",
      "900 steps | score: [-0.011958610266447067]\n",
      "1000 steps | score: [0.016991999000310898]\n",
      "1100 steps | score: [0.004572533071041107]\n",
      "0 steps | score: [0.229684978723526, 0.03334673494100571]\n",
      "100 steps | score: [0.324606716632843, -0.5536859631538391]\n",
      "200 steps | score: [0.15669435262680054, -0.22194941341876984]\n",
      "300 steps | score: [-0.08799268305301666, 0.5720430612564087]\n",
      "400 steps | score: [0.2168474793434143, -0.37113678455352783]\n",
      "500 steps | score: [-0.20451810956001282, 0.9029830098152161]\n",
      "600 steps | score: [-0.011112219654023647, 0.3372219204902649]\n",
      "700 steps | score: [-0.17657935619354248, 0.7317513227462769]\n",
      "800 steps | score: [0.18513473868370056, -0.2928120195865631]\n",
      "900 steps | score: [0.28081974387168884, -0.6689172983169556]\n",
      "1000 steps | score: [0.0019745901226997375, 0.25280633568763733]\n",
      "1100 steps | score: [0.006627443712204695, 0.20929284393787384]\n",
      "1200 steps | score: [0.12321829795837402, -0.1290031522512436]\n",
      "1300 steps | score: [-0.017168747261166573, 0.2967835068702698]\n",
      "1400 steps | score: [0.12980107963085175, -0.1842191070318222]\n",
      "1500 steps | score: [0.07471296936273575, 0.01277906447649002]\n",
      "1600 steps | score: [0.0881267562508583, -0.009866788983345032]\n",
      "1700 steps | score: [0.2537582516670227, -0.538798987865448]\n",
      "1800 steps | score: [0.09165509045124054, -0.04212102293968201]\n",
      "1900 steps | score: [0.21833370625972748, -0.47207891941070557]\n",
      "2000 steps | score: [0.1373826414346695, -0.1711030900478363]\n",
      "2100 steps | score: [0.20125000178813934, -0.34666311740875244]\n",
      "2200 steps | score: [0.18979978561401367, -0.33334875106811523]\n",
      "2300 steps | score: [0.10235769301652908, -0.07721137255430222]\n",
      "2400 steps | score: [0.2670362591743469, -0.5850052833557129]\n",
      "2500 steps | score: [0.055291589349508286, 0.06549949944019318]\n",
      "2600 steps | score: [0.17591522634029388, -0.3136017322540283]\n",
      "2700 steps | score: [0.08842158317565918, -0.014092028141021729]\n",
      "unknown params:  tensor([-0.8691,  0.8850, -0.2564, -0.1429,  0.4132, -0.3716])\n",
      "gt params:  tensor([-0.8776,  0.9116, -0.2377, -0.1497,  0.4273, -0.4609])\n",
      "ols params:  tensor([-0.5854,  0.5970, -0.1761, -0.1001,  0.2845,  1.4970])\n",
      "unknown mse:  tensor(0.0016)\n",
      "ols mse:  tensor(0.6740)\n",
      "gt params:  tensor([-0.8975,  0.9142, -0.2371, -0.1430,  0.4231, -0.4692])\n",
      "0 steps | score: [0.04916802793741226]\n",
      "100 steps | score: [-0.14781416952610016]\n",
      "200 steps | score: [-0.1282310038805008]\n",
      "300 steps | score: [-0.21285556256771088]\n",
      "400 steps | score: [-0.2353236973285675]\n",
      "500 steps | score: [-0.14216336607933044]\n",
      "600 steps | score: [-0.13086050748825073]\n",
      "700 steps | score: [-0.17422936856746674]\n",
      "800 steps | score: [-0.19744928181171417]\n",
      "900 steps | score: [-0.18772362172603607]\n",
      "1000 steps | score: [-0.13728025555610657]\n",
      "1100 steps | score: [-0.16077373921871185]\n",
      "1200 steps | score: [-0.19428390264511108]\n",
      "1300 steps | score: [-0.20630095899105072]\n",
      "1400 steps | score: [-0.1532738357782364]\n",
      "1500 steps | score: [-0.13029590249061584]\n",
      "1600 steps | score: [-0.14724496006965637]\n",
      "1700 steps | score: [-0.19399455189704895]\n",
      "1800 steps | score: [-0.2099694162607193]\n",
      "1900 steps | score: [-0.1478106677532196]\n",
      "2000 steps | score: [-0.17870545387268066]\n",
      "2100 steps | score: [-0.1490485668182373]\n",
      "2200 steps | score: [-0.2001824826002121]\n",
      "2300 steps | score: [-0.1606430560350418]\n",
      "2400 steps | score: [-0.16305002570152283]\n",
      "2500 steps | score: [-0.17364056408405304]\n",
      "2600 steps | score: [-0.17191419005393982]\n",
      "2700 steps | score: [-0.19480304419994354]\n",
      "0 steps | score: [0.2569747567176819, -0.15497851371765137]\n",
      "100 steps | score: [0.25928106904029846, -0.3809121549129486]\n",
      "200 steps | score: [0.012832306325435638, 0.1945173144340515]\n",
      "300 steps | score: [-0.11767986416816711, 0.47483837604522705]\n",
      "400 steps | score: [0.05039536952972412, 0.05771214887499809]\n",
      "500 steps | score: [0.047689586877822876, 0.05279295891523361]\n",
      "600 steps | score: [-0.002319306368008256, 0.1916068196296692]\n",
      "700 steps | score: [-0.04172208905220032, 0.2679518461227417]\n",
      "800 steps | score: [-0.011425996199250221, 0.24373206496238708]\n",
      "900 steps | score: [0.11911208182573318, -0.10189163684844971]\n",
      "1000 steps | score: [0.12035686522722244, -0.1110229641199112]\n",
      "1100 steps | score: [0.05027942359447479, 0.10612230747938156]\n",
      "1200 steps | score: [-0.009699906222522259, 0.18727625906467438]\n",
      "1300 steps | score: [-0.12340544164180756, 0.4815479815006256]\n",
      "1400 steps | score: [0.01731373742222786, 0.11604776978492737]\n",
      "1500 steps | score: [0.07859205454587936, -0.034099046140909195]\n",
      "1600 steps | score: [0.2856813967227936, -0.6001918911933899]\n",
      "1700 steps | score: [0.007632391527295113, 0.1354360729455948]\n",
      "1800 steps | score: [0.01275675743818283, 0.1783648133277893]\n",
      "1900 steps | score: [0.09892824292182922, -0.09909193217754364]\n",
      "2000 steps | score: [0.0788249522447586, -0.0336502306163311]\n",
      "2100 steps | score: [0.025190629065036774, 0.08839348703622818]\n",
      "2200 steps | score: [-0.016198154538869858, 0.21147114038467407]\n",
      "2300 steps | score: [0.12272108346223831, -0.13812008500099182]\n",
      "2400 steps | score: [0.08487720042467117, -0.048563435673713684]\n",
      "2500 steps | score: [0.0625358521938324, 0.04099644348025322]\n",
      "2600 steps | score: [0.0460178405046463, 0.07632853090763092]\n",
      "2700 steps | score: [0.019955521449446678, 0.09153356403112411]\n",
      "unknown params:  tensor([-0.8498,  0.8690, -0.2201, -0.1313,  0.4335, -0.2707])\n",
      "gt params:  tensor([-0.8975,  0.9142, -0.2371, -0.1430,  0.4231, -0.4692])\n",
      "ols params:  tensor([-0.5698,  0.5809, -0.1495, -0.0917,  0.2961,  1.7016])\n",
      "unknown mse:  tensor(0.0074)\n",
      "ols mse:  tensor(0.8262)\n",
      "gt params:  tensor([-0.8953,  0.9171, -0.2393, -0.1577,  0.4208, -0.5323])\n",
      "0 steps | score: [0.30933597683906555]\n",
      "100 steps | score: [0.24596752226352692]\n",
      "200 steps | score: [0.0058365473523736]\n",
      "0 steps | score: [0.08929436653852463, 0.24888931214809418]\n",
      "100 steps | score: [0.10175593942403793, 0.029152557253837585]\n",
      "200 steps | score: [-0.25333085656166077, 0.7552353143692017]\n",
      "300 steps | score: [-0.04641120880842209, 0.2370375394821167]\n",
      "400 steps | score: [0.10081891715526581, -0.16112768650054932]\n",
      "500 steps | score: [-0.10863788425922394, 0.43729686737060547]\n",
      "600 steps | score: [-0.2051597386598587, 0.651931643486023]\n",
      "700 steps | score: [-0.1764049082994461, 0.5619086027145386]\n",
      "800 steps | score: [-0.1728736311197281, 0.5732919573783875]\n",
      "900 steps | score: [-0.03820977360010147, 0.1983497142791748]\n",
      "1000 steps | score: [-0.11726540327072144, 0.43121159076690674]\n",
      "1100 steps | score: [-0.028741812333464622, 0.17282260954380035]\n",
      "1200 steps | score: [-0.17358051240444183, 0.5492998361587524]\n",
      "1300 steps | score: [-0.1998656541109085, 0.6364778876304626]\n",
      "1400 steps | score: [-0.04441983625292778, 0.22556084394454956]\n",
      "1500 steps | score: [-0.0004469003470148891, 0.08743728697299957]\n",
      "1600 steps | score: [-0.15693336725234985, 0.5024503469467163]\n",
      "1700 steps | score: [-0.2348475605249405, 0.6929474472999573]\n",
      "1800 steps | score: [-0.12691445648670197, 0.420291006565094]\n",
      "1900 steps | score: [-0.05181168019771576, 0.2812527120113373]\n",
      "2000 steps | score: [-0.15671217441558838, 0.4941280484199524]\n",
      "2100 steps | score: [-0.20949240028858185, 0.6397359371185303]\n",
      "2200 steps | score: [-0.15197470784187317, 0.4892515242099762]\n",
      "2300 steps | score: [-0.06113240122795105, 0.24488431215286255]\n",
      "2400 steps | score: [-0.1512608677148819, 0.5435344576835632]\n",
      "2500 steps | score: [-0.2279394119977951, 0.6850838661193848]\n",
      "2600 steps | score: [-0.1692526936531067, 0.501028299331665]\n",
      "2700 steps | score: [-0.08371104300022125, 0.30105268955230713]\n",
      "unknown params:  tensor([-0.8974,  0.9618, -0.2279, -0.1621,  0.3770, -0.2820])\n",
      "gt params:  tensor([-0.8953,  0.9171, -0.2393, -0.1577,  0.4208, -0.5323])\n",
      "ols params:  tensor([-0.5414,  0.5778, -0.1457, -0.1027,  0.2363,  1.8406])\n",
      "unknown mse:  tensor(0.0111)\n",
      "ols mse:  tensor(0.9861)\n",
      "gt params:  tensor([-0.8847,  0.9253, -0.2433, -0.1552,  0.4079, -0.4322])\n",
      "0 steps | score: [0.10953235626220703]\n",
      "100 steps | score: [-0.15239150822162628]\n",
      "200 steps | score: [-0.12437626719474792]\n",
      "300 steps | score: [-0.054285481572151184]\n",
      "400 steps | score: [-0.09561317414045334]\n",
      "500 steps | score: [-0.08224062621593475]\n",
      "600 steps | score: [-0.08108040690422058]\n",
      "700 steps | score: [-0.06928282231092453]\n",
      "800 steps | score: [-0.12253464013338089]\n",
      "900 steps | score: [-0.10737335681915283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 steps | score: [-0.11538168787956238]\n",
      "1100 steps | score: [-0.12440813332796097]\n",
      "1200 steps | score: [-0.06183312460780144]\n",
      "1300 steps | score: [-0.12704071402549744]\n",
      "1400 steps | score: [-0.1330290138721466]\n",
      "1500 steps | score: [-0.0888962671160698]\n",
      "1600 steps | score: [-0.09254215657711029]\n",
      "1700 steps | score: [-0.07244395464658737]\n",
      "1800 steps | score: [-0.06856916844844818]\n",
      "1900 steps | score: [-0.10477831959724426]\n",
      "2000 steps | score: [-0.07898807525634766]\n",
      "2100 steps | score: [-0.060162656009197235]\n",
      "2200 steps | score: [-0.12846580147743225]\n",
      "2300 steps | score: [-0.12625545263290405]\n",
      "2400 steps | score: [-0.1180715560913086]\n",
      "2500 steps | score: [-0.08478990197181702]\n",
      "2600 steps | score: [-0.07281622290611267]\n",
      "2700 steps | score: [-0.08172537386417389]\n",
      "0 steps | score: [0.2969127893447876, -0.45836377143859863]\n",
      "100 steps | score: [0.2478371411561966, -0.532973051071167]\n",
      "200 steps | score: [0.04300776124000549, -0.14957267045974731]\n",
      "300 steps | score: [0.10934039950370789, -0.32284441590309143]\n",
      "400 steps | score: [-0.016492700204253197, -0.00888538546860218]\n",
      "500 steps | score: [0.5269899964332581, -1.4729050397872925]\n",
      "600 steps | score: [0.05545172467827797, -0.22032935917377472]\n",
      "700 steps | score: [0.09356782585382462, -0.3342588543891907]\n",
      "800 steps | score: [0.004149534273892641, -0.07055158168077469]\n",
      "900 steps | score: [0.14726825058460236, -0.43397027254104614]\n",
      "1000 steps | score: [0.024810412898659706, -0.10076221823692322]\n",
      "1100 steps | score: [0.175560861825943, -0.5513491034507751]\n",
      "1200 steps | score: [0.009649998508393764, -0.0941895991563797]\n",
      "1300 steps | score: [0.19413280487060547, -0.5688515305519104]\n",
      "1400 steps | score: [-0.04442043602466583, 0.06352424621582031]\n",
      "1500 steps | score: [0.2926631569862366, -0.8625908493995667]\n",
      "1600 steps | score: [0.21555718779563904, -0.6543181538581848]\n",
      "1700 steps | score: [0.16530945897102356, -0.4775009751319885]\n",
      "1800 steps | score: [0.07819701731204987, -0.26370227336883545]\n",
      "1900 steps | score: [0.08428516983985901, -0.2787833511829376]\n",
      "2000 steps | score: [0.06569886952638626, -0.2608603239059448]\n",
      "2100 steps | score: [0.16186584532260895, -0.47916746139526367]\n",
      "2200 steps | score: [0.04223910719156265, -0.17077931761741638]\n",
      "2300 steps | score: [0.14155341684818268, -0.45584675669670105]\n",
      "2400 steps | score: [0.07850730419158936, -0.25824880599975586]\n",
      "2500 steps | score: [0.14138883352279663, -0.4452216923236847]\n",
      "2600 steps | score: [0.15486331284046173, -0.4454786479473114]\n",
      "2700 steps | score: [0.13361670076847076, -0.41109228134155273]\n",
      "unknown params:  tensor([-0.8841,  0.9684, -0.2687, -0.1701,  0.4131, -0.3729])\n",
      "gt params:  tensor([-0.8847,  0.9253, -0.2433, -0.1552,  0.4079, -0.4322])\n",
      "ols params:  tensor([-0.5156,  0.5547, -0.1546, -0.1061,  0.2448,  2.0573])\n",
      "unknown mse:  tensor(0.0010)\n",
      "ols mse:  tensor(1.0847)\n",
      "gt params:  tensor([-0.9005,  0.9118, -0.2474, -0.1425,  0.4054, -0.4106])\n",
      "0 steps | score: [0.15927845239639282]\n",
      "100 steps | score: [-0.10889454185962677]\n",
      "200 steps | score: [-0.11396487057209015]\n",
      "300 steps | score: [-0.08461306244134903]\n",
      "400 steps | score: [-0.041081201285123825]\n",
      "500 steps | score: [-0.10018829256296158]\n",
      "600 steps | score: [-0.07427588850259781]\n",
      "700 steps | score: [-0.10932667553424835]\n",
      "800 steps | score: [-0.07606352865695953]\n",
      "900 steps | score: [-0.06926282495260239]\n",
      "1000 steps | score: [-0.08436328172683716]\n",
      "1100 steps | score: [-0.03529370576143265]\n",
      "1200 steps | score: [-0.0754142478108406]\n",
      "1300 steps | score: [-0.059999048709869385]\n",
      "1400 steps | score: [-0.06867703050374985]\n",
      "1500 steps | score: [-0.07051141560077667]\n",
      "1600 steps | score: [-0.08117914944887161]\n",
      "1700 steps | score: [-0.07120263576507568]\n",
      "1800 steps | score: [-0.057790715247392654]\n",
      "1900 steps | score: [-0.08583085983991623]\n",
      "2000 steps | score: [-0.046820733696222305]\n",
      "2100 steps | score: [-0.09855293482542038]\n",
      "2200 steps | score: [-0.0685933455824852]\n",
      "2300 steps | score: [-0.07299024611711502]\n",
      "2400 steps | score: [-0.07581496238708496]\n",
      "2500 steps | score: [-0.07333379238843918]\n",
      "2600 steps | score: [-0.06837037205696106]\n",
      "2700 steps | score: [-0.04216410219669342]\n",
      "0 steps | score: [0.2721656858921051, -0.3054831027984619]\n",
      "100 steps | score: [0.2919585406780243, -0.5483818054199219]\n",
      "200 steps | score: [-0.06502442061901093, 0.2877950966358185]\n",
      "300 steps | score: [-0.1039154976606369, 0.3438875079154968]\n",
      "400 steps | score: [-0.09449926018714905, 0.32243531942367554]\n",
      "500 steps | score: [0.4530949592590332, -1.1324070692062378]\n",
      "600 steps | score: [0.0389217771589756, -0.02691192924976349]\n",
      "700 steps | score: [-0.03421055153012276, 0.14211440086364746]\n",
      "800 steps | score: [0.31842607259750366, -0.761386513710022]\n",
      "900 steps | score: [-0.11279262602329254, 0.3296586573123932]\n",
      "1000 steps | score: [0.09361214935779572, -0.1783977895975113]\n",
      "1100 steps | score: [0.08450531959533691, -0.11763772368431091]\n",
      "1200 steps | score: [0.05157671868801117, -0.01575320214033127]\n",
      "1300 steps | score: [0.3187248706817627, -0.7308413982391357]\n",
      "1400 steps | score: [0.13428637385368347, -0.23747695982456207]\n",
      "1500 steps | score: [0.16492319107055664, -0.3310546875]\n",
      "1600 steps | score: [0.11612893640995026, -0.1857786327600479]\n",
      "1700 steps | score: [0.1001274436712265, -0.18964076042175293]\n",
      "1800 steps | score: [0.19640396535396576, -0.41492772102355957]\n",
      "1900 steps | score: [0.0446351058781147, -0.0434626080095768]\n",
      "2000 steps | score: [0.19382621347904205, -0.4120942950248718]\n",
      "2100 steps | score: [0.010050365701317787, 0.03276457637548447]\n",
      "2200 steps | score: [0.0775725319981575, -0.10703366249799728]\n",
      "2300 steps | score: [0.05871287360787392, -0.0603950060904026]\n",
      "2400 steps | score: [0.049470506608486176, -0.050938233733177185]\n",
      "2500 steps | score: [0.036232925951480865, -0.01428050547838211]\n",
      "2600 steps | score: [0.15566331148147583, -0.3149081766605377]\n",
      "2700 steps | score: [0.1662256419658661, -0.352254718542099]\n",
      "unknown params:  tensor([-0.8207,  0.8430, -0.2216, -0.1422,  0.3980, -0.0727])\n",
      "gt params:  tensor([-0.9005,  0.9118, -0.2474, -0.1425,  0.4054, -0.4106])\n",
      "ols params:  tensor([-0.4996,  0.5149, -0.1390, -0.0897,  0.2517,  2.3103])\n",
      "unknown mse:  tensor(0.0210)\n",
      "ols mse:  tensor(1.2933)\n",
      "gt params:  tensor([-0.8966,  0.8981, -0.2408, -0.1449,  0.4309, -0.5149])\n",
      "0 steps | score: [0.2483656108379364]\n",
      "100 steps | score: [-0.036026351153850555]\n",
      "200 steps | score: [-0.08522245287895203]\n",
      "300 steps | score: [-0.027229852974414825]\n",
      "400 steps | score: [0.005912716966122389]\n",
      "0 steps | score: [0.3610325753688812, -0.4774659276008606]\n",
      "100 steps | score: [0.22183848917484283, -0.33053556084632874]\n",
      "200 steps | score: [-0.0646173357963562, 0.22604484856128693]\n",
      "300 steps | score: [-0.08655273169279099, 0.2798052132129669]\n",
      "400 steps | score: [0.37073615193367004, -0.7647225856781006]\n",
      "500 steps | score: [0.020050615072250366, 0.05014532804489136]\n",
      "600 steps | score: [0.11994142085313797, -0.19091540575027466]\n",
      "700 steps | score: [0.10272813588380814, -0.18863047659397125]\n",
      "800 steps | score: [0.18136566877365112, -0.3420317471027374]\n",
      "900 steps | score: [0.11933566629886627, -0.15447212755680084]\n",
      "1000 steps | score: [0.08687084168195724, -0.12399185448884964]\n",
      "1100 steps | score: [0.2818586230278015, -0.631144106388092]\n",
      "1200 steps | score: [0.10043983906507492, -0.16172751784324646]\n",
      "1300 steps | score: [0.20317892730236053, -0.40375518798828125]\n",
      "1400 steps | score: [0.18829482793807983, -0.3807066082954407]\n",
      "1500 steps | score: [0.3138226270675659, -0.6617536544799805]\n",
      "1600 steps | score: [0.0617908351123333, -0.09307989478111267]\n",
      "1700 steps | score: [0.2317662239074707, -0.44317978620529175]\n",
      "1800 steps | score: [0.13990846276283264, -0.26031142473220825]\n",
      "1900 steps | score: [0.12765486538410187, -0.2173164188861847]\n",
      "2000 steps | score: [0.11598540842533112, -0.20071212947368622]\n",
      "2100 steps | score: [0.15194852650165558, -0.3104337453842163]\n",
      "2200 steps | score: [0.14662878215312958, -0.2453756183385849]\n",
      "2300 steps | score: [0.297841340303421, -0.6581128835678101]\n",
      "2400 steps | score: [0.2143460065126419, -0.4332866668701172]\n",
      "2500 steps | score: [0.17048116028308868, -0.31813785433769226]\n",
      "2600 steps | score: [0.1578182727098465, -0.2914850115776062]\n",
      "2700 steps | score: [0.13108579814434052, -0.22740265727043152]\n",
      "unknown params:  tensor([-0.8250,  0.8208, -0.2592, -0.1238,  0.4218,  0.0555])\n",
      "gt params:  tensor([-0.8966,  0.8981, -0.2408, -0.1449,  0.4309, -0.5149])\n",
      "ols params:  tensor([-0.4756,  0.4750, -0.1509, -0.0771,  0.2504,  2.4727])\n",
      "unknown mse:  tensor(0.0562)\n",
      "ols mse:  tensor(1.5545)\n",
      "gt params:  tensor([-0.8761,  0.9121, -0.2402, -0.1460,  0.4358, -0.4275])\n",
      "0 steps | score: [0.2905293405056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [0.1209934651851654]\n",
      "200 steps | score: [0.07550263404846191]\n",
      "300 steps | score: [0.054532669484615326]\n",
      "400 steps | score: [-0.000830523669719696]\n",
      "0 steps | score: [0.3296787142753601, -0.68241286277771]\n",
      "100 steps | score: [0.21038806438446045, -0.5803426504135132]\n",
      "200 steps | score: [0.11528602987527847, -0.4217684268951416]\n",
      "300 steps | score: [0.28915029764175415, -0.9009606242179871]\n",
      "400 steps | score: [-0.0485110729932785, -0.09373512119054794]\n",
      "500 steps | score: [0.03477563336491585, -0.2867264449596405]\n",
      "600 steps | score: [0.028620578348636627, -0.23643390834331512]\n",
      "700 steps | score: [0.2209601253271103, -0.7284462451934814]\n",
      "800 steps | score: [0.09012243151664734, -0.40366455912590027]\n",
      "900 steps | score: [0.12454940378665924, -0.47338658571243286]\n",
      "1000 steps | score: [-0.015269407071173191, -0.15470100939273834]\n",
      "1100 steps | score: [0.006810449529439211, -0.22467288374900818]\n",
      "1200 steps | score: [0.22473514080047607, -0.7259577512741089]\n",
      "1300 steps | score: [0.07277707755565643, -0.3632805347442627]\n",
      "1400 steps | score: [0.2370167225599289, -0.7882667183876038]\n",
      "1500 steps | score: [0.20913001894950867, -0.6824835538864136]\n",
      "1600 steps | score: [0.08866321295499802, -0.39303088188171387]\n",
      "1700 steps | score: [0.10329494625329971, -0.4908164441585541]\n",
      "1800 steps | score: [0.02639761194586754, -0.29495665431022644]\n",
      "1900 steps | score: [0.08073259145021439, -0.41485992074012756]\n",
      "2000 steps | score: [0.10110564529895782, -0.44396117329597473]\n",
      "2100 steps | score: [0.13349264860153198, -0.5689452290534973]\n",
      "2200 steps | score: [0.06970249116420746, -0.3695322275161743]\n",
      "2300 steps | score: [0.10153376311063766, -0.4608287215232849]\n",
      "2400 steps | score: [0.07909950613975525, -0.3905849754810333]\n",
      "2500 steps | score: [0.01667124778032303, -0.2681065499782562]\n",
      "2600 steps | score: [0.16402335464954376, -0.571759819984436]\n",
      "2700 steps | score: [0.12161897122859955, -0.49316996335983276]\n",
      "unknown params:  tensor([-0.9114,  0.9707, -0.2180, -0.1152,  0.4732, -0.1567])\n",
      "gt params:  tensor([-0.8761,  0.9121, -0.2402, -0.1460,  0.4358, -0.4275])\n",
      "ols params:  tensor([-0.4692,  0.4943, -0.1119, -0.0668,  0.2452,  2.5732])\n",
      "unknown mse:  tensor(0.0135)\n",
      "ols mse:  tensor(1.5673)\n",
      "gt params:  tensor([-0.8621,  0.9029, -0.2257, -0.1562,  0.4199, -0.4395])\n",
      "0 steps | score: [0.2664157450199127]\n",
      "100 steps | score: [-0.04635392501950264]\n",
      "200 steps | score: [-0.019293133169412613]\n",
      "300 steps | score: [-0.022755054756999016]\n",
      "400 steps | score: [-0.012689165771007538]\n",
      "500 steps | score: [-0.024206142872571945]\n",
      "600 steps | score: [-0.006780557334423065]\n",
      "0 steps | score: [-0.02982070855796337, 0.26546788215637207]\n",
      "100 steps | score: [-0.5108379125595093, 1.1140764951705933]\n",
      "200 steps | score: [-0.2606945037841797, 0.5539368391036987]\n",
      "300 steps | score: [-0.25684893131256104, 0.5225605964660645]\n",
      "400 steps | score: [-0.14169006049633026, 0.24007508158683777]\n",
      "500 steps | score: [0.025963090360164642, -0.1518513262271881]\n",
      "600 steps | score: [-0.1825922727584839, 0.35577213764190674]\n",
      "700 steps | score: [-0.22575144469738007, 0.429350882768631]\n",
      "800 steps | score: [-0.36320361495018005, 0.7692437171936035]\n",
      "900 steps | score: [-0.33250436186790466, 0.6833445429801941]\n",
      "1000 steps | score: [-0.24372127652168274, 0.4757046103477478]\n",
      "1100 steps | score: [-0.03576856851577759, -0.030183859169483185]\n",
      "1200 steps | score: [-0.3374266028404236, 0.6902536153793335]\n",
      "1300 steps | score: [-0.2722553312778473, 0.5520029664039612]\n",
      "1400 steps | score: [0.09066565334796906, -0.36228716373443604]\n",
      "1500 steps | score: [-0.26947033405303955, 0.5337250828742981]\n",
      "1600 steps | score: [-0.2523292899131775, 0.49233493208885193]\n",
      "1700 steps | score: [-0.25424227118492126, 0.5099006295204163]\n",
      "1800 steps | score: [-0.2459164559841156, 0.4877786636352539]\n",
      "1900 steps | score: [-0.29209303855895996, 0.5622129440307617]\n",
      "2000 steps | score: [-0.2711755335330963, 0.5164356231689453]\n",
      "2100 steps | score: [-0.2356901317834854, 0.46214282512664795]\n",
      "2200 steps | score: [-0.18102015554904938, 0.3165430426597595]\n",
      "2300 steps | score: [-0.2435533106327057, 0.4685693085193634]\n",
      "2400 steps | score: [-0.032143499702215195, -0.05485805124044418]\n",
      "2500 steps | score: [-0.1770997792482376, 0.3593515157699585]\n",
      "2600 steps | score: [-0.1821521669626236, 0.34512194991111755]\n",
      "2700 steps | score: [-0.24096991121768951, 0.461319237947464]\n",
      "2800 steps | score: [-0.23492394387722015, 0.4702548384666443]\n",
      "unknown params:  tensor([-0.8473,  0.9333, -0.2467, -0.1448,  0.4392, -0.1877])\n",
      "gt params:  tensor([-0.8621,  0.9029, -0.2257, -0.1562,  0.4199, -0.4395])\n",
      "ols params:  tensor([-0.4206,  0.4625, -0.1251, -0.0761,  0.2247,  2.7278])\n",
      "unknown mse:  tensor(0.0109)\n",
      "ols mse:  tensor(1.7459)\n",
      "gt params:  tensor([-0.8613,  0.9130, -0.2266, -0.1430,  0.4214, -0.4103])\n",
      "0 steps | score: [0.0884275883436203]\n",
      "100 steps | score: [-0.19093775749206543]\n",
      "200 steps | score: [-0.13193148374557495]\n",
      "300 steps | score: [-0.1439409852027893]\n",
      "400 steps | score: [-0.13371239602565765]\n",
      "500 steps | score: [-0.1297462284564972]\n",
      "600 steps | score: [-0.18191421031951904]\n",
      "700 steps | score: [-0.19679641723632812]\n",
      "800 steps | score: [-0.14040005207061768]\n",
      "900 steps | score: [-0.105848029255867]\n",
      "1000 steps | score: [-0.18053999543190002]\n",
      "1100 steps | score: [-0.18836596608161926]\n",
      "1200 steps | score: [-0.1591726690530777]\n",
      "1300 steps | score: [-0.14988301694393158]\n",
      "1400 steps | score: [-0.1379128098487854]\n",
      "1500 steps | score: [-0.14844194054603577]\n"
     ]
    }
   ],
   "source": [
    " # expriment parameters\n",
    "w_lower, w_upper = -1, 1\n",
    "d, k = 5, 1\n",
    "# distribution for generating feature vectors\n",
    "W = Uniform(w_lower, w_upper)\n",
    "# dist = MultivariateNormal(ch.zeros(d), ch.eye(d)/d)\n",
    "dist = Uniform(-5, 5)\n",
    "phi = oracle.Left(0.0)\n",
    "\n",
    "for i in range(args.trials):\n",
    "    # create store and add table\n",
    "    store = Store(OUT_DIR + EXP)\n",
    "    store.add_table(TABLE_NAME, { \n",
    "        'ols_r2': float,\n",
    "        'ols_param_mse': float,\n",
    "        'ols_var_l1': float,\n",
    "#         'known_emp_r2': float,\n",
    "#         'known_emp_param_mse': float,\n",
    "#         'known_emp_time': int,\n",
    "        'known_r2': float,\n",
    "        'known_param_mse': float,\n",
    "        'known_time': int,\n",
    "        'unknown_r2': float, \n",
    "        'unknown_param_mse': float,\n",
    "        'unknown_var_l1': float,\n",
    "        'unknown_time': int,\n",
    "        'alpha': float, \n",
    "        'num_samples': int,\n",
    "        'noise_scale': float, \n",
    "    })\n",
    "    \n",
    "    # generate ground truth\n",
    "    gt = ch.nn.Linear(in_features=d, out_features=k)\n",
    "    gt.weight = ch.nn.Parameter(W.sample(ch.Size([k, d])))\n",
    "    gt.bias = ch.nn.Parameter(W.sample(ch.Size([1, 1]))) if args.bias else None\n",
    "    \n",
    "    # create base classifier\n",
    "    with ch.no_grad():\n",
    "        # generate data\n",
    "        X = dist.sample(ch.Size([args.samples, d])) if isinstance(dist, Uniform) else dist.sample(ch.Size([args.samples]))\n",
    "        y = gt(X)\n",
    "        \n",
    "    for noise_var in range(1, 21): \n",
    "        noise_var = Tensor([noise_var])[None,...]\n",
    "        # add noise to ground-truth pedictions\n",
    "        noised = y + ch.sqrt(noise_var)*ch.randn(X.size(0), 1)\n",
    "        # truncate based off of the standardized data\n",
    "        indices = phi(noised).flatten().nonzero(as_tuple=False).flatten()\n",
    "        y_trunc, x_trunc = noised[indices], X[indices]\n",
    "        alpha = Tensor([y_trunc.size(0) / args.samples])\n",
    "        \n",
    "        # normalize x features so that ||x_{i}||_{2}^{2} <= 1\n",
    "        l_inf = LA.norm(x_trunc, dim=-1, ord=float('inf')).max() # find max l_inf\n",
    "        # calculate normalizing constant\n",
    "        beta = l_inf*math.sqrt(d)\n",
    "        \"\"\"\n",
    "        Divide input features by normalizing constant. By doing so, \n",
    "        the weights will be increased by a magnitude of beta.\n",
    "        \"\"\"\n",
    "        x_trunc_norm = x_trunc / beta\n",
    "         # normalize entire dataset by beta\n",
    "        x_norm = X / beta\n",
    "        \n",
    "        # ground-truth ols\n",
    "        gt_ols = LinearRegression()\n",
    "        gt_ols.fit(X, noised)\n",
    "        gt_params = ch.cat([Tensor(gt_ols.coef_).T, Tensor(gt_ols.intercept_)[..., None]]).flatten()\n",
    "        print(\"gt params: \", gt_params)\n",
    "        \n",
    "        # empirical linear regression\n",
    "        ols = LinearRegression() \n",
    "        ols.fit(x_trunc, y_trunc)\n",
    "        ols_var = ch.var(Tensor(ols.predict(x_trunc)) - y_trunc, dim=0)[..., None]\n",
    "        ols_params = ch.cat([Tensor(ols.coef_).T, Tensor(ols.intercept_)[..., None]]).flatten()\n",
    "        # check r2 for entire dataset\n",
    "        ols_pred = ols.predict(X)\n",
    "\n",
    "        # ols results\n",
    "        store[TABLE_NAME].update_row({\n",
    "            'ols_r2': r2_score(noised.flatten(), ols_pred.flatten()), \n",
    "            'ols_var_l1': ch.abs(ols_var - noise_var),\n",
    "            'ols_param_mse': mse_loss(ols_params, gt_params),\n",
    "        })\n",
    "        \n",
    "        \"\"\"\n",
    "        Run dataset on truncated regression with known variance, while \n",
    "        assuming that the empirical noise variance is the underlying noise \n",
    "        variance of our linear regression. This means that we want to standardize \n",
    "        our dependent variable by the empirical noise variance. \n",
    "        \"\"\"\n",
    "        # variance of the residuals\n",
    "#         emp_noise_var = (y_trunc - ols.predict(x_trunc_norm)).var(0)\n",
    "        # standardize y trunc by the empirical noise variance\n",
    "        emp_stand_y_trunc = y_trunc / ch.sqrt(ols_var)\n",
    "#         # standardize noised by the empirical noise variance\n",
    "#         emp_stand_noised = noised / ch.sqrt(emp_noise_var)\n",
    "        \n",
    "#         trunc_reg = TruncatedRegression(phi=phi, alpha=alpha, args=args, bias=args.bias, var=ch.ones(1))\n",
    "#         st = datetime.datetime.now()\n",
    "#         known_emp_results = trunc_reg.fit(x_trunc, y_trunc)\n",
    "#         w, w0 = (known_emp_results.weight.detach().cpu()), known_emp_results.bias.detach().cpu()[..., None]\n",
    "#         known_emp_params = ch.cat([w, w0], dim=1).flatten()\n",
    "#         # known emp results\n",
    "#         store[TABLE_NAME].update_row({\n",
    "#             'known_emp_r2': r2_score(noised.flatten(), X@w.T + w0), \n",
    "#             'known_emp_param_mse': mse_loss(known_emp_params, gt_params),\n",
    "#             'known_emp_time': int((datetime.datetime.now() - st).total_seconds()), \n",
    "#         })\n",
    "        \n",
    "        \"\"\"\n",
    "        Run dataset on truncated regression with known variance. This means that we want to standardize \n",
    "        our dependent variable by the true noise variance. \n",
    "        \"\"\"\n",
    "        # standardize y trunc by the empirical noise variance\n",
    "        stand_y_trunc = y_trunc / math.sqrt(noise_var)\n",
    "        # standardize noised by the empirical noise variance\n",
    "        stand_noised = noised / math.sqrt(noise_var)\n",
    "        trunc_reg = trunc_reg = TruncatedRegression(phi=phi, alpha=alpha, bias=args.bias, unknown=False, bs=args.bs, n=100, tol=args.tol, steps=args.steps)\n",
    "        st = datetime.datetime.now()\n",
    "        known_results = trunc_reg.fit(x_trunc_norm, stand_y_trunc)\n",
    "        w, w0 = (known_results.weight.detach().cpu() * math.sqrt(noise_var)) / beta, known_results.bias.detach().cpu()[..., None] * math.sqrt(noise_var)\n",
    "        known_params = ch.cat([w, w0], dim=1).flatten()\n",
    "        # known results\n",
    "        store[TABLE_NAME].update_row({\n",
    "            'known_r2': r2_score(noised.flatten(), X@w.T + w0), \n",
    "            'known_param_mse': mse_loss(known_params, gt_params),\n",
    "            'known_time': int((datetime.datetime.now() - st).total_seconds()), \n",
    "        })\n",
    "        \n",
    "        \n",
    "        # truncated regression with unknown variance\n",
    "        trunc_reg = TruncatedRegression(phi=phi, alpha=alpha, bias=args.bias, unknown=True, bs=args.bs, n=100, tol=args.tol, steps=args.steps)\n",
    "        st = datetime.datetime.now()\n",
    "        unknown_results = trunc_reg.fit(x_trunc_norm, emp_stand_y_trunc)\n",
    "\n",
    "        var_ = unknown_results.lambda_.inverse()\n",
    "        unknown_var = var_ * ols_var\n",
    "        w, w0 = (((unknown_results.weight * var_) * ch.sqrt(ols_var)) / beta).detach(), ((unknown_results.bias * ch.sqrt(ols_var))).detach()\n",
    "        unknown_params = ch.cat([w, w0], dim=1).flatten()\n",
    "        print(\"unknown params: \", unknown_params)\n",
    "        print(\"gt params: \", gt_params)\n",
    "        print(\"ols params: \", ols_params)\n",
    "        print(\"unknown mse: \", mse_loss(unknown_params, gt_params))\n",
    "        print(\"ols mse: \", mse_loss(ols_params, gt_params))\n",
    "        \n",
    "        # known emp results\n",
    "        store[TABLE_NAME].update_row({\n",
    "            'unknown_r2': r2_score(noised.flatten(), X@w.T + w0), \n",
    "            'unknown_param_mse': mse_loss(unknown_params, gt_params),\n",
    "            'unknown_var_l1': float(ch.abs(unknown_var - noise_var)),\n",
    "            'unknown_time': int((datetime.datetime.now() - st).total_seconds()), \n",
    "        })\n",
    "        \n",
    "        \n",
    "        # add additional exp data to store\n",
    "        store[TABLE_NAME].update_row({ \n",
    "            'alpha': float(alpha.flatten()),\n",
    "            'num_samples': x_trunc.size(0),\n",
    "            'noise_scale': noise_var, \n",
    "        })\n",
    "\n",
    "        # append row to table\n",
    "        store[TABLE_NAME].flush_row()\n",
    "    store.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 167.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ols_r2</th>\n",
       "      <th>ols_param_mse</th>\n",
       "      <th>ols_var_l1</th>\n",
       "      <th>known_r2</th>\n",
       "      <th>known_param_mse</th>\n",
       "      <th>known_time</th>\n",
       "      <th>unknown_r2</th>\n",
       "      <th>unknown_param_mse</th>\n",
       "      <th>unknown_var_l1</th>\n",
       "      <th>unknown_time</th>\n",
       "      <th>alpha</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>noise_scale</th>\n",
       "      <th>exp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.825877</td>\n",
       "      <td>0.090879</td>\n",
       "      <td>0.161282</td>\n",
       "      <td>0.900431</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>2</td>\n",
       "      <td>0.902417</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4436</td>\n",
       "      <td>4436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b16c5916-334e-463f-a139-7e7319c5a7d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.625891</td>\n",
       "      <td>0.248922</td>\n",
       "      <td>0.539320</td>\n",
       "      <td>0.812587</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817055</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.027418</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>4499</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b16c5916-334e-463f-a139-7e7319c5a7d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.476504</td>\n",
       "      <td>0.411766</td>\n",
       "      <td>0.950132</td>\n",
       "      <td>0.749884</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>2</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.014123</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4463</td>\n",
       "      <td>4463</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b16c5916-334e-463f-a139-7e7319c5a7d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.336984</td>\n",
       "      <td>0.581966</td>\n",
       "      <td>1.516841</td>\n",
       "      <td>0.613062</td>\n",
       "      <td>0.102531</td>\n",
       "      <td>0</td>\n",
       "      <td>0.694725</td>\n",
       "      <td>0.007412</td>\n",
       "      <td>0.329541</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4457</td>\n",
       "      <td>4457</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b16c5916-334e-463f-a139-7e7319c5a7d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.220827</td>\n",
       "      <td>0.765942</td>\n",
       "      <td>2.060451</td>\n",
       "      <td>0.639502</td>\n",
       "      <td>0.016978</td>\n",
       "      <td>2</td>\n",
       "      <td>0.646315</td>\n",
       "      <td>0.011085</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4475</td>\n",
       "      <td>4475</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b16c5916-334e-463f-a139-7e7319c5a7d5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ols_r2  ols_param_mse  ols_var_l1  known_r2  known_param_mse  known_time  \\\n",
       "0  0.825877       0.090879    0.161282  0.900431         0.001991           2   \n",
       "1  0.625891       0.248922    0.539320  0.812587         0.003113           1   \n",
       "2  0.476504       0.411766    0.950132  0.749884         0.004383           2   \n",
       "3  0.336984       0.581966    1.516841  0.613062         0.102531           0   \n",
       "4  0.220827       0.765942    2.060451  0.639502         0.016978           2   \n",
       "\n",
       "   unknown_r2  unknown_param_mse  unknown_var_l1  unknown_time   alpha  \\\n",
       "0    0.902417           0.000221        0.021800             3  0.4436   \n",
       "1    0.817055           0.000727        0.027418             3  0.4499   \n",
       "2    0.753074           0.000389        0.014123             3  0.4463   \n",
       "3    0.694725           0.007412        0.329541             3  0.4457   \n",
       "4    0.646315           0.011085        0.033900             3  0.4475   \n",
       "\n",
       "   num_samples  noise_scale                                exp_id  \n",
       "0         4436          1.0  b16c5916-334e-463f-a139-7e7319c5a7d5  \n",
       "1         4499          2.0  b16c5916-334e-463f-a139-7e7319c5a7d5  \n",
       "2         4463          3.0  b16c5916-334e-463f-a139-7e7319c5a7d5  \n",
       "3         4457          4.0  b16c5916-334e-463f-a139-7e7319c5a7d5  \n",
       "4         4475          5.0  b16c5916-334e-463f-a139-7e7319c5a7d5  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store.close()\n",
    "reader = CollectionReader(OUT_DIR + EXP)\n",
    "logs = reader.df(TABLE_NAME)\n",
    "reader.close()\n",
    "logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_logs = pd.DataFrame(columns=logs.columns)\n",
    "for var in range(1, 21):\n",
    "    noise_scale = logs[logs['noise_scale'] == var].reset_index()\n",
    "    noise_scale.drop(index=noise_scale[['unknown_param_mse', 'unknown_var_l1']].sum(1).idxmax(), inplace=True)\n",
    "    noise_scale.drop(index=noise_scale[['unknown_param_mse', 'unknown_var_l1']].sum(1).idxmin(), inplace=True)\n",
    "    noise_scale.drop(index=noise_scale[['unknown_param_mse', 'unknown_var_l1']].sum(1).idxmax(), inplace=True)\n",
    "    noise_scale.drop(index=noise_scale[['unknown_param_mse', 'unknown_var_l1']].sum(1).idxmin(), inplace=True)\n",
    "    cleaned_logs = pd.concat([cleaned_logs, noise_scale])\n",
    "cleaned_logs = cleaned_logs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ols_r2</th>\n",
       "      <th>ols_param_mse</th>\n",
       "      <th>ols_var_l1</th>\n",
       "      <th>known_r2</th>\n",
       "      <th>known_param_mse</th>\n",
       "      <th>known_time</th>\n",
       "      <th>unknown_r2</th>\n",
       "      <th>unknown_param_mse</th>\n",
       "      <th>unknown_var_l1</th>\n",
       "      <th>unknown_time</th>\n",
       "      <th>alpha</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>noise_scale</th>\n",
       "      <th>exp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.953869</td>\n",
       "      <td>0.011049</td>\n",
       "      <td>0.085401</td>\n",
       "      <td>0.957999</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.591293</td>\n",
       "      <td>3.518955</td>\n",
       "      <td>0.066915</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5458</td>\n",
       "      <td>2729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fe616041-0d1d-403a-86a3-de0130fba30d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.971371</td>\n",
       "      <td>0.014418</td>\n",
       "      <td>0.065293</td>\n",
       "      <td>0.958059</td>\n",
       "      <td>0.021575</td>\n",
       "      <td>1</td>\n",
       "      <td>0.452888</td>\n",
       "      <td>2.046007</td>\n",
       "      <td>0.065323</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5036</td>\n",
       "      <td>2518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9e560f1b-f082-4e42-a3a9-93bab7d2bd34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966528</td>\n",
       "      <td>0.019166</td>\n",
       "      <td>0.065895</td>\n",
       "      <td>0.971150</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>2</td>\n",
       "      <td>0.167991</td>\n",
       "      <td>2.847439</td>\n",
       "      <td>0.059922</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>feed8927-ecc3-4d39-9760-ca106071e3af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.957883</td>\n",
       "      <td>0.012880</td>\n",
       "      <td>0.059511</td>\n",
       "      <td>0.962427</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.444422</td>\n",
       "      <td>3.657547</td>\n",
       "      <td>0.036958</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>2686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cda7d55f-08bd-444a-9b82-45a626fe7139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.940727</td>\n",
       "      <td>0.012825</td>\n",
       "      <td>0.092347</td>\n",
       "      <td>0.947373</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.793896</td>\n",
       "      <td>5.163057</td>\n",
       "      <td>0.060686</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5804</td>\n",
       "      <td>2902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84941efd-1646-42ab-b644-374b9338e788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.960335</td>\n",
       "      <td>0.008530</td>\n",
       "      <td>0.061928</td>\n",
       "      <td>0.959485</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.981114</td>\n",
       "      <td>5.049184</td>\n",
       "      <td>0.036888</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5482</td>\n",
       "      <td>2741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9e765182-ce98-4641-a732-c72cf2dde33e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972368</td>\n",
       "      <td>0.007703</td>\n",
       "      <td>0.027631</td>\n",
       "      <td>0.935219</td>\n",
       "      <td>0.030958</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.343707</td>\n",
       "      <td>8.530482</td>\n",
       "      <td>0.028357</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5306</td>\n",
       "      <td>2653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>837fefe0-dc5f-48c2-bc46-f63f9f66c068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.938778</td>\n",
       "      <td>0.033326</td>\n",
       "      <td>0.085147</td>\n",
       "      <td>0.939374</td>\n",
       "      <td>0.030894</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.039236</td>\n",
       "      <td>3.762332</td>\n",
       "      <td>0.036914</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>2645</td>\n",
       "      <td>2.0</td>\n",
       "      <td>837fefe0-dc5f-48c2-bc46-f63f9f66c068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950464</td>\n",
       "      <td>0.011591</td>\n",
       "      <td>0.081339</td>\n",
       "      <td>0.952515</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.962248</td>\n",
       "      <td>6.429024</td>\n",
       "      <td>0.065298</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5674</td>\n",
       "      <td>2837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37160d66-0953-4352-973a-5d2c59b9e00d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.970826</td>\n",
       "      <td>0.015208</td>\n",
       "      <td>0.117910</td>\n",
       "      <td>0.973600</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.456412</td>\n",
       "      <td>5.433389</td>\n",
       "      <td>0.119912</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4280</td>\n",
       "      <td>2140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0f6e6e1c-3620-47b8-82db-053b2108c3cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.963489</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.038866</td>\n",
       "      <td>0.952987</td>\n",
       "      <td>0.011571</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.392460</td>\n",
       "      <td>9.462757</td>\n",
       "      <td>0.042531</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5530</td>\n",
       "      <td>2765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a53a13d8-6095-4758-af9d-230bf7e1f319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.924356</td>\n",
       "      <td>0.028482</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.068302</td>\n",
       "      <td>2.921065</td>\n",
       "      <td>0.169561</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5506</td>\n",
       "      <td>2753</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a53a13d8-6095-4758-af9d-230bf7e1f319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.923649</td>\n",
       "      <td>0.018162</td>\n",
       "      <td>0.072658</td>\n",
       "      <td>0.934555</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.666605</td>\n",
       "      <td>2.554775</td>\n",
       "      <td>0.033070</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5638</td>\n",
       "      <td>2819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8f40c8a6-b903-499b-a901-a7dc16e9ba30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ols_r2  ols_param_mse  ols_var_l1  known_r2  known_param_mse  known_time  \\\n",
       "0  0.953869       0.011049    0.085401  0.957999         0.003468           0   \n",
       "0  0.971371       0.014418    0.065293  0.958059         0.021575           1   \n",
       "0  0.966528       0.019166    0.065895  0.971150         0.005870           2   \n",
       "0  0.957883       0.012880    0.059511  0.962427         0.003392           1   \n",
       "0  0.940727       0.012825    0.092347  0.947373         0.002698           0   \n",
       "0  0.960335       0.008530    0.061928  0.959485         0.005150           2   \n",
       "0  0.972368       0.007703    0.027631  0.935219         0.030958           2   \n",
       "1  0.938778       0.033326    0.085147  0.939374         0.030894           2   \n",
       "0  0.950464       0.011591    0.081339  0.952515         0.008678           0   \n",
       "0  0.970826       0.015208    0.117910  0.973600         0.005665           2   \n",
       "0  0.963489       0.008237    0.038866  0.952987         0.011571           2   \n",
       "1  0.924356       0.028482    0.236000  0.934211         0.003876           2   \n",
       "0  0.923649       0.018162    0.072658  0.934555         0.003861           0   \n",
       "\n",
       "   unknown_r2  unknown_param_mse  unknown_var_l1  unknown_time   alpha  \\\n",
       "0   -0.591293           3.518955        0.066915             2  0.5458   \n",
       "0    0.452888           2.046007        0.065323             2  0.5036   \n",
       "0    0.167991           2.847439        0.059922             0  0.4500   \n",
       "0   -0.444422           3.657547        0.036958             1  0.5372   \n",
       "0   -1.793896           5.163057        0.060686             2  0.5804   \n",
       "0   -0.981114           5.049184        0.036888             2  0.5482   \n",
       "0   -1.343707           8.530482        0.028357             2  0.5306   \n",
       "1   -0.039236           3.762332        0.036914             2  0.5290   \n",
       "0   -1.962248           6.429024        0.065298             2  0.5674   \n",
       "0   -0.456412           5.433389        0.119912             2  0.4280   \n",
       "0   -2.392460           9.462757        0.042531             2  0.5530   \n",
       "1   -0.068302           2.921065        0.169561             2  0.5506   \n",
       "0   -0.666605           2.554775        0.033070             2  0.5638   \n",
       "\n",
       "   num_samples  noise_scale                                exp_id  \n",
       "0         2729          1.0  fe616041-0d1d-403a-86a3-de0130fba30d  \n",
       "0         2518          1.0  9e560f1b-f082-4e42-a3a9-93bab7d2bd34  \n",
       "0         2250          1.0  feed8927-ecc3-4d39-9760-ca106071e3af  \n",
       "0         2686          1.0  cda7d55f-08bd-444a-9b82-45a626fe7139  \n",
       "0         2902          1.0  84941efd-1646-42ab-b644-374b9338e788  \n",
       "0         2741          1.0  9e765182-ce98-4641-a732-c72cf2dde33e  \n",
       "0         2653          1.0  837fefe0-dc5f-48c2-bc46-f63f9f66c068  \n",
       "1         2645          2.0  837fefe0-dc5f-48c2-bc46-f63f9f66c068  \n",
       "0         2837          1.0  37160d66-0953-4352-973a-5d2c59b9e00d  \n",
       "0         2140          1.0  0f6e6e1c-3620-47b8-82db-053b2108c3cf  \n",
       "0         2765          1.0  a53a13d8-6095-4758-af9d-230bf7e1f319  \n",
       "1         2753          2.0  a53a13d8-6095-4758-af9d-230bf7e1f319  \n",
       "0         2819          1.0  8f40c8a6-b903-499b-a901-a7dc16e9ba30  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs[logs['unknown_param_mse'] > 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = cleaned_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = logs[logs['noise_scale'] > 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'noise_scale'), Text(0, 0.5, 'L1 Distance to Ground-Truth')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=logs, x='noise_scale', y='ols_param_mse', label='ols')\n",
    "# sns.lineplot(data=logs, x='noise_scale', y='known_emp_param_mse', label='known emp')\n",
    "ax = sns.lineplot(data=logs, x='noise_scale', y='known_param_mse', label='known')\n",
    "ax = sns.lineplot(data=logs, x='noise_scale', y='unknown_param_mse', label='unknown')\n",
    "ax.set(xlabel='noise_scale', ylabel='L2 Distance to Ground-Truth')\n",
    "plt.show()\n",
    "\n",
    "sns.lineplot(data=logs, x='noise_scale', y='ols_var_l1', label='ols')\n",
    "ax = sns.lineplot(data=logs, x='noise_scale', y='unknown_var_l1', label='unknown')\n",
    "ax.set(xlabel='noise_scale', ylabel='L1 Distance to Ground-Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.9077]], grad_fn=<InverseBackward>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.lambda_.inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.6700]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.gca(projection='3d')\n",
    "# data = ch.from_numpy(np.linspace(-3.0, 3.0, 100)).unsqueeze(1).float()\n",
    "\n",
    "ax.scatter3D(X[indices][:,0], X[indices][:,1], noised[indices], color=\"green\", alpha=.1)\n",
    "ax.scatter3D(x_trunc[:,0], x_trunc[:,1], y_trunc, color=\"red\", alpha=.75)\n",
    "\n",
    "ax.view_init(10, -150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_logs = pd.DataFrame(columns=logs.columns)\n",
    "for var in range(1, 21):\n",
    "    noise_scale = logs[logs['noise_scale'] == var].reset_index()\n",
    "    noise_scale.drop(index=noise_scale[['unknown_param_mse', 'unknown_var_mse']].sum(1).idxmax(), inplace=True)\n",
    "    cleaned_logs = pd.concat([cleaned_logs, noise_scale])\n",
    "cleaned_logs = cleaned_logs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6702)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.sample(ch.Size([10000])).norm(dim=-1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = Uniform(-1/d, 1/d)\n",
    "\n",
    "s = u.sample(ch.Size([10000, d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.0481],\n",
       "        [-4.1819],\n",
       "        [-3.8256],\n",
       "        ...,\n",
       "        [ 0.5905],\n",
       "        [-2.1130],\n",
       "        [-1.7292]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_trunc@w+w0 - y_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.3957]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.5118]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.5949]], requires_grad=True))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.weight, gt.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1744, 2.7350])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5809])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch.abs((x_trunc@w + w0) - y_trunc).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.8567])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((X@w + w0) - noised).var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.2200])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_trunc@w + w0 - y_trunc).var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd30c687dc0>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, noised)\n",
    "plt.scatter(x_trunc, y_trunc)\n",
    "plt.plot(x_trunc, x_trunc@w + w0, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Tensor(np.expand_dims(np.linspace(-3, 3), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_half, y_half = X[:5000], noised[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.1086])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_half@w + w0 - y_half).var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.2200])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_trunc@w - y_trunc).var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1702]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = ch.randn(100, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False],\n",
       "         [False],\n",
       "         [False],\n",
       "         ...,\n",
       "         [False],\n",
       "         [False],\n",
       "         [ True]],\n",
       "\n",
       "        [[ True],\n",
       "         [False],\n",
       "         [False],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False]],\n",
       "\n",
       "        [[ True],\n",
       "         [False],\n",
       "         [ True],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[False],\n",
       "         [ True],\n",
       "         [False],\n",
       "         ...,\n",
       "         [False],\n",
       "         [ True],\n",
       "         [ True]],\n",
       "\n",
       "        [[False],\n",
       "         [False],\n",
       "         [False],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False]],\n",
       "\n",
       "        [[ True],\n",
       "         [False],\n",
       "         [ True],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [False]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand > 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ch.nn.Linear(in_features=1, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'Linear' object has no attribute 'copy_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0f2c0803ce64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    779\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'Linear' object has no attribute 'copy_'"
     ]
    }
   ],
   "source": [
    "test.copy_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch.ones(1).clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
