{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi Synthetic Experiment \n",
    "Semi-synthetic dataset experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../..')\n",
    "sys.path.append('/opt/anaconda3/lib/python3.7/site-packages')\n",
    "\n",
    "import cox\n",
    "from cox.store import Store\n",
    "from cox.utils import Parameters\n",
    "from cox.readers import CollectionReader\n",
    "import torch as ch\n",
    "from torch import Tensor\n",
    "import torch.linalg as LA\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.datasets import load_boston\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import subprocess\n",
    "\n",
    "from delphi import oracle \n",
    "from delphi.stats.linear_regression import TruncatedRegression\n",
    "\n",
    "# set environment variable so that stores can create output files\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "\n",
    "TABLE_NAME = 'logs'\n",
    "COMMAND = 'RScript'\n",
    "\n",
    "# commands and arguments\n",
    "COMMAND = 'Rscript'\n",
    "PATH2SCRIPT = './truncreg.R'\n",
    "TMP_FILE = 'tmp.csv'\n",
    "RESULT_FILE = 'result.csv'\n",
    "\n",
    "# mean squared error loss\n",
    "mse_loss = ch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset into Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = '/Users/patroklos/Desktop/research/'\n",
    "# df = pd.read_excel(dataset)\n",
    "# df.head()\n",
    "\n",
    "bunch = load_boston()\n",
    "data = np.concatenate([bunch['data'], np.expand_dims(bunch['target'], 1)], axis=1)\n",
    "df = pd.DataFrame(data, columns=bunch['feature_names'].tolist() + ['MEDV'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we want to do is check if there are any columns with NaN values in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "nan_values = df.isna()\n",
    "nan_columns = nan_values.any()\n",
    "\n",
    "columns_with_nan = df.columns[nan_columns].tolist()\n",
    "print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are two columsn with NaN values in them. We will fill the values of these columns with the mean of the rest of the data for the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(columns_with_nan) > 0: \n",
    "    df['Ozone'].replace(np.nan, df['Ozone'].dropna().mean(), inplace=True)\n",
    "    df['Solar.R'].replace(np.nan, df['Solar.R'].dropna().mean(), inplace=True)\n",
    "# drop Unnamed: 0 column if in dataframe\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ZN', 'CHAS', 'NOX', 'RM', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "X, y = df[['ZN', 'CHAS', 'NOX', 'RM', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']].to_numpy(), df['MEDV'].to_numpy().reshape(-1, 1)\n",
    "# X, y = df[['X2 house age', 'X4 number of convenience stores', 'X3 distance to the nearest MRT station', 'X6 longitude']].to_numpy(), df['Y house price of unit area'][...,None]\n",
    "\n",
    "X, y = Tensor(X), Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  1.,  1.,  0.,  5.,  2.,  1.,  6.,  3.,  0.,  3.,  3.,  5.,\n",
       "         3.,  4.,  6.,  3.,  5., 14.,  9.,  9.,  6., 11.,  8.,  6.,  6.,\n",
       "         8., 10.,  9.,  9., 15., 13., 20., 16., 19., 10., 14., 19., 13.,\n",
       "        15., 21., 11., 14., 12., 14.,  1.,  0.,  4.,  5.,  2.,  6.,  3.,\n",
       "         7.,  4.,  3.,  6.,  2.,  3.,  4.,  3.,  4.,  2.,  7.,  2.,  1.,\n",
       "         1.,  5.,  3.,  1.,  4.,  1.,  3.,  1.,  1.,  1.,  0.,  0.,  1.,\n",
       "         0.,  0.,  1.,  1.,  1.,  0.,  2.,  1.,  2.,  0.,  1.,  1.,  0.,\n",
       "         1.,  1.,  0.,  0.,  0.,  2.,  1.,  0., 16.]),\n",
       " array([ 5.  ,  5.45,  5.9 ,  6.35,  6.8 ,  7.25,  7.7 ,  8.15,  8.6 ,\n",
       "         9.05,  9.5 ,  9.95, 10.4 , 10.85, 11.3 , 11.75, 12.2 , 12.65,\n",
       "        13.1 , 13.55, 14.  , 14.45, 14.9 , 15.35, 15.8 , 16.25, 16.7 ,\n",
       "        17.15, 17.6 , 18.05, 18.5 , 18.95, 19.4 , 19.85, 20.3 , 20.75,\n",
       "        21.2 , 21.65, 22.1 , 22.55, 23.  , 23.45, 23.9 , 24.35, 24.8 ,\n",
       "        25.25, 25.7 , 26.15, 26.6 , 27.05, 27.5 , 27.95, 28.4 , 28.85,\n",
       "        29.3 , 29.75, 30.2 , 30.65, 31.1 , 31.55, 32.  , 32.45, 32.9 ,\n",
       "        33.35, 33.8 , 34.25, 34.7 , 35.15, 35.6 , 36.05, 36.5 , 36.95,\n",
       "        37.4 , 37.85, 38.3 , 38.75, 39.2 , 39.65, 40.1 , 40.55, 41.  ,\n",
       "        41.45, 41.9 , 42.35, 42.8 , 43.25, 43.7 , 44.15, 44.6 , 45.05,\n",
       "        45.5 , 45.95, 46.4 , 46.85, 47.3 , 47.75, 48.2 , 48.65, 49.1 ,\n",
       "        49.55, 50.  ], dtype=float32),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y.T, bins=100, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Correlation Matrix\n",
    "Create a correlation matrix to see which features are correlated to air quality data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZN</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ZN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.360445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CHAS</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.175260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NOX</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.427321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RM</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.695360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DIS</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.249929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RAD</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>-0.381626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>-0.468536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.507787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>0.333461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.737663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MEDV</td>\n",
       "      <td>0.360445</td>\n",
       "      <td>0.175260</td>\n",
       "      <td>-0.427321</td>\n",
       "      <td>0.695360</td>\n",
       "      <td>0.249929</td>\n",
       "      <td>-0.381626</td>\n",
       "      <td>-0.468536</td>\n",
       "      <td>-0.507787</td>\n",
       "      <td>0.333461</td>\n",
       "      <td>-0.737663</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ZN      CHAS       NOX        RM       DIS       RAD       TAX  \\\n",
       "ZN       1.000000 -0.042697 -0.516604  0.311991  0.664408 -0.311948 -0.314563   \n",
       "CHAS    -0.042697  1.000000  0.091203  0.091251 -0.099176 -0.007368 -0.035587   \n",
       "NOX     -0.516604  0.091203  1.000000 -0.302188 -0.769230  0.611441  0.668023   \n",
       "RM       0.311991  0.091251 -0.302188  1.000000  0.205246 -0.209847 -0.292048   \n",
       "DIS      0.664408 -0.099176 -0.769230  0.205246  1.000000 -0.494588 -0.534432   \n",
       "RAD     -0.311948 -0.007368  0.611441 -0.209847 -0.494588  1.000000  0.910228   \n",
       "TAX     -0.314563 -0.035587  0.668023 -0.292048 -0.534432  0.910228  1.000000   \n",
       "PTRATIO -0.391679 -0.121515  0.188933 -0.355501 -0.232471  0.464741  0.460853   \n",
       "B        0.175520  0.048788 -0.380051  0.128069  0.291512 -0.444413 -0.441808   \n",
       "LSTAT   -0.412995 -0.053929  0.590879 -0.613808 -0.496996  0.488676  0.543993   \n",
       "MEDV     0.360445  0.175260 -0.427321  0.695360  0.249929 -0.381626 -0.468536   \n",
       "\n",
       "          PTRATIO         B     LSTAT      MEDV  \n",
       "ZN      -0.391679  0.175520 -0.412995  0.360445  \n",
       "CHAS    -0.121515  0.048788 -0.053929  0.175260  \n",
       "NOX      0.188933 -0.380051  0.590879 -0.427321  \n",
       "RM      -0.355501  0.128069 -0.613808  0.695360  \n",
       "DIS     -0.232471  0.291512 -0.496996  0.249929  \n",
       "RAD      0.464741 -0.444413  0.488676 -0.381626  \n",
       "TAX      0.460853 -0.441808  0.543993 -0.468536  \n",
       "PTRATIO  1.000000 -0.177383  0.374044 -0.507787  \n",
       "B       -0.177383  1.000000 -0.366087  0.333461  \n",
       "LSTAT    0.374044 -0.366087  1.000000 -0.737663  \n",
       "MEDV    -0.507787  0.333461 -0.737663  1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = df.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x1a30e7af50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1980x1980 with 132 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take see if there is a linear relationship between solar.R and Ozone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2:  0.7348380172045117\n",
      "ground-truth variance:  22.429183959960938\n"
     ]
    }
   ],
   "source": [
    "data = ch.linspace(0, 1500, 100).reshape(100, 1)\n",
    "\n",
    "gt_ols = LinearRegression()\n",
    "gt_ols.fit(X, y)\n",
    "score = gt_ols.score(X, y)\n",
    "print(\"r^2: \", score)\n",
    "gt_var = (y - gt_ols.predict(X)).var(0)\n",
    "print('ground-truth variance: ', float(gt_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we standardize our empirical data and generate new ols estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = ch.randn(X.shape[1], 2)\n",
    "x_transform = X@random\n",
    "w_transform = Tensor(gt_ols.coef_)@random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "# X_ = np.arange(-50, 50, 0.25)\n",
    "# Y = np.arange(-50, 50, 0.25)\n",
    "\n",
    "x_max, x_min = x_transform.max(0)[0], x_transform.min(0)[0]\n",
    "X_ = np.arange(x_min[0], x_max[0], 5.0)\n",
    "Y = np.arange(x_min[1], x_max[1], 5.0)\n",
    "X_, Y = np.meshgrid(X_, Y) \n",
    "\n",
    "# pred = Tensor([])\n",
    "# for i in range(X_.shape[0]): \n",
    "#     input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "#     pred = ch.cat([pred, input_@w_transform.T + ols.intercept_], 1)\n",
    "# ax.plot_surface(X_, Y, pred.numpy().T, alpha=.15, color='green')\n",
    "\n",
    "actual = Tensor([])\n",
    "for i in range(X_.shape[0]): \n",
    "    input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "    actual = ch.cat([actual, input_@w_transform.T + gt_ols.intercept_], 1)\n",
    "ax.plot_surface(X_, Y, actual.numpy().T, alpha=.15, color='blue')\n",
    "\n",
    "\n",
    "# emp = Tensor([])\n",
    "# for i in range(X_.shape[0]): \n",
    "#     input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "#     emp = ch.cat([emp, Tensor(ols.predict(input_))], 1)\n",
    "# ax.plot_surface(X_, Y, emp.numpy().T, alpha=.15, color='red')\n",
    "\n",
    "ax.scatter3D(x_transform[:,0], x_transform[:,1], y, color='grey', label='S', alpha=.4)\n",
    "# ax.scatter3D(x_trunc[:,0], x_trunc[:,1], y_trunc, color='grey', label='S', alpha=.4)\n",
    "ax.view_init(0, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x = StandardScaler().fit_transform(X.T)\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "pca.fit(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_components = pca.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_ols = LinearRegression()\n",
    "pca_ols.fit(principal_components, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAIuCAYAAAC7EdIKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzd6W8j92E+8GdmSA7vQyIlUSutdrX3elfeXduJ3Rb5uShaJEXQIECbGn3jFwHapH2TvGqABkX6KklRBOgf4KJG0Lxo86ZB2gJB4uRNDNtrew/vvav7oESKEu+5Z34vlJnVQUmURF3c5wMIkobD4XcokfPwewqO44CIiIiok4mHXQAiIiKi/cbAQ0RERB2PgYeIiIg6HgMPERERdTwGHiIiIup4DDxERETU8Xzb3M4x60RERHRcCJvdwBoeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcdj4CEiIqKOx8BDREREHY+Bh4iIiDoeAw8RERF1PAYeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcdj4CEiIqKOx8BDREREHY+Bh4iIiDoeAw8RERF1PAYeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcdj4CEiIqKOx8BDREREHY+Bh4iIiDoeAw8RERF1PAYeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcdj4CEiIqKOx8BDREREHY+Bh4iIiDoeAw8RERF1PAYeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcdj4CEiIqKOx8BDREREHY+Bh4iIiDoeAw8RERF1PAYeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcdj4CEiIqKOx8BDREREHY+Bh4iIiDoeAw8RERF1PAYeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcdj4CEiIqKOx8BDREREHY+Bh4iIiDoeAw8RERF1PAYeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcdj4CEiIqKOx8BDREREHY+Bh4iIiDoeAw8RERF1PAYeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcdj4CEiIqKOx8BDREREHY+Bh4iIiDoeAw8RERF1PAYeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcdj4CEiIqKOx8BDREREHY+Bh4iIiDoeAw8RERF1PAYeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcdj4CEiIqKOx8BDREREHY+Bh4iIiDoeAw8RERF1PAYeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcdj4CEiIqKOx8BDREREHY+Bh4iIiDoeAw8RERF1PAYeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcdj4CEiIqKOx8BDREREHY+Bh4iIiDoeAw8RERF1PAYeIiIi6ngMPERERNTxGHiIiIio4zHwEBERUcfzHXYBiIiIqH0cx4HjOGt+Xv9l2/aan4PBIAKBwCGXfH8x8BARER0xuwktALzvWx1XEAQA8L4DwJe//GX84he/2KezORoYeIiIiPbB6nCy/vdWQ0sul0MikUA4HF5z3GahRRAEiKK4YXsrisXi7k7yGGHgISIi2sRWoWV1QFEUBYIgwOfzrdl/q+O2Elrq9TpisRgkSdqP03uhMPDsgmEYsCxrzbb1/7Drt62+bf32zfZrZRsREW2t1dCyvsZlJ6Flenoa8Xgc3d3da97n+b59dDDw7EKzNtLVL4xWXijrCYLQ0n0EQcDCwgJ6e3u931fftn5bK9t3s42I6CCtbwpavW0nocW2bTx9+hQXLlzwjrFZTctOQou7v1s7Q0cPA88ebPUi2E1I2Oo+q1+0Y2NjXuA5yKDlPsbS0hLS6fSG2xi0iGgzzWpXVv/eLLQYhoFKpYJkMrntsXcSWhRFYRPRC4iB55hoJTRstX0nx16t2aejZ8+eobu7e80+Ow1auy1bvV6HLMvw+/0MWkQHbLvQYlkWBEHYc/OQ+13TNORyOXR1dfF1SXvGwENb2kuY2IvN3hwnJyfR39+PZDK5b0FrsxBUr9cRCAS8uSqaPQd7CVV8Q6eDsJuallZDyyeffIJXXnkFwNr3itVfO7HbEUdEzTDw0JG0VQ3WfnYI3OwN3XEcTE5Ooq+vD6lU6kCDFgDUajXEYrGm++0laPFCcjxtNszZ3bY+pDQLLY1GA+VyGdls1rvfVh9wWgktgiCwqYiOLAYeolW2CwC7/aS6na2CFgDcvXsXb7zxxqEFrVZHHDY7HmuzmttpaNE0DYqiIBqNbvn/0mposW0b9XqdAYVeGAw8REfATkaBtNNRDFrunCbRaPTIB63tQotpmt7AgPUBZqehpdFoYG5uDhcvXtyX/wWiTsfAQ/QCO4ygtVV4chwHuq7j4cOHeOWVVw40aFWrVa82a/U+pml6ZdtJaAGATz/9tG19WvardpHoRcHAQ0QHqpVmQ/f7QQatBw8e4MaNG95MuS5N07xaF/ZpITq+GHiI6IWwk9qsZnO5cEI5ouONr2AiIiLqeAw8RERE1PEYeIiIiKjjsQ8Ptcxd22Z1h07btjE3N4dyuYxwOIzBwUH4fPy3IiKio4VXJmpJoVDAo0ePYFkWisUiVFVFMBjE06dPkcvlIMsyFhcXMTs7i3g8Dr/fj8HBQUSj0cMuOhERbcG2bdi2jZmZGZTLZVSrVbz++uuHXay2Y+ChbTUaDTx48ACRSASiKCKXy+HRo0d46aWXMD8/j0QiAUEQYBgGxsbGkM1moWkanj59is9//vPeyu5ERNRe7gSX7pdlWWt+32y7ZVkAgH/7t3/Dxx9/jOXlZfzt3/4tEokEEokEPv/5z7c0svHUqVOIxWKQJAk+nw8ff/wxlpaW8Jd/+ZeYmJjAqVOn8J//+Z9IpVL7/VRsi4GHttVoNAAAPp8Ptm0jEAigXC5vmNdkaWkJiqLg4cOHEEURwWAQH3zwAf7f//t/SCaTh1F0IqIjy7btbYNKuVyGpmkQRdHb5i7w6gYSn8/nBY71X6FQqOl2URQhCAI+97nPAQDefPNN/OxnP9vVefz6179GOp32fv/BD36AP/qjP8J3vvMd/OAHP8APfvAD/PCHP9zjs7V3DDy0rUAgsGYVZcuyEAqFEAgE0N/fj9nZWQQCAeTzedTrdW++kmq1ing8jsnJyaaBp1qtYnx8HJqmoaenB4ODg5zrhIiOPPf9cHVYURQFtm1D1/UtQ8zqY4iiuGlQkSQJsiyjUqkgnU4jmUx624/6ZJb//d//jd/85jcAgLfffhtvvvkmA89xVa1WMTk5CVEUvS9Jktb8vtXXZvse1Wnj4/E4hoaGMDU15b3QL168CAA4c+YMIpEIisUiwuEwVFX1XsjugofNZrhVVRV37tyBKIrw+/0YGxuDbds4ffp028pdr9fx6aefolQqIZ1O48aNG6jX6ygUCqhUKohGo0ilUujt7T2Sz3u72baNarUKAIhGo2veNPP5PKrVKhKJBLq7u1GpVGAYBgzD2HAcXddRKpXgOA5SqRQCgcCBnQPRXrlLgqiquqsmIPf9zA0q7ndFUQAAwWAQfr+/ac2K+96/E8vLy4hEIgiHw+19ItpEEAT8yZ/8CQRBwN/8zd/gr//6r7GwsIBsNgsAyGazyOfzh1zKFQw8uxAKhTAwMOBd/G3bhmVZ3s/uaKbVv6/+Wr+v+7XV1PfuTK+iKKLRaODWrVttC1rr92kWvE6fPo2enh5omga/3494PA4AEEUR/f39yGQymJmZgWVZqNfr3m0A0N/fv+F8KpUKLMvyOjXH43HMzc21LfDouo5f/epXqFQqkGUZT58+RT6fRzQaRbVaRaVSgd/vRyaTQaVSwfnz59vyuEeVaZq4d+8eSqUSACAWi2FkZAR+vx+3bt3CZ5995i1y2d/fD5/PB0EQMDs7i2KxiO7ubgArQfX27dtQVRXAypv7tWvXEAwGD+3c6MWx1/4qLkVR8OTJk6a1K7IsIxKJNA0rW30wGhsbQzweX9O08yL47W9/i/7+fuTzefzxH/+x92H4KGLg2QWfz+d11D0I7icSNxh99NFHuHDhwrYByr1tdfjaal/39u0WbGw0Grh58+aGsBQMBmEYBgRBgGma8Pv9GBoagqqqmJmZWbNvuVyGoijw+/3e/oIgeG3Vq2u9dmN5eRnlctn7OwUCAeRyOZw9exa6riOZTEJRFEiShLm5OQwNDUGW5V091nEwOzuLUqnkNS2Wy2VMT08jnU7j/v37iMfjkCQJjUYDjx49wmuvvQZZlrGwsIDHjx/jjTfe8AKQ+/wBK7WdMzMzOHv27GGeHh0DrfRXWb9d13WoqoqPPvpoTX+VzfqshMPhpttXv5dYloXbt29jZGTkMJ+OjuF+oO3p6cFXv/pVfPTRR+jt7UUul0M2m0Uul0NPT88hl3IFA88xsH4tH1EUD6160zRN3Lx5E9euXdsQngYHBzE4OIhcLgcA6O3tRTQabRq83I53c3NzAFbeDLPZLO7du7fmuOspioJisbhtbVW1WkWj0fCeN/eTYbVa9WondF2HoigQRRGlUgmhUGjLYx5niqKsaXoKBAJoNBrec+E2b7nfTdOELMuQJMn7u7k/r55nSZIk6Lp+gGdCB61Zf5XNwoqiKPjss8829FcBVt7HtupcK8vyhm26rmNiYgJXrlw5pLOnrdTrddi2jVgshnq9jl/84hf4x3/8R/zZn/0Z3n33XXznO9/Bu+++i6985SuHXVQADDy0Q2748vv98Pv9G25PJpMtf9o/d+4cFhcXYZom4vG410y2lQcPHqC/vx+JRAKO42xaY2UYBgqFAgqFAkRRhGVZa4bHl8tlr0YjFothcXFxy5ovx3GgKAoWFxc3TKy4urmxnX26Vn+5F53d9vNKJBLI5XIIBoMQBAGqqmJwcNCbM6nRaCAcDkPXde/v6vZzSCaTXhDq7u5GLpfz9tE07YWrwj9O3NdIs7BSrVZRrVYxOjq6ZROQ4zgb+qus/lrdX6VYLOLs2bO77q+y3vrQREfLwsICvvrVrwJY+Vv91V/9Fb74xS/itddew9e+9jW88847OHnyJP7rv/7rkEu6goGH2sY0Tdy6dQszMzOQZRk3btxAX1/fpvv7fL4tb99KKytYf/GLX8SjR49QLpeRTqdx/vx5LC0tYW5uzqvRSafTOHnyZEuzQz948ADZbHbNfBLrmxtb6avVrLlxu30bjQY+/PDDbZsbt+sQPzExAUEQkE6noes68vk8Ll26hLt37yKfzyMcDuPzn/88lpeXUa/XEQwGMTg46NWEJZNJnDt3DtPT0xAEARcuXDgy1dWdZn1/Fbd2cn5+fstmoNX9AQVB2DSsACv/L4lEYsf9VTYjSRJCoVBbnwc6uoaHh3Hnzp0N27u7u/GrX/3qEEq0NQYeapubN2/i6dOnCIfDKJfLeO+99/ClL33p0CacCgQCG9rpM5kMMplM2x6jleDVDu+//z7eeOONLfdxg9dm4am/v9+7QAqC4O2bSCTw+7//+9B1HaIowrZtyLIMy7KwsLDgjc5bfVw36E1MTGBiYmJDWfZSq2XbNjRNQ6FQaLmm7KhZ3WxbrVZb6q+y2fwqbgBxhzzrut5yf5WtlMtlWJbFGjp6YTDwUFuYpomZmRlEIhEEAgHIsux1jD0KM2y+CNxP8+2co6NSqeDatWs7us9mNV6t1IAZhgFd12FZFpaWlrxwtVUNWKujG7cLWqqqYmpqygsN7r5uONmuH8v6x/X5fNA0DTMzMxtCSTAY3DSsbPW3mJubw8mTJ3f09yCiFQw81Bbup0r3E6p70WvWz4c6216Dl6ZpqFQquHDhwp7KsVlz42bhSRRFbzi+aZowDAOWZUHXdUiS5PVb28n8Kjdv3sSlS5f2dB5E1B4MPNQWoiji6tWr+Oijj7zJB+PxOE6dOrXpfWzbxtTUFHK5HCRJwvDwMKvXqW122tw4MTHhzUG0mjuS7Sg2nRFR6xh4qG0uXLiAWCyGubk5yLKMM2fObNmBcWZmBuPj44jFYrBtG/fu3cONGzdaGq1FRES0Eww81Fb9/f1NZ1ZuJp/PezOaAitNGaVSiYGHiIjajnW0dGgCgcCazp6WZbHPDxER7QsGHjo0w8PDsG0bpVIJpVIJsVisrUPGiYiIXGzSokMTjUbx6quvolwuQxRFpFKpliYAJCIi2ileXehQBYNBrrRNRET7jk1aRERE1PEYeIiIiKjjsUmLDpWmaVhYWIBlWejq6kIikTjsIhERUQdi4KFDo+s6bt++DVVVIUkSJicncfXqVXR3dx920YiIqMOwSYt2zDAMLC4uolQqbblw43aKxSIURUEikUA0GkUwGMTk5GQbS0pERLSCNTy0I5VKBTMzM94q1T09Pbh06RIEQdjxsWzbXnM/URRhWVY7i0tERASANTy0Q0+fPoUkSUgkEkgkEsjn81heXt7VsVKpFCRJQqPRgKZpqNfrOHHiRJtLTERExMBDO6RpGgRBgOM43mrUhmHs6ljhcBgvv/wyEokEZFnGxYsXkc1m21xiIiIiNmnRDjiOA8dxUCgU4DgO4vE4gsEgotHoro8Zi8Xw0ksvtbGUREREG7GGh1pWKBSg6zpCoRAAYHFxEb29vYhEIodcMiIioq2xhodatry8jGAwiEQigdOnT0PTNHYyJiKiY4E1PNQyWZZhmiYAeH13uA4WEREdBww81LL+/n6Ew2EoioJyuYxAIIDBwcHDLhYREdG22KRFLQsEAnj55ZdRq9Vw5coVxONx+P3+XR3L7fxcKpUQCoWQzWbh8/HfkYiI9gevMLQjPp8P4XB4z8s/TE5OYnx8HIFAAIZhoFgsYmRkBKLISkciImo/Bh46cLZtY2pqColEwgs45XIZ1WqVi4cSEdG+YOChfaGqqjcDc1dXF2RZ9m5z5/NZvxzFXtblIiIi2goDD7VdvV7H7du3YZomHMdBMBjEtWvXvBFdkiShv78fMzMzCIVC0HUdkUgEsVjskEtORESdioGH2m56ehq2bXudkBVFwfz8PE6dOuXtc+bMGQSDQZRKJaTTaZw8eRKSJB1SiYmIqNMx8FDbaZqGfD4P0zS9dbd6enrW7COKIgYHBzmsnYiIDgSHxFDbGIaBZ8+eYWpqCouLi/D5fPD7/dB1HZqmHXbxiIjoBcbAQ23hOA7u37+P2dlZCIIAv9+PSqUCAMhms2yuIiKiQ8XAQ23hzr4cCoXg8/kQCAS8CQUlSUJXV9dhF5GIiF5g7MNDbSGKotc5WRAEmKaJRqOBer2OU6dO4cSJE4ddRCIieoEx8FBbBINBGIYBy7Lg9/sRDAYRi8Vw/fp11u4QEdGhY+ChtnAcB/F4HPF4HIZhIBAIwLZt2La97X0rlQpGR0eh6zp6enowNDTEJSaIiKiteFWhthAEwRt67s6sLIoiIpHIlvdTFAV37tyBpmmQJAkTExOYmJg4gBITEdGLhIGH2ubcuXPo6elBvV6HIAgYGRlBKBTa8j6VSgWWZSEYDMLn8yEej2N+fn7Dfo7jtFRbRERE1AybtKhtfD4fLl26tKP7SJK0Zg0t0zS9GZpdi4uLePz4MUzThKqqyGQybSkvERG9OFjDQ4cqlUohlUqhVCqhXC5DVVWcPXvWu71er+P+/fsIBAKIx+Oo1WqYnJw8xBITEdFxxBoeOlSSJOHq1asoFoswTRPxeBzRaNS7vV6vAwD8fj8AQJZllEqlQykrEREdXww8dChs28b8/Dzq9Tqi0Sh6e3ubjszy+/2wbRuO43jz+wQCgUMoMRERHWcMPHTgHMfB48ePsbCwAL/fj9nZWVQqFVy4cGHDvslkEn19fVhYWPAWIh0eHj6EUhMR0XHGwEMHTlVV5PN5JBIJL8TkcjkMDQ0hGAyu2VcQBFy8eBH9/f2wLAvT09NrmryIiIhawcBDB84dlSUIgvfd/bkZQRCQSCQAoOmQ9b2UY2lpCbquIxwOe49BRESdh4GHDlwoFEIikUC5XEYwGISiKOju7oYsywdWBsdx8OTJE8zNzUEURTiOg/Pnz6O/v//AykBERAeHgYcOnCAIeOmllzA1NYVqtYqenh4MDg5uWcvTbvV6HfPz80gmkxAEAZZl4dmzZ+jt7YUkSQdWDiIiOhgMPHQo/H4/zpw5c2iPb1kWgOfNau4EiLZtM/AQEXUgTjxIL6RwOAxZllGv12FZFsrlMpLJpDffDxERdRYGHnoh+f1+jIyMIBqNQtd19Pb24vLly4ddLCIi2ids0qKWOI6DSqUCwzBgmuZhF6ctwuEwXn755cMuBhHRkWJZVkc27TPw0LYcx8GjR4+wsLAAYGVoeK1W43w4RET7xLZt2LYNy7Kg6zoajcaabe7Pzb5avR0A3nnnHdy8eROFQgE3btyAIAjw+Xz44IMPWh5IYlkWXn31VZw4cQI///nPMT4+jrfeegtLS0u4ceMGfvzjHx+JGfIZeHbBcRxvqYMXwdLSEhYWFpBIJOA4DhYWFvD06VNcv379sItGRLRvdhIqarUaDMOAoig7CiTNuNcXSZKgKAoURYEsyxBFcc2XJElrfvf5fFve3uzrtddeAwC8+eab+OSTT3b1PP3rv/4rLl26hEqlAgD4+7//e3z729/GW2+9hW984xt455138M1vfnN3f4Q2YuDZhVKphIcPH+74fu4Ee82+RFFsebuqqhgdHW15/50cu9l2VVW9yQIdx/FehERE+81xHJimueOajM1usywL9Xodt27d8rat/gC7emJU9/2w2df6MOGGF5/Ph0AgsG3YkCTJO/5WHj9+jL6+viM7MerMzAz+53/+B//wD/+AH/3oR3AcB++99x5+8pOfAADefvttfO9732PgOa5SqRTeeOONHdXwrA4M7gts9VezbZttz+VyiEQim+6/k2O1sl1VVczNzWFxcRHAyhw2hUIB77//fkvnvteAt3p7uVwGACwvL+9bwNvsNqIX0fr3lq2ChWEYyOVyu2p6Wf14wMr7hm3b0DQNd+/e3TZwrK/paFYj4oYLVVVx5coV7/W9XehohWVZiMfjSKfTez7WcfKtb30L//zP/4xqtQoAKBaLSCaT8PlW4sXAwABmZ2cPs4geBp4DsnoZhb2+uPx+P/r6+tpRrJbl83k8efLEW638T//0T1sawt0sSG0VsrYLYKVSCYFAALIsbxvy2hH83G0AoCgKFhcXvRfydtoZwjRNw/j4+L4Eua2209Gw+v9c1/W29OXQNA2Koqyp6djMZjUdzWo5TNPcNnQ0u2+z/7dGo4GxsTFcuXKlbc+lZVkQRZFTULTBz3/+c/T09OCVV17Bb37zGwDPA+tqR+W9hIGHWtLT04NMJgPTNPHJJ5+0/GbR7gtnsVhEOp1GMpls2zFb9eDBA2SzWaRSqW33bUfIW71NFEUEg8EN290LTDtqDpttr9VqLdfkufZa82bbNur1+qbNtrsJc6089urzb/Y/26ymY7vAoes6pqamdhRINmtecWtQHjx40HJNh9/v3/T2RqOBxcVFnDt3bsvQsROLi4sYHBzc0zHo+Pjtb3+Ln/3sZ/jf//1fqKqKSqWCb33rWyiVSjBNEz6fDzMzM0dmyR4GHmpZu6p+XwTtDnqjo6PIZrNtO16r3n//ffze7/1ey/vvNMg1267rOpaWlhCNRjfd3zCMttYcOo6DarWKjz/+eMM5uTUfq0NSq4EDAAKBwLZ9Obar6QCASqWCubk5XLx4cRd/yY3coces6aDd+v73v4/vf//7AIDf/OY3+Jd/+Rf8x3/8B/7iL/4CP/3pT/HWW2/h3XffxVe+8pVDLukKBh5qO8dZWYW8Wq0iFAohk8kwKL0g2hH0NE3D3Nwcent721Sq1nz44Yd45ZVXNjRZqqoKALv6H56fnz/w5meiw/bDH/4Qb731Fr773e/i+vXr+PrXv37YRQLAwEP7YHJyEuPj4/D5fDBNE729vbh06dKRacclIqL2evPNN/Hmm28CAIaHh/HRRx8dboGa4MduaivTNDE5OYlEIoFYLIZkMolCoYB6vX7YRSMiohcYAw/tyFYjOdzbV3e6dL9vdz8iIqL9xCYtasni4iKePHkCXddRLpdhGEbTzo6BQACZTAaFQgHhcBiapiEcDiMSiRxCqYmIiFawhoe2Va/Xcf/+ffj9fsRiMdTrdTx79mzT/S9cuICBgQFIkoRMJoORkZGOXIiOiIiOD9bw0Lbc/jd+vx+2bUOWZRSLxU339/l8OHv27EEVj4iIaFsMPLQtN+i4k6BZlgVZlvd0zFqthomJCZimiZ6eHmSzWY7iIiKifcPAQ9tKJpOIxWJ48uSJNyX9+fPnN+xXKBQwNjYG0zTR39+PoaGhpnOXKIqC27dvQxAE+Hw+PH78GLZtY2Bg4CBOh4iIXkDsw0PbajQaqNVq6OnpQV9fHyRJ8hbxdFUqFdy/fx+CICAYDGJiYgLT09NNj1cqlWBZFiKRCGRZRjQaxdzc3EGcChERvaAYeGhb5XIZgiAglUohkUggGAxiYWFhzT6lUgmiKCIQCECSJEQiERQKhabHE0VxzQJztm1zJmYiItpXbNKibUmStCGgrB915fbzcZmmiWg02vR4XV1dCIVCKJfLEEURlmW1dTXk9er1OsbHx6GqKjKZDAYHBxmwiIheMAw8tK3u7m5Eo1GUSiUAK52Wh4eH1+yTyWSQy+W8fXw+34Z9XH6/H9evX8fCwgJM00RXVxcSicS+lF3TNNy+fdt7XLeP0ZkzZ/bl8YiI6Ghi4KFt+Xw+vPzyyygWizAMA6IoIplMbthnZGQET58+RbFYRDwe37IWJRAIYHBwcL+LjkqlAtM0vUDl8/kwNzfHwENE9IJhvT61pF6vY2ZmBtPT01haWsLMzAzy+Twsy/L2yeVymJ+fh8/nQ6VSwa1bt7yVpg9apVJBoVCAqqprmuMsy+IkiERELyDW8NC2arUa7t69C1mWUavVMD4+jsXFRSQSCZw+fRrXr1+HJEmYnZ1FLBaDz7fyb1UqlVAulxEMBg+0vO5q7YIgePMHlUolSJIEy7Jw+fLlAy0PEREdPgYe2lalUoHjOJAkCZOTkxAEwZskcGxsDKdOnUI6nYYgCNB1HYuLi9A0DY7jHPiioaqqYnx83GtSs95EEzUAACAASURBVCwL1WoVZ8+ehW3biMfjG5rjiIio8zHw0LZ8Ph9s24au694Qcp/Ph2AwiFKpBE3TAAAnT57Er3/9aziO4w09z+fzyGazB1ZWt4+R239IkiQIgoB0On3gNU1ERHR0MPDQtrq7u5FIJLC4uAhBEGCaJsLhMFRVhSAIXo1JJBJBd3e3N4NyLBZDqVTadGX1/RAKhRAIBNBoNBAKhVCv1xEOhxEIBA7k8YmI6Ghip2XaliRJePnllzEyMoITJ07A5/OhVCpB13W88cYbiEQiqFaruHv3LvL5PHRdRzwe9zoHH+QaWT6fD1evXoUsy6hWq4hGo7h69Srn3SEiesGxhodaIkkSarUaZFlGPB5HJBJBOBxGf38/dF3H3bt3IUkSurq6UCwWoSgK0uk0Tp8+7XViPiiRSASvvPIKHMfhgqRERASAgYda5DgOxsfHkcvlsLy8DMMwvNFb586d89bGymaz3iSFly9fRk9Pz6GVmWGHiIhcrOenlpimiXw+D0VRvPWydF3H8vKy15nZcRxvoVFRFJFIJBg6iIjoSGAND7VEURQkEglUKhVYluWtpyWKIlRVRTwex8zMDJaXl72mrTt37uDGjRsH1mHZtm1MT09jeXkZ4XAYp06dgqqqGB0dhWEY6OnpwcmTJ9mfh4joBcTAQy0JBAKIxWLIZDKYn59HMBiEZVlYXl7G+Pg4gJUJCk+cOIFoNApZllEqlVAqlZDJZHb0WKZpolqtQhAExGKxlmdGfvr0KXK5HEKhECqVChYXF2GaJvx+P3w+H8bHx+E4Dk6fPr3j8yciouONgYdaEgwGvb46pVIJfr8fsVgMiUTCG5Y+NzcHx3Egy7J3v9XLOrRC0zTcuXMHiqLAcRzE43GMjIxs2/HZNE3Mz897zWiyLGNubg6SJCEejwMA4vE45ufnGXiIiF5ADDzUsv7+fsTjcQiCgDfeeAMPHjyAaZre7YlEAtVqFZFIBKZpIhgM7nhW46mpKWia5i32WS6XMTc3h5MnT255P7ev0FYjs0zTPPARY0REdDTw3Z92JBQKIRQKIRgMIp1OY3R01JuJORKJYGBgAJqmIRAI4OTJkzue8E9V1TV9fnw+X0sLkEqShKGhIYyPj8Pv98M0TfT393vNbm6/nStXruzshImIqCMw8NCuDQwMwDRNzM7OQpIkXLp0CX19fXs6ZiqVQrFY9IKSrust1xINDQ0hHA6jUqkgFAqhr68PjuOgWCzCNE3E43HEYrE9lY+IiI4nBh7aNVEUMTw8jOHhYQBAPp/H+++/D8uycOLECZw6dWrHI6LciQxnZmYAAMPDwy13ehYEAT09PRvm/unt7d1RGYiIqPMw8FBblEol3L9/H9FoFMFgEJOTk14z0064IcrtWMx5fIiIqB0YeGhHCoUCHj9+jLGxMcTjcdy4cQP9/f0ol8vw+Xxe/5tIJILFxcUdBx4Xgw4REbUTZ2CjllUqFdy8edNbibxareLDDz9EsVj0OgeXy2VYloV6vQ5d11GpVHb0GIVCAbdu3cLt27dRLBb36UyIiOhFwxoealm1WkWpVIJt29B1HcFgELquY3R0FGNjY1heXsbs7CyCwSB8Ph+y2Sw+/fRTnD59etuaHtu28ezZMzx48ACJRAKhUAifffYZrl27tuOh7UREROuxhodals/nUa/XYZomKpWKF34eP34MYKXDcSwWQ71eR09PD9LpNOLxOCYmJqAoyqbHdRwHjx8/xp07d9BoNJDP59FoNOD3+1EoFNp6Do7joFaroVqtwrbtth6biIiOLgYeaok7w3JPTw8cx4Fpmmg0GkgkEpAkCbIsQxRFRKNRACudj03TRL1eh6IoWwaeer2OhYUFRKNRBAIBBINBb1mIVpeVaIVt23jw4AE++eQTfPrpp7h16xZ0XW/b8YmI6Ohi4KGWlMtl5PN5ACszKp86dQpDQ0MYGRlBLBaDpmmwLAuGYUCSJFiWhcnJSUxPT2NxcRFPnjzZNFzYtg1BEJBKpQCsTD6oaRoEQUA2m23bOczPz6NQKCAejyORSKBer2NycrJtxycioqOLgYe2Va/Xce/ePQSDQSiKAlVVYZom+vr6kM1m0d/fD1VVsbCwAEVR8IUvfAGO40BRFITDYZw9exaapmF+fr7p8SORCEKhEAzDQDabRSgUwsmTJ/Haa68hFAq17TwURYHP5/NGgMmyjHq93rbjdyrTtNFoGFheVrGwUMfsbA2KYm5/RyKiI4SdlmlbpVIJjuNgcHAQS0tLUFUVkiRhZGQE1WoVlUoFp06dgm3bMAwDPT09sCwLyWTSCyyWZUHTNJRKJSwvL8Pn86Gvrw9+v9871tjYGOr1Oi5duoTTp0+3fd2rWCyGqakpr0ZJUZQNkxS+yCzLhq7b0HULmrbyNTurYny8vGHfRsNAOOxHJhNCINC+Zkciov3CwEPbkiQJjuNAFEV0dXVhaWkJfX19CAQC3gSDwMrcOT6fDwsLC0in094SEY7jQNd1OI6D27dvw+fzeaubX7t2DX6/H8FgEJcvX25bmW3b3jDLcyaTwdDQEKanpwEAPT092y5K2okcx4GmWV6w0XUbmmbCsjaubG/bm69232gYmJw0EI8HkE6HIEmsMCaio4uBh7bV3d2NSCSC5eVlCIIA0zS95SQcx8Hs7KwXLtyanWw2C8MwMDMzA0EQcPHiRUxNTSEcDnvrZLm1Pe2sZanVanjw4AEURUE0GsWlS5cQDocBrASy4eFhDA4OwnGcHS9setw4jgPDsL3aGjfgmGZ7R6dVKjpqNQPJpIxUKghR5KSRRHT0MPDQtvx+P65du4bFxUXoug5BELy5cQRBgOM43s/A807IQ0NDGBoagmEYUFUVuq5v6JPjOA5KpRI0TUMoFEI8Ht91OU3TxGeffQZgpWN1o9HAvXv38Oqrr66p7Vm9GnunMIy1tTW6bsMwLDibV9C0lW07WFpSUS5r6O4OIZGQD+aBiYhaxMBDLfH7/chms7AsC7lcztsuCAL6+/u93yVJWhMuKpUKPvvsM29Yuzu0XVVVWJaF6elp5HI51Ot1OI6Ds2fP4saNG7sajq6qKgzD8EKTu3K6O0liJzBNe1VT1Mp3w7C3bHo6SJblIJ9voFTSkE6HEIl0XrgkouOJgYf2JJ1OY2ZmBuFwGIIgoFareU1UjuPg/v378Pl8iEQiCIfDyOVy0DQNS0tLEEURDx48ALASqGKxGB4+fOg1Re2Uz+eD4zhe/x3TNL3tx836DsT5vIbR0dKRCTbb0XULc3M1hEI+ZDIhyPLx+xsQUWfhuxDtSTKZxEsvvYSJiQk4joPz588jk8lAURSvs3IikQCwEjzi8Tgsy0I2m8XExAR8Ph90XYff74eiKIhEIsjlcrh48eK2C4jW63XU63X4fD6kUikEg0GcOXMGo6Oj3j4XLlw40oGn1Q7EmnZ0anF2otEwMDVlIhbzI50Ow+djx2YiOhxH90pAx0Ymk0Emk4GqqpidncUvf/lL+Hw+L8woioJQKATTNL0aGEmSvFFdqqp6szdLkoRAILBt2FlaWsK9e/fgOA4cx0Emk8Hly5cxMDCAZDIJTdMQDAYRiUQO6FnY2kF1ID5MjuOs+rs5AAS4v1arBmq1MpLJILq62LGZiA4eAw+1haqq+PTTTzE+Pg5N0yDLsrdgqLv2liAIuHLlCqamplCv1xEIBBCJRKBpGjRNg8/nQzKZxNmzZ7d9vMePHyMYDHrD3guFAkqlElKpFKLRqLfExWE47A7E+889EWFVyHHWhVRh3XfAcYDlZbdjcxCJhLxtsCUiahcGHmqLXC6HcrmMcrkM27ZRrVahaRqGh4dx8eJFxGIxr9YnGo3i/v373pIUZ86cgSRJOHnyJLLZrNcEtpmV2hLD64gsCAIEQYBlWQdxqp7VHYjdWhtd78Rg87vfHOd3NTbPQ8rzwNJ6cLFtB4WCguVlDZlMCNFoZ08PQERHAwMPtYVpmigWi7Asy5uksFKpIJ/P49VXX10zSioYDOLGjRteE5ZpmvD5fBsmCtyMIAjIZDLI5/OIxWLQdX3NwqXASo2Tu+J6LBbb07m5HYirVQN+v4JazQddt45ln5rmVpqfvN/WTTPgandtjGnayOXqCAZXgk8wyLcjIto/fIehtshkMjAMA36/H6ZpwrIsSJIESZKa9qMRBMGbD2c3EwCeO3cOtm0jl8shFAphZGTEC1WlUgl37971+vecPHnSmyhxK9t1IF5a0iFJOoDjuY7U2j42wPOgs7/BZjuqamJ6uopo1I90un1rpxERrcbAQ3vi9p8pl8vo7u7G9PQ0ZFlGIBCALMvo7u7ecB/DMGAYBmRZ3tV8OwCg6zqq1SoCgQAMw0A+n/fm33n48OGa/j1TU1PIZDJeTc+L0YEYEAT3u9uBeH2QOVr9Z2o1A/W6gWAQTZe5ICLaCwYe2pPJyUmMj4/D7/fDMAwAgKZpcBwH6XQaZ8+eXXOhnZ+fx5MnTwCs1OxcuXJlVx2Mnz59CsuyEI/H4TgOZmZmkE6nkUgk1gyFtywHqmojn6+hVhM6rgOxG2x+9xvcEONuW9/n5qhzHKBc1pHLqVhaUpFKsWMzEbUHAw/tmm3bmJycRCKRgKqqME0T3d3dSCaTME0TsVgMAwMDAFb6+Ny/fx93796FLMvo6+sDANy/fx+f+9zndnxRq9frazotO46AUqkOIATTDGJ0dBF+fxiKokBRFHR1qbDt4zvb8srTsxJoVvexWfu07T4Y2LYNRVEAAKFQqOX+VO3nAHBg28DiYgOlkop0OoR4nEtVENHeMPDsgqIoKBQKay7SzS7YO7l9J8dwm3AO8nEdx0G5XEatVlszGkvTNPj9fjQaDW+UlCzLiMfjUFUVtVoNADA2Nobp6Wlv6YmZmRkMDAzAMAxUq1VvckDLsrxjyvLGi5yum6hUGnAcGZOTi5DlKDTNRK3WQDRqoNGooLv7BKrVCa+pLZFI4PHjR+jr68PAwMCun/f9tnqItxte3G0rGcetvWl352ETT58+RbVaBQDE43GcPXt2XyZsXN+PaGMHabdPkfO7kXcOFhYa3oiucJhLVRwG9+/krKoa3WybYRgt7d/Kbe5yMZVKpaX9WymfbdvQdR0LCws7ut92t5VKJaiq6r2Odlu+9d/L5TJUVfX6PO61zOv3+fd//3fcvHkT8/Pz+NznPuc9R5988gk6jbD65JvokIr/9iqVSigUCmu2rX8et/t9N/u4P09PT2NwcHBPx9jpfQqFAhYXF73lI/r7+9HX14eFhQVvFfVisej123EXCnVreEZHR+E4DpaWliBJEmzbRigUQjAYxOnTpyEIAhRFwezsrLf4aG9vLwKBMOp1E4ax0u+mUql5QahQWISmqRAE4Xfz77ijsVbKPjs7C8dx4Pf7f9chWfvdMQObnutW29y5gnbb72g19/q+uq/NVhqNhrfqe7tVKhVUKhXveVVVFclkErFYzHvcnQdnB44jYKWiqNn8PO59Nh7Tth3U6zXEYrENjxEK+ZBK+eH3i2vus1XZWi17Pp9HJpPxbnO/r5/uYCcXseXlZW+h3fX77fSCZVnWmukY9mo3x2v2vK7eVq1WEY/HN9y23f0229+yLFQqFXR1de35mO7PjuMgl8vhxIkTOyrLVtsEQcDCwgLC4bDXl3C357x+n8nJSXR3d294PezlmKu/67oOAPjiF7+Ijz76CKIoeue0HVVV8YUvfAGapsE0Tfz5n/85/umf/gnj4+N46623sLS0hBs3buDHP/7xrgan7NKmBWcNzy6EQiEMDg4eWt+CQqGAc+fOHdjjGYaBYrGIM2fOAADGx8chyzLOnj2LK1euYGZmxvt0U6/XIYoiYrEYXnrpJe8ialkWJicnEQwGUavV4PP50NPTg9dffx2xWAy2beODDz7AyZMnIcsyTNNEo9HA9etXYRgiFhcVmKaNZ8+eoaenx+u7YxgmJEncEELcgBOJRLy/U7Vaxblz55BKpXb1PDx79gyZTGbbeYJWlWJVHxu3lmb9SKnWfPrpp7hx48aO79eKp0+fIpFIeBc+RVGQTCZx+vRpfPrpp7h+/TqA5uF6Y1hz1vy+9gLe7NE3HtMwDIyOjnr/481CQDweQFdXED6f2JYPF+4n6RMnTnj/S+4+mqZBEASvmW8nF8K7d+/i/PnzLd9vq9uq1Srm5uZw8eLFDee3G+VyGfPz87hw4UJbjgcAN2/e9P5f2qHRaGBsbKxt5wysvBctLS15E6O2S61WQzweRzqdbutx/X4/wuHwvk2mGgqtjIx0Z77fCVmW8d577yEajcIwDPzBH/wBvvSlL+FHP/oRvv3tb+Ott97CN77xDbzzzjv45je/uR/F3xEGHtqWba+MXhJF0at9cSf6E0URfX193osmFotBFEWvVmVpacm7f6PR8EZmCYKAkZERb+SUO3LLrcVwX3i6riMejyMa9aNS0TE+vvaCEAg0b+IQBAGxWBy1WhWRSMRbSHR/Vk13m6A2NkWtzjZHtQNxLBbzaueAlefcDYqrz0EQVi74bhBYWR6i/efjhotmTZouwwDyeQOpVBCpVKgtS1W4a72tf9NXVRUAdtWvSRTFffqfIzp8giB4Qcx9DxcEAe+99x5+8pOfAADefvttfO9732PgoeMhEAggmUyiVCohGAxC0zSEQiGEw2Goqorbt297F4VQKIRr167Btm3cu3fPa+5aWFjAiRMn4Pf7IYoiDMOApmneY/j9fgQCAZRKJa8/UDAY9C56giAgkZDR3x9CJBKEbQvexH/VahX5fB6O46C3t9cLUcPDp/Hs2TNUq1WIooizZ896wWw31tZcrAQY23ZWXWwPvt9PO/T09KDRaHj90np7e9DTk/FqpFbO9eidm+MAS0vuUhUhxOPbr8FGRO1lWRZeeeUVPHv2DH/3d3+HM2fOIJlMeh8cBgYGMDs7e8ilXMHAQ9sSBAGXL1/G+Pg4lpeXEQ6HceHCBViWhZmZGei67vVTqFQqmJmZQTgcRrFYRDKZhCiKWF5e9pri3Oam1eFDFEUMDQ3h17/+tXfRkiQJiqKs+aQvigJSKRmxWBxLSypmZ4t4+PCh9+IqFou4fPkyYrEYAoEALl++DMMwvM7SrVo7j83qZRXc5+R5eY6j1cPZRVHEqVOnMTCw0i9sba1Za235h8myHOTzDSwvq8hkwohE2LGZ6KBIkoTbt2+jVCrhq1/9Kh4+fLhhn6PyHsLAQy3x+/04f/48dF3H//3f/+HWrVsA4NXEuCzLwoMHD6AoCorFIuLxOEKhkLdIaLlcBgD09vZuaOuu1WpeHx5JkqBpGnK5nBemVpMkEZlMGPn8JOJxGY6z0iHO7WC9ejkJd3TDdpoN937+/Wi8YHemtaY2YCW4bdY8eNS552QYFubmaggGJWQyYS5VQXSAkskk3nzzTXzwwQcolUrekkEzMzPo7+8/7OIBAA5rsg06pmZnZ1EulyFJEoLBoBdsTNPE0tISHj16hEKh4A0jXVpawvz8PCYmJhAIBDA0NIQLFy6gv7/f69vjcvuMBAIBSJIEd02urfj9ElIpH7LZIEKh1kdPNevY2urIhKPr+cifle/Hu6lttY2jmgD3fNcOaQdU1cL0dBXz83UYxsEuKEv0IikUCiiVSgBWBjv88pe/xKVLl/CHf/iH+OlPfwoAePfdd/GVr3zlMIvp4Ucg2pGxsTHUajVvTp1EIoF4PI5areY1Zbl9cWRZRrVahSzLCIVC6Ovrw+3bt5FMJiEIAiKRCEZGRrzhitlsFvPz86hWq78bnmxv+8kgm81iYWEBmtZAKASk0z4MDDy/z9o+Ns8dxwv/5mthuYRjXiMFuKO2nhffXRYDWBvcgNXn20y1qqNW05FIyOjubk/HZiJ6LpfL4e2334ZlWbBtG1/72tfw5S9/GZcvX8Zbb72F7373u7h+/Tq+/vWvH3ZRATDw0A7UajXMzc1B0zRv+LmiKLh06RJEUfSak9yaGbdKU5Zlr4NztVrFyZMnvdXUJyYmvGG70WgUN27cwPz8PICVZq/thmLGYjFcu3bNu09fXx9isRjqdQOLiwp0/fh9wm8WbNZ3HF5xnC/g68Ma1pzj88qcjbVUO3oUByiVNFQqOrq6gkgmuVQFUbuMjIx43RtWGx4exkcffXQIJdoaAw+1bHFxEZZleX1idF2HLMvo6elBqVSCbduIx+MoFAowDAOKongXF5/Ph7m5OUSjUa+ZSpZlNBqNNY8RiUS8+X5aFYvF1vTZWTmOH5GIH5WKhmJRPYILg66/4D/vb9Ms2ByXa7RlWajX6wBW/paSJGJjsGk+F9F+nqNtO1hcVFAqaUinQ4jFDmwSNCI6Ihh4qGWO43g1Nl1dXVBV1VsVPZVKectOqKoK27bR1dXlTTTohpxoNOrN5aMoCnp6eva1zPG4jFgsgHJ5Jfi4Q9kPjvt4z6/m60d8rb39mCSbNVZqoEzTxKNHj6AoChzHQTgcwcWLFzZ0Gj/MGhbTtDE/X/dGdIVCfAskelHw1U4ti8fj6O7uxszMDEzThN/vx7lz5+AuKxGLxdDd3Y3Z2VmEQiFv0sBAIIDu7m5IkuQtR+Gupu4ukbFX7iSImy0jkEwGEY/LWF5WUSpp+x583CaZVpY1OC5WgurKBIRup2g3vAmCgPn5eSiK4tW2VSoVLCwseMuLHCWaZmFmpopIxI90OoRAYO/LhbSbu6ZRO5YyISIGHtqBrq4unD17FsvLy17/GnfKd13X4ff7EY1GEY1GUavVYBiGt/ifqqoYGBjA+fPn0d/fj4cPH6JYLOLjjz/G5cuXvfVndkpRFDx48AC12soaW5cuXdp06QdRFNDdHUIyKXsT1m23htV6K6OF1ja/NOsYfUwzzTru0hEOpqenvX5S2Ww/BgZOeEHHtXqBQ2BlOgB3nZ6jql7XUa8bSCZlWNbRWTqwWCziyZMnsCwLqVTK6+dGRLvHYenUMkEQMDw8jMHBQbz22mu4fv26NylgMpmEaZowTRNdXV0wDAOpVAqCICAUCmF4eBiXLl0CADx69AiGYSCRSEAQBHz22We7ujA6joP79+9DVdUdHcudw2doKL5FXw5n3ffnz0GzOWyOm+aLBq/ftrL+Vz5fwNzcHCKRCCKRCGZnZzYsngsA8XgCmqbBtm1vRer9Wv9nL56f+/N+VKWShlxOxdKSuslzc3AajQYePXoEWZYRj8dRKpXw7NmzQy0TUSdgDQ/tmLuY3WrJZBIXL17E2NgYbNvGq6++ilQq5c2AXCgUMDY2hkwmg8XFRTiOg2q1ilQqBcuyoCjKjlfTNQwD9Xrdq9GRZRmqqrZ8LL9fQl9fBKmUjGJRQb2+st7W+rlddN2A49iHfiFsl+Z9iIDN+g9VKmXIsuz1wwoEAqjVahv6X/X0ZKDrmlcTdOLEADKZTDuLvo3nHb/dEV/NOkivn7fHu7cDFIsKajUT6XQI8fjma3ntJ7cjv/vaiUajWFpawokTJw6lPESdgoGH2iabzSKbza65yCwvL+POnTsIBAKwbRujo6PI5/MIh8MQRdELPTsNO8DKBUGSJBiGAb/fD9teCSWtzqzskmUf+vtjUBQThUIDmrYylN1xHMzMzCCXywFYaT7r6uracTkPwvNZooH1syqvt9M+RMFgEMvLy96M2qZpNv17CYKAwcFB78K8m8U2W/E8sK2eRXrtRIt7mY/IshwsLDSwvKwhkwlhn05jU6v/lwVBgK7rXICUqA3YpEVtt/oiMzs7683DE41GUa1WEYvFYJomVFVFvV5HKpXa1aKeoiji4sWLaDQaqFQqqFarGB4e3lD71KpQyIeTJ+PIZiPw+0WUSmXMzs4iEokgFotBVVUv/ByGZrMNu9uezxLd/lmVe3v7EAqFUK1WUalUEA6H0dvbu+n+oii2MeysPt/nS39sHNXW/mZFXbcwO1vD3FzNC8EHIR6PI5vNev/TpmmyDw9RG7CGh3at0WhgamoK+XweoiginU5jaGhoQ3hZ3xTk9rFxL8irA4o7GaFhGF6N0VYX7nQ6jZGRES9IpVKpPZ9XNBpANBpAo7GIQMDnXbz9fv+GeYP2x/qh7Btrb5r9vl8CAT8uX768bn6dvY8cWltTA7i1NGv/Xw5/WYxGw0SjUfVmbPb59vdzoiAIOHPmDHp7e2GaJsLhMGRZRqVS2dfHJep0DDzUEsdxsLy8DEVRoCgKVFXFrVu3UCqVvLVUKpUKlpeXcePGDa8z88DAAG7fvu3VREQiERQKBa8zq8/nQ6FQ8GpqPvzwQ6iqCkmSUCwW4TjOln0XZmZmMDo66h3rypUrm47S2qmengQyGQmS5EO1asE0zV3VRG1u69mGnzv8OXokSdr1SLrnNi5iutbK70d12H6lYqBaNZBKyUilgvvaWV0QhA2TaRLR3jDwUEtGR0cxPT0NAJibm/NGWqmqimg0CsdxoGkadF1HuVz2OrQmk0lcv34dCwsLEAQBp06dwr179wCsNH0kk0koioJGo4E7d+5gamoKsVjMW0trampq08DTaDTw7NkzxONxiKIITdPw4MEDvP766225aHZ3d2NwcPB3zVpAKhVEf392F0dqFmwOfrbh/bWxVmpjeDv82pq9chxgaUlDpaIhlQoikeBSFUTHBQMPbavRaGB2dhbJZBKO46BYLGJubg7BYNAbCeNewJtdyBOJhFfroqoqIpEIAoGAN9onGAzi1q1bGB8f92p3UqkU6vX6lk1ImqZBEIQ1S1WUy2VYluWNcNkLQRBw7tw5DAwMwLZtjI+Po7e3C44jo1JZP4fP6gv884t/uzoOHz0OHOf5iKiNtR3HZzmMza0NqqL4fB4m0xRQKKgol3V0dwcRjXKpCqKjjp2WaVuWZa3qFLtSMxMMBhEIBLylI+r1utc5OZlMbnqsYDCIq1evwnEcVCoVJBIJ+P1+iKKIeDwOWZahKAoqlQosy0JfX9+mxwqFQhAEAYZhAFgJJ7TQ3AAAIABJREFUZuFwuC1hZ/3jRCIRiKIIn09ET487h48fjrMy8eDa2oznnWqPZ7BxsLGz8MY5etyJB4/jPETNrF+8dP0sBLaN34W85+er6zZyuQZmZqpQVfMAS0tEO8UaHtpWOBz2go07100qlcLFixcxPz+PpaUliKKIrq4uZLPZbYeFJ5NJvP76617txyeffAKfz4euri40Gg1vHp3u7m6cOnVq0+MEg0FcvnwZjx49QqPRQCgUwksvvdTms29uZQ6fKJJJE4uLChTleF7s1tdANetDdDxD23ZWL43hhtPmw/tboSgWpqdriMX86O4Owu/nchBERw0DD21LkiRcvXoVz549Q6VSQSQSwUsvvYRAIIDTp0/j9OnTuzque6Hp7e3F06dPEYvF0Nvbi6WlJQwPD+P8+fOIRCJbHiOdTuONN97w5oY56ItzMOjDwEAMjYaBxUXlQIcvt6ZZX5rnTTUbw83Blaz9NvaVAg62g3S1aqBWW1mqIpU6nIkLiag5Bh5qSSgUwtWrV2FZFm7evOlNPOc4DkzThM/n2/XF48SJE7BtG7lcDvF4HC+//DK6u7tbvr8kSYe+wGI47MfJk378f/a+5TeONS3/qXtV36++X5I4TuycJCfJyTkDI1bwYwsSs2CBxCyQQGKDhFicP2FYILFizYgVrJgNEowYNIgBhjkzJ3fbsR1f232/VlfXveq36Hyfu+223XbsxPbUI0V236vKnfqeet/nfR5VtVCt6rBt7yNvweCJL+C4qa+rjt6pr+49g76CH5sE+z5Qr5toNk2oqnOkjitAgAAfFwHhCXAqeJ6HTqeDcrkMx3Hw7t07OI5Dqz6nGdt2HAcMw4DjOMzMzGBmZuYCt/zjIBoVEYkIaLW6xOd8AykHVTAGVXC6+Fg+PR8Hh1tQn8KT6DTwPKDRsLG1pSKdlo/JbQsQIMDHQEB4AgwN13Xx6tUrFAoF+L6PfD6PkZER6kL8+vVr3L9/H+12GyzLQtM0NJtNcByHTCaDVCoFjuPgeR7W1taoa/H09DRu3rx5ba6CGYZBPC4hFhNRr5uo1w143mmIz3HE5tCnndiG0jQNW1tbaLVaSCSSmJ2dOURMVVVFpVIBwzAYGRk5s1v16XB0C+owrq4I3LY9FAodNBomMhkZinK66JMAAQKcDwLCE2BoVKtVmqlERsoNw0A0GkUoFIIgCPj5z38O3/exs7ODZrNJX5vNZnH79m18/vnn2Nvbw/b2Nl1UNzc3EQ6H++IKdF2HpmkQBAGxWIwudJZloV6vAwBNSL+sYBgGqZSMeFxErWag2ewdZR/szUNeN+DdzrSvmqbhV7/6FRWWF4tF1Os1PH78mOYztVotLC8v07ZgtVrF4uLiBZCey9mCOm8wTD9hY9nuJJ9hONjd1RCJdIXNohgImwME+JgICE+AoWHbNvW8aTabtCXF83xf5o9hGKhWq/T5PM+jXq+jWCxib28PxWIR1WoVtVqNeviQVtnU1BRUVcWrV6/oY5OTk7h9+zaazSbW19cRiUQgSRLGx8dx586dS79AchyLbDaEZFJGtaqj2TQBHF7sL2I/KpUKNE2DoijgeR62baPZbKJWq2FiYgIAUCgUwPM8rfpomoZqtXZGwtMf5nmVWlCnQy859d9PeDHvx9n798vzgN59bbe7wuZ4XEQ6LYPjAneQAAE+BgLCE2BoxGIxKlLWNA2u68LzPJRKJUiShFgsBlEUsbu7C9d1KZExDAO6rsM0TTSbTXp/PB5Hq9VCrVaDKIrY2Nig8RU8z6PT6cBxHKytrWF0dBTLy8sQBAHRaBSKoiCfz2N0dBSJRAKNRgN7e3tgGAaTk5PnEINw/uB5FqOjYSSTMioVHZpmf5LtOEisBotqB7WVBiWTd6sX+148/T8vOxk9Cb3ttV7jQaKb6j7MYGAX7gQ0mxZU1UIiISOZlK6Nn1GAAJcVAeEJMDSi0Sjm5+exvr4OwzAgyzLS6TQ8z4Ou65icnISqqpTQeF7/pJJlWWg0GvB9H5FIhKacMwyDZrOJTqeDnZ0dGlXheR5YlkWn00GhUIBlWbTtQowQHcdBo9HAs2fPIIoifN9HuVzGo0ePTkV6fN9HpVJBs9mk1aPzNjAkEEUOExMRGMbFe/hkMhmEQiHU6/X3FR4HIyPZvpDVsbExLC8v04qa7/t0So7wFc/z3xsNAgcrM9dhoT6oGyLBpr2ErbdSc148zvOAWs1Aq2W+b38Go+wBAlwUAsITYGg4joNcLkcdli3LgqZpkGUZiUQCjx49wubmJgqFAo186CU9PM/D930IggDbthEKhaDrOjzPowsty7Jot9vgeR5jY2PwPA+iKKJYLEJRFBQKBSQSCViWBYZhEA6HsbGxAVEUEQqFaPTFysoK7t27d6KPj23baDQaKBQK9DNs20a5XMbnn39+oePuxMNH07oePpZ1/h4+4XAYX3zxBd69ewdVVRGPx3Hz5s0e0bKPeDyOe/cWUSx2U+9HR0dpO4vwgKtParpRGPtEpb9K9anNFh3HR6nUbXem0wrC4UDYHCDAeSMgPAGGRqvVovENLMtCkiS4rotsNovR0VEoioLFxUUwDAPTNNFoNGCaJq3WAF2CEQ6H6eMsy8K2bZimCZZlac6WYRh9ZCqXy2F0dBSaptHpMDIGz7IsJUylUgmlUgmqqqLT6eDevXvIZrMD98c0TTx79gy6rmNnZwehUAjxeBzhcBiNRgOqqh4bk3FeCIcFhMNdD59KRYfjnJeHT3dRD4dDePDgAb23f2Ksu7BHozFEo5evDfghIFUa0n7q5zCXk8CZpoe9PQ2hEI9MRoEkBcLmAAHOC4FaLsCpwbIspqamIMsyHMeBbdtQVZV68qiqSvOtiM4H6BIMx3FgmiZSqRSy2SxkWYYgCDSvC+hWJaLRKDKZDMbGxlAul5HJZJBMJhEOh6lAenV1FZqmYWJiAo7joFarUT3R+Pg4wuEwVlZWjhhzBnK5HEzTRDwep+SNTICRINTzQr1ex4sXL/D8+XNUKpWBz4lGRdy4EUM2q3xwRYXke3XRfS/Xdd/rovq1Q5qmYW1tDUtLSyiVSue63+eNwbleg0fZu9+ns023fWp0Og62t1UUi9o5EuAAAX69EVR4AgyNWCyGcDiMQqEAx3FodSUajYLjOGxvb6NarSKXy/XpbQDQKgzDMNRVmRAgnufp447jIJVKQRAEZLNZWJaFdDqNTCYD0zTRbrchiiIURYHv+3j9+jW++uorPHnyBOvr61BVFWNjY3Tk2nXdI9PTLcuiDtGJRAKlUgm6rkNVVciyjGg0ei7Hrdls4vnz55AkCQzD4NWrV3jw4MFAN+nutsiIxSTU6wYaDfNARWawcPggDhImwzCwsrICy7Lg+z6mpqYwMTEBwzCwvLwMoOtYvb7+Dr7v91kEfHz476sx/ft4nGPxVSQ1B0HG2fdbbz5U1YaqWkgmZXDc5SWiAQJcBQSEJ8DQ4HkeDx48QKVSQSqVQiqVQqFQoHqPWCyG5eVlaJpGBcUcx1E3ZVLtMQyjr83lui4EQUAqlaIhoolEAq1Wi05lEa2P53ngOA6CIIDneTSbTbiui2g0inv37kHTNABdR+h2u41EInGk+DiVSiGfz0MURSQSCei6jlQqhdHRUczMzJybaLlUKvWNffu+j0KhcGx8BssySKcVJBISqlVjwGj36RZ4Un2LRCLwPA87OzuIxWLodDr0+HU/l0OxWLxwwkPaTQdH2MnEE5l+6sV1IjWDPJh6x9n7959BrWZC1zWYph1EVQQIcEYEhCfAqSCKIlKpFO7evYulpSXs7e2h0Wggk8nQiSpCFHo9dsgJuneC66AgWJIkfPe73wXHcVhdXYWiKNA0jfr5ENKTyWTo2HooFKLvI4oiHj58iJWVFWiahlQqhTt37hy5L4IgwPd9vHv3DtFoFE+ePMHU1NS5LyakekUwaN+PAsexGBkJYWxMRDQqQlWtM21Dp9OBKIrodDrUS8k0TTAMA9u2oes6WJalYvPzwv7i3Gs62Et29n/up5Zf7cW8S2r2p7n2J908HK0iOHmfPc9HrWZje7sbVRGJBFEVAQKcBgHhCXAm5PN5FAoFhMNhaJqGd+/eIR6PY2xsDLqu0zHyXrEyAdHrkIktEv7J8zwymQxev36NSCQCQehOqjiOg5s3byIcDlMPIEEQoCgK7t27R99X0zSUSiUkk0ncvXv32JaUqqp4/vw5QqEQbt68iXa7Ddd1YVnWuaeuj4+Po1AooNVqAQD1CjoNeJ7F2FgYyaSESsVAp3M6Dx+WZfHu3QZEUaDHXRRFOtZfLlfAMEAoFMLTp09P9d6DcHis++iJqKsJv4egkYoM8ejpr9Tsu0qfD5G0LA/5fAeKYiKTUSDL53sad12XemGR1nCAANcBAeEJcCaUSiWEw2EkEglomgZVVTE+Po5WqwVJktBsNvsIz0GQigchQiMjI4jH4yiXy5R09D7XMAysr6+j3W4jFApBkiQ8evQIktT1LdE0Dd9++y2tKORyuWO9eOr1OjiOgyzL8H0fmqbhf//3fzE2NoZsNouFhYVzG0kPhUJ48uQJFQRns9kTx+WPgiTxmJyMQNe7Hj6GcbKHT6lUQi6Xg653YJosnbLzPA9bW1sYGxuDZdlwXQee51Gi2Y+DmqHjNUTXg9Tsg+wOw/i03USIzEFx+MeCrrvY2WkjGu1GVQjCh39fdV3H69ev6XTl9PQ0Zmdnz2FrAwT49AgIT4AzQRAEaJoGSZIQjUbheR5isRgqlQqdnnLdk31lWJZFJpMBABSLRXAcR8XMqVQKrutCURTUajXwPI9QKIREIgHTNFGv1zE2NgYA2NvbAwBa1Wk2m1hZWaGVnt4F2DRNbGxsYHt7G9FolI6hJxIJSrpI5ee8oCjKuS4cisJjejqKdrs7ym7bg4llp9PBxsYGGIZBLBaDbTs0n8yyLFiW9T4LDeiKZNtwnH4SNVgzcn0ITe/+kd08uM8kuPVgbMRlgKp2oyoSCQnJpPRBURVv376F4zj0//T29jb9fxEgwFVHQHgCnAmzs7Oo1+toNBoAAFmWsbq6imKxSLUxJ4G0tYiB4cLCAlKpFDzPQ7lcRiqVQiQSwdjYGJ4/f94nImZZtm9hJtog0pba29uDKIrQNK0vc4tMdhG3Z03TUKlUqN9PoVBAu92GaZqYmpo6otpxeRCJiIhERLRaJioVHa7bf9wty4LrujBNE6ZpwvM8NBp1OI6NW7duIhrtHoNQKAzH6RLUg22M61atAfp1RAeJDXD19tn3gXrdRLPZdWxOJKQzh82SIQSi6bKss+nGAgS4bAh8eAKcCZFIBF988QXm5+eRTqfBMAxKpRIikQgcxzmyldULhmHoaPvY2BhSqRSA7olWURRMTk5iZmYGoihidHS0T2fj+z696iTBo1tbW1heXsby8jI8z8P4+Dji8Tjy+TxNbic+QYlEAtPT05iamkIsFkM8HkelUkG73a1wGIZBiVEvyJTZwSrIp0YsJuHmzTgyGQUcRxY6H5Ikod3ujtlzHAvb7m63KErY2trG9PQMQqEQ2m0Vtm1hfv7OFdVt+Ad+Hu3ZA+x79Fx1MIz/XiS9/7Na1bG11UKrdXqiQib3ANA8vKv5fQgQ4DCCCk+AM0OWZdRqNVQqFRoQahjGsVeEJAOLZVk6vZROpzExMQFN0xAOh2FZFiU9BFNTU/B9H8+ePQPHcfjss89o+2pvbw/1eh1zc3NoNBrY2dnpi0cgk0hA12uGVId4nqeBqJIkYW1tDZIkIRKJYGJiAs1mE6Zp0hO+ZVl49eoVfc87d+7QltplAMMwSCa7eUy1moFGw4CiKIjHux5DnucjEglDURSEw2G4rgvbtnHv3r0+C4HLiEFj7Ifv7/159ao0R8Pv0RD1+vUcLZC2bR/FYud9VIWMUGi4SuXt27extLREM/Hm5ubOzY8qQIBPjYDwBDg1SG+/WCxie3sbkiRB13VwHIdOp3Mk4VEUhZIP13XBsixkWaZtq0KhgGazCVEUsbi4SH17CDmanZ2lzsq9kQ+tVguyLENRFIRCIViWBcMwAOyLonvL9Hfu3MHS0hJtcc3MzGBsbAztdhuRSIQKocnzCUiOWDabheu6WF5ephqgywSWZZDJdD18ajUDN27coJNxPM/D8zyaGUb276KCUk+DffKyn0Te1c1cf1LTvxv9hO6gQPo0OiLDcJHLaQiHu1EVoni8sFmWZTx69AimaVK/qwABrgs+/VkuwJWBruuwLAulUolOYBWLRYiiiHQ6DUVRKNEYBDL5QUJCE4kEFhcXoWkafvKTnyCbzSKTyWBiYgJv3ryhlZf79+8fSypCoRDK5TI9OcdiMZrAzvM8Pvvss77Xj46O0rR2URRpa2x2dha5XI4Sshs3btBpMTIpRp5LqiG6rl86wkPA810Pn0TiNmSZwYsXK6hWq4hEIjBNC6lUcuir93a7jd3dXdi2TbPTTks2LMvC7u7u+ziPGEZHx+gkHEljP1y5uS6kZj/XC+iS0i552Z/62sdRv58dmuZA01TE4yJSKRk8f7SagWGYoI0V4FoiIDwBToTv+3SqyXVd5PN5jI+P0xFmkqfF8zzi8Tj18TgIUq0RRRG+70PXdVQqFRQKBZimCVEUUalUsL6+jjt37lBzwTdv3uDLL788cvsSiQS++eYbrK6uQhAEjI2N4bd/+7cpKRm0YIbD4UNEZX5+HqlUCp1OB5FIBMlkkj7GMAwkSYJpmtStmBCyyw5R5HH//iw0rQLXNdBoaBBFETdv3hrKZFDXdSwtLYHneXAch83NTfi+j/Hx8SNecXhk3XEcLC8v07/zzs4uDMPErVu3AFyHNHaA6IUG8bODpGZf4nYw1PRi0WxaUFULiYQMlg2iKgL8eiEQLQc4EY1GA1tbW4jFYrQiUCqVwHEcwuEwNQ4kouNEIgFZlgcSDaLbsSwLqqpieXkZjUaDCp0lSUKj0aBX/qFQiMYfDIKmafiv//ovdDodKIpC86oqlQqdMumF7/uo1+soFAp0woyAYRhkMhnMzMwglUodeu3ExAQYhkGr1YKqqrh169aV0Tesra2hUikgFvMxMRFCq1XDq1cvhxKXt1oqFa8KgoBQKIxyufT+UaIn6dWVHH6PTqcDwzAQiUQgiiKi0SgqlcpQ1gWXCUQk3OvLQ8TCXULDwPf3/+2/7vIQOs8DajUDOztttNvOpQ6LDRDgPBFUeAKcCNM0qY6GZEI1m01IkgRVVeF5HjRNgyzLyGQyqFQqtLJC/Ew4joPneVQcS0BOtqIoQtd1hEIhmsMlCAIMw3g/YTRYe0BaJMSZmbTdVFXFyMgItra2UKlUIIoi5ubmUCwWsbOzQ4nX3NwcpqenhzoOsizjwYMHdOG/KmX/VquF169fo1qtIhwOIx6PY3zcQ6Oxg1/+0oIkhTE3d2tAa67bbuG4/eR4hvHhui5EkWg7DsZC7N/Xi4OVJPK9uExEoBeDvId8/3A0xGX05RkWruujWjWxva0ik1EQDgd6nQDXGwHhCXAiZFmG67ool8uwbZumbTcaDdy8eROyLFNNz5MnT/CjH/2oT7hMqj+2baNer8P3fVoVIoseEdU6joP5+Xl0Oh0qsn348OGR22bbNmRZRrPZhK7rfSLlZ8+eYWNjA6FQCJFIBN988w08z0MqlYLjOCiXy/if//kfOI6D2dnZodo7PM9fmaoO0NXNvHjxglbcTNNEPp+nbtYzM1Houo/19bdYXLxPdVD7hASIxxNQlBBarRZ1aL5163SmjKFQCLFYjOqqLMvGzMz0ueZ2DQ//vSC6N7gU6B1hH0TEzisa4tOjdz8Bx3GRz7chyzyy2RAk6XwcxgMEuGwICE+AExGNRmnCNxHqCoIA27ahqio6nQ5GRkbgOA4URUEmk0G73aaLo+d5sCyLTguR6orneTBNE9FolLafFhYW8OjRIwD7ZOa4CaLR0VFsb2/TSpPrupAkCZZlYWlpCbIsQ9M0Wj0Culqi3d1dOI4D13WxtrYGz/MwNzf3UY7nxwRpB05OTkJVVdpG4nkekiShWq1iZmYGgtBEOMzAcZj3AuL9BV8QBCwuLqBWq8N1HcTj8VMLtVmWxfz8PCqVCq3I9WqkzhuHJ7vI/d2fBzO+jqpMXVUc5ms+bTceNFr0vO5tXXexva0iFhOQSp1PVEWAAJcJAeEJcCJUVQXP87h37x46nQ6ePXuGb775Bo7jIBQKYWRkBJubm5icnKRj5qFQCLquw3VduK4LjuOgKApSqRTN2XIcp6+6s7i4iCdPnsA0TWxtbcG2bYyMjGB8fPzI1kc2m0UqlUK73QbHcUgmkxAEASsrK+A4jrbGHMeBZVmIxWKo1Wq0TRcOh5FKpZDL5XDr1q1L22I5KwhZZFkWt2/fphU6UqlSVfW9R4+HTCYEWVZQr5toNIw+LY4gCBgdHfmgbeE4DqOjo0M/3/O890TWRzgc7mmjERDdTL9I2vP8I0XQ14XY9HrxkET240fX+6MzjkOrZUNVbSSTEpJJ+ZoIygMECAhPgCFB2lC5XI4SlGg0Ck3T0Gg0oCgKJiYmwHEcpqensbS0RBO5fd+n3jmkpaTrOsrlMqamptBsNuH7PlZXV6l4med58DyPlZUVeJ6HqampI7ctFothamqKVnBINIRlWdQ1liy2X375JV68eIFSqYRYLIaRke4ift2IDkEkEsH09DSdsOM4DlNTUzBNE7lcjlaA4vE4isXie3LZQSrFwbY/nabD9328ffsWzWbzfWuTw+LiPSiKjMN+PP1/u+uyQA/6ShKB9FGGg+cF3wdqNRPNpoVkUjpzVEWAAJcJAeEJcCKi0Sii0SiazSZarRY1rCNVlXA4jNHRUUSjUZTLZRSLRerkKwgCDR9st9uIxWLgOA62baPVaqHZbEIQBAiCAJZlUalUIEkSMpkM9fTZ2dmB67rY2dlBuVwGx3F9xoMTExMolbpTQ47j0AqGIAhIJpNUX7S4uIhwOIyvvvoKkiSh1WrBMAzYto35+fkPOqHbtg3DMC6lmPnWrVtIp9OwbRvhcBhv376F7/vodDpIpVKYm5uDJElYWVnB1tYWbTl2DRklhMMCNM2+oK3rrc6QhdyHrneg6x3EYl3fo06ng+3tbdy9e/eCtuPjg1RpevefoDs8d/j72D0+H494uK6PSsVAs2khnZYRjYof7bMDBDhvBIQnwIngOA4PHjzA+vo6lpaW6Cgx0eYUCgWk02lomoa1tTXk83k6tUVaKpZlIZFIQFVVGj/hOA5YloUkSfR3Mpm1tbUF3/dpZlWn00EikQDP89jY2EA6naYp64lEAgsLC/jFL35BoyBs28bExAQMw6ATZsREkOM4PHz4EPl8HqZpIpFI0Pc6C1RVxYsXL+i2zs3NHVuR+hQg/kimaWJ6eprGdwiCQIXj1WoVt27dQigUgud52NnZeV+di8AwHFQqOnT9rBlih715DreeGNpychyX/r0AQBBEmOZVDbHs1UQNjoXooneM/eNs2bCwbQ+FQgeNholMRoGiBEtHgKuH4FsbYCh0Oh0UCgXq20LGlAmRcBwHS0tLfd48rVYLnU4H1WoVsVgM5XKZ6ndYlkU0GoUgCGi1WrSqw3EcnQYTRZFWg0g7htjd12o1SlJc18Xq6ioVKzebTbTbbbTbbczPzwPomuetra1B13VEIhEsLCwMPY5+Et68eUP32/M8rK+vI5lMXhoHZt/3sbW1hTdv3qBYLCIWi1EyqKoqTNOEruvUTZpEfpCpOQCQZR5TU1Fomo1KRYdlHfTP6VZnehfq/VH2wVWJ41pPkiTBdV1KhDsdDZOTl4tEAoerNAzTJXJAb5uJ6fv9KsMwXOzuthGJCEin5ROjKgIEuEwICE+AofD8+XMUCoW+EE4yVs5xHCKRCHZ3dxGPx8GyLG1hua6LWCyGUChEW1OpVIpWHBKJBObm5lCtViFJEm7evInXr19DVVUqKu79XKDbtiIOx57n4fXr19jY2IDv+zBNE9lsFjzPw/d97O3tYXJyEgzDoFgswnEcVKtVaJqG7373u0f6+wwL13X7IifImLVpmpeC8Pi+j1/96lf4+c9/TtOviUv06Ogo1Utpmgae57G3twdBEJBOp6nfUC9kmUU87kHTHJgmj33fQAa+76HT0eF5HkKh0AcdW0mSMDY2hu3tbXieh9HRUUxMDHZ23jc99Om//dv0WYeed/B313WhaRr9G5LHLMuigbfd7zsLQlzIPpIqGXnex3ZQvmj0E1lA0yxomoV4XEIqJb8/JgECXG4EhCfAifA8D7lcDpIkIRaLwTRNOtLNcRxtXRGyY5om6vU6rRrouo5arUZJS71eh6ZpiEQiiEQiuHXrVt9I+MTEBN69e4doNEoJE8/zaDQadASexBpUKpW+9heZ7JFlGRMTE4jFYrhz5w7+9V//lcYaED2Qqqp9WiAC3/eRz+dRrVbfe9XMQJZlShYIcSDPlWUZrVYLiqLAcZy+NtxJi+yg3wc9Zts2CoXCsc8b9LpWq4Wf//zn6HQ64HmexoCQ0fQbN25Qy4FoNIpGowFVVdFut/Hw4UO0Wi28fPkSvt81HNze3oZhGGAYBqIoIhYbRbvtwbZdlMsl6LoOhmEoaSLEs3fbTgIhrrZtUwJRr9dRr9ePfM2+8SHT93sv8eglJb2vAbrVJssyUSjkexy6mR6CSLeOEsaj/vW6V+u6jpcvXxy7v71EqXebyW3yz3Gc9+3ezT4X8d7XDvrXS8B6n9vpdOA4DnS98/4YsAPehwS5DjZcbDQstFoWkkkZyeTlj1kJ8OuNgPBcIgyzgJETqmEYJz7vtIvqUc8jC2S73YYoihBFkY51cxwHXdexsbGBxcVFGIaBZrMJx3Ho2LOqqiBGdmThJI7Ioiji5cuX9DEAlFRsb2+DYRhabSBBnRzH4fnz5/B9H5ubm6hUKnQx8H0fmqYhk8lga2sL2WwWzWaTEjb52TUBAAAgAElEQVQiyDVNEz/96U+pYJo4PAPdKI1arUb37b//+78xOTkJnudRr9fB83zfYkNMDImYe3R0FFtbW/Rx8vPgYjvs7wzDUDfrQQv2wffuXbQIcSBO1xzHwXVdjI6O4quvvoIgCGg2mwiHw4hGo0gmk/A8D7quY35+Hi9fvsTs7CwYhsHW1hbC4TDGxsZAIjamptKYmprGyso2Op02nXrrdDpIJpOYnZ0duF/HwbIsrKys4MGDB8c+73To1xD1EhiyPc+fP8fc3O1Dvk+maQI4m/Hgy5cv8ODB0caZpPLUW3kDMIBUAZrWRq1Wp38j399//cHnk9u993fhwfP2K1e6rmN3d/f9MfHft+MOv+cw4DgGgmDhm2++6fsODiJjxz3ee7tLyHTk8/kTnzvsY8PuT4Drh4DwnAH1eh1LS0sX8t7DLIKGYeDNmzcnPu+0i+pRtz3PQyKRQKvVguM41LSOiJAB0BYJuUqMRqPodDowTZNWRA6ebEg7IJlM0pYQsG9SN2h7V1dXMTY2hng8DtM0USqV6MmbLFRkauzBgweYmJgA0B1VJ07BAGjuVjgchuM4SKVSWFhYAMMw+NnPfoZMJoO9vT2wLEsF1tFoFAsLCwMN84iAm4zTnzdKpRLm5ubgeR6q1So17xtUoepF78JBKg8sy2JhYYFWyaLRKDWVFEUR7XYbMzMzSCQS4DgOsViMvlc4HKbtRCJuDoUURCIsZmdjcF0RqupQ9+0PbRkOj/5pr8Namf7b+5zrU/ed9ispLHvSsfLRbmt0cu3QOzEHIzF6tUSH97PdVlEul3Hz5q0zb/1BvHz5ApnMPFIpEYrCHyJgx/0+6D4ydUl+Hvfa0zzW6XTwi1/8Yqh9Gpa8kcpoo9E4NSE77rm2bcM0TVpZPaqaF+BkBITnDEgkEviN3/iNT2SLD/z3f/83njx58lE/M51O49WrVzBNExsbG2AYho6ZC4JA21wzMzMwTRPv3r0Dy7IYGRnB3t4eAPQtuqSqYlkWPUEQHQ5JYicj6nfu3KGLLhEti6IIy7JQrVah6zo1MQS67svZbBaTk5N0+x8/fowXL17QEx6pOuXzebiui1wuh1qthps3b4JhGGiaBtM0aeVHURSUy2UsLCwMPD5E6HuR8H0fy8vLKJVK1MV6fn6+bz8PIhaL0e8paS8dDHaVJAmff/451tbWYJompqamcPPm4eiIRCKBcrlMCY9pmpSoxuPx9xquECIRDjs7GqLRs0++DcYgIjN42ut64mBwKZn2IsSGtOHI8z/NcbBtH8WiiXDYRTqtfFBURafTgaZp5zZgAHS1Ws+ePcMXX3xx7POOa1kO+n13d5dGqJxE8o4jZAdvq6pKL6YGvddpMIis/eM//iNev36NUqmE73//+7Tq/Xd/93fXjkgFhOcMuG5fgmEQj8fxne98B8ViEXt7e1BVFZqm0Qmrubk5NJtNAKAGg+R2JBIBy7LQNI2enHmeh67rSKfTKJVKqFQqiMViYBgGL168gCAImJychG3bePHiBZ4+fXqIUJCTAYmrIPeVSiXaSiEYHx+HoihotVrwPA8//elPkc/n6UmDZVlks1ksLy9DFEVqyud5HhRFQTgcpvvzqaCq3SvyeDwOhuk6VK+vr2N8fPxI8m3bNjKZDG0zAl1ydjApPhKJ4NGjR1Tf9Pr1a+qlRDA+Pg5d15HL5QAAs7OzGBsbA9B1vJ6dncX29jY0TUMsJmFkRIAg+LDtYf+/kPiDo1oOg9/nuhgNkorMfmWTVGeI+JqksL9/9iWf/NI0B5qmIh4XkUrJ4PmrJWw+beWEuMynUqlz3Y6VlRVa1f4QHEXc/vzP/xytVgt/9md/hr/6q7+Cbdt9F5DHYWdnB3/8x3+MQqEAlmXxp3/6p/iLv/gL1Go1/OEf/iE2Nzdx48YN/NM//dOFRskMi4DwBBgaPM+j3W5TjQ0prTqOg0qlQk3hiKCZjJmTINHp6WmUSiXU63U6zh6JROB5Hk1EJ/oaMpLOcRwdMz9IeHiepzoiAnLFQxbiXiQSCSQSCTqe7vs+WJali3qj0UA6ncbu7i6y2Sx2dnYoKSsUClS4/KlA9q1Xq9NL2AZBFEUkk0m4rtvXfqzX66hWq0in0/S5pIJULpchyzLq9TrK5TJ9fxJPQao/vcedYRjcunULLMtifX0diqKgUilCUVpYWHiARsOGYTg4qkpDDuv1Ls/vV2cAIgZ+/4i/f1yuCqEZFs0mETYHURWfEkf93yKeYcRv7TTgeR5/8zd/gydPnkBVVXzxxRf43d/9Xfz93/89fud3fgdff/01fvCDH+AHP/gB/vqv//pc9uNDcLUod4BPDoZhaBwBWfBYloVhGLTs7Ps+rabUajUYhgFFURCLxTA7O0uvVNrtNq2kkOpJb6mVgIhtD4IElXIcR4mPJEmYmJg49mpCVVVaISFkTBAEuK6LWq0GRVEwOjqKhw8fQhRFKphUVRXr6+ufjPQQ/Uy73YbjOGg2m8hkMsdqhkKhED777DMqtBZFEXfv3qW6nV5YlkUrSLIsU50UiecgIET0IHzfx87ODhKJBC3ta5oGy9IwPR3FxEQEojh4WxnmulROfexXaoDeKTH/vdkg+ed5vbEQ12Hf99Ftvfnv/64A4KNeN7C52USjYV5b4bDvd6dSNU07dbvpKmJ8fJzKK6LRKBYXF5HL5fCjH/0I3//+9wEA3//+9/HP//zPn3IzKYIKT4ChQcqcRK9DFlpCPIhnC6nSEMGzaZq07fWf//mf8H2fLsChUAjJZBJ7e3tUDD02NgbP82jbZWRk5Ehx7ldffYVf/vKXqNVq8DwPsVgMX331VV81qNPp0AywkZERSrJ6S7uO49CRdUKWSM98ZmYGyWQSuVwO1WoVqqpSTdHHhCAIVGuj6zomJycHam0OYmpqCvfv38fe3h4SiQQEQYCmaYdIy8ErQLIofQgR6X1tOCwgHBbQapmoVg04ztVbEPZ3Z5/UkLXb8w4nke+3o64Loeui33DRp8eBCKePEo27LlAu62g2TaTTMiKR6xNV4fs+tre3oes6gO4Fyr1796jm7bpjc3MT3377LZU+kKGI8fFxGv3zqREQngBDQVVVvHz5kupeWJalpMf3/T4RNan+EPNAx3GQz+dh2zbi8TgNqpRlmY78joyMIBwOw7IsRKNRjI2NgeM48DyPZDJ55GIxOzsLWZZRrVbBcRxmZ2ehKAp9XNd1fPvtt7RKtLW1hWq1imQyCVVVaWuL+AnNzs6iUqlA0zQ6zh2JRADsE4LeKzfLsuC67iEh8EVBUZQzjWtHo1G0Wi20Wi3EYjHIsnxI7CyKIiYmJrC7uwtRFGHbNkKhEA1lPQkMw2BmZgbv3r2j8R6KohzSHsRiEqJREY2GiVrNoM7ElwVkwd5fvOkj2I+D6G8/AZcvDuJDwDA+JTDd24BlOcjn96DrBqLR6PupTA69Qunua04+EJblIZ/vQFG6URWyfPWXIlVVUalUqG1Du93G1tYW7ty586k37cLRbrfxve99D3/7t3/7SS4Gh8XV/5YFuHD4vo/Xr19THQchDyQJfXZ2tk8kTNpFIyMjsG0bzWYTnU4Hz549o07Ivu9TfQhx9DUMA+l0GpZlYXV1FU+ePEE0GqXbMOhEyjAMRkdHqW9Po9HAzMwMHUcvl8twHIcuumSii0xSkBZRLBZDo9GAIAi4efMmfN+nwafEp4ZMJREH5Y2NDeoVFIlEcP/+/b78p8uCcrmM9fV1ZLNZSvI+//xzemx7cfv2bUQiEaiqinA4jM3NzVMRuZmZGUiShFqtBkmSMDU1NbDlxjAMkkkZ8biEet1Ao2FeGuLTu7/9+36NGE1PhYq0nroVqv6cL0JkSHyLrusQBIFm4n3oSLuuu9jZaSMa7UZVCMLVjaogkTnkO0POLdcdtm3je9/7Hv7oj/4If/AHfwCgOymbz+cxPj6OfD5P/bk+NQLCE+BEkNBJQhpc1wXDMNTE7qBglvi3OI5D/8OTxHWWZbG3t4dms9mXhq4oCu7cuUPLv7Zt05HztbU1OI5DoxAOolQq4e3bt3QBX1lZgSAIyGazh54riiJCoRCNESDbwLIsTVhvtVp4+vQpgG4b7927d6jX61AUBQsLCzTLa3Nzk7pLt1otrK+vY3Fx8TwO+blib28PiqJAlmXEYjGoqnpIl0PAMAzGx8dpOZoYKA4LhmEwNjY2UDQ+CCzLIJ1WkEhIqFYNtFrmqT5vMPy+SkNvlYboaq47eltvvt89zgcnvoBeXRHo7UHQdQOdjo5IpEv2BUFErVbH9LQNnhcGv+gUUFUb7baNREJCMildyagKSZLoyDnRNY6Ojn7qzbpQ+L6PP/mTP8Hi4iL+8i//kt7/e7/3e/jhD3+Ir7/+Gj/84Q/x+7//+59wK/dx9b5VAT46OI6Doii0N03EwcT4jgh/CSRJwhdffAFJkmioZjgchizLNGiUxErIskwrPMQTBwB1k37z5g1EUUQ0GkU+nx/YC65WqzTeguiAqtUqgO64NMdxaLfbVGz91Vdf0YgMoEt2VFVFq9WC7/t9o9g8z+POnTv4zne+g5mZGdou03WdVryArji41Wqd85E/H5BpLoKDU12u66JarSKXy32yK1KOYzEyEsLsbAyRyEkLqH/E7wTMoSrNvj7pepAdIgYm/1h2v1rj+x4VQxNvnn2B9NmOweEi34fruw69ow/U6ya2tlTU68aVEzZHIhGMj49Tk1MypHGd8bOf/Qz/8A//gJ/85Cd49OgRHj16hH/5l3/B119/jR//+MeYn5/Hj3/8Y3z99defelMBBBWeAEOAYRjcu3cPr169omLjaDQKURTBsmzfaDPB7du3EQqFsLy8jEajgfHxcTquTkbBHceBoigwTRPpdJpGOoiiCEmSqC6GtEQikQg1MewFIVEERIAMdDUvjx8/Ri6Xo1WiVCqFt2/fIhQKURfTdrsNSZKwu7uL6elpKrQ+CoqiUB8L4n593v4b54Xp6Wk8f/4ctm2j0WjAcRyMj4/DdV24rov/+7//w9bWFm0vPn36dCgx9EVAEDiMjYUxNiZDUXjoevfv2l+lua5tpl74fdUooiciE0/7WqL3z+4ZYb8ILVkoFEIiEUej0aCV3a7O7vyXENf1UakYaDYthEJXh/QwDIOJiQksLi7C8zyIonithOqD8Fu/9VtHEtN///d//8hbczICwhNgKEQiEXz55Ze0HUIcfAVBoP47vWBZFlNTU5iYmMD29jZKpRIEQaCRDY7jwDRNWJaFcDiMbDYLSZJw48YNhEIhpNNpbG1toVKpwLIsJBIJaq1+sK01NTWFSqWCcrkM13URjUb7BLnhcLhPOOg4Dmq1GhiGQSwWg2EYlPAQp+X19XXcu3fvyOORTCYxPT2NXC5Hp816A1BPQu9Y/0UjkUjg0aNH+Oabb+D7PrLZLPb29iip297eRigUoqnpr169QjabpWLtTwFRZDE1FUWnY6NS0WGa7skvukLonXI6qE8jounedYS06D7dCDuDmzdv0liTcDh8jkZyvVNe+7EYjuOhWNRRKOiYm3OgKJdvuXIcB3t7e2i321BVFZFIhE6rBrh8uHzfoACXFhzHIRqN0ugBx3GQTCYHil8JWJbFjRs3cOPGDQDdgMZ0Oo16vQ7bttHpdMBxHDqdDubn53Hz5k24ros3b95gY2MDnuehUChgZ2eHRkq8efMGX375Ja3AyLKMZDJJSQzRHB1VoSE+MmQSiWiSpqenEQqFkM/nkcvlYBgG7ty5M3DhZxgGt2/fxtTUFFzXhaIoQ0WNtFotLC0twTAMOrY67BTUh0AURfA8T0vsvu+jVqvR8X1SRSOJ6gfblJ8KoZCAmRkB7baFSkWHbV+NUfZ9QkNEwfsEpivO7q9S9V8kX86qAMtyyGZPLz7tPRbd2/uZegd9iAaZLdq2j93dNiKRrrBZFC+HsJkYdTYaDYiiSCNfstnsta/sXFUEGp4ApwbHcZiYmMDMzMyxZGcQyMQUy7JIJBK0kpBOpynZef78OZ4/f06jHVKpFHzfx+TkJKLRKHRdx/r6OoDuOOTKygpWV1eRzWYxPj4OURSPDXdlGAY3btxANBqFLMvUFDGZTCKfz6PZbFKNz/Pnz49d/GVZRjgcHors2LaNly9fwvd9xONxWJaFV69efVSDMrLQuK4LwzAQCoWowNL3fdi2TY/JRYBEV7x58wZbW1t9eqnjEImImJ2NYWQkBI779ItJdxEn5no+1dAQ40FiLgjgkMngdVsMyX4f1BWRNlyv2eL+sSDHZ/gWXLttY2tLRbncget+euKr6zoajQa1eQiFQmg0GpfmYiHAYQQVngCnAhH/GoZxprDMaDSKzc1NuK5L2yjT09NU8Fur1dBqtaiQ2XVdNJtNGmhHPrfVaqHRaODFixfodDqo1WpwHAfT09OQJIkKkI86mT58+JDmQvE8j3A4TN8zHo9jZGQEPM/TkfpB4+YkdLTdbiMSiWBycvLYNpVhGHBdl461h0IhNJtNWJZ14cGjsixjZGSEuivncjmEQiGUy2VkMhlUKhU0m00kEgk8ffr0QgiP7/tYWVlBqVSCJEkolUpotVq4f//+UIsewzCIxyXEYiLqdRP1+kV6+PQa6+0Lgrv7cXhs+7rEQAxCd7+7BoPd2/0TX72hpfsVG9DnnjcaDRJVISOZlD45gew9z1w1ofWvGwLCE2BobGxsYHNzE4VCAb/4xS/w2WefnUqou7W1hb29PWrKJQgCZmdn+3xaSHspnU6jWCyCZVnYtg1BECDLMvX/SKVS2NjYgCiKkGUZzWYTqqpS/5dEInHsiVAQBHAchxs3bkCWZXieh06ng/HxccTjcWqoSEwJD6I3d4os3qqq4t69e0d+riAIfdlXjuNQHdRFg2EYmjr//PlzZLNZOrbfarXw//7f/0MoFIIsy0dWq0zTRL1eB9DVMJ3WQdY0zb7wU0VRUKvVoOv6qdp6DMMglZIRj3eJT6NhHDlOfRT2BcD9f6t9cfAgUfD1IzNd7B+LrqloP3E52mzx0x0PzwOqVQPNpvn+u3CxbsbEN0xVVRo9oygKUqkUqtUqBEGg549fF2flq4iA8AQYCu12G9vb24hGo6jX65BlGUtLS/jud7871BWWaZrY3NxELBZDLBajoaBkvPuzzz4DAJqYLssyRkdHUalUcPv2bUqADKPr8jo3N4eXL1/SHC2WZdFsNmGaJkZGRvDFF18cuz2k7NyrzzEMA/Pz89jc3KRkZ3JycqCGxzAMVCoVunjLsoxKpUJzwwZBlmXMzc3RdhzDMFhcXLxw8bLjOFhdXUW5XAbP8+A4DiMjI/TvRjQVx5EO4lhNjpskSXj8+PHQlalWq4W3b99S64HzELxyHItMhnj46Gi19lsJR011+f7RZIc8/qkrBueL/vHxrifPQb8dpo/EXKUIKMfxUSqRqAoF4fDFXDxsbm5SHaHjOKjX61hcXMTdu3dRKBSgaRp4nsfMzMyFfH6A80FAeAIMBZKjRa7+yRWN67rHhlce9frp6WmIoojx8XEaWum6Lg3tfPfuHViWxdOnTzE7O0vFz0tLSzROYnx8HKurqzBNE7ZtY2RkhI6UVyoV2jrqheu61PhQVVVIkgRJkmDbNliWxeTkJFKpFG1jnVQpOi2mpqaQTCZhmiYURbkwrUwv3r17h2KxiHg8Dsdx0Gq1wPM80uk0HMcBCXs9Dru7u3Bdl2aatVot5HK5oSbTOp0Onj9/Tj2ZdnZ2qH4onU5/8DHgeRajo2EkkzIqlQ7a7e4o+2Bn7utFaHojIPbJ2r65YP90VxdXidAMC9P0sLenIRTikcnIkKTzW9ocx0Eul6OTqQBQr9fR6XRoKxsAPWcFuLwICE+AoUCmkMgVvqqqcBwHb968gSzLmJmZOfZqnxgMtttthEIhdDodsCyLb7/9Fq7rIhKJIBaLwbIszMzM9GVz9b6HJEn0pEJONM+ePaMp6YqiwPd9aJp26PW+7+PNmzeoVqvUQ2hvbw/pdBoMw9BUceIKfRxkWUYmk6F6FMuykM1mh6p4ECPGj4VyuYxoNAqGYSAIAtLpNK2IsSyLhYWFE0fQSa4YAc/zsG17qM9vNpvwPI+KxGVZhq7ruHXrFiYnJ8+NgIgih4mJKAzDQaWiUw8fAKjXG9jby8H3fYyOjg504T4f9Gt/zuP99ttN+zEQ+1NOg7RER0VjXA/si8P3g0tJLIamWeh0HMRiAtJpBTz/4QTkqBDdQK9z9RAQngBDQZIk3L9/H69fv4ZhGDSSodPpoNlsol6v48mTJ0fqUTiOw4MHD7C8vIx6vQ5BEGj2TDQaRafTgWma2N7eHroszDAMpqamAABra2uQZRkkqf1gYCXZ1lqtRqsUiqJgd3cXlmWB4zhUq1UkEomhrtIYhsHCwgKNaohGo5iYmLiUCwwJ8uQ4DiT4dX5+nmqIjkqi70U2m0WpVKLVPMuykMlkhvp8kr9GficTcRdV/pdlnnr4lMs6KpU63r5doUaW6+vrRxpmnh0+isUS9vZyALpZQiTP7aTX9VZlSATE/mK6X53pEp1P6cVz8Tg4wt69b7+CtW+6uK8rGhRc2mrZUFUbyaSEZFIGy579eJGYmlKpRAOPI5HIR7GTCHC+CAhPgKGRSCTwne98BwBoVYZlWciyjEajAVVVjxUx+74Py7Lo9BMxEgS6hIoYGhqGgZWVFbRaLYTDYSwsLBx7cpmYmICmaXQCaXJykmZBHYdOp4N6vY5sNgtRFOnE1rAuwxzHYXp6eqjnfkrMz8/jxYsXaDabdCR+c3OTulNvb2/j8ePHxx7jbDaLu3fvYmdnh5K9YQlPOp1GJBJBvV6npOssie+nRSgkYHZWQL2egyQJdNKO6K3Ok/DU6w3s7GwjHA6DYRjs7e1Rctg75XQwpHN/we7+P9hvN11vQkPacKTddrBi1Yv+ya/hj4vvA7WaiWbToiL3s16QEOf4RqOBdDqN6enpj2YcGuD8EBCeAKcC0eGQWIXe+486mei6juXlZayuroJlWXplX61WaUYXcR6emZnBq1evqDGfYRh48eIFnj59eqRWiGVZ3L17F7dudZObj6oyde3xE6jX6zRvi+R5Ad1WU6VS+WSxCheFWCyGp0+fQtM0cByHcrmMdrtNq2CqqiKXy2F+fv7Y9+kNFT0NeJ7Ho0ePUKlUYNv2iWaV5414XMbICA+WFdBsOkPrzoYB+cq3Ws33k38sfB+QJBHNZtdqoXfK6aSQzqsMQmb2CR7Q23rqTjpVUalUADCYmBhHLEYqsRdH8FzXR7lMhM0yFOX0RIVc3FyFC5wARyMgPAFODWLct7a21hcGGovFDj3X8zy8fPmS6j1830cul8PMzAwikQgkSaKj6I8ePUI2m8XGxgZdjEkop2EYJ+pMeomOpmnQdR2iKNLtIjqd3d1daJpGx6IJLMsauA9XGe12G/l8nmpX4vE4CoVC39UpSba/SAiCcCayNAi+71OfpXA4fOJY//j4OAqFAiyrg3DYB8vymJgYZlsOOgST+5gD7ZVuhdJxXEpkHMeFLEswDP2Ue3d50Vup6k9g73eP7q/S7JO9arWKzc1N2npeXV3DwsLCR9OzWZaHfL4DUWRgWddQuR3gRASEJ8CZMDU1BVmW6Yj6+Pj4wBKvaZowDAOxWIwGhWqahq2tLfi+j8XFRaTTabpw2bZN4yE4jqOVpNNckReLRSwvLwPoLo690RY8z9PfXdfFq1evUK/XaUjp+Pg4Hd8+7wmtj412u41vv/2WVt/29vbw+PFjZDIZbGxsoN1uQxRFkHytqwDP8/DmzRtUKhWwLAtRFPH5558fO+klyzKePHmCarUKz/OQTqchihJqta6PC2kx9WI4L5793zOZDOr1OtrtrlhekkSMjY2h0Wh84B6fL2zbogMD/RXa3lbTvtmi5+234XrJC9A/7TXM/5NqtQpJkihBdRwHjUb9owr4AcAwHBSLJgoFDem0DEEIWlO/LggIT4BTIZ/P02Tt6elpzM/PH3uyI5oNkq68trZGF4FUKoW9vT2Mj4/Tk6AgCJibm8Pa2hqAfcIyrN+L67p4+/YtwuEweJ6H53nY3NzEyMjIIY0KEVKTKSIydUa2l1QQwuEwbt++fZbD9UlRLBYB7HsNdTod7O7ugud56mDt+z7u37+PTCYDz/Ogqip830ckEukjmb7vo91uw/M8emw/BUhILPHxabfbePfuHfVxOgpkiq8X2Wzo/Si7DlXtjwM4LdHl+W6IbrvdBoD3LuKXJ0SSYbqt5bdvV95XonxIkghFCeFg+vrBiS+it/lQ8DwPXd+veHne6S5kzhuqakPTbMRiIlIpGRwXjJRfdwSEJ8DQqFQqePv2Lb2yXltbo1WRoyCKIm7fvo3V1VW6iExOTiKZTNKJh1qt1kdGJicnEYvFoOs6JEkaOHF1FBzHged59ETKsiwYhjmyZcOyLF08f/7zn0OWZYiiiN3dXdRqNczOzsJxHLx48eJKTmWQY24YBvb29mg7a2pqChzHwXVd1Ot1WJaFpaUlWu2SZRmff/45gG5VZWlp6b32ojvd9vDhwwuPwxgEwzD6Fkkidj8reJ7F2FgYqZSMt28/7EqfZbkeTcrHRG+0QW/rrd8tOZfLwfdBKyrVavWjTnyNjo6h2Wy+r4L5EEXxVE7tp8XRVSvyDB+ex9CoilRKRiLx6aMqAlwcAsITYGjUajUaycDzPBRFQaVSOVGbQQiMYRjQNA31eh2madJcqUEnmGG8cAZBFEWEw2G0222Ew2GYpglBEIYytzNNE9FoFK7rotPp0JiFSCSCVqt15aYyRkdHkcvlsLe3h+3tbaq18n2fmj6SClyxWEStVqPkT1VVbG5uAuj6+JRKJdriU1UVGxsbWFxcPNX2qKoKTdMgiiKSyeSZFpZoNArH6QqPWZaFpmmYnJyEpmm0+nQW8zdR5JDJiJiaiqLRsGEYF6tpOri8ykwAACAASURBVA16Q0kZhjgldxfzQSaCR5EY0zT7yCKJN/lYCIfDWFxcRLPZAssySCQSEITDGXXD4rAfz9GJ9IPF4vuPex5QqRh0oisWO/t2Bbi8CAhPgKEhimJfurVt2wNDNQchGo2C53m6GJE2UqPRwO3bt6mJ4Iei2WzS2ApN05BKpXD//v2h8qqy2SyKxSIikQhdUCVJ6su/ukqIRCJYXFzEf/zHf0AURarTqdVqqFQqSKVSMAwDyWSS5pURSJJE2w+kqnLQQuA0KBaLWFpaAsMw8DwPExMTuHPnzqlJTzKZxJ07d7C+vk61R4Zh4JtvvqH7/ODBg6G/lwehKDyiURmaZqNS0WFZw6W5fwj6xdDdLCuiK+ou3Cy6i3N3Qe/V05zm8BHBejgcged121ofu0onywpk+eSLj95Jr4Mkr9t+O9qPp/uas1VpbNtDsdihE12h0OVpSwb4cASEJ8DQmJiYQLFYhK7raDQakCTpVOZxjuNAURQIgkCT0n3fR6FQwPT09KlaV4PQbDbx7NkzWipvt9tQFAX5fB7ZbPZEgz0ylk3IgO/70HUdmqZhbGyMmuddJQiCQKs2hAQQgTipiHQ6HVQqFRqMyLIsOp0OZmdnoes6rap4ngeGYdDpdE41ntudyFmluiDf95HP5zE+Pn6mqbjJyUlMTEzA8zwUi0WsrKzQ6lOr1cLW1taJI/YnIRwWEA4LaLVM7O3ZcJyz/e2JO/Kg+/cnnvoXbvI1O+9cr/HxcbiuSwXfU1NTH7XCQ9B7PMg+9hoL9gukcYjkvX+XC91Gw3CRy2kIh3lkMgpE8eKru+TC6qpVkq8SAsITYGiQiRiSCp5IJE51JU3Ijmma1P1XURRYloVcLkddl8+KYrFIyZTjOKjVami1WhgbG0Mul8Nnn33WN41k2zby+Twcx0EqlUIikehr0zQaDWiaBkmSkE6nsbS0dOZt+1SQZZkmzZPsMwD48ssvkUql8Ktf/QqKolDH6Hw+j2g0ivHxcczMzCCfzyOVSmFubg4bGxsAupWw2dnZobfB87w+7xvi5dRbLTwtGIYBx3HQdR2CIPRVnwbFipwVsZgEQYii2bTQaFhw3YOj6v1Geu/v7YkjGGym1/MO57atJ4FlOczMzL6/SGHQbqsol8sX8Em9mqL+ilXXRPDw9FuvseBlktBomgNNUxGPd4XN5xFV0QvbtlGv11EqlVCr1cCyLDKZDG7fvv1JBd3XFcERDXAqCIKASCSCkZGRU7+W53ncvXsXy8vLaLVaEEURpmlSEXSpVDpESk4DkvoNdKd3bNtGPB6nWp6trS363p1OB//2b/8GVVXBcRySySS++OKLvv1KJBJDxS5cZsiyjM8++wxv3ryhROPhw4eYnp7G9vY2OI6DJEkAuhUAlmXx+PHjQ1eZMzMzmJycPLVFAAAaGprP5xGJRMBxHL3vQxGNRrG9vU2rT7qun+m7eRwYhkEiISGRkFGvd3Uertstwwyabnr/qnPdhvPF2bftYFjpwSiM7s/B6eunNVt0XQe6bnwQMT4vNJsWVNVCIiEjmZQ+KKqCwLIsvHjxAvV6HeVyGbIsY2pqCpVKBaIoUiPVAOeHqyVKCHCpUK1W8ebNG7x9+3ZoTUe5XMatW7cwMzODUCgETdOQzWaRyWQQDoexurp65u0hY8eqqqLT6cD3fUpYeskQAHz77bdQVRWJRAKhUAi1Wg3Pnz+nY8XXCb1txHQ6TVtcgiD0LSaO40AUxSNL6kSsflqUSiU0m010Oh1sbW2h1Wrh4cOHZ9bZ9CKbzWJmZgaqqqLVatHbFwGWZZBOK5idjV7LaZ5u1IPf89Ont4lomrTfyE/P623PHe22DnQJjKZpsCzzxG3pdDS8efMGq6tvsbu7i3K5dB67+AHw4Xk+6nUD29stNJvmB4eHFotFGIYBSZJoK7nRaEBRFNTr9XPa7gC9CCo8Ac6EcrmM169fQxRFeJ6HcrmMJ0+enDgNpes6FEVBIpGgwmWy8HEcB8MwBpq+DYNwOIzHjx/TvCfbtikR03UdCwsLALpXoc1mk36u4zhotVpwHAe//OUvcePGjVO1bC4zXNfFy5cvYZomTNOErut49uwZfvM3fxOZTAa5XK7PeLE3VqNSqWBvbw+//OUvMTk5ibGxMei6TrVYw5Af3/fx9u1bxONxpNNp6pJ8XmAYBnNzc5iZmaHTZxcNjmORzYaQSHTNC1ut4VLjPyUGjWh379+v2hzUEh14hw/6/E5Hw9raGhzHge8Dk5MTGBs7errz3bt3ALp+RrpuYHt7B9FodCjB8+lxMA29P/GeVK26vwO27aNU0tFomMhkFITDZxM2k0BfIuQnFyCWZX2wnjHAYASEJ8CZsLPz/9s78+A4yjP/f3vuU6P7sGTrtGxLxpaNDYQKgeCQJSQLlSxXliQE4kp2F3JQGwLZ1A+WkAKyJCy5KlVJOFML4QjHVg6SLJtrw336PiTLtmTZOmak0dxHz/P7Q7yvelo9o5E0kuXx86ma0kyrp6e7551+v/19nvd5B+B0OmU4JBgMwu/3y9nLc1FZWYlDhw7BZrPJ94o6OeFweMEzjpvNZgQCATnkfWJiAl6vF93d3TLUoSiKzFmJx+OYmJhAJpNBbW0tvF4v+vv7UVNTc0rW3dETj8cxPDyMwcFBOb2H3W5HZ2cnamtr0dPTg0AggEwmA5/PJwXr6OgoduzYAVVVoaoq9u7di+PHj2NychKKosBms2HDhg2zniOj/J18dZHyMTY2hr6+PqRSKdTX16O1tVW6UYWMwis2VqsZdXVulJer8PtjiERO3lD2+QzRFs/z5xgVh/7+fiiKArfb/d70MkMoKyuDyzUzrJnJqEgkkvB43LKURSIRx5EjR9DR0QGzeS7dVi4xMyXCkskkbDYbXC53nglKjc9PMpnB0FAELtdUYvNcqaqqwrFjx+BwOOB0OuXEpHOZwJiZGyx4mCVl5cqVSCaTGBoagslkwtlnny2HkNfV1aG9vX1B2z9x4gTS6XTWXFxut3tGXscZZ5yBZDKJsbExpNNprFixAnV1dTCZTDCZTEgmk3k780QigbGxMaiqKqfGWI6IxOxUKgWHwwFVVRGPx7Fr1y5ceOGFsFgsWecmk8ng4MGD2LNnDyKRCNLptBQrBw8eREdHhxzFtX//fmzatCnv54v8qImJCXg8HiQSiXnl74RCIezevRtOpxMul0u6eAttL8XAbjdjxQoPYrE0xsZiiMeLnXMiHM+pENNSDdEuFkQZxOMJeDzurP0RAlyPyWSGwzFVFmFsbAzJZAImkwMTExM4cuSoJrdlppiZcktEjlG2MzPF1OtQKIS9e/fJ9zU1rURdXd28ji8aTePo0RDGxxNwuQofzefz+bBu3TocPXoUtbW16OzsRFVVFTwez0kR8KcDLHiYeSFmNRcOgMViQXV19azvM5lMWL16Ndrb26EoCkZHR3HixAn5XOTzzBcxEen4+LgMjxmF2Xw+H84991xEIhG8++67IJqazTmZTMJkMuUNzcXjcbzzzjtIJBJQFAVHjhzBxo0bl+XEo8KNicfjSCaTUBQFVqs1Z87V0NCQTC5OJpMIh8MIBoPSfhe1iBwOR8H5TmvXrsXBgwcxPj4Op9OJzs5Ow9BTIpGQycd6QqEQgOmh9V6vF2NjY8tC8AicTgtWrvQiHE7C748XNEFlriHa2jmspt2aqdyZpR6ivVAUxQS32yXD2aK8g3B4jWhra8OePXsQi8WgKEBdXS1cLjfGxwPIZFbBZDLDSMzop8UwIp1OIxgMYtWqVTCZTMhkMhgcHERlZcWCCiFGImkMDERgtcZQUeEoKLG5urp6Qdc7Zm6w4GHmRXV1NTZs2ICRkRGYzWY0NjbOqYiZcFH2798va/Kk02ns3bsX55xzzrzvcGpqarBjxw5Eo1FYrVbE43F4vV7DwoF2ux2Dg4PIZDIYGxvDiRMn0NTUhI0bN+a9GI+MjGTF2aPRKI4ePYr169dnraeqKvr7+xEIBGC329He3j7rjO/Fxul0ZiVBivyoXBdZMXrO7XZjcnISmUwGgUAA5eXlsgq12WxGJBIpOM/AZrPlneuKiNDX14djx45BURS4XK4ZI3NE3SCBcKyWIx6P7b0aPkmYzdPDrMUQ7WlXJt8Q7eLNYbX0kGwnQnS0trair69PTq7a2toMh8MhQ3F6Z8bpdGHt2rVIJBJIpVLvhZyE06V1s+aOCKeK64H4q6oqFmqsEAGBQALBYBIVFfaSTG4/lWHBw8ybysrKBc2Fk0qlsoY5i0ktxaSXLpdrztt3uVxwuVwyt0MUDAyHwzMcmGAwiMHBQVRVVaG6ulrW3JltKLpwkQS5SvT39fVhaGgIHo9HOklbtmzJK6aKjahtZLFYkEhMjY6x2WyIRCIIBoMzRIvb7cbIyAhcLhdWrVqFYDCIlpYWdHV1IRAIyArHbrcbnZ2dRdnH0dFROeGrw+HA5OQk4vF41jqirYkEa7PZvKzcHT2KosDns6OhwY6qKgfGxxNQVe1UEKXZCSaTKezatROJRPI9kd8Gt9sNu92Brq4uJJPJ98oSTP3mteJO+xqYaouVlZUYGBiQNaRWrlz5nrszf8T0OFMjpBxIJOKw221FTXhXVZJTVVRVOeD1zr5tLjy4+LDgYU4adrsdZrMZiUQCdrsdiUQCoVAIBw4ckOKntbUVLS0tc9quw+FAbW2tFCXBYNBwPRHiEes5nc6CitZVVVXhyJEjiMfjsvaLfh9FBWmfzydHQE1NnBheUsEj7PuqqioEg0HplIgJQc8555ys9RsbGzExMSFntPf5fNi4cSMsFgsaGxtRV1eHdDoNu704d66ZTAY7d+6E3+9HKBSCoiioqqqS4kwgZrYfHx9HJpN5b8TO8nR4tCiKgooKB3w+O8bH4xgfT8y5Hk2xiEQiGB4+AVVVUV1dA6t1rpd/kQytzSmadmZUVUUg4Ed9fb0Mifb29qG7u1uGoGy2ubR9BatWrUIsFkN9fT3cbndRJmc1m82oqamRRSrdbhdaWloWLKSmoKxpMdJpFcPDkfemqnDC6TQ+536/HwcPHpTOdENDA6qqqni0VpFhwcOcNCwWC9avX4/du3cjGAxCURTY7XYZ9jGZTDhy5AgaGxsLDnFZLBasWLECg4ODsNvtsvigUSjJ5XKBiGRibiQSKajQYFlZGXp6enD48GGoqop169ahvr4+ax3hQmhHKE2FNJa29JUQlMFgEKqqyqRhIYSmQw9TWCwWnHHGGTLH5913380afm6xWIpaATYQCCAej8Nms8HpdEJVVYyMjBhe6E0mE6qqqor22UuJqOHj800NZQ8Gk0v6+bFYFPv375N5WIcO9emSdPOLmeyCgvq/U85MMpmEqqrSKbHZbAiHp0ZCzXc4uZi8t6FhxbyP3QiLxYK1a9dhemTb7MychV7RJZCLczQzvyoWUzE4GIbHY0VVlSNrqopYLIZ9+/ZBVVX4/X5MTEzgwIEDqK2tRUtLC1dcLiJ8JpmTis/nwznnnINUKoVEIoE///nPcpZum82GsrKy92LrhQfX29vb5ZB0t9uNxsZGQ6EhJtc8cOAAMpkMysrKCg7TlJeXo6enJ+86q1evlhWOM5kMqqurl/yOTYgccVEWc2KdOHECTqcTfX19WL169YwQnRCIi51/oKqqzOESdZnMZvMpK2xmw2IxobZ2uoZPKLQUNXxIOnZO55QrpihTYnMqzEsGib+FJQBrER2zyJebSkDHMu+wxQSllOW8TVWQnh7mP7NO0RTZE7nOfo7C4RQikZScqsJsNskiqYFAQA6TB6YE5PDwMLs8RWQ5t0TmNEHMSh6JRBAOh2E2m9+7OwzDYrHMOQRkMpmwYsUKWXk5H3V1daipqZFOTDE7+NraWjmayWq1oqqqaskdHhGiEx0QMHUn6nK50NraiqGhIdTX15+0EWZerxcmkwnl5eXw+XyYnJxEU1PTnGdjP9Ww2cyor3ejvDwNvz+OaHS+NXxmd2bE6C/tnFXTy6Y69WI0e4tlaqLaWCwmlzU3N8NiOXlDrLVCZvr8aAsuaof1T5M9Eq64op8ImJhIYnIyiYoKhwzfq6oqb0xEeQxRQJUpDix4mGVDKpVCTU0NkskkEokEKisr4Xa7F91lEBeXxaCsrOykDlefvtNWZJ6UoihobGyEzWZDLBaDqqqYmJiQ+UVLKcxcLhc2btyIgwcPIplMoq2tDStWrMCePXuW5PNPNg6HBY2NHkSjKYyNxZBIaIeyG4kZ7aSkhTkzijKV9D08PIxIJPKeICI0NTUWXVi6XC50dnZKp8JuX8w8K9IINa1TM/XcuODitPCbFjlLm0BONDWIYqoMRgp2uxUVFfXw+/1Ip9NQVRU+nw9EBLPZXBIFUJcLLHiYZYPDMXW3U1lZCZPJhHA4vKDZ05mpcyocMnEBFTOVx+NxmM1mBINBHD58WI4283q9aG9vNxRqmUwGAwMDGB4ehsViQVtb24InWC0vL8fWrVvla33C8umAy2XFqlVWhEIJjI/HkUhkcogZbe2Zwp0Zm82OtWvXyqra5eUVIMosipNmtzsWLHS0ib/TjowQMaK8gmlGArjWqVmOw8EzGRW9vb3v1ZVSYLNZ0dnZCaezDh0dLkxMDCIQGJYFTcXoSKY4sOBhlg0+nw+tra04fPgwFEWB0+nEmjVr5rWtcDgsQ0mVlZXL8uK3FNjtdtTW1soRUEQk5+txu91Yt24dduzYIYXl4OCgnF+rvLx8xnD7gYEB9Pf3y1E4O3bswJlnnrlsK02fani9dng8NkxOJhEIxJFOF29Il93uyEr+DYdDRdt24Uy7VVNMV0mezhXKDjFNOzLT65+qv+dAIIBQKCRz5GKxGI4dG0JbWxucTi+cznXo6DgDlZUOOBwW+R6mOLDgYYrOxMQEhoaGoCgKVqxYMaeku+bmZtTX10NVVTgcjnmFVsTEpiJZuK6uDuvWrTtlL5ILwWQyYcOGDdizZ48cJVZXV4eenh45WkskmY6Pj8sSAR6PB/F4fMaQ/uHhYXg8HjlaS4wAY8FTPEQNH6/XhomJKccnU/iMBSeN6ZnWhTgRIafpSTgLm6+qdH+nqVQKJpMJZrMCs1mBxWKHzZZGVZUDFosJFovy3t+lzfU7XWDBwxSVYDCId999F1arFUSEkZERbNq0aU55LAutU3Pw4EG43e6sfVixYsWCQy+nKlVVVbDZbAiFQrDb7WhubpZD0cWUIKOjo4jH40in0zIMZlRQ0WKxIJlMZg21X96jcE5dTCYFlZUO+Hw2jI8nEIkUNpXHYiCGZGsTgKeHq0/nxGgTo/VzehUrOXo5YzIBNpspS7yYzdPPKyrqAYzB67XBZDJhcjKBVasaUVm5/GtKlQJ8pWKKyvHjx2GxWGSiXSQSwYkTJ5YscZeIkEql5FxYorCgfqqC04VMJoMdO3bIiUDF6/POO08O9V+zZg1sNhuOHj0q6xgpioJ4PD6juF9bWxveffddOdTd6/UuqNo2MztmswnV1U6YTB6Ew/5F+ITpRGghSmYbkq0PMc1GOBzCkSNHkEqlUFFRgaampjnOer50RKMRTE5OQlFMcn6tqeH12Q7MlEMz/VdRXCgv96K6Ove1zuGoRGdnJw4dOgQiwooVK7By5colPLrTm+XZ4piSgfRZhYuMoiiora3FyMiIzDMxm81LPofVckHMTK8oChwOB9LpNI4fP45QKCSFisViwerVq9HR0YGjR4/iyJEjSCaTWLVqFY4fP561vfLycmzZsgXBYFDWy2GHZ2mwWEyorrajudkLvz+OcDj/cGUxJFs/m7gIN03/NrMn4cwWMgu3ZBKJOA4cOACr1QqHw4GxsSnR1tzcsuBtF4MpwTIlWmKxCIaGemE2KzCZCBMTQWzatEHWL8pHIZOFAlPT3Yiij+K7ISJZj8flci15+YrTBb5SMUVlxYoVGB4eljNpZzIZNDQ0LOk+rF69GiaTCWNjY3A4HOjs7FzS6RyWE4qiyBngE4mEHKZuNPeXoihobm7GqlWr5OsTJ07MWM/tdnPOzknEZjOjocGNeDwNvz+GWGzKvVQUkrk+WtFiHGJSliynLRqNgWh6pnu324VAILDogkdRAKt12oERboyiEPx+O1pavO85M9PnYdeuw6iqckpnc3JyEuPjATidxa30rP3MTCaD/fv3w++fEoIejwfd3d3znkCZyQ0LHqaolJWVYfPmzbKjbGhoWHJ3xWKxYM2aNfMe4VVK2Gw2WK1WBAIBKXY8Ho8M+RlxOiZ3A1Nu2MTEBDwezykxT9dUDR8vIpEU/P7sGj7L6Ss0m02YHpU1Ve17oZ25NrRksSjv5clkh5xyOS6qqsJuN8FqnTl3lqqqWe7KUoTDR0ZGMDo6KufdC4VCOHr06LKeHPdUhQUPU3S8Xi/Xz1kmpFIpeL1eORQdmJ4tnb+jaQYGBjAwMCDnVevq6jplprdwu61wu61yKHsqtbyGdHm9XpSXl783vcVUXlBZWRkOHjwAl8uF+vp6mc9jMiFLyDgcGYTDNjQ0uHQuzeIourq6Ohw4cAAAZGXyioqKRfksgZgwVByTqDrPFB8WPAxT4phMJsRiMcRiMaTTacTjcezYsQPhcBgdHR0ne/dOOrFYDIcOHYLD4UBZWZmcSf7cc889pXIpysps8HqtCAanhI+qnqRp2XUoignt7W2IRiMgUjE2NoJEIgqn045k0o9IJIP167tgtZpnuDLRqIJg0AKPx7Yk+ypya4aHh2E2m7Fq1apFd6i9Xi8GBwdlRfR4PI7q6upF/czTFRY8DFPCWCwWjIyMyCHnQvBYLBYcO3YMtbW1cgRdKpXC8PCwHEmzlMP4p2q0EDKZDFKpFDKZDGKxGDKZjFwu/oqH0fJ8y3L9PxqN4vjx4yAiOXFtPB6XlanFnb6iKO/VUDHnfZhMJlgsFlnROhwOZy0zm82L5lAoioLycjvKyqaGsk9MLH4NH23Sr9ttQWWlwzDkBFQiFoshHB5Eba0Y2efG5OQkMpkUTKaT3x0pioL6+nrU19cvaDuxWAxHjx5FMplEVVUVGhoacn7n1dXVWLlyJY4dOwZFUVBZWckjtxaJk9/CGIYpOkJATJWwB5xOJ2KxmOzABwcHUVNTA7/fj1QqhWQyiX379iEajcq8hebmZiSTSRw+fHhOwsJImBSCmCwRmKqUvXfvXrlMO5mifpl+udVqLXhdUWtIVVUMDw+jubkZ8XgcdrsdW7ZskXfcAGQhSzHRY65HKpVCPB6Xz48ePQpVVWWyeEanQERByNmEVDKZRCwWg9/vz7mOOH8mk4KqKgfKy20IBOIIBpMzpmGYjamh2AomJvyIRMLweFxobGyA3W7NypfRduTHjllRVZU7/0k7Kml68tLSQlQgz2QysFgs6O3thaqqOUWMoihobW1FU1MTiCgrvMUUFxY8DFMAQkCk02kkk8l5OwvzdSEikQheffXVOQsIIWYikUjWjOmRSAQWiwWTk5NIJBIIh8MyYVdRFKTTaQwNDcHhcMwQEIU81y+bywU8kUhg586d2Lx587y+q/nQ09ODF154AaFQCF6vF93d3TP2WVEUKSwKZXx8HF1dXXnXEW1rNiGlqirS6TQmJiZy/l+P2GciBeFwBrHYVBKxzWYBkQqiBOLxcdjtVthsFthsZs1zK44ePYrJyeOw2+0IhSYxNBTF+vXr5x3qs9vtqKmpwcjICKxWq5ww+FRIEi+UyclJpFIp6ZwKN3U214ZHZS0+LHiYk8J8wxTRaBRjY2NytuH5Cgv9skKIx+OYmJiAzWabtYPPtUzchc/FsTCZTHjjjTdw5plnzllAEBEqKyvxpz/9SYodt9sNj8eDs846S+bwjIyMIBwOyzCWSHImIjQ2Ns7jGz618Pl8aG5uRk9Pz5J3vuL7NJlMeTu9yclJqKo6p9E7ekcqlUqDaGpZKBTC+LiK8nILVDUNVU0gEskgGExLcdXb2yuHkwNThUUnJydht9sNHaZEIoHDhw/ndapWrlwJl8uFWCwGr9eLurq6knI09M6VCI0yJx8WPCVCMZ2FfOuqqopIJIJ3330373sKYT5ugXAstPkQs4mM2bZbqIDYs2cPGhoaFn3UhhGKosyrwJ+iKLDZbKipqcHk5CSsViusVitWrlyZdcdZVlYGq9UqnZ9oNIq2tjYcO3asmIexrJnvOV7OiDZvJKSsViuSyWRO5yGdTiMcDsPr9crfx+TkJDZu3Ai3220Y3vP7/XC5XFnhvXyOVTAYxODgYNbnasURESEcDqOvr0/mQenzpLTXAm0e1VKKqPHxcRw7dgwTExNob2+H2z2VmyTmq+vs7FyyfWFyU1q/7iUinU4jEoksWUhDLyDC4TBeeumlrGXau8SFhB7MZrOMIRutC0xd9Nrb23Nud64hjLmQTCZP63mx5goR4fjx42hvb5czyCcSCbS3t2cVY3Q4HOjp6cHhw4eRTCbR2NiIxsbG00rwMNlYLBbU19fL0GYymYTH44Hb7Za/d71AtFgsqK2tnfdn6kN7kUgEAwMDKC8vnxHai0ajM0SXyJHS50kByLpBikaj2L9//6x5U0YJ6fprWyAQwO7duxEOh5FMJrFnzx50d3djcnISyWQSFRUVJ+UmiZkJC555IDLwteGJXAJBCIj5hD9yCYiXXnoJ55577kk5dlVVT+upGk5FRNvx+Xzw+XyYmJgwLDzodrvR3d291LvHLGPa2trgdDoxOTkJp9OJxsbGRR2qL1w2rZCy2WwLrokkbh5FqHbPnj2or6+f4Tglk8m8jpSRkBoeHpaVy4VI2717N+rr66VbKkZG5nKkFnPkHjMNC5554PV6sX79em6gzLJHjAA5ePAgrFYr0uk0ysrKlmwyV+bUxmQySbfvVERVVcTjcZjNZjgcjiyB4fP5Frx9IsJbb72FSCQiR/eJ35jH48lynuLxeN5RfnrEDbOooaXf/0If3E9Nw4KHYUqcwA2EBQAAIABJREFUpqYmOJ1OTExMwOFwoK6u7pRMoiQimb91Ku4/s7TEYjHs3r1blhVoampCS0tL0bafyWTQ29uLQCCAsbExAEBVVRW8Xq90xha6fVVVceDAAVRVVWXlRmmFVCKRyOtK6dGONjSbzfjVr36FQ4cOIRgM4u6775Zhy+uuu67kxBILHoY5DaiqqjplpkowIh6PyzwJk8mEzs5OWRWXYYw4ePCgdFsymQwGBgZQUVFRtHD88PAwTpw4gdraWng8HvT398NsNmPjxo0LFjsAsvKknE5n0VxZIaREXahLLrkEx44dw86dO9HR0YFwOIxIJFKQ2Ln++uvxq1/9CrW1tdi1axeAqZymq666CocPH0ZLSwuefPLJZZPDdOrUTWcYZkEcP34cr7/+Ol5//XWMjIws6meNjY3hwIEDMgl6oezfvx+xWAw+nw9OpxN79+7l+YaYvEQiEVliQORDFqMtCsLhMGw2GxRFgdvtRmVlJdxuN1wuV9E+YzEQo/bsdjvcbjfOOOMMXHzxxbDZbLjiiitw3XXX4cYbbyxoW5/97GfxwgsvZC275557sG3bNhw8eBDbtm3DPffcsxiHMS9Y8DBMiZNOp/H222/jr3/9K8bGxqCqKvbs2YNAILAonzc0NISdO3didHQUR44cwTvvvINUKjXv7RERgsEg3G43gKmRQIqiIBqNFmuXmRKkrKxMthFVVUFERa2x5Ha7kUql5CjaVCq17MVOsfnABz6AysrKrGXPP/88rr32WgDAtddei+eee+5k7JohLHgYpoQhIuzduxe9vb0gIkxOTsLv98Nisci8g2Jz+PBheL1euN1u+Hw+RKNRBIPBgt6bSqXkHFoCRVHgdDplLoYo1aAdVs8wetrb2+F0OhEKhRCJRNDW1gav11u07dfX16OmpgahUAiTk5PweDyGYdZMJiPnsjsdGB4eRkNDAwCgoaFh0d3kucA5PAxTwiQSCQQCAXg8HkQiEdjtdmn1L1YpezFPkqDQOZOGh4exf/9+WcCuu7tbujrr1q3Djh07EAwGQURobm7mkWZMXhwOBzZu3IhkMinLgxQTk8mENWvWoLm5Wda70ifTR6NR7NmzB4lEAoqioLOzU86EnkgkEI1GYTabs4o7MosHCx6GKXHE9BKRSASRSATJZBI2m03ehRWblStXoq+vD06nE6lUCna7fdYhwLFYDPv27YPb7QYRYWxsDLt378ZZZ50FAPB4PNi6dStisRgsFstpFzpg8pNOp3H06FGMj4/D7XajpaUFDocDJpNp1jBWNBpFJBKB2WxGeXn5nOoMCfdRPNci3FVVVeH1epFOp7F//354PB4kk0ns2rVLupX19fXo6OgoCdFTV1eH48ePo6GhAcePH19QIcpiwyEthilh7HY76urqEIvFUFNTA4/Hg46ODmzdunXR5oxauXIl1q5dC7fbjbq6OvT09GTNx2SECFeJgnNWqxWxWCwrDGC1WlFWVsZih5nBgQMHZFXwQCCAXbt2FRRCmpiYwNtvv439+/dj9+7d2Ldvn2FxwfmgqipisZgURKJtx+NxWRdL1MQ6ceJEwWHf5c6ll16KRx55BADwyCOP4LLLLjvJezQNOzwMU8IoioI1a9bAZrPhxIkTaGpqwpo1axZ1gkxFUdDQ0DAnB0nk44i6IalUCg6Ho+TmtmKKTyqVQiAQQFlZGRRFgdVqRSgUQjQanTXs2dvbC7vdLgW53+9HMBgsyjBqs9kMm82GRCIBu90uE6ftdjvi8ThcLpectDeVSqGpqemUmzLnk5/8JP70pz9hbGwMTU1NuOOOO3DrrbfiyiuvxAMPPIBVq1bhqaeeOtm7KeGrCcOUOOFwGL29vTJfIBqN4swzz1xWSb8ulwudnZ2ydgoAnuaCKQgx5FzkjolpJAoJTaVSqayaOYqiFC25WFEUrFu3Drt370YoFAIwnUhdWVmJ3t5eJBIJKbaOHDmC+vr6otTwWSoef/xxw+UvvvjiEu9JYbDgYZgS5/XXX5ezTRMR/H4/VqxYUdSqs/nQJzHnoqGhQeYa9fb28nxtTEGYzWY0Nzfj0KFDMJvNUFUVtbW1MuE9H9XV1Thx4gS8Xi9SqRQURSlqu/N6vTjzzDORSCRk7RsA6OjowIEDB6AoCjKZDJqamqCqKsLh8CkleE41WPAwTAmTSqVw+PBhWCwW2O12EBHC4TCGh4cXXfCoqoq+vj6cOHECFosFHR0dsyYwig5hMSeoZEqPpqYmuN1uORKxqqqqIJHd1tYGRVEwOjoKm82G9evXF11wWK3WGSPErFYrGhsbs8orBINBDuEuMnx2GaaEUVUVFotFlpIXbstShLMOHz6MY8eOwefzyWKHDoeDh5Mzi0JFRcWcc2/MZjM6OjrQ0dFRtP3IZDKYmJhAOp2Gy+XK6Rh1dHRg9+7dSCQSICJUVVUVZUJTJjcseBimhLHZbKirq8Pg4CCAqYuxx+PBqlWrFv2z/X4/vF6vnBPIZDIhFAqx4GFKFiLCgQMHMDo6Kh2mtWvXyto7WsrLy7Fp06Z5D4ln5g4LHoYpYUwmEz7wgQ/gb3/7G4aHh+H1erF169YZ5eCLQSaTgaIo8kIvihwKm15V1UUrdsiUBqqqor+/X4aYGhsbT/YuzUosFsORI0dw7NgxeL1exONx+Hw+mQDd29trKHiAqWR9LrOwdLDgYZgSx+Vy4aKLLlq07RMR+vv7MTAwAEVR0NzcjFWrVqG9vR3vvvuurI5cWVmZ88LPMMBUGPT48eOyUN++ffuWtSOYTCaxc+dOqKoKVVVx4sQJmEwmObzcbDYjnU4XnLjPLC4seBiGWRBDQ0M4cuSIzD84dOgQnE4namtrsWXLFoRCIZjNZvh8PrbsmbyMjo7C4/HAZDLBZrOBiJBIJE72buUkFAohmUyirKwMsVgMPp8Pw8PDiMVisNlsCIfDqK2tZbGzTGDBwzDMgggEAnA6nVLM2O12TExMoLa2Fna7fVnV+2GWN1arFel0Ws5JRUTLWiTr981kMqGurg52ux2JRAL19fVobW09SXvH6GHBwzCnAaLMvcViKXqVZafTifHxcbldMX8Ww8yVjo4O7Nq1S45cqqiomDEh53KirKwMXq8XwWAQsVgMqVQKGzduRH19/cneNcYAFjwMU+JEo1Hs3LlTdiItLS1obm4u2vZXrlyJ8fFxmatTVlaGFStWFG37zOmDz+fD5s2bEQ6H5dQMhw8fPtm7lROz2Yzu7m6Mjo7iyJEjqKurY7GzjGHBwzAlzv79+5FOp1FWVoZMJoP+/n6Ul5cXreaH3W7Hpk2bEAqFoCgKvF7vsr4rZ5Y3TqdTFv+LRqMneW9mx2KxoKGhAbFYDF6v92TvDpMHFjwMU+KEw2FZZl/MO1TsRFCLxVKUCRcZhmEWCxY8DFPieL1enDhxQs4VZLPZkMlksG/fPqRSKdTU1KCuro5HkjAMU9Kw4GGYEqe8vBx79+4FEckcm3379sFiscBisWBsbAyZTIbzbhiGKWlY8DBMieP3++UkiWazGSdOnMDk5KScXsJsNmNwcJAFD8MwJQ0LHoYpcRRFyZqVWSwTcBVYhmFOB1jwMEyJ09LSgh07diCdTiOTych5fiYnJ2E2m5FKpdDV1XWyd5NhGGZRYcHDMCVOZWUlNm3ahEAgALPZjLq6OgDA8ePHkUqlUF1dzSOsGIYpeVjwMMxpgM/nm1F3p6Wl5eTsDMMwzElg+U5SwjAMwzAMUyRY8DAMwzAMU/Kw4GEYhmEYpuRhwcMwDMMwTMnDgodhGIZhmJKHBQ/DMAzDMCUPCx6GYRiGYUoeFjwMwzAMw5Q8XHiQYRhGQyaTmfFaURS53GTi+0SGORVhwcMwzLJELzyAqYlOcy3T/q/Q9bT/M5vNeOWVV2CxWGCxWGC1WmGxWGA2m+Uyo4eYeJWIssRQJpORDwGLJYY5ebDgYRgmL0stPNLpNEKhEF5++WWYzWYpPPR/9c/NZvMMQUFEIKIs8ZHJZEBEUFU1a1ltbS1UVYWqqkilUkin00gmk0in03K5eGi3o0WIH0VRYDKZYLFYMDg4OCexpJ25nmexZ5jiwYKHYU4RjIQHMFM4FEt4AIDZbMZLL72UJTyE0MglRIyEh9hmJpOBqqqGIkQ8VFVFW1sbMpkMUqkUUqkUVFVFLBaTgkPM/K7dnpH4EMJDPMxms3xoj8disch17HY7nE6nXF/7XqPnWtEiRFIqlUIikZDPo9GoFE/ieNLpdNY+i30V+61HVVV4vV5Eo9E5iyV2lhiGBQ/DzJmTITySySRefvnlGc5GPuGh7Yz129Q6FEaCQzxvaGiQDkc6nZYduhAfQnjM5nrkEx5610O7jtVqLVh4aDt1sW/JZDLrkUqlsv5Go1F5DOLcaIWM2O9c51Acnx79sWqPx+12Zy3Tiybt9yLOq9Zl2r9//wyxpHW59NsW29ceBxEhGo3KbeuPg8USU4qw4GFOWRZLeOTahqIo2LlzJ2w22wxxYbPZZggQ0XkDuUMT+hCLVoBoRUR7e7vs9ITrEY/HEYlEsjpDfdhGIDpvbSeu7RjziQ7RURciOsxmc5ZDIYSH2GfhegjRIR6xWEx24mK/taJBu+/670X7MMJoH61WK+x2u6HwUBQlS9CI70Ub0tKKQPG5iqIYhtm0n6EVftpwm/jutN9hvmXaNiWcpVQqJY831znStwuz2YwdO3bI71f8nU/Okrb9as89wywXWPAwC2aphcfOnTvhcDgMHQ698NBfcHMJD21noL1wazsbn88Ht9stnQ6tS6DtBPUdk7ZDzCc89J2kkaiw2Wwy3FKI8yE6b63oEPutfaTTacTjcaRSqZyioxDhIY7dCCOXx2QyweVyGe63dmSU3oHSiw99Jy6+fyPxoRUe4jP037XRsnyCUuxjMplEIpHI+s5znSchosV51goNsd9Op1Meh91uh81mg91uh8WS+9KdSzTr26b2/Ik2MJ+cJW1btlqtRctZYrHEFBsWPCXEUgiPTCaDSCSCN954I0tY6EMsQnjkEhjaC592HX2SqT65tLq6GuXl5UgkElJ4xONx+VwvPLSdtzah1Eh4aB0Nvcuhf2632w076lwCxEh0aMWH+CuOS7vPevGj33ftuTPq6HKdf/0+6o9H63YYJf8aiQ6xP/q2oX3oBR2AWZ0NsW3t96Vtn9r3ivOs3W9te9O2M+3/hENjJDwcDods11rRoQ+lGaFtw7mOUys2RMJ0PB5HOBzOKTz0Qlr73ChsqHVw9GE2I7drtpwlEQ7T7rO2TYdCoazl+lyr2dqzaBd2ux3JZDKns6Q9dgGLJcYIFjyLwGILj2QyiXfeeWeGyNCLj1zJj1pyCQ9xHHrnI5PJYP369VlhiUQigWg0Ki9u2twObaditD9G4mO2C67WEbHb7YaugVF+h7Zz1osN7etEIiHv0sXn5MqL0B6TkSukdwWM0O6jPmFW3w6M8ju0naE4p2azWYbe8j2EU5DPBSjELTDan2QyOSPkpG/zejGqdTrEX207dzgc0unQfi9G4TQjxD4YHafWtRPtIZ1OIxKJYHJyck5iWvvcSEiLv/p2pXXw8v0OtE6YdlSZdr/1wjqRSCAcDmede6PPEN+D/vpg1PaMrld6MS2+N6PP0X4n2uuMeJjNZqTTabz77rszbgK0olQfhtN/jtF+p9NpFkunGSx45sH999+Pvr4+VFZWorq6GlVVVaiqqkJlZaV8brPZst5TyPDSfOEW7d31+vXrZfghkUjIPA5xFyX+ivfqR3+Iu3ajz9bby7MJj0LzO7QdjVYU6QVHKpXK6kCNcmG0+6jNs5itc57tQg1AdjrifOkvfvoRQtrtaoWdPgwhHloHTJy3XIKpULGh/59W2AnHSNtB58p5yeV0aUc0if12Op2GLpheZM7W7rXHLESSPsFY63ZonTz9MRh1VPnCiLMJCn3CdK71tTk/RkJDv0zsu9hnrROjz/PR/i5zibW5CBCtmDJyCMVvSv85ekEthIyRu2v0XNxw5Gu/hf4V3388Hp+1Xedq4zabDQcOHDAUS/owaKHOUq5rCrN8YMEzD66++mocOXIEo6OjGBsbw9DQEHbs2IGxsTH5SCQSGB8fh6IocDqdcDgc8Hg8cLlcyGQy+OQnP4mGhoasETW5HAAAeZ0L0bHmungDyNkhai1pkfQoPk/bQevvnLTb1oedhGgpVIDkQuRXiM5PH47QCg6t2NC7XtrcB+1zvYOiZS55EEb/Ex2dEKTiQq0PSWgvkkY5LkZuh3b4t1Zs5nMCChUfWodLn1wci8UwOTmZ5XII8oUmcolr/THnOg6HwwG3251XfBu1cX3b1goO8T+tmDO6EdA6DyJsN1uHrN2HXO1aK260bV3fNvSiWru+2G/Rpo1y2HLlsunbt9G+52vz2jYej8ezriu5BIjWxTNq43o3TxyXkTidS7vWHrOqqkgkEvJmUZvPFolE5DFp85i0bVjv4GmXq6oKq9WKUCg0Z7EkzguzuCizqFKWrPMkHo/jwQcfhMVikT+qWCyGRCKBeDwOp9OJyclJjI6OYmRkBOPj41JweL1e6RxpXSSRv+J2u2Gz2ZBOp+FwOFBRUVFQqKGQ50D+PAftcq3QAGB4p6TNexBCQ3/nXEhHnK+j0S/ThyT0FzB9xwLkdgK0ya5a4ZHPzSo0FKE/RtGJ5EosFselHc2kvXs3cvL051B7Ho3Qd0aFHI/efdCHJfTCWvtZucJs+k4OQMHis1ABor/26cMs4jON2rpoG3rnS9vOxXNtx5ePQo5LL6q1Scb6ZGOtWNKSK3ycy+nQuk96oWL0eraQorgp0uev6V29XHk/2nYujke7fSORpf2O87Vt/fnQr69tD3rXSfv71Dt54lznat/aa45WJKmqiuHhYbS1taGsrCzrmIotli644AK8+eabC97OMiBnA2TBs4wQP9RgMCiFkN/vx/33348DBw5kWfm1tbUwm81Yu3YtzjjjDPljstlscDgccDqdcLvd8Hg88Hq98Pl88Hq9M35s83EB9I6O9o5Pe9ek//HrnYFcuT2F5PXMFkIrdJk4ZqMkYqOLsvaOT98ZaC/44gKkv0jm6sxy/Q5nE1Tau0z9xVhsX3/eZ8vx0Tt74u51Lg5XoaGJ2cJsRi6YcPGMnC+x70JYi/BkoeJa/9n5QiqirRsJD+05N/p+Zwu15XJUC+mYjUJu+k40X8hNe0zaTlu0R/1vJ5eAN7pJMaJQAaINx+sdMK3Q034H2vM9WwhOe74B5G2/c/mf/ubK6CZSu9zoRkwkzevbfb4wnPb6qj0P2r/i/AMseAAWPMseEYbw+/0YHR3Neojw2ujoKPx+P8bHxzEyMoJMJiM7BSGKMpkMPv7xj6Ozs3PGxVaPkQswH7EhfpT6C5VWcIjn2s5aH2bLdcdkJMwK7ayN0Aov/UU+l+gwEhrajlnrBhQ6wm0uYZV8HbbWedGKpHwX3lyhCKMRe/lCEQsRIKIGkTZpXt+Bi0c+F0/7vRn9XytCCnE2ChEi4rvTi4xcuT/a31yutq5tj9p8okLdLyNyCQ492jajFx7acypcMKNwm36ZcPTE95Mrn2guokM/itOonetzf/Q3XPo2b+TuiVC5kVCbL2L/jRLTRVkMbVVvvbsnBO4jjzwCRVGQSCTkPokk+VgshjfffBMjIyPz3s9lBAseZuqO5ec//zkcDgeISI6uisfjiMfjUBQFoVAIIyMjUjTFYjEAUxdcbVK2NllbhNo8Hg/MZjMSiQTKysrgcrnm1SHrl+kvRNo7JH3Hpb34AjMdAe0FVh9+cDgc8+6IC+lYcl209OE2vY0/W7gt35DjuVj4sx23NhShHfljFI7Qfm/67es7Z/1d+1zdgNmEiLaz1ncEWuGnPS7tuc83ElLv7M2nc87X3rXo80f0v4dcbV8vKvThZW0hzULbvdHvNJfwEB2utv3nCr+JY9Ifs5HQFm1ee3yziey5uNliX/TtPtdoOH05hEwmM6Pd7du3D/v27ZPCSJxzm80m0x60j2g0Kq/RyWQy67wQTY2yc7lccLlccDqdhs+9Xi9cLhdOnDghc/TE38bGRlx55ZVwOBz43Oc+hxdffLGg73+Zw4KHmT9EhFQqhUAggJGREeka3XrrrVn1cMxmMyorK2GxWHDOOeegpaUlKwHRKNRWXl4Ol8uV90I11/i0vtMRycP6JFzROWsvwOL9wHRCrRYjl2CuomIu6wLTBe1mC7tpHQ0jQaR15rTCw0hsGolPo2tFvnBjrjCEkSjQnn+xb7OF2/SOQL5cr/kID60zoN2+XnTrX2vPi77wnt7d0+b5zLe952r3WsdUnwOWS2wbhd6M2r1RWHE2kTHbMiPX1EhkGzliRvlhRq4jEWFoaAiDg4Nwu91wuVwyzzIej0uBEYvF5Gu9ANE/14aqxLkSzkl5eTl8Ph/Kysrg9XoRiUQwNDQkP0d87vbt27Fq1aq8wsVqtc6rXZyGsOBhlg5x8Y9EIlnhNSGWtI/R0dGsC4wQRXa7HT6fD2azGWVlZfjUpz6V1TmIi7sR+lDEfISIPm9FH4bQCg6BPlyl75S12y405JBPiOQLR+jdgHx5Plq3TC8u9Am42ryYQttCPiGVT2jkSzrXu2D5vnttx6zvAGdrF/Nx/MR5Fu1Ee0edK79NnCutm2EUCtE7f7mOvZBjyrdM61bpiyIaiQ/tPuVyw7Svo9EofD6fHHwhBIReZIjnRv/LJ0JSqZS8lmgfZWVlCAaDOHDgACYnJxEMBqWgveKKK9DU1CQFhpHo0L8WrjCzrGDBwyxv/vznP+PNN9807ChUVYXD4ZB5SmNjY7K6st1unxFeq6ysRE1NjVxWU1MDj8cjOxDRyS/kzt+og86XF5ArYVHrxOQLPWjrERXDCTA6Bv3IMH0ITpv/oBdb+ZwArcs0l7v9uYbfiCinKDV6aDtpbY6Gdvt6ly9f+DKfAC3kuLVCQy9K9eE3rSMG5K9sPdsQ9VxtRBtiMRIV+ufiIXLutKE10c6F0/v888/L3MJMJgOz2Yyamhps3Lgxr8hwu915BYh4brfbF5Q3w5zSsOBhSgvRbiORiHSKtC7SU089hb6+PtlhZzIZVFZWwmQyoaOjA1dffXVWIqg+5OZ2uwvKCTDqsOZyDKo6XWxPX/9G6wToc2L0oSkguzid2H6+TjhffkOhx611q/QOgF5waDtovZOkzcEwCunNJUFV/3e248+XT6R34kRehjYRV5uwmsvdKFbnm8lkpNMh/kYiESk2RBvSJq/qc6kA4MEHH8TAwIAsWmqxTM3bVV1dLT/LZrPNKiyMREguQSLmBTNC1PPxeDxFOU/MaQ0LHub0Ih6PG474yGQycrSauMPU5iX5/X6MjY3B7/dLq95ms8Hn88HhcMgEQGGRC4FwxRVXwGaz5Q1VzZYLU0gIQu9SGTkAIklUn3hrVOlZv0x/91+oyzWX/+XKidF+T9r/i2MQ56KQOk/a4bmLcacv8trEQ5v/oR1BphWr4hyMjIzgiSeegNVqRSKRkILI4/GAiLLEi1E70QqIfIJE5KjkWs9msyGRSCAWi2FiYgImkwlnnXVW0c8VwywxLHgYZq6I30YsFsNjjz2GZ555BsD09BKiU1VVFW1tbQiHw7IDFEP+vV4vysrK4PP5UFFRIcNuIuQmpiCZS6dsFOrIJzKEANKHp7QPIzfIaHSMVnAIZ0Ybaiskd2Q+OTGFhKu0IkN/DMK5SSQS+N3vfge3251V20RRFMTj8RnhGaPRMmL72two4ZDM5oiIoqF+v1+6eGL7l1xyCXp6erIECYdlGGbOsOBhmKVAuBITExNZLpK+PpLf78eePXsQi8Wk0LBaraitrYWqqlizZg2uuuqqGaN8hGtRaA5MIWEpo5wY7egYo7pI2ufakInRaCrxPBaLQVEUVFVVIZ1OZyWkaoXFfEbLxONxef4FiqLA7XajsrIS5eXlslTCnj17EI/HMT4+LkNAH/rQh3DuuecW5JxYLDwjD8MsY1jwMMxy449//COSyaQclp9MJhEMBuWs1qFQKCvUNjo6imAwKN/v9XplYrY2aVskcQsXyeFwAJjdRRIiZL6jZcRkjgIRdhJiob+/H2+99Rb8fj/i8ThMJhOcTie2bduW1xHJlz8iXovZuBmGOe1hwVMoL7zwAr785S9DVVVs374dt956a9b/E4kEPvOZz+DNN99EVVUVnnjiCbS0tMj/Hz16FF1dXfj3f/93fPWrXwUATExMYPv27di1axcURcGDDz6I973vfUt5WEwJIVykycnJvC6ScJISiYQcdZNKpVBeXg5VVbNCMiLPJ5ew0IuMQoftWq3WvEIrFovB6XQu1aljGKb0yXnBYW9Wg6qquOGGG/CHP/wBTU1N2Lp1Ky699FJ0dXXJdR544AFUVFSgt7cXv/jFL3DLLbfgiSeekP+/6aab8JGPfCRru1/+8pdx8cUX4+mnn5alwBlmvohE3PLycpSXl6Ozs3PW94i6SJFIBNXV1cumdgiLHYZhlgr2gDW89tpr6OjoQFtbG2w2G66++mo8//zzWes8//zzuPbaawEAl19+OV588UV5l/zcc8+hra0N3d3dAKbcoo6ODjz22GMYHR0FMDXUs7y8HMCUW3TVVVeho6MDZ599Ng4fPpz1WUePHoXH48F3vvOdrOWqqmLTpk342Mc+VvRzwJQmYhRQXV3dshE7DMMwSwkLHg3Hjh3DypUr5eumpiYcO3Ys5zoWiwU+nw9+vx+RSATf/va3cfvttwOYSvq84YYbcP/996Onpwf33nsv1q1bh+3btyMSiQDIdotuuukm3HLLLVmfZeQWAcD3vvc9rFu3rqjHzjAMwzClDAseDbnqoxSyzu23346bbrpJFs4aGBhAR0cH6uvr8fbbb+Pqq6/GZz7zGbjdbtxzzz0ACneL9u3bhzVr1qCjowNf//rX8etf/xrbt2+Xnz9Xp2hgYAAf/OAHsW7dOnT/jPVXAAATwklEQVR3d+N73/vePM8YwzAMcyoQCARw0UUXYfXq1bjoooswPj5uuN7FF1+M8vLyGRGEa665BmvWrMH69etx/fXXy2l1/vSnP8Hn86Gnpwc9PT345je/uejHMl9Y8GhoamrCwMCAfD04OIgVK1bkXCedTiMYDKKyshKvvvoqvva1r6GlpQX3338/HnroIYRCITQ1NaGpqQnve9/7cOzYMVx++eV46623ABTmFmUyGTz77LP47W9/iz179uDHP/4x/umf/ilrRMpcnKIXXngBF1xwAXp7e3HttdfilVdewY9+9CPs2bMHwPzCbC+88IIUZELMMQzDMNksVHT09/fj7LPPxurVq3HVVVfJGdRnu24DwD333INt27bh4MGD2LZtW85r9c0334yf//znM5Zfc8012LdvH3bu3IlYLIaf/exn8n/nnXce3nnnHbzzzju47bbbCj0dSw4LHg1bt27FwYMH0d/fj2QyiV/84he49NJLs9a59NJL8cgjjwAAnn76aVx44YVQFAV//etfcfjwYRw+fBhf+cpX8PGPfxxdXV2or6/HypUrcfz4cSiKghdffFEmQRfiFh07dgzV1dVoa2vD73//e6xduxa9vb1Z7ynUKRJhtj/84Q/o6+vD448/joGBAaxbt06G7uYaZhOJ3kKQPf7441I8MQzDLDcKFR2PPPIIVq9ejdWrV8trfigUkk5GT08Pqqur8ZWvfAUA8PDDD6Ompkb+TysIBAsVHbfccgtuuukmHDx4EBUVFXjggQcAzH7dBrL7iWuvvRbPPfec4Wdv27YNXq93xvJLLrlEDpg466yzMDg4aPj+ZY3RZIeax2nHr3/9a1q9ejW1tbXRt771LSIi+n//7//R888/T0REsViMLr/8cmpvb6etW7dSX1/fjG3cfvvtdOONN9KHP/xhIiJ6++23qbGxkerr6+myyy6jQCBAREQf/vCH6aWXXiIiolQqRVVVVZTJZOj9738/NTc3U3NzM7lcLrLZbPSDH/yAbr31VqqoqCCv10t1dXXkdDrpmmuuoe7ubhoYGJCf39bWRqOjoxQOh+mcc86hUCg0Y5+IiO666y66+eabaeXKlRQMBvPuExHRs88+S1/96lfp9ttvp3vvvZeIiO677z5yuVzU3t5Od999N91111101113yc+Ix+N05ZVXUnt7O5111lnU399PRESvvvoqbdy4kTZu3EgbNmygZ555Rr7nvvvuo66uLuru7qarr76aYrHYfL9OhmGYLG6++Wa6++67iYjo7rvvpq997Wsz1vH7/dTa2kp+v58CgQC1trbK67aWzZs305///GciInrooYfohhtuyPvZnZ2dNDQ0REREQ0ND1NnZmXPdP/7xj/TRj35Uvs5kMlRVVUWpVIqIiF566SV5Pc933Rb4fL6s1+Xl5QV/tpZkMkmbNm2iv/zlL3LdyspK2rBhA1188cW0a9eunNtdInJqGhY8i0QqlaLW1lY6dOgQJRIJ2rBhw4yG8MMf/pC+8IUvEBHR448/TldcccWM7Vx++eV01llnydePPvoo3XjjjVkNsqura4bgGRsbo3/913+lJ554goimRNinP/1p+tznPifX+8lPfkI1NTX0y1/+Ui4rVDzde++9lE6nqba2lq688kp5jHfffXfWj/5HP/pR1jFeeeWVREQUiUTkD3doaIhqamoolUrR4OAgtbS0UDQaJSKiK664gh566KFCTzvDMKcAfr+fPvShD1FHRwd96EMfMhQTREQPP/wwdXR0UEdHBz388MNy+fnnn0+dnZ3ypml4eJiIct9gaSlEdDz22GP0+c9/Xr7+/Oc/T4899ljWOgcOHKCmpiYpLAoRPAsRHaOjo9Te3i5fHz16lLq7u4lo+rq9bds26u7uJqvVSmvWrKHu7m7q7u6m5557rmiCZ/v27fTlL39Zvg4GgxQKhYhoyjDo6OjIud0lIqem4ZDWImGxWPDDH/4Qf/d3f4d169bhyiuvRHd3N2677Tb893//NwDgc5/7HPx+Pzo6OnDfffcZ2ptlZWWYmJiQrxeSV/TMM8/IcFMqlcL3v/99dHZ24hOf+ITcFhWYlA1MDeOvr6+H1+uVw/jfeuutrETvXOE2l8slS/TH43EoioLf/e53OO+88zAwMIC7775bVv4Vx5srTv3aa69JG3njxo149tln5edPTEzg8ssvx9q1a7Fu3Tq8/PLLs311DFPyLCSsE41G8dGPfhRr165Fd3d3VnHWQsI6QGGhnUAggDvuuAOvvvoqXnvtNdxxxx1Z+/lf//VfMm+ktrYWQGGhneHhYTQ0NAAAGhoaMDIyMmOdQkbsPv7447jqqquyrne//OUv4fV64fP5ZIKveOhLnMyVXNdm7f/+53/+B7t27cLKlSvxt7/9Dbt27cKuXbtw2WWXoa6uDsePHwcAHD9+XJ6zuXDHHXdgdHQU9913n1xWVlYm+4VLLrkEqVQKY2Njc972kpBPDS25LmNmUCynSBvSymQy9OlPf5rOPffcrPATUWFhNp/PRxUVFXT99dfTxz72MWmrPvroo3TOOedkbTOXY0RE9Morr1BXVxe53W56+umnqa2tjfr6+ug73/kOmUwmqqiooH/8x3+U752rW0REtG3bNqqrq6P29na68847aXx8POt45xNyIyJKp9PU09OT8y6IYfT89re/pc7OThn+1ZPPnbjrrruovb2dOjs76YUXXih4m7lYSFgnEonQ//7v/xIRUSKRoPe///30m9/8hogKczmIFu6ynH/++fT666/PeI+4fm3bto26urrIbDbL8PhcnI7/+I//oDvvvFO+/uY3v0nf+c53stZZt24dvfHGG/L12NgYxeNxIiL68Y9/TB/84AfnddyCYoe0vvrVr2Z95zfffHPBn01E9NOf/pTe9773SfddcPz4cflZr776Kq1cuXLGZy8xHNI6lSlWXtG3v/1tam1tpSeeeIIAkMPhoDVr1tDGjRvp17/+NREVLp7uvfdeevLJJ+m6666TguzBBx+kqqqqLEGWK9ymZc+ePbRu3Tratm0bBQIB+uAHP0j/9m//RnfeeSdddtll9POf/5yICvtRHzp0iGpraymVSlEgECCLxUK9vb1SLO7evTtr/fmIKCKi7373u/TJT36SBQ9TEOl0Wgr6ubbF3bt304YNGygej9OhQ4eora2N0ul0QdvMRbHCOkREX/rSl+gnP/kJERUueAoRHffee+8M0SFyB88//3xav349bdy4kb75zW/K60C+GyxBMY79nXfeodWrV+c8vnQ6TWVlZTOWL1R0XH755fT4448TEdEXvvAF+tGPfkREhV23x8bG6MILL6SOjg668MILye/3ExHR66+/npXq8P73v5+qq6vJ4XBQY2OjFNhms5na2trkjeAdd9xBREQ/+MEPqKurizZs2EBnn302/e1vf8t5TEsECx5mimKJp3vvvVfeYYhtVlZW0kUXXZS1biEihWjqQnXppZfSk08+Sddffz09+uijdMMNN9AjjzxC//zP/yzXKcQtEm7Mww8/TGVlZXTttddST08Pbdmyhf793/99zvunFVG//e1vqbW1lZxOJ23fvn3GBWmujtHRo0fpggsuoLVr11JXVxfdf//9ht8bszDm6678/ve/p82bN9P69etp8+bN9OKLL8r35MojMUJ7N05EM5L7iXK3Rf26Yr1CtpmLhQoOwfj4OLW2tsrrxEMPPUT19fV0xhlnUE1NDXV2dkp3pZguy+DgIBERTU5O0kUXXUSPPPIIERV2g1WI6PD7/dTS0kKBQIACgQC1tLRIgUBEdMstt9Btt92W9R4hooiInnnmGTr77LNnbHehoqOvr4+2bt1K7e3tdPnll0tHqZDr9mkECx6m+Cwk3Hbo0CHpmBw+fJgqKirommuukcLlpz/9Kd1www30mc98hr7//e8TUeFu0datWykWi9E999xDiqLQK6+8QkRTHcWWLVuy1p+LiBJ31BdffDG9/PLL1NbWRueff37W9ubqGA0NDdGbb75JRFMX79WrVxd8l36qMF+x0d/fTw6HQwoKcV6JiN544w1av349tbe30xe/+MW8FvpC3JW33nqLjh07RkREO3fupBUrVsj35AqrGPHUU09ldWhC0GvJ1RZvuOEG6XISEV1//fX01FNPzbpNkcC6GIKDaOr3f/HFF9N//ud/ymWFhHWIiuswaV2lQm5gChUdDzzwALW3t1N7ezs9+OCDWdtobW2lvXv3Zi279dZbpdNxwQUXzPg/s2Sw4GEWh/k6Ro8++ih1dXXRxo0badOmTXT33XfLu9XbbruNqqurqba2lj71qU/JC2ihbtEFF1xAr7/+Ov3kJz8hj8cjl3/jG9+g5ubmrHXnIqL++Mc/0qZNm6TjtH37dlqzZk3WunN1jPRceuml9Pvf/37G8lOVhYiN/v5+OQpFz9atW+mll16iTCZDF198scwhMWIh7oqWTCZDlZWVsj3ORfA8+eSTM8TJjTfemLVOrrb4L//yLzMEz9NPP13QNnNRDMFx3XXX0Re/+MWcn5ErrEO0MJcllUrJm5JkMkn/8A//QD/+8Y+JqLDQDlPysOBhljfFdIsaGhpodHSUXnrpJSovL6d9+/YREdGFF15I5513XtY25yKi7rnnHtqwYQM1NjbK5G2LxULXXHONXG+uYTct/f39WTWRSoGFiI1cgmdoaChLaOo7Zj0LcVf029m2bZt8nSuPxIjlFtJaaFjnG9/4Bn3iE58gVVWz3lNIWIdoYS5LOBymzZs30xlnnEFdXV30pS99idLpNBFxaIchIhY8zKlAsdyiZ599loimOo0VK1bQ+vXraf369VRWVjYjoW4uIupnP/tZ1sX461//+oIcI21BxVAoRJs3b86qiVQKLERs9Pf3k8vlop6eHvrABz4gC529/vrrWcLjL3/5S97k8YW4K4Jdu3ZRW1sb9fb2ymW58kiMWIig37VrV1bScmtrK6XT6YK2mYuFCI6BgQECQGvXrpXhxp/+9KdExGEdZlnAgoc5PSmmiNLfUc83pEU0HXYjmrLlP/zhD9N3v/vd4p+Ak8xCxEY8Hpei44033qCmpiYKBoP02muvzRA8H/vYx3Luw0JDWgMDA7R69Wr6v//7v5yfUcjopIUMGPjWt75FbW1t1NnZmRW+M9omw5zmsOBhmIWyGGE3URNJW7m0lChW/gzRdM7MXENaC/nexsfHacOGDfT000/P2GauPBKGYU4qLHgYphgUO+z217/+lQDQGWecIcMDoiZSKbAQsTEyMiJzM/r6+mjFihUy9LJlyxZ6+eWXZdLybOdsvt/bnXfeSS6XS343Yvh5vjwShmFOKjk1jUI0s1y1thDzkpR7ZhimZPnNb36Dr3zlK1BVFddffz2+8Y1v4LbbbsOWLVtw6aWXIh6P49Of/jTefvttVFZW4he/+AXa2trwy1/+ErfddhssFgvMZjPuuOMO/P3f/z0A4I033sBnP/tZxGIxfOQjH8EPfvCDrBL/DMOctuS8ELDgYRiGYRimVMgpeHjyUIZhGIZhSh4WPAzDMAzDlDwseBiGYRiGKXlY8DAMwzAMU/Kw4GEYhmEYpuRhwcMwDMMwTMnDgodhGIZhmJKHBQ/DMAzDMCUPCx6GYRiGYUoeFjwMwzAMw5Q8LHgYhmEYhil5WPAwDMMwDFPysOBhGIZhGKbkYcHDMAzDMEzJw4KHYRiGYZiShwUPwzAMwzAlDwsehmEYhmFKHhY8DMMwDMOUPCx4GIZhGIYpeVjwMAzDMAxT8rDgYRiGYRim5GHBwzAMwzBMycOCh2EYhmGYkocFD8MwDMMwJQ8LHoZhGIZhSh4WPAzDMAzDlDwseBiGYRiGKXlY8DAMwzAMU/Kw4GEYhmEYpuRhwcMwDMMwTMnDgodhGIZhmJKHBQ/DMAzDMCUPCx6GYRiGYUoeFjwMwzAMw5Q8LHgYhmEYhil5WPAwDMMwDFPysOBhGIZhGKbkYcHDMAzDMEzJw4KHYRiGYZiShwUPwzAMwzAlDwsehmEYhmFKHhY8DMMwDMOUPCx4GIZhGIYpeVjwMAzDMAxT8rDgYRiGYRim5GHBwzAMwzBMycOCh2EYhmGYkocFD8MwDMMwJQ8LHoZhGIZhSh4WPAzDMAzDlDwseBiGYRiGKXlY8DAMwzAMU/Kw4GEYhmEYpuRhwcMwDMMwTMnDgodhGIZhmJKHBQ/DMAzDMCUPCx6GYRiGYUoeFjwMwzAMw5Q8LHgYhmEYhil5WPAwDMMwDFPysOBhGIZhGKbkYcHDMAzDMEzJw4KHYRiGYZiShwUPwzAMwzAlDwsehmEYhmFKHhY8DMMwDMOUPCx4GIZhGIYpeVjwMAzDMAxT8rDgYRiGYRim5GHBwzAMwzBMycOCh2EYhmGYkocFD8MwDMMwJQ8LHoZhGIZhSh4WPAzDMAzDlDwseBiGYRiGKXlY8DAMwzAMU/Kw4GEYhmEYpuRhwcMwDMMwTMnDgodhGIZhmJKHBQ/DMAzDMCUPCx6GYRiGYUoeFjwMwzAMw5Q8LHgYhmEYhil5WPAwDMMwDFPysOBhGIZhGKbkYcHDMAzDMEzJw4KHYRiGYZiShwUPwzAMwzAlDwsehmEYhmFKHhY8DMMwDMOUPCx4GIZhGIYpeVjwMAzDMAxT8rDgYRiGYRim5LHM8n9lSfaCYRiGYRhmEWGHh2EYhmGYkocFD8MwDMMwJQ8LHoZhGIZhSh4WPAzDMAzDlDwseBiGYRiGKXlY8DAMwzAMU/L8fxsSDmayT6B/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "x_max, x_min = Tensor(principal_components.max(0)), Tensor(principal_components.min(0))\n",
    "X_ = np.arange(x_min[0], x_max[0], 0.01)\n",
    "Y = np.arange(x_min[1], x_max[1], 0.01)\n",
    "X_, Y = np.meshgrid(X_, Y) \n",
    "\n",
    "# pred = Tensor([])\n",
    "# for i in range(X_.shape[0]): \n",
    "#     input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "#     pred = ch.cat([pred, input_@w_transform.T + ols.intercept_], 1)\n",
    "# ax.plot_surface(X_, Y, pred.numpy().T, alpha=.15, color='green')\n",
    "\n",
    "actual = Tensor([])\n",
    "for i in range(X_.shape[0]): \n",
    "    input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "    actual = ch.cat([actual, Tensor(pca_ols.predict(input_))], 1)\n",
    "ax.plot_surface(X_, Y, actual.numpy().T, alpha=.15, color='blue')\n",
    "\n",
    "\n",
    "# emp = Tensor([])\n",
    "# for i in range(X_.shape[0]): \n",
    "#     input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "#     emp = ch.cat([emp, Tensor(ols.predict(input_))], 1)\n",
    "# ax.plot_surface(X_, Y, emp.numpy().T, alpha=.15, color='red')\n",
    "\n",
    "ax.scatter3D(principal_components[:,0], principal_components[:,1], y, color='grey', label='S', alpha=.4)\n",
    "ax.view_init(0, 145)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.575098814229249\n"
     ]
    }
   ],
   "source": [
    "phi = oracle.Left(20)\n",
    "indices = phi(y).flatten().nonzero(as_tuple=False).flatten()\n",
    "x_trunc, y_trunc = X[indices], y[indices]\n",
    "alpha = x_trunc.size(0) / X.size(0)\n",
    "print(\"alpha: \", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2:  0.4670807850836223\n",
      "empirical variance:  22.095067977905273\n"
     ]
    }
   ],
   "source": [
    "trunc_ols = LinearRegression()\n",
    "trunc_ols.fit(x_trunc, y_trunc) \n",
    "score = trunc_ols.score(X, y)\n",
    "print(\"r^2: \", score)\n",
    "emp_var = (y_trunc - trunc_ols.predict(x_trunc)).var(0)\n",
    "print('empirical variance: ', float(emp_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trunc_transform = x_transform[indices]\n",
    "w = Tensor(trunc_ols.coef_)@random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncate Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "We will now use our algorithms to try to correct for this bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ch.linspace(0, 1.5, 100).reshape(-1, 1)\n",
    "\n",
    "# scale wind by actual noise variance\n",
    "y_trunc_mu = y_trunc.mean(0)\n",
    "y_trunc_scaled = (y_trunc - y_trunc_mu) / ch.sqrt(gt_var)\n",
    "y_scaled = (y - y_trunc_mu) / ch.sqrt(gt_var)\n",
    "\n",
    "beta = LA.norm(x_trunc, dim=-1, ord=float('inf')).max()*math.sqrt(X.size(1))\n",
    "x_trunc_norm = x_trunc / beta\n",
    "x_norm = X / beta\n",
    "\n",
    "scaled_ols = LinearRegression()\n",
    "scaled_ols.fit(x_norm, y_scaled)\n",
    "\n",
    "trunc_scaled_ols = LinearRegression()\n",
    "trunc_scaled_ols.fit(x_trunc_norm, y_trunc_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ch.linspace(0, 1.5, 100).reshape(-1, 1)\n",
    "\n",
    "# scale wind by actual noise variance\n",
    "y_trunc_mu = y_trunc.mean(0)\n",
    "y_trunc_emp_scaled = (y_trunc - y_trunc_mu) / ch.sqrt(emp_var)\n",
    "y_emp_scaled = (y - y_trunc_mu) / ch.sqrt(emp_var)\n",
    "\n",
    "beta = LA.norm(x_trunc, dim=-1, ord=float('inf')).max()*math.sqrt(X.size(1))\n",
    "x_trunc_norm = x_trunc / beta\n",
    "x_norm = X / beta\n",
    "\n",
    "emp_scaled_ols = LinearRegression()\n",
    "emp_scaled_ols.fit(x_norm, y_emp_scaled)\n",
    "\n",
    "trunc_emp_scaled_ols = LinearRegression()\n",
    "trunc_emp_scaled_ols.fit(x_trunc_norm, y_trunc_emp_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_trunc_transform = Tensor(trunc_ols.coef_)@random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "\n",
    "x_max, x_min = x_transform.max(0)[0], x_transform.min(0)[0]\n",
    "X_ = np.arange(x_min[0], x_max[0]/2, 1.0)\n",
    "Y = np.arange(x_min[1], x_max[1]/2, 1.0)\n",
    "X_, Y = np.meshgrid(X_, Y) \n",
    "\n",
    "with ch.no_grad():\n",
    "    emp = Tensor([])\n",
    "    for i in range(X_.shape[0]): \n",
    "        input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "        emp = ch.cat([emp, input_@w.T + trunc_ols.intercept_], 1)\n",
    "    ax.plot_surface(X_, Y, emp.numpy().T, alpha=.15, color='red')\n",
    "    \n",
    "    actual = Tensor([])\n",
    "    for i in range(X_.shape[0]): \n",
    "        input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "        actual = ch.cat([actual, input_@w_transform.T + gt_ols.intercept_], 1)\n",
    "    ax.plot_surface(X_, Y, actual.numpy().T, alpha=.15, color='blue')\n",
    "    \n",
    "    \n",
    "    pred = Tensor([])\n",
    "    for i in range(X_.shape[0]): \n",
    "        input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "        pred = ch.cat([pred, input_@w_transform.T + trunc_ols.intercept_], 1)\n",
    "    ax.plot_surface(X_, Y, pred.numpy().T, alpha=.15, color='blue')\n",
    "\n",
    "ax.scatter3D(x_trunc_transform[:,0], x_trunc_transform[:,1], y_trunc, color='grey', label='S', alpha=.4)\n",
    "\n",
    "    \n",
    "red_patch = mpatches.Patch(color='red', label='ols')\n",
    "\n",
    "green_patch = mpatches.Patch(color='green', label='our algorithm')\n",
    "blue_patch = mpatches.Patch(color='blue', label=\"$W^{*}$\")\n",
    "plt.legend(handles=[red_patch, blue_patch, green_patch], loc=\"upper right\")\n",
    "    \n",
    "ax.view_init(9.0, 220)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will our truncated regression algorithm with known variance of the truncated regression data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(x_trunc_norm, y_trunc_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   18.88254 ,   787.4221  , -4972.1377  ,  2633.556   ,\n",
       "          -646.74243 ,   214.78758 ,    -5.972389,  -320.45624 ,\n",
       "           -11.254149,  -300.3299  ]], dtype=float32),\n",
       " array([0.36083272], dtype=float32))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_, reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([22.4292]), tensor([22.0951]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_var, emp_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical weight:  Parameter containing:\n",
      "tensor([[   18.8825,   787.4221, -4972.1377,  2633.5559,  -646.7424,   214.7876,\n",
      "            -5.9724,  -320.4562,   -11.2541,  -300.3299]], requires_grad=True)\n",
      "empirical bias:  Parameter containing:\n",
      "tensor([0.3608], requires_grad=True)\n",
      "weight bounds:  Bounds(lower=tensor([-4.9404e+00,  1.2093e+03, -5.3137e+03,  2.3596e+03, -7.1175e+02,\n",
      "         1.5237e+02, -2.8686e+01, -4.0427e+02, -3.9637e+01, -3.5918e+02]), upper=tensor([   43.0014,  1257.2842, -5265.7417,  2407.5557,  -663.8094,   200.3102,\n",
      "           19.2559,  -356.3237,     8.3044,  -311.2369]))\n",
      "bias bounds:  Bounds(lower=tensor([-21.4898]), upper=tensor([26.4519]))\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   18.8825,   787.4221, -4972.1377,  2633.5559,  -646.7424,   214.7876,\n",
      "            -5.9724,  -320.4562,   -11.2541,  -300.3299]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0039, 0.0000, 0.0001, 0.0014, 0.0011, 0.0005, 0.0702, 0.0044, 0.0898,\n",
      "         0.0018]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3608], requires_grad=True)\n",
      "bias grad:  tensor([0.5116])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   18.8821,   787.4221, -4972.1377,  2633.5557,  -646.7426,   214.7875,\n",
      "            -5.9794,  -320.4567,   -11.2631,  -300.3301]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3097], requires_grad=True)\n",
      "Iteration 1 | Score: 0.14045941829681396\n",
      "updating best value\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   18.8821,   787.4221, -4972.1377,  2633.5557,  -646.7426,   214.7875,\n",
      "            -5.9794,  -320.4567,   -11.2631,  -300.3301]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3517e-04, 5.0959e-05, 9.0816e-06, 1.8402e-05, 1.9319e-04, 6.5397e-04,\n",
      "         9.1830e-03, 7.9672e-04, 1.0875e-02, 1.5094e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3097], requires_grad=True)\n",
      "bias grad:  tensor([0.0525])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   18.8821,   787.4221, -4972.1377,  2633.5557,  -646.7426,   214.7875,\n",
      "            -5.9803,  -320.4568,   -11.2642,  -300.3302]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3044], requires_grad=True)\n",
      "Iteration 2 | Score: 0.09340514987707138\n",
      "updating best value\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   18.8821,   787.4221, -4972.1377,  2633.5557,  -646.7426,   214.7875,\n",
      "            -5.9803,  -320.4568,   -11.2642,  -300.3302]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.7391e-03, -5.3426e-05,  1.1452e-04,  1.3740e-03,  1.2328e-03,\n",
      "          2.2456e-03,  8.4950e-02,  4.5237e-03,  8.7112e-02,  2.1684e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3044], requires_grad=True)\n",
      "bias grad:  tensor([0.5162])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   18.8812,   787.4221, -4972.1377,  2633.5554,  -646.7427,   214.7872,\n",
      "            -5.9888,  -320.4572,   -11.2729,  -300.3304]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2528], requires_grad=True)\n",
      "Iteration 3 | Score: 0.06902902573347092\n",
      "updating best value\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   18.8812,   787.4221, -4972.1377,  2633.5554,  -646.7427,   214.7872,\n",
      "            -5.9888,  -320.4572,   -11.2729,  -300.3304]], requires_grad=True)\n",
      "weight grad:  tensor([[2.1100e-03, 0.0000e+00, 8.3214e-05, 9.4097e-04, 8.6962e-04, 1.4817e-03,\n",
      "         6.4452e-02, 3.0809e-03, 6.3269e-02, 1.4669e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2528], requires_grad=True)\n",
      "bias grad:  tensor([0.3703])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   18.8810,   787.4221, -4972.1377,  2633.5554,  -646.7427,   214.7871,\n",
      "            -5.9953,  -320.4576,   -11.2793,  -300.3306]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2158], requires_grad=True)\n",
      "Iteration 4 | Score: 0.03551940247416496\n",
      "updating best value\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   18.8810,   787.4221, -4972.1377,  2633.5554,  -646.7427,   214.7871,\n",
      "            -5.9953,  -320.4576,   -11.2793,  -300.3306]], requires_grad=True)\n",
      "weight grad:  tensor([[2.2461e-05, 0.0000e+00, 3.4539e-05, 3.6368e-04, 2.4055e-04, 9.1560e-04,\n",
      "         3.2467e-02, 1.3591e-03, 2.6087e-02, 8.0135e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2158], requires_grad=True)\n",
      "bias grad:  tensor([0.1457])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   18.8810,   787.4221, -4972.1377,  2633.5554,  -646.7427,   214.7870,\n",
      "            -5.9985,  -320.4577,   -11.2819,  -300.3307]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2012], requires_grad=True)\n",
      "Iteration 5 | Score: 0.02557745948433876\n",
      "updating best value\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   18.8810,   787.4221, -4972.1377,  2633.5554,  -646.7427,   214.7870,\n",
      "            -5.9985,  -320.4577,   -11.2819,  -300.3307]], requires_grad=True)\n",
      "weight grad:  tensor([[1.1373e-03, 3.8395e-05, 7.0611e-05, 8.1935e-04, 4.2482e-04, 1.6285e-03,\n",
      "         5.7248e-02, 2.4866e-03, 5.3300e-02, 1.4697e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2012], requires_grad=True)\n",
      "bias grad:  tensor([0.3070])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   18.8809,   787.4221, -4972.1377,  2633.5554,  -646.7428,   214.7868,\n",
      "            -6.0042,  -320.4579,   -11.2872,  -300.3308]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1705], requires_grad=True)\n",
      "Iteration 6 | Score: 0.05507345125079155\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   18.8809,   787.4221, -4972.1377,  2633.5554,  -646.7428,   214.7868,\n",
      "            -6.0042,  -320.4579,   -11.2872,  -300.3308]], requires_grad=True)\n",
      "weight grad:  tensor([[1.3492e-03, 0.0000e+00, 6.3654e-05, 7.9149e-04, 4.1331e-04, 7.6810e-04,\n",
      "         4.1824e-02, 2.0122e-03, 4.8866e-02, 1.2109e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1705], requires_grad=True)\n",
      "bias grad:  tensor([0.2800])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   18.8808,   787.4221, -4972.1377,  2633.5554,  -646.7429,   214.7868,\n",
      "            -6.0084,  -320.4581,   -11.2921,  -300.3310]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1425], requires_grad=True)\n",
      "Final Score: 0.009129256010055542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=1, bias=True)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_phi = oracle.Left((phi.left - y_trunc_mu) / ch.sqrt(gt_var))\n",
    "trunc_reg = TruncatedRegression(phi=scaled_phi, alpha=Tensor([alpha]), lr=1e-1, unknown=False, bs=10, n=1, tol=1e-2, steps=2500, val=int(.1*y_trunc.size(0)))\n",
    "trunc_reg.fit(x_trunc_norm, y_trunc_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_w, known_w0 = (trunc_reg.weight * ch.sqrt(gt_var)) / beta, trunc_reg.intercept * ch.sqrt(gt_var) + y_trunc_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "\n",
    "# ax.scatter3D(x_non_trunc[:,0], x_non_trunc[:,1], y_non_trunc, color='red', label='not seen', alpha=.1)\n",
    "\n",
    "\n",
    "x_max, x_min = x_transform.max(0)[0], x_transform.min(0)[0]\n",
    "X_ = np.arange(x_min[0], x_max[0]/2, 1.0)\n",
    "Y = np.arange(x_min[1], x_max[1]/2, 1.0)\n",
    "X_, Y = np.meshgrid(X_, Y) \n",
    "\n",
    "with ch.no_grad():\n",
    "    emp = Tensor([])\n",
    "    for i in range(X_.shape[0]): \n",
    "        input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "        emp = ch.cat([emp, input_@w.T + trunc_ols.intercept_], 1)\n",
    "    ax.plot_surface(X_, Y, emp.numpy().T, alpha=.15, color='red')\n",
    "    \n",
    "    actual = Tensor([])\n",
    "    for i in range(X_.shape[0]): \n",
    "        input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "        actual = ch.cat([actual, input_@w_transform.T + gt_ols.intercept_], 1)\n",
    "    ax.plot_surface(X_, Y, actual.numpy().T, alpha=.15, color='blue')\n",
    "    \n",
    "    known_w_transform = known_w.T@random\n",
    "    \n",
    "    pred = Tensor([])\n",
    "    for i in range(X_.shape[0]): \n",
    "        input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "        pred = ch.cat([pred, input_@known_w_transform.T + known_w0], 1)\n",
    "    ax.plot_surface(X_, Y, pred.numpy().T, alpha=.15, color='green')\n",
    "\n",
    "ax.scatter3D(x_trunc_transform[:,0], x_trunc_transform[:,1], y_trunc, color='grey', label='S', alpha=.4)\n",
    "\n",
    "    \n",
    "red_patch = mpatches.Patch(color='red', label='ols')\n",
    "\n",
    "green_patch = mpatches.Patch(color='green', label='our algorithm')\n",
    "blue_patch = mpatches.Patch(color='blue', label=\"$W^{*}$\")\n",
    "plt.legend(handles=[red_patch, blue_patch, green_patch], loc=\"upper right\")\n",
    "    \n",
    "ax.view_init(10.0, 220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical weight:  Parameter containing:\n",
      "tensor([[   19.0248,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0174,  -322.8699,   -11.3389,  -302.5919]], requires_grad=True)\n",
      "empirical bias:  Parameter containing:\n",
      "tensor([0.3635], requires_grad=True)\n",
      "weight bounds:  Bounds(lower=tensor([  -16.0021,   869.9271, -4606.3906,  2592.8062,  -665.3607,   176.1867,\n",
      "          -39.4233,  -384.2904,   -44.9140,  -345.3293]), upper=tensor([   51.9397,   937.8689, -4538.4492,  2660.7480,  -597.4189,   244.1284,\n",
      "           28.5184,  -316.3486,    23.0278,  -277.3876]))\n",
      "bias bounds:  Bounds(lower=tensor([-33.5406]), upper=tensor([34.4012]))\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0248,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0174,  -322.8699,   -11.3389,  -302.5919]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8053e-03,  3.6434e-05,  7.9227e-05,  7.6133e-04,  3.4434e-04,\n",
      "          1.7405e-03,  6.2220e-02,  2.7323e-03,  5.2128e-02,  1.9292e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3635], requires_grad=True)\n",
      "bias grad:  tensor([0.3070])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[1.]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3955]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0248,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0180,  -322.8699,   -11.3394,  -302.5920]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3605], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.9605]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0248,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0180,  -322.8699,   -11.3394,  -302.5920]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6238e-03,  0.0000e+00, -4.0400e-05,  1.9854e-04,  5.0838e-04,\n",
      "         -4.4232e-03, -8.8377e-02, -6.7359e-04, -7.3322e-04,  1.0323e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3605], requires_grad=True)\n",
      "bias grad:  tensor([-0.0330])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.9605]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.2741]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0248,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0172,  -322.8699,   -11.3394,  -302.5920]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3608], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8330]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0248,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0172,  -322.8699,   -11.3394,  -302.5920]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.9116e-03, -1.4005e-05, -4.7682e-06,  3.3270e-04,  9.0469e-04,\n",
      "         -3.1041e-03, -4.9176e-02,  4.0772e-04,  1.9939e-02,  3.0118e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3608], requires_grad=True)\n",
      "bias grad:  tensor([0.0969])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8330]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8608]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0248,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0167,  -322.8699,   -11.3396,  -302.5920]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3598], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7470]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0248,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0167,  -322.8699,   -11.3396,  -302.5920]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.5015e-03, -5.8038e-05, -1.7302e-05, -1.5394e-04,  3.5943e-04,\n",
      "         -1.3315e-03, -3.2263e-02,  1.3931e-04,  3.6739e-04,  7.2965e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3598], requires_grad=True)\n",
      "bias grad:  tensor([-0.0196])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7470]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1619]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0247,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0163,  -322.8699,   -11.3396,  -302.5920]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3600], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6308]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0247,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0163,  -322.8699,   -11.3396,  -302.5920]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.8895e-03, -1.7124e-04, -6.6940e-05, -2.2182e-04,  2.5756e-04,\n",
      "         -4.7146e-03, -1.0185e-01, -2.1884e-03, -2.9723e-02, -5.3783e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3600], requires_grad=True)\n",
      "bias grad:  tensor([-0.1707])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6308]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5431]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0247,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4059,\n",
      "            -6.0153,  -322.8699,   -11.3393,  -302.5920]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3617], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5765]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0247,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4059,\n",
      "            -6.0153,  -322.8699,   -11.3393,  -302.5920]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0044, 0.0000, 0.0002, 0.0028, 0.0009, 0.0017, 0.1196, 0.0062, 0.1603,\n",
      "         0.0035]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3617], requires_grad=True)\n",
      "bias grad:  tensor([0.9166])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5765]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.7736]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0246,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0165,  -322.8699,   -11.3409,  -302.5920]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3526], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7538]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0246,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0165,  -322.8699,   -11.3409,  -302.5920]], requires_grad=True)\n",
      "weight grad:  tensor([[8.2747e-04, 4.8270e-05, 2.9100e-05, 3.3878e-04, 1.5553e-04, 3.7019e-04,\n",
      "         1.4844e-02, 1.2305e-03, 2.4185e-02, 7.3075e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3526], requires_grad=True)\n",
      "bias grad:  tensor([0.1440])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7538]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1492]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0246,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0167,  -322.8699,   -11.3411,  -302.5920]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3511], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7687]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0246,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0167,  -322.8699,   -11.3411,  -302.5920]], requires_grad=True)\n",
      "weight grad:  tensor([[3.8210e-03, 5.5939e-05, 1.6007e-04, 2.0446e-03, 1.2322e-03, 4.1737e-03,\n",
      "         1.4107e-01, 5.8247e-03, 1.1142e-01, 2.9717e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3511], requires_grad=True)\n",
      "bias grad:  tensor([0.6954])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7687]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.4046]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0246,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0181,  -322.8700,   -11.3422,  -302.5920]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3442], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8092]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0246,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0181,  -322.8700,   -11.3422,  -302.5920]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0063, 0.0000, 0.0001, 0.0018, 0.0013, 0.0009, 0.0935, 0.0047, 0.1075,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3442], requires_grad=True)\n",
      "bias grad:  tensor([0.6230])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8092]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0492]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0245,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0190,  -322.8701,   -11.3433,  -302.5921]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3379], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8043]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0245,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0190,  -322.8701,   -11.3433,  -302.5921]], requires_grad=True)\n",
      "weight grad:  tensor([[1.4531e-03, 0.0000e+00, 5.8837e-05, 6.7433e-04, 4.6179e-04, 7.8287e-04,\n",
      "         4.2356e-02, 2.2294e-03, 4.5483e-02, 1.1492e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3379], requires_grad=True)\n",
      "bias grad:  tensor([0.2587])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8043]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2229]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0245,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0194,  -322.8701,   -11.3438,  -302.5921]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3354], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7820]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0245,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0194,  -322.8701,   -11.3438,  -302.5921]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0024, 0.0001, 0.0001, 0.0015, 0.0007, 0.0019, 0.0834, 0.0044, 0.0908,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3354], requires_grad=True)\n",
      "bias grad:  tensor([0.5212])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7820]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3230]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0245,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0203,  -322.8701,   -11.3447,  -302.5921]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3301], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8143]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0245,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0203,  -322.8701,   -11.3447,  -302.5921]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.0165e-03, -6.2812e-05, -2.6649e-06,  2.4025e-05,  4.5783e-04,\n",
      "         -1.2301e-03, -2.1343e-02,  2.4495e-04,  7.4417e-03,  7.5652e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3301], requires_grad=True)\n",
      "bias grad:  tensor([0.0475])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8143]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6330]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0245,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0201,  -322.8701,   -11.3448,  -302.5921]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3297], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7510]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0245,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4058,\n",
      "            -6.0201,  -322.8701,   -11.3448,  -302.5921]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0020, 0.0000, 0.0001, 0.0016, 0.0010, 0.0013, 0.0765, 0.0048, 0.0964,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3297], requires_grad=True)\n",
      "bias grad:  tensor([0.5653])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7510]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0113]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0244,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0208,  -322.8702,   -11.3457,  -302.5921]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3240], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7498]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0244,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0208,  -322.8702,   -11.3457,  -302.5921]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8918e-03, 1.9154e-05, 6.2886e-05, 6.3776e-04, 5.4138e-04, 2.5157e-03,\n",
      "         7.2753e-02, 2.3113e-03, 3.9985e-02, 1.7623e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3240], requires_grad=True)\n",
      "bias grad:  tensor([0.2469])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7498]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2950]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0244,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0215,  -322.8702,   -11.3461,  -302.5922]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3215], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7203]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0244,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0215,  -322.8702,   -11.3461,  -302.5922]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4972e-03, 5.6439e-05, 1.0949e-04, 1.2698e-03, 8.4675e-04, 3.3221e-03,\n",
      "         1.0558e-01, 3.8326e-03, 7.4990e-02, 1.9710e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3215], requires_grad=True)\n",
      "bias grad:  tensor([0.4392])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7203]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1999]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0244,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0226,  -322.8702,   -11.3469,  -302.5922]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3172], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7403]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0244,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0226,  -322.8702,   -11.3469,  -302.5922]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4528e-04, 4.8204e-05, 2.0086e-04, 2.1020e-03, 9.2176e-04, 2.8447e-03,\n",
      "         1.2982e-01, 5.7077e-03, 1.1911e-01, 3.2290e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3172], requires_grad=True)\n",
      "bias grad:  tensor([0.7385])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7403]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1904]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0244,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0239,  -322.8703,   -11.3481,  -302.5922]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3098], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7594]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0244,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4057,\n",
      "            -6.0239,  -322.8703,   -11.3481,  -302.5922]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0071, 0.0000, 0.0001, 0.0017, 0.0013, 0.0022, 0.1007, 0.0047, 0.1062,\n",
      "         0.0028]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3098], requires_grad=True)\n",
      "bias grad:  tensor([0.6075])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7594]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2449]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0243,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4056,\n",
      "            -6.0249,  -322.8704,   -11.3491,  -302.5923]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3037], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7839]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0243,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4056,\n",
      "            -6.0249,  -322.8704,   -11.3491,  -302.5923]], requires_grad=True)\n",
      "weight grad:  tensor([[2.9987e-03, 0.0000e+00, 7.3780e-05, 8.2561e-04, 6.6355e-04, 1.2158e-03,\n",
      "         5.8128e-02, 2.9375e-03, 5.5312e-02, 1.2012e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3037], requires_grad=True)\n",
      "bias grad:  tensor([0.3168])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7839]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3186]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0243,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4056,\n",
      "            -6.0255,  -322.8704,   -11.3497,  -302.5923]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.3005], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7520]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0243,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4056,\n",
      "            -6.0255,  -322.8704,   -11.3497,  -302.5923]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0034, 0.0003, 0.0003, 0.0036, 0.0011, 0.0076, 0.2442, 0.0085, 0.1713,\n",
      "         0.0030]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.3005], requires_grad=True)\n",
      "bias grad:  tensor([1.0400])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7520]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.4468]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0279,  -322.8705,   -11.3514,  -302.5923]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2901], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8967]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0279,  -322.8705,   -11.3514,  -302.5923]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6788e-04,  0.0000e+00,  5.8509e-05,  6.2134e-04,  4.6492e-04,\n",
      "          8.8208e-04,  4.3749e-02,  2.4618e-03,  4.3400e-02,  7.5119e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2901], requires_grad=True)\n",
      "bias grad:  tensor([0.2530])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8967]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2285]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0284,  -322.8705,   -11.3518,  -302.5923]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2876], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8738]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0284,  -322.8705,   -11.3518,  -302.5923]], requires_grad=True)\n",
      "weight grad:  tensor([[2.6551e-03, 5.8133e-05, 1.4650e-04, 1.9055e-03, 1.2280e-03, 1.5937e-03,\n",
      "         9.3448e-02, 4.8665e-03, 1.1093e-01, 2.9767e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2876], requires_grad=True)\n",
      "bias grad:  tensor([0.6606])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8738]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda grad:  tensor([[-0.1938]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0293,  -322.8706,   -11.3529,  -302.5923]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2810], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8932]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0293,  -322.8706,   -11.3529,  -302.5923]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6920e-03, -1.1292e-05,  9.0567e-05,  1.1863e-03,  9.1221e-04,\n",
      "          1.5236e-03,  6.2183e-02,  3.8794e-03,  7.9170e-02,  2.6158e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2810], requires_grad=True)\n",
      "bias grad:  tensor([0.4510])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8932]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6466]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0299,  -322.8706,   -11.3537,  -302.5923]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2765], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8286]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0299,  -322.8706,   -11.3537,  -302.5923]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5264e-03, 2.2997e-05, 1.2624e-04, 1.3468e-03, 7.5528e-04, 3.3406e-03,\n",
      "         1.0110e-01, 3.9828e-03, 8.6765e-02, 2.1394e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2765], requires_grad=True)\n",
      "bias grad:  tensor([0.4937])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8286]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0452]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0309,  -322.8706,   -11.3546,  -302.5924]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2715], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8331]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0309,  -322.8706,   -11.3546,  -302.5924]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3378e-03, -3.3420e-05,  1.9425e-05,  9.9604e-05,  1.2460e-04,\n",
      "          2.0300e-04,  1.4545e-02,  9.2957e-04,  1.6463e-02,  9.2583e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2715], requires_grad=True)\n",
      "bias grad:  tensor([0.0965])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8331]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5743]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0311,  -322.8706,   -11.3548,  -302.5924]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2706], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7757]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0311,  -322.8706,   -11.3548,  -302.5924]], requires_grad=True)\n",
      "weight grad:  tensor([[4.4247e-03, 0.0000e+00, 7.2407e-05, 9.4622e-04, 6.3393e-04, 5.7117e-04,\n",
      "         4.9646e-02, 2.1081e-03, 5.2705e-02, 8.7612e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2706], requires_grad=True)\n",
      "bias grad:  tensor([0.3101])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7757]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.4185]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0316,  -322.8707,   -11.3553,  -302.5924]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2675], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8175]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0316,  -322.8707,   -11.3553,  -302.5924]], requires_grad=True)\n",
      "weight grad:  tensor([[6.5482e-03, 4.5167e-05, 1.4299e-04, 1.7990e-03, 1.3568e-03, 2.0372e-03,\n",
      "         1.0198e-01, 5.1643e-03, 1.1075e-01, 3.3879e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2675], requires_grad=True)\n",
      "bias grad:  tensor([0.6524])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8175]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0309]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0326,  -322.8707,   -11.3564,  -302.5924]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2610], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8206]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0326,  -322.8707,   -11.3564,  -302.5924]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0946e-02,  0.0000e+00,  6.2714e-06, -2.0363e-04, -3.6441e-04,\n",
      "         -7.1367e-05, -3.4405e-03, -8.5792e-06, -6.3190e-03,  2.4743e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2610], requires_grad=True)\n",
      "bias grad:  tensor([-0.0321])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8206]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1766]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0326,  -322.8707,   -11.3563,  -302.5924]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2613], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8029]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0326,  -322.8707,   -11.3563,  -302.5924]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.3003e-03,  2.2622e-05,  7.3012e-05,  7.3438e-04,  2.6955e-04,\n",
      "          1.6888e-03,  5.6423e-02,  2.4623e-03,  4.7477e-02,  1.5833e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2613], requires_grad=True)\n",
      "bias grad:  tensor([0.2806])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8029]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1155]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4054,\n",
      "            -6.0331,  -322.8708,   -11.3568,  -302.5924]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2585], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7914]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4054,\n",
      "            -6.0331,  -322.8708,   -11.3568,  -302.5924]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.4463e-03,  0.0000e+00, -4.6556e-05,  1.1898e-04,  4.3833e-04,\n",
      "         -4.4689e-03, -9.1624e-02, -9.9122e-04, -6.8691e-03,  8.7074e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2585], requires_grad=True)\n",
      "bias grad:  tensor([-0.0669])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7914]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1427]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0322,  -322.8708,   -11.3567,  -302.5924]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2591], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6771]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0322,  -322.8708,   -11.3567,  -302.5924]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.1666e-03,  7.0563e-06,  1.6368e-05,  7.1918e-04,  1.0936e-03,\n",
      "         -2.8681e-03, -3.8925e-02,  1.0954e-03,  3.7199e-02,  1.5049e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2591], requires_grad=True)\n",
      "bias grad:  tensor([0.1996])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6771]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2876]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0318,  -322.8708,   -11.3571,  -302.5924]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2571], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6484]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0318,  -322.8708,   -11.3571,  -302.5924]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.5440e-03, -4.3291e-05,  1.5505e-05,  3.1685e-04,  5.7271e-04,\n",
      "         -8.9110e-04, -9.4922e-03,  1.2694e-03,  2.4800e-02,  8.5059e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2571], requires_grad=True)\n",
      "bias grad:  tensor([0.1247])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6484]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7047]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0317,  -322.8708,   -11.3573,  -302.5924]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2559], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5779]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0317,  -322.8708,   -11.3573,  -302.5924]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3395e-03, -1.7450e-04, -4.8106e-05, -1.8045e-04,  2.1269e-04,\n",
      "         -4.0704e-03, -8.3096e-02, -1.5302e-03, -1.8976e-02,  1.7717e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2559], requires_grad=True)\n",
      "bias grad:  tensor([-0.1193])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5779]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6271]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4056,\n",
      "            -6.0309,  -322.8707,   -11.3572,  -302.5924]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2571], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5152]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4056,\n",
      "            -6.0309,  -322.8707,   -11.3572,  -302.5924]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0050, 0.0000, 0.0002, 0.0028, 0.0008, 0.0016, 0.1102, 0.0057, 0.1533,\n",
      "         0.0032]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2571], requires_grad=True)\n",
      "bias grad:  tensor([0.8776])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5152]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.3361]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4056,\n",
      "            -6.0320,  -322.8708,   -11.3587,  -302.5925]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2483], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7488]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4056,\n",
      "            -6.0320,  -322.8708,   -11.3587,  -302.5925]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.6179e-04,  4.3818e-05,  6.8211e-06,  4.5645e-05, -4.8075e-05,\n",
      "          5.5193e-05, -3.2810e-03,  3.6922e-04,  6.5770e-03,  3.6169e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2483], requires_grad=True)\n",
      "bias grad:  tensor([0.0400])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7488]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1631]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4056,\n",
      "            -6.0320,  -322.8708,   -11.3588,  -302.5925]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2479], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7651]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4056,\n",
      "            -6.0320,  -322.8708,   -11.3588,  -302.5925]], requires_grad=True)\n",
      "weight grad:  tensor([[3.0201e-03, 3.4767e-05, 1.3962e-04, 1.7857e-03, 1.0864e-03, 3.7353e-03,\n",
      "         1.2621e-01, 5.0787e-03, 9.7458e-02, 2.5906e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2479], requires_grad=True)\n",
      "bias grad:  tensor([0.6060])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7651]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3281]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0332,  -322.8708,   -11.3597,  -302.5925]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2419], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7979]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0332,  -322.8708,   -11.3597,  -302.5925]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0067, 0.0000, 0.0001, 0.0017, 0.0013, 0.0009, 0.0836, 0.0045, 0.1036,\n",
      "         0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2419], requires_grad=True)\n",
      "bias grad:  tensor([0.6019])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7979]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0207]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0341,  -322.8709,   -11.3608,  -302.5925]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2358], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7958]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0341,  -322.8709,   -11.3608,  -302.5925]], requires_grad=True)\n",
      "weight grad:  tensor([[2.1740e-03, 0.0000e+00, 5.2840e-05, 6.1136e-04, 4.3884e-04, 7.7755e-04,\n",
      "         3.8926e-02, 1.9882e-03, 4.1425e-02, 1.0862e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2358], requires_grad=True)\n",
      "bias grad:  tensor([0.2356])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7958]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1680]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0345,  -322.8709,   -11.3612,  -302.5925]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2335], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7790]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0345,  -322.8709,   -11.3612,  -302.5925]], requires_grad=True)\n",
      "weight grad:  tensor([[1.1225e-03, 9.4366e-05, 7.2232e-05, 9.0194e-04, 2.6747e-04, 1.2657e-03,\n",
      "         5.5511e-02, 2.6815e-03, 5.5820e-02, 1.3794e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2335], requires_grad=True)\n",
      "bias grad:  tensor([0.3215])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7790]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2371]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0350,  -322.8709,   -11.3617,  -302.5925]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2303], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8027]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0350,  -322.8709,   -11.3617,  -302.5925]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.9830e-03, -6.1509e-05,  1.0220e-06,  8.4746e-05,  4.9746e-04,\n",
      "         -1.2700e-03, -1.8656e-02,  3.7468e-04,  1.0727e-02,  7.0397e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2303], requires_grad=True)\n",
      "bias grad:  tensor([0.0660])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8027]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5371]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0348,  -322.8709,   -11.3618,  -302.5925]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2296], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7490]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0348,  -322.8709,   -11.3618,  -302.5925]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0020, 0.0000, 0.0001, 0.0014, 0.0009, 0.0013, 0.0709, 0.0042, 0.0842,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2296], requires_grad=True)\n",
      "bias grad:  tensor([0.4956])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7490]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0479]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0355,  -322.8710,   -11.3627,  -302.5926]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2246], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7442]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0355,  -322.8710,   -11.3627,  -302.5926]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4106e-03, 2.6665e-05, 6.9719e-05, 6.5538e-04, 5.3364e-04, 2.8017e-03,\n",
      "         7.8195e-02, 2.4764e-03, 4.2220e-02, 2.0108e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2246], requires_grad=True)\n",
      "bias grad:  tensor([0.2597])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7442]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3879]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0363,  -322.8710,   -11.3631,  -302.5926]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2220], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7054]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4055,\n",
      "            -6.0363,  -322.8710,   -11.3631,  -302.5926]], requires_grad=True)\n",
      "weight grad:  tensor([[4.1752e-03, 4.9228e-05, 1.2296e-04, 1.4939e-03, 1.0941e-03, 3.4180e-03,\n",
      "         1.1587e-01, 4.5466e-03, 8.9470e-02, 2.3414e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2220], requires_grad=True)\n",
      "bias grad:  tensor([0.5233])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7054]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1208]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4054,\n",
      "            -6.0375,  -322.8710,   -11.3640,  -302.5926]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2168], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7175]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4054,\n",
      "            -6.0375,  -322.8710,   -11.3640,  -302.5926]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1549e-04, 5.5234e-05, 2.0764e-04, 2.1915e-03, 9.7901e-04, 2.9261e-03,\n",
      "         1.3354e-01, 5.9760e-03, 1.2376e-01, 3.3531e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2168], requires_grad=True)\n",
      "bias grad:  tensor([0.7708])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7175]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2822]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4054,\n",
      "            -6.0388,  -322.8711,   -11.3652,  -302.5927]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2091], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7457]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4054,\n",
      "            -6.0388,  -322.8711,   -11.3652,  -302.5927]], requires_grad=True)\n",
      "weight grad:  tensor([[5.9823e-03, 0.0000e+00, 9.0933e-05, 1.1444e-03, 8.7738e-04, 1.7290e-03,\n",
      "         7.3984e-02, 3.0946e-03, 7.0526e-02, 1.5501e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2091], requires_grad=True)\n",
      "bias grad:  tensor([0.4027])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7457]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2571]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4054,\n",
      "            -6.0395,  -322.8711,   -11.3660,  -302.5927]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2051], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7715]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4054,\n",
      "            -6.0395,  -322.8711,   -11.3660,  -302.5927]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7388e-03, 0.0000e+00, 4.9954e-05, 5.6021e-04, 4.6382e-04, 7.1464e-04,\n",
      "         4.0090e-02, 2.0923e-03, 3.8688e-02, 6.5157e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2051], requires_grad=True)\n",
      "bias grad:  tensor([0.2215])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7715]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2602]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4054,\n",
      "            -6.0399,  -322.8712,   -11.3663,  -302.5927]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.2029], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7454]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4054,\n",
      "            -6.0399,  -322.8712,   -11.3663,  -302.5927]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0029, 0.0003, 0.0003, 0.0035, 0.0010, 0.0077, 0.2403, 0.0082, 0.1618,\n",
      "         0.0028]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.2029], requires_grad=True)\n",
      "bias grad:  tensor([0.9869])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7454]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5064]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0424,  -322.8712,   -11.3680,  -302.5927]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1930], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8961]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0424,  -322.8712,   -11.3680,  -302.5927]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2076e-04,  0.0000e+00,  5.5022e-05,  5.5386e-04,  4.5717e-04,\n",
      "          9.1950e-04,  4.2487e-02,  2.2963e-03,  3.9773e-02,  7.2179e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1930], requires_grad=True)\n",
      "bias grad:  tensor([0.2325])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8961]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2796]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0428,  -322.8713,   -11.3684,  -302.5927]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1907], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8681]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0428,  -322.8713,   -11.3684,  -302.5927]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6799e-03, 5.6559e-05, 1.1271e-04, 1.4529e-03, 8.6806e-04, 1.2888e-03,\n",
      "         7.1565e-02, 3.7082e-03, 8.3497e-02, 2.2227e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1907], requires_grad=True)\n",
      "bias grad:  tensor([0.5002])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8681]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1742]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0435,  -322.8713,   -11.3692,  -302.5927]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1857], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8855]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0435,  -322.8713,   -11.3692,  -302.5927]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3259e-03, -2.4149e-05,  8.3119e-05,  1.0744e-03,  8.2109e-04,\n",
      "          1.4613e-03,  5.8139e-02,  3.6266e-03,  7.3076e-02,  2.4603e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1857], requires_grad=True)\n",
      "bias grad:  tensor([0.4156])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8855]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6710]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0441,  -322.8713,   -11.3699,  -302.5928]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1815], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8184]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0441,  -322.8713,   -11.3699,  -302.5928]], requires_grad=True)\n",
      "weight grad:  tensor([[2.6591e-03, 1.2738e-05, 9.5681e-05, 9.2762e-04, 5.0382e-04, 3.0357e-03,\n",
      "         8.4821e-02, 2.9681e-03, 6.2585e-02, 1.7265e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1815], requires_grad=True)\n",
      "bias grad:  tensor([0.3555])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8184]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0610]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0449,  -322.8714,   -11.3705,  -302.5928]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1780], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8123]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0449,  -322.8714,   -11.3705,  -302.5928]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0196e-03, -2.9135e-05, -4.3292e-07, -1.5826e-04, -6.8413e-05,\n",
      "         -3.1331e-05, -1.8851e-03,  2.7324e-04,  2.5733e-03,  6.7611e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1780], requires_grad=True)\n",
      "bias grad:  tensor([0.0131])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8123]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6270]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0449,  -322.8714,   -11.3706,  -302.5928]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1778], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7496]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0449,  -322.8714,   -11.3706,  -302.5928]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1263e-03, 0.0000e+00, 4.6362e-05, 5.8816e-04, 3.9798e-04, 4.0477e-04,\n",
      "         3.4344e-02, 1.1798e-03, 3.1505e-02, 4.1043e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1778], requires_grad=True)\n",
      "bias grad:  tensor([0.1865])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7496]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3896]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0452,  -322.8714,   -11.3709,  -302.5928]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1760], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7886]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0452,  -322.8714,   -11.3709,  -302.5928]], requires_grad=True)\n",
      "weight grad:  tensor([[6.4137e-03, 3.7547e-05, 1.4419e-04, 1.8164e-03, 1.3936e-03, 2.0821e-03,\n",
      "         1.0394e-01, 5.2215e-03, 1.1188e-01, 3.4506e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1760], requires_grad=True)\n",
      "bias grad:  tensor([0.6593])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7886]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0173]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0463,  -322.8714,   -11.3720,  -302.5928]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1694], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7903]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0463,  -322.8714,   -11.3720,  -302.5928]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3210e-02,  0.0000e+00, -5.5510e-06, -4.0663e-04, -6.0428e-04,\n",
      "         -2.1349e-04, -9.8581e-03, -5.2493e-04, -1.7553e-02, -1.1483e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1694], requires_grad=True)\n",
      "bias grad:  tensor([-0.0960])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7903]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2095]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0462,  -322.8714,   -11.3718,  -302.5928]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1703], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7694]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0462,  -322.8714,   -11.3718,  -302.5928]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.4137e-03,  2.0923e-05,  7.6897e-05,  8.0158e-04,  3.4718e-04,\n",
      "          1.8340e-03,  6.3042e-02,  2.6268e-03,  5.1430e-02,  1.6278e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1703], requires_grad=True)\n",
      "bias grad:  tensor([0.3035])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7694]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0551]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0468,  -322.8715,   -11.3723,  -302.5929]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1673], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7639]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0468,  -322.8715,   -11.3723,  -302.5929]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.2588e-03,  0.0000e+00, -7.0365e-05, -1.4506e-04,  3.1388e-04,\n",
      "         -4.8472e-03, -1.0807e-01, -1.7502e-03, -2.3784e-02,  4.9646e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1673], requires_grad=True)\n",
      "bias grad:  tensor([-0.1648])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7639]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1901]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0457,  -322.8714,   -11.3721,  -302.5929]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1689], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6448]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0457,  -322.8714,   -11.3721,  -302.5929]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.0983e-03,  1.8001e-05,  1.8672e-05,  7.6921e-04,  1.1141e-03,\n",
      "         -2.8394e-03, -3.8648e-02,  1.1707e-03,  3.9367e-02,  1.2242e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1689], requires_grad=True)\n",
      "bias grad:  tensor([0.2110])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6448]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1786]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0454,  -322.8714,   -11.3725,  -302.5929]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1668], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6270]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0454,  -322.8714,   -11.3725,  -302.5929]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.1869e-03, -4.8320e-05,  2.1936e-07,  1.1921e-04,  5.1402e-04,\n",
      "         -1.2046e-03, -2.0208e-02,  7.5038e-04,  1.4066e-02,  6.7597e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1668], requires_grad=True)\n",
      "bias grad:  tensor([0.0622])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6270]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8197]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0451,  -322.8714,   -11.3726,  -302.5929]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1662], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5450]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0451,  -322.8714,   -11.3726,  -302.5929]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.4514e-03, -1.9071e-04, -3.1254e-05, -1.1539e-04,  2.6382e-04,\n",
      "         -3.5900e-03, -6.7236e-02, -1.0996e-03, -1.0283e-02,  1.7198e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1662], requires_grad=True)\n",
      "bias grad:  tensor([-0.0638])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5450]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6002]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0445,  -322.8714,   -11.3725,  -302.5929]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1668], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4850]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0445,  -322.8714,   -11.3725,  -302.5929]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0049, 0.0000, 0.0002, 0.0027, 0.0007, 0.0016, 0.1078, 0.0054, 0.1479,\n",
      "         0.0031]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1668], requires_grad=True)\n",
      "bias grad:  tensor([0.8471])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4850]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.3863]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0456,  -322.8715,   -11.3740,  -302.5929]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1584], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7236]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0456,  -322.8715,   -11.3740,  -302.5929]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.2214e-04,  4.1401e-05, -1.0346e-05, -1.7084e-04, -1.7440e-04,\n",
      "         -2.8677e-04, -1.5135e-02, -2.3664e-04, -5.7931e-03,  1.3204e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1584], requires_grad=True)\n",
      "bias grad:  tensor([-0.0343])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7236]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0871]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0454,  -322.8715,   -11.3740,  -302.5929]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1587], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7323]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0454,  -322.8715,   -11.3740,  -302.5929]], requires_grad=True)\n",
      "weight grad:  tensor([[1.8240e-03, 5.6252e-05, 1.2645e-04, 1.5874e-03, 8.9262e-04, 3.7056e-03,\n",
      "         1.1731e-01, 4.5177e-03, 8.5832e-02, 2.4230e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1587], requires_grad=True)\n",
      "bias grad:  tensor([0.5398])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7323]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3133]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0466,  -322.8715,   -11.3748,  -302.5929]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1533], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7637]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0466,  -322.8715,   -11.3748,  -302.5929]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0052, 0.0000, 0.0001, 0.0017, 0.0012, 0.0009, 0.1020, 0.0048, 0.1072,\n",
      "         0.0024]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1533], requires_grad=True)\n",
      "bias grad:  tensor([0.6191])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7637]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1204]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0476,  -322.8716,   -11.3759,  -302.5930]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1471], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7516]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0476,  -322.8716,   -11.3759,  -302.5930]], requires_grad=True)\n",
      "weight grad:  tensor([[1.8051e-03, 0.0000e+00, 5.0600e-05, 5.4306e-04, 3.4783e-04, 7.3074e-04,\n",
      "         3.8451e-02, 1.8965e-03, 3.8320e-02, 1.0602e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1471], requires_grad=True)\n",
      "bias grad:  tensor([0.2180])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7516]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2340]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0480,  -322.8716,   -11.3763,  -302.5930]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1449], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7282]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0480,  -322.8716,   -11.3763,  -302.5930]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6399e-03, 1.0741e-04, 7.8913e-05, 9.9404e-04, 3.5057e-04, 1.3092e-03,\n",
      "         5.7493e-02, 2.9293e-03, 6.1482e-02, 1.5316e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1449], requires_grad=True)\n",
      "bias grad:  tensor([0.3533])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7282]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2611]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0486,  -322.8716,   -11.3769,  -302.5930]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1414], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7543]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0486,  -322.8716,   -11.3769,  -302.5930]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1698e-03, -7.8757e-05, -2.7230e-05, -2.7999e-04,  2.5882e-04,\n",
      "         -1.6759e-03, -3.8040e-02, -6.7538e-04, -1.1641e-02,  3.2709e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1414], requires_grad=True)\n",
      "bias grad:  tensor([-0.0630])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7543]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6113]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0482,  -322.8716,   -11.3768,  -302.5930]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1420], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6932]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4053,\n",
      "            -6.0482,  -322.8716,   -11.3768,  -302.5930]], requires_grad=True)\n",
      "weight grad:  tensor([[2.3909e-03, 0.0000e+00, 9.8359e-05, 1.2761e-03, 8.4386e-04, 9.0973e-04,\n",
      "         5.9550e-02, 3.7674e-03, 7.7678e-02, 1.7269e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1420], requires_grad=True)\n",
      "bias grad:  tensor([0.4507])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6932]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0844]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0488,  -322.8717,   -11.3775,  -302.5930]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1375], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7016]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0488,  -322.8717,   -11.3775,  -302.5930]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2023e-06,  1.7719e-05,  3.2504e-05,  1.9420e-04,  1.8500e-04,\n",
      "          2.1745e-03,  5.0078e-02,  1.1806e-03,  1.4690e-02,  1.1918e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1375], requires_grad=True)\n",
      "bias grad:  tensor([0.0973])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7016]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3348]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0493,  -322.8717,   -11.3777,  -302.5930]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1366], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6682]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0493,  -322.8717,   -11.3777,  -302.5930]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4219e-03, 4.9939e-05, 9.5063e-05, 1.0774e-03, 5.8482e-04, 3.2931e-03,\n",
      "         9.7498e-02, 3.1548e-03, 6.2615e-02, 1.6681e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1366], requires_grad=True)\n",
      "bias grad:  tensor([0.3646])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6682]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3335]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0502,  -322.8717,   -11.3783,  -302.5930]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1329], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7015]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0502,  -322.8717,   -11.3783,  -302.5930]], requires_grad=True)\n",
      "weight grad:  tensor([[2.5021e-04, 4.5555e-05, 1.7652e-04, 1.8920e-03, 8.4430e-04, 2.5457e-03,\n",
      "         1.1520e-01, 5.1083e-03, 1.0755e-01, 2.8522e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1329], requires_grad=True)\n",
      "bias grad:  tensor([0.6609])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7015]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2348]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0514,  -322.8718,   -11.3794,  -302.5931]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1263], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7250]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0514,  -322.8718,   -11.3794,  -302.5931]], requires_grad=True)\n",
      "weight grad:  tensor([[5.9579e-03, 0.0000e+00, 9.3826e-05, 1.1898e-03, 9.2528e-04, 1.6824e-03,\n",
      "         7.5298e-02, 3.2512e-03, 7.3949e-02, 1.7202e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1263], requires_grad=True)\n",
      "bias grad:  tensor([0.4221])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7250]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1844]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0522,  -322.8718,   -11.3801,  -302.5931]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1221], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7434]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4052,\n",
      "            -6.0522,  -322.8718,   -11.3801,  -302.5931]], requires_grad=True)\n",
      "weight grad:  tensor([[2.6104e-03, 0.0000e+00, 5.2576e-05, 5.6191e-04, 4.7369e-04, 9.6627e-04,\n",
      "         4.4673e-02, 2.2291e-03, 3.9042e-02, 6.9486e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1221], requires_grad=True)\n",
      "bias grad:  tensor([0.2247])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7434]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2618]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0526,  -322.8718,   -11.3805,  -302.5931]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1198], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7173]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0526,  -322.8718,   -11.3805,  -302.5931]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0020, 0.0003, 0.0003, 0.0033, 0.0009, 0.0076, 0.2299, 0.0076, 0.1483,\n",
      "         0.0024]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1198], requires_grad=True)\n",
      "bias grad:  tensor([0.9095])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7173]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5411]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0549,  -322.8719,   -11.3820,  -302.5931]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1107], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8714]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0549,  -322.8719,   -11.3820,  -302.5931]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.8270e-04,  0.0000e+00,  2.9666e-05,  2.5363e-04,  2.4657e-04,\n",
      "          5.2712e-04,  2.4437e-02,  1.4378e-03,  2.1976e-02,  3.7290e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1107], requires_grad=True)\n",
      "bias grad:  tensor([0.1273])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8714]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3134]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0551,  -322.8719,   -11.3822,  -302.5931]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1095], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8400]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0551,  -322.8719,   -11.3822,  -302.5931]], requires_grad=True)\n",
      "weight grad:  tensor([[1.0607e-03, 4.1453e-05, 9.4356e-05, 1.1972e-03, 6.9702e-04, 1.0771e-03,\n",
      "         6.0469e-02, 3.0438e-03, 6.8188e-02, 1.8382e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1095], requires_grad=True)\n",
      "bias grad:  tensor([0.4116])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8400]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1814]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0557,  -322.8719,   -11.3829,  -302.5932]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1054], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8582]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0557,  -322.8719,   -11.3829,  -302.5932]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.8449e-04, -2.5853e-05,  5.6859e-05,  7.1352e-04,  4.9084e-04,\n",
      "          1.0751e-03,  4.1042e-02,  2.6013e-03,  5.1202e-02,  1.9834e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1054], requires_grad=True)\n",
      "bias grad:  tensor([0.2899])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8582]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6327]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0562,  -322.8719,   -11.3834,  -302.5932]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.1025], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7949]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0562,  -322.8719,   -11.3834,  -302.5932]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5365e-03, 7.2914e-06, 8.8696e-05, 8.5537e-04, 4.0158e-04, 2.8186e-03,\n",
      "         7.7969e-02, 2.6905e-03, 5.6907e-02, 1.5266e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.1025], requires_grad=True)\n",
      "bias grad:  tensor([0.3233])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7949]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda grad:  tensor([[0.0388]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0569,  -322.8720,   -11.3840,  -302.5932]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0992], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7910]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0569,  -322.8720,   -11.3840,  -302.5932]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7634e-03, -2.8261e-05, -5.8407e-06, -2.5862e-04, -2.0069e-04,\n",
      "         -7.3139e-05, -3.7210e-03,  6.3821e-06, -4.2323e-03,  5.3946e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0992], requires_grad=True)\n",
      "bias grad:  tensor([-0.0240])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7910]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6181]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0569,  -322.8720,   -11.3839,  -302.5932]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0995], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7292]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0569,  -322.8720,   -11.3839,  -302.5932]], requires_grad=True)\n",
      "weight grad:  tensor([[3.9221e-03, 0.0000e+00, 4.7564e-05, 6.3801e-04, 4.7982e-04, 3.6270e-04,\n",
      "         3.4852e-02, 1.2435e-03, 3.3527e-02, 4.9724e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0995], requires_grad=True)\n",
      "bias grad:  tensor([0.2016])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7292]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.4034]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0572,  -322.8720,   -11.3843,  -302.5932]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0975], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7695]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0572,  -322.8720,   -11.3843,  -302.5932]], requires_grad=True)\n",
      "weight grad:  tensor([[5.0985e-03, 3.1688e-05, 1.0925e-04, 1.3744e-03, 1.0612e-03, 1.5087e-03,\n",
      "         7.8484e-02, 3.9788e-03, 8.4798e-02, 2.8181e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0975], requires_grad=True)\n",
      "bias grad:  tensor([0.5019])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7695]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0047]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0580,  -322.8720,   -11.3851,  -302.5933]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0924], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7700]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0580,  -322.8720,   -11.3851,  -302.5933]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4696e-02,  0.0000e+00, -1.6223e-05, -5.7560e-04, -7.9826e-04,\n",
      "         -3.3506e-04, -1.5337e-02, -9.7808e-04, -2.7131e-02, -2.3857e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0924], requires_grad=True)\n",
      "bias grad:  tensor([-0.1507])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7700]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1955]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0579,  -322.8720,   -11.3849,  -302.5933]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0939], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7505]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0579,  -322.8720,   -11.3849,  -302.5933]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6804e-03,  2.6916e-05,  6.6196e-05,  6.3037e-04,  1.8709e-04,\n",
      "          1.5942e-03,  5.0885e-02,  2.1994e-03,  4.1775e-02,  1.5381e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0939], requires_grad=True)\n",
      "bias grad:  tensor([0.2466])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7505]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1153]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0584,  -322.8720,   -11.3853,  -302.5933]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0915], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7389]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0584,  -322.8720,   -11.3853,  -302.5933]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.2188e-04,  0.0000e+00, -9.4728e-05, -4.7084e-04,  7.5445e-05,\n",
      "         -5.1908e-03, -1.2671e-01, -2.7081e-03, -4.4185e-02,  1.7062e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0915], requires_grad=True)\n",
      "bias grad:  tensor([-0.2827])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7389]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1842]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0571,  -322.8720,   -11.3848,  -302.5933]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0943], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6205]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0571,  -322.8720,   -11.3848,  -302.5933]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.3094e-03,  1.8909e-05,  1.4573e-05,  7.1117e-04,  1.0079e-03,\n",
      "         -2.9924e-03, -4.1872e-02,  9.3313e-04,  3.4449e-02,  1.9757e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0943], requires_grad=True)\n",
      "bias grad:  tensor([0.1879])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6205]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0990]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0567,  -322.8720,   -11.3852,  -302.5933]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0924], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6106]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0567,  -322.8720,   -11.3852,  -302.5933]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.2145e-03, -6.0271e-05, -1.4964e-05, -5.2478e-05,  3.7344e-04,\n",
      "         -1.3824e-03, -3.1131e-02,  2.2476e-04,  3.5072e-03,  4.9250e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0924], requires_grad=True)\n",
      "bias grad:  tensor([0.0020])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6106]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7487]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0564,  -322.8720,   -11.3852,  -302.5933]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0924], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5357]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0564,  -322.8720,   -11.3852,  -302.5933]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.2522e-03, -1.8153e-04, -2.7351e-05, -1.1326e-04,  2.8927e-04,\n",
      "         -3.3689e-03, -6.4826e-02, -9.8106e-04, -7.5653e-03,  2.9407e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0924], requires_grad=True)\n",
      "bias grad:  tensor([-0.0570])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5357]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7523]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0557,  -322.8720,   -11.3851,  -302.5933]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0930], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4605]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0557,  -322.8720,   -11.3851,  -302.5933]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0052, 0.0000, 0.0002, 0.0026, 0.0006, 0.0015, 0.0957, 0.0049, 0.1382,\n",
      "         0.0028]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0930], requires_grad=True)\n",
      "bias grad:  tensor([0.7930])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4605]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.8954]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0567,  -322.8721,   -11.3865,  -302.5933]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0850], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7500]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0567,  -322.8721,   -11.3865,  -302.5933]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.5126e-03,  3.0906e-05, -3.6226e-05, -6.0192e-04, -4.6285e-04,\n",
      "         -5.2710e-04, -3.1693e-02, -1.2549e-03, -2.8632e-02, -1.1990e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0850], requires_grad=True)\n",
      "bias grad:  tensor([-0.1667])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7500]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2122]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0564,  -322.8721,   -11.3862,  -302.5933]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0867], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7288]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4051,\n",
      "            -6.0564,  -322.8721,   -11.3862,  -302.5933]], requires_grad=True)\n",
      "weight grad:  tensor([[1.0020e-03, 4.3220e-05, 1.1049e-04, 1.3650e-03, 7.6908e-04, 3.2347e-03,\n",
      "         1.0276e-01, 3.9485e-03, 7.4331e-02, 2.1354e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0867], requires_grad=True)\n",
      "bias grad:  tensor([0.4673])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7288]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2293]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0574,  -322.8721,   -11.3870,  -302.5934]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0820], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7518]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0574,  -322.8721,   -11.3870,  -302.5934]], requires_grad=True)\n",
      "weight grad:  tensor([[4.8155e-03, 0.0000e+00, 9.0865e-05, 1.2400e-03, 9.1324e-04, 5.4459e-04,\n",
      "         6.6659e-02, 3.3414e-03, 7.6118e-02, 1.5919e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0820], requires_grad=True)\n",
      "bias grad:  tensor([0.4416])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7518]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0903]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0581,  -322.8721,   -11.3877,  -302.5934]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0776], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7427]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0581,  -322.8721,   -11.3877,  -302.5934]], requires_grad=True)\n",
      "weight grad:  tensor([[1.4524e-03, 0.0000e+00, 3.8781e-05, 3.9242e-04, 2.2499e-04, 5.9951e-04,\n",
      "         3.0962e-02, 1.4146e-03, 2.8808e-02, 8.9663e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0776], requires_grad=True)\n",
      "bias grad:  tensor([0.1641])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7427]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2339]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0584,  -322.8721,   -11.3880,  -302.5934]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0760], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7193]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0584,  -322.8721,   -11.3880,  -302.5934]], requires_grad=True)\n",
      "weight grad:  tensor([[1.1181e-03, 9.4316e-05, 6.5230e-05, 7.8743e-04, 1.9413e-04, 1.1686e-03,\n",
      "         4.8966e-02, 2.3932e-03, 4.9672e-02, 1.2587e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0760], requires_grad=True)\n",
      "bias grad:  tensor([0.2853])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7193]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2176]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0589,  -322.8722,   -11.3885,  -302.5934]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0731], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7411]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0589,  -322.8722,   -11.3885,  -302.5934]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.9330e-03, -5.8732e-05, -1.0977e-05, -7.3458e-05,  2.8261e-04,\n",
      "         -1.1633e-03, -2.3336e-02, -9.6503e-05, -2.8091e-04,  2.8951e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0731], requires_grad=True)\n",
      "bias grad:  tensor([0.0006])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7411]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3735]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0586,  -322.8722,   -11.3885,  -302.5934]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0731], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7038]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0586,  -322.8722,   -11.3885,  -302.5934]], requires_grad=True)\n",
      "weight grad:  tensor([[7.2624e-04, 0.0000e+00, 8.3800e-05, 1.0136e-03, 6.4024e-04, 9.3551e-04,\n",
      "         4.9927e-02, 3.1433e-03, 6.2559e-02, 1.5086e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0731], requires_grad=True)\n",
      "bias grad:  tensor([0.3663])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7038]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0138]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0591,  -322.8722,   -11.3891,  -302.5934]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0695], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7051]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0591,  -322.8722,   -11.3891,  -302.5934]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5497e-03, 1.3653e-05, 3.9075e-05, 3.2276e-04, 3.6592e-04, 2.1047e-03,\n",
      "         5.4558e-02, 1.5447e-03, 2.2831e-02, 1.3832e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0695], requires_grad=True)\n",
      "bias grad:  tensor([0.1450])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7051]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4027]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0597,  -322.8722,   -11.3894,  -302.5934]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0680], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6649]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0597,  -322.8722,   -11.3894,  -302.5934]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8064e-03, 4.5423e-05, 7.9739e-05, 9.1577e-04, 5.7896e-04, 2.9343e-03,\n",
      "         8.6702e-02, 2.7877e-03, 5.3480e-02, 1.5649e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0680], requires_grad=True)\n",
      "bias grad:  tensor([0.3150])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6649]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2206]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0606,  -322.8723,   -11.3899,  -302.5934]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0649], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6869]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0606,  -322.8723,   -11.3899,  -302.5934]], requires_grad=True)\n",
      "weight grad:  tensor([[4.1111e-04, 4.7148e-05, 1.4910e-04, 1.5964e-03, 6.6559e-04, 2.4387e-03,\n",
      "         1.0159e-01, 4.2841e-03, 8.9742e-02, 2.4669e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0649], requires_grad=True)\n",
      "bias grad:  tensor([0.5556])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6869]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3002]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0616,  -322.8723,   -11.3908,  -302.5934]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0593], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7169]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0616,  -322.8723,   -11.3908,  -302.5934]], requires_grad=True)\n",
      "weight grad:  tensor([[5.0697e-03, 0.0000e+00, 7.5303e-05, 9.6199e-04, 7.6437e-04, 1.3240e-03,\n",
      "         5.9284e-02, 2.5874e-03, 5.9502e-02, 1.3010e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0593], requires_grad=True)\n",
      "bias grad:  tensor([0.3391])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7169]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2216]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0622,  -322.8723,   -11.3914,  -302.5934]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0559], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7391]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0622,  -322.8723,   -11.3914,  -302.5934]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7526e-03, 0.0000e+00, 4.8258e-05, 4.8334e-04, 3.5671e-04, 7.4507e-04,\n",
      "         3.6545e-02, 1.8958e-03, 3.4856e-02, 9.0171e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0559], requires_grad=True)\n",
      "bias grad:  tensor([0.1996])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7391]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3232]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0625,  -322.8723,   -11.3918,  -302.5934]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0539], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7068]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0625,  -322.8723,   -11.3918,  -302.5934]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0018, 0.0003, 0.0003, 0.0033, 0.0009, 0.0076, 0.2332, 0.0077, 0.1521,\n",
      "         0.0026]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0539], requires_grad=True)\n",
      "bias grad:  tensor([0.9315])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7068]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5265]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0649,  -322.8724,   -11.3933,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0446], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8594]], requires_grad=True)\n",
      "Iteration 1 | Score: 0.23055382072925568\n",
      "updating best value\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0649,  -322.8724,   -11.3933,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8224e-03,  0.0000e+00,  2.3805e-05,  1.3387e-04,  1.1847e-04,\n",
      "          5.7767e-04,  2.1066e-02,  1.1568e-03,  1.5381e-02,  3.2948e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0446], requires_grad=True)\n",
      "bias grad:  tensor([0.0893])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8594]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2919]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0651,  -322.8724,   -11.3934,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0437], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8303]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0651,  -322.8724,   -11.3934,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[1.1168e-03, 4.6443e-05, 9.3839e-05, 1.2057e-03, 7.4145e-04, 1.0597e-03,\n",
      "         5.8859e-02, 3.0714e-03, 6.9530e-02, 1.8783e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0437], requires_grad=True)\n",
      "bias grad:  tensor([0.4167])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8303]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1538]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0657,  -322.8725,   -11.3941,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0395], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8456]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0657,  -322.8725,   -11.3941,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.7697e-04, -4.0945e-05,  4.1956e-05,  5.2131e-04,  3.2860e-04,\n",
      "          6.8156e-04,  2.9273e-02,  2.0833e-03,  3.9649e-02,  1.7678e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0395], requires_grad=True)\n",
      "bias grad:  tensor([0.2232])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8456]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6807]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0660,  -322.8725,   -11.3945,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0373], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7776]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0660,  -322.8725,   -11.3945,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[1.2240e-03, 8.6843e-06, 7.7729e-05, 6.9247e-04, 2.7320e-04, 2.6882e-03,\n",
      "         7.0026e-02, 2.3062e-03, 4.8312e-02, 1.4135e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0373], requires_grad=True)\n",
      "bias grad:  tensor([0.2737])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7776]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1009]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0667,  -322.8725,   -11.3950,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0346], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7675]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0667,  -322.8725,   -11.3950,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.4926e-03, -3.2639e-05, -2.6082e-05, -5.3216e-04, -3.1699e-04,\n",
      "         -2.3831e-04, -1.5065e-02, -6.1440e-04, -1.8816e-02,  3.6289e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0346], requires_grad=True)\n",
      "bias grad:  tensor([-0.1106])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7675]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7299]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0665,  -322.8725,   -11.3948,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0357], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6945]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0665,  -322.8725,   -11.3948,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5837e-03, 0.0000e+00, 3.2376e-05, 3.8648e-04, 3.3623e-04, 3.0171e-04,\n",
      "         2.6575e-02, 5.7906e-04, 1.9765e-02, 1.6729e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0357], requires_grad=True)\n",
      "bias grad:  tensor([0.1214])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6945]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3793]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0668,  -322.8725,   -11.3950,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0345], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7324]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0668,  -322.8725,   -11.3950,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[6.1731e-03, 3.8245e-05, 1.1606e-04, 1.5066e-03, 1.1795e-03, 1.5241e-03,\n",
      "         8.1294e-02, 4.2255e-03, 9.2425e-02, 2.8146e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0345], requires_grad=True)\n",
      "bias grad:  tensor([0.5439])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7324]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1481]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0676,  -322.8726,   -11.3959,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0290], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7472]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0676,  -322.8726,   -11.3959,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3723e-02,  0.0000e+00, -2.0471e-05, -6.0276e-04, -8.1215e-04,\n",
      "         -3.6455e-04, -1.6637e-02, -1.1221e-03, -2.9362e-02, -2.8147e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0290], requires_grad=True)\n",
      "bias grad:  tensor([-0.1639])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7472]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2412]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0674,  -322.8726,   -11.3956,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0307], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7231]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0674,  -322.8726,   -11.3956,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.0560e-03,  2.2813e-05,  5.4675e-05,  4.9557e-04,  8.4587e-05,\n",
      "          1.3077e-03,  4.1346e-02,  1.7938e-03,  3.3183e-02,  1.2774e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0307], requires_grad=True)\n",
      "bias grad:  tensor([0.1988])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7231]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0855]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0678,  -322.8726,   -11.3960,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0287], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7146]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0678,  -322.8726,   -11.3960,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.5668e-04,  0.0000e+00, -9.8731e-05, -5.5124e-04,  1.7479e-05,\n",
      "         -5.1624e-03, -1.2826e-01, -2.8992e-03, -4.8445e-02,  9.5549e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0287], requires_grad=True)\n",
      "bias grad:  tensor([-0.3081])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7146]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.2135]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0665,  -322.8726,   -11.3955,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0318], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5932]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0665,  -322.8726,   -11.3955,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.3719e-03,  1.3756e-05, -1.3255e-05,  4.0517e-04,  8.5251e-04,\n",
      "         -3.2577e-03, -5.9499e-02,  1.2509e-05,  1.5390e-02, -4.9563e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0318], requires_grad=True)\n",
      "bias grad:  tensor([0.0728])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5932]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0244]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0660,  -322.8726,   -11.3956,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0310], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5908]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0660,  -322.8726,   -11.3956,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.0806e-03, -4.5360e-05, -1.6592e-05, -1.1288e-04,  2.8176e-04,\n",
      "         -1.2261e-03, -2.9890e-02,  2.3465e-05, -1.6137e-04,  3.6940e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0310], requires_grad=True)\n",
      "bias grad:  tensor([-0.0188])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5908]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7136]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0657,  -322.8726,   -11.3956,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0312], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5194]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0657,  -322.8726,   -11.3956,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.2527e-03, -1.8371e-04, -7.9441e-05, -4.5983e-04,  1.4376e-04,\n",
      "         -4.4550e-03, -1.0306e-01, -2.2581e-03, -3.3339e-02, -4.5277e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0312], requires_grad=True)\n",
      "bias grad:  tensor([-0.2202])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5194]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6244]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0646,  -322.8725,   -11.3953,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0334], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4570]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0646,  -322.8725,   -11.3953,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0045, 0.0000, 0.0002, 0.0024, 0.0005, 0.0013, 0.0918, 0.0046, 0.1293,\n",
      "         0.0027]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0334], requires_grad=True)\n",
      "bias grad:  tensor([0.7418])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4570]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.5075]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0655,  -322.8726,   -11.3966,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0260], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7077]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0655,  -322.8726,   -11.3966,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5117e-03,  3.2316e-05, -3.5931e-05, -5.4931e-04, -4.2613e-04,\n",
      "         -5.9589e-04, -3.3357e-02, -1.2360e-03, -2.6932e-02, -1.7526e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0260], requires_grad=True)\n",
      "bias grad:  tensor([-0.1582])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7077]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0119]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0652,  -322.8726,   -11.3963,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0276], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7065]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0652,  -322.8726,   -11.3963,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[6.0851e-05, 4.0468e-05, 8.5015e-05, 1.0416e-03, 5.3663e-04, 3.0212e-03,\n",
      "         8.7069e-02, 3.0538e-03, 5.7058e-02, 1.5919e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0276], requires_grad=True)\n",
      "bias grad:  tensor([0.3556])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7065]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2491]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0661,  -322.8726,   -11.3969,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0240], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7314]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0661,  -322.8726,   -11.3969,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2694e-03, 0.0000e+00, 6.3310e-05, 9.0364e-04, 6.9365e-04, 3.6626e-04,\n",
      "         4.3460e-02, 2.3352e-03, 5.4684e-02, 1.0177e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0240], requires_grad=True)\n",
      "bias grad:  tensor([0.3194])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7314]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0343]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0665,  -322.8727,   -11.3974,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0208], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7349]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0665,  -322.8727,   -11.3974,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[8.7786e-05, 0.0000e+00, 2.5894e-05, 1.7468e-04, 5.7274e-05, 4.5226e-04,\n",
      "         2.2324e-02, 9.0574e-04, 1.6729e-02, 7.2062e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0208], requires_grad=True)\n",
      "bias grad:  tensor([0.0952])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7349]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2923]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0667,  -322.8727,   -11.3976,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0199], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7056]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0667,  -322.8727,   -11.3976,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[6.6395e-04, 7.9539e-05, 4.9735e-05, 5.7214e-04, 1.1782e-05, 1.0729e-03,\n",
      "         4.2330e-02, 1.7776e-03, 3.6920e-02, 9.8627e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0199], requires_grad=True)\n",
      "bias grad:  tensor([0.2120])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7056]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2183]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0672,  -322.8727,   -11.3980,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0178], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7275]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0672,  -322.8727,   -11.3980,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.7413e-03, -7.5031e-05, -3.0727e-05, -3.3738e-04,  1.9912e-04,\n",
      "         -1.7815e-03, -4.0307e-02, -8.3284e-04, -1.4992e-02,  2.9068e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0178], requires_grad=True)\n",
      "bias grad:  tensor([-0.0827])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7275]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6185]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0668,  -322.8727,   -11.3978,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0186], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6656]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0668,  -322.8727,   -11.3978,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5783e-03, 0.0000e+00, 9.2953e-05, 1.1582e-03, 7.4844e-04, 9.1588e-04,\n",
      "         5.3433e-02, 3.5069e-03, 7.0959e-02, 1.6863e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0186], requires_grad=True)\n",
      "bias grad:  tensor([0.4136])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6656]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0274]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0673,  -322.8727,   -11.3985,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0144], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6683]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0673,  -322.8727,   -11.3985,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[1.2602e-03, 1.9946e-05, 3.0835e-05, 2.4280e-04, 2.5024e-04, 1.9712e-03,\n",
      "         4.7743e-02, 1.1857e-03, 1.6562e-02, 1.1205e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0144], requires_grad=True)\n",
      "bias grad:  tensor([0.1062])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6683]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2867]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0678,  -322.8727,   -11.3987,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0134], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6397]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0678,  -322.8727,   -11.3987,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0423e-03, 4.3803e-05, 7.0207e-05, 7.6416e-04, 4.3292e-04, 2.6393e-03,\n",
      "         7.7111e-02, 2.3362e-03, 4.4906e-02, 1.3636e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0134], requires_grad=True)\n",
      "bias grad:  tensor([0.2638])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6397]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2015]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0685,  -322.8727,   -11.3992,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0107], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6598]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0685,  -322.8727,   -11.3992,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4156e-04, 4.3907e-05, 1.5145e-04, 1.5981e-03, 7.0278e-04, 2.1753e-03,\n",
      "         9.8790e-02, 4.3992e-03, 8.9526e-02, 2.5423e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0107], requires_grad=True)\n",
      "bias grad:  tensor([0.5646])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6598]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2436]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0695,  -322.8728,   -11.4001,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0051], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6842]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0695,  -322.8728,   -11.4001,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[4.6477e-03, 0.0000e+00, 8.1139e-05, 1.0155e-03, 7.7383e-04, 1.4393e-03,\n",
      "         6.2218e-02, 2.7311e-03, 6.2562e-02, 1.5454e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0051], requires_grad=True)\n",
      "bias grad:  tensor([0.3569])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6842]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2891]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0701,  -322.8728,   -11.4007,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0015], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7131]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0701,  -322.8728,   -11.4007,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7844e-03, 0.0000e+00, 6.0191e-05, 6.7281e-04, 5.6561e-04, 7.9935e-04,\n",
      "         4.4049e-02, 2.4218e-03, 4.5248e-02, 1.0895e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0015], requires_grad=True)\n",
      "bias grad:  tensor([0.2613])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7131]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2706]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0706,  -322.8728,   -11.4011,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0011], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6860]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0706,  -322.8728,   -11.4011,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0019, 0.0003, 0.0003, 0.0032, 0.0008, 0.0076, 0.2249, 0.0073, 0.1425,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0011], requires_grad=True)\n",
      "bias grad:  tensor([0.8771])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6860]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5893]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0728,  -322.8729,   -11.4026,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0099], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8450]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0728,  -322.8729,   -11.4026,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1553e-03,  0.0000e+00,  2.9780e-05,  1.9733e-04,  2.0200e-04,\n",
      "          7.3688e-04,  2.6217e-02,  1.3584e-03,  1.9732e-02,  3.9370e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0099], requires_grad=True)\n",
      "bias grad:  tensor([0.1158])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8450]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3150]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0731,  -322.8729,   -11.4028,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0110], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8135]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0731,  -322.8729,   -11.4028,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[3.9729e-04, 4.5223e-05, 9.4773e-05, 1.1996e-03, 7.6141e-04, 1.0721e-03,\n",
      "         6.1075e-02, 3.1574e-03, 7.0597e-02, 2.1166e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0110], requires_grad=True)\n",
      "bias grad:  tensor([0.4211])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8135]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0611]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0737,  -322.8729,   -11.4035,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0152], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8196]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0737,  -322.8729,   -11.4035,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.4077e-04, -3.5185e-05,  3.5694e-05,  4.2939e-04,  2.7675e-04,\n",
      "          8.2027e-04,  2.8301e-02,  1.8364e-03,  3.4308e-02,  1.6794e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0152], requires_grad=True)\n",
      "bias grad:  tensor([0.1927])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8196]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6790]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0740,  -322.8730,   -11.4038,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0171], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7517]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0740,  -322.8730,   -11.4038,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[1.0533e-03, 5.7772e-06, 8.0656e-05, 7.3254e-04, 3.2415e-04, 2.6929e-03,\n",
      "         7.2573e-02, 2.4698e-03, 5.1162e-02, 1.4646e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0171], requires_grad=True)\n",
      "bias grad:  tensor([0.2897])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7517]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0906]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0747,  -322.8730,   -11.4043,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0200], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7426]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0747,  -322.8730,   -11.4043,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.7848e-03, -3.7260e-05, -2.7772e-05, -5.6533e-04, -3.5965e-04,\n",
      "         -2.5687e-04, -1.8832e-02, -7.0620e-04, -2.0824e-02,  2.7026e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0200], requires_grad=True)\n",
      "bias grad:  tensor([-0.1218])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7426]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7196]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0745,  -322.8730,   -11.4041,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0188], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6706]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0745,  -322.8730,   -11.4041,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[2.9810e-03, 0.0000e+00, 1.8952e-05, 2.2976e-04, 2.5305e-04, 1.5438e-04,\n",
      "         1.6804e-02, 1.7278e-04, 9.4484e-03, 4.2931e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0188], requires_grad=True)\n",
      "bias grad:  tensor([0.0647])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6706]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3497]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0747,  -322.8730,   -11.4042,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0195], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7056]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0747,  -322.8730,   -11.4042,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[5.7675e-03, 3.4683e-05, 1.1940e-04, 1.4924e-03, 1.1524e-03, 1.6109e-03,\n",
      "         8.4548e-02, 4.2584e-03, 9.2414e-02, 2.9684e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0195], requires_grad=True)\n",
      "bias grad:  tensor([0.5447])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7056]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0284]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0755,  -322.8730,   -11.4051,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0249], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7085]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0755,  -322.8730,   -11.4051,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7687e-02,  0.0000e+00, -1.6138e-05, -6.5122e-04, -9.1827e-04,\n",
      "         -3.7037e-04, -1.6986e-02, -1.0443e-03, -3.0090e-02, -2.4977e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0249], requires_grad=True)\n",
      "bias grad:  tensor([-0.1665])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7085]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3465]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0754,  -322.8730,   -11.4048,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0233], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6738]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0754,  -322.8730,   -11.4048,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.8743e-03,  1.5583e-05,  5.8128e-05,  6.1998e-04,  2.0899e-04,\n",
      "          1.4104e-03,  4.5709e-02,  1.9762e-03,  3.8348e-02,  1.1294e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0233], requires_grad=True)\n",
      "bias grad:  tensor([0.2279])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6738]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0829]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0758,  -322.8730,   -11.4052,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0255], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6821]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0758,  -322.8730,   -11.4052,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.2527e-05,  0.0000e+00, -9.0958e-05, -4.4642e-04,  7.6539e-05,\n",
      "         -4.9895e-03, -1.2217e-01, -2.5602e-03, -4.1988e-02,  1.5598e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0255], requires_grad=True)\n",
      "bias grad:  tensor([-0.2704])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6821]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1747]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0746,  -322.8730,   -11.4048,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0228], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5646]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0746,  -322.8730,   -11.4048,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.7242e-03,  2.7915e-05,  4.5815e-06,  6.0741e-04,  9.2105e-04,\n",
      "         -3.0547e-03, -5.0166e-02,  6.0244e-04,  2.7921e-02, -1.3686e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0228], requires_grad=True)\n",
      "bias grad:  tensor([0.1459])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5646]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0621]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0741,  -322.8730,   -11.4051,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0243], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5708]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0741,  -322.8730,   -11.4051,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.8983e-03, -5.8600e-05, -3.1198e-05, -2.7195e-04,  2.3720e-04,\n",
      "         -1.6358e-03, -4.3026e-02, -4.1167e-04, -8.8938e-03,  2.6265e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0243], requires_grad=True)\n",
      "bias grad:  tensor([-0.0710])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5708]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8247]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0737,  -322.8730,   -11.4050,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0236], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4884]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0737,  -322.8730,   -11.4050,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.1787e-03, -1.8572e-04, -5.1222e-05, -3.1920e-04,  1.9350e-04,\n",
      "         -3.5810e-03, -7.7504e-02, -1.5130e-03, -2.2089e-02, -1.9695e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0236], requires_grad=True)\n",
      "bias grad:  tensor([-0.1339])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4884]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6530]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0729,  -322.8730,   -11.4048,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0222], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4231]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0729,  -322.8730,   -11.4048,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0053, 0.0000, 0.0002, 0.0029, 0.0007, 0.0016, 0.1144, 0.0056, 0.1541,\n",
      "         0.0031]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0222], requires_grad=True)\n",
      "bias grad:  tensor([0.8836])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4231]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.0399]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0740,  -322.8731,   -11.4063,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0311], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7271]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0740,  -322.8731,   -11.4063,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.4121e-03,  2.8418e-05, -5.8819e-05, -9.3442e-04, -6.8120e-04,\n",
      "         -7.1875e-04, -4.4951e-02, -2.1812e-03, -4.8209e-02, -4.2106e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0311], requires_grad=True)\n",
      "bias grad:  tensor([-0.2787])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7271]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2501]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0736,  -322.8730,   -11.4058,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0283], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7021]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0736,  -322.8730,   -11.4058,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.5660e-04,  3.3679e-05,  8.8696e-05,  1.0648e-03,  5.4688e-04,\n",
      "          2.8076e-03,  8.5440e-02,  3.1585e-03,  5.7821e-02,  1.7127e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0283], requires_grad=True)\n",
      "bias grad:  tensor([0.3654])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7021]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2334]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0745,  -322.8731,   -11.4064,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0319], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7254]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0745,  -322.8731,   -11.4064,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[3.8146e-03, 0.0000e+00, 8.5216e-05, 1.1665e-03, 8.0803e-04, 5.5170e-04,\n",
      "         5.8020e-02, 3.1370e-03, 7.1213e-02, 1.3871e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0319], requires_grad=True)\n",
      "bias grad:  tensor([0.4141])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7254]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0348]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0750,  -322.8731,   -11.4071,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0361], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7289]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0750,  -322.8731,   -11.4071,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7835e-04,  0.0000e+00,  1.4949e-05,  4.2718e-05,  1.7509e-05,\n",
      "          3.9684e-04,  1.6029e-02,  5.4721e-04,  8.6881e-03,  5.7007e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0361], requires_grad=True)\n",
      "bias grad:  tensor([0.0490])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7289]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3572]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0752,  -322.8731,   -11.4072,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0366], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6932]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0752,  -322.8731,   -11.4072,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.1976e-04,  8.4433e-05,  5.3652e-05,  6.1262e-04, -8.0994e-06,\n",
      "          1.1199e-03,  4.5192e-02,  1.9112e-03,  3.9439e-02,  1.0565e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0366], requires_grad=True)\n",
      "bias grad:  tensor([0.2278])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6932]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2571]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0756,  -322.8731,   -11.4076,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0389], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7189]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0756,  -322.8731,   -11.4076,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.7530e-04, -7.8730e-05, -4.4733e-05, -5.2490e-04,  5.0785e-05,\n",
      "         -1.8399e-03, -4.6857e-02, -1.2780e-03, -2.5595e-02,  4.3418e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0389], requires_grad=True)\n",
      "bias grad:  tensor([-0.1453])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7189]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5602]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0752,  -322.8731,   -11.4073,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0374], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6628]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0752,  -322.8731,   -11.4073,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.9674e-04,  0.0000e+00,  8.6466e-05,  1.0148e-03,  5.5162e-04,\n",
      "          8.8037e-04,  4.8590e-02,  3.2294e-03,  6.3804e-02,  1.6909e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0374], requires_grad=True)\n",
      "bias grad:  tensor([0.3717])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6628]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0211]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0757,  -322.8732,   -11.4080,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0411], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6607]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0757,  -322.8732,   -11.4080,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.3424e-04,  1.2360e-05,  5.6952e-06, -7.3795e-05,  1.4436e-04,\n",
      "          1.5466e-03,  2.9143e-02,  4.4372e-04, -3.9015e-04,  7.1551e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0411], requires_grad=True)\n",
      "bias grad:  tensor([0.0049])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6607]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4271]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0760,  -322.8732,   -11.4080,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0412], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6180]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0760,  -322.8732,   -11.4080,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[1.3129e-03, 3.4482e-05, 6.0091e-05, 6.6545e-04, 3.4756e-04, 2.5181e-03,\n",
      "         7.1182e-02, 2.0802e-03, 3.9095e-02, 1.0521e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0412], requires_grad=True)\n",
      "bias grad:  tensor([0.2275])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6180]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2051]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0767,  -322.8732,   -11.4084,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0434], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6385]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0767,  -322.8732,   -11.4084,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3624e-04, 4.1349e-05, 1.3655e-04, 1.4433e-03, 5.9114e-04, 2.0846e-03,\n",
      "         9.0311e-02, 3.7780e-03, 8.1351e-02, 2.1369e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0434], requires_grad=True)\n",
      "bias grad:  tensor([0.4985])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6385]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3225]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0776,  -322.8732,   -11.4092,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0484], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6708]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0776,  -322.8732,   -11.4092,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[4.9301e-03, 0.0000e+00, 6.1325e-05, 7.8111e-04, 6.4176e-04, 1.0748e-03,\n",
      "         4.9083e-02, 2.0291e-03, 4.8376e-02, 9.3410e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0484], requires_grad=True)\n",
      "bias grad:  tensor([0.2739])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6708]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3299]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0781,  -322.8733,   -11.4097,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0512], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7038]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0781,  -322.8733,   -11.4097,  -302.5940]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight grad:  tensor([[5.7989e-03, 0.0000e+00, 5.4631e-05, 6.1190e-04, 7.9453e-04, 8.7578e-04,\n",
      "         4.7990e-02, 2.6323e-03, 4.3587e-02, 6.3844e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0512], requires_grad=True)\n",
      "bias grad:  tensor([0.2543])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7038]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3770]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0785,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0537], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6661]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0785,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0003, 0.0003, 0.0003, 0.0031, 0.0007, 0.0075, 0.2244, 0.0072, 0.1366,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0537], requires_grad=True)\n",
      "bias grad:  tensor([0.8444])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6661]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5370]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0808,  -322.8734,   -11.4115,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0622], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8198]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0808,  -322.8734,   -11.4115,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7725e-03,  0.0000e+00,  1.1858e-05, -3.8950e-05,  1.8297e-05,\n",
      "          5.1682e-04,  1.3735e-02,  6.8674e-04,  5.5577e-03,  1.6508e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0622], requires_grad=True)\n",
      "bias grad:  tensor([0.0316])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8198]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3158]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0809,  -322.8734,   -11.4115,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0625], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7882]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0809,  -322.8734,   -11.4115,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1091e-04,  4.6658e-05,  8.5309e-05,  1.0610e-03,  6.4792e-04,\n",
      "          9.9075e-04,  5.5512e-02,  2.8437e-03,  6.2099e-02,  1.9343e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0625], requires_grad=True)\n",
      "bias grad:  tensor([0.3739])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7882]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0567]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0815,  -322.8734,   -11.4121,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0662], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7939]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0815,  -322.8734,   -11.4121,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.9576e-04, -3.7848e-05,  2.6065e-05,  3.0274e-04,  1.7493e-04,\n",
      "          6.0248e-04,  2.0599e-02,  1.4685e-03,  2.6447e-02,  1.4982e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0662], requires_grad=True)\n",
      "bias grad:  tensor([0.1475])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7939]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6736]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0817,  -322.8734,   -11.4124,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0677], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7265]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0817,  -322.8734,   -11.4124,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5360e-03, 7.7457e-06, 7.5807e-05, 7.3395e-04, 3.1048e-04, 2.5175e-03,\n",
      "         6.7113e-02, 2.2986e-03, 4.8396e-02, 1.3282e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0677], requires_grad=True)\n",
      "bias grad:  tensor([0.2753])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7265]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0479]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0824,  -322.8734,   -11.4129,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0704], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7313]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0824,  -322.8734,   -11.4129,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.1293e-03, -2.1601e-05, -2.1501e-05, -4.5287e-04, -2.6053e-04,\n",
      "         -1.9899e-04, -1.5330e-02, -5.2098e-04, -1.5476e-02,  2.9524e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0704], requires_grad=True)\n",
      "bias grad:  tensor([-0.0900])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7313]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5559]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0822,  -322.8734,   -11.4127,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0695], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6757]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0822,  -322.8734,   -11.4127,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3114e-03,  0.0000e+00, -6.7816e-06, -1.3859e-04,  5.4246e-05,\n",
      "          4.8818e-06,  3.3929e-03, -5.9722e-04, -1.0140e-02, -3.8645e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0695], requires_grad=True)\n",
      "bias grad:  tensor([-0.0514])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6757]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1857]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0822,  -322.8734,   -11.4126,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0690], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6943]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0822,  -322.8734,   -11.4126,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[5.1166e-03, 3.1349e-05, 1.2160e-04, 1.5120e-03, 1.1319e-03, 1.5829e-03,\n",
      "         8.3374e-02, 4.3570e-03, 9.3815e-02, 3.0164e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0690], requires_grad=True)\n",
      "bias grad:  tensor([0.5536])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6943]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0340]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0831,  -322.8734,   -11.4136,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0746], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6977]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0831,  -322.8734,   -11.4136,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5515e-02,  0.0000e+00, -2.4843e-05, -7.0229e-04, -9.3949e-04,\n",
      "         -4.2864e-04, -1.9548e-02, -1.3352e-03, -3.4481e-02, -3.3696e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0746], requires_grad=True)\n",
      "bias grad:  tensor([-0.1927])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6977]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2127]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0829,  -322.8734,   -11.4132,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0726], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6764]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0829,  -322.8734,   -11.4132,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.3649e-03,  1.8849e-05,  5.2596e-05,  5.2504e-04,  2.0717e-04,\n",
      "          1.4253e-03,  4.5454e-02,  1.7656e-03,  3.3929e-02,  1.0554e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0726], requires_grad=True)\n",
      "bias grad:  tensor([0.2011])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6764]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0723]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0833,  -322.8735,   -11.4136,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0746], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6836]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0833,  -322.8735,   -11.4136,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.8273e-04,  0.0000e+00, -1.1486e-04, -7.5172e-04, -1.4847e-04,\n",
      "         -5.3644e-03, -1.3968e-01, -3.4238e-03, -6.1085e-02, -2.4952e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0746], requires_grad=True)\n",
      "bias grad:  tensor([-0.3806])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6836]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1883]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0819,  -322.8734,   -11.4129,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0708], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5648]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0819,  -322.8734,   -11.4129,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.6206e-03,  2.4591e-05, -1.6967e-05,  3.9319e-04,  8.0558e-04,\n",
      "         -3.4602e-03, -6.7194e-02, -1.4197e-04,  1.3600e-02, -6.0259e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0708], requires_grad=True)\n",
      "bias grad:  tensor([0.0591])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5648]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1969]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0813,  -322.8734,   -11.4131,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0714], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5845]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0813,  -322.8734,   -11.4131,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.2712e-03, -6.6416e-05, -4.8387e-05, -5.5597e-04, -4.7210e-05,\n",
      "         -1.7620e-03, -5.5736e-02, -1.1230e-03, -2.4736e-02,  1.9686e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0714], requires_grad=True)\n",
      "bias grad:  tensor([-0.1624])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5845]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9277]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0807,  -322.8734,   -11.4128,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0698], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4917]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0807,  -322.8734,   -11.4128,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.1025e-04, -1.9023e-04, -3.1641e-05, -2.2450e-04,  1.6174e-04,\n",
      "         -3.6740e-03, -7.1984e-02, -1.2731e-03, -1.3238e-02,  3.7100e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0698], requires_grad=True)\n",
      "bias grad:  tensor([-0.0884])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4917]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8783]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0800,  -322.8734,   -11.4127,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0689], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4039]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0800,  -322.8734,   -11.4127,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0053, 0.0000, 0.0002, 0.0029, 0.0008, 0.0018, 0.1227, 0.0058, 0.1585,\n",
      "         0.0033]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0689], requires_grad=True)\n",
      "bias grad:  tensor([0.9078])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4039]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.1138]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0812,  -322.8735,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0780], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7153]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0812,  -322.8735,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.5751e-03,  2.6714e-05, -5.2784e-05, -8.4375e-04, -5.9670e-04,\n",
      "         -6.8775e-04, -4.0515e-02, -1.8564e-03, -4.1835e-02, -2.7883e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0780], requires_grad=True)\n",
      "bias grad:  tensor([-0.2433])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7153]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2844]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0808,  -322.8735,   -11.4139,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0756], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6868]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0808,  -322.8735,   -11.4139,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[5.5748e-05, 3.5526e-05, 6.2115e-05, 7.6659e-04, 3.5927e-04, 2.4676e-03,\n",
      "         6.6520e-02, 2.2555e-03, 3.9631e-02, 1.2029e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0756], requires_grad=True)\n",
      "bias grad:  tensor([0.2581])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6868]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2994]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0815,  -322.8735,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0781], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7168]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0815,  -322.8735,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0042, 0.0000, 0.0001, 0.0015, 0.0009, 0.0007, 0.0999, 0.0042, 0.0929,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0781], requires_grad=True)\n",
      "bias grad:  tensor([0.5362])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7168]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0839]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0825,  -322.8735,   -11.4152,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0835], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7084]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0825,  -322.8735,   -11.4152,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0740e-04,  0.0000e+00,  9.6301e-06, -4.5381e-05, -6.4042e-05,\n",
      "          4.0385e-04,  1.3290e-02,  2.6420e-04,  4.0188e-03,  5.8566e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0835], requires_grad=True)\n",
      "bias grad:  tensor([0.0227])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7084]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3266]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0826,  -322.8735,   -11.4152,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0837], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6757]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0826,  -322.8735,   -11.4152,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[7.1615e-04, 7.6376e-05, 4.7231e-05, 5.5022e-04, 3.0993e-05, 8.6135e-04,\n",
      "         3.6990e-02, 1.6893e-03, 3.5218e-02, 9.2484e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0837], requires_grad=True)\n",
      "bias grad:  tensor([0.2035])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6757]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1815]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0830,  -322.8736,   -11.4156,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0858], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6939]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0830,  -322.8736,   -11.4156,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.0945e-04, -6.8841e-05, -3.1814e-05, -3.7764e-04,  8.5784e-05,\n",
      "         -1.6080e-03, -3.8136e-02, -8.3326e-04, -1.6020e-02,  2.7283e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0858], requires_grad=True)\n",
      "bias grad:  tensor([-0.0916])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6939]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5585]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0826,  -322.8736,   -11.4154,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0849], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6380]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0826,  -322.8736,   -11.4154,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.9497e-04,  0.0000e+00,  9.3400e-05,  1.0092e-03,  5.7711e-04,\n",
      "          1.5023e-03,  5.9956e-02,  3.3135e-03,  6.3157e-02,  1.7101e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0849], requires_grad=True)\n",
      "bias grad:  tensor([0.3799])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6380]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0401]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0832,  -322.8736,   -11.4161,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0887], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6420]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0832,  -322.8736,   -11.4161,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.7089e-04,  1.3558e-05,  9.9352e-06, -1.2146e-05,  1.0482e-04,\n",
      "          1.5634e-03,  3.2131e-02,  5.2068e-04,  1.5874e-03,  6.9785e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0887], requires_grad=True)\n",
      "bias grad:  tensor([0.0193])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6420]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3544]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0835,  -322.8736,   -11.4161,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0888], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6066]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0835,  -322.8736,   -11.4161,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8145e-03, 3.8553e-05, 6.4896e-05, 7.4956e-04, 4.8913e-04, 2.5979e-03,\n",
      "         7.5834e-02, 2.3181e-03, 4.3636e-02, 1.3168e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0888], requires_grad=True)\n",
      "bias grad:  tensor([0.2587])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6066]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1838]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0843,  -322.8736,   -11.4165,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0914], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6250]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0843,  -322.8736,   -11.4165,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7768e-04, 4.1471e-05, 1.1662e-04, 1.2224e-03, 4.7588e-04, 1.7434e-03,\n",
      "         7.6442e-02, 3.1300e-03, 6.8433e-02, 1.7973e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0914], requires_grad=True)\n",
      "bias grad:  tensor([0.4190])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6250]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3038]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0850,  -322.8737,   -11.4172,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0956], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6554]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0850,  -322.8737,   -11.4172,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0460e-03, 0.0000e+00, 4.2044e-05, 4.7097e-04, 3.8697e-04, 1.2209e-03,\n",
      "         4.1536e-02, 1.4998e-03, 3.1454e-02, 8.1277e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0956], requires_grad=True)\n",
      "bias grad:  tensor([0.1783])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6554]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1022]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0854,  -322.8737,   -11.4175,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0974], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6656]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0854,  -322.8737,   -11.4175,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5827e-03, 0.0000e+00, 3.7987e-05, 4.0119e-04, 2.8164e-04, 6.1747e-04,\n",
      "         3.0189e-02, 1.6290e-03, 2.7820e-02, 4.8772e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0974], requires_grad=True)\n",
      "bias grad:  tensor([0.1608])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6656]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1648]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8737,   -11.4178,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0990], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6491]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8737,   -11.4178,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0011, 0.0003, 0.0003, 0.0032, 0.0008, 0.0077, 0.2276, 0.0073, 0.1405,\n",
      "         0.0024]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0990], requires_grad=True)\n",
      "bias grad:  tensor([0.8679])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6491]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6945]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0880,  -322.8737,   -11.4192,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1077], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8185]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0880,  -322.8737,   -11.4192,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0248e-03,  0.0000e+00, -2.4629e-06, -1.8969e-04, -5.6828e-05,\n",
      "          2.2263e-04,  3.4335e-03,  2.4370e-04, -3.6969e-03, -1.3873e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1077], requires_grad=True)\n",
      "bias grad:  tensor([-0.0207])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8185]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3457]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0881,  -322.8737,   -11.4192,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1075], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7840]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0881,  -322.8737,   -11.4192,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7210e-04,  3.5058e-05,  9.3287e-05,  1.1718e-03,  8.9307e-04,\n",
      "          1.0215e-03,  5.8010e-02,  3.1682e-03,  7.1670e-02,  2.3877e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1075], requires_grad=True)\n",
      "bias grad:  tensor([0.4264])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7840]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0026]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0886,  -322.8738,   -11.4199,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1117], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7842]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0886,  -322.8738,   -11.4199,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6570e-04, -2.4730e-05,  2.9034e-05,  3.6456e-04,  2.4107e-04,\n",
      "          5.3873e-04,  2.0387e-02,  1.5495e-03,  2.9104e-02,  1.4677e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1117], requires_grad=True)\n",
      "bias grad:  tensor([0.1637])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7842]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5914]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0888,  -322.8738,   -11.4202,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1134], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7251]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0888,  -322.8738,   -11.4202,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7048e-04, 7.1598e-06, 7.0698e-05, 6.0142e-04, 2.2119e-04, 2.6827e-03,\n",
      "         6.8955e-02, 2.0744e-03, 4.1926e-02, 1.3275e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1134], requires_grad=True)\n",
      "bias grad:  tensor([0.2382])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7251]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0307]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0895,  -322.8738,   -11.4206,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1158], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7220]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0895,  -322.8738,   -11.4206,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.0958e-03, -3.2595e-05, -4.9429e-05, -8.7831e-04, -6.1538e-04,\n",
      "         -4.3896e-04, -3.2847e-02, -1.5355e-03, -4.0021e-02, -1.2295e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1158], requires_grad=True)\n",
      "bias grad:  tensor([-0.2315])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7220]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7052]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0892,  -322.8738,   -11.4202,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1135], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6515]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0892,  -322.8738,   -11.4202,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.7407e-04,  0.0000e+00,  5.5595e-07, -7.6261e-05,  2.6965e-06,\n",
      "          7.1128e-05,  3.7640e-03, -4.6183e-04, -6.9540e-03, -3.2654e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1135], requires_grad=True)\n",
      "bias grad:  tensor([-0.0343])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6515]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2721]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0892,  -322.8738,   -11.4201,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1131], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6787]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0892,  -322.8738,   -11.4201,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2819e-03, 2.5923e-05, 9.0722e-05, 1.1304e-03, 8.6997e-04, 1.2964e-03,\n",
      "         6.6111e-02, 3.2917e-03, 6.9720e-02, 2.4965e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1131], requires_grad=True)\n",
      "bias grad:  tensor([0.4152])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6787]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0385]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0899,  -322.8738,   -11.4208,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1173], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6826]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0899,  -322.8738,   -11.4208,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3096e-02,  0.0000e+00, -6.3163e-06, -4.1311e-04, -6.0929e-04,\n",
      "         -2.1955e-04, -1.0127e-02, -5.5231e-04, -1.8018e-02, -1.2281e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1173], requires_grad=True)\n",
      "bias grad:  tensor([-0.0987])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6826]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0898]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0898,  -322.8738,   -11.4206,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1163], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6736]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0898,  -322.8738,   -11.4206,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.4388e-03,  2.6222e-05,  3.6101e-05,  2.7141e-04, -3.4109e-05,\n",
      "          1.2419e-03,  3.2266e-02,  1.1564e-03,  1.9568e-02,  9.5448e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1163], requires_grad=True)\n",
      "bias grad:  tensor([0.1178])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6736]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0486]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0901,  -322.8738,   -11.4208,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1175], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6687]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0901,  -322.8738,   -11.4208,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.6391e-04,  0.0000e+00, -1.1626e-04, -7.4494e-04, -1.3017e-04,\n",
      "         -5.4119e-03, -1.4015e-01, -3.4597e-03, -6.1471e-02, -3.0381e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1175], requires_grad=True)\n",
      "bias grad:  tensor([-0.3829])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6687]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1469]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0887,  -322.8738,   -11.4202,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1136], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5540]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0887,  -322.8738,   -11.4202,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6362e-03,  1.5273e-05, -2.6148e-05,  2.1521e-04,  6.3452e-04,\n",
      "         -3.3913e-03, -6.9531e-02, -5.0861e-04,  4.1746e-03, -6.7911e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1136], requires_grad=True)\n",
      "bias grad:  tensor([0.0062])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5540]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0338]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0880,  -322.8738,   -11.4203,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1137], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5574]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0880,  -322.8738,   -11.4203,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.7885e-03, -6.6875e-05, -5.2684e-05, -6.3455e-04, -9.9238e-05,\n",
      "         -1.8502e-03, -5.8122e-02, -1.2578e-03, -2.8561e-02,  2.4063e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1137], requires_grad=True)\n",
      "bias grad:  tensor([-0.1844])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5574]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.0421]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0874,  -322.8738,   -11.4200,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1118], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4532]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0874,  -322.8738,   -11.4200,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.3252e-04, -1.9818e-04, -6.5396e-05, -5.1533e-04, -2.1377e-05,\n",
      "         -4.0901e-03, -9.1120e-02, -2.1227e-03, -3.2403e-02, -3.4285e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1118], requires_grad=True)\n",
      "bias grad:  tensor([-0.2036])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4532]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6299]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8738,   -11.4196,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1098], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3902]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8738,   -11.4196,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0058, 0.0000, 0.0003, 0.0032, 0.0009, 0.0019, 0.1282, 0.0063, 0.1724,\n",
      "         0.0035]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1098], requires_grad=True)\n",
      "bias grad:  tensor([0.9880])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3902]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.5007]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0878,  -322.8738,   -11.4214,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1197], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7403]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0878,  -322.8738,   -11.4214,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.1252e-03,  2.5967e-05, -6.5475e-05, -1.0520e-03, -7.9963e-04,\n",
      "         -7.4262e-04, -4.6675e-02, -2.4254e-03, -5.4663e-02, -4.5972e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1197], requires_grad=True)\n",
      "bias grad:  tensor([-0.3150])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7403]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2898]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0873,  -322.8738,   -11.4208,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1165], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7113]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0873,  -322.8738,   -11.4208,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.9869e-04,  3.9172e-05,  7.0016e-05,  8.2446e-04,  3.8922e-04,\n",
      "          2.6378e-03,  7.2668e-02,  2.4819e-03,  4.5125e-02,  1.3676e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1165], requires_grad=True)\n",
      "bias grad:  tensor([0.2845])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7113]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1755]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0881,  -322.8738,   -11.4213,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1194], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7289]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0881,  -322.8738,   -11.4213,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2171e-03, 0.0000e+00, 5.2921e-05, 7.7454e-04, 6.2982e-04, 2.7327e-04,\n",
      "         3.5638e-02, 1.9801e-03, 4.6876e-02, 8.5618e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1194], requires_grad=True)\n",
      "bias grad:  tensor([0.2746])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7289]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0619]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0884,  -322.8739,   -11.4217,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1221], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7350]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0884,  -322.8739,   -11.4217,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0666e-03,  0.0000e+00, -7.4600e-06, -2.9975e-04, -2.8076e-04,\n",
      "          1.6392e-04,  1.8617e-03, -3.7646e-04, -1.1259e-02,  2.8300e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1221], requires_grad=True)\n",
      "bias grad:  tensor([-0.0642])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7350]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3763]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0884,  -322.8739,   -11.4216,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1215], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6974]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0884,  -322.8739,   -11.4216,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1969e-04,  6.2782e-05,  2.5821e-05,  2.3080e-04, -2.3768e-04,\n",
      "          6.1042e-04,  2.3934e-02,  8.4099e-04,  1.7023e-02,  5.6518e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1215], requires_grad=True)\n",
      "bias grad:  tensor([0.0983])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6974]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1335]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0887,  -322.8739,   -11.4218,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1225], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7108]], requires_grad=True)\n",
      "Iteration 2 | Score: 0.33094048500061035\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0649,  -322.8724,   -11.3933,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3901e-03, -1.3035e-04, -6.7076e-05, -8.0973e-04,  6.6911e-05,\n",
      "         -2.2640e-03, -6.4631e-02, -1.8192e-03, -3.8672e-02,  8.1307e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0446], requires_grad=True)\n",
      "bias grad:  tensor([-0.2193])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8594]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.0556]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0642,  -322.8724,   -11.3929,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0468], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7539]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0642,  -322.8724,   -11.3929,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.1279e-04,  0.0000e+00,  6.4999e-05,  7.6277e-04,  4.5056e-04,\n",
      "          7.1614e-04,  3.6632e-02,  2.3981e-03,  4.7576e-02,  1.2368e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0468], requires_grad=True)\n",
      "bias grad:  tensor([0.2792])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7539]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0210]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0646,  -322.8724,   -11.3934,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0440], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7560]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0646,  -322.8724,   -11.3934,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[1.2272e-04, 1.5017e-05, 1.8410e-05, 7.6469e-05, 1.4588e-04, 1.5514e-03,\n",
      "         3.3366e-02, 7.9153e-04, 7.4642e-03, 9.0139e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0440], requires_grad=True)\n",
      "bias grad:  tensor([0.0538])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7560]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3625]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0649,  -322.8724,   -11.3934,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0435], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7197]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0649,  -322.8724,   -11.3934,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[8.5766e-04, 3.9376e-05, 5.2871e-05, 5.6613e-04, 3.4853e-04, 2.4455e-03,\n",
      "         6.7839e-02, 1.9703e-03, 3.4825e-02, 1.1537e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0435], requires_grad=True)\n",
      "bias grad:  tensor([0.2036])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7197]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0143]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0656,  -322.8725,   -11.3938,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0414], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7183]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0656,  -322.8725,   -11.3938,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[1.8349e-05, 5.0474e-05, 1.4500e-04, 1.5348e-03, 6.6068e-04, 2.2599e-03,\n",
      "         9.7571e-02, 4.2042e-03, 8.7228e-02, 2.4610e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0414], requires_grad=True)\n",
      "bias grad:  tensor([0.5388])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7183]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1469]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0666,  -322.8725,   -11.3947,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0360], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7330]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0666,  -322.8725,   -11.3947,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[4.6013e-03, 0.0000e+00, 7.2775e-05, 8.9266e-04, 7.5088e-04, 1.2295e-03,\n",
      "         5.7826e-02, 2.6193e-03, 5.8708e-02, 1.4511e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0360], requires_grad=True)\n",
      "bias grad:  tensor([0.3327])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7330]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0285]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0671,  -322.8725,   -11.3952,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0327], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7358]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0671,  -322.8725,   -11.3952,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5489e-03, 0.0000e+00, 4.3416e-05, 4.0269e-04, 2.6265e-04, 8.0812e-04,\n",
      "         3.6271e-02, 1.6949e-03, 3.0399e-02, 7.5953e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0327], requires_grad=True)\n",
      "bias grad:  tensor([0.1737])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7358]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2859]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0675,  -322.8726,   -11.3955,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0310], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7072]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0675,  -322.8726,   -11.3955,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0010, 0.0003, 0.0003, 0.0032, 0.0008, 0.0075, 0.2261, 0.0074, 0.1444,\n",
      "         0.0025]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0310], requires_grad=True)\n",
      "bias grad:  tensor([0.8881])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7072]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5162]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0698,  -322.8726,   -11.3970,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0221], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8589]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0698,  -322.8726,   -11.3970,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3191e-03,  0.0000e+00,  1.3248e-05,  7.7527e-06,  1.3177e-04,\n",
      "          4.5794e-04,  1.4875e-02,  8.2312e-04,  8.7112e-03,  1.9273e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0221], requires_grad=True)\n",
      "bias grad:  tensor([0.0501])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8589]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3548]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0699,  -322.8726,   -11.3971,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0216], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8234]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0699,  -322.8726,   -11.3971,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4866e-04, 5.1809e-05, 7.7464e-05, 9.9746e-04, 6.3955e-04, 9.2741e-04,\n",
      "         4.9267e-02, 2.5715e-03, 5.7472e-02, 1.6292e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0216], requires_grad=True)\n",
      "bias grad:  tensor([0.3470])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8234]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1199]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0704,  -322.8727,   -11.3977,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0181], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8354]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0704,  -322.8727,   -11.3977,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.8215e-04, -2.7411e-05,  3.9285e-05,  4.7801e-04,  2.7591e-04,\n",
      "          7.8818e-04,  2.9695e-02,  1.9524e-03,  3.6801e-02,  1.7172e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0181], requires_grad=True)\n",
      "bias grad:  tensor([0.2073])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8354]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6377]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0707,  -322.8727,   -11.3980,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0160], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7716]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0707,  -322.8727,   -11.3980,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0556e-03, 1.6288e-05, 8.4653e-05, 8.0006e-04, 4.1783e-04, 2.7154e-03,\n",
      "         7.5107e-02, 2.6035e-03, 5.4683e-02, 1.5673e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0160], requires_grad=True)\n",
      "bias grad:  tensor([0.3105])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7716]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1090]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0715,  -322.8727,   -11.3986,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0129], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7607]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0715,  -322.8727,   -11.3986,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.6700e-03, -2.8427e-05, -2.1593e-05, -4.8277e-04, -3.5973e-04,\n",
      "         -2.3147e-04, -1.3551e-02, -5.8674e-04, -1.7577e-02,  3.5252e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0129], requires_grad=True)\n",
      "bias grad:  tensor([-0.1002])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7607]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5857]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0713,  -322.8727,   -11.3984,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0139], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7021]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0713,  -322.8727,   -11.3984,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.4141e-03,  0.0000e+00,  2.1078e-05,  2.1986e-04,  1.4381e-04,\n",
      "          2.1316e-04,  1.6977e-02,  2.5648e-04,  9.7247e-03, -3.1589e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0139], requires_grad=True)\n",
      "bias grad:  tensor([0.0605])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7021]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3204]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0715,  -322.8727,   -11.3985,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0133], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7342]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0715,  -322.8727,   -11.3985,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[5.6222e-03, 2.8810e-05, 1.3196e-04, 1.6611e-03, 1.2735e-03, 1.6758e-03,\n",
      "         9.0421e-02, 4.7498e-03, 1.0283e-01, 3.2113e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0133], requires_grad=True)\n",
      "bias grad:  tensor([0.6055])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7342]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0191]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0724,  -322.8728,   -11.3995,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0073], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7361]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0724,  -322.8728,   -11.3995,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6281e-02,  0.0000e+00, -2.8244e-05, -7.6364e-04, -1.0132e-03,\n",
      "         -4.7092e-04, -2.1459e-02, -1.4864e-03, -3.7829e-02, -3.7758e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0073], requires_grad=True)\n",
      "bias grad:  tensor([-0.2118])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7361]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2801]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0722,  -322.8728,   -11.3991,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0094], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7081]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0722,  -322.8728,   -11.3991,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.3663e-03,  2.2357e-05,  6.1014e-05,  6.0624e-04,  2.2696e-04,\n",
      "          1.1939e-03,  4.3690e-02,  2.0436e-03,  3.9744e-02,  1.3669e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0094], requires_grad=True)\n",
      "bias grad:  tensor([0.2358])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7081]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0618]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0726,  -322.8728,   -11.3995,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0070], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7019]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0726,  -322.8728,   -11.3995,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1221e-04,  0.0000e+00, -8.9137e-05, -3.7870e-04,  1.2248e-04,\n",
      "         -5.0817e-03, -1.2168e-01, -2.3803e-03, -3.8792e-02,  9.4295e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0070], requires_grad=True)\n",
      "bias grad:  tensor([-0.2514])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7019]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1540]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0714,  -322.8728,   -11.3991,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0096], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5865]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0714,  -322.8728,   -11.3991,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.5097e-03,  2.5274e-05, -3.0874e-06,  5.3456e-04,  9.6359e-04,\n",
      "         -3.2123e-03, -5.5528e-02,  3.6453e-04,  2.3837e-02, -3.0094e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0096], requires_grad=True)\n",
      "bias grad:  tensor([0.1209])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5865]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0176]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0708,  -322.8728,   -11.3994,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0083], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5882]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0708,  -322.8728,   -11.3994,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.8295e-03, -5.8871e-05, -3.5617e-05, -3.3794e-04,  1.0788e-04,\n",
      "         -1.6127e-03, -4.6279e-02, -5.4775e-04, -1.2851e-02,  2.1223e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0083], requires_grad=True)\n",
      "bias grad:  tensor([-0.0933])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5882]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8018]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0704,  -322.8728,   -11.3993,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0093], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5081]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0704,  -322.8728,   -11.3993,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.3348e-04, -1.8475e-04, -4.2073e-05, -2.9511e-04,  1.1366e-04,\n",
      "         -3.6275e-03, -7.4076e-02, -1.4905e-03, -1.9130e-02,  4.5814e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0093], requires_grad=True)\n",
      "bias grad:  tensor([-0.1210])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5081]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7123]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0696,  -322.8728,   -11.3991,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0105], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4368]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0696,  -322.8728,   -11.3991,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0054, 0.0000, 0.0002, 0.0028, 0.0006, 0.0017, 0.1106, 0.0054, 0.1513,\n",
      "         0.0032]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0105], requires_grad=True)\n",
      "bias grad:  tensor([0.8674])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4368]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.1110]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0708,  -322.8728,   -11.4006,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0018], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7479]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0708,  -322.8728,   -11.4006,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.0910e-03,  3.5507e-05, -4.7123e-05, -8.0427e-04, -6.3811e-04,\n",
      "         -4.6273e-04, -3.5953e-02, -1.7702e-03, -4.0740e-02, -1.8418e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0018], requires_grad=True)\n",
      "bias grad:  tensor([-0.2319])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7479]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2752]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0704,  -322.8728,   -11.4002,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0041], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7204]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0704,  -322.8728,   -11.4002,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.4546e-04,  5.1661e-05,  1.0122e-04,  1.2291e-03,  6.3323e-04,\n",
      "          3.3244e-03,  9.8803e-02,  3.5541e-03,  6.5686e-02,  2.0049e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0041], requires_grad=True)\n",
      "bias grad:  tensor([0.4191])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7204]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2428]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0714,  -322.8728,   -11.4008,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-5.8074e-05], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7447]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0714,  -322.8728,   -11.4008,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2030e-03, 0.0000e+00, 7.0406e-05, 1.0023e-03, 7.7919e-04, 4.0510e-04,\n",
      "         4.5570e-02, 2.6429e-03, 6.1153e-02, 1.2115e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-5.8074e-05], requires_grad=True)\n",
      "bias grad:  tensor([0.3555])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7447]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0120]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0718,  -322.8729,   -11.4014,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0036], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7435]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0718,  -322.8729,   -11.4014,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[ 9.8778e-04,  0.0000e+00,  1.5935e-05,  6.2076e-05, -1.2322e-05,\n",
      "          3.9260e-04,  1.7269e-02,  5.5431e-04,  9.6367e-03,  5.5666e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0036], requires_grad=True)\n",
      "bias grad:  tensor([0.0548])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7435]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2319]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0720,  -322.8729,   -11.4015,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0042], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7203]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0720,  -322.8729,   -11.4015,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[7.7658e-04, 8.8170e-05, 5.0870e-05, 6.0328e-04, 5.5333e-05, 8.2135e-04,\n",
      "         3.7310e-02, 1.8475e-03, 3.8225e-02, 9.5054e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0042], requires_grad=True)\n",
      "bias grad:  tensor([0.2194])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7203]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2121]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0724,  -322.8729,   -11.4019,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0064], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7415]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0724,  -322.8729,   -11.4019,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3414e-03, -1.1340e-04, -4.9116e-05, -5.9704e-04,  5.6566e-05,\n",
      "         -1.8099e-03, -4.9975e-02, -1.3701e-03, -2.8142e-02,  1.6923e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0064], requires_grad=True)\n",
      "bias grad:  tensor([-0.1597])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7415]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7298]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0719,  -322.8729,   -11.4016,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0048], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6685]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0719,  -322.8729,   -11.4016,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.3640e-04,  0.0000e+00,  7.2339e-05,  8.2768e-04,  4.8307e-04,\n",
      "          8.6103e-04,  4.1737e-02,  2.6320e-03,  5.1839e-02,  1.3557e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0048], requires_grad=True)\n",
      "bias grad:  tensor([0.3060])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6685]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0261]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0723,  -322.8729,   -11.4022,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0078], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6659]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0723,  -322.8729,   -11.4022,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[5.9808e-04, 1.0058e-05, 1.9287e-05, 8.9320e-05, 1.3514e-04, 1.7157e-03,\n",
      "         3.8011e-02, 7.6864e-04, 6.6560e-03, 7.5571e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0078], requires_grad=True)\n",
      "bias grad:  tensor([0.0531])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6659]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2823]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0727,  -322.8729,   -11.4022,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0083], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6377]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0727,  -322.8729,   -11.4022,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[2.2578e-03, 3.3634e-05, 6.7159e-05, 7.6699e-04, 5.1322e-04, 2.4333e-03,\n",
      "         7.3990e-02, 2.4487e-03, 4.5741e-02, 1.3594e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0083], requires_grad=True)\n",
      "bias grad:  tensor([0.2702])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6377]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1453]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0734,  -322.8730,   -11.4027,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0111], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6522]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0734,  -322.8730,   -11.4027,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[2.9137e-04, 4.7962e-05, 1.5384e-04, 1.6547e-03, 7.4125e-04, 2.3570e-03,\n",
      "         1.0196e-01, 4.5559e-03, 9.3770e-02, 2.5828e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0111], requires_grad=True)\n",
      "bias grad:  tensor([0.5815])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6522]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2875]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0744,  -322.8730,   -11.4036,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0169], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6810]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0744,  -322.8730,   -11.4036,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[4.8481e-03, 0.0000e+00, 5.3311e-05, 6.9551e-04, 6.3481e-04, 1.1220e-03,\n",
      "         4.8004e-02, 1.8976e-03, 4.3847e-02, 8.5827e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0169], requires_grad=True)\n",
      "bias grad:  tensor([0.2486])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6810]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2004]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0749,  -322.8730,   -11.4041,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0194], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7010]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0749,  -322.8730,   -11.4041,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[2.2606e-04, 0.0000e+00, 3.2358e-05, 3.2045e-04, 1.4964e-04, 5.4428e-04,\n",
      "         2.6311e-02, 1.2518e-03, 2.3410e-02, 5.4190e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0194], requires_grad=True)\n",
      "bias grad:  tensor([0.1315])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7010]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1725]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0752,  -322.8730,   -11.4043,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0207], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6837]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0752,  -322.8730,   -11.4043,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0013, 0.0003, 0.0003, 0.0033, 0.0008, 0.0078, 0.2328, 0.0076, 0.1473,\n",
      "         0.0025]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0207], requires_grad=True)\n",
      "bias grad:  tensor([0.9071])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6837]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6964]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0775,  -322.8731,   -11.4058,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0297], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8534]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0775,  -322.8731,   -11.4058,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2968e-03,  0.0000e+00,  8.3848e-06, -6.8211e-05,  7.0618e-05,\n",
      "          4.2945e-04,  1.1890e-02,  6.1381e-04,  4.2539e-03,  1.1124e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0297], requires_grad=True)\n",
      "bias grad:  tensor([0.0224])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8534]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3593]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0776,  -322.8731,   -11.4058,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0300], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8175]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0776,  -322.8731,   -11.4058,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5955e-05, 4.9662e-05, 7.0099e-05, 8.9157e-04, 5.2801e-04, 8.5880e-04,\n",
      "         4.4128e-02, 2.2611e-03, 5.0848e-02, 1.4370e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0300], requires_grad=True)\n",
      "bias grad:  tensor([0.3070])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8175]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1411]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0781,  -322.8731,   -11.4063,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0330], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8316]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0781,  -322.8731,   -11.4063,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.1603e-04, -3.9300e-05,  5.0808e-05,  6.3241e-04,  4.4702e-04,\n",
      "          8.9686e-04,  3.6501e-02,  2.4405e-03,  4.7103e-02,  1.9865e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0330], requires_grad=True)\n",
      "bias grad:  tensor([0.2660])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8316]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7049]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0784,  -322.8731,   -11.4068,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0357], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7611]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0784,  -322.8731,   -11.4068,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7330e-03, 1.5428e-05, 7.4320e-05, 6.6967e-04, 2.9506e-04, 2.5330e-03,\n",
      "         6.6383e-02, 2.1918e-03, 4.6320e-02, 1.3680e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0357], requires_grad=True)\n",
      "bias grad:  tensor([0.2627])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7611]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0401]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0791,  -322.8732,   -11.4073,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0383], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7571]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0791,  -322.8732,   -11.4073,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.5187e-03, -3.7124e-05, -3.1897e-05, -6.0885e-04, -3.8542e-04,\n",
      "         -2.6143e-04, -2.1560e-02, -8.3927e-04, -2.3547e-02,  2.3144e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0383], requires_grad=True)\n",
      "bias grad:  tensor([-0.1387])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7571]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7202]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0789,  -322.8732,   -11.4070,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0369], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6851]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0789,  -322.8732,   -11.4070,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.9183e-03,  0.0000e+00,  1.3811e-05,  1.3518e-04,  1.8853e-04,\n",
      "          1.3903e-04,  1.4616e-02,  4.2183e-05,  5.4366e-03, -4.3753e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0369], requires_grad=True)\n",
      "bias grad:  tensor([0.0389])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6851]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2524]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0790,  -322.8732,   -11.4071,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0373], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7103]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0790,  -322.8732,   -11.4071,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[4.3572e-03, 2.7400e-05, 9.6791e-05, 1.1779e-03, 8.6297e-04, 1.3959e-03,\n",
      "         6.8309e-02, 3.4209e-03, 7.3329e-02, 2.5536e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0373], requires_grad=True)\n",
      "bias grad:  tensor([0.4350])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7103]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0503]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0797,  -322.8732,   -11.4078,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0417], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7153]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0797,  -322.8732,   -11.4078,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5025e-02,  0.0000e+00, -1.5508e-05, -5.7526e-04, -8.0262e-04,\n",
      "         -3.3210e-04, -1.5212e-02, -9.5770e-04, -2.6923e-02, -2.3202e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0417], requires_grad=True)\n",
      "bias grad:  tensor([-0.1493])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7153]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2766]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0796,  -322.8732,   -11.4075,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0402], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6877]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0796,  -322.8732,   -11.4075,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.0412e-03,  2.0840e-05,  4.5116e-05,  3.8720e-04,  2.3874e-05,\n",
      "          1.2550e-03,  3.6602e-02,  1.4350e-03,  2.6202e-02,  1.0255e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0402], requires_grad=True)\n",
      "bias grad:  tensor([0.1568])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6877]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0332]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0799,  -322.8732,   -11.4078,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0417], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6843]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0799,  -322.8732,   -11.4078,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6229e-04,  0.0000e+00, -9.9530e-05, -5.3252e-04,  1.8575e-05,\n",
      "         -5.2205e-03, -1.2904e-01, -2.8365e-03, -4.7958e-02, -1.1291e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0417], requires_grad=True)\n",
      "bias grad:  tensor([-0.3043])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6843]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1889]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0786,  -322.8732,   -11.4073,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0387], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5654]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0786,  -322.8732,   -11.4073,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.7017e-03,  1.1717e-05, -7.1905e-06,  4.2422e-04,  8.0674e-04,\n",
      "         -3.1306e-03, -5.5567e-02,  2.0406e-04,  1.8428e-02, -2.9145e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0387], requires_grad=True)\n",
      "bias grad:  tensor([0.0880])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5654]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0867]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0781,  -322.8732,   -11.4075,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0396], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5568]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0781,  -322.8732,   -11.4075,  -302.5938]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight grad:  tensor([[ 4.3417e-03, -5.1411e-05, -3.0005e-05, -2.5540e-04,  1.5445e-04,\n",
      "         -1.6199e-03, -4.2139e-02, -4.7122e-04, -9.3366e-03,  2.8664e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0396], requires_grad=True)\n",
      "bias grad:  tensor([-0.0716])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5568]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6224]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0777,  -322.8732,   -11.4074,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0389], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4945]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0777,  -322.8732,   -11.4074,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.0460e-04, -1.8515e-04, -1.0056e-04, -8.4623e-04, -7.8609e-05,\n",
      "         -4.1889e-03, -1.1020e-01, -3.2133e-03, -5.3747e-02, -1.4471e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0389], requires_grad=True)\n",
      "bias grad:  tensor([-0.3301])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4945]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6731]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0766,  -322.8731,   -11.4069,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0356], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4272]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0766,  -322.8731,   -11.4069,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0054, 0.0000, 0.0002, 0.0028, 0.0006, 0.0015, 0.1042, 0.0051, 0.1457,\n",
      "         0.0029]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0356], requires_grad=True)\n",
      "bias grad:  tensor([0.8360])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4272]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.1090]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0776,  -322.8732,   -11.4083,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0439], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7381]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0776,  -322.8732,   -11.4083,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.6819e-03,  2.8421e-05, -5.8248e-05, -9.1152e-04, -6.6691e-04,\n",
      "         -7.7038e-04, -4.5402e-02, -2.1405e-03, -4.7190e-02, -4.3504e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0439], requires_grad=True)\n",
      "bias grad:  tensor([-0.2737])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7381]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2337]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0771,  -322.8732,   -11.4079,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0412], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7148]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0771,  -322.8732,   -11.4079,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0305e-04,  3.8032e-05,  7.5244e-05,  9.2416e-04,  4.6665e-04,\n",
      "          2.7306e-03,  7.7906e-02,  2.6850e-03,  4.9005e-02,  1.4352e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0412], requires_grad=True)\n",
      "bias grad:  tensor([0.3137])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7148]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2419]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0779,  -322.8732,   -11.4083,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0443], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7389]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0779,  -322.8732,   -11.4083,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0034, 0.0000, 0.0001, 0.0014, 0.0008, 0.0006, 0.0935, 0.0039, 0.0853,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0443], requires_grad=True)\n",
      "bias grad:  tensor([0.4906])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7389]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1324]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0789,  -322.8732,   -11.4092,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0492], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7257]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0789,  -322.8732,   -11.4092,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.7506e-05,  0.0000e+00,  1.1968e-05, -2.4948e-05, -8.8958e-05,\n",
      "          3.5156e-04,  1.4788e-02,  3.7486e-04,  5.2574e-03,  5.5059e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0492], requires_grad=True)\n",
      "bias grad:  tensor([0.0298])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7257]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3079]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0790,  -322.8732,   -11.4092,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0495], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6949]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0790,  -322.8732,   -11.4092,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.1573e-05,  6.3898e-05,  3.9483e-05,  4.1273e-04, -1.0915e-04,\n",
      "          1.0208e-03,  3.6470e-02,  1.3601e-03,  2.7561e-02,  7.6134e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0495], requires_grad=True)\n",
      "bias grad:  tensor([0.1586])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6949]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1864]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0794,  -322.8732,   -11.4095,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0511], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7136]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0794,  -322.8732,   -11.4095,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 9.1217e-04, -9.4688e-05, -6.6425e-05, -7.5504e-04,  3.2364e-07,\n",
      "         -2.2853e-03, -6.2391e-02, -1.8897e-03, -3.9681e-02, -3.8086e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0511], requires_grad=True)\n",
      "bias grad:  tensor([-0.2259])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7136]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6323]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0787,  -322.8732,   -11.4091,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0489], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6503]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0787,  -322.8732,   -11.4091,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[7.1002e-04, 0.0000e+00, 8.2231e-05, 9.7811e-04, 5.9953e-04, 1.1214e-03,\n",
      "         5.2507e-02, 3.0345e-03, 6.0173e-02, 1.4281e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0489], requires_grad=True)\n",
      "bias grad:  tensor([0.3559])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6503]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0259]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0793,  -322.8732,   -11.4097,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0524], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6529]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0793,  -322.8732,   -11.4097,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[2.1438e-04, 3.2140e-05, 2.5548e-05, 1.7300e-04, 1.8407e-04, 1.7565e-03,\n",
      "         4.0420e-02, 1.0520e-03, 1.3058e-02, 1.2503e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0524], requires_grad=True)\n",
      "bias grad:  tensor([0.0888])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6529]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3256]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0797,  -322.8732,   -11.4099,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0533], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6204]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0797,  -322.8732,   -11.4099,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5200e-03, 4.4020e-05, 8.4794e-05, 9.7658e-04, 6.3092e-04, 2.9223e-03,\n",
      "         8.9142e-02, 2.9682e-03, 5.6988e-02, 1.7371e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0533], requires_grad=True)\n",
      "bias grad:  tensor([0.3380])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6204]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2071]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0806,  -322.8733,   -11.4104,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0567], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6411]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0806,  -322.8733,   -11.4104,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7279e-04, 3.6145e-05, 1.2209e-04, 1.3058e-03, 5.6734e-04, 1.7599e-03,\n",
      "         7.9308e-02, 3.4887e-03, 7.4029e-02, 1.9078e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0567], requires_grad=True)\n",
      "bias grad:  tensor([0.4520])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6411]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3078]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0814,  -322.8733,   -11.4112,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0612], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6718]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0814,  -322.8733,   -11.4112,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7885e-03, 0.0000e+00, 5.5710e-05, 6.9292e-04, 5.8833e-04, 9.1145e-04,\n",
      "         4.3042e-02, 1.9488e-03, 4.4329e-02, 1.0578e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0612], requires_grad=True)\n",
      "bias grad:  tensor([0.2519])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6718]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1979]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0818,  -322.8733,   -11.4116,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0637], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6916]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0818,  -322.8733,   -11.4116,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5231e-03, 0.0000e+00, 4.2557e-05, 4.5403e-04, 2.9864e-04, 5.8811e-04,\n",
      "         3.3412e-02, 1.7612e-03, 3.1713e-02, 6.4764e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0637], requires_grad=True)\n",
      "bias grad:  tensor([0.1815])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6916]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2174]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0821,  -322.8734,   -11.4119,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0655], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6699]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0821,  -322.8734,   -11.4119,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0007, 0.0003, 0.0003, 0.0031, 0.0007, 0.0076, 0.2237, 0.0071, 0.1363,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0655], requires_grad=True)\n",
      "bias grad:  tensor([0.8435])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6699]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6369]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0844,  -322.8734,   -11.4133,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0740], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8336]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0844,  -322.8734,   -11.4133,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9200e-03,  0.0000e+00, -5.7616e-07, -1.8510e-04, -4.3740e-05,\n",
      "          3.1051e-04,  5.0345e-03,  2.8601e-04, -2.9444e-03,  9.2734e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0740], requires_grad=True)\n",
      "bias grad:  tensor([-0.0179])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8336]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3201]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0844,  -322.8734,   -11.4133,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0738], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8016]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0844,  -322.8734,   -11.4133,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[2.5187e-04, 4.2050e-05, 8.1680e-05, 1.0474e-03, 6.8084e-04, 9.6837e-04,\n",
      "         5.3731e-02, 2.7733e-03, 6.1105e-02, 1.7854e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0738], requires_grad=True)\n",
      "bias grad:  tensor([0.3674])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8016]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1508]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0850,  -322.8734,   -11.4139,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0775], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8167]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0850,  -322.8734,   -11.4139,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.3494e-04, -3.7867e-05,  2.5632e-05,  3.1919e-04,  2.3969e-04,\n",
      "          5.3783e-04,  1.9321e-02,  1.4762e-03,  2.6957e-02,  1.4670e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0775], requires_grad=True)\n",
      "bias grad:  tensor([0.1512])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8167]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6295]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0851,  -322.8734,   -11.4141,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0790], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7537]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0851,  -322.8734,   -11.4141,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0650e-04,  1.1940e-05,  6.1452e-05,  4.9928e-04,  1.4044e-04,\n",
      "          2.2720e-03,  5.7561e-02,  1.7528e-03,  3.6274e-02,  1.2042e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0790], requires_grad=True)\n",
      "bias grad:  tensor([0.2053])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7537]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0880]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0857,  -322.8735,   -11.4145,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0810], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7449]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0857,  -322.8735,   -11.4145,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.1580e-03, -3.6331e-05, -3.7299e-05, -6.9302e-04, -4.2597e-04,\n",
      "         -3.2526e-04, -2.4853e-02, -1.0339e-03, -2.8180e-02,  1.2919e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0810], requires_grad=True)\n",
      "bias grad:  tensor([-0.1646])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7449]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7396]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0855,  -322.8735,   -11.4142,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0794], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6709]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0855,  -322.8735,   -11.4142,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.4761e-03,  0.0000e+00,  6.6263e-06,  1.6378e-05,  8.4016e-05,\n",
      "          1.2709e-04,  9.9539e-03, -2.8048e-04, -1.5782e-03, -2.1523e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0794], requires_grad=True)\n",
      "bias grad:  tensor([-0.0021])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6709]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2764]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0856,  -322.8735,   -11.4142,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0794], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6986]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0856,  -322.8735,   -11.4142,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[4.8025e-03, 3.2265e-05, 1.0323e-04, 1.3063e-03, 1.0054e-03, 1.3820e-03,\n",
      "         7.2714e-02, 3.7315e-03, 8.0472e-02, 2.6678e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0794], requires_grad=True)\n",
      "bias grad:  tensor([0.4763])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6986]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0732]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0863,  -322.8735,   -11.4150,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0841], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7059]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0863,  -322.8735,   -11.4150,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7132e-02,  0.0000e+00, -3.9143e-05, -9.1912e-04, -1.1843e-03,\n",
      "         -5.8702e-04, -2.6679e-02, -1.9337e-03, -4.6937e-02, -5.0124e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0841], requires_grad=True)\n",
      "bias grad:  tensor([-0.2640])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7059]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2708]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0860,  -322.8735,   -11.4145,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0815], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6788]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0860,  -322.8735,   -11.4145,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8648e-03,  1.0716e-05,  4.2307e-05,  3.6823e-04,  4.8129e-05,\n",
      "          1.2696e-03,  3.6324e-02,  1.4084e-03,  2.4747e-02,  8.8264e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0815], requires_grad=True)\n",
      "bias grad:  tensor([0.1489])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6788]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0059]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0864,  -322.8735,   -11.4148,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0830], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6782]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0864,  -322.8735,   -11.4148,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.0676e-04,  0.0000e+00, -9.5624e-05, -4.8291e-04,  5.6643e-05,\n",
      "         -5.0655e-03, -1.2412e-01, -2.7120e-03, -4.5195e-02, -9.6672e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0830], requires_grad=True)\n",
      "bias grad:  tensor([-0.2887])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6782]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1673]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0852,  -322.8734,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0801], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5615]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0852,  -322.8734,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.4125e-03,  3.1142e-05, -2.9704e-06,  5.2791e-04,  9.2514e-04,\n",
      "         -3.0454e-03, -5.3149e-02,  3.1443e-04,  2.2726e-02, -3.2641e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0801], requires_grad=True)\n",
      "bias grad:  tensor([0.1145])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5615]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1052]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0846,  -322.8734,   -11.4146,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0812], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5720]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0846,  -322.8734,   -11.4146,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.1042e-03, -6.9443e-05, -4.1801e-05, -4.2721e-04,  1.0892e-05,\n",
      "         -1.9606e-03, -5.5233e-02, -8.6522e-04, -1.7859e-02,  1.0242e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0812], requires_grad=True)\n",
      "bias grad:  tensor([-0.1243])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5720]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7524]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0841,  -322.8734,   -11.4144,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0800], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4968]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0841,  -322.8734,   -11.4144,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.0951e-04, -1.8913e-04, -4.9532e-05, -3.4441e-04,  1.6226e-04,\n",
      "         -3.6962e-03, -7.9190e-02, -1.6275e-03, -2.2064e-02, -6.0292e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0800], requires_grad=True)\n",
      "bias grad:  tensor([-0.1394])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4968]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7432]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0833,  -322.8734,   -11.4142,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0786], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4225]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0833,  -322.8734,   -11.4142,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0054, 0.0000, 0.0002, 0.0023, 0.0004, 0.0012, 0.0782, 0.0038, 0.1147,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0786], requires_grad=True)\n",
      "bias grad:  tensor([0.6592])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4225]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.0897]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0841,  -322.8734,   -11.4153,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0852], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7314]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0841,  -322.8734,   -11.4153,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.0263e-03,  2.9884e-05, -6.3339e-05, -1.0019e-03, -7.2791e-04,\n",
      "         -8.2227e-04, -4.9468e-02, -2.3099e-03, -5.1316e-02, -4.4403e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0852], requires_grad=True)\n",
      "bias grad:  tensor([-0.2982])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7314]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3003]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0836,  -322.8734,   -11.4148,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0822], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7014]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0836,  -322.8734,   -11.4148,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.8686e-04,  3.7281e-05,  7.9230e-05,  9.4997e-04,  5.1193e-04,\n",
      "          2.8673e-03,  8.1710e-02,  2.8181e-03,  5.0766e-02,  1.5941e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0822], requires_grad=True)\n",
      "bias grad:  tensor([0.3274])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7014]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2155]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0844,  -322.8734,   -11.4153,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0855], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7230]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0844,  -322.8734,   -11.4153,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0042, 0.0000, 0.0001, 0.0014, 0.0009, 0.0006, 0.0938, 0.0038, 0.0844,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0855], requires_grad=True)\n",
      "bias grad:  tensor([0.4876])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7230]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1120]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0853,  -322.8735,   -11.4162,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0904], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7118]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0853,  -322.8735,   -11.4162,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.4123e-04,  0.0000e+00,  4.9975e-06, -9.0919e-05, -1.2779e-04,\n",
      "          3.1991e-04,  1.0782e-02,  9.5469e-05,  3.4420e-04,  4.6087e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0904], requires_grad=True)\n",
      "bias grad:  tensor([0.0021])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7118]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2624]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0854,  -322.8735,   -11.4162,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0904], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6855]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0854,  -322.8735,   -11.4162,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5101e-04,  5.7065e-05,  2.4106e-05,  1.9588e-04, -2.6179e-04,\n",
      "          6.1047e-04,  2.2351e-02,  7.4605e-04,  1.5294e-02,  4.9063e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0904], requires_grad=True)\n",
      "bias grad:  tensor([0.0872])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6855]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1580]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8735,   -11.4163,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0913], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7013]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8735,   -11.4163,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.5241e-03, -7.9375e-05, -4.0665e-05, -4.7335e-04,  1.3197e-04,\n",
      "         -1.5355e-03, -4.0534e-02, -1.0242e-03, -2.1798e-02,  1.2565e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0913], requires_grad=True)\n",
      "bias grad:  tensor([-0.1228])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7013]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6006]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0852,  -322.8735,   -11.4161,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0900], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6413]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0852,  -322.8735,   -11.4161,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3135e-03,  0.0000e+00,  5.2435e-05,  6.2015e-04,  2.7736e-04,\n",
      "          3.6242e-04,  2.2584e-02,  1.9841e-03,  3.9392e-02,  1.0343e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0900], requires_grad=True)\n",
      "bias grad:  tensor([0.2251])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6413]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0859]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0855,  -322.8735,   -11.4165,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0923], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6498]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0855,  -322.8735,   -11.4165,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 9.5140e-04, -3.1790e-06,  1.0353e-05, -2.0279e-05,  1.3634e-04,\n",
      "          1.7388e-03,  3.6624e-02,  5.6980e-04,  7.7331e-04,  5.8878e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0923], requires_grad=True)\n",
      "bias grad:  tensor([0.0203])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6498]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3096]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0858,  -322.8735,   -11.4165,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0925], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6189]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0858,  -322.8735,   -11.4165,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7077e-03, 3.2844e-05, 5.0339e-05, 5.3289e-04, 3.0877e-04, 2.2505e-03,\n",
      "         6.2372e-02, 1.7146e-03, 3.0931e-02, 1.0311e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0925], requires_grad=True)\n",
      "bias grad:  tensor([0.1849])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6189]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1395]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8735,   -11.4168,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0943], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6328]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8735,   -11.4168,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7997e-04, 3.2864e-05, 1.2868e-04, 1.3692e-03, 6.4267e-04, 1.8997e-03,\n",
      "         8.4730e-02, 3.9069e-03, 7.7403e-02, 2.1956e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0943], requires_grad=True)\n",
      "bias grad:  tensor([0.4885])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6328]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1170]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0873,  -322.8736,   -11.4176,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0992], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6446]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0873,  -322.8736,   -11.4176,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0059, 0.0000, 0.0001, 0.0013, 0.0011, 0.0016, 0.0775, 0.0036, 0.0826,\n",
      "         0.0024]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0992], requires_grad=True)\n",
      "bias grad:  tensor([0.4719])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6446]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2096]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0881,  -322.8736,   -11.4184,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1039], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6655]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0881,  -322.8736,   -11.4184,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[4.5123e-03, 0.0000e+00, 6.2606e-05, 7.3812e-04, 7.6539e-04, 7.1789e-04,\n",
      "         4.6220e-02, 2.5830e-03, 4.9554e-02, 1.2194e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1039], requires_grad=True)\n",
      "bias grad:  tensor([0.2859])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6655]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2275]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0885,  -322.8736,   -11.4189,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1068], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6428]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0885,  -322.8736,   -11.4189,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0005, 0.0003, 0.0003, 0.0031, 0.0008, 0.0077, 0.2279, 0.0073, 0.1390,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1068], requires_grad=True)\n",
      "bias grad:  tensor([0.8594])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6428]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6788]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0908,  -322.8737,   -11.4203,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1154], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8106]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0908,  -322.8737,   -11.4203,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1972e-03,  0.0000e+00, -3.1614e-06, -2.4393e-04, -1.1525e-04,\n",
      "          3.7733e-04,  3.8919e-03,  1.1148e-04, -6.1410e-03, -3.5315e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1154], requires_grad=True)\n",
      "bias grad:  tensor([-0.0374])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8106]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2971]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0909,  -322.8737,   -11.4202,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1150], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7809]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0909,  -322.8737,   -11.4202,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[2.1656e-04, 3.3749e-05, 6.0115e-05, 7.5915e-04, 4.2913e-04, 7.5478e-04,\n",
      "         3.8765e-02, 1.9158e-03, 4.2223e-02, 1.1256e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1150], requires_grad=True)\n",
      "bias grad:  tensor([0.2592])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7809]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1779]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0913,  -322.8737,   -11.4207,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1176], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7987]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0913,  -322.8737,   -11.4207,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2361e-03, -4.4066e-05,  2.2891e-05,  2.4457e-04,  1.0451e-04,\n",
      "          5.9973e-04,  2.0117e-02,  1.3878e-03,  2.3605e-02,  1.4749e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1176], requires_grad=True)\n",
      "bias grad:  tensor([0.1311])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7987]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7031]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0915,  -322.8737,   -11.4209,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1189], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7284]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0915,  -322.8737,   -11.4209,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8173e-04, 1.1632e-05, 5.9582e-05, 4.4815e-04, 1.2021e-04, 2.3584e-03,\n",
      "         5.7795e-02, 1.6759e-03, 3.3877e-02, 1.1753e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1189], requires_grad=True)\n",
      "bias grad:  tensor([0.1913])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7284]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1040]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0920,  -322.8737,   -11.4212,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1208], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7180]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0920,  -322.8737,   -11.4212,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.1612e-03, -3.5098e-05, -2.7774e-05, -5.5638e-04, -3.5896e-04,\n",
      "         -2.6520e-04, -1.6637e-02, -7.5212e-04, -2.1618e-02,  3.1335e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1208], requires_grad=True)\n",
      "bias grad:  tensor([-0.1249])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7180]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6445]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0919,  -322.8737,   -11.4210,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1196], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6536]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0919,  -322.8737,   -11.4210,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.5098e-04,  0.0000e+00, -6.5557e-06, -1.6430e-04, -5.0440e-05,\n",
      "          3.4264e-05,  9.5718e-04, -7.1911e-04, -1.2521e-02, -4.8113e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1196], requires_grad=True)\n",
      "bias grad:  tensor([-0.0664])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6536]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2370]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0919,  -322.8737,   -11.4209,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1189], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6773]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0919,  -322.8737,   -11.4209,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6550e-03, 2.6036e-05, 9.1799e-05, 1.1195e-03, 8.2192e-04, 1.1998e-03,\n",
      "         6.2749e-02, 3.2624e-03, 6.9782e-02, 2.4858e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1189], requires_grad=True)\n",
      "bias grad:  tensor([0.4144])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6773]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0485]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0925,  -322.8738,   -11.4216,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1231], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6821]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0925,  -322.8738,   -11.4216,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8137e-02,  0.0000e+00, -4.4574e-05, -1.0115e-03, -1.2931e-03,\n",
      "         -6.5188e-04, -2.9607e-02, -2.1701e-03, -5.2062e-02, -5.6521e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1231], requires_grad=True)\n",
      "bias grad:  tensor([-0.2931])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6821]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2349]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0922,  -322.8737,   -11.4211,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1201], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6586]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0922,  -322.8737,   -11.4211,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.2683e-03,  1.5383e-05,  2.3662e-05,  4.7385e-05, -2.6136e-04,\n",
      "          1.1878e-03,  2.3672e-02,  6.7896e-04,  6.9167e-03,  6.6737e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1201], requires_grad=True)\n",
      "bias grad:  tensor([0.0463])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6586]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1119]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0924,  -322.8737,   -11.4211,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1206], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6474]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0924,  -322.8737,   -11.4211,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6116e-04,  0.0000e+00, -1.1985e-04, -7.6349e-04, -1.5553e-04,\n",
      "         -5.5021e-03, -1.4279e-01, -3.5167e-03, -6.3569e-02, -4.6981e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1206], requires_grad=True)\n",
      "bias grad:  tensor([-0.3948])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6474]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.0904]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0910,  -322.8737,   -11.4205,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1166], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5384]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0910,  -322.8737,   -11.4205,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.7034e-03,  2.8440e-05, -1.7182e-05,  3.3941e-04,  7.5893e-04,\n",
      "         -3.3246e-03, -6.3536e-02, -1.8256e-04,  1.1558e-02, -5.0203e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1166], requires_grad=True)\n",
      "bias grad:  tensor([0.0508])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5384]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0399]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0904,  -322.8737,   -11.4206,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1172], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5424]], requires_grad=True)\n",
      "Iteration 3 | Score: 1.2981785535812378\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0649,  -322.8724,   -11.3933,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.1178e-03, -9.9652e-05, -1.1075e-04, -1.3333e-03, -1.3758e-04,\n",
      "         -3.1198e-03, -1.0170e-01, -2.8920e-03, -6.3490e-02, -9.1517e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0446], requires_grad=True)\n",
      "bias grad:  tensor([-0.3947])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8594]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.8723]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0638,  -322.8724,   -11.3926,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0485], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6722]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0638,  -322.8724,   -11.3926,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2954e-04, -1.8740e-04, -9.4973e-05, -8.6911e-04, -1.5521e-04,\n",
      "         -4.2179e-03, -1.0861e-01, -3.1717e-03, -5.5560e-02, -1.2585e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0485], requires_grad=True)\n",
      "bias grad:  tensor([-0.3284])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6722]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8568]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0628,  -322.8724,   -11.3921,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0518], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5865]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0628,  -322.8724,   -11.3921,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0019, 0.0000, 0.0001, 0.0013, 0.0001, 0.0006, 0.0553, 0.0027, 0.0773,\n",
      "         0.0019]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0518], requires_grad=True)\n",
      "bias grad:  tensor([0.4429])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5865]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.8342]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0633,  -322.8724,   -11.3929,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0474], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6699]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0633,  -322.8724,   -11.3929,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2701e-03,  3.0324e-05, -2.6539e-05, -4.3863e-04, -3.5490e-04,\n",
      "         -4.1501e-04, -2.6021e-02, -9.1806e-04, -2.0565e-02, -6.1144e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0474], requires_grad=True)\n",
      "bias grad:  tensor([-0.1196])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6699]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0187]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0630,  -322.8724,   -11.3926,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0486], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6681]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0630,  -322.8724,   -11.3926,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[6.6572e-04, 4.5184e-05, 9.1241e-05, 1.1352e-03, 5.7243e-04, 3.1773e-03,\n",
      "         9.1539e-02, 3.2887e-03, 5.8944e-02, 1.7793e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0486], requires_grad=True)\n",
      "bias grad:  tensor([0.3832])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6681]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3466]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0640,  -322.8724,   -11.3932,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0448], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7027]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0640,  -322.8724,   -11.3932,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[3.8007e-03, 0.0000e+00, 6.2426e-05, 8.8831e-04, 6.6414e-04, 3.1813e-04,\n",
      "         3.9500e-02, 2.3164e-03, 5.3913e-02, 1.0527e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0448], requires_grad=True)\n",
      "bias grad:  tensor([0.3145])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7027]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0336]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0644,  -322.8725,   -11.3938,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0416], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7061]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0644,  -322.8725,   -11.3938,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[5.4917e-04, 0.0000e+00, 3.5752e-05, 3.4062e-04, 1.9180e-04, 5.3600e-04,\n",
      "         2.7934e-02, 1.3068e-03, 2.5654e-02, 8.2242e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0416], requires_grad=True)\n",
      "bias grad:  tensor([0.1461])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7061]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2577]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0646,  -322.8725,   -11.3940,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0402], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6803]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0646,  -322.8725,   -11.3940,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[7.6046e-04, 8.7973e-05, 5.3252e-05, 6.2266e-04, 5.1717e-05, 9.0850e-04,\n",
      "         4.0025e-02, 1.9171e-03, 3.9832e-02, 1.0312e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0402], requires_grad=True)\n",
      "bias grad:  tensor([0.2292])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6803]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1945]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0650,  -322.8725,   -11.3944,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0379], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6998]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0650,  -322.8725,   -11.3944,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.7054e-03, -5.4187e-05, -1.3122e-05, -1.0756e-04,  2.3034e-04,\n",
      "         -1.2451e-03, -2.4422e-02, -2.5914e-04, -3.2205e-03,  1.4866e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0379], requires_grad=True)\n",
      "bias grad:  tensor([-0.0165])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6998]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2432]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0648,  -322.8725,   -11.3944,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0380], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6754]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0648,  -322.8725,   -11.3944,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[9.7253e-04, 0.0000e+00, 8.5938e-05, 1.0246e-03, 6.1479e-04, 1.0427e-03,\n",
      "         5.1840e-02, 3.1718e-03, 6.3067e-02, 1.5533e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0380], requires_grad=True)\n",
      "bias grad:  tensor([0.3714])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6754]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0584]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0653,  -322.8725,   -11.3950,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0343], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6813]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0653,  -322.8725,   -11.3950,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2325e-04, 2.3383e-05, 2.2010e-05, 1.3519e-04, 1.7607e-04, 1.7071e-03,\n",
      "         3.8374e-02, 9.4737e-04, 1.0910e-02, 1.0824e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0343], requires_grad=True)\n",
      "bias grad:  tensor([0.0723])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6813]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3641]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0657,  -322.8725,   -11.3951,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0336], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6449]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0657,  -322.8725,   -11.3951,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[2.2700e-03, 4.1967e-05, 7.3480e-05, 8.3473e-04, 4.7109e-04, 2.7143e-03,\n",
      "         7.9395e-02, 2.4049e-03, 4.8125e-02, 1.2544e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0336], requires_grad=True)\n",
      "bias grad:  tensor([0.2810])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6449]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3231]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0665,  -322.8726,   -11.3956,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0308], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6772]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0665,  -322.8726,   -11.3956,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0223e-04, 4.5352e-05, 1.5044e-04, 1.5715e-03, 6.6389e-04, 2.1234e-03,\n",
      "         9.7021e-02, 4.1801e-03, 8.8050e-02, 2.3997e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0308], requires_grad=True)\n",
      "bias grad:  tensor([0.5493])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6772]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2226]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0675,  -322.8726,   -11.3965,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0253], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6995]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0675,  -322.8726,   -11.3965,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[5.3944e-03, 0.0000e+00, 8.3266e-05, 1.0566e-03, 8.2284e-04, 1.3188e-03,\n",
      "         6.3549e-02, 2.8180e-03, 6.5514e-02, 1.6441e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0253], requires_grad=True)\n",
      "bias grad:  tensor([0.3738])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6995]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2414]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0681,  -322.8726,   -11.3972,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0216], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7236]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0681,  -322.8726,   -11.3972,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[2.6688e-03, 0.0000e+00, 5.3479e-05, 5.7059e-04, 4.9194e-04, 8.8440e-04,\n",
      "         4.4483e-02, 2.2212e-03, 4.0573e-02, 7.5446e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0216], requires_grad=True)\n",
      "bias grad:  tensor([0.2316])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7236]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2970]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0685,  -322.8727,   -11.3976,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0192], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6939]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0685,  -322.8727,   -11.3976,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0011, 0.0003, 0.0003, 0.0033, 0.0009, 0.0077, 0.2371, 0.0079, 0.1541,\n",
      "         0.0028]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0192], requires_grad=True)\n",
      "bias grad:  tensor([0.9434])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6939]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.4578]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0709,  -322.8727,   -11.3991,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0098], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8397]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0709,  -322.8727,   -11.3991,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2400e-03,  0.0000e+00,  3.0638e-05,  2.5901e-04,  2.1181e-04,\n",
      "          5.3142e-04,  2.4345e-02,  1.4325e-03,  2.1839e-02,  3.9696e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0098], requires_grad=True)\n",
      "bias grad:  tensor([0.1270])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8397]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2351]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0712,  -322.8727,   -11.3993,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0085], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8162]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0712,  -322.8727,   -11.3993,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[1.2201e-03, 5.2291e-05, 9.4716e-05, 1.2171e-03, 7.0808e-04, 1.0959e-03,\n",
      "         5.9055e-02, 3.0247e-03, 6.8959e-02, 1.7802e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0085], requires_grad=True)\n",
      "bias grad:  tensor([0.4149])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8162]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2392]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0717,  -322.8728,   -11.4000,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0044], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8401]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0717,  -322.8728,   -11.4000,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.7493e-04, -4.1667e-05,  4.3433e-05,  5.0897e-04,  3.2164e-04,\n",
      "          8.7795e-04,  3.2625e-02,  2.2001e-03,  4.0248e-02,  1.8643e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0044], requires_grad=True)\n",
      "bias grad:  tensor([0.2266])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8401]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7631]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0721,  -322.8728,   -11.4004,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0021], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7638]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0721,  -322.8728,   -11.4004,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[8.8256e-04, 1.4111e-05, 8.5403e-05, 8.1048e-04, 3.0555e-04, 2.7676e-03,\n",
      "         7.4213e-02, 2.5790e-03, 5.3923e-02, 1.5082e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0021], requires_grad=True)\n",
      "bias grad:  tensor([0.3067])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7638]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0104]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0728,  -322.8728,   -11.4010,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0009], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7648]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0728,  -322.8728,   -11.4010,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.6136e-03, -2.3872e-05, -3.6593e-05, -6.4925e-04, -4.3699e-04,\n",
      "         -3.4055e-04, -2.5511e-02, -9.9867e-04, -2.7229e-02,  8.0992e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0009], requires_grad=True)\n",
      "bias grad:  tensor([-0.1598])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7648]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6004]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0726,  -322.8728,   -11.4007,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0007], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7048]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0726,  -322.8728,   -11.4007,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1000e-03,  0.0000e+00,  1.6355e-05,  1.6815e-04,  1.7812e-04,\n",
      "          1.9349e-04,  1.5668e-02,  8.5366e-05,  6.8448e-03, -1.5323e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0007], requires_grad=True)\n",
      "bias grad:  tensor([0.0474])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7048]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3010]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0727,  -322.8728,   -11.4007,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0002], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7349]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0727,  -322.8728,   -11.4007,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[4.8000e-03, 2.5381e-05, 1.1531e-04, 1.4497e-03, 1.1401e-03, 1.6201e-03,\n",
      "         8.3926e-02, 4.2399e-03, 8.9956e-02, 2.9913e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0002], requires_grad=True)\n",
      "bias grad:  tensor([0.5326])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7349]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0247]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0736,  -322.8729,   -11.4016,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0051], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7324]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0736,  -322.8729,   -11.4016,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1746e-02,  0.0000e+00, -1.9023e-05, -5.3433e-04, -7.1397e-04,\n",
      "         -3.2660e-04, -1.4893e-02, -1.0193e-03, -2.6268e-02, -2.5747e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0051], requires_grad=True)\n",
      "bias grad:  tensor([-0.1469])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7324]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1039]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0734,  -322.8729,   -11.4014,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0037], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7220]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0734,  -322.8729,   -11.4014,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.2150e-03,  2.1392e-05,  4.9562e-05,  4.0983e-04,  4.9259e-05,\n",
      "          1.3527e-03,  4.1309e-02,  1.6772e-03,  2.9330e-02,  1.2257e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0037], requires_grad=True)\n",
      "bias grad:  tensor([0.1759])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7220]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1763]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0738,  -322.8729,   -11.4017,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0054], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7044]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0738,  -322.8729,   -11.4017,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.1327e-04,  0.0000e+00, -9.9586e-05, -5.3625e-04,  7.3251e-06,\n",
      "         -5.2692e-03, -1.2996e-01, -2.9272e-03, -4.8710e-02,  3.0986e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0054], requires_grad=True)\n",
      "bias grad:  tensor([-0.3094])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7044]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1634]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0725,  -322.8729,   -11.4012,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0023], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5881]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0725,  -322.8729,   -11.4012,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.5944e-03,  1.6614e-05,  1.0897e-05,  6.8552e-04,  1.0140e-03,\n",
      "         -3.0045e-03, -4.3882e-02,  8.3576e-04,  3.2531e-02,  4.8935e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0023], requires_grad=True)\n",
      "bias grad:  tensor([0.1756])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5881]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0182]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0721,  -322.8729,   -11.4015,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0041], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5899]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0721,  -322.8729,   -11.4015,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.1952e-03, -7.3770e-05, -3.4541e-05, -3.5144e-04,  1.1249e-04,\n",
      "         -1.5632e-03, -4.4506e-02, -6.0214e-04, -1.3482e-02,  4.2554e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0041], requires_grad=True)\n",
      "bias grad:  tensor([-0.0958])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5899]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8408]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0716,  -322.8729,   -11.4014,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0031], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5058]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0716,  -322.8729,   -11.4014,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.0509e-04, -1.9533e-04, -9.3437e-05, -5.2608e-04,  6.7830e-05,\n",
      "         -5.5871e-03, -1.2587e-01, -2.8398e-03, -4.2257e-02, -3.9197e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0031], requires_grad=True)\n",
      "bias grad:  tensor([-0.2726])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5058]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6500]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0704,  -322.8728,   -11.4010,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0004], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4408]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0704,  -322.8728,   -11.4010,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0053, 0.0000, 0.0002, 0.0028, 0.0007, 0.0015, 0.1036, 0.0052, 0.1466,\n",
      "         0.0029]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0004], requires_grad=True)\n",
      "bias grad:  tensor([0.8405])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4408]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.8059]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0714,  -322.8729,   -11.4024,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0088], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7214]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0714,  -322.8729,   -11.4024,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6440e-03,  3.4459e-05, -5.0251e-05, -7.8911e-04, -5.8565e-04,\n",
      "         -7.1103e-04, -4.1032e-02, -1.8020e-03, -4.0020e-02, -3.3803e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0088], requires_grad=True)\n",
      "bias grad:  tensor([-0.2326])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7214]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1984]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0710,  -322.8729,   -11.4020,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0065], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7016]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0710,  -322.8729,   -11.4020,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.9208e-04,  3.7079e-05,  9.1239e-05,  1.0856e-03,  5.4971e-04,\n",
      "          2.9805e-03,  8.8633e-02,  3.2525e-03,  5.9130e-02,  1.8121e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0065], requires_grad=True)\n",
      "bias grad:  tensor([0.3736])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7016]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2440]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0719,  -322.8729,   -11.4026,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0102], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7260]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0719,  -322.8729,   -11.4026,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0005e-03, 0.0000e+00, 8.7118e-05, 1.2060e-03, 8.3317e-04, 5.2556e-04,\n",
      "         5.7452e-02, 3.2166e-03, 7.3557e-02, 1.4280e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0102], requires_grad=True)\n",
      "bias grad:  tensor([0.4273])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7260]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0159]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0725,  -322.8729,   -11.4034,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0145], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7275]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0725,  -322.8729,   -11.4034,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[4.9472e-04, 0.0000e+00, 2.0632e-05, 1.0012e-04, 4.1501e-08, 4.3035e-04,\n",
      "         1.9959e-02, 7.0050e-04, 1.2604e-02, 6.5567e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0145], requires_grad=True)\n",
      "bias grad:  tensor([0.0718])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7275]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2798]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0727,  -322.8729,   -11.4035,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0152], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6996]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0727,  -322.8729,   -11.4035,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.2814e-04,  7.4540e-05,  4.2945e-05,  4.8779e-04, -1.4723e-05,\n",
      "          7.0832e-04,  3.2679e-02,  1.5198e-03,  3.1897e-02,  8.3882e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0152], requires_grad=True)\n",
      "bias grad:  tensor([0.1836])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6996]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1818]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0730,  -322.8729,   -11.4038,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0171], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7177]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0730,  -322.8729,   -11.4038,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.4293e-03, -1.0440e-04, -5.4863e-05, -6.4205e-04,  6.3484e-05,\n",
      "         -2.0334e-03, -5.5986e-02, -1.5527e-03, -3.1956e-02, -5.4748e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0171], requires_grad=True)\n",
      "bias grad:  tensor([-0.1807])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7177]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7981]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0724,  -322.8729,   -11.4035,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0153], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6379]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0724,  -322.8729,   -11.4035,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0284e-04, 0.0000e+00, 7.8280e-05, 9.5388e-04, 5.8724e-04, 8.2747e-04,\n",
      "         4.4756e-02, 2.9687e-03, 5.9124e-02, 1.4459e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0153], requires_grad=True)\n",
      "bias grad:  tensor([0.3443])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6379]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0224]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0729,  -322.8729,   -11.4041,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0187], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6402]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0729,  -322.8729,   -11.4041,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[8.2224e-04, 1.3525e-05, 2.6482e-05, 1.7835e-04, 2.1640e-04, 1.7737e-03,\n",
      "         4.2081e-02, 1.0443e-03, 1.2956e-02, 1.0008e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0187], requires_grad=True)\n",
      "bias grad:  tensor([0.0877])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6402]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3705]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0733,  -322.8729,   -11.4042,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0196], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6031]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0733,  -322.8729,   -11.4042,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5079e-03, 4.6098e-05, 6.1377e-05, 6.5163e-04, 3.2241e-04, 2.5759e-03,\n",
      "         7.1538e-02, 2.0093e-03, 3.8459e-02, 1.3374e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0196], requires_grad=True)\n",
      "bias grad:  tensor([0.2251])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6031]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2324]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0740,  -322.8730,   -11.4046,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0218], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6264]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0740,  -322.8730,   -11.4046,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[2.9698e-04, 4.2556e-05, 1.5245e-04, 1.5982e-03, 7.0531e-04, 2.1124e-03,\n",
      "         9.7510e-02, 4.3724e-03, 8.9430e-02, 2.4795e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0218], requires_grad=True)\n",
      "bias grad:  tensor([0.5638])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6264]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2142]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0750,  -322.8730,   -11.4055,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0275], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6478]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0750,  -322.8730,   -11.4055,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[5.5677e-03, 0.0000e+00, 6.4567e-05, 8.3714e-04, 6.7036e-04, 1.1900e-03,\n",
      "         5.4282e-02, 2.0757e-03, 5.0352e-02, 9.7958e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0275], requires_grad=True)\n",
      "bias grad:  tensor([0.2864])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6478]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3620]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0755,  -322.8730,   -11.4060,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0303], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6840]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0755,  -322.8730,   -11.4060,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[2.5595e-03, 0.0000e+00, 4.4610e-05, 4.9407e-04, 4.3390e-04, 7.3311e-04,\n",
      "         3.7005e-02, 1.9830e-03, 3.4259e-02, 5.0722e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0303], requires_grad=True)\n",
      "bias grad:  tensor([0.1969])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6840]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2198]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0759,  -322.8730,   -11.4063,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0323], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6620]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0759,  -322.8730,   -11.4063,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0013, 0.0003, 0.0003, 0.0031, 0.0008, 0.0075, 0.2241, 0.0072, 0.1395,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0323], requires_grad=True)\n",
      "bias grad:  tensor([0.8603])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6620]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5868]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0781,  -322.8731,   -11.4077,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0409], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8207]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0781,  -322.8731,   -11.4077,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4222e-03,  0.0000e+00,  1.7514e-05,  3.0091e-05,  8.9396e-05,\n",
      "          5.7314e-04,  1.7950e-02,  8.6503e-04,  9.6858e-03,  2.2902e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0409], requires_grad=True)\n",
      "bias grad:  tensor([0.0568])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8207]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2932]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0783,  -322.8731,   -11.4078,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0415], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7914]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0783,  -322.8731,   -11.4078,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[1.0089e-03, 4.4767e-05, 9.0776e-05, 1.1529e-03, 6.7859e-04, 1.0239e-03,\n",
      "         5.6641e-02, 2.9617e-03, 6.6302e-02, 1.7974e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0415], requires_grad=True)\n",
      "bias grad:  tensor([0.3976])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7914]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1944]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0789,  -322.8731,   -11.4085,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0454], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8108]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0789,  -322.8731,   -11.4085,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.9088e-04, -3.8284e-05,  2.9732e-05,  3.5122e-04,  2.5541e-04,\n",
      "          6.5606e-04,  2.3416e-02,  1.6498e-03,  2.9939e-02,  1.5841e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0454], requires_grad=True)\n",
      "bias grad:  tensor([0.1679])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8108]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7018]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0791,  -322.8732,   -11.4088,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0471], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7406]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0791,  -322.8732,   -11.4088,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0368e-04, 5.1451e-06, 7.4463e-05, 6.4736e-04, 2.1456e-04, 2.7008e-03,\n",
      "         6.9679e-02, 2.1857e-03, 4.4919e-02, 1.3533e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0471], requires_grad=True)\n",
      "bias grad:  tensor([0.2548])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7406]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0559]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8732,   -11.4092,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0497], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7350]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8732,   -11.4092,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.3600e-03, -2.8133e-05, -2.8721e-05, -5.7281e-04, -3.3831e-04,\n",
      "         -2.2011e-04, -1.8616e-02, -7.6182e-04, -2.2024e-02,  2.3248e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0497], requires_grad=True)\n",
      "bias grad:  tensor([-0.1269])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7350]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6632]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0796,  -322.8732,   -11.4090,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0484], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6687]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0796,  -322.8732,   -11.4090,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.3095e-03,  0.0000e+00,  1.2727e-05,  1.3687e-04,  2.1785e-04,\n",
      "          1.2987e-04,  1.4088e-02,  3.1380e-05,  4.7979e-03, -1.1066e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0484], requires_grad=True)\n",
      "bias grad:  tensor([0.0365])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6687]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2828]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8732,   -11.4091,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0488], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6970]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8732,   -11.4091,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[5.2987e-03, 2.4599e-05, 1.1254e-04, 1.4076e-03, 1.1067e-03, 1.5343e-03,\n",
      "         8.0970e-02, 4.0600e-03, 8.7201e-02, 2.9076e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0488], requires_grad=True)\n",
      "bias grad:  tensor([0.5157])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6970]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0051]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0806,  -322.8732,   -11.4099,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0539], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6965]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0806,  -322.8732,   -11.4099,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1487e-02,  0.0000e+00, -3.8670e-05, -1.0249e-03, -1.3546e-03,\n",
      "         -6.3504e-04, -2.8927e-02, -2.0165e-03, -5.0981e-02, -5.1370e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0539], requires_grad=True)\n",
      "bias grad:  tensor([-0.2856])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6965]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2600]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0803,  -322.8732,   -11.4094,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0511], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6705]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0803,  -322.8732,   -11.4094,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.6786e-03,  1.2722e-05,  5.6450e-05,  5.7984e-04,  1.5898e-04,\n",
      "          1.3251e-03,  4.2996e-02,  1.8751e-03,  3.6274e-02,  1.0848e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0511], requires_grad=True)\n",
      "bias grad:  tensor([0.2163])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6705]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0956]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0807,  -322.8732,   -11.4098,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0532], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6800]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0807,  -322.8732,   -11.4098,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.5317e-04,  0.0000e+00, -1.0668e-04, -6.2585e-04, -4.4997e-05,\n",
      "         -5.2257e-03, -1.3150e-01, -3.1302e-03, -5.4328e-02, -2.2446e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0532], requires_grad=True)\n",
      "bias grad:  tensor([-0.3407])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6800]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1714]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0794,  -322.8732,   -11.4092,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0498], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5629]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0794,  -322.8732,   -11.4092,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.6808e-03,  1.5223e-05,  1.1146e-05,  6.9532e-04,  9.8577e-04,\n",
      "         -2.9560e-03, -4.3911e-02,  8.5746e-04,  3.2835e-02, -4.1886e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0498], requires_grad=True)\n",
      "bias grad:  tensor([0.1730])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5629]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0850]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0790,  -322.8732,   -11.4096,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0516], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5714]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0790,  -322.8732,   -11.4096,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.3862e-03, -6.0522e-05, -4.3196e-05, -4.5226e-04,  8.9533e-05,\n",
      "         -1.7020e-03, -4.9764e-02, -8.5177e-04, -1.9087e-02,  1.6626e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0516], requires_grad=True)\n",
      "bias grad:  tensor([-0.1285])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5714]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8681]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0785,  -322.8732,   -11.4094,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0503], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4846]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0785,  -322.8732,   -11.4094,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3555e-03, -1.8033e-04, -2.4287e-05, -5.3232e-05,  3.5890e-04,\n",
      "         -3.3018e-03, -6.0340e-02, -7.7605e-04, -4.4447e-03,  3.1828e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0503], requires_grad=True)\n",
      "bias grad:  tensor([-0.0335])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4846]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6562]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0779,  -322.8732,   -11.4093,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0499], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4190]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0779,  -322.8732,   -11.4093,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0050, 0.0000, 0.0002, 0.0026, 0.0006, 0.0015, 0.0982, 0.0048, 0.1364,\n",
      "         0.0027]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0499], requires_grad=True)\n",
      "bias grad:  tensor([0.7825])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4190]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.9036]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0789,  -322.8733,   -11.4107,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0578], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7093]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0789,  -322.8733,   -11.4107,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3566e-03,  2.7638e-05, -5.7204e-05, -8.5676e-04, -6.1408e-04,\n",
      "         -8.5474e-04, -4.4241e-02, -2.0421e-03, -4.4251e-02, -4.2530e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0578], requires_grad=True)\n",
      "bias grad:  tensor([-0.2590])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7093]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1558]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8732,   -11.4102,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0552], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6938]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8732,   -11.4102,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.4058e-04,  4.6458e-05,  7.3568e-05,  8.6738e-04,  4.0238e-04,\n",
      "          2.7586e-03,  7.5936e-02,  2.6095e-03,  4.6803e-02,  1.4449e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0552], requires_grad=True)\n",
      "bias grad:  tensor([0.2980])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6938]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2348]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0792,  -322.8733,   -11.4107,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0581], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7172]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0792,  -322.8733,   -11.4107,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0046, 0.0000, 0.0001, 0.0014, 0.0010, 0.0006, 0.0854, 0.0039, 0.0858,\n",
      "         0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0581], requires_grad=True)\n",
      "bias grad:  tensor([0.4950])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7172]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1465]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0800,  -322.8733,   -11.4116,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0631], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7026]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0800,  -322.8733,   -11.4116,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3439e-05,  0.0000e+00,  1.7103e-05,  5.8599e-05, -1.2196e-06,\n",
      "          4.3423e-04,  1.8565e-02,  6.0063e-04,  1.0122e-02,  6.2891e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0631], requires_grad=True)\n",
      "bias grad:  tensor([0.0574])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7026]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3478]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0802,  -322.8733,   -11.4117,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0637], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6678]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0802,  -322.8733,   -11.4117,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.0024e-04,  8.5841e-05,  4.3353e-05,  4.8399e-04, -7.9355e-05,\n",
      "          8.6498e-04,  3.5166e-02,  1.5167e-03,  3.1393e-02,  8.5395e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0637], requires_grad=True)\n",
      "bias grad:  tensor([0.1808])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6678]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2232]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0806,  -322.8733,   -11.4120,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0655], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6901]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0806,  -322.8733,   -11.4120,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6756e-03, -7.1969e-05, -2.7520e-05, -2.7999e-04,  2.3003e-04,\n",
      "         -1.5345e-03, -3.3521e-02, -6.4910e-04, -1.2219e-02,  1.0886e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0655], requires_grad=True)\n",
      "bias grad:  tensor([-0.0669])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6901]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4695]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0802,  -322.8733,   -11.4119,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0648], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6432]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0802,  -322.8733,   -11.4119,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0566e-03,  0.0000e+00,  6.9112e-05,  7.6499e-04,  3.9474e-04,\n",
      "          8.3323e-04,  3.8760e-02,  2.5058e-03,  4.8145e-02,  1.3019e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0648], requires_grad=True)\n",
      "bias grad:  tensor([0.2845])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6432]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0317]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0806,  -322.8733,   -11.4123,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0677], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6463]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0806,  -322.8733,   -11.4123,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7213e-04, 1.6359e-05, 1.6907e-05, 6.5073e-05, 1.6059e-04, 1.6069e-03,\n",
      "         3.5068e-02, 7.6100e-04, 6.7795e-03, 8.9437e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0677], requires_grad=True)\n",
      "bias grad:  tensor([0.0504])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6463]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3457]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0810,  -322.8733,   -11.4124,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0682], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6118]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0810,  -322.8733,   -11.4124,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0075e-03, 4.4614e-05, 7.3583e-05, 8.2430e-04, 5.0329e-04, 2.7770e-03,\n",
      "         8.2386e-02, 2.5971e-03, 4.9371e-02, 1.4910e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0682], requires_grad=True)\n",
      "bias grad:  tensor([0.2885])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6118]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1036]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0818,  -322.8734,   -11.4129,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0710], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6221]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0818,  -322.8734,   -11.4129,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2507e-04, 4.4613e-05, 1.6395e-04, 1.7394e-03, 8.1703e-04, 2.2733e-03,\n",
      "         1.0552e-01, 4.9797e-03, 9.6523e-02, 2.7945e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0710], requires_grad=True)\n",
      "bias grad:  tensor([0.6230])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6221]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2354]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0828,  -322.8734,   -11.4139,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0773], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6457]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0828,  -322.8734,   -11.4139,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[4.4116e-03, 0.0000e+00, 7.9027e-05, 9.8369e-04, 7.3543e-04, 1.2486e-03,\n",
      "         5.7457e-02, 2.6417e-03, 6.0989e-02, 1.4273e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0773], requires_grad=True)\n",
      "bias grad:  tensor([0.3468])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6457]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3139]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0834,  -322.8734,   -11.4145,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0807], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6771]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0834,  -322.8734,   -11.4145,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7152e-03, 0.0000e+00, 3.4538e-05, 3.7321e-04, 2.4280e-04, 5.6827e-04,\n",
      "         3.0013e-02, 1.4772e-03, 2.5710e-02, 3.5209e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0807], requires_grad=True)\n",
      "bias grad:  tensor([0.1480])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6771]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1233]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0837,  -322.8734,   -11.4147,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0822], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6647]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0837,  -322.8734,   -11.4147,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0009, 0.0003, 0.0003, 0.0032, 0.0008, 0.0076, 0.2296, 0.0075, 0.1431,\n",
      "         0.0026]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0822], requires_grad=True)\n",
      "bias grad:  tensor([0.8814])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6647]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5159]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0860,  -322.8735,   -11.4162,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0910], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8163]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0860,  -322.8735,   -11.4162,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2949e-03,  0.0000e+00,  9.2016e-07, -1.9561e-04, -7.2041e-05,\n",
      "          4.9021e-04,  7.2598e-03,  2.8036e-04, -2.7860e-03,  3.9833e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0910], requires_grad=True)\n",
      "bias grad:  tensor([-0.0158])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8163]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3384]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0861,  -322.8735,   -11.4161,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0909], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7825]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0861,  -322.8735,   -11.4161,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3637e-04, 3.6221e-05, 6.8101e-05, 8.7936e-04, 5.5723e-04, 8.4529e-04,\n",
      "         4.4064e-02, 2.2697e-03, 5.0541e-02, 1.3953e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0909], requires_grad=True)\n",
      "bias grad:  tensor([0.3044])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7825]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1303]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8735,   -11.4167,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0939], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7955]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8735,   -11.4167,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1457e-03, -3.4525e-05,  3.5268e-05,  4.1436e-04,  2.1721e-04,\n",
      "          6.6539e-04,  2.6439e-02,  1.7832e-03,  3.2852e-02,  1.5445e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0939], requires_grad=True)\n",
      "bias grad:  tensor([0.1847])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7955]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6150]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0868,  -322.8736,   -11.4170,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0958], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7340]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0868,  -322.8736,   -11.4170,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[5.6594e-04, 4.6931e-06, 7.2389e-05, 6.1780e-04, 2.5124e-04, 2.6143e-03,\n",
      "         6.8735e-02, 2.1348e-03, 4.3741e-02, 1.3081e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0958], requires_grad=True)\n",
      "bias grad:  tensor([0.2479])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7340]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0644]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0875,  -322.8736,   -11.4174,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0983], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7276]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0875,  -322.8736,   -11.4174,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6901e-03, -3.3739e-05, -3.8881e-05, -7.1405e-04, -4.5218e-04,\n",
      "         -3.4388e-04, -2.8101e-02, -1.0464e-03, -2.8779e-02,  1.3185e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0983], requires_grad=True)\n",
      "bias grad:  tensor([-0.1699])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7276]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7110]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0872,  -322.8736,   -11.4171,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0966], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6565]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0872,  -322.8736,   -11.4171,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6721e-04,  0.0000e+00, -1.8059e-05, -3.5332e-04, -1.2447e-04,\n",
      "         -5.7485e-05, -6.9420e-03, -1.1022e-03, -2.1718e-02, -6.2030e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0966], requires_grad=True)\n",
      "bias grad:  tensor([-0.1195])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6565]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1641]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0871,  -322.8736,   -11.4169,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0954], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6729]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0871,  -322.8736,   -11.4169,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7708e-03, 1.6479e-05, 8.7041e-05, 1.0650e-03, 8.1955e-04, 1.1561e-03,\n",
      "         6.1182e-02, 3.0987e-03, 6.6550e-02, 2.4350e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0954], requires_grad=True)\n",
      "bias grad:  tensor([0.3958])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6729]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0178]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0877,  -322.8736,   -11.4176,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0993], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6747]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0877,  -322.8736,   -11.4176,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5197e-02,  0.0000e+00, -3.3182e-05, -7.9644e-04, -1.0312e-03,\n",
      "         -5.0577e-04, -2.2996e-02, -1.6549e-03, -4.0471e-02, -4.2765e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0993], requires_grad=True)\n",
      "bias grad:  tensor([-0.2274])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6747]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2107]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0875,  -322.8736,   -11.4172,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0970], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6536]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0875,  -322.8736,   -11.4172,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.6912e-03,  1.4469e-05,  5.1804e-05,  4.5423e-04,  2.2830e-05,\n",
      "          1.1968e-03,  3.5878e-02,  1.6937e-03,  3.0267e-02,  1.1879e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0970], requires_grad=True)\n",
      "bias grad:  tensor([0.1821])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6536]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0053]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0879,  -322.8736,   -11.4175,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0989], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6531]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0879,  -322.8736,   -11.4175,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.2937e-04,  0.0000e+00, -1.0817e-04, -6.2313e-04, -6.2150e-05,\n",
      "         -5.3961e-03, -1.3666e-01, -3.1409e-03, -5.4515e-02, -1.6034e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0989], requires_grad=True)\n",
      "bias grad:  tensor([-0.3429])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6531]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1103]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8736,   -11.4169,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0954], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5420]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8736,   -11.4169,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1281e-03,  3.1269e-05,  6.4556e-06,  6.2077e-04,  8.8618e-04,\n",
      "         -3.1403e-03, -4.9791e-02,  5.8211e-04,  2.7791e-02,  4.4353e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0954], requires_grad=True)\n",
      "bias grad:  tensor([0.1483])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5420]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0669]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0860,  -322.8736,   -11.4172,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0969], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5487]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0860,  -322.8736,   -11.4172,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.4108e-03, -6.1327e-05, -4.1578e-05, -4.3058e-04,  5.0960e-05,\n",
      "         -1.6456e-03, -4.9345e-02, -8.5749e-04, -1.8572e-02,  1.3726e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0969], requires_grad=True)\n",
      "bias grad:  tensor([-0.1252])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5487]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7938]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0855,  -322.8736,   -11.4170,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0957], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4694]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0855,  -322.8736,   -11.4170,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6642e-04, -1.9220e-04, -5.7521e-05, -4.6619e-04,  1.4308e-05,\n",
      "         -3.8862e-03, -8.5929e-02, -1.9171e-03, -2.9371e-02, -2.3253e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0957], requires_grad=True)\n",
      "bias grad:  tensor([-0.1822])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4694]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7180]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0847,  -322.8736,   -11.4167,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0938], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3976]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0847,  -322.8736,   -11.4167,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0056, 0.0000, 0.0002, 0.0027, 0.0005, 0.0014, 0.0943, 0.0047, 0.1385,\n",
      "         0.0026]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0938], requires_grad=True)\n",
      "bias grad:  tensor([0.7959])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3976]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.8333]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0856,  -322.8736,   -11.4181,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1018], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7809]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0856,  -322.8736,   -11.4181,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.9412e-03,  2.6072e-05, -6.5508e-05, -1.0499e-03, -7.5062e-04,\n",
      "         -8.9193e-04, -5.1327e-02, -2.3755e-03, -5.3462e-02, -4.9608e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1018], requires_grad=True)\n",
      "bias grad:  tensor([-0.3116])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7809]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3850]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0851,  -322.8736,   -11.4176,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0987], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7424]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0851,  -322.8736,   -11.4176,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2975e-03,  4.2013e-05,  6.7329e-05,  7.8758e-04,  3.5654e-04,\n",
      "          2.6365e-03,  7.1068e-02,  2.3791e-03,  4.2006e-02,  1.3437e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0987], requires_grad=True)\n",
      "bias grad:  tensor([0.2699])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7424]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1702]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0858,  -322.8736,   -11.4180,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1014], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7594]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0858,  -322.8736,   -11.4180,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5778e-03, 0.0000e+00, 6.0443e-05, 8.4768e-04, 6.2519e-04, 3.0597e-04,\n",
      "         4.0256e-02, 2.2351e-03, 5.1711e-02, 1.0494e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1014], requires_grad=True)\n",
      "bias grad:  tensor([0.3012])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7594]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0457]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0862,  -322.8737,   -11.4185,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1044], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7640]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0862,  -322.8737,   -11.4185,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3075e-03,  0.0000e+00, -4.1254e-06, -2.7051e-04, -2.3656e-04,\n",
      "          2.3127e-04,  5.2172e-03, -2.3588e-04, -8.4606e-03,  3.8879e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1044], requires_grad=True)\n",
      "bias grad:  tensor([-0.0484])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7640]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4429]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0862,  -322.8737,   -11.4184,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1039], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7197]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0862,  -322.8737,   -11.4184,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6250e-04,  5.6218e-05,  2.7371e-05,  2.3553e-04, -2.3694e-04,\n",
      "          6.8532e-04,  2.5701e-02,  8.7268e-04,  1.7974e-02,  6.3275e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1039], requires_grad=True)\n",
      "bias grad:  tensor([0.1038])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7197]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0866]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0865,  -322.8737,   -11.4186,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1049], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7284]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0865,  -322.8737,   -11.4186,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.9976e-04, -1.0323e-04, -7.3126e-05, -8.6887e-04, -5.9837e-05,\n",
      "         -2.1717e-03, -6.3850e-02, -2.0476e-03, -4.4650e-02, -4.8640e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1049], requires_grad=True)\n",
      "bias grad:  tensor([-0.2555])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7284]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7723]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0859,  -322.8736,   -11.4182,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1024], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6511]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0859,  -322.8736,   -11.4182,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.4675e-04,  0.0000e+00,  7.3983e-05,  8.8899e-04,  5.3366e-04,\n",
      "          6.5636e-04,  3.7866e-02,  2.7354e-03,  5.5266e-02,  1.3925e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1024], requires_grad=True)\n",
      "bias grad:  tensor([0.3217])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6511]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0546]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0862,  -322.8737,   -11.4187,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1056], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6566]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0862,  -322.8737,   -11.4187,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 9.1067e-04,  9.0117e-06, -4.1285e-06, -1.8212e-04,  1.2778e-04,\n",
      "          1.2634e-03,  2.2019e-02,  1.7495e-04, -6.3173e-03,  5.6360e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1056], requires_grad=True)\n",
      "bias grad:  tensor([-0.0286])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6566]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4583]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0865,  -322.8737,   -11.4187,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1053], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6108]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0865,  -322.8737,   -11.4187,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[6.5552e-04, 3.3804e-05, 3.2993e-05, 3.0290e-04, 9.0618e-05, 1.9100e-03,\n",
      "         4.7868e-02, 1.0520e-03, 1.7649e-02, 7.2122e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1053], requires_grad=True)\n",
      "bias grad:  tensor([0.1048])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6108]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2044]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0869,  -322.8737,   -11.4188,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1064], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6312]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0869,  -322.8737,   -11.4188,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0100e-04, 3.3239e-05, 1.4408e-04, 1.5290e-03, 6.8966e-04, 1.9663e-03,\n",
      "         9.2121e-02, 4.1916e-03, 8.4951e-02, 2.3572e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1064], requires_grad=True)\n",
      "bias grad:  tensor([0.5407])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6312]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2144]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0879,  -322.8737,   -11.4197,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1118], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6526]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0879,  -322.8737,   -11.4197,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5737e-03, 0.0000e+00, 4.5648e-05, 5.8811e-04, 5.1106e-04, 7.5805e-04,\n",
      "         3.5945e-02, 1.5736e-03, 3.6651e-02, 6.9384e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1118], requires_grad=True)\n",
      "bias grad:  tensor([0.2077])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6526]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2186]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0882,  -322.8737,   -11.4200,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1139], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6745]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0882,  -322.8737,   -11.4200,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.0572e-04,  0.0000e+00,  1.7109e-05,  9.6277e-05, -2.6941e-05,\n",
      "          4.0675e-04,  1.7094e-02,  7.7676e-04,  1.0907e-02,  1.1617e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1139], requires_grad=True)\n",
      "bias grad:  tensor([0.0610])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6745]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1740]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0884,  -322.8737,   -11.4202,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1145], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6571]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0884,  -322.8737,   -11.4202,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0007, 0.0003, 0.0003, 0.0031, 0.0007, 0.0075, 0.2236, 0.0072, 0.1367,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1145], requires_grad=True)\n",
      "bias grad:  tensor([0.8454])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6571]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5390]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0906,  -322.8738,   -11.4215,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1229], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8110]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0906,  -322.8738,   -11.4215,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8492e-03,  0.0000e+00,  1.0345e-06, -1.4829e-04, -9.2713e-06,\n",
      "          3.0379e-04,  6.5340e-03,  3.9622e-04, -7.5010e-04,  3.2215e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1229], requires_grad=True)\n",
      "bias grad:  tensor([-0.0053])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8110]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3300]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0907,  -322.8738,   -11.4215,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1229], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7780]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0907,  -322.8738,   -11.4215,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[8.1927e-05, 4.1716e-05, 1.0034e-04, 1.2934e-03, 9.8000e-04, 1.1319e-03,\n",
      "         6.6964e-02, 3.4981e-03, 7.8605e-02, 2.5571e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1229], requires_grad=True)\n",
      "bias grad:  tensor([0.4666])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7780]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0085]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8738,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1275], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7788]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8738,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2577e-03, -4.3369e-05,  2.6112e-05,  2.9163e-04,  1.4247e-04,\n",
      "          5.0508e-04,  1.9462e-02,  1.4525e-03,  2.5849e-02,  1.3869e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1275], requires_grad=True)\n",
      "bias grad:  tensor([0.1441])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7788]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6320]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0916,  -322.8738,   -11.4226,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1290], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7156]], requires_grad=True)\n",
      "Iteration 4 | Score: 0.30809465050697327\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0916,  -322.8738,   -11.4226,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[6.4488e-04, 7.8352e-06, 6.1339e-05, 4.6701e-04, 1.3955e-04, 2.5179e-03,\n",
      "         6.1078e-02, 1.7177e-03, 3.5131e-02, 1.2060e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1290], requires_grad=True)\n",
      "bias grad:  tensor([0.1985])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7156]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1050]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0922,  -322.8738,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1310], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7051]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0922,  -322.8738,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.8687e-03, -1.8596e-05, -3.7189e-05, -6.8811e-04, -4.7294e-04,\n",
      "         -3.5981e-04, -2.5714e-02, -1.0913e-03, -2.9247e-02,  4.3082e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1310], requires_grad=True)\n",
      "bias grad:  tensor([-0.1695])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7051]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6379]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0919,  -322.8738,   -11.4226,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1293], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6414]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0919,  -322.8738,   -11.4226,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.4989e-03,  0.0000e+00, -2.7897e-06, -1.1534e-04, -1.5041e-05,\n",
      "          6.5347e-05,  3.8236e-03, -7.5278e-04, -1.1134e-02, -3.6993e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1293], requires_grad=True)\n",
      "bias grad:  tensor([-0.0543])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6414]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3797]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0920,  -322.8738,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1287], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6793]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0920,  -322.8738,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[3.9719e-03, 1.9186e-05, 9.2376e-05, 1.1290e-03, 8.6566e-04, 1.1907e-03,\n",
      "         6.4146e-02, 3.2717e-03, 7.0726e-02, 2.5268e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1287], requires_grad=True)\n",
      "bias grad:  tensor([0.4198])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6793]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0589]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0926,  -322.8739,   -11.4232,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1329], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6852]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0926,  -322.8739,   -11.4232,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8286e-02,  0.0000e+00, -3.2993e-05, -8.7328e-04, -1.1539e-03,\n",
      "         -5.4125e-04, -2.4655e-02, -1.7194e-03, -4.3450e-02, -4.3810e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1329], requires_grad=True)\n",
      "bias grad:  tensor([-0.2434])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6852]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3694]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0923,  -322.8738,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1305], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6483]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0923,  -322.8738,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.0122e-03,  1.8477e-05,  3.5754e-05,  2.6585e-04, -4.7061e-05,\n",
      "          1.0656e-03,  2.8717e-02,  1.1157e-03,  1.9098e-02,  8.7391e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1305], requires_grad=True)\n",
      "bias grad:  tensor([0.1154])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6483]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0014]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0926,  -322.8738,   -11.4230,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1316], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6481]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0926,  -322.8738,   -11.4230,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.4462e-04,  0.0000e+00, -9.3546e-05, -4.5176e-04,  9.7631e-05,\n",
      "         -5.1735e-03, -1.2514e-01, -2.6716e-03, -4.3182e-02,  1.6973e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1316], requires_grad=True)\n",
      "bias grad:  tensor([-0.2766])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6481]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1715]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0914,  -322.8738,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1289], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5310]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0914,  -322.8738,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.7853e-03,  2.1912e-05, -3.8817e-06,  5.0375e-04,  8.4980e-04,\n",
      "         -3.0258e-03, -5.2941e-02,  2.9281e-04,  2.1102e-02, -3.1404e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1289], requires_grad=True)\n",
      "bias grad:  tensor([0.1072])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5310]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0489]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8738,   -11.4227,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1299], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5359]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8738,   -11.4227,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.1588e-03, -5.4015e-05, -3.3009e-05, -3.0695e-04,  1.7719e-04,\n",
      "         -1.5475e-03, -4.1338e-02, -5.6064e-04, -1.2398e-02,  1.3485e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1299], requires_grad=True)\n",
      "bias grad:  tensor([-0.0865])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5359]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6587]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8738,   -11.4226,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1291], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4700]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8738,   -11.4226,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.2564e-04, -1.9633e-04, -5.0047e-05, -4.5350e-04, -7.6944e-05,\n",
      "         -3.9851e-03, -8.7147e-02, -1.8845e-03, -2.7469e-02, -6.5948e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1291], requires_grad=True)\n",
      "bias grad:  tensor([-0.1772])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4700]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7500]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0896,  -322.8738,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1273], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3950]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0896,  -322.8738,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0054, 0.0000, 0.0002, 0.0025, 0.0004, 0.0013, 0.0851, 0.0041, 0.1232,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1273], requires_grad=True)\n",
      "bias grad:  tensor([0.7086])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3950]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.5549]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8738,   -11.4236,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1344], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7505]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8738,   -11.4236,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.3581e-03,  2.0130e-05, -8.0646e-05, -1.2725e-03, -8.8484e-04,\n",
      "         -1.0510e-03, -6.1520e-02, -2.9871e-03, -6.5845e-02, -6.8766e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1344], requires_grad=True)\n",
      "bias grad:  tensor([-0.3840])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7505]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4005]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0898,  -322.8738,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1306], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7104]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0898,  -322.8738,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8397e-03,  3.4817e-05,  5.5252e-05,  6.2816e-04,  3.1072e-04,\n",
      "          2.1833e-03,  5.8454e-02,  1.9604e-03,  3.5461e-02,  1.0394e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1306], requires_grad=True)\n",
      "bias grad:  tensor([0.2199])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7104]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2125]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8738,   -11.4233,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1328], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7317]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8738,   -11.4233,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[3.2230e-03, 0.0000e+00, 6.0395e-05, 8.4276e-04, 5.9512e-04, 3.2706e-04,\n",
      "         3.7702e-02, 2.2257e-03, 5.1260e-02, 1.0162e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1328], requires_grad=True)\n",
      "bias grad:  tensor([0.2994])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7317]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0300]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0908,  -322.8738,   -11.4238,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1357], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7347]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0908,  -322.8738,   -11.4238,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1036e-03,  0.0000e+00,  1.2715e-06, -1.9047e-04, -1.6996e-04,\n",
      "          3.0294e-04,  9.1091e-03,  1.1387e-05, -3.5546e-03,  4.1731e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1357], requires_grad=True)\n",
      "bias grad:  tensor([-0.0206])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7347]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4193]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8738,   -11.4238,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1355], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6928]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8738,   -11.4238,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.6315e-04,  6.9291e-05,  3.2754e-05,  3.3000e-04, -1.5768e-04,\n",
      "          5.7809e-04,  2.6024e-02,  1.0950e-03,  2.3108e-02,  7.1287e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1355], requires_grad=True)\n",
      "bias grad:  tensor([0.1336])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6928]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1651]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0911,  -322.8738,   -11.4240,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1369], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7093]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0911,  -322.8738,   -11.4240,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.5235e-04, -1.0299e-04, -7.1643e-05, -8.4123e-04, -2.6438e-05,\n",
      "         -2.2607e-03, -6.5218e-02, -2.0473e-03, -4.3465e-02, -2.5026e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1369], requires_grad=True)\n",
      "bias grad:  tensor([-0.2472])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7093]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7912]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0905,  -322.8738,   -11.4235,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1344], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6301]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0905,  -322.8738,   -11.4235,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5453e-03,  0.0000e+00,  6.9619e-05,  7.6240e-04,  3.9940e-04,\n",
      "          8.5039e-04,  4.0337e-02,  2.5499e-03,  4.8441e-02,  1.3758e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1344], requires_grad=True)\n",
      "bias grad:  tensor([0.2860])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6301]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0253]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8738,   -11.4240,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1373], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6276]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8738,   -11.4240,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.2518e-03,  1.4057e-05,  9.7333e-06, -2.0328e-05,  2.0345e-04,\n",
      "          1.6557e-03,  3.4069e-02,  6.2202e-04,  2.4613e-03,  8.4920e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1373], requires_grad=True)\n",
      "bias grad:  tensor([0.0271])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6276]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4306]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0912,  -322.8738,   -11.4241,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1375], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5846]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0912,  -322.8738,   -11.4241,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[2.1061e-03, 3.2622e-05, 4.6299e-05, 4.8803e-04, 2.4826e-04, 2.1764e-03,\n",
      "         5.8601e-02, 1.5272e-03, 2.7370e-02, 9.6557e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1375], requires_grad=True)\n",
      "bias grad:  tensor([0.1654])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5846]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2765]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0918,  -322.8739,   -11.4243,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1392], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6122]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0918,  -322.8739,   -11.4243,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[3.2435e-04, 4.3257e-05, 1.2962e-04, 1.3595e-03, 5.4666e-04, 1.8628e-03,\n",
      "         8.4251e-02, 3.5523e-03, 7.5260e-02, 2.0781e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1392], requires_grad=True)\n",
      "bias grad:  tensor([0.4721])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6122]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2993]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0926,  -322.8739,   -11.4251,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1439], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6421]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0926,  -322.8739,   -11.4251,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[4.4641e-03, 0.0000e+00, 9.7394e-05, 1.2022e-03, 9.3629e-04, 1.5459e-03,\n",
      "         7.2786e-02, 3.4434e-03, 7.7019e-02, 2.2968e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1439], requires_grad=True)\n",
      "bias grad:  tensor([0.4396])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6421]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1613]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0934,  -322.8739,   -11.4259,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1483], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6583]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0934,  -322.8739,   -11.4259,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[1.3271e-03, 0.0000e+00, 3.0928e-05, 2.8632e-04, 2.0794e-04, 5.2774e-04,\n",
      "         2.6050e-02, 1.3047e-03, 2.2256e-02, 4.3397e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1483], requires_grad=True)\n",
      "bias grad:  tensor([0.1275])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6583]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2558]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0936,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1496], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6327]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0936,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0013, 0.0003, 0.0003, 0.0033, 0.0008, 0.0080, 0.2389, 0.0076, 0.1440,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1496], requires_grad=True)\n",
      "bias grad:  tensor([0.8922])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6327]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.8820]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0960,  -322.8740,   -11.4275,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1585], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8209]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0960,  -322.8740,   -11.4275,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.8813e-03,  0.0000e+00, -1.3494e-05, -3.7348e-04, -2.3149e-04,\n",
      "          2.0464e-04, -4.0438e-03, -2.2826e-04, -1.3993e-02, -1.5436e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1585], requires_grad=True)\n",
      "bias grad:  tensor([-0.0820])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8209]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2471]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0960,  -322.8740,   -11.4274,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1577], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7962]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0960,  -322.8740,   -11.4274,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[3.8131e-04, 3.4168e-05, 7.3835e-05, 9.4494e-04, 6.2395e-04, 8.7837e-04,\n",
      "         4.6767e-02, 2.4270e-03, 5.4775e-02, 1.5620e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1577], requires_grad=True)\n",
      "bias grad:  tensor([0.3298])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7962]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0787]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0964,  -322.8741,   -11.4279,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1610], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8041]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0964,  -322.8741,   -11.4279,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.9761e-04, -4.2010e-05,  3.1636e-05,  3.7497e-04,  2.2352e-04,\n",
      "          6.5787e-04,  2.4914e-02,  1.6966e-03,  3.1277e-02,  1.6492e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1610], requires_grad=True)\n",
      "bias grad:  tensor([0.1750])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8041]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6752]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0967,  -322.8741,   -11.4282,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1627], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7365]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0967,  -322.8741,   -11.4282,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.0195e-04,  1.2666e-05,  4.7657e-05,  2.9851e-04, -8.0170e-06,\n",
      "          2.0987e-03,  4.8646e-02,  1.2279e-03,  2.4580e-02,  9.9778e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1627], requires_grad=True)\n",
      "bias grad:  tensor([0.1385])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7365]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1052]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0972,  -322.8741,   -11.4285,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1641], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7260]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0972,  -322.8741,   -11.4285,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.3765e-03, -2.9659e-05, -4.9627e-05, -8.4170e-04, -5.7120e-04,\n",
      "         -4.5720e-04, -3.3996e-02, -1.4377e-03, -3.7965e-02, -9.3807e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1641], requires_grad=True)\n",
      "bias grad:  tensor([-0.2226])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7260]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6664]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8741,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1619], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6594]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8741,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.5324e-04,  0.0000e+00, -6.7411e-06, -1.6034e-04, -6.4931e-06,\n",
      "          5.2548e-06,  2.7534e-03, -6.9198e-04, -1.1510e-02, -3.9491e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1619], requires_grad=True)\n",
      "bias grad:  tensor([-0.0594])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6594]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2127]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0969,  -322.8741,   -11.4280,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1613], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6806]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0969,  -322.8741,   -11.4280,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7208e-03, 2.7086e-05, 8.6783e-05, 1.0554e-03, 7.8291e-04, 1.3680e-03,\n",
      "         6.4441e-02, 3.1202e-03, 6.5275e-02, 2.4253e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1613], requires_grad=True)\n",
      "bias grad:  tensor([0.3896])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6806]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0699]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0975,  -322.8741,   -11.4286,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1652], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6876]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0975,  -322.8741,   -11.4286,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0093e-02,  0.0000e+00, -2.8790e-05, -8.6804e-04, -1.1743e-03,\n",
      "         -5.2228e-04, -2.3845e-02, -1.5965e-03, -4.2096e-02, -3.9907e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1652], requires_grad=True)\n",
      "bias grad:  tensor([-0.2349])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6876]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3022]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0973,  -322.8741,   -11.4282,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1628], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6574]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0973,  -322.8741,   -11.4282,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.3057e-03,  1.7238e-05,  2.1444e-05,  6.1152e-05, -1.9618e-04,\n",
      "          8.5059e-04,  1.8750e-02,  6.2080e-04,  7.5937e-03,  6.7424e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1628], requires_grad=True)\n",
      "bias grad:  tensor([0.0490])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6574]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1156]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0975,  -322.8741,   -11.4283,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1633], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6458]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0975,  -322.8741,   -11.4283,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.9339e-04,  0.0000e+00, -1.0730e-04, -6.1609e-04, -4.7415e-05,\n",
      "         -5.2588e-03, -1.3484e-01, -3.0322e-03, -5.3466e-02, -1.7212e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1633], requires_grad=True)\n",
      "bias grad:  tensor([-0.3365])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6458]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1508]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0961,  -322.8741,   -11.4278,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1600], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5308]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0961,  -322.8741,   -11.4278,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6929e-03,  2.1317e-05, -1.6651e-05,  3.2368e-04,  7.1930e-04,\n",
      "         -3.4020e-03, -6.5411e-02, -1.9510e-04,  1.1318e-02, -4.2405e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1600], requires_grad=True)\n",
      "bias grad:  tensor([0.0468])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5308]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0240]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0955,  -322.8741,   -11.4279,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1604], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5332]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0955,  -322.8741,   -11.4279,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.6118e-03, -6.4884e-05, -4.7146e-05, -5.1060e-04,  3.8034e-05,\n",
      "         -1.9374e-03, -5.6366e-02, -1.0617e-03, -2.2764e-02,  1.0548e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1604], requires_grad=True)\n",
      "bias grad:  tensor([-0.1506])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5332]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8661]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0949,  -322.8741,   -11.4276,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1589], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4466]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0949,  -322.8741,   -11.4276,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7669e-04, -1.9581e-04, -7.1804e-05, -6.4079e-04, -9.5706e-05,\n",
      "         -4.1190e-03, -9.4525e-02, -2.4280e-03, -3.9799e-02, -4.6238e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1589], requires_grad=True)\n",
      "bias grad:  tensor([-0.2431])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4466]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7779]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0939,  -322.8740,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1565], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3688]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0939,  -322.8740,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0061, 0.0000, 0.0003, 0.0033, 0.0006, 0.0020, 0.1252, 0.0061, 0.1715,\n",
      "         0.0037]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1565], requires_grad=True)\n",
      "bias grad:  tensor([0.9836])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3688]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.0816]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0952,  -322.8741,   -11.4290,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1663], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7769]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0952,  -322.8741,   -11.4290,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2095e-03,  2.0788e-05, -8.4559e-05, -1.3832e-03, -9.9829e-04,\n",
      "         -9.0718e-04, -6.1083e-02, -3.1851e-03, -7.1450e-02, -6.2199e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1663], requires_grad=True)\n",
      "bias grad:  tensor([-0.4126])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7769]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5059]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0946,  -322.8741,   -11.4282,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1622], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7263]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0946,  -322.8741,   -11.4282,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.8697e-03,  2.9457e-05,  6.4704e-05,  6.9280e-04,  2.7977e-04,\n",
      "          2.5321e-03,  6.9113e-02,  2.2362e-03,  3.9111e-02,  1.3465e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1622], requires_grad=True)\n",
      "bias grad:  tensor([0.2464])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7263]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0944]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0953,  -322.8741,   -11.4286,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1647], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7358]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0953,  -322.8741,   -11.4286,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[3.0451e-03, 0.0000e+00, 9.4373e-05, 1.1447e-03, 6.7698e-04, 4.6399e-04,\n",
      "         8.2963e-02, 3.3359e-03, 7.2403e-02, 1.9023e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1647], requires_grad=True)\n",
      "bias grad:  tensor([0.4166])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7358]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1203]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0961,  -322.8741,   -11.4294,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1688], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7238]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0961,  -322.8741,   -11.4294,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.8872e-03,  0.0000e+00, -2.0249e-05, -4.9143e-04, -4.2866e-04,\n",
      "          3.0834e-05, -5.0742e-03, -8.7889e-04, -2.2242e-02,  1.3656e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1688], requires_grad=True)\n",
      "bias grad:  tensor([-0.1266])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7238]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4314]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0961,  -322.8741,   -11.4291,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1676], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6806]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0961,  -322.8741,   -11.4291,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.6237e-04,  7.0551e-05,  2.6548e-05,  2.0469e-04, -3.2154e-04,\n",
      "          5.8353e-04,  2.2497e-02,  8.1343e-04,  1.6504e-02,  6.2060e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1676], requires_grad=True)\n",
      "bias grad:  tensor([0.0951])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6806]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1707]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8741,   -11.4293,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1685], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6977]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8741,   -11.4293,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.5739e-04, -8.2097e-05, -6.0348e-05, -7.5027e-04, -8.3472e-05,\n",
      "         -2.0954e-03, -5.7536e-02, -1.7816e-03, -3.7076e-02, -4.7716e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1685], requires_grad=True)\n",
      "bias grad:  tensor([-0.2130])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6977]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6704]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0957,  -322.8741,   -11.4289,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1664], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6306]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0957,  -322.8741,   -11.4289,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.7973e-04,  0.0000e+00,  5.0773e-05,  5.7478e-04,  3.1307e-04,\n",
      "          5.0180e-04,  2.6538e-02,  1.8498e-03,  3.6196e-02,  9.8295e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1664], requires_grad=True)\n",
      "bias grad:  tensor([0.2124])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6306]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0426]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0960,  -322.8741,   -11.4293,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1685], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6349]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0960,  -322.8741,   -11.4293,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0374e-03,  1.8705e-05, -1.6943e-05, -3.4163e-04, -8.0074e-05,\n",
      "          1.1394e-03,  1.0010e-02, -2.6062e-04, -1.6551e-02,  4.2079e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1685], requires_grad=True)\n",
      "bias grad:  tensor([-0.0877])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6349]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4369]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0961,  -322.8741,   -11.4291,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1676], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5912]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0961,  -322.8741,   -11.4291,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[1.1054e-03, 2.7819e-05, 2.6162e-05, 2.3320e-04, 8.9266e-05, 1.8536e-03,\n",
      "         4.5054e-02, 8.8554e-04, 1.3152e-02, 7.2175e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1676], requires_grad=True)\n",
      "bias grad:  tensor([0.0825])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5912]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1421]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0965,  -322.8741,   -11.4293,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1685], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6054]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0965,  -322.8741,   -11.4293,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[5.4165e-04, 3.8231e-05, 1.2351e-04, 1.3212e-03, 5.6574e-04, 1.8300e-03,\n",
      "         8.0246e-02, 3.5234e-03, 7.3337e-02, 1.9303e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1685], requires_grad=True)\n",
      "bias grad:  tensor([0.4591])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6054]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3556]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0973,  -322.8741,   -11.4300,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1731], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6410]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0973,  -322.8741,   -11.4300,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[4.6901e-03, 0.0000e+00, 5.9058e-05, 7.3652e-04, 6.4549e-04, 1.1844e-03,\n",
      "         5.1806e-02, 2.0505e-03, 4.7862e-02, 1.1687e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1731], requires_grad=True)\n",
      "bias grad:  tensor([0.2705])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6410]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1488]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0978,  -322.8742,   -11.4305,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1758], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6558]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0978,  -322.8742,   -11.4305,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0437e-03, 0.0000e+00, 2.9293e-05, 2.7893e-04, 2.9759e-04, 3.6650e-04,\n",
      "         2.4976e-02, 1.2606e-03, 2.2996e-02, 5.1692e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1758], requires_grad=True)\n",
      "bias grad:  tensor([0.1299])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6558]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3367]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0981,  -322.8742,   -11.4307,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1771], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6222]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0981,  -322.8742,   -11.4307,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0004, 0.0003, 0.0003, 0.0031, 0.0007, 0.0077, 0.2296, 0.0073, 0.1384,\n",
      "         0.0024]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1771], requires_grad=True)\n",
      "bias grad:  tensor([0.8562])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6222]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5740]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8742,   -11.4321,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1856], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7796]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8742,   -11.4321,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3538e-03,  0.0000e+00, -7.3948e-06, -2.9330e-04, -1.3313e-04,\n",
      "          4.1034e-04,  2.5523e-03, -2.0953e-05, -8.9864e-03, -5.1576e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1856], requires_grad=True)\n",
      "bias grad:  tensor([-0.0513])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7796]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3215]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8742,   -11.4320,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1851], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7474]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8742,   -11.4320,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.9366e-04,  3.5107e-05,  5.6229e-05,  6.9374e-04,  3.8249e-04,\n",
      "          7.1251e-04,  3.5827e-02,  1.8428e-03,  3.9209e-02,  1.1277e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1851], requires_grad=True)\n",
      "bias grad:  tensor([0.2399])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7474]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1418]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1008,  -322.8743,   -11.4324,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1875], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7616]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1008,  -322.8743,   -11.4324,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.2417e-04, -2.4786e-05,  3.3336e-05,  4.1049e-04,  2.2942e-04,\n",
      "          5.7811e-04,  2.3879e-02,  1.7024e-03,  3.1774e-02,  1.5129e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1875], requires_grad=True)\n",
      "bias grad:  tensor([0.1791])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7616]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5954]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1010,  -322.8743,   -11.4327,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1893], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7021]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1010,  -322.8743,   -11.4327,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3122e-03,  7.5879e-06,  5.2561e-05,  3.6428e-04,  5.1103e-06,\n",
      "          2.3263e-03,  5.5167e-02,  1.4158e-03,  2.7228e-02,  1.0603e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1893], requires_grad=True)\n",
      "bias grad:  tensor([0.1544])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7021]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0578]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1016,  -322.8743,   -11.4330,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1908], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6963]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1016,  -322.8743,   -11.4330,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7220e-03, -2.6769e-05, -4.5058e-05, -7.9575e-04, -5.7381e-04,\n",
      "         -4.0970e-04, -3.1211e-02, -1.3465e-03, -3.5911e-02, -8.8309e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1908], requires_grad=True)\n",
      "bias grad:  tensor([-0.2089])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6963]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5892]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1013,  -322.8743,   -11.4326,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1888], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6374]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1013,  -322.8743,   -11.4326,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.7373e-05,  0.0000e+00, -8.4318e-06, -2.0439e-04, -7.4488e-05,\n",
      "          1.4456e-05,  4.4447e-05, -7.4443e-04, -1.3573e-02, -4.1779e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1888], requires_grad=True)\n",
      "bias grad:  tensor([-0.0731])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6374]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2565]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1013,  -322.8743,   -11.4325,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1880], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6630]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1013,  -322.8743,   -11.4325,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6834e-03, 2.7140e-05, 9.0550e-05, 1.1082e-03, 8.0857e-04, 1.2106e-03,\n",
      "         6.2219e-02, 3.2191e-03, 6.8749e-02, 2.4590e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1880], requires_grad=True)\n",
      "bias grad:  tensor([0.4091])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6630]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0871]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1019,  -322.8743,   -11.4332,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1921], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6717]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1019,  -322.8743,   -11.4332,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4673e-02,  0.0000e+00, -3.1024e-05, -7.5652e-04, -9.8294e-04,\n",
      "         -4.7848e-04, -2.1762e-02, -1.5581e-03, -3.8308e-02, -4.0171e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1921], requires_grad=True)\n",
      "bias grad:  tensor([-0.2152])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6717]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0693]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1017,  -322.8743,   -11.4328,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1900], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6648]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1017,  -322.8743,   -11.4328,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.6210e-03,  2.5273e-05,  3.4624e-05,  2.1443e-04, -1.0681e-04,\n",
      "          1.1700e-03,  2.9056e-02,  1.0887e-03,  1.6996e-02,  9.3623e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1900], requires_grad=True)\n",
      "bias grad:  tensor([0.1041])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6648]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1197]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1019,  -322.8743,   -11.4330,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1910], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6528]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1019,  -322.8743,   -11.4330,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4846e-03,  0.0000e+00, -1.3088e-04, -9.4088e-04, -2.5951e-04,\n",
      "         -5.6076e-03, -1.5122e-01, -3.9625e-03, -7.3262e-02, -5.2396e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1910], requires_grad=True)\n",
      "bias grad:  tensor([-0.4508])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6528]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1669]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8743,   -11.4322,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1865], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5362]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8743,   -11.4322,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.0851e-03,  1.2612e-05, -3.2922e-05,  1.6212e-04,  6.1264e-04,\n",
      "         -3.4922e-03, -7.4446e-02, -7.1913e-04,  2.1248e-04, -8.7308e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1865], requires_grad=True)\n",
      "bias grad:  tensor([-0.0166])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5362]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1330]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0997,  -322.8743,   -11.4322,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1863], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5495]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0997,  -322.8743,   -11.4322,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.4194e-03, -9.7509e-05, -8.8014e-05, -1.0037e-03, -1.9084e-04,\n",
      "         -2.7497e-03, -8.6553e-02, -2.3285e-03, -4.9936e-02, -1.8775e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1863], requires_grad=True)\n",
      "bias grad:  tensor([-0.3082])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5495]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1437]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0988,  -322.8742,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1833], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4351]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0988,  -322.8742,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.8594e-05, -1.9543e-04, -4.8862e-05, -3.1978e-04,  1.8733e-04,\n",
      "         -3.8635e-03, -8.0507e-02, -1.3684e-03, -1.7631e-02,  1.0302e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1833], requires_grad=True)\n",
      "bias grad:  tensor([-0.1192])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4351]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8550]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0980,  -322.8742,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1821], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3496]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0980,  -322.8742,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0067, 0.0000, 0.0003, 0.0042, 0.0012, 0.0027, 0.1736, 0.0086, 0.2263,\n",
      "         0.0049]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1821], requires_grad=True)\n",
      "bias grad:  tensor([1.2954])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3496]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.6506]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0998,  -322.8743,   -11.4338,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1950], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8146]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0998,  -322.8743,   -11.4338,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2117e-03,  1.2214e-05, -1.0227e-04, -1.6237e-03, -1.1156e-03,\n",
      "         -1.1721e-03, -7.2206e-02, -3.8027e-03, -8.5121e-02, -9.3322e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1950], requires_grad=True)\n",
      "bias grad:  tensor([-0.4940])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8146]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5875]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0990,  -322.8743,   -11.4330,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1901], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7559]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0990,  -322.8743,   -11.4330,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.0824e-03,  3.8543e-05,  5.2389e-05,  5.4434e-04,  1.4685e-04,\n",
      "          2.4081e-03,  5.9957e-02,  1.7681e-03,  2.9455e-02,  1.1389e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1901], requires_grad=True)\n",
      "bias grad:  tensor([0.1920])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7559]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1481]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0996,  -322.8743,   -11.4333,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1920], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7707]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0996,  -322.8743,   -11.4333,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0030, 0.0000, 0.0001, 0.0013, 0.0008, 0.0006, 0.0897, 0.0038, 0.0814,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1920], requires_grad=True)\n",
      "bias grad:  tensor([0.4689])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7707]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1306]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1005,  -322.8744,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1967], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7576]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1005,  -322.8744,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.3124e-03,  0.0000e+00, -2.1972e-05, -5.3802e-04, -4.3151e-04,\n",
      "          1.0173e-04, -3.5808e-03, -9.0240e-04, -2.3370e-02,  1.8062e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1967], requires_grad=True)\n",
      "bias grad:  tensor([-0.1334])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7576]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5018]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1005,  -322.8744,   -11.4338,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1953], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7075]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1005,  -322.8744,   -11.4338,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.0478e-04,  4.9010e-05,  2.1603e-05,  1.5663e-04, -2.9372e-04,\n",
      "          5.9400e-04,  2.1285e-02,  6.3953e-04,  1.3013e-02,  4.4364e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1953], requires_grad=True)\n",
      "bias grad:  tensor([0.0747])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7075]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1321]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1007,  -322.8744,   -11.4340,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1961], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7207]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1007,  -322.8744,   -11.4340,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6914e-04, -1.2195e-04, -8.2283e-05, -1.0080e-03, -1.5154e-04,\n",
      "         -2.3020e-03, -6.9663e-02, -2.3854e-03, -5.1617e-02, -4.6933e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1961], requires_grad=True)\n",
      "bias grad:  tensor([-0.2961])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7207]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8225]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1000,  -322.8743,   -11.4335,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1931], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6384]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1000,  -322.8743,   -11.4335,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.5949e-03,  0.0000e+00,  3.5259e-05,  3.5420e-04,  1.1323e-04,\n",
      "          3.1912e-04,  1.4964e-02,  1.2808e-03,  2.3741e-02,  8.2049e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1931], requires_grad=True)\n",
      "bias grad:  tensor([0.1378])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6384]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0095]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1002,  -322.8743,   -11.4337,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1945], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6394]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1002,  -322.8743,   -11.4337,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.2756e-04,  3.5574e-06, -8.1985e-06, -2.5550e-04, -6.7559e-05,\n",
      "          1.1026e-03,  1.4300e-02, -1.3622e-04, -1.2508e-02,  2.1791e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1945], requires_grad=True)\n",
      "bias grad:  tensor([-0.0641])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6394]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3334]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1003,  -322.8743,   -11.4336,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1939], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6060]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1003,  -322.8743,   -11.4336,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6778e-03, 3.4029e-05, 5.8498e-05, 6.6914e-04, 5.0061e-04, 2.3809e-03,\n",
      "         7.3278e-02, 2.2906e-03, 4.1864e-02, 1.2534e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1939], requires_grad=True)\n",
      "bias grad:  tensor([0.2445])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6060]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1157]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1010,  -322.8744,   -11.4340,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1963], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6176]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1010,  -322.8744,   -11.4340,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[2.3074e-04, 3.5485e-05, 1.2263e-04, 1.2966e-03, 5.5877e-04, 1.7725e-03,\n",
      "         8.0098e-02, 3.5203e-03, 7.2572e-02, 2.0482e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1963], requires_grad=True)\n",
      "bias grad:  tensor([0.4560])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6176]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2083]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1018,  -322.8744,   -11.4347,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2009], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6384]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1018,  -322.8744,   -11.4347,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8581e-03, 0.0000e+00, 6.3996e-05, 7.6034e-04, 6.5049e-04, 1.0393e-03,\n",
      "         4.8566e-02, 2.2661e-03, 5.0109e-02, 1.7650e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2009], requires_grad=True)\n",
      "bias grad:  tensor([0.2861])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6384]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1131]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1023,  -322.8744,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2037], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6498]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1023,  -322.8744,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[6.2150e-03, 0.0000e+00, 7.7147e-05, 8.5986e-04, 1.0465e-03, 9.0610e-04,\n",
      "         5.5124e-02, 3.1717e-03, 5.9721e-02, 1.7964e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2037], requires_grad=True)\n",
      "bias grad:  tensor([0.3472])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6498]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4751]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1029,  -322.8745,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2072], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6022]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1029,  -322.8745,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0008, 0.0003, 0.0003, 0.0031, 0.0007, 0.0079, 0.2279, 0.0071, 0.1327,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2072], requires_grad=True)\n",
      "bias grad:  tensor([0.8271])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6022]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.9246]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1052,  -322.8745,   -11.4371,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2155], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7947]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1052,  -322.8745,   -11.4371,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2221e-03,  0.0000e+00, -1.0134e-05, -3.1876e-04, -1.3146e-04,\n",
      "          2.7016e-04, -6.9079e-04, -8.6190e-05, -1.0567e-02, -1.0354e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2155], requires_grad=True)\n",
      "bias grad:  tensor([-0.0614])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7947]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3413]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1051,  -322.8745,   -11.4370,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2149], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7606]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1051,  -322.8745,   -11.4370,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[1.3219e-04, 4.4897e-05, 7.5996e-05, 9.7210e-04, 6.0281e-04, 9.3314e-04,\n",
      "         4.8870e-02, 2.4969e-03, 5.6224e-02, 1.6178e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2149], requires_grad=True)\n",
      "bias grad:  tensor([0.3360])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7606]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda grad:  tensor([[-0.1626]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1056,  -322.8745,   -11.4376,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2182], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7768]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1056,  -322.8745,   -11.4376,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9792e-03, -4.1867e-05,  1.2082e-05,  7.5210e-05, -6.3853e-05,\n",
      "          4.3451e-04,  1.3290e-02,  9.2746e-04,  1.3426e-02,  1.2100e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2182], requires_grad=True)\n",
      "bias grad:  tensor([0.0725])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7768]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6581]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1058,  -322.8745,   -11.4377,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2190], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7110]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1058,  -322.8745,   -11.4377,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4602e-04, 8.1617e-06, 4.9256e-05, 3.2515e-04, 1.0532e-04, 2.1363e-03,\n",
      "         5.2089e-02, 1.3972e-03, 2.6999e-02, 1.0486e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2190], requires_grad=True)\n",
      "bias grad:  tensor([0.1520])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7110]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2021]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1063,  -322.8745,   -11.4380,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2205], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6908]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1063,  -322.8745,   -11.4380,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.5575e-03, -2.6035e-05, -6.6821e-05, -1.0946e-03, -7.4781e-04,\n",
      "         -6.0475e-04, -4.5650e-02, -2.0012e-03, -5.2579e-02, -3.5888e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2205], requires_grad=True)\n",
      "bias grad:  tensor([-0.3069])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6908]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6580]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1058,  -322.8745,   -11.4375,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2174], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6250]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1058,  -322.8745,   -11.4375,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.3346e-04,  0.0000e+00,  7.3116e-07, -6.7647e-05,  1.8748e-05,\n",
      "          5.9035e-05,  5.0895e-03, -4.5823e-04, -6.4632e-03, -3.0560e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2174], requires_grad=True)\n",
      "bias grad:  tensor([-0.0316])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6250]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2875]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1059,  -322.8745,   -11.4374,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2171], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6538]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1059,  -322.8745,   -11.4374,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[3.2057e-03, 1.5799e-05, 8.7990e-05, 1.0814e-03, 8.1963e-04, 1.2543e-03,\n",
      "         6.3007e-02, 3.1976e-03, 6.6994e-02, 2.4885e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2171], requires_grad=True)\n",
      "bias grad:  tensor([0.3998])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6538]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0687]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1065,  -322.8745,   -11.4381,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2211], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6606]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1065,  -322.8745,   -11.4381,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0356e-02,  0.0000e+00, -6.9061e-05, -1.3687e-03, -1.6900e-03,\n",
      "         -9.1643e-04, -4.1509e-02, -3.1822e-03, -7.2836e-02, -8.4429e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2211], requires_grad=True)\n",
      "bias grad:  tensor([-0.4121])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6606]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3583]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1061,  -322.8745,   -11.4373,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2170], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6248]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1061,  -322.8745,   -11.4373,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.9035e-03,  1.2885e-05,  2.9169e-05,  1.8451e-04, -1.1298e-04,\n",
      "          1.0949e-03,  2.5007e-02,  9.2005e-04,  1.3454e-02,  7.5220e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2170], requires_grad=True)\n",
      "bias grad:  tensor([0.0842])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6248]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0139]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1063,  -322.8745,   -11.4375,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2178], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6262]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1063,  -322.8745,   -11.4375,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0729e-03,  0.0000e+00, -1.0803e-04, -6.5063e-04, -8.4690e-05,\n",
      "         -5.3565e-03, -1.3801e-01, -3.0837e-03, -5.4343e-02, -5.9904e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2178], requires_grad=True)\n",
      "bias grad:  tensor([-0.3418])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6262]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1850]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1050,  -322.8745,   -11.4369,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2144], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5077]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1050,  -322.8745,   -11.4369,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1639e-03,  2.7842e-05, -1.0109e-05,  4.4968e-04,  7.8591e-04,\n",
      "         -3.1897e-03, -6.0474e-02,  2.3764e-05,  1.6811e-02, -4.6306e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2144], requires_grad=True)\n",
      "bias grad:  tensor([0.0783])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5077]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2611]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1044,  -322.8745,   -11.4371,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2152], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5338]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1044,  -322.8745,   -11.4371,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.4003e-03, -7.1963e-05, -6.4839e-05, -7.2265e-04, -1.2020e-04,\n",
      "         -1.9714e-03, -6.6047e-02, -1.6431e-03, -3.4580e-02, -8.6668e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2152], requires_grad=True)\n",
      "bias grad:  tensor([-0.2196])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5338]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8185]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1037,  -322.8745,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2130], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4520]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1037,  -322.8745,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2767e-04, -1.9943e-04, -8.2888e-05, -7.1336e-04, -7.8157e-05,\n",
      "         -4.2905e-03, -1.0148e-01, -2.5626e-03, -4.0883e-02, -4.9769e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2130], requires_grad=True)\n",
      "bias grad:  tensor([-0.2648])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4520]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8316]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1027,  -322.8744,   -11.4364,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2103], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3688]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1027,  -322.8744,   -11.4364,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0056, 0.0000, 0.0003, 0.0032, 0.0008, 0.0020, 0.1309, 0.0062, 0.1694,\n",
      "         0.0036]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2103], requires_grad=True)\n",
      "bias grad:  tensor([0.9706])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3688]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.3970]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1040,  -322.8745,   -11.4380,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2200], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7085]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1040,  -322.8745,   -11.4380,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2778e-03,  1.8656e-05, -9.2467e-05, -1.4150e-03, -1.0167e-03,\n",
      "         -1.2311e-03, -6.8206e-02, -3.4266e-03, -7.4937e-02, -8.4160e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2200], requires_grad=True)\n",
      "bias grad:  tensor([-0.4369])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7085]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3813]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1033,  -322.8745,   -11.4373,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2157], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6704]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1033,  -322.8745,   -11.4373,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7746e-03,  2.9354e-05,  7.0221e-05,  8.0561e-04,  3.5696e-04,\n",
      "          2.7023e-03,  7.4381e-02,  2.4933e-03,  4.1892e-02,  1.4397e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2157], requires_grad=True)\n",
      "bias grad:  tensor([0.2773])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6704]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1857]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1041,  -322.8745,   -11.4377,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2184], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6889]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1041,  -322.8745,   -11.4377,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0030, 0.0000, 0.0001, 0.0012, 0.0008, 0.0006, 0.0878, 0.0036, 0.0784,\n",
      "         0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2184], requires_grad=True)\n",
      "bias grad:  tensor([0.4507])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6889]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1838]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1049,  -322.8745,   -11.4385,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2229], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6706]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1049,  -322.8745,   -11.4385,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1350e-04,  0.0000e+00, -8.4952e-06, -2.6378e-04, -2.4759e-04,\n",
      "          2.1387e-04,  2.7265e-03, -4.3930e-04, -1.0243e-02,  2.7343e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2229], requires_grad=True)\n",
      "bias grad:  tensor([-0.0581])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6706]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1665]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1050,  -322.8745,   -11.4384,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2224], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6539]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1050,  -322.8745,   -11.4384,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9607e-05,  6.5519e-05,  2.6100e-05,  2.5108e-04, -2.4110e-04,\n",
      "          5.2808e-04,  2.2746e-02,  8.4336e-04,  1.7397e-02,  4.8342e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2224], requires_grad=True)\n",
      "bias grad:  tensor([0.1001])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6539]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3012]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1052,  -322.8745,   -11.4386,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2234], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6840]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1052,  -322.8745,   -11.4386,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.2044e-04, -8.7452e-05, -6.7091e-05, -7.9590e-04, -1.1741e-05,\n",
      "         -2.1945e-03, -6.2352e-02, -1.8931e-03, -4.0262e-02, -1.4960e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2234], requires_grad=True)\n",
      "bias grad:  tensor([-0.2294])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6840]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7198]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1046,  -322.8745,   -11.4382,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2211], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6121]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1046,  -322.8745,   -11.4382,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3095e-03,  0.0000e+00,  4.0518e-05,  3.8510e-04,  1.2335e-04,\n",
      "          4.3120e-04,  1.5879e-02,  1.3977e-03,  2.5251e-02,  7.9442e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2211], requires_grad=True)\n",
      "bias grad:  tensor([0.1500])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6121]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0785]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1047,  -322.8745,   -11.4384,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2226], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6199]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1047,  -322.8745,   -11.4384,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1537e-03,  6.4412e-06, -1.7201e-05, -3.6979e-04, -1.3271e-04,\n",
      "          1.2558e-03,  1.1389e-02, -3.7717e-04, -1.8821e-02,  1.8151e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2226], requires_grad=True)\n",
      "bias grad:  tensor([-0.1027])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6199]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3305]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1048,  -322.8745,   -11.4382,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2215], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5869]], requires_grad=True)\n",
      "Iteration 5 | Score: 0.7316675186157227\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0649,  -322.8724,   -11.3933,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[1.0176e-03, 4.0506e-05, 4.9369e-05, 5.5078e-04, 4.3587e-04, 2.4670e-03,\n",
      "         7.0002e-02, 2.1367e-03, 3.5591e-02, 1.2344e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0446], requires_grad=True)\n",
      "bias grad:  tensor([0.2083])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8594]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1869]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0656,  -322.8725,   -11.3936,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0425], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8408]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0656,  -322.8725,   -11.3936,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.4112e-04,  3.6422e-05,  1.3604e-04,  1.3759e-03,  6.1065e-04,\n",
      "          2.0084e-03,  9.1208e-02,  3.9764e-03,  7.8263e-02,  2.4001e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0425], requires_grad=True)\n",
      "bias grad:  tensor([0.4965])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8408]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0814]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0665,  -322.8725,   -11.3944,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0375], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8326]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0665,  -322.8725,   -11.3944,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1135e-03, 0.0000e+00, 5.5514e-05, 6.3198e-04, 6.6495e-04, 1.2013e-03,\n",
      "         5.1035e-02, 2.3031e-03, 4.7113e-02, 1.4965e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0375], requires_grad=True)\n",
      "bias grad:  tensor([0.2663])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8326]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3333]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0670,  -322.8725,   -11.3949,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0349], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7993]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0670,  -322.8725,   -11.3949,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[7.8531e-04, 0.0000e+00, 2.4419e-05, 1.1363e-04, 1.0066e-04, 5.7536e-04,\n",
      "         2.3117e-02, 1.0484e-03, 1.5425e-02, 4.8055e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0349], requires_grad=True)\n",
      "bias grad:  tensor([0.0866])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7993]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5270]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0672,  -322.8725,   -11.3950,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0340], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7466]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0672,  -322.8725,   -11.3950,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0005, 0.0003, 0.0003, 0.0031, 0.0008, 0.0072, 0.2185, 0.0073, 0.1419,\n",
      "         0.0026]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0340], requires_grad=True)\n",
      "bias grad:  tensor([0.8691])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7466]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.1975]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0694,  -322.8726,   -11.3965,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0253], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8663]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0694,  -322.8726,   -11.3965,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0607e-03,  0.0000e+00,  1.4372e-05,  5.0993e-05,  1.5966e-04,\n",
      "          3.8751e-04,  1.5290e-02,  9.2214e-04,  1.0559e-02,  2.0267e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0253], requires_grad=True)\n",
      "bias grad:  tensor([0.0615])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8663]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3670]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0696,  -322.8726,   -11.3966,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0247], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8296]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0696,  -322.8726,   -11.3966,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[1.0816e-03, 4.1821e-05, 9.1333e-05, 1.1686e-03, 6.9402e-04, 1.0501e-03,\n",
      "         5.6877e-02, 2.9523e-03, 6.6672e-02, 1.7396e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0247], requires_grad=True)\n",
      "bias grad:  tensor([0.4012])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8296]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1854]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0701,  -322.8726,   -11.3972,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0207], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8482]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0701,  -322.8726,   -11.3972,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2139e-04, -3.2335e-05,  4.4556e-05,  5.4529e-04,  3.4296e-04,\n",
      "          7.7678e-04,  3.1178e-02,  2.1562e-03,  4.1018e-02,  1.7746e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0207], requires_grad=True)\n",
      "bias grad:  tensor([0.2313])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8482]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6543]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0704,  -322.8727,   -11.3976,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0184], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7827]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0704,  -322.8727,   -11.3976,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[1.3189e-03, 6.8365e-06, 7.9720e-05, 7.0536e-04, 3.3291e-04, 2.7182e-03,\n",
      "         7.2955e-02, 2.4003e-03, 4.9773e-02, 1.4571e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0184], requires_grad=True)\n",
      "bias grad:  tensor([0.2817])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7827]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1787]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0712,  -322.8727,   -11.3981,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0156], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7649]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0712,  -322.8727,   -11.3981,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.0535e-03, -2.7486e-05, -1.1795e-05, -3.0727e-04, -1.6245e-04,\n",
      "         -6.6209e-05, -8.7006e-03, -1.3957e-04, -7.0798e-03,  4.2165e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0156], requires_grad=True)\n",
      "bias grad:  tensor([-0.0425])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7649]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5482]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0711,  -322.8727,   -11.3981,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0160], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7100]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0711,  -322.8727,   -11.3981,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[2.2530e-03, 0.0000e+00, 2.3705e-05, 2.6778e-04, 2.6050e-04, 2.1557e-04,\n",
      "         1.9491e-02, 3.6660e-04, 1.2744e-02, 1.1531e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0160], requires_grad=True)\n",
      "bias grad:  tensor([0.0818])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7100]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2950]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0713,  -322.8727,   -11.3982,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0152], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7395]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0713,  -322.8727,   -11.3982,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[5.4708e-03, 3.3282e-05, 1.1522e-04, 1.4382e-03, 1.0960e-03, 1.6529e-03,\n",
      "         8.2162e-02, 4.1012e-03, 8.9217e-02, 2.8607e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0152], requires_grad=True)\n",
      "bias grad:  tensor([0.5264])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7395]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0587]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0721,  -322.8727,   -11.3991,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0099], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7454]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0721,  -322.8727,   -11.3991,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3748e-02,  0.0000e+00, -1.5206e-06, -3.7100e-04, -5.7554e-04,\n",
      "         -1.8087e-04, -8.4086e-03, -3.7937e-04, -1.5048e-02, -7.2568e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0099], requires_grad=True)\n",
      "bias grad:  tensor([-0.0813])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7454]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2019]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0720,  -322.8727,   -11.3989,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0107], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7252]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0720,  -322.8727,   -11.3989,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.2943e-03,  2.0656e-05,  5.1291e-05,  4.9212e-04,  1.1856e-04,\n",
      "          1.2898e-03,  4.1064e-02,  1.6899e-03,  3.2199e-02,  1.1460e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0107], requires_grad=True)\n",
      "bias grad:  tensor([0.1911])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7252]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0560]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0724,  -322.8727,   -11.3993,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0088], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7196]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0724,  -322.8727,   -11.3993,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.4723e-04,  0.0000e+00, -8.1272e-05, -3.0816e-04,  1.6907e-04,\n",
      "         -5.0001e-03, -1.1557e-01, -2.2480e-03, -3.4071e-02,  2.8112e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0088], requires_grad=True)\n",
      "bias grad:  tensor([-0.2240])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7196]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1749]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0713,  -322.8727,   -11.3989,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0111], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6021]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0713,  -322.8727,   -11.3989,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.3431e-03,  9.7461e-06,  1.8706e-06,  5.0697e-04,  8.3415e-04,\n",
      "         -3.0271e-03, -4.8666e-02,  4.8688e-04,  2.3717e-02, -9.7712e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0111], requires_grad=True)\n",
      "bias grad:  tensor([0.1237])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6021]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2318]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0708,  -322.8727,   -11.3992,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0098], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5790]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0708,  -322.8727,   -11.3992,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.1810e-03, -5.4757e-05, -2.5933e-05, -2.0327e-04,  1.6463e-04,\n",
      "         -1.6326e-03, -4.1423e-02, -3.1098e-04, -5.8614e-03,  1.9615e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0098], requires_grad=True)\n",
      "bias grad:  tensor([-0.0537])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5790]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6457]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0704,  -322.8727,   -11.3991,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0104], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5144]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0704,  -322.8727,   -11.3991,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.6833e-04, -1.9104e-04, -4.0335e-05, -1.9909e-04,  2.7460e-04,\n",
      "         -3.6445e-03, -7.4350e-02, -1.1299e-03, -1.1539e-02,  1.6845e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0104], requires_grad=True)\n",
      "bias grad:  tensor([-0.0847])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5144]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7832]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0696,  -322.8727,   -11.3990,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0112], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4361]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0696,  -322.8727,   -11.3990,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0052, 0.0000, 0.0002, 0.0025, 0.0006, 0.0014, 0.0933, 0.0045, 0.1294,\n",
      "         0.0025]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0112], requires_grad=True)\n",
      "bias grad:  tensor([0.7424])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4361]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.8298]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0706,  -322.8727,   -11.4003,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0038], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7191]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0706,  -322.8727,   -11.4003,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7159e-03,  3.3361e-05, -3.7178e-05, -6.0365e-04, -4.6001e-04,\n",
      "         -4.3761e-04, -2.9502e-02, -1.3331e-03, -3.0147e-02, -1.9498e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0038], requires_grad=True)\n",
      "bias grad:  tensor([-0.1730])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7191]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0865]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0703,  -322.8727,   -11.4000,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0055], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7104]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0703,  -322.8727,   -11.4000,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[7.8211e-04, 4.7491e-05, 1.0558e-04, 1.2952e-03, 6.8287e-04, 3.2673e-03,\n",
      "         9.9618e-02, 3.7850e-03, 6.8868e-02, 2.0846e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0055], requires_grad=True)\n",
      "bias grad:  tensor([0.4425])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7104]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2691]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0713,  -322.8728,   -11.4007,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0011], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7373]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0713,  -322.8728,   -11.4007,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0037, 0.0000, 0.0001, 0.0013, 0.0008, 0.0006, 0.0901, 0.0037, 0.0812,\n",
      "         0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0011], requires_grad=True)\n",
      "bias grad:  tensor([0.4676])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7373]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0873]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0722,  -322.8728,   -11.4015,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0036], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7286]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0722,  -322.8728,   -11.4015,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[4.3262e-04, 0.0000e+00, 1.5458e-05, 5.7022e-05, 7.3028e-06, 4.3119e-04,\n",
      "         1.7294e-02, 5.2992e-04, 9.4723e-03, 5.8972e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0036], requires_grad=True)\n",
      "bias grad:  tensor([0.0538])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7286]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2578]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0723,  -322.8728,   -11.4016,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0041], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7028]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0723,  -322.8728,   -11.4016,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[9.0266e-04, 8.7501e-05, 5.1824e-05, 5.9779e-04, 3.7713e-05, 9.1673e-04,\n",
      "         3.9790e-02, 1.8498e-03, 3.8854e-02, 1.0690e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0041], requires_grad=True)\n",
      "bias grad:  tensor([0.2239])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7028]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1839]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0727,  -322.8728,   -11.4020,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0064], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7212]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0727,  -322.8728,   -11.4020,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3923e-03, -8.9711e-05, -4.7222e-05, -5.3217e-04,  7.2691e-05,\n",
      "         -1.8357e-03, -4.8863e-02, -1.3292e-03, -2.7040e-02, -2.0448e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0064], requires_grad=True)\n",
      "bias grad:  tensor([-0.1532])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7212]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5633]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0722,  -322.8728,   -11.4017,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0048], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6649]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0722,  -322.8728,   -11.4017,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.6285e-04,  0.0000e+00,  6.4720e-05,  7.5297e-04,  4.3167e-04,\n",
      "          7.1475e-04,  3.5656e-02,  2.3725e-03,  4.7026e-02,  1.2033e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0048], requires_grad=True)\n",
      "bias grad:  tensor([0.2762])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6649]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0205]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0726,  -322.8729,   -11.4022,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0076], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6669]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0726,  -322.8729,   -11.4022,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7443e-04, 1.1742e-05, 2.6989e-05, 1.3413e-04, 1.5772e-04, 2.2045e-03,\n",
      "         4.8905e-02, 1.0509e-03, 9.8692e-03, 1.0487e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0076], requires_grad=True)\n",
      "bias grad:  tensor([0.0769])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6669]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3343]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0731,  -322.8729,   -11.4023,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0084], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6335]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0731,  -322.8729,   -11.4023,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[1.8905e-03, 2.8879e-05, 6.9560e-05, 8.3234e-04, 5.2387e-04, 2.6704e-03,\n",
      "         8.0388e-02, 2.5928e-03, 4.9905e-02, 1.4107e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0084], requires_grad=True)\n",
      "bias grad:  tensor([0.2904])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6335]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1262]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0739,  -322.8729,   -11.4028,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0113], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6461]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0739,  -322.8729,   -11.4028,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[2.6541e-04, 3.1437e-05, 1.5761e-04, 1.6271e-03, 6.9059e-04, 2.3142e-03,\n",
      "         1.0409e-01, 4.4263e-03, 9.1333e-02, 2.5100e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0113], requires_grad=True)\n",
      "bias grad:  tensor([0.5726])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6461]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2060]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0749,  -322.8729,   -11.4037,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0170], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6667]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0749,  -322.8729,   -11.4037,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2692e-03, 0.0000e+00, 9.9454e-05, 1.2168e-03, 9.5353e-04, 1.4855e-03,\n",
      "         7.1652e-02, 3.5046e-03, 7.8088e-02, 2.3298e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0170], requires_grad=True)\n",
      "bias grad:  tensor([0.4455])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6667]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1617]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0756,  -322.8730,   -11.4044,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0215], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6829]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0756,  -322.8730,   -11.4044,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6522e-03, 0.0000e+00, 5.1741e-05, 5.4307e-04, 3.5128e-04, 9.1032e-04,\n",
      "         4.0654e-02, 2.1206e-03, 3.6934e-02, 7.2262e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0215], requires_grad=True)\n",
      "bias grad:  tensor([0.2133])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6829]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2323]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0761,  -322.8730,   -11.4048,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0236], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6596]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0761,  -322.8730,   -11.4048,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0016, 0.0003, 0.0003, 0.0032, 0.0008, 0.0076, 0.2256, 0.0073, 0.1411,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0236], requires_grad=True)\n",
      "bias grad:  tensor([0.8702])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6596]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6247]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0783,  -322.8730,   -11.4062,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0323], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8221]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0783,  -322.8730,   -11.4062,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0798e-03,  0.0000e+00,  1.2542e-05, -3.9372e-05,  3.0261e-06,\n",
      "          5.5803e-04,  1.4160e-02,  6.9020e-04,  5.5865e-03,  1.8895e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0323], requires_grad=True)\n",
      "bias grad:  tensor([0.0324])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8221]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2944]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0784,  -322.8730,   -11.4063,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0326], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7927]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0784,  -322.8730,   -11.4063,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[4.1427e-04, 5.2710e-05, 8.7493e-05, 1.1206e-03, 6.8704e-04, 1.0359e-03,\n",
      "         5.7183e-02, 2.9555e-03, 6.5114e-02, 1.8750e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0326], requires_grad=True)\n",
      "bias grad:  tensor([0.3897])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7927]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1113]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0790,  -322.8731,   -11.4069,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0365], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8038]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0790,  -322.8731,   -11.4069,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.1248e-04, -2.2369e-05,  4.1883e-05,  5.2559e-04,  2.7873e-04,\n",
      "          5.9333e-04,  2.7614e-02,  1.9493e-03,  3.8202e-02,  1.6002e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0365], requires_grad=True)\n",
      "bias grad:  tensor([0.2155])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8038]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5448]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0793,  -322.8731,   -11.4073,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0387], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7493]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0793,  -322.8731,   -11.4073,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[4.8188e-04, 1.2623e-05, 6.6847e-05, 5.5824e-04, 2.1092e-04, 2.3709e-03,\n",
      "         6.1695e-02, 1.9705e-03, 4.0602e-02, 1.2958e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0387], requires_grad=True)\n",
      "bias grad:  tensor([0.2296])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7493]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1467]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0799,  -322.8731,   -11.4077,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0410], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7347]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0799,  -322.8731,   -11.4077,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.2208e-03, -2.8191e-05, -1.7914e-05, -4.2568e-04, -3.3997e-04,\n",
      "         -1.9827e-04, -1.2877e-02, -4.6615e-04, -1.4390e-02,  3.3244e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0410], requires_grad=True)\n",
      "bias grad:  tensor([-0.0826])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7347]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5374]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8731,   -11.4076,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0401], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6809]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8731,   -11.4076,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3769e-03,  0.0000e+00, -1.1846e-06, -5.2967e-05,  4.6590e-05,\n",
      "          2.0123e-05,  4.5973e-03, -4.8684e-04, -6.4193e-03, -3.6459e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0401], requires_grad=True)\n",
      "bias grad:  tensor([-0.0307])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6809]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2841]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8731,   -11.4075,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0398], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7093]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8731,   -11.4075,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[5.3856e-03, 3.5371e-05, 1.0763e-04, 1.3769e-03, 1.0689e-03, 1.2745e-03,\n",
      "         7.3120e-02, 3.9056e-03, 8.5312e-02, 2.7021e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0398], requires_grad=True)\n",
      "bias grad:  tensor([0.5027])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7093]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0649]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0806,  -322.8732,   -11.4084,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0449], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7158]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0806,  -322.8732,   -11.4084,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6564e-02,  0.0000e+00, -1.5980e-05, -6.2049e-04, -8.7083e-04,\n",
      "         -3.5527e-04, -1.6284e-02, -1.0120e-03, -2.8835e-02, -2.4347e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0449], requires_grad=True)\n",
      "bias grad:  tensor([-0.1598])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7158]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2504]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0804,  -322.8732,   -11.4081,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0433], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6908]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0804,  -322.8732,   -11.4081,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7681e-03,  1.6172e-05,  3.7731e-05,  2.9587e-04,  2.6158e-05,\n",
      "          1.2980e-03,  3.5769e-02,  1.2364e-03,  2.1054e-02,  8.7875e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0433], requires_grad=True)\n",
      "bias grad:  tensor([0.1270])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6908]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1105]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0808,  -322.8732,   -11.4083,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0445], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6797]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0808,  -322.8732,   -11.4083,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.4698e-05,  0.0000e+00, -9.8600e-05, -5.4986e-04,  2.4603e-05,\n",
      "         -5.0438e-03, -1.2506e-01, -2.8829e-03, -4.8433e-02, -1.0869e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0445], requires_grad=True)\n",
      "bias grad:  tensor([-0.3072])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6797]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1972]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0795,  -322.8731,   -11.4078,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0415], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5600]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0795,  -322.8731,   -11.4078,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.4749e-03,  2.0565e-05, -1.6529e-05,  3.4937e-04,  7.6088e-04,\n",
      "         -3.3236e-03, -6.4400e-02, -1.1536e-04,  1.2758e-02, -5.5787e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0415], requires_grad=True)\n",
      "bias grad:  tensor([0.0548])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5600]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0102]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0789,  -322.8731,   -11.4079,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0420], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5610]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0789,  -322.8731,   -11.4079,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.8107e-03, -5.8949e-05, -4.0629e-05, -3.9339e-04,  4.4323e-06,\n",
      "         -1.7019e-03, -5.0683e-02, -7.9927e-04, -1.6732e-02,  3.1397e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0420], requires_grad=True)\n",
      "bias grad:  tensor([-0.1162])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5610]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7367]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0784,  -322.8731,   -11.4078,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0408], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4874]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0784,  -322.8731,   -11.4078,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.2534e-03, -1.9163e-04, -6.1295e-05, -4.0759e-04,  1.8735e-04,\n",
      "         -3.8397e-03, -8.7531e-02, -1.8600e-03, -2.5631e-02, -4.5524e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0408], requires_grad=True)\n",
      "bias grad:  tensor([-0.1699])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4874]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7022]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0775,  -322.8731,   -11.4075,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0391], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4171]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0775,  -322.8731,   -11.4075,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0055, 0.0000, 0.0002, 0.0026, 0.0006, 0.0014, 0.0928, 0.0046, 0.1336,\n",
      "         0.0026]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0391], requires_grad=True)\n",
      "bias grad:  tensor([0.7667])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4171]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.1661]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8732,   -11.4088,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0468], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7337]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8732,   -11.4088,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.0207e-03,  2.3158e-05, -5.6459e-05, -8.7243e-04, -6.4465e-04,\n",
      "         -8.4360e-04, -4.5241e-02, -2.0234e-03, -4.4519e-02, -4.4956e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0468], requires_grad=True)\n",
      "bias grad:  tensor([-0.2610])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7337]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1907]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0780,  -322.8731,   -11.4084,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0442], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7147]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0780,  -322.8731,   -11.4084,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.0945e-04,  3.8655e-05,  7.7418e-05,  9.2359e-04,  4.2874e-04,\n",
      "          2.9043e-03,  8.0997e-02,  2.7763e-03,  4.9716e-02,  1.5002e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0442], requires_grad=True)\n",
      "bias grad:  tensor([0.3159])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7147]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2272]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0788,  -322.8732,   -11.4089,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0474], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7374]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0788,  -322.8732,   -11.4089,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6296e-03, 0.0000e+00, 7.0930e-05, 9.9234e-04, 7.2476e-04, 4.0811e-04,\n",
      "         4.4342e-02, 2.6345e-03, 6.0498e-02, 1.2208e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0474], requires_grad=True)\n",
      "bias grad:  tensor([0.3519])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7374]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0100]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0792,  -322.8732,   -11.4095,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0509], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7364]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0792,  -322.8732,   -11.4095,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1274e-05, 0.0000e+00, 1.8930e-05, 1.0057e-04, 1.1967e-05, 4.0112e-04,\n",
      "         1.8491e-02, 6.5727e-04, 1.1613e-02, 6.1675e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0509], requires_grad=True)\n",
      "bias grad:  tensor([0.0661])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7364]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2774]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0794,  -322.8732,   -11.4096,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0515], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7087]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0794,  -322.8732,   -11.4096,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[9.0791e-04, 9.0346e-05, 5.4030e-05, 6.5311e-04, 7.5596e-05, 1.0355e-03,\n",
      "         4.3445e-02, 1.9741e-03, 4.0777e-02, 1.0131e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0515], requires_grad=True)\n",
      "bias grad:  tensor([0.2343])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7087]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2672]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8732,   -11.4100,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0539], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7354]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8732,   -11.4100,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.0853e-04, -8.7952e-05, -5.0602e-05, -6.2039e-04, -3.8288e-06,\n",
      "         -1.8339e-03, -4.9923e-02, -1.3806e-03, -2.9111e-02, -3.0028e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0539], requires_grad=True)\n",
      "bias grad:  tensor([-0.1674])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7354]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7148]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0793,  -322.8732,   -11.4097,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0522], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6639]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0793,  -322.8732,   -11.4097,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.7039e-05,  0.0000e+00,  7.4828e-05,  8.9634e-04,  5.1551e-04,\n",
      "          7.2743e-04,  4.0577e-02,  2.7890e-03,  5.5650e-02,  1.4129e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0522], requires_grad=True)\n",
      "bias grad:  tensor([0.3247])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6639]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0308]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0797,  -322.8733,   -11.4103,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0555], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6670]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0797,  -322.8733,   -11.4103,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0291e-03, 1.3176e-05, 1.6076e-05, 1.0632e-04, 2.7478e-04, 1.5189e-03,\n",
      "         3.4629e-02, 8.3195e-04, 9.1316e-03, 8.5084e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0555], requires_grad=True)\n",
      "bias grad:  tensor([0.0611])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6670]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3500]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0801,  -322.8733,   -11.4104,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0561], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6320]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0801,  -322.8733,   -11.4104,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[1.8998e-03, 3.8216e-05, 5.5360e-05, 6.2336e-04, 4.4109e-04, 2.2570e-03,\n",
      "         6.6097e-02, 2.0704e-03, 3.7864e-02, 1.3255e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0561], requires_grad=True)\n",
      "bias grad:  tensor([0.2238])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6320]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0190]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0807,  -322.8733,   -11.4108,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0583], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6339]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0807,  -322.8733,   -11.4108,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7446e-04, 4.3239e-05, 1.3652e-04, 1.4382e-03, 5.9172e-04, 2.0629e-03,\n",
      "         9.0219e-02, 3.8198e-03, 8.0662e-02, 2.2405e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0583], requires_grad=True)\n",
      "bias grad:  tensor([0.5014])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6339]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2464]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0816,  -322.8733,   -11.4116,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0633], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6585]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0816,  -322.8733,   -11.4116,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[5.1601e-03, 0.0000e+00, 7.7568e-05, 9.7973e-04, 7.6373e-04, 1.2307e-03,\n",
      "         5.8553e-02, 2.5757e-03, 6.0740e-02, 1.4187e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0633], requires_grad=True)\n",
      "bias grad:  tensor([0.3452])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6585]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2841]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0822,  -322.8734,   -11.4122,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0668], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6869]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0822,  -322.8734,   -11.4122,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[2.3007e-03, 0.0000e+00, 3.0431e-05, 2.8007e-04, 2.9170e-04, 6.3054e-04,\n",
      "         2.8739e-02, 1.4447e-03, 2.2129e-02, 3.0912e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0668], requires_grad=True)\n",
      "bias grad:  tensor([0.1285])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6869]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2665]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0825,  -322.8734,   -11.4124,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0681], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6603]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0825,  -322.8734,   -11.4124,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0016, 0.0003, 0.0003, 0.0031, 0.0008, 0.0075, 0.2217, 0.0071, 0.1395,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0681], requires_grad=True)\n",
      "bias grad:  tensor([0.8591])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6603]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5571]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0847,  -322.8734,   -11.4138,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0766], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8160]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0847,  -322.8734,   -11.4138,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2305e-03,  0.0000e+00,  1.9134e-06, -1.3779e-04, -6.2383e-06,\n",
      "          2.7103e-04,  5.7775e-03,  3.2648e-04, -1.2014e-03,  2.1773e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0766], requires_grad=True)\n",
      "bias grad:  tensor([-0.0071])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8160]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2486]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0848,  -322.8734,   -11.4138,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0766], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7912]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0848,  -322.8734,   -11.4138,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7081e-04, 4.8097e-05, 8.8208e-05, 1.1190e-03, 7.4362e-04, 9.9088e-04,\n",
      "         5.4766e-02, 2.9109e-03, 6.5813e-02, 1.9689e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0766], requires_grad=True)\n",
      "bias grad:  tensor([0.3940])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7912]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0799]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0853,  -322.8734,   -11.4144,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0805], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7991]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0853,  -322.8734,   -11.4144,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.1458e-04, -1.8574e-05,  4.4097e-05,  5.3305e-04,  2.9872e-04,\n",
      "          7.1060e-04,  3.0376e-02,  2.0617e-03,  3.9612e-02,  1.7155e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0805], requires_grad=True)\n",
      "bias grad:  tensor([0.2235])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7991]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5725]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0856,  -322.8735,   -11.4148,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0827], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7419]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0856,  -322.8735,   -11.4148,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[6.7914e-04, 4.4006e-06, 6.9014e-05, 5.9745e-04, 2.6749e-04, 2.4825e-03,\n",
      "         6.6165e-02, 2.0852e-03, 4.2277e-02, 1.2812e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0827], requires_grad=True)\n",
      "bias grad:  tensor([0.2397])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7419]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1306]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0863,  -322.8735,   -11.4153,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0851], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7288]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0863,  -322.8735,   -11.4153,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.1635e-03, -2.4240e-05, -2.5136e-05, -4.6794e-04, -2.1215e-04,\n",
      "         -1.7686e-04, -1.5744e-02, -4.8758e-04, -1.6508e-02,  2.7191e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0851], requires_grad=True)\n",
      "bias grad:  tensor([-0.0985])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7288]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5883]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0861,  -322.8735,   -11.4151,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0842], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6700]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0861,  -322.8735,   -11.4151,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6140e-03,  0.0000e+00,  3.3097e-06,  1.7725e-05,  1.3003e-04,\n",
      "          3.1547e-05,  7.0616e-03, -2.5328e-04, -1.7693e-03, -2.5351e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0842], requires_grad=True)\n",
      "bias grad:  tensor([-0.0036])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6700]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2750]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0862,  -322.8735,   -11.4151,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0841], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6975]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0862,  -322.8735,   -11.4151,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[3.9574e-03, 2.6289e-05, 1.0450e-04, 1.3247e-03, 1.0722e-03, 1.4641e-03,\n",
      "         7.8519e-02, 4.0248e-03, 8.3080e-02, 2.8542e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0841], requires_grad=True)\n",
      "bias grad:  tensor([0.4925])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6975]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0286]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0870,  -322.8735,   -11.4159,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0890], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6946]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0870,  -322.8735,   -11.4159,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6693e-02,  0.0000e+00, -1.0976e-05, -5.6242e-04, -8.1329e-04,\n",
      "         -3.0824e-04, -1.4180e-02, -8.1871e-04, -2.5179e-02, -1.8880e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0890], requires_grad=True)\n",
      "bias grad:  tensor([-0.1386])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6946]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3066]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0869,  -322.8735,   -11.4157,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0877], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6640]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0869,  -322.8735,   -11.4157,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.5681e-03,  3.4332e-05,  4.7895e-05,  3.9484e-04,  1.3739e-05,\n",
      "          1.2923e-03,  3.6198e-02,  1.5197e-03,  2.7415e-02,  1.2218e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0877], requires_grad=True)\n",
      "bias grad:  tensor([0.1637])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6640]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0727]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0872,  -322.8735,   -11.4159,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0893], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6567]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0872,  -322.8735,   -11.4159,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9799e-04,  0.0000e+00, -1.0244e-04, -5.5630e-04,  3.1651e-06,\n",
      "         -5.3056e-03, -1.3225e-01, -2.9049e-03, -4.9703e-02, -4.2979e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0893], requires_grad=True)\n",
      "bias grad:  tensor([-0.3148])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6567]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1772]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0859,  -322.8735,   -11.4154,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0862], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5390]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0859,  -322.8735,   -11.4154,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.5447e-03,  3.0667e-05, -1.3983e-05,  4.3391e-04,  8.2684e-04,\n",
      "         -3.3324e-03, -6.2844e-02, -6.3633e-05,  1.5318e-02, -5.4723e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0862], requires_grad=True)\n",
      "bias grad:  tensor([0.0702])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5390]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3011]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0853,  -322.8735,   -11.4156,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0869], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5691]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0853,  -322.8735,   -11.4156,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.8139e-03, -6.3035e-05, -4.9025e-05, -5.0636e-04,  1.6659e-05,\n",
      "         -1.9019e-03, -5.6400e-02, -1.1160e-03, -2.3045e-02, -6.8407e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0869], requires_grad=True)\n",
      "bias grad:  tensor([-0.1520])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5691]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7880]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0847,  -322.8735,   -11.4154,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0853], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4903]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0847,  -322.8735,   -11.4154,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.4233e-04, -1.8971e-04, -5.9672e-05, -4.9977e-04, -2.8460e-05,\n",
      "         -3.9007e-03, -8.8126e-02, -1.9726e-03, -2.9292e-02, -1.5095e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0853], requires_grad=True)\n",
      "bias grad:  tensor([-0.1907])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4903]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7844]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0838,  -322.8735,   -11.4151,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0834], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4119]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0838,  -322.8735,   -11.4151,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0054, 0.0000, 0.0002, 0.0027, 0.0005, 0.0016, 0.1020, 0.0049, 0.1398,\n",
      "         0.0029]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0834], requires_grad=True)\n",
      "bias grad:  tensor([0.8023])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4119]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.2199]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0848,  -322.8735,   -11.4165,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0915], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7339]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0848,  -322.8735,   -11.4165,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.9017e-03,  2.1393e-05, -6.2530e-05, -9.7840e-04, -7.2688e-04,\n",
      "         -8.4553e-04, -4.7304e-02, -2.2638e-03, -5.0327e-02, -4.5016e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0915], requires_grad=True)\n",
      "bias grad:  tensor([-0.2932])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7339]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2584]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0844,  -322.8735,   -11.4160,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0885], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7080]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0844,  -322.8735,   -11.4160,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1244e-03,  3.8908e-05,  6.9796e-05,  8.1765e-04,  4.2196e-04,\n",
      "          2.5344e-03,  7.1192e-02,  2.4898e-03,  4.5867e-02,  1.3221e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0885], requires_grad=True)\n",
      "bias grad:  tensor([0.2849])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7080]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1812]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0851,  -322.8735,   -11.4164,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0914], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7261]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0851,  -322.8735,   -11.4164,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4511e-03, 0.0000e+00, 5.4641e-05, 7.7143e-04, 5.7064e-04, 2.2796e-04,\n",
      "         3.5489e-02, 2.0098e-03, 4.6939e-02, 9.6765e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0914], requires_grad=True)\n",
      "bias grad:  tensor([0.2735])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7261]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0039]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0854,  -322.8736,   -11.4169,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0941], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7265]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0854,  -322.8736,   -11.4169,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8127e-04,  0.0000e+00,  2.1136e-05,  9.3807e-05, -2.9790e-05,\n",
      "          3.9527e-04,  1.9166e-02,  6.8050e-04,  1.1870e-02,  6.7886e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0941], requires_grad=True)\n",
      "bias grad:  tensor([0.0679])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7265]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3040]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0856,  -322.8736,   -11.4170,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0948], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6961]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0856,  -322.8736,   -11.4170,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.5561e-04,  6.6425e-05,  3.5442e-05,  3.8071e-04, -1.1265e-04,\n",
      "          6.9786e-04,  3.0113e-02,  1.2319e-03,  2.5432e-02,  7.0975e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0948], requires_grad=True)\n",
      "bias grad:  tensor([0.1466])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6961]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1815]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0859,  -322.8736,   -11.4173,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0962], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7143]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0859,  -322.8736,   -11.4173,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3820e-03, -7.9758e-05, -4.5437e-05, -5.2984e-04,  7.0860e-05,\n",
      "         -1.7885e-03, -4.7550e-02, -1.3085e-03, -2.6368e-02,  3.3950e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0962], requires_grad=True)\n",
      "bias grad:  tensor([-0.1487])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7143]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6088]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0855,  -322.8736,   -11.4170,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0948], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6534]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0855,  -322.8736,   -11.4170,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.7776e-04,  0.0000e+00,  8.1050e-05,  9.2364e-04,  5.2893e-04,\n",
      "          1.0568e-03,  4.9407e-02,  2.9402e-03,  5.7585e-02,  1.5172e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0948], requires_grad=True)\n",
      "bias grad:  tensor([0.3412])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6534]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0087]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0860,  -322.8736,   -11.4176,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0982], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6525]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0860,  -322.8736,   -11.4176,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0770e-03,  1.4628e-05,  7.8346e-06, -8.7951e-05, -4.3603e-06,\n",
      "          1.5223e-03,  2.7123e-02,  3.8804e-04, -2.1353e-03,  7.2194e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0982], requires_grad=True)\n",
      "bias grad:  tensor([-0.0009])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6525]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3742]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0862,  -322.8736,   -11.4176,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0982], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6151]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0862,  -322.8736,   -11.4176,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4140e-03, 3.8481e-05, 7.1238e-05, 8.0721e-04, 4.8721e-04, 2.5243e-03,\n",
      "         7.5482e-02, 2.4639e-03, 4.7402e-02, 1.4754e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0982], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias grad:  tensor([0.2796])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6151]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1858]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0870,  -322.8736,   -11.4180,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1010], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6337]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0870,  -322.8736,   -11.4180,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7428e-04, 2.7889e-05, 1.3537e-04, 1.4078e-03, 5.9556e-04, 1.9998e-03,\n",
      "         8.9092e-02, 3.7864e-03, 7.9047e-02, 2.1592e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1010], requires_grad=True)\n",
      "bias grad:  tensor([0.4941])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6337]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2123]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0879,  -322.8737,   -11.4188,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1059], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6549]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0879,  -322.8737,   -11.4188,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[4.8331e-03, 0.0000e+00, 9.3014e-05, 1.1566e-03, 9.6651e-04, 1.2188e-03,\n",
      "         6.5008e-02, 3.3476e-03, 7.4653e-02, 2.1949e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1059], requires_grad=True)\n",
      "bias grad:  tensor([0.4262])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6549]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0903]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0885,  -322.8737,   -11.4196,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1102], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6639]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0885,  -322.8737,   -11.4196,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5601e-03, 0.0000e+00, 3.9977e-05, 4.0801e-04, 2.8865e-04, 5.2138e-04,\n",
      "         2.8821e-02, 1.6870e-03, 2.9721e-02, 6.1750e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1102], requires_grad=True)\n",
      "bias grad:  tensor([0.1704])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6639]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2234]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0888,  -322.8737,   -11.4199,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1119], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6416]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0888,  -322.8737,   -11.4199,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0010, 0.0003, 0.0003, 0.0032, 0.0008, 0.0077, 0.2287, 0.0073, 0.1398,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1119], requires_grad=True)\n",
      "bias grad:  tensor([0.8640])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6416]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6706]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0911,  -322.8738,   -11.4213,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1205], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8087]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0911,  -322.8738,   -11.4213,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6018e-03,  0.0000e+00,  3.8747e-06, -1.3176e-04, -1.2500e-06,\n",
      "          3.4997e-04,  7.9471e-03,  4.3140e-04,  1.3370e-04,  5.5384e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1205], requires_grad=True)\n",
      "bias grad:  tensor([-0.0014])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8087]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2901]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0912,  -322.8738,   -11.4213,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1205], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7797]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0912,  -322.8738,   -11.4213,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[6.0822e-05, 3.2127e-05, 8.6918e-05, 1.1096e-03, 8.3991e-04, 9.8833e-04,\n",
      "         5.6264e-02, 2.8837e-03, 6.6854e-02, 2.1823e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1205], requires_grad=True)\n",
      "bias grad:  tensor([0.3988])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7797]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0344]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0917,  -322.8738,   -11.4219,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1245], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7831]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0917,  -322.8738,   -11.4219,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0795e-03, -2.5594e-05,  2.7492e-05,  3.0238e-04,  7.1315e-05,\n",
      "          5.5494e-04,  2.1597e-02,  1.4539e-03,  2.5815e-02,  1.4341e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1245], requires_grad=True)\n",
      "bias grad:  tensor([0.1443])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7831]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5894]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0920,  -322.8738,   -11.4222,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1259], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7241]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0920,  -322.8738,   -11.4222,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 9.1674e-05, -6.3353e-06,  5.0626e-05,  3.8083e-04,  8.0135e-05,\n",
      "          2.1472e-03,  5.1844e-02,  1.4265e-03,  2.8100e-02,  8.9391e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1259], requires_grad=True)\n",
      "bias grad:  tensor([0.1588])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7241]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0070]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0925,  -322.8738,   -11.4225,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1275], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7234]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0925,  -322.8738,   -11.4225,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.9739e-03, -2.6921e-05, -3.7944e-05, -6.8885e-04, -4.2866e-04,\n",
      "         -3.5374e-04, -2.5438e-02, -1.0039e-03, -2.8413e-02,  1.3219e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1275], requires_grad=True)\n",
      "bias grad:  tensor([-0.1663])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7234]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6259]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0922,  -322.8738,   -11.4222,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1258], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6609]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0922,  -322.8738,   -11.4222,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.0174e-03,  0.0000e+00,  5.9660e-06,  1.9260e-05,  9.4870e-05,\n",
      "          1.0212e-04,  9.9692e-03, -2.0006e-04, -1.4540e-03, -1.7222e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1258], requires_grad=True)\n",
      "bias grad:  tensor([-0.0009])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6609]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2135]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0923,  -322.8738,   -11.4222,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1258], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6822]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0923,  -322.8738,   -11.4222,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[4.9520e-03, 3.3998e-05, 9.6561e-05, 1.2255e-03, 9.6127e-04, 1.3287e-03,\n",
      "         6.9434e-02, 3.4992e-03, 7.5792e-02, 2.5142e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1258], requires_grad=True)\n",
      "bias grad:  tensor([0.4475])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6822]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1584]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0930,  -322.8738,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1303], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6980]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0930,  -322.8738,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0568e-02,  0.0000e+00, -7.0299e-05, -1.3893e-03, -1.7141e-03,\n",
      "         -9.3102e-04, -4.2167e-02, -3.2357e-03, -7.3987e-02, -8.5881e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1303], requires_grad=True)\n",
      "bias grad:  tensor([-0.4187])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6980]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2874]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0926,  -322.8738,   -11.4222,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1261], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6693]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0926,  -322.8738,   -11.4222,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.1714e-03,  9.9508e-06,  3.0314e-05,  1.3878e-04, -1.5403e-04,\n",
      "          1.0960e-03,  2.4367e-02,  9.7317e-04,  1.2540e-02,  8.3569e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1261], requires_grad=True)\n",
      "bias grad:  tensor([0.0794])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6693]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1545]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0928,  -322.8738,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1269], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6539]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0928,  -322.8738,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3294e-03,  0.0000e+00, -1.3721e-04, -1.0121e-03, -3.4756e-04,\n",
      "         -5.7575e-03, -1.5692e-01, -4.2264e-03, -7.8389e-02, -6.3793e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1269], requires_grad=True)\n",
      "bias grad:  tensor([-0.4815])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6539]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1215]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0913,  -322.8738,   -11.4215,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1221], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5417]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0913,  -322.8738,   -11.4215,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1265e-03,  2.9120e-05, -1.5645e-05,  3.8112e-04,  7.2538e-04,\n",
      "         -3.2789e-03, -6.3076e-02, -1.6334e-04,  1.2220e-02, -5.2360e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1221], requires_grad=True)\n",
      "bias grad:  tensor([0.0569])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5417]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1587]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0906,  -322.8738,   -11.4216,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1227], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5576]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0906,  -322.8738,   -11.4216,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.6109e-03, -6.8851e-05, -4.7953e-05, -5.0255e-04,  6.1833e-05,\n",
      "         -2.1412e-03, -5.9383e-02, -1.0246e-03, -2.1535e-02,  8.4854e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1227], requires_grad=True)\n",
      "bias grad:  tensor([-0.1461])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5576]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8890]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0900,  -322.8738,   -11.4214,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1212], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4687]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0900,  -322.8738,   -11.4214,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.9264e-05, -1.9727e-04, -8.5360e-05, -7.3460e-04, -1.0521e-04,\n",
      "         -4.2078e-03, -1.0280e-01, -2.6991e-03, -4.4618e-02, -6.3413e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1212], requires_grad=True)\n",
      "bias grad:  tensor([-0.2799])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4687]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7290]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0890,  -322.8737,   -11.4210,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1184], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3958]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0890,  -322.8737,   -11.4210,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0056, 0.0000, 0.0002, 0.0028, 0.0006, 0.0016, 0.1015, 0.0051, 0.1445,\n",
      "         0.0028]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1184], requires_grad=True)\n",
      "bias grad:  tensor([0.8297])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3958]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.5019]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0900,  -322.8738,   -11.4224,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1267], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7460]], requires_grad=True)\n",
      "Iteration 6 | Score: 0.2741817831993103\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0900,  -322.8738,   -11.4224,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.7099e-03,  2.5196e-05, -6.2257e-05, -1.0159e-03, -7.4428e-04,\n",
      "         -6.9695e-04, -4.6558e-02, -2.2940e-03, -5.1725e-02, -3.9786e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1267], requires_grad=True)\n",
      "bias grad:  tensor([-0.2986])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7460]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2999]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0896,  -322.8738,   -11.4219,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1237], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7160]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0896,  -322.8738,   -11.4219,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.7746e-04,  4.0211e-05,  7.2513e-05,  8.6778e-04,  4.3755e-04,\n",
      "          2.6661e-03,  7.5169e-02,  2.5592e-03,  4.6522e-02,  1.4411e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1237], requires_grad=True)\n",
      "bias grad:  tensor([0.2978])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7160]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2267]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0903,  -322.8738,   -11.4224,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1267], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7386]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0903,  -322.8738,   -11.4224,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3134e-03, 0.0000e+00, 5.8009e-05, 8.2201e-04, 5.6843e-04, 1.9501e-04,\n",
      "         3.6130e-02, 2.1474e-03, 5.0196e-02, 1.0131e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1267], requires_grad=True)\n",
      "bias grad:  tensor([0.2916])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7386]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0043]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0907,  -322.8738,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1296], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7391]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0907,  -322.8738,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1047e-03,  0.0000e+00,  1.3576e-06, -1.6819e-04, -1.9011e-04,\n",
      "          2.4178e-04,  7.1172e-03, -5.7286e-05, -3.8518e-03,  4.3039e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1296], requires_grad=True)\n",
      "bias grad:  tensor([-0.0219])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7391]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3658]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0907,  -322.8738,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1294], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7025]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0907,  -322.8738,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.2387e-05,  5.9555e-05,  2.9244e-05,  2.8021e-04, -1.4543e-04,\n",
      "          5.0331e-04,  2.2695e-02,  9.8684e-04,  2.0395e-02,  6.2503e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1294], requires_grad=True)\n",
      "bias grad:  tensor([0.1170])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7025]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1180]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0910,  -322.8738,   -11.4230,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1306], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7143]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0910,  -322.8738,   -11.4230,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.7102e-04, -8.9365e-05, -5.8927e-05, -6.9421e-04, -1.1772e-08,\n",
      "         -1.9057e-03, -5.3695e-02, -1.6600e-03, -3.5177e-02, -1.7602e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1306], requires_grad=True)\n",
      "bias grad:  tensor([-0.2001])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7143]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6007]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8738,   -11.4227,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1286], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6542]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8738,   -11.4227,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1765e-03,  0.0000e+00,  4.6133e-05,  5.8637e-04,  3.2190e-04,\n",
      "          2.6030e-04,  2.1483e-02,  1.8289e-03,  3.6926e-02,  8.6051e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1286], requires_grad=True)\n",
      "bias grad:  tensor([0.2091])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6542]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0539]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0906,  -322.8738,   -11.4231,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1307], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6596]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0906,  -322.8738,   -11.4231,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2797e-03,  5.2355e-06, -9.5173e-06, -2.9171e-04, -8.7203e-05,\n",
      "          1.3195e-03,  1.6488e-02, -1.1921e-04, -1.3945e-02,  3.5809e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1307], requires_grad=True)\n",
      "bias grad:  tensor([-0.0707])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6596]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4114]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0908,  -322.8738,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1300], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6185]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0908,  -322.8738,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[1.4439e-03, 2.9756e-05, 3.0480e-05, 2.8085e-04, 1.4163e-04, 1.8795e-03,\n",
      "         4.7569e-02, 1.0671e-03, 1.6134e-02, 8.2069e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1300], requires_grad=True)\n",
      "bias grad:  tensor([0.1011])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6185]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1248]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0913,  -322.8738,   -11.4231,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1310], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6310]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0913,  -322.8738,   -11.4231,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[4.4104e-05, 3.7502e-05, 1.2461e-04, 1.3070e-03, 5.7853e-04, 1.9690e-03,\n",
      "         8.4392e-02, 3.6769e-03, 7.3838e-02, 2.1363e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1310], requires_grad=True)\n",
      "bias grad:  tensor([0.4645])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6310]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1338]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0921,  -322.8739,   -11.4238,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1356], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6443]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0921,  -322.8739,   -11.4238,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[4.8910e-03, 0.0000e+00, 8.0576e-05, 1.0150e-03, 8.8867e-04, 1.2352e-03,\n",
      "         6.1841e-02, 2.8998e-03, 6.5765e-02, 2.0213e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1356], requires_grad=True)\n",
      "bias grad:  tensor([0.3751])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6443]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0980]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0928,  -322.8739,   -11.4245,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1394], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6541]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0928,  -322.8739,   -11.4245,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0129e-03, 0.0000e+00, 1.7675e-05, 1.5080e-04, 1.6616e-04, 2.5537e-04,\n",
      "         1.7456e-02, 8.5227e-04, 1.3746e-02, 1.8549e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1394], requires_grad=True)\n",
      "bias grad:  tensor([0.0785])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6541]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2254]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0929,  -322.8739,   -11.4246,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1401], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6316]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0929,  -322.8739,   -11.4246,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0017, 0.0003, 0.0003, 0.0031, 0.0008, 0.0077, 0.2261, 0.0071, 0.1360,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1401], requires_grad=True)\n",
      "bias grad:  tensor([0.8432])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6316]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.7745]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0952,  -322.8740,   -11.4260,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1486], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8090]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0952,  -322.8740,   -11.4260,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0758e-03,  0.0000e+00, -1.2040e-05, -3.4642e-04, -1.1074e-04,\n",
      "          2.3060e-04, -5.1335e-04, -7.9075e-05, -1.1426e-02, -1.3859e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1486], requires_grad=True)\n",
      "bias grad:  tensor([-0.0649])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8090]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3560]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0952,  -322.8740,   -11.4259,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1479], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7734]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0952,  -322.8740,   -11.4259,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.0933e-04,  3.9396e-05,  6.6495e-05,  8.5354e-04,  6.1599e-04,\n",
      "          7.9175e-04,  4.3928e-02,  2.2793e-03,  5.0765e-02,  1.6189e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1479], requires_grad=True)\n",
      "bias grad:  tensor([0.3053])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7734]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0454]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0956,  -322.8740,   -11.4264,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1510], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7780]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0956,  -322.8740,   -11.4264,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6580e-04, -4.8680e-05,  2.1286e-05,  2.4665e-04,  2.2054e-04,\n",
      "          6.5369e-04,  1.9820e-02,  1.3606e-03,  2.3408e-02,  1.4128e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1510], requires_grad=True)\n",
      "bias grad:  tensor([0.1307])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7780]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6774]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0958,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1523], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7102]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0958,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[5.9115e-04, 1.1759e-05, 6.6798e-05, 5.7384e-04, 2.1412e-04, 2.4192e-03,\n",
      "         6.2904e-02, 1.9280e-03, 4.0470e-02, 1.2521e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1523], requires_grad=True)\n",
      "bias grad:  tensor([0.2299])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7102]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0315]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0964,  -322.8740,   -11.4270,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1546], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7071]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0964,  -322.8740,   -11.4270,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.8882e-03, -1.9933e-05, -4.1705e-05, -7.2014e-04, -4.4416e-04,\n",
      "         -3.4825e-04, -3.0738e-02, -1.1614e-03, -3.0630e-02, -3.3013e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1546], requires_grad=True)\n",
      "bias grad:  tensor([-0.1795])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7071]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5738]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0961,  -322.8740,   -11.4267,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1528], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6497]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0961,  -322.8740,   -11.4267,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.2553e-03,  0.0000e+00, -7.2828e-06, -1.5238e-04, -3.1211e-06,\n",
      "          3.7281e-05,  2.9556e-03, -7.0828e-04, -1.1413e-02, -3.5303e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1528], requires_grad=True)\n",
      "bias grad:  tensor([-0.0580])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6497]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2781]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0962,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1522], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6775]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0962,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4726e-03, 3.5069e-05, 8.0999e-05, 9.7847e-04, 7.0903e-04, 1.2782e-03,\n",
      "         6.0694e-02, 2.9468e-03, 6.0377e-02, 2.3288e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1522], requires_grad=True)\n",
      "bias grad:  tensor([0.3615])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6775]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0721]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0968,  -322.8741,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1558], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6847]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0968,  -322.8741,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8444e-02,  0.0000e+00, -4.2311e-05, -9.9158e-04, -1.2771e-03,\n",
      "         -6.3362e-04, -2.8796e-02, -2.0885e-03, -5.0660e-02, -5.4150e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1558], requires_grad=True)\n",
      "bias grad:  tensor([-0.2849])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6847]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2346]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0965,  -322.8740,   -11.4267,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1530], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6613]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0965,  -322.8740,   -11.4267,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.3061e-03,  2.4855e-05,  3.9401e-05,  2.8628e-04, -4.7180e-05,\n",
      "          1.2340e-03,  3.1878e-02,  1.2602e-03,  2.0858e-02,  9.9975e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1530], requires_grad=True)\n",
      "bias grad:  tensor([0.1261])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6613]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0524]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0968,  -322.8740,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1542], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6560]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0968,  -322.8740,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.6876e-04,  0.0000e+00, -1.1599e-04, -7.4874e-04, -1.0197e-04,\n",
      "         -5.3380e-03, -1.3917e-01, -3.4779e-03, -6.1520e-02, -2.3774e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1542], requires_grad=True)\n",
      "bias grad:  tensor([-0.3827])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6560]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1513]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0954,  -322.8740,   -11.4263,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1504], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5409]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0954,  -322.8740,   -11.4263,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.5395e-03,  1.3386e-05, -1.8945e-05,  2.7571e-04,  7.2098e-04,\n",
      "         -3.3221e-03, -6.3697e-02, -2.3595e-04,  9.5826e-03, -4.4769e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1504], requires_grad=True)\n",
      "bias grad:  tensor([0.0362])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5409]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0667]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0948,  -322.8740,   -11.4264,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1508], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5342]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0948,  -322.8740,   -11.4264,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.5801e-03, -6.4533e-05, -5.7296e-05, -5.8438e-04, -1.2383e-05,\n",
      "         -2.1805e-03, -6.3146e-02, -1.3213e-03, -2.8058e-02, -1.8835e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1508], requires_grad=True)\n",
      "bias grad:  tensor([-0.1796])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5342]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7484]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0941,  -322.8740,   -11.4261,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1490], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4594]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0941,  -322.8740,   -11.4261,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6377e-04, -1.8763e-04, -4.1367e-05, -3.2454e-04,  1.6175e-04,\n",
      "         -3.6541e-03, -7.6497e-02, -1.4504e-03, -1.8199e-02,  1.3889e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1490], requires_grad=True)\n",
      "bias grad:  tensor([-0.1231])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4594]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8716]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0934,  -322.8740,   -11.4259,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1477], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3722]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0934,  -322.8740,   -11.4259,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0057, 0.0000, 0.0002, 0.0030, 0.0006, 0.0017, 0.1099, 0.0054, 0.1531,\n",
      "         0.0031]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1477], requires_grad=True)\n",
      "bias grad:  tensor([0.8788])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3722]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.8183]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8741,   -11.4274,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1565], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7541]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8741,   -11.4274,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7272e-03,  1.8567e-05, -8.1454e-05, -1.3216e-03, -9.4488e-04,\n",
      "         -9.0592e-04, -5.8836e-02, -3.0692e-03, -6.8447e-02, -6.5279e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1565], requires_grad=True)\n",
      "bias grad:  tensor([-0.3960])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7541]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4094]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0939,  -322.8740,   -11.4268,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1526], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7131]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0939,  -322.8740,   -11.4268,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4003e-03,  3.4872e-05,  6.5873e-05,  7.6439e-04,  3.4218e-04,\n",
      "          2.6633e-03,  7.1678e-02,  2.3316e-03,  4.1807e-02,  1.3011e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1526], requires_grad=True)\n",
      "bias grad:  tensor([0.2640])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7131]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1698]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0946,  -322.8741,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1552], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7301]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0946,  -322.8741,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[2.6356e-03, 0.0000e+00, 5.6033e-05, 7.5208e-04, 4.9864e-04, 1.8955e-04,\n",
      "         3.8499e-02, 2.0695e-03, 4.6727e-02, 1.0819e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1552], requires_grad=True)\n",
      "bias grad:  tensor([0.2710])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7301]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0168]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0950,  -322.8741,   -11.4276,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1579], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7284]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0950,  -322.8741,   -11.4276,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3111e-03,  0.0000e+00, -1.3408e-05, -3.9537e-04, -3.7586e-04,\n",
      "          9.0945e-05, -8.4260e-04, -6.2915e-04, -1.6686e-02,  2.4494e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1579], requires_grad=True)\n",
      "bias grad:  tensor([-0.0950])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7284]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3935]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0950,  -322.8741,   -11.4275,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1570], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6891]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0950,  -322.8741,   -11.4275,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1044e-05,  6.4451e-05,  4.2831e-05,  4.2672e-04, -7.3051e-05,\n",
      "          8.8939e-04,  3.3042e-02,  1.4661e-03,  2.9844e-02,  8.6782e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1570], requires_grad=True)\n",
      "bias grad:  tensor([0.1711])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6891]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1244]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0953,  -322.8741,   -11.4278,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1587], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7015]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0953,  -322.8741,   -11.4278,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.3381e-04, -1.1208e-04, -6.9945e-05, -8.4013e-04, -1.0866e-04,\n",
      "         -2.0945e-03, -6.3256e-02, -2.1033e-03, -4.4304e-02, -4.6917e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1587], requires_grad=True)\n",
      "bias grad:  tensor([-0.2533])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7015]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6358]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0947,  -322.8741,   -11.4273,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1562], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6379]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0947,  -322.8741,   -11.4273,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6794e-03,  0.0000e+00,  5.5805e-05,  6.2138e-04,  3.0333e-04,\n",
      "          5.2583e-04,  2.6795e-02,  2.0260e-03,  3.9666e-02,  1.1440e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1562], requires_grad=True)\n",
      "bias grad:  tensor([0.2318])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6379]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0092]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0950,  -322.8741,   -11.4277,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1585], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6370]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0950,  -322.8741,   -11.4277,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.9327e-04,  2.0794e-06,  4.5246e-06, -1.0163e-04,  1.2544e-04,\n",
      "          1.4960e-03,  2.7836e-02,  3.7939e-04, -2.1381e-03,  5.7414e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1585], requires_grad=True)\n",
      "bias grad:  tensor([-0.0043])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6370]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4061]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0952,  -322.8741,   -11.4277,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1584], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5964]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0952,  -322.8741,   -11.4277,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7167e-03, 3.4277e-05, 4.5134e-05, 4.8327e-04, 3.3199e-04, 2.2480e-03,\n",
      "         6.2720e-02, 1.7133e-03, 2.9468e-02, 1.1348e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1584], requires_grad=True)\n",
      "bias grad:  tensor([0.1765])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5964]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0125]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0959,  -322.8741,   -11.4280,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1602], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5976]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0959,  -322.8741,   -11.4280,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.1986e-04, 3.8516e-05, 1.1866e-04, 1.2280e-03, 4.9562e-04, 1.7728e-03,\n",
      "         7.6966e-02, 3.2498e-03, 6.7873e-02, 1.8530e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1602], requires_grad=True)\n",
      "bias grad:  tensor([0.4280])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5976]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3644]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0966,  -322.8741,   -11.4287,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1645], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6341]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0966,  -322.8741,   -11.4287,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0820e-03, 0.0000e+00, 7.1400e-05, 8.8773e-04, 7.6108e-04, 1.0838e-03,\n",
      "         5.4343e-02, 2.5064e-03, 5.6606e-02, 1.8289e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1645], requires_grad=True)\n",
      "bias grad:  tensor([0.3242])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6341]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1630]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0972,  -322.8742,   -11.4293,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1677], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6504]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0972,  -322.8742,   -11.4293,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9181e-04,  0.0000e+00,  2.4621e-05,  2.0365e-04,  3.3845e-05,\n",
      "          3.9724e-04,  1.8569e-02,  1.0507e-03,  1.6379e-02,  2.9277e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1677], requires_grad=True)\n",
      "bias grad:  tensor([0.0939])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6504]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1903]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0974,  -322.8742,   -11.4294,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1687], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6314]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0974,  -322.8742,   -11.4294,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0015, 0.0003, 0.0003, 0.0030, 0.0008, 0.0074, 0.2190, 0.0070, 0.1342,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1687], requires_grad=True)\n",
      "bias grad:  tensor([0.8302])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6314]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6192]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0995,  -322.8742,   -11.4308,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1770], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7933]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0995,  -322.8742,   -11.4308,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3753e-03,  0.0000e+00, -8.9377e-06, -2.7621e-04, -3.0259e-05,\n",
      "          1.0456e-04, -4.9597e-04,  3.1788e-05, -8.3210e-03, -1.1235e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1770], requires_grad=True)\n",
      "bias grad:  tensor([-0.0510])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7933]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3438]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0995,  -322.8742,   -11.4307,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1764], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7589]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0995,  -322.8742,   -11.4307,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.4218e-04,  4.0629e-05,  8.2856e-05,  1.0350e-03,  7.0937e-04,\n",
      "          9.4322e-04,  5.0670e-02,  2.6566e-03,  6.1519e-02,  1.9615e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1764], requires_grad=True)\n",
      "bias grad:  tensor([0.3672])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7589]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0627]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1000,  -322.8743,   -11.4313,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1801], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7652]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1000,  -322.8743,   -11.4313,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9565e-03, -3.1112e-05,  1.4881e-05,  1.5013e-04,  2.8076e-06,\n",
      "          4.1995e-04,  1.3974e-02,  9.7200e-04,  1.6326e-02,  1.1807e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1801], requires_grad=True)\n",
      "bias grad:  tensor([0.0900])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7652]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5368]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1002,  -322.8743,   -11.4315,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1810], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7115]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1002,  -322.8743,   -11.4315,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.4434e-04,  5.5989e-06,  5.1236e-05,  3.5275e-04,  2.5185e-05,\n",
      "          2.2014e-03,  5.2308e-02,  1.4025e-03,  2.7180e-02,  1.0104e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1810], requires_grad=True)\n",
      "bias grad:  tensor([0.1535])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7115]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1320]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1007,  -322.8743,   -11.4317,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1825], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6983]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1007,  -322.8743,   -11.4317,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.4647e-03, -3.8958e-05, -3.2100e-05, -6.2448e-04, -3.9506e-04,\n",
      "         -2.7118e-04, -2.0808e-02, -8.3900e-04, -2.4254e-02,  2.3464e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1825], requires_grad=True)\n",
      "bias grad:  tensor([-0.1421])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6983]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7770]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1005,  -322.8743,   -11.4315,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1811], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6206]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1005,  -322.8743,   -11.4315,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6538e-03,  0.0000e+00,  6.9701e-06,  4.2718e-05,  9.2253e-05,\n",
      "          9.3751e-05,  8.4728e-03, -2.6715e-04, -1.0616e-03, -2.0897e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1811], requires_grad=True)\n",
      "bias grad:  tensor([0.0009])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6206]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3771]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1006,  -322.8743,   -11.4315,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1811], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6583]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1006,  -322.8743,   -11.4315,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0195e-03, 2.9000e-05, 8.7288e-05, 1.0916e-03, 8.3871e-04, 1.2377e-03,\n",
      "         6.3190e-02, 3.1736e-03, 6.7718e-02, 2.4064e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1811], requires_grad=True)\n",
      "bias grad:  tensor([0.4031])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6583]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0324]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1012,  -322.8743,   -11.4321,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1852], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6615]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1012,  -322.8743,   -11.4321,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8836e-02,  0.0000e+00, -6.4844e-05, -1.2780e-03, -1.5756e-03,\n",
      "         -8.5713e-04, -3.8818e-02, -2.9815e-03, -6.8109e-02, -7.9162e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1852], requires_grad=True)\n",
      "bias grad:  tensor([-0.3854])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6615]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3013]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1008,  -322.8743,   -11.4315,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1813], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6314]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1008,  -322.8743,   -11.4315,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6136e-03,  7.5972e-06,  2.9578e-05,  2.0991e-04, -2.6215e-05,\n",
      "          9.8580e-04,  2.6377e-02,  9.6124e-04,  1.5519e-02,  6.5067e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1813], requires_grad=True)\n",
      "bias grad:  tensor([0.0944])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6314]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0014]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1011,  -322.8743,   -11.4316,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1823], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6315]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1011,  -322.8743,   -11.4316,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.4559e-04,  0.0000e+00, -1.1415e-04, -7.6480e-04, -1.5436e-04,\n",
      "         -5.2728e-03, -1.3720e-01, -3.4419e-03, -6.1324e-02, -2.6208e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1823], requires_grad=True)\n",
      "bias grad:  tensor([-0.3818])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6315]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1766]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0997,  -322.8742,   -11.4310,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1784], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5139]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0997,  -322.8742,   -11.4310,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.5312e-03,  3.0347e-05, -3.9504e-06,  5.4217e-04,  8.5577e-04,\n",
      "         -3.2809e-03, -5.9291e-02,  2.8951e-04,  2.2618e-02, -3.4413e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1784], requires_grad=True)\n",
      "bias grad:  tensor([0.1111])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5139]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2476]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0991,  -322.8742,   -11.4312,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1796], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5386]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0991,  -322.8742,   -11.4312,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.1867e-03, -4.6690e-05, -3.2171e-05, -3.1056e-04,  7.1256e-05,\n",
      "         -1.4296e-03, -4.3378e-02, -5.1141e-04, -1.1640e-02,  1.7794e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1796], requires_grad=True)\n",
      "bias grad:  tensor([-0.0868])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5386]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6568]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0987,  -322.8742,   -11.4311,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1787], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4730]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0987,  -322.8742,   -11.4311,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7757e-05, -2.0152e-04, -6.6781e-05, -5.8009e-04,  4.7374e-05,\n",
      "         -4.1742e-03, -9.2737e-02, -2.2941e-03, -3.3619e-02, -2.5113e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1787], requires_grad=True)\n",
      "bias grad:  tensor([-0.2168])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4730]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9015]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0978,  -322.8742,   -11.4308,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1765], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3828]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0978,  -322.8742,   -11.4308,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0054, 0.0000, 0.0002, 0.0024, 0.0005, 0.0013, 0.0844, 0.0042, 0.1227,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1765], requires_grad=True)\n",
      "bias grad:  tensor([0.7049])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3828]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.3882]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0986,  -322.8742,   -11.4320,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1836], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7216]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0986,  -322.8742,   -11.4320,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.5781e-03,  2.4618e-05, -8.2536e-05, -1.2955e-03, -9.1150e-04,\n",
      "         -1.0387e-03, -5.8743e-02, -3.0751e-03, -6.7731e-02, -6.6419e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1836], requires_grad=True)\n",
      "bias grad:  tensor([-0.3931])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7216]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3943]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0980,  -322.8742,   -11.4313,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1796], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6822]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0980,  -322.8742,   -11.4313,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1495e-03,  3.5252e-05,  4.7239e-05,  5.5215e-04,  2.3880e-04,\n",
      "          2.0301e-03,  5.2788e-02,  1.6697e-03,  3.0427e-02,  8.7146e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1796], requires_grad=True)\n",
      "bias grad:  tensor([0.1898])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6822]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2167]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0986,  -322.8742,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1815], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7039]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0986,  -322.8742,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7186e-03, 0.0000e+00, 4.8902e-05, 6.7946e-04, 4.4285e-04, 1.4973e-04,\n",
      "         3.1138e-02, 1.7917e-03, 4.1538e-02, 8.5115e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1815], requires_grad=True)\n",
      "bias grad:  tensor([0.2425])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7039]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0348]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0989,  -322.8743,   -11.4321,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1840], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7073]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0989,  -322.8743,   -11.4321,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3468e-03,  0.0000e+00, -2.1507e-05, -4.9950e-04, -3.9733e-04,\n",
      "          9.1181e-05, -4.4338e-03, -8.8164e-04, -2.2293e-02,  1.4299e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1840], requires_grad=True)\n",
      "bias grad:  tensor([-0.1272])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7073]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4245]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0988,  -322.8743,   -11.4318,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1827], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6649]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0988,  -322.8743,   -11.4318,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.5810e-04,  8.2191e-05,  2.7861e-05,  2.7973e-04, -2.5290e-04,\n",
      "          5.1098e-04,  2.2334e-02,  9.0066e-04,  1.8748e-02,  5.2346e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1827], requires_grad=True)\n",
      "bias grad:  tensor([0.1075])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6649]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2690]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0990,  -322.8743,   -11.4320,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1838], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6918]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0990,  -322.8743,   -11.4320,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.0032e-05, -1.1330e-04, -8.3193e-05, -9.9863e-04, -1.4919e-04,\n",
      "         -2.3129e-03, -6.9917e-02, -2.4211e-03, -5.2807e-02, -6.5225e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1838], requires_grad=True)\n",
      "bias grad:  tensor([-0.3024])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6918]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7605]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0983,  -322.8742,   -11.4315,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1807], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6157]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0983,  -322.8742,   -11.4315,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6588e-03,  0.0000e+00,  5.0022e-05,  5.7543e-04,  3.0608e-04,\n",
      "          3.6724e-04,  2.1935e-02,  1.8786e-03,  3.6717e-02,  1.0007e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1807], requires_grad=True)\n",
      "bias grad:  tensor([0.2117])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6157]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0077]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0986,  -322.8743,   -11.4319,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1829], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6165]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0986,  -322.8743,   -11.4319,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8778e-03,  1.0196e-05, -1.5556e-05, -3.5971e-04, -1.7201e-04,\n",
      "          1.2486e-03,  1.0658e-02, -3.2687e-04, -1.8125e-02,  2.9551e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1829], requires_grad=True)\n",
      "bias grad:  tensor([-0.0975])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6165]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3629]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0987,  -322.8743,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1819], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5802]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0987,  -322.8743,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[4.7831e-04, 3.0246e-05, 3.8572e-05, 3.5417e-04, 1.7322e-04, 1.9386e-03,\n",
      "         5.3314e-02, 1.2931e-03, 2.2031e-02, 8.0611e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1819], requires_grad=True)\n",
      "bias grad:  tensor([0.1303])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5802]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1794]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0992,  -322.8743,   -11.4319,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1832], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5982]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0992,  -322.8743,   -11.4319,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[1.1420e-04, 3.9090e-05, 1.1174e-04, 1.1636e-03, 4.6497e-04, 1.5896e-03,\n",
      "         7.2648e-02, 3.0275e-03, 6.4821e-02, 1.7929e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1832], requires_grad=True)\n",
      "bias grad:  tensor([0.4039])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5982]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2460]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0999,  -322.8743,   -11.4325,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1872], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6228]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0999,  -322.8743,   -11.4325,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[4.7637e-03, 0.0000e+00, 6.2443e-05, 7.9273e-04, 6.0295e-04, 1.1724e-03,\n",
      "         5.0722e-02, 1.9990e-03, 4.7759e-02, 9.1452e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1872], requires_grad=True)\n",
      "bias grad:  tensor([0.2715])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6228]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.4210]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8743,   -11.4330,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1899], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6649]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8743,   -11.4330,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3642e-04, 0.0000e+00, 1.5724e-05, 1.1978e-04, 4.0596e-05, 3.8443e-04,\n",
      "         1.6702e-02, 7.4011e-04, 1.1377e-02, 7.7267e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1899], requires_grad=True)\n",
      "bias grad:  tensor([0.0625])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6649]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0753]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1006,  -322.8743,   -11.4331,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1906], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6573]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1006,  -322.8743,   -11.4331,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-0.0007,  0.0003,  0.0002,  0.0029,  0.0006,  0.0072,  0.2107,  0.0067,\n",
      "          0.1263,  0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1906], requires_grad=True)\n",
      "bias grad:  tensor([0.7827])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6573]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.3563]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1027,  -322.8744,   -11.4344,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1984], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7930]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1027,  -322.8744,   -11.4344,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2426e-03,  0.0000e+00, -1.5831e-05, -3.9655e-04, -2.2145e-04,\n",
      "          1.7534e-04, -6.1070e-03, -3.7506e-04, -1.5888e-02, -1.9660e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1984], requires_grad=True)\n",
      "bias grad:  tensor([-0.0925])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7930]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2928]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1027,  -322.8744,   -11.4342,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1975], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7637]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1027,  -322.8744,   -11.4342,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.0247e-04,  3.9875e-05,  6.6794e-05,  8.1579e-04,  5.1140e-04,\n",
      "          7.8477e-04,  4.1173e-02,  2.1494e-03,  4.7462e-02,  1.5193e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1975], requires_grad=True)\n",
      "bias grad:  tensor([0.2892])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7637]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0648]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1031,  -322.8744,   -11.4347,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2004], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7702]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1031,  -322.8744,   -11.4347,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1410e-03, -2.5653e-05,  3.0255e-05,  3.4067e-04,  1.4607e-04,\n",
      "          5.2164e-04,  2.2086e-02,  1.5377e-03,  2.8164e-02,  1.4634e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2004], requires_grad=True)\n",
      "bias grad:  tensor([0.1575])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7702]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6090]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1033,  -322.8745,   -11.4350,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2019], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7093]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1033,  -322.8745,   -11.4350,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.0181e-04,  9.0587e-06,  5.4171e-05,  3.9839e-04,  6.4505e-05,\n",
      "          2.2751e-03,  5.4562e-02,  1.4874e-03,  2.9161e-02,  1.0628e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2019], requires_grad=True)\n",
      "bias grad:  tensor([0.1651])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7093]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0548]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1038,  -322.8745,   -11.4353,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2036], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7038]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1038,  -322.8745,   -11.4353,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2006e-03, -2.7234e-05, -6.5621e-05, -1.0834e-03, -7.3993e-04,\n",
      "         -6.1069e-04, -4.4893e-02, -2.0485e-03, -5.1683e-02, -3.3334e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2036], requires_grad=True)\n",
      "bias grad:  tensor([-0.3010])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7038]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6753]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1034,  -322.8744,   -11.4348,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2006], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6363]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1034,  -322.8744,   -11.4348,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4800e-03,  0.0000e+00, -1.6730e-05, -3.3386e-04, -1.7967e-04,\n",
      "         -5.2570e-05, -7.4637e-03, -9.7968e-04, -2.0390e-02, -5.3814e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2006], requires_grad=True)\n",
      "bias grad:  tensor([-0.1146])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6363]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2131]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1033,  -322.8744,   -11.4346,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1994], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6576]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1033,  -322.8744,   -11.4346,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[3.9688e-03, 2.4398e-05, 1.0269e-04, 1.2859e-03, 1.0132e-03, 1.3039e-03,\n",
      "         7.3432e-02, 3.8686e-03, 8.0609e-02, 2.7910e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1994], requires_grad=True)\n",
      "bias grad:  tensor([0.4776])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6576]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0586]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1040,  -322.8745,   -11.4354,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2042], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6517]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1040,  -322.8745,   -11.4354,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.4763e-02,  0.0000e+00, -5.4262e-05, -1.3001e-03, -1.6827e-03,\n",
      "         -8.2600e-04, -3.7555e-02, -2.7042e-03, -6.6091e-02, -6.9896e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2042], requires_grad=True)\n",
      "bias grad:  tensor([-0.3714])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6517]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4796]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1037,  -322.8744,   -11.4347,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2005], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6037]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1037,  -322.8744,   -11.4347,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.0229e-03,  1.6811e-05,  2.0387e-05,  3.4366e-05, -2.2625e-04,\n",
      "          1.0932e-03,  2.1232e-02,  5.8654e-04,  5.7120e-03,  6.2703e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2005], requires_grad=True)\n",
      "bias grad:  tensor([0.0386])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6037]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0550]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1039,  -322.8744,   -11.4348,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2009], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5982]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1039,  -322.8744,   -11.4348,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4060e-03,  0.0000e+00, -1.1938e-04, -8.0901e-04, -2.1015e-04,\n",
      "         -5.4650e-03, -1.4465e-01, -3.5872e-03, -6.5012e-02, -3.3313e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2009], requires_grad=True)\n",
      "bias grad:  tensor([-0.4037])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5982]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1041]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1024,  -322.8744,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1968], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4878]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1024,  -322.8744,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.8556e-03,  3.5612e-05,  2.4342e-06,  6.0527e-04,  8.1163e-04,\n",
      "         -2.9429e-03, -5.0649e-02,  3.9741e-04,  2.4376e-02, -2.2516e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1968], requires_grad=True)\n",
      "bias grad:  tensor([0.1268])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4878]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3840]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1019,  -322.8744,   -11.4344,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1981], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5262]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1019,  -322.8744,   -11.4344,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.2558e-03, -7.3491e-05, -6.0107e-05, -5.9682e-04, -1.0960e-05,\n",
      "         -2.4139e-03, -6.8370e-02, -1.3966e-03, -2.8479e-02, -2.6793e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1981], requires_grad=True)\n",
      "bias grad:  tensor([-0.1844])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5262]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7578]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1012,  -322.8744,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1963], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4505]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1012,  -322.8744,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1793e-04, -2.0009e-04, -8.0184e-05, -6.9314e-04,  2.2293e-06,\n",
      "         -4.2135e-03, -1.0047e-01, -2.5321e-03, -3.9726e-02, -4.6622e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1963], requires_grad=True)\n",
      "bias grad:  tensor([-0.2579])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4505]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9103]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1002,  -322.8744,   -11.4337,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1937], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3594]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1002,  -322.8744,   -11.4337,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0063, 0.0000, 0.0003, 0.0033, 0.0009, 0.0019, 0.1247, 0.0061, 0.1697,\n",
      "         0.0031]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1937], requires_grad=True)\n",
      "bias grad:  tensor([0.9743])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3594]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.4427]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1015,  -322.8744,   -11.4354,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2034], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8037]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1015,  -322.8744,   -11.4354,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2469e-03,  1.4317e-05, -1.0336e-04, -1.5917e-03, -1.1057e-03,\n",
      "         -1.3009e-03, -7.5158e-02, -3.8378e-03, -8.4542e-02, -1.0272e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2034], requires_grad=True)\n",
      "bias grad:  tensor([-0.4923])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8037]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4791]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1007,  -322.8744,   -11.4345,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1985], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7558]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1007,  -322.8744,   -11.4345,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4652e-03,  3.5828e-05,  5.8535e-05,  6.6030e-04,  3.0045e-04,\n",
      "          2.2721e-03,  6.1064e-02,  2.0631e-03,  3.6085e-02,  1.2183e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1985], requires_grad=True)\n",
      "bias grad:  tensor([0.2321])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7558]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1122]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1013,  -322.8744,   -11.4349,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2008], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7670]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1013,  -322.8744,   -11.4349,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[3.2811e-03, 0.0000e+00, 8.1326e-05, 9.7773e-04, 5.5498e-04, 3.9023e-04,\n",
      "         7.6214e-02, 2.7989e-03, 6.1470e-02, 1.5722e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2008], requires_grad=True)\n",
      "bias grad:  tensor([0.3553])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7670]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0628]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1021,  -322.8745,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2044], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7607]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1021,  -322.8745,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.7530e-03,  0.0000e+00, -2.4897e-05, -5.8022e-04, -4.9274e-04,\n",
      "         -3.4582e-06, -7.8189e-03, -1.0678e-03, -2.6711e-02,  1.2062e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2044], requires_grad=True)\n",
      "bias grad:  tensor([-0.1521])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7607]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5467]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1020,  -322.8745,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2028], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7061]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1020,  -322.8745,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.2119e-04,  4.5464e-05,  2.2464e-05,  1.5426e-04, -2.6727e-04,\n",
      "          5.3695e-04,  1.9450e-02,  6.8107e-04,  1.3550e-02,  4.8723e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2028], requires_grad=True)\n",
      "bias grad:  tensor([0.0766])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7061]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1011]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1022,  -322.8745,   -11.4354,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2036], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7162]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1022,  -322.8745,   -11.4354,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.2520e-04, -1.0142e-04, -7.7250e-05, -9.5094e-04, -1.1490e-04,\n",
      "         -2.3518e-03, -6.9368e-02, -2.2677e-03, -4.8657e-02, -2.1704e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2036], requires_grad=True)\n",
      "bias grad:  tensor([-0.2780])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7162]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8839]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1015,  -322.8744,   -11.4349,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2008], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6278]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1015,  -322.8744,   -11.4349,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9733e-03,  0.0000e+00,  7.1084e-05,  7.1551e-04,  2.7820e-04,\n",
      "          1.0743e-03,  4.0149e-02,  2.4466e-03,  4.5922e-02,  1.4181e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2008], requires_grad=True)\n",
      "bias grad:  tensor([0.2762])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6278]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda grad:  tensor([[0.0068]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1019,  -322.8745,   -11.4353,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2036], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6271]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1019,  -322.8745,   -11.4353,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.6308e-04,  4.1681e-06, -6.6649e-06, -2.2253e-04, -3.2072e-05,\n",
      "          1.2970e-03,  2.0430e-02, -2.8931e-05, -1.0166e-02,  3.2748e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2036], requires_grad=True)\n",
      "bias grad:  tensor([-0.0535])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6271]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3405]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1021,  -322.8745,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2031], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5931]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1021,  -322.8745,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[2.3076e-03, 3.3793e-05, 6.3765e-05, 7.4699e-04, 6.0684e-04, 2.3994e-03,\n",
      "         7.6920e-02, 2.4832e-03, 4.6437e-02, 1.3585e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2031], requires_grad=True)\n",
      "bias grad:  tensor([0.2725])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5931]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0507]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1029,  -322.8745,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2058], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5981]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1029,  -322.8745,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[2.1729e-04, 2.4554e-05, 1.0239e-04, 1.0416e-03, 4.0237e-04, 1.5080e-03,\n",
      "         6.7759e-02, 2.7477e-03, 5.7516e-02, 1.6510e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2058], requires_grad=True)\n",
      "bias grad:  tensor([0.3650])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5981]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2397]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1036,  -322.8745,   -11.4363,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2094], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6221]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1036,  -322.8745,   -11.4363,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4166e-03, 0.0000e+00, 9.1511e-05, 1.1027e-03, 8.6046e-04, 1.1562e-03,\n",
      "         6.0524e-02, 3.2155e-03, 7.1449e-02, 2.1697e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2094], requires_grad=True)\n",
      "bias grad:  tensor([0.4071])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6221]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1423]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1042,  -322.8745,   -11.4370,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2135], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6363]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1042,  -322.8745,   -11.4370,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7631e-04,  0.0000e+00,  5.2409e-06, -2.0444e-05, -5.4016e-05,\n",
      "          2.8948e-04,  1.1057e-02,  3.6830e-04,  3.5914e-03, -1.9094e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2135], requires_grad=True)\n",
      "bias grad:  tensor([0.0169])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6363]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1878]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1043,  -322.8745,   -11.4370,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2137], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6176]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1043,  -322.8745,   -11.4370,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-0.0005,  0.0003,  0.0002,  0.0028,  0.0006,  0.0074,  0.2095,  0.0064,\n",
      "          0.1181,  0.0019]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2137], requires_grad=True)\n",
      "bias grad:  tensor([0.7389])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6176]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5478]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1064,  -322.8746,   -11.4382,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2211], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7723]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1064,  -322.8746,   -11.4382,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8799e-03,  0.0000e+00, -5.5935e-06, -2.9401e-04, -8.3835e-05,\n",
      "          4.0066e-04,  4.3298e-03,  7.2388e-05, -8.3331e-03, -4.8606e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2211], requires_grad=True)\n",
      "bias grad:  tensor([-0.0479])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7723]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3567]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1064,  -322.8746,   -11.4381,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2206], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7367]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1064,  -322.8746,   -11.4381,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6924e-04, 3.0907e-05, 6.0231e-05, 7.7043e-04, 4.8338e-04, 7.4523e-04,\n",
      "         3.9168e-02, 1.9296e-03, 4.3653e-02, 1.2162e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2206], requires_grad=True)\n",
      "bias grad:  tensor([0.2660])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7367]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1930]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1068,  -322.8746,   -11.4386,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2232], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7560]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1068,  -322.8746,   -11.4386,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0849e-03, -4.0098e-05,  1.3836e-05,  1.3225e-04,  5.4900e-06,\n",
      "          4.3350e-04,  1.3061e-02,  9.9598e-04,  1.5955e-02,  1.2216e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2232], requires_grad=True)\n",
      "bias grad:  tensor([0.0876])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7560]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6386]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1070,  -322.8746,   -11.4387,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2241], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6921]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1070,  -322.8746,   -11.4387,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.0599e-04,  8.6727e-06,  6.7218e-05,  5.7265e-04,  1.7015e-04,\n",
      "          2.4653e-03,  6.3393e-02,  1.9384e-03,  4.0121e-02,  1.2856e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2241], requires_grad=True)\n",
      "bias grad:  tensor([0.2276])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6921]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0234]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1076,  -322.8747,   -11.4391,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2264], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6898]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1076,  -322.8747,   -11.4391,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.1432e-03, -1.8237e-05, -4.1735e-05, -7.1740e-04, -4.9555e-04,\n",
      "         -3.8248e-04, -2.9161e-02, -1.1733e-03, -3.1350e-02,  9.0223e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2264], requires_grad=True)\n",
      "bias grad:  tensor([-0.1842])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6898]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5424]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1073,  -322.8747,   -11.4388,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2246], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6355]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1073,  -322.8747,   -11.4388,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.6004e-04,  0.0000e+00, -1.8211e-05, -3.0884e-04, -7.1463e-05,\n",
      "         -1.1299e-04, -7.5738e-03, -1.0904e-03, -2.0977e-02, -6.0917e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2246], requires_grad=True)\n",
      "bias grad:  tensor([-0.1135])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6355]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2601]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1072,  -322.8747,   -11.4386,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2234], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6615]], requires_grad=True)\n",
      "Iteration 7 | Score: 0.3966544270515442\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0649,  -322.8724,   -11.3933,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[4.6049e-03, 2.4080e-05, 1.1690e-04, 1.4401e-03, 1.1077e-03, 1.6145e-03,\n",
      "         8.3846e-02, 4.2657e-03, 9.0202e-02, 3.0336e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0446], requires_grad=True)\n",
      "bias grad:  tensor([0.5337])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8594]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1050]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0657,  -322.8725,   -11.3942,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0393], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8489]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0657,  -322.8725,   -11.3942,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7915e-02,  0.0000e+00, -3.6335e-05, -9.0475e-04, -1.1808e-03,\n",
      "         -5.6922e-04, -2.5899e-02, -1.8418e-03, -4.5604e-02, -4.7345e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0393], requires_grad=True)\n",
      "bias grad:  tensor([-0.2560])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8489]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3975]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0654,  -322.8724,   -11.3937,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0418], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8092]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0654,  -322.8724,   -11.3937,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.1067e-03,  2.3375e-05,  4.7086e-05,  3.5150e-04,  3.7719e-05,\n",
      "          1.3564e-03,  3.8278e-02,  1.5751e-03,  2.6312e-02,  1.2528e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0418], requires_grad=True)\n",
      "bias grad:  tensor([0.1576])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8092]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3089]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0658,  -322.8725,   -11.3940,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0402], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7783]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0658,  -322.8725,   -11.3940,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.1184e-04,  0.0000e+00, -9.5626e-05, -5.1021e-04, -2.9851e-05,\n",
      "         -5.0654e-03, -1.2557e-01, -2.7372e-03, -4.6450e-02, -5.1267e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0402], requires_grad=True)\n",
      "bias grad:  tensor([-0.2958])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7783]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1442]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0646,  -322.8724,   -11.3935,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0432], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6639]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0646,  -322.8724,   -11.3935,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.4991e-03, -2.2797e-06, -1.6607e-05,  2.1673e-04,  7.4562e-04,\n",
      "         -3.3468e-03, -6.0490e-02, -1.1252e-04,  1.0409e-02, -1.8481e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0432], requires_grad=True)\n",
      "bias grad:  tensor([0.0432])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6639]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6026]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0640,  -322.8724,   -11.3936,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0428], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6036]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0640,  -322.8724,   -11.3936,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.1775e-03, -7.2513e-05, -1.9216e-05, -8.3194e-05,  2.9218e-04,\n",
      "         -1.7627e-03, -4.0436e-02,  5.4705e-05,  1.1568e-03,  4.3269e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0428], requires_grad=True)\n",
      "bias grad:  tensor([-0.0135])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6036]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7907]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0636,  -322.8724,   -11.3936,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0429], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5246]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0636,  -322.8724,   -11.3936,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.7464e-05, -1.8413e-04, -1.1163e-04, -7.3770e-04, -1.6151e-04,\n",
      "         -5.5004e-03, -1.3185e-01, -3.4310e-03, -5.6533e-02, -7.7016e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0429], requires_grad=True)\n",
      "bias grad:  tensor([-0.3496])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5246]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5641]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0622,  -322.8724,   -11.3931,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0464], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4681]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0622,  -322.8724,   -11.3931,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0045, 0.0000, 0.0002, 0.0024, 0.0005, 0.0013, 0.0893, 0.0045, 0.1260,\n",
      "         0.0027]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0464], requires_grad=True)\n",
      "bias grad:  tensor([0.7221])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4681]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.2966]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0631,  -322.8724,   -11.3943,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0392], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6978]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0631,  -322.8724,   -11.3943,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9300e-03,  3.0243e-05, -4.0087e-05, -6.2366e-04, -4.7584e-04,\n",
      "         -5.4558e-04, -3.4250e-02, -1.4428e-03, -3.1661e-02, -2.4945e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0392], requires_grad=True)\n",
      "bias grad:  tensor([-0.1836])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6978]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0142]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0628,  -322.8724,   -11.3940,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0410], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6964]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0628,  -322.8724,   -11.3940,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[6.4249e-04, 4.2580e-05, 1.0926e-04, 1.3373e-03, 7.0912e-04, 3.2844e-03,\n",
      "         1.0278e-01, 3.8962e-03, 7.1918e-02, 2.1310e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0410], requires_grad=True)\n",
      "bias grad:  tensor([0.4570])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6964]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2647]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0638,  -322.8725,   -11.3947,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0364], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7229]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0638,  -322.8725,   -11.3947,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7952e-03, 0.0000e+00, 8.5329e-05, 1.1257e-03, 8.0228e-04, 5.1384e-04,\n",
      "         6.4129e-02, 3.1282e-03, 6.9866e-02, 1.5991e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0364], requires_grad=True)\n",
      "bias grad:  tensor([0.4042])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7229]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0720]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0645,  -322.8725,   -11.3954,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0324], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7157]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0645,  -322.8725,   -11.3954,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[1.3230e-03, 0.0000e+00, 3.6709e-05, 3.5278e-04, 1.9191e-04, 5.6081e-04,\n",
      "         2.9508e-02, 1.3576e-03, 2.6689e-02, 8.4216e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0324], requires_grad=True)\n",
      "bias grad:  tensor([0.1518])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7157]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2176]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0648,  -322.8725,   -11.3957,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0309], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6939]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0648,  -322.8725,   -11.3957,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[1.2447e-03, 9.0707e-05, 7.0893e-05, 8.6678e-04, 2.6123e-04, 1.2722e-03,\n",
      "         5.4061e-02, 2.6075e-03, 5.4521e-02, 1.3784e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0309], requires_grad=True)\n",
      "bias grad:  tensor([0.3139])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6939]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2449]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0653,  -322.8725,   -11.3962,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0277], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7184]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0653,  -322.8725,   -11.3962,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.0155e-03, -6.4300e-05, -1.3971e-05, -1.2086e-04,  2.6510e-04,\n",
      "         -1.4360e-03, -2.7387e-02, -3.3183e-04, -3.1837e-03,  4.1778e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0277], requires_grad=True)\n",
      "bias grad:  tensor([-0.0152])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7184]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3806]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0650,  -322.8725,   -11.3962,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0279], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6803]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0650,  -322.8725,   -11.3962,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[1.8143e-04, 0.0000e+00, 7.1773e-05, 8.5122e-04, 5.1068e-04, 7.6693e-04,\n",
      "         3.9315e-02, 2.6512e-03, 5.2713e-02, 1.3166e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0279], requires_grad=True)\n",
      "bias grad:  tensor([0.3088])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6803]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0212]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0654,  -322.8726,   -11.3967,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0248], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6825]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0654,  -322.8726,   -11.3967,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7833e-03, 1.5765e-05, 3.4114e-05, 2.8417e-04, 3.4255e-04, 1.9642e-03,\n",
      "         4.9706e-02, 1.3868e-03, 2.0242e-02, 1.2766e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0248], requires_grad=True)\n",
      "bias grad:  tensor([0.1274])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6825]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3784]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0659,  -322.8726,   -11.3969,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0235], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6446]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0659,  -322.8726,   -11.3969,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0303e-03, 3.7111e-05, 6.7802e-05, 7.8148e-04, 4.7156e-04, 2.8452e-03,\n",
      "         8.1434e-02, 2.4562e-03, 4.6077e-02, 1.3556e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0235], requires_grad=True)\n",
      "bias grad:  tensor([0.2701])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6446]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1787]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0667,  -322.8726,   -11.3974,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0208], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6625]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0667,  -322.8726,   -11.3974,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[2.9395e-04, 4.6771e-05, 1.3403e-04, 1.4131e-03, 5.7265e-04, 2.1522e-03,\n",
      "         9.0173e-02, 3.7460e-03, 7.9594e-02, 2.1624e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0208], requires_grad=True)\n",
      "bias grad:  tensor([0.4899])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6625]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2693]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0676,  -322.8726,   -11.3982,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0159], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6894]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0676,  -322.8726,   -11.3982,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[5.2653e-03, 0.0000e+00, 8.7339e-05, 1.0991e-03, 8.3630e-04, 1.4611e-03,\n",
      "         6.5805e-02, 2.9481e-03, 6.8096e-02, 1.4732e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0159], requires_grad=True)\n",
      "bias grad:  tensor([0.3870])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6894]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2758]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0683,  -322.8727,   -11.3989,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0121], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7170]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0683,  -322.8727,   -11.3989,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[3.9446e-04, 0.0000e+00, 3.3709e-05, 3.2011e-04, 1.4889e-04, 6.9248e-04,\n",
      "         2.9679e-02, 1.3941e-03, 2.3591e-02, 3.6474e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0121], requires_grad=True)\n",
      "bias grad:  tensor([0.1342])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7170]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2055]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0686,  -322.8727,   -11.3991,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0107], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6964]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0686,  -322.8727,   -11.3991,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0003, 0.0003, 0.0003, 0.0031, 0.0007, 0.0076, 0.2245, 0.0072, 0.1383,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0107], requires_grad=True)\n",
      "bias grad:  tensor([0.8535])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6964]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.4907]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0708,  -322.8727,   -11.4005,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0022], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8455]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0708,  -322.8727,   -11.4005,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3284e-03,  0.0000e+00,  1.4058e-05,  4.3977e-05,  1.2108e-04,\n",
      "          4.3951e-04,  1.4707e-02,  8.3086e-04,  9.6626e-03,  2.1503e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0022], requires_grad=True)\n",
      "bias grad:  tensor([0.0557])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8455]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2423]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0710,  -322.8727,   -11.4006,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0016], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8213]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0710,  -322.8727,   -11.4006,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[4.9309e-04, 4.8777e-05, 8.7354e-05, 1.1041e-03, 6.4524e-04, 1.0139e-03,\n",
      "         5.4451e-02, 2.9009e-03, 6.3512e-02, 1.7436e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0016], requires_grad=True)\n",
      "bias grad:  tensor([0.3821])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8213]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1291]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0715,  -322.8727,   -11.4012,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0022], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8342]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0715,  -322.8727,   -11.4012,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8001e-04, -3.3988e-05,  3.9733e-05,  4.9395e-04,  3.1550e-04,\n",
      "          7.7449e-04,  3.0082e-02,  1.9737e-03,  3.7477e-02,  1.6545e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0022], requires_grad=True)\n",
      "bias grad:  tensor([0.2115])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8342]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6110]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0718,  -322.8728,   -11.4016,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0043], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7731]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0718,  -322.8728,   -11.4016,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[9.8842e-04, 9.6859e-06, 7.3991e-05, 6.4297e-04, 2.4731e-04, 2.6182e-03,\n",
      "         6.8077e-02, 2.1796e-03, 4.5093e-02, 1.3503e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0043], requires_grad=True)\n",
      "bias grad:  tensor([0.2556])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7731]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0598]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0725,  -322.8728,   -11.4021,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0069], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7671]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0725,  -322.8728,   -11.4021,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.5086e-03, -3.2118e-05, -3.4245e-05, -6.5754e-04, -4.6647e-04,\n",
      "         -3.0495e-04, -2.2650e-02, -9.8621e-04, -2.6857e-02,  1.8394e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0069], requires_grad=True)\n",
      "bias grad:  tensor([-0.1554])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7671]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6970]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0723,  -322.8728,   -11.4018,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0053], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6974]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0723,  -322.8728,   -11.4018,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.8570e-03,  0.0000e+00,  1.1944e-05,  9.0764e-05,  1.2564e-04,\n",
      "          1.8895e-04,  1.4852e-02, -6.5288e-05,  2.9747e-03, -1.8600e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0053], requires_grad=True)\n",
      "bias grad:  tensor([0.0233])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6974]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2599]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0724,  -322.8728,   -11.4018,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0055], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7234]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0724,  -322.8728,   -11.4018,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[4.9450e-03, 3.0716e-05, 1.1113e-04, 1.3774e-03, 1.0261e-03, 1.4731e-03,\n",
      "         7.6633e-02, 3.9447e-03, 8.5016e-02, 2.8205e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0055], requires_grad=True)\n",
      "bias grad:  tensor([0.5030])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7234]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0464]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0732,  -322.8728,   -11.4027,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0106], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7280]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0732,  -322.8728,   -11.4027,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7777e-02,  0.0000e+00, -2.9780e-05, -8.2084e-04, -1.0930e-03,\n",
      "         -5.0391e-04, -2.2970e-02, -1.5815e-03, -4.0505e-02, -4.0060e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0106], requires_grad=True)\n",
      "bias grad:  tensor([-0.2266])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7280]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2637]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0730,  -322.8728,   -11.4023,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0083], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7017]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0730,  -322.8728,   -11.4023,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.8443e-03,  2.0038e-05,  5.8063e-05,  5.3215e-04,  8.3327e-05,\n",
      "          1.5312e-03,  4.5104e-02,  1.9082e-03,  3.4874e-02,  1.2795e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0083], requires_grad=True)\n",
      "bias grad:  tensor([0.2083])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7017]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0362]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0734,  -322.8728,   -11.4026,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0104], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6981]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0734,  -322.8728,   -11.4026,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.5780e-05,  0.0000e+00, -9.5570e-05, -4.9265e-04,  3.4177e-05,\n",
      "         -5.0969e-03, -1.2511e-01, -2.7268e-03, -4.5521e-02,  1.1604e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0104], requires_grad=True)\n",
      "bias grad:  tensor([-0.2908])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6981]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1908]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0722,  -322.8728,   -11.4022,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0075], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5790]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0722,  -322.8728,   -11.4022,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.2927e-03,  1.0445e-05, -1.9032e-05,  2.7772e-04,  7.1727e-04,\n",
      "         -3.2356e-03, -6.2952e-02, -2.3334e-04,  9.4828e-03, -5.1693e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0075], requires_grad=True)\n",
      "bias grad:  tensor([0.0359])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5790]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1371]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0715,  -322.8728,   -11.4022,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0078], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5653]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0715,  -322.8728,   -11.4022,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.8959e-03, -4.9705e-05, -2.9066e-05, -2.6549e-04,  6.8693e-05,\n",
      "         -1.5905e-03, -4.3236e-02, -4.1272e-04, -9.4728e-03,  1.5798e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0078], requires_grad=True)\n",
      "bias grad:  tensor([-0.0735])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5653]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6354]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0711,  -322.8728,   -11.4022,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0071], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5017]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0711,  -322.8728,   -11.4022,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.9765e-04, -1.8555e-04, -3.8509e-05, -2.6134e-04,  2.1165e-04,\n",
      "         -3.5916e-03, -7.1248e-02, -1.4272e-03, -1.6041e-02,  1.0165e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0071], requires_grad=True)\n",
      "bias grad:  tensor([-0.1077])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5017]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7545]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0704,  -322.8728,   -11.4020,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0060], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4263]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0704,  -322.8728,   -11.4020,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0056, 0.0000, 0.0003, 0.0032, 0.0007, 0.0020, 0.1314, 0.0064, 0.1734,\n",
      "         0.0038]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0060], requires_grad=True)\n",
      "bias grad:  tensor([0.9932])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4263]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.1221]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0717,  -322.8729,   -11.4037,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0160], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7385]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0717,  -322.8729,   -11.4037,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6663e-03,  3.6866e-05, -4.2964e-05, -7.2498e-04, -5.6182e-04,\n",
      "         -5.0710e-04, -3.4093e-02, -1.5650e-03, -3.5673e-02, -1.4455e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0160], requires_grad=True)\n",
      "bias grad:  tensor([-0.2049])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7385]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2116]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0714,  -322.8728,   -11.4034,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0139], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7173]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0714,  -322.8728,   -11.4034,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.3053e-04,  4.8417e-05,  1.0437e-04,  1.2215e-03,  6.0625e-04,\n",
      "          3.2255e-03,  9.8362e-02,  3.6360e-03,  6.6866e-02,  2.1413e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0139], requires_grad=True)\n",
      "bias grad:  tensor([0.4245])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7173]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1723]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0723,  -322.8729,   -11.4040,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0182], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7346]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0723,  -322.8729,   -11.4040,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6699e-03, 0.0000e+00, 6.1687e-05, 8.6917e-04, 6.4779e-04, 2.8780e-04,\n",
      "         4.0124e-02, 2.2879e-03, 5.2926e-02, 1.0798e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0182], requires_grad=True)\n",
      "bias grad:  tensor([0.3084])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7346]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0099]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0727,  -322.8729,   -11.4046,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0212], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7356]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0727,  -322.8729,   -11.4046,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[4.3957e-04, 0.0000e+00, 1.9477e-05, 1.0860e-04, 1.1710e-05, 3.6377e-04,\n",
      "         1.7509e-02, 6.6608e-04, 1.1932e-02, 5.8791e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0212], requires_grad=True)\n",
      "bias grad:  tensor([0.0678])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7356]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2717]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0729,  -322.8729,   -11.4047,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0219], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7084]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0729,  -322.8729,   -11.4047,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[1.1912e-03, 9.7150e-05, 5.7737e-05, 7.0214e-04, 1.2043e-04, 1.0716e-03,\n",
      "         4.4922e-02, 2.1113e-03, 4.4046e-02, 1.1197e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0219], requires_grad=True)\n",
      "bias grad:  tensor([0.2524])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7084]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2393]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0734,  -322.8729,   -11.4051,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0244], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7323]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0734,  -322.8729,   -11.4051,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.2707e-03, -7.8347e-05, -5.1834e-05, -6.2467e-04,  4.0877e-05,\n",
      "         -1.7211e-03, -4.8601e-02, -1.4505e-03, -3.0926e-02, -1.1230e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0244], requires_grad=True)\n",
      "bias grad:  tensor([-0.1753])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7323]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6724]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0729,  -322.8729,   -11.4048,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0227], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6651]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0729,  -322.8729,   -11.4048,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[8.2149e-04, 0.0000e+00, 8.6948e-05, 1.0380e-03, 6.5750e-04, 1.0092e-03,\n",
      "         5.1721e-02, 3.2003e-03, 6.3959e-02, 1.6045e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0227], requires_grad=True)\n",
      "bias grad:  tensor([0.3768])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6651]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0403]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0734,  -322.8730,   -11.4055,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0265], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6691]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0734,  -322.8730,   -11.4055,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.0610e-03,  8.1782e-06,  4.6340e-06, -5.3603e-05,  1.4291e-04,\n",
      "          1.4658e-03,  2.9504e-02,  4.4043e-04, -7.1470e-04,  6.3421e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0265], requires_grad=True)\n",
      "bias grad:  tensor([0.0092])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6691]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3701]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0737,  -322.8730,   -11.4055,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0265], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6321]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0737,  -322.8730,   -11.4055,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6165e-03, 3.7800e-05, 5.0135e-05, 5.2646e-04, 2.7788e-04, 2.5123e-03,\n",
      "         6.7311e-02, 1.7432e-03, 3.0623e-02, 1.0256e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0265], requires_grad=True)\n",
      "bias grad:  tensor([0.1821])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6321]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1305]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0744,  -322.8730,   -11.4058,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0284], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6451]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0744,  -322.8730,   -11.4058,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7139e-04, 4.2265e-05, 1.4485e-04, 1.5239e-03, 6.5002e-04, 2.1132e-03,\n",
      "         9.4363e-02, 4.1058e-03, 8.4827e-02, 2.3462e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0284], requires_grad=True)\n",
      "bias grad:  tensor([0.5346])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6451]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2564]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0753,  -322.8730,   -11.4066,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0337], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6708]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0753,  -322.8730,   -11.4066,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[5.2741e-03, 0.0000e+00, 5.9256e-05, 7.7707e-04, 6.7532e-04, 8.8267e-04,\n",
      "         4.5680e-02, 1.9535e-03, 4.7426e-02, 9.5029e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0337], requires_grad=True)\n",
      "bias grad:  tensor([0.2694])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6708]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2948]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0758,  -322.8730,   -11.4071,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0364], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7003]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0758,  -322.8730,   -11.4071,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[2.1766e-03, 0.0000e+00, 4.0144e-05, 4.2935e-04, 3.2308e-04, 7.0343e-04,\n",
      "         3.4677e-02, 1.7606e-03, 2.9859e-02, 4.1776e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0364], requires_grad=True)\n",
      "bias grad:  tensor([0.1722])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7003]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2159]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0761,  -322.8731,   -11.4074,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0381], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6787]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0761,  -322.8731,   -11.4074,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0014, 0.0003, 0.0003, 0.0033, 0.0009, 0.0077, 0.2331, 0.0076, 0.1483,\n",
      "         0.0025]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0381], requires_grad=True)\n",
      "bias grad:  tensor([0.9118])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6787]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5782]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8732,   -11.4089,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0472], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8365]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8732,   -11.4089,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3069e-03,  0.0000e+00,  1.7047e-05,  6.9393e-05,  1.3518e-04,\n",
      "          4.0447e-04,  1.6242e-02,  9.6881e-04,  1.1639e-02,  2.1459e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0472], requires_grad=True)\n",
      "bias grad:  tensor([0.0659])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8365]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3188]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0786,  -322.8732,   -11.4090,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0479], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8046]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0786,  -322.8732,   -11.4090,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5311e-04, 5.3086e-05, 8.5890e-05, 1.0687e-03, 6.2592e-04, 9.6693e-04,\n",
      "         5.3190e-02, 2.7591e-03, 6.1241e-02, 1.7782e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0479], requires_grad=True)\n",
      "bias grad:  tensor([0.3720])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8046]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1257]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0791,  -322.8732,   -11.4096,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0516], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8172]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0791,  -322.8732,   -11.4096,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.9881e-04, -2.8772e-05,  4.1721e-05,  5.1662e-04,  2.9467e-04,\n",
      "          7.9814e-04,  3.1196e-02,  2.0297e-03,  3.8922e-02,  1.7315e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0516], requires_grad=True)\n",
      "bias grad:  tensor([0.2195])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8172]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6317]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0795,  -322.8732,   -11.4100,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0538], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7540]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0795,  -322.8732,   -11.4100,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[7.6577e-04, 1.3280e-05, 6.8871e-05, 5.4590e-04, 1.8456e-04, 2.5656e-03,\n",
      "         6.4337e-02, 1.9624e-03, 4.0796e-02, 1.3156e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0538], requires_grad=True)\n",
      "bias grad:  tensor([0.2304])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7540]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1490]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0801,  -322.8733,   -11.4104,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0561], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7391]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0801,  -322.8733,   -11.4104,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.0222e-03, -3.7766e-05, -3.0369e-05, -6.0216e-04, -4.3238e-04,\n",
      "         -2.9415e-04, -2.1147e-02, -8.5922e-04, -2.4002e-02,  1.6178e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0561], requires_grad=True)\n",
      "bias grad:  tensor([-0.1401])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7391]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6360]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0799,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0547], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6755]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0799,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.1559e-03,  0.0000e+00, -6.2289e-06, -1.2637e-04,  4.3165e-05,\n",
      "         -3.2455e-05,  1.7816e-03, -6.2200e-04, -1.0543e-02, -4.4813e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0547], requires_grad=True)\n",
      "bias grad:  tensor([-0.0539])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6755]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2230]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0799,  -322.8733,   -11.4100,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0542], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6978]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0799,  -322.8733,   -11.4100,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[4.8113e-03, 1.6908e-05, 1.0573e-04, 1.3344e-03, 1.0667e-03, 1.4892e-03,\n",
      "         7.7321e-02, 3.8773e-03, 8.2592e-02, 2.8031e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0542], requires_grad=True)\n",
      "bias grad:  tensor([0.4893])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6978]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0033]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0807,  -322.8733,   -11.4109,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0591], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6975]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0807,  -322.8733,   -11.4109,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5602e-02,  0.0000e+00, -2.6865e-05, -7.2934e-04, -9.6841e-04,\n",
      "         -4.4933e-04, -2.0477e-02, -1.4166e-03, -3.6100e-02, -3.5962e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0591], requires_grad=True)\n",
      "bias grad:  tensor([-0.2021])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6975]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2826]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0805,  -322.8733,   -11.4105,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0571], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6692]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0805,  -322.8733,   -11.4105,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.2293e-03,  1.1851e-05,  4.2315e-05,  3.3833e-04, -6.0764e-05,\n",
      "          1.3335e-03,  3.4935e-02,  1.3552e-03,  2.2797e-02,  9.4091e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0571], requires_grad=True)\n",
      "bias grad:  tensor([0.1390])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6692]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0225]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0808,  -322.8733,   -11.4107,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0584], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6670]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0808,  -322.8733,   -11.4107,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.5266e-04,  0.0000e+00, -1.0761e-04, -6.2308e-04, -4.3879e-05,\n",
      "         -5.3957e-03, -1.3830e-01, -3.0612e-03, -5.3280e-02, -4.7648e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0584], requires_grad=True)\n",
      "bias grad:  tensor([-0.3360])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6670]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1914]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0794,  -322.8733,   -11.4102,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0551], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5479]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0794,  -322.8733,   -11.4102,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.4313e-03,  2.4811e-05, -1.3485e-05,  3.4866e-04,  7.5556e-04,\n",
      "         -3.3235e-03, -6.0390e-02, -1.0237e-04,  1.2812e-02, -2.9401e-04]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias before:  Parameter containing:\n",
      "tensor([-0.0551], requires_grad=True)\n",
      "bias grad:  tensor([0.0611])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5479]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0684]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0788,  -322.8733,   -11.4103,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0557], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5410]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0788,  -322.8733,   -11.4103,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.0546e-03, -6.1655e-05, -2.6518e-05, -2.0205e-04,  1.2528e-04,\n",
      "         -1.6853e-03, -4.2645e-02, -3.2912e-04, -6.6636e-03,  1.7183e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0557], requires_grad=True)\n",
      "bias grad:  tensor([-0.0562])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5410]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6183]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8733,   -11.4103,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0551], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4792]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8733,   -11.4103,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6840e-04, -1.8707e-04, -6.2220e-05, -5.2874e-04, -7.8996e-05,\n",
      "         -3.8870e-03, -8.6433e-02, -2.0956e-03, -3.3936e-02, -2.2635e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0551], requires_grad=True)\n",
      "bias grad:  tensor([-0.2000])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4792]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7746]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0775,  -322.8732,   -11.4099,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0531], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4017]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0775,  -322.8732,   -11.4099,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0059, 0.0000, 0.0003, 0.0031, 0.0008, 0.0019, 0.1207, 0.0060, 0.1652,\n",
      "         0.0034]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0531], requires_grad=True)\n",
      "bias grad:  tensor([0.9471])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4017]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.5303]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0787,  -322.8733,   -11.4116,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0626], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7547]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0787,  -322.8733,   -11.4116,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.0210e-03,  2.3426e-05, -6.7242e-05, -1.0987e-03, -8.0363e-04,\n",
      "         -7.1570e-04, -4.8723e-02, -2.5328e-03, -5.6890e-02, -5.0135e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0626], requires_grad=True)\n",
      "bias grad:  tensor([-0.3277])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7547]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3499]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0783,  -322.8733,   -11.4110,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0593], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7198]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0783,  -322.8733,   -11.4110,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[4.7181e-04, 3.1315e-05, 7.8819e-05, 9.6617e-04, 5.3259e-04, 2.5516e-03,\n",
      "         7.7474e-02, 2.8272e-03, 5.3917e-02, 1.4872e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0593], requires_grad=True)\n",
      "bias grad:  tensor([0.3336])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7198]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2210]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0790,  -322.8733,   -11.4115,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0627], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7419]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0790,  -322.8733,   -11.4115,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0030, 0.0000, 0.0001, 0.0013, 0.0008, 0.0006, 0.0915, 0.0039, 0.0841,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0627], requires_grad=True)\n",
      "bias grad:  tensor([0.4844])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7419]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1695]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0800,  -322.8733,   -11.4124,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0675], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7249]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0800,  -322.8733,   -11.4124,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0545e-04,  0.0000e+00,  8.4694e-06, -6.8271e-05, -1.0987e-04,\n",
      "          3.4563e-04,  1.2656e-02,  2.1777e-04,  2.6675e-03,  5.3817e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0675], requires_grad=True)\n",
      "bias grad:  tensor([0.0152])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7249]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3115]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0801,  -322.8733,   -11.4124,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0677], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6938]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0801,  -322.8733,   -11.4124,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.9483e-04,  8.4609e-05,  4.6497e-05,  5.4239e-04, -1.0690e-06,\n",
      "          8.7648e-04,  3.6847e-02,  1.6625e-03,  3.4454e-02,  8.7904e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0677], requires_grad=True)\n",
      "bias grad:  tensor([0.1984])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6938]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2575]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0804,  -322.8734,   -11.4128,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0696], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7195]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0804,  -322.8734,   -11.4128,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.1159e-04, -1.0005e-04, -6.1144e-05, -7.3054e-04, -2.7354e-05,\n",
      "         -2.0305e-03, -5.7114e-02, -1.7589e-03, -3.7226e-02, -2.4775e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0696], requires_grad=True)\n",
      "bias grad:  tensor([-0.2121])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7195]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6865]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0799,  -322.8733,   -11.4124,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0675], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6509]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0799,  -322.8733,   -11.4124,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.2652e-04,  0.0000e+00,  6.1755e-05,  7.4578e-04,  4.3324e-04,\n",
      "          4.2977e-04,  2.9274e-02,  2.3726e-03,  4.6846e-02,  1.1529e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0675], requires_grad=True)\n",
      "bias grad:  tensor([0.2691])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6509]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0405]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0802,  -322.8734,   -11.4129,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0702], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6549]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0802,  -322.8734,   -11.4129,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2087e-04,  1.3855e-05,  1.2547e-05, -5.4665e-06,  1.0438e-04,\n",
      "          1.6415e-03,  3.2616e-02,  6.3713e-04,  3.2989e-03,  8.7469e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0702], requires_grad=True)\n",
      "bias grad:  tensor([0.0282])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6549]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4067]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0805,  -322.8734,   -11.4129,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0705], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6142]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0805,  -322.8734,   -11.4129,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8979e-03, 3.2543e-05, 6.5459e-05, 7.6858e-04, 5.3727e-04, 2.5987e-03,\n",
      "         7.6934e-02, 2.4123e-03, 4.4941e-02, 1.3619e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0705], requires_grad=True)\n",
      "bias grad:  tensor([0.2677])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6142]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2065]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0813,  -322.8734,   -11.4133,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0732], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6349]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0813,  -322.8734,   -11.4133,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0331e-04, 3.8956e-05, 1.2252e-04, 1.2958e-03, 5.5028e-04, 1.9135e-03,\n",
      "         8.2286e-02, 3.5426e-03, 7.3091e-02, 2.0673e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0732], requires_grad=True)\n",
      "bias grad:  tensor([0.4549])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6349]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1588]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0821,  -322.8734,   -11.4141,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0777], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6508]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0821,  -322.8734,   -11.4141,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[5.0106e-03, 0.0000e+00, 9.9985e-05, 1.2334e-03, 1.0037e-03, 1.4683e-03,\n",
      "         7.2792e-02, 3.5566e-03, 7.9705e-02, 2.3575e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0777], requires_grad=True)\n",
      "bias grad:  tensor([0.4543])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6508]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1026]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0828,  -322.8734,   -11.4149,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0823], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6610]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0828,  -322.8734,   -11.4149,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5278e-03, 0.0000e+00, 5.3396e-05, 5.7443e-04, 3.6682e-04, 8.4896e-04,\n",
      "         4.0551e-02, 2.0489e-03, 3.8529e-02, 9.8043e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0823], requires_grad=True)\n",
      "bias grad:  tensor([0.2211])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6610]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1736]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0832,  -322.8735,   -11.4152,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0845], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6437]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0832,  -322.8735,   -11.4152,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0012, 0.0003, 0.0003, 0.0033, 0.0009, 0.0078, 0.2333, 0.0076, 0.1472,\n",
      "         0.0025]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0845], requires_grad=True)\n",
      "bias grad:  tensor([0.9062])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6437]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6003]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0856,  -322.8735,   -11.4167,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0935], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8037]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0856,  -322.8735,   -11.4167,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.0144e-04,  0.0000e+00,  1.3674e-05,  2.9321e-05,  1.5223e-04,\n",
      "          4.0281e-04,  1.4334e-02,  7.7762e-04,  8.9022e-03,  1.8059e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0935], requires_grad=True)\n",
      "bias grad:  tensor([0.0502])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8037]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2436]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8735,   -11.4168,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0940], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7793]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8735,   -11.4168,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[5.2146e-04, 4.5688e-05, 8.1969e-05, 1.0408e-03, 6.0674e-04, 9.4844e-04,\n",
      "         5.2648e-02, 2.7247e-03, 5.9955e-02, 1.6778e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0940], requires_grad=True)\n",
      "bias grad:  tensor([0.3611])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7793]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1168]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0862,  -322.8736,   -11.4174,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0977], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7910]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0862,  -322.8736,   -11.4174,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.6893e-04, -3.0992e-05,  3.3511e-05,  3.9064e-04,  2.6345e-04,\n",
      "          8.2690e-04,  2.8282e-02,  1.7543e-03,  3.1907e-02,  1.5835e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0977], requires_grad=True)\n",
      "bias grad:  tensor([0.1797])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7910]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6530]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8736,   -11.4177,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0995], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7257]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8736,   -11.4177,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[7.7949e-04, 3.2626e-06, 6.3731e-05, 5.4319e-04, 2.0175e-04, 2.3135e-03,\n",
      "         5.9117e-02, 1.8863e-03, 3.8941e-02, 1.1808e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0995], requires_grad=True)\n",
      "bias grad:  tensor([0.2201])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7257]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0956]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0871,  -322.8736,   -11.4181,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1017], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7162]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0871,  -322.8736,   -11.4181,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.4989e-03, -2.4794e-05, -3.3682e-05, -6.5545e-04, -4.6841e-04,\n",
      "         -3.2179e-04, -2.3232e-02, -9.7836e-04, -2.6862e-02,  1.6976e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1017], requires_grad=True)\n",
      "bias grad:  tensor([-0.1549])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7162]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6050]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0869,  -322.8736,   -11.4178,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1001], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6557]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0869,  -322.8736,   -11.4178,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1250e-03,  0.0000e+00,  1.6960e-05,  1.7603e-04,  2.0701e-04,\n",
      "          1.8672e-04,  1.7360e-02,  1.9164e-04,  8.5042e-03, -2.9884e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1001], requires_grad=True)\n",
      "bias grad:  tensor([0.0549])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6557]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2555]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0870,  -322.8736,   -11.4179,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1007], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6812]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0870,  -322.8736,   -11.4179,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[3.9160e-03, 3.4289e-05, 9.5442e-05, 1.1451e-03, 8.2478e-04, 1.5009e-03,\n",
      "         6.9788e-02, 3.3707e-03, 7.1072e-02, 2.5650e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1007], requires_grad=True)\n",
      "bias grad:  tensor([0.4230])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6812]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0526]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0877,  -322.8737,   -11.4186,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1049], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6865]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0877,  -322.8737,   -11.4186,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5404e-02,  0.0000e+00, -2.5540e-05, -7.0801e-04, -9.4376e-04,\n",
      "         -4.3407e-04, -1.9789e-02, -1.3600e-03, -3.4897e-02, -3.4420e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1049], requires_grad=True)\n",
      "bias grad:  tensor([-0.1952])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6865]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2363]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0875,  -322.8737,   -11.4183,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1029], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6628]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0875,  -322.8737,   -11.4183,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8533e-03,  1.7938e-05,  4.4074e-05,  3.5860e-04,  2.5631e-06,\n",
      "          1.0082e-03,  2.9999e-02,  1.4198e-03,  2.5025e-02,  1.1554e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1029], requires_grad=True)\n",
      "bias grad:  tensor([0.1503])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6628]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0946]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0878,  -322.8737,   -11.4185,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1044], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6534]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0878,  -322.8737,   -11.4185,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.2888e-04,  0.0000e+00, -1.1332e-04, -6.9003e-04, -9.5120e-05,\n",
      "         -5.4025e-03, -1.3795e-01, -3.3139e-03, -5.8537e-02, -3.1091e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1044], requires_grad=True)\n",
      "bias grad:  tensor([-0.3656])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6534]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1415]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8736,   -11.4180,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1008], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5392]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8736,   -11.4180,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.1504e-03,  2.3907e-05, -3.2677e-05,  1.5180e-04,  6.8718e-04,\n",
      "         -3.5311e-03, -7.4356e-02, -7.2396e-04,  1.0514e-03, -8.0600e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1008], requires_grad=True)\n",
      "bias grad:  tensor([-0.0165])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5392]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0633]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8736,   -11.4180,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1006], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5456]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8736,   -11.4180,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.7365e-03, -6.3756e-05, -3.5965e-05, -3.9506e-04,  3.6857e-06,\n",
      "         -1.5679e-03, -4.6736e-02, -7.0618e-04, -1.5823e-02,  2.9825e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1006], requires_grad=True)\n",
      "bias grad:  tensor([-0.1105])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5456]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8022]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0852,  -322.8736,   -11.4178,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0995], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4653]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0852,  -322.8736,   -11.4178,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.5870e-03, -1.8754e-04, -3.6106e-05, -1.5839e-04,  3.2299e-04,\n",
      "         -3.4659e-03, -7.3005e-02, -1.0408e-03, -9.0518e-03,  1.5212e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0995], requires_grad=True)\n",
      "bias grad:  tensor([-0.0767])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4653]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6914]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0845,  -322.8736,   -11.4177,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0987], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3962]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0845,  -322.8736,   -11.4177,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0054, 0.0000, 0.0002, 0.0024, 0.0004, 0.0013, 0.0840, 0.0041, 0.1225,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0987], requires_grad=True)\n",
      "bias grad:  tensor([0.7039])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3962]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.3552]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0854,  -322.8737,   -11.4189,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1058], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7317]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0854,  -322.8737,   -11.4189,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.9803e-03,  1.7252e-05, -6.0480e-05, -9.3186e-04, -6.4440e-04,\n",
      "         -9.4892e-04, -4.8412e-02, -2.1511e-03, -4.6833e-02, -4.2789e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1058], requires_grad=True)\n",
      "bias grad:  tensor([-0.2767])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7317]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2803]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0849,  -322.8736,   -11.4185,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1030], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7037]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0849,  -322.8736,   -11.4185,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.0309e-05,  3.8747e-05,  8.3748e-05,  1.0190e-03,  5.7960e-04,\n",
      "          2.6148e-03,  7.9288e-02,  3.0217e-03,  5.7768e-02,  1.5110e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1030], requires_grad=True)\n",
      "bias grad:  tensor([0.3525])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7037]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1863]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8737,   -11.4191,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1065], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7223]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8737,   -11.4191,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1939e-03, 0.0000e+00, 6.8527e-05, 9.2888e-04, 6.1196e-04, 3.5540e-04,\n",
      "         4.7305e-02, 2.4680e-03, 5.6682e-02, 1.1761e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1065], requires_grad=True)\n",
      "bias grad:  tensor([0.3289])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7223]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0380]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0861,  -322.8737,   -11.4196,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1098], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7261]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0861,  -322.8737,   -11.4196,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1102e-03,  0.0000e+00, -7.4319e-06, -2.8130e-04, -2.5922e-04,\n",
      "          2.0525e-04,  3.2699e-03, -3.7632e-04, -1.0421e-02,  3.2086e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1098], requires_grad=True)\n",
      "bias grad:  tensor([-0.0594])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7261]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3750]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0862,  -322.8737,   -11.4195,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1092], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6886]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0862,  -322.8737,   -11.4195,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3958e-04,  6.5314e-05,  4.6683e-05,  4.8052e-04, -6.1386e-05,\n",
      "          9.4993e-04,  3.7039e-02,  1.6235e-03,  3.2932e-02,  9.3349e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1092], requires_grad=True)\n",
      "bias grad:  tensor([0.1897])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6886]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1562]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8737,   -11.4198,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1111], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7042]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8737,   -11.4198,  -302.5943]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight grad:  tensor([[ 8.6797e-04, -7.7153e-05, -4.9611e-05, -5.7537e-04,  2.7734e-05,\n",
      "         -1.8659e-03, -4.8375e-02, -1.3886e-03, -2.8740e-02, -1.8956e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1111], requires_grad=True)\n",
      "bias grad:  tensor([-0.1641])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7042]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5707]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0861,  -322.8737,   -11.4196,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1095], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6472]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0861,  -322.8737,   -11.4196,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.5938e-04,  0.0000e+00,  8.0105e-05,  9.4336e-04,  5.3593e-04,\n",
      "          8.3575e-04,  4.5115e-02,  2.9533e-03,  5.8888e-02,  1.5683e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1095], requires_grad=True)\n",
      "bias grad:  tensor([0.3453])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6472]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0005]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8737,   -11.4201,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1129], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6471]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8737,   -11.4201,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.1654e-04,  5.6175e-06,  3.6849e-06, -9.2590e-05,  1.2062e-04,\n",
      "          1.5460e-03,  2.8387e-02,  4.1372e-04, -2.3417e-03,  6.5530e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1129], requires_grad=True)\n",
      "bias grad:  tensor([-0.0005])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6471]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3864]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0868,  -322.8737,   -11.4201,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1129], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6085]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0868,  -322.8737,   -11.4201,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[6.8605e-04, 3.5772e-05, 3.3507e-05, 3.1212e-04, 1.1599e-04, 2.1463e-03,\n",
      "         5.1989e-02, 1.1012e-03, 1.7929e-02, 7.8680e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1129], requires_grad=True)\n",
      "bias grad:  tensor([0.1079])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6085]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1569]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0873,  -322.8737,   -11.4203,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1140], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6242]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0873,  -322.8737,   -11.4203,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[8.6986e-05, 4.2682e-05, 1.1275e-04, 1.2129e-03, 5.2219e-04, 1.8047e-03,\n",
      "         7.6294e-02, 3.2872e-03, 6.8755e-02, 1.9191e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1140], requires_grad=True)\n",
      "bias grad:  tensor([0.4238])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6242]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1984]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0881,  -322.8738,   -11.4210,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1183], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6440]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0881,  -322.8738,   -11.4210,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[3.8548e-03, 0.0000e+00, 4.1035e-05, 5.3245e-04, 4.6821e-04, 6.3444e-04,\n",
      "         3.1857e-02, 1.3528e-03, 3.3062e-02, 5.9015e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1183], requires_grad=True)\n",
      "bias grad:  tensor([0.1868])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6440]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2764]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0884,  -322.8738,   -11.4213,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1201], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6717]], requires_grad=True)\n",
      "Iteration 8 | Score: 0.5379179120063782\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0649,  -322.8724,   -11.3933,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7635e-03, 0.0000e+00, 2.6274e-05, 1.2972e-04, 2.2831e-04, 5.8825e-04,\n",
      "         2.6376e-02, 1.1417e-03, 1.8055e-02, 5.7311e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0446], requires_grad=True)\n",
      "bias grad:  tensor([0.1009])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8594]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6290]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0651,  -322.8724,   -11.3935,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0436], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7965]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0651,  -322.8724,   -11.3935,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[1.9372e-04, 2.7682e-04, 2.4709e-04, 2.8900e-03, 7.4103e-04, 6.8464e-03,\n",
      "         2.0945e-01, 6.8734e-03, 1.3208e-01, 2.3859e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0436], requires_grad=True)\n",
      "bias grad:  tensor([0.8111])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7965]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.0092]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0672,  -322.8725,   -11.3948,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0355], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8975]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0672,  -322.8725,   -11.3948,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7524e-03,  0.0000e+00,  2.0983e-05,  1.1116e-04,  1.1413e-04,\n",
      "          4.9755e-04,  1.8495e-02,  1.0977e-03,  1.4003e-02,  2.8709e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0355], requires_grad=True)\n",
      "bias grad:  tensor([0.0814])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8975]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3527]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0674,  -322.8725,   -11.3949,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0347], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8622]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0674,  -322.8725,   -11.3949,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2537e-04, 4.5889e-05, 8.4867e-05, 1.0861e-03, 6.8400e-04, 9.9833e-04,\n",
      "         5.4661e-02, 2.8612e-03, 6.3110e-02, 1.7942e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0347], requires_grad=True)\n",
      "bias grad:  tensor([0.3783])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8622]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0774]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0680,  -322.8725,   -11.3955,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0309], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8699]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0680,  -322.8725,   -11.3955,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.8295e-04, -3.6181e-05,  4.3718e-05,  5.4203e-04,  3.4437e-04,\n",
      "          7.9122e-04,  3.1637e-02,  2.1782e-03,  4.1139e-02,  1.8328e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0309], requires_grad=True)\n",
      "bias grad:  tensor([0.2321])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8699]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7316]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0683,  -322.8726,   -11.3960,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0286], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7968]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0683,  -322.8726,   -11.3960,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1420e-04, 1.1176e-06, 7.5044e-05, 6.3758e-04, 2.3918e-04, 2.6970e-03,\n",
      "         7.0330e-02, 2.2101e-03, 4.5643e-02, 1.3574e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0286], requires_grad=True)\n",
      "bias grad:  tensor([0.2581])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7968]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1512]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0690,  -322.8726,   -11.3964,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0260], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7817]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0690,  -322.8726,   -11.3964,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.6510e-03, -2.9786e-05, -1.2957e-05, -3.4312e-04, -1.8676e-04,\n",
      "         -9.0082e-05, -8.0438e-03, -1.6128e-04, -8.5236e-03,  4.9902e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0260], requires_grad=True)\n",
      "bias grad:  tensor([-0.0504])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7817]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6668]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0689,  -322.8726,   -11.3963,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0265], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7150]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0689,  -322.8726,   -11.3963,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8095e-03, 0.0000e+00, 3.0369e-05, 3.6134e-04, 3.1354e-04, 2.7883e-04,\n",
      "         2.4258e-02, 5.9209e-04, 1.8500e-02, 1.5663e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0265], requires_grad=True)\n",
      "bias grad:  tensor([0.1138])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7150]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2878]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0691,  -322.8726,   -11.3965,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0253], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7438]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0691,  -322.8726,   -11.3965,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2204e-03, 2.4807e-05, 1.0861e-04, 1.3120e-03, 9.6534e-04, 1.5134e-03,\n",
      "         7.5730e-02, 3.8305e-03, 8.2010e-02, 2.8174e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0253], requires_grad=True)\n",
      "bias grad:  tensor([0.4856])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7438]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0146]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0699,  -322.8726,   -11.3973,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0205], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7423]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0699,  -322.8726,   -11.3973,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6622e-02,  0.0000e+00, -2.7856e-05, -7.6763e-04, -1.0221e-03,\n",
      "         -4.7127e-04, -2.1482e-02, -1.4791e-03, -3.7881e-02, -3.7468e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0205], requires_grad=True)\n",
      "bias grad:  tensor([-0.2119])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7423]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3086]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0697,  -322.8726,   -11.3970,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0226], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7114]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0697,  -322.8726,   -11.3970,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.1735e-03,  1.7501e-05,  5.2779e-05,  5.0727e-04,  1.4952e-04,\n",
      "          1.3944e-03,  4.3011e-02,  1.7794e-03,  3.3084e-02,  1.1431e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0226], requires_grad=True)\n",
      "bias grad:  tensor([0.1972])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7114]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0360]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0701,  -322.8727,   -11.3973,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0206], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7078]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0701,  -322.8727,   -11.3973,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.8077e-04,  0.0000e+00, -7.9751e-05, -3.0331e-04,  1.8097e-04,\n",
      "         -4.8632e-03, -1.1437e-01, -2.1523e-03, -3.2989e-02,  3.4734e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0206], requires_grad=True)\n",
      "bias grad:  tensor([-0.2176])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7078]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1880]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0690,  -322.8726,   -11.3970,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0228], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5890]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0690,  -322.8726,   -11.3970,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.6917e-03,  2.7254e-05,  1.2634e-05,  7.1988e-04,  1.0472e-03,\n",
      "         -2.8383e-03, -4.2744e-02,  8.9052e-04,  3.4493e-02, -5.7759e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0228], requires_grad=True)\n",
      "bias grad:  tensor([0.1844])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5890]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0523]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0685,  -322.8726,   -11.3973,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0210], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5943]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0685,  -322.8726,   -11.3973,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.0499e-03, -5.1875e-05, -2.2639e-05, -2.1517e-04,  1.5580e-04,\n",
      "         -1.3653e-03, -3.6886e-02, -1.8597e-04, -5.6532e-03,  4.2014e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0210], requires_grad=True)\n",
      "bias grad:  tensor([-0.0513])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5943]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7371]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0682,  -322.8726,   -11.3972,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0215], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5206]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0682,  -322.8726,   -11.3972,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[ 9.7838e-04, -1.8667e-04, -3.3302e-05, -1.7956e-04,  2.4861e-04,\n",
      "         -3.5062e-03, -6.9468e-02, -1.1482e-03, -1.2597e-02,  1.9119e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0215], requires_grad=True)\n",
      "bias grad:  tensor([-0.0793])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5206]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7370]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0675,  -322.8726,   -11.3971,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0223], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4469]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0675,  -322.8726,   -11.3971,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0050, 0.0000, 0.0002, 0.0027, 0.0005, 0.0015, 0.1023, 0.0050, 0.1427,\n",
      "         0.0029]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0223], requires_grad=True)\n",
      "bias grad:  tensor([0.8184])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4469]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.9662]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0685,  -322.8727,   -11.3985,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0141], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7435]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0685,  -322.8727,   -11.3985,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.1634e-03,  3.4133e-05, -4.2638e-05, -7.3972e-04, -5.5443e-04,\n",
      "         -5.5452e-04, -3.4018e-02, -1.5186e-03, -3.5362e-02, -1.2017e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0141], requires_grad=True)\n",
      "bias grad:  tensor([-0.2045])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7435]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2608]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0682,  -322.8727,   -11.3982,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0161], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7174]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0682,  -322.8727,   -11.3982,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.2072e-04,  3.7850e-05,  8.9260e-05,  1.0488e-03,  5.2838e-04,\n",
      "          2.8069e-03,  8.5260e-02,  3.1597e-03,  5.8073e-02,  1.8112e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0161], requires_grad=True)\n",
      "bias grad:  tensor([0.3651])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7174]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1797]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0690,  -322.8727,   -11.3988,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0125], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7354]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0690,  -322.8727,   -11.3988,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[4.3287e-03, 0.0000e+00, 9.5339e-05, 1.2712e-03, 8.9134e-04, 5.7043e-04,\n",
      "         7.0580e-02, 3.5001e-03, 7.8612e-02, 1.7217e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0125], requires_grad=True)\n",
      "bias grad:  tensor([0.4555])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7354]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0304]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0697,  -322.8727,   -11.3996,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0079], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7323]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0697,  -322.8727,   -11.3996,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5347e-05,  0.0000e+00,  2.3931e-05,  1.5021e-04,  1.0474e-05,\n",
      "          4.0139e-04,  2.1506e-02,  8.2091e-04,  1.4978e-02,  6.7767e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0079], requires_grad=True)\n",
      "bias grad:  tensor([0.0855])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7323]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2933]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0699,  -322.8727,   -11.3997,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0071], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7030]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0699,  -322.8727,   -11.3997,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[6.6604e-04, 7.2304e-05, 5.7189e-05, 6.8781e-04, 1.4502e-04, 1.0762e-03,\n",
      "         4.4786e-02, 2.0731e-03, 4.3162e-02, 1.0834e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0071], requires_grad=True)\n",
      "bias grad:  tensor([0.2489])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7030]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1967]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0704,  -322.8728,   -11.4001,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0046], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7227]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0704,  -322.8728,   -11.4001,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6686e-03, -8.1485e-05, -4.2248e-05, -4.6779e-04,  1.3920e-04,\n",
      "         -1.7699e-03, -4.4901e-02, -1.1297e-03, -2.2975e-02, -4.5179e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0046], requires_grad=True)\n",
      "bias grad:  tensor([-0.1289])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7227]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5471]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0699,  -322.8728,   -11.3999,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0059], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6680]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0699,  -322.8728,   -11.3999,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.4763e-05,  0.0000e+00,  8.4757e-05,  9.6649e-04,  5.7343e-04,\n",
      "          1.1043e-03,  5.0098e-02,  3.0629e-03,  6.0027e-02,  1.5687e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0059], requires_grad=True)\n",
      "bias grad:  tensor([0.3561])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6680]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0078]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0704,  -322.8728,   -11.4005,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0023], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6687]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0704,  -322.8728,   -11.4005,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[7.7011e-04, 1.0344e-05, 1.1450e-05, 1.8366e-05, 1.6181e-04, 1.6815e-03,\n",
      "         3.4142e-02, 6.7932e-04, 3.9056e-03, 8.2963e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0023], requires_grad=True)\n",
      "bias grad:  tensor([0.0341])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6687]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3600]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0708,  -322.8728,   -11.4005,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0020], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6327]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0708,  -322.8728,   -11.4005,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[1.9294e-03, 4.6570e-05, 5.9444e-05, 6.4595e-04, 3.6532e-04, 2.8161e-03,\n",
      "         7.6219e-02, 2.0397e-03, 3.7578e-02, 1.2204e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0020], requires_grad=True)\n",
      "bias grad:  tensor([0.2217])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6327]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1801]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0715,  -322.8728,   -11.4009,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0002], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6507]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0715,  -322.8728,   -11.4009,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[2.3276e-04, 4.0632e-05, 1.3776e-04, 1.4698e-03, 6.3553e-04, 2.0326e-03,\n",
      "         9.1030e-02, 3.9868e-03, 8.2324e-02, 2.3419e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0002], requires_grad=True)\n",
      "bias grad:  tensor([0.5170])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6507]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2312]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0724,  -322.8729,   -11.4017,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0054], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6739]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0724,  -322.8729,   -11.4017,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[5.2902e-03, 0.0000e+00, 7.6437e-05, 9.6163e-04, 7.7344e-04, 1.4578e-03,\n",
      "         6.2953e-02, 2.6113e-03, 5.9964e-02, 1.3298e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0054], requires_grad=True)\n",
      "bias grad:  tensor([0.3411])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6739]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2124]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0731,  -322.8729,   -11.4023,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0088], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6951]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0731,  -322.8729,   -11.4023,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[2.2320e-03, 0.0000e+00, 4.7354e-05, 5.0315e-04, 4.1525e-04, 8.5484e-04,\n",
      "         3.9618e-02, 1.9290e-03, 3.5276e-02, 7.0125e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0088], requires_grad=True)\n",
      "bias grad:  tensor([0.2019])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6951]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2510]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0735,  -322.8729,   -11.4027,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0108], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6700]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0735,  -322.8729,   -11.4027,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0016, 0.0003, 0.0003, 0.0034, 0.0009, 0.0080, 0.2397, 0.0079, 0.1556,\n",
      "         0.0027]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0108], requires_grad=True)\n",
      "bias grad:  tensor([0.9552])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6700]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.7441]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0759,  -322.8730,   -11.4043,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0204], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8444]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0759,  -322.8730,   -11.4043,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3051e-03,  0.0000e+00,  1.7179e-05,  7.2738e-05,  1.5756e-04,\n",
      "          4.9149e-04,  1.8466e-02,  1.0031e-03,  1.2222e-02,  2.3994e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0204], requires_grad=True)\n",
      "bias grad:  tensor([0.0695])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8444]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3211]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0760,  -322.8730,   -11.4044,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0211], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8123]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0760,  -322.8730,   -11.4044,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7596e-04, 5.2398e-05, 9.0988e-05, 1.1581e-03, 7.1693e-04, 1.0480e-03,\n",
      "         5.6967e-02, 3.0416e-03, 6.7458e-02, 1.9212e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0211], requires_grad=True)\n",
      "bias grad:  tensor([0.4039])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8123]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1196]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0766,  -322.8730,   -11.4051,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0251], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8243]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0766,  -322.8730,   -11.4051,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.4227e-04, -2.4851e-05,  4.0416e-05,  4.9846e-04,  2.9073e-04,\n",
      "          7.1469e-04,  2.9254e-02,  1.9697e-03,  3.7642e-02,  1.7065e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0251], requires_grad=True)\n",
      "bias grad:  tensor([0.2123])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8243]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6254]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0769,  -322.8731,   -11.4054,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0273], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7617]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0769,  -322.8731,   -11.4054,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6458e-05, 1.0820e-05, 8.1415e-05, 7.3628e-04, 2.3469e-04, 2.7250e-03,\n",
      "         7.1758e-02, 2.4122e-03, 5.0521e-02, 1.4869e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0273], requires_grad=True)\n",
      "bias grad:  tensor([0.2865])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7617]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0226]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0776,  -322.8731,   -11.4059,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0301], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7595]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0776,  -322.8731,   -11.4059,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.0614e-03, -3.6114e-05, -3.3917e-05, -6.5416e-04, -3.8774e-04,\n",
      "         -2.8907e-04, -2.1979e-02, -8.6795e-04, -2.5489e-02,  2.1197e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0301], requires_grad=True)\n",
      "bias grad:  tensor([-0.1483])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7595]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7860]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0774,  -322.8731,   -11.4057,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0286], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6809]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0774,  -322.8731,   -11.4057,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0145e-03, 0.0000e+00, 1.9155e-05, 2.0468e-04, 1.9374e-04, 1.8564e-04,\n",
      "         1.8457e-02, 2.1268e-04, 9.2948e-03, 1.9129e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0286], requires_grad=True)\n",
      "bias grad:  tensor([0.0607])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6809]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3107]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0776,  -322.8731,   -11.4058,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0292], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7119]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0776,  -322.8731,   -11.4058,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[5.0690e-03, 3.4117e-05, 1.0779e-04, 1.3622e-03, 1.0520e-03, 1.3756e-03,\n",
      "         7.5537e-02, 3.9300e-03, 8.4174e-02, 2.7742e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0292], requires_grad=True)\n",
      "bias grad:  tensor([0.4976])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7119]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0419]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0783,  -322.8731,   -11.4066,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0342], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7161]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0783,  -322.8731,   -11.4066,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0751e-02,  0.0000e+00,  1.7476e-05, -6.1203e-05, -2.1598e-04,\n",
      "          3.9778e-05,  1.5432e-03,  4.3545e-04,  2.3574e-03,  1.4911e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0342], requires_grad=True)\n",
      "bias grad:  tensor([0.0179])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7161]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1729]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0784,  -322.8731,   -11.4066,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0344], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6988]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0784,  -322.8731,   -11.4066,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.2811e-03,  1.3372e-05,  6.9511e-05,  7.1612e-04,  3.0383e-04,\n",
      "          1.4842e-03,  5.1450e-02,  2.3718e-03,  4.5865e-02,  1.4163e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0344], requires_grad=True)\n",
      "bias grad:  tensor([0.2709])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6988]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0219]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0789,  -322.8732,   -11.4071,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0371], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6967]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0789,  -322.8732,   -11.4071,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6192e-04,  0.0000e+00, -1.0510e-04, -5.7316e-04,  1.1665e-05,\n",
      "         -5.4786e-03, -1.3538e-01, -3.0117e-03, -5.1034e-02, -2.7876e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0371], requires_grad=True)\n",
      "bias grad:  tensor([-0.3233])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6967]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1601]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0775,  -322.8731,   -11.4066,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0339], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5807]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0775,  -322.8731,   -11.4066,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.5240e-03,  2.7212e-05, -2.2143e-05,  2.6383e-04,  6.7500e-04,\n",
      "         -3.1875e-03, -6.4842e-02, -3.6826e-04,  7.2422e-03, -6.6792e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0339], requires_grad=True)\n",
      "bias grad:  tensor([0.0244])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5807]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0842]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0769,  -322.8731,   -11.4067,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0341], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5891]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0769,  -322.8731,   -11.4067,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.0555e-03, -6.1440e-05, -3.5976e-05, -3.2429e-04,  1.7995e-04,\n",
      "         -1.7695e-03, -4.7455e-02, -5.6341e-04, -1.2186e-02,  1.5550e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0341], requires_grad=True)\n",
      "bias grad:  tensor([-0.0897])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5891]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8111]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0764,  -322.8731,   -11.4065,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0332], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5080]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0764,  -322.8731,   -11.4065,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.8891e-04, -1.8805e-04, -4.7761e-05, -3.2327e-04,  1.4826e-04,\n",
      "         -3.7127e-03, -7.6542e-02, -1.5497e-03, -2.0657e-02, -3.9261e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0332], requires_grad=True)\n",
      "bias grad:  tensor([-0.1300])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5080]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7567]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0756,  -322.8731,   -11.4063,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0319], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4323]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0756,  -322.8731,   -11.4063,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0047, 0.0000, 0.0002, 0.0023, 0.0004, 0.0013, 0.0872, 0.0042, 0.1211,\n",
      "         0.0025]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0319], requires_grad=True)\n",
      "bias grad:  tensor([0.6953])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4323]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.8630]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0765,  -322.8731,   -11.4075,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0389], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7186]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0765,  -322.8731,   -11.4075,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.3990e-03,  2.5743e-05, -6.3749e-05, -9.9728e-04, -7.1756e-04,\n",
      "         -8.3241e-04, -5.0410e-02, -2.3916e-03, -5.1893e-02, -5.2364e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0389], requires_grad=True)\n",
      "bias grad:  tensor([-0.3017])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7186]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1980]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0760,  -322.8731,   -11.4070,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0359], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6988]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0760,  -322.8731,   -11.4070,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.5356e-04,  3.6450e-05,  7.6015e-05,  8.8910e-04,  4.0869e-04,\n",
      "          2.7015e-03,  7.7132e-02,  2.6804e-03,  4.7446e-02,  1.5671e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0359], requires_grad=True)\n",
      "bias grad:  tensor([0.3077])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6988]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1861]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0768,  -322.8731,   -11.4075,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0389], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7174]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0768,  -322.8731,   -11.4075,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0048, 0.0000, 0.0001, 0.0017, 0.0012, 0.0009, 0.1091, 0.0048, 0.1049,\n",
      "         0.0025]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0389], requires_grad=True)\n",
      "bias grad:  tensor([0.6048])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7174]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1579]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0779,  -322.8732,   -11.4085,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0450], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7016]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0779,  -322.8732,   -11.4085,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.4780e-04,  0.0000e+00,  1.0897e-05, -1.9444e-05, -6.1275e-05,\n",
      "          3.7313e-04,  1.4441e-02,  3.3946e-04,  5.1319e-03,  5.5551e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0450], requires_grad=True)\n",
      "bias grad:  tensor([0.0291])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7016]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3422]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0780,  -322.8732,   -11.4086,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0453], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6674]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0780,  -322.8732,   -11.4086,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[8.7332e-04, 8.5271e-05, 5.1732e-05, 6.0068e-04, 3.1942e-05, 1.0311e-03,\n",
      "         4.2107e-02, 1.8542e-03, 3.8506e-02, 1.0162e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0453], requires_grad=True)\n",
      "bias grad:  tensor([0.2222])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6674]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2188]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8732,   -11.4090,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0475], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6893]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8732,   -11.4090,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.0172e-03, -7.6417e-05, -4.1065e-05, -4.7315e-04,  5.7783e-05,\n",
      "         -1.6365e-03, -4.3348e-02, -1.1581e-03, -2.3575e-02, -6.5264e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0475], requires_grad=True)\n",
      "bias grad:  tensor([-0.1336])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6893]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4368]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0780,  -322.8732,   -11.4087,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0462], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6456]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0780,  -322.8732,   -11.4087,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.5656e-04,  0.0000e+00,  7.7579e-05,  8.6933e-04,  4.7875e-04,\n",
      "          9.6131e-04,  4.3031e-02,  2.8253e-03,  5.4525e-02,  1.4678e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0462], requires_grad=True)\n",
      "bias grad:  tensor([0.3221])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6456]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0037]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8733,   -11.4093,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0494], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6452]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8733,   -11.4093,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[1.2466e-03, 1.5136e-05, 2.5522e-05, 2.0082e-04, 2.3679e-04, 1.6400e-03,\n",
      "         3.9976e-02, 1.0310e-03, 1.4111e-02, 9.5506e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0494], requires_grad=True)\n",
      "bias grad:  tensor([0.0894])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6452]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2883]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0788,  -322.8733,   -11.4094,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0503], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6164]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0788,  -322.8733,   -11.4094,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1976e-03, 3.2496e-05, 7.3656e-05, 8.7617e-04, 6.2499e-04, 2.5914e-03,\n",
      "         8.0727e-02, 2.6990e-03, 5.1671e-02, 1.5361e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0503], requires_grad=True)\n",
      "bias grad:  tensor([0.3064])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6164]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1632]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0796,  -322.8733,   -11.4100,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0533], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6327]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0796,  -322.8733,   -11.4100,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[2.3515e-04, 4.0853e-05, 1.3570e-04, 1.4614e-03, 6.5353e-04, 2.1382e-03,\n",
      "         9.1284e-02, 4.0417e-03, 8.3108e-02, 2.2799e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0533], requires_grad=True)\n",
      "bias grad:  tensor([0.5130])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6327]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1971]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0805,  -322.8733,   -11.4108,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0585], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6524]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0805,  -322.8733,   -11.4108,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[4.6005e-03, 0.0000e+00, 9.8016e-05, 1.2239e-03, 9.2183e-04, 1.3967e-03,\n",
      "         6.8796e-02, 3.3127e-03, 7.5438e-02, 2.1878e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0585], requires_grad=True)\n",
      "bias grad:  tensor([0.4321])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6524]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2820]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0812,  -322.8734,   -11.4115,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0628], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6806]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0812,  -322.8734,   -11.4115,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6315e-03, 0.0000e+00, 3.1861e-05, 3.0842e-04, 2.4986e-04, 6.2161e-04,\n",
      "         2.8704e-02, 1.3668e-03, 2.3682e-02, 4.1980e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0628], requires_grad=True)\n",
      "bias grad:  tensor([0.1342])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6806]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2476]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0815,  -322.8734,   -11.4118,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0641], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6559]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0815,  -322.8734,   -11.4118,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0010, 0.0003, 0.0003, 0.0031, 0.0008, 0.0075, 0.2228, 0.0072, 0.1372,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0641], requires_grad=True)\n",
      "bias grad:  tensor([0.8478])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6559]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5718]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0837,  -322.8734,   -11.4131,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0726], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8130]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0837,  -322.8734,   -11.4131,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7120e-03,  0.0000e+00,  1.3905e-05, -3.1966e-06,  7.6535e-06,\n",
      "          5.2642e-04,  1.3712e-02,  6.6320e-04,  6.1895e-03,  2.1549e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0726], requires_grad=True)\n",
      "bias grad:  tensor([0.0370])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8130]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1948]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0839,  -322.8734,   -11.4132,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0730], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7936]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0839,  -322.8734,   -11.4132,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5976e-04, 4.4674e-05, 7.2639e-05, 9.2806e-04, 5.7527e-04, 8.6012e-04,\n",
      "         4.6283e-02, 2.4026e-03, 5.3579e-02, 1.5231e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0730], requires_grad=True)\n",
      "bias grad:  tensor([0.3223])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7936]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1194]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0843,  -322.8734,   -11.4137,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0762], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8055]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0843,  -322.8734,   -11.4137,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6874e-04, -2.6371e-05,  4.9149e-05,  5.9998e-04,  4.0482e-04,\n",
      "          1.0740e-03,  3.8172e-02,  2.3107e-03,  4.4468e-02,  1.8529e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0762], requires_grad=True)\n",
      "bias grad:  tensor([0.2514])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8055]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6217]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0847,  -322.8735,   -11.4142,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0787], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7433]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0847,  -322.8735,   -11.4142,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[1.4838e-04, 1.0270e-05, 6.1117e-05, 4.9726e-04, 9.7129e-05, 2.3759e-03,\n",
      "         5.7366e-02, 1.7293e-03, 3.5441e-02, 1.1848e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0787], requires_grad=True)\n",
      "bias grad:  tensor([0.2007])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7433]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0217]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0853,  -322.8735,   -11.4145,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0807], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7412]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0853,  -322.8735,   -11.4145,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.9678e-03, -3.3326e-05, -2.4409e-05, -5.3527e-04, -4.0323e-04,\n",
      "         -1.9919e-04, -1.7612e-02, -5.8403e-04, -1.9055e-02,  3.1906e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0807], requires_grad=True)\n",
      "bias grad:  tensor([-0.1118])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7412]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6942]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0851,  -322.8735,   -11.4144,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0796], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6717]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0851,  -322.8735,   -11.4144,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.4198e-03,  0.0000e+00, -4.1462e-06, -9.5111e-05,  4.3779e-05,\n",
      "         -2.0247e-05,  2.1983e-03, -5.9793e-04, -8.5981e-03, -3.5450e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0796], requires_grad=True)\n",
      "bias grad:  tensor([-0.0423])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6717]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2371]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0851,  -322.8735,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0792], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6954]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0851,  -322.8735,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[4.3109e-03, 3.1794e-05, 1.0518e-04, 1.3105e-03, 9.8993e-04, 1.4714e-03,\n",
      "         7.4936e-02, 3.8302e-03, 8.1069e-02, 2.7463e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0792], requires_grad=True)\n",
      "bias grad:  tensor([0.4803])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6954]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0414]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0859,  -322.8735,   -11.4151,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0840], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6996]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0859,  -322.8735,   -11.4151,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7355e-02,  0.0000e+00, -3.0573e-05, -8.1975e-04, -1.0859e-03,\n",
      "         -5.0652e-04, -2.3078e-02, -1.6028e-03, -4.0679e-02, -4.0764e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0840], requires_grad=True)\n",
      "bias grad:  tensor([-0.2278])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6996]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2744]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8735,   -11.4147,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0817], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6721]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8735,   -11.4147,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.8272e-03,  1.6225e-05,  3.3570e-05,  2.3167e-04, -1.0708e-04,\n",
      "          1.0912e-03,  2.8282e-02,  1.0159e-03,  1.6764e-02,  8.0480e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0817], requires_grad=True)\n",
      "bias grad:  tensor([0.1029])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6721]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0202]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0860,  -322.8735,   -11.4148,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0827], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6701]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0860,  -322.8735,   -11.4148,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.7773e-04,  0.0000e+00, -1.2771e-04, -8.6940e-04, -2.0443e-04,\n",
      "         -5.6302e-03, -1.5027e-01, -3.8198e-03, -6.9732e-02, -4.4082e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0827], requires_grad=True)\n",
      "bias grad:  tensor([-0.4305])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6701]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1456]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0844,  -322.8735,   -11.4141,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0784], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5556]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0844,  -322.8735,   -11.4141,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.4819e-03,  2.1339e-05, -1.2441e-05,  3.7795e-04,  7.4552e-04,\n",
      "         -3.2703e-03, -6.0040e-02, -3.2570e-05,  1.4114e-02, -3.4541e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0784], requires_grad=True)\n",
      "bias grad:  tensor([0.0672])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5556]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0177]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0838,  -322.8735,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0791], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5538]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0838,  -322.8735,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.8354e-03, -5.8472e-05, -1.4341e-05, -6.9345e-05,  2.2218e-04,\n",
      "         -1.2917e-03, -3.1268e-02,  6.3537e-05,  1.1585e-03,  4.3709e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0791], requires_grad=True)\n",
      "bias grad:  tensor([-0.0102])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5538]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5593]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0835,  -322.8735,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0790], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4979]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0835,  -322.8735,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.4324e-04, -1.8757e-04, -4.5369e-05, -3.6192e-04,  2.4876e-05,\n",
      "         -3.7299e-03, -7.8727e-02, -1.7128e-03, -2.3653e-02, -1.7801e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0790], requires_grad=True)\n",
      "bias grad:  tensor([-0.1470])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4979]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6697]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0827,  -322.8734,   -11.4141,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0775], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4309]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0827,  -322.8734,   -11.4141,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0050, 0.0000, 0.0002, 0.0023, 0.0003, 0.0011, 0.0784, 0.0039, 0.1172,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0775], requires_grad=True)\n",
      "bias grad:  tensor([0.6742])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4309]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.0910]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0835,  -322.8735,   -11.4152,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0843], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7400]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0835,  -322.8735,   -11.4152,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.0468e-03,  2.7492e-05, -6.6876e-05, -1.0603e-03, -7.5166e-04,\n",
      "         -8.4840e-04, -5.1985e-02, -2.4915e-03, -5.4960e-02, -5.3962e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0843], requires_grad=True)\n",
      "bias grad:  tensor([-0.3188])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7400]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2882]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0830,  -322.8734,   -11.4147,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0811], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7112]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0830,  -322.8734,   -11.4147,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4410e-04,  3.3336e-05,  8.1006e-05,  9.9049e-04,  5.3754e-04,\n",
      "          2.6592e-03,  7.9312e-02,  2.9027e-03,  5.3908e-02,  1.5299e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0811], requires_grad=True)\n",
      "bias grad:  tensor([0.3381])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7112]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2509]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0838,  -322.8735,   -11.4152,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0845], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7363]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0838,  -322.8735,   -11.4152,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3737e-03, 0.0000e+00, 7.9420e-05, 1.0705e-03, 7.7113e-04, 4.7282e-04,\n",
      "         5.3760e-02, 2.9597e-03, 6.6319e-02, 1.4899e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0845], requires_grad=True)\n",
      "bias grad:  tensor([0.3838])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7363]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0778]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0843,  -322.8735,   -11.4159,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0883], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7285]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0843,  -322.8735,   -11.4159,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2885e-03,  0.0000e+00,  6.3938e-07, -2.0183e-04, -2.3425e-04,\n",
      "          2.0461e-04,  7.3016e-03, -7.4520e-05, -5.0642e-03,  3.9504e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0883], requires_grad=True)\n",
      "bias grad:  tensor([-0.0289])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7285]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3660]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0844,  -322.8735,   -11.4158,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0880], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6919]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0844,  -322.8735,   -11.4158,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.2935e-04,  7.5668e-05,  4.1463e-05,  4.5607e-04, -6.7142e-05,\n",
      "          8.4277e-04,  3.3864e-02,  1.4544e-03,  2.9881e-02,  8.0478e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0880], requires_grad=True)\n",
      "bias grad:  tensor([0.1721])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6919]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2081]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0848,  -322.8735,   -11.4161,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0897], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7127]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0848,  -322.8735,   -11.4161,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.2114e-03, -1.0037e-04, -5.4164e-05, -6.1764e-04,  5.7525e-05,\n",
      "         -1.9590e-03, -5.3564e-02, -1.4728e-03, -3.0977e-02, -2.8787e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0897], requires_grad=True)\n",
      "bias grad:  tensor([-0.1764])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7127]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6476]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0842,  -322.8735,   -11.4158,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0880], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6479]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0842,  -322.8735,   -11.4158,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7472e-04,  0.0000e+00,  6.4733e-05,  7.5264e-04,  4.4281e-04,\n",
      "          7.4067e-04,  3.7044e-02,  2.3835e-03,  4.7008e-02,  1.2071e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0880], requires_grad=True)\n",
      "bias grad:  tensor([0.2761])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6479]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0467]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0846,  -322.8735,   -11.4163,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0907], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6526]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0846,  -322.8735,   -11.4163,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7341e-03, 2.1259e-05, 2.8614e-05, 2.1686e-04, 3.4359e-04, 1.7035e-03,\n",
      "         4.2027e-02, 1.2013e-03, 1.7366e-02, 1.2347e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0907], requires_grad=True)\n",
      "bias grad:  tensor([0.1076])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6526]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3960]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0850,  -322.8735,   -11.4165,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0918], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6130]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0850,  -322.8735,   -11.4165,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[1.9400e-03, 2.9290e-05, 4.7563e-05, 5.2288e-04, 2.8448e-04, 2.1179e-03,\n",
      "         5.7971e-02, 1.5965e-03, 2.9620e-02, 1.0177e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0918], requires_grad=True)\n",
      "bias grad:  tensor([0.1774])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6130]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2276]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0856,  -322.8736,   -11.4168,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0936], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6358]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0856,  -322.8736,   -11.4168,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1936e-04, 4.3781e-05, 1.3499e-04, 1.4326e-03, 5.8460e-04, 1.9198e-03,\n",
      "         8.7412e-02, 3.6935e-03, 7.9889e-02, 2.1146e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0936], requires_grad=True)\n",
      "bias grad:  tensor([0.4942])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6358]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3064]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8736,   -11.4176,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0985], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6664]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0865,  -322.8736,   -11.4176,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[4.5304e-03, 0.0000e+00, 4.9880e-05, 6.2661e-04, 5.6123e-04, 1.0007e-03,\n",
      "         4.5005e-02, 1.7231e-03, 3.9992e-02, 8.8122e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0985], requires_grad=True)\n",
      "bias grad:  tensor([0.2272])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6664]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1234]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0869,  -322.8736,   -11.4180,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1008], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6788]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0869,  -322.8736,   -11.4180,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.2953e-04,  0.0000e+00,  1.8679e-05,  1.4359e-04, -2.0551e-05,\n",
      "          4.8923e-04,  1.8362e-02,  7.6670e-04,  1.2042e-02,  1.5277e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1008], requires_grad=True)\n",
      "bias grad:  tensor([0.0669])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6788]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0692]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0871,  -322.8736,   -11.4181,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1015], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6718]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0871,  -322.8736,   -11.4181,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[1.3847e-04, 2.8830e-04, 2.4780e-04, 2.9115e-03, 7.0905e-04, 7.1574e-03,\n",
      "         2.1274e-01, 6.8019e-03, 1.3014e-01, 2.2209e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1015], requires_grad=True)\n",
      "bias grad:  tensor([0.8034])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6718]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.2946]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0892,  -322.8737,   -11.4194,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1095], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8013]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0892,  -322.8737,   -11.4194,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2687e-03,  0.0000e+00,  1.8671e-05,  1.0030e-04,  9.6112e-05,\n",
      "          3.7613e-04,  1.5353e-02,  9.5505e-04,  1.2304e-02,  2.1319e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1095], requires_grad=True)\n",
      "bias grad:  tensor([0.0699])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8013]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1869]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0894,  -322.8737,   -11.4195,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1102], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7826]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0894,  -322.8737,   -11.4195,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0771e-04, 4.3501e-05, 8.1875e-05, 1.0343e-03, 6.4492e-04, 9.4917e-04,\n",
      "         5.2346e-02, 2.6573e-03, 5.9660e-02, 1.7454e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1102], requires_grad=True)\n",
      "bias grad:  tensor([0.3607])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7826]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1071]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0899,  -322.8737,   -11.4201,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1138], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7933]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0899,  -322.8737,   -11.4201,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0266e-03, -3.3594e-05,  3.3707e-05,  3.8142e-04,  1.8375e-04,\n",
      "          7.6103e-04,  2.7296e-02,  1.7453e-03,  3.1725e-02,  1.6367e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1138], requires_grad=True)\n",
      "bias grad:  tensor([0.1775])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7933]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6971]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0902,  -322.8737,   -11.4204,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1156], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7236]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0902,  -322.8737,   -11.4204,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[5.7532e-04, 4.6578e-06, 6.5259e-05, 5.5294e-04, 1.8095e-04, 2.4997e-03,\n",
      "         6.2932e-02, 1.8936e-03, 3.8496e-02, 1.1919e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1156], requires_grad=True)\n",
      "bias grad:  tensor([0.2185])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7236]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0106]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0908,  -322.8738,   -11.4208,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1178], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7247]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0908,  -322.8738,   -11.4208,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8860e-03, -3.5359e-05, -4.1902e-05, -7.5805e-04, -5.2553e-04,\n",
      "         -3.7281e-04, -2.8786e-02, -1.2026e-03, -3.2670e-02,  3.4696e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1178], requires_grad=True)\n",
      "bias grad:  tensor([-0.1911])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7247]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6570]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0905,  -322.8738,   -11.4205,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1159], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6590]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0905,  -322.8738,   -11.4205,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.5327e-05,  0.0000e+00, -1.1495e-05, -2.2978e-04, -5.1053e-05,\n",
      "         -1.0188e-05, -1.6220e-03, -7.7766e-04, -1.5212e-02, -5.3967e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1159], requires_grad=True)\n",
      "bias grad:  tensor([-0.0828])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6590]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2155]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0905,  -322.8738,   -11.4203,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1150], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6805]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0905,  -322.8738,   -11.4203,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5322e-03, 2.9702e-05, 8.7172e-05, 1.0505e-03, 7.5060e-04, 1.1100e-03,\n",
      "         5.8619e-02, 3.0716e-03, 6.5492e-02, 2.3799e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1150], requires_grad=True)\n",
      "bias grad:  tensor([0.3888])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6805]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0360]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0911,  -322.8738,   -11.4210,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1189], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6841]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0911,  -322.8738,   -11.4210,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6130e-02,  0.0000e+00, -3.7080e-05, -8.6814e-04, -1.1179e-03,\n",
      "         -5.5489e-04, -2.5217e-02, -1.8295e-03, -4.4364e-02, -4.7443e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1189], requires_grad=True)\n",
      "bias grad:  tensor([-0.2495])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6841]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2498]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0908,  -322.8738,   -11.4205,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1164], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6592]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0908,  -322.8738,   -11.4205,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.1247e-03,  3.4778e-06,  3.4795e-05,  2.7752e-04, -5.4312e-05,\n",
      "          1.0481e-03,  2.8121e-02,  1.1334e-03,  1.8885e-02,  7.7529e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1164], requires_grad=True)\n",
      "bias grad:  tensor([0.1148])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6592]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0676]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0911,  -322.8738,   -11.4207,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1176], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6659]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0911,  -322.8738,   -11.4207,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7049e-04,  0.0000e+00, -1.0899e-04, -6.3711e-04, -6.2891e-05,\n",
      "         -5.3743e-03, -1.3664e-01, -3.1829e-03, -5.5190e-02, -1.5023e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1176], requires_grad=True)\n",
      "bias grad:  tensor([-0.3466])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6659]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1457]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0897,  -322.8737,   -11.4202,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1141], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5513]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0897,  -322.8737,   -11.4202,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.5527e-03,  2.4705e-05, -2.4293e-05,  2.5438e-04,  7.0954e-04,\n",
      "         -3.5135e-03, -6.9950e-02, -4.0702e-04,  6.8730e-03, -6.2173e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1141], requires_grad=True)\n",
      "bias grad:  tensor([0.0216])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5513]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0086]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0890,  -322.8737,   -11.4202,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1143], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5522]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0890,  -322.8737,   -11.4202,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.8708e-03, -5.5696e-05, -4.3147e-05, -4.8009e-04,  2.5784e-05,\n",
      "         -1.6433e-03, -5.1579e-02, -8.9158e-04, -2.0006e-02,  1.8842e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1143], requires_grad=True)\n",
      "bias grad:  tensor([-0.1364])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5522]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8302]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0885,  -322.8737,   -11.4200,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1130], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4692]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0885,  -322.8737,   -11.4200,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.1707e-04, -1.9630e-04, -9.0057e-05, -7.2617e-04, -6.6099e-05,\n",
      "         -4.1971e-03, -1.0263e-01, -2.6661e-03, -4.4502e-02, -7.6594e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1130], requires_grad=True)\n",
      "bias grad:  tensor([-0.2800])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4692]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6673]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0875,  -322.8737,   -11.4196,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1102], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4025]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0875,  -322.8737,   -11.4196,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0052, 0.0000, 0.0002, 0.0025, 0.0005, 0.0014, 0.0892, 0.0043, 0.1278,\n",
      "         0.0025]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1102], requires_grad=True)\n",
      "bias grad:  tensor([0.7345])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4025]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.3421]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0884,  -322.8737,   -11.4209,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1175], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7367]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0884,  -322.8737,   -11.4209,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6260e-03,  2.6577e-05, -6.0822e-05, -1.0062e-03, -7.7343e-04,\n",
      "         -6.5518e-04, -4.5239e-02, -2.2914e-03, -5.1838e-02, -4.0698e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1175], requires_grad=True)\n",
      "bias grad:  tensor([-0.2979])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7367]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2904]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0879,  -322.8737,   -11.4204,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1145], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7076]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0879,  -322.8737,   -11.4204,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6124e-03,  3.6440e-05,  7.0001e-05,  7.9956e-04,  3.5433e-04,\n",
      "          2.5774e-03,  7.2040e-02,  2.4620e-03,  4.2438e-02,  1.4273e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1145], requires_grad=True)\n",
      "bias grad:  tensor([0.2771])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7076]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2048]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0887,  -322.8737,   -11.4208,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1173], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7281]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0887,  -322.8737,   -11.4208,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[3.2623e-03, 0.0000e+00, 5.9555e-05, 8.2854e-04, 6.1875e-04, 3.0362e-04,\n",
      "         3.9187e-02, 2.2332e-03, 5.0897e-02, 1.0676e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1173], requires_grad=True)\n",
      "bias grad:  tensor([0.2963])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7281]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0210]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0891,  -322.8738,   -11.4213,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1203], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7260]], requires_grad=True)\n",
      "Iteration 9 | Score: 0.37098369002342224\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0649,  -322.8724,   -11.3933,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3499e-03,  0.0000e+00,  7.5680e-06, -1.1486e-04, -1.1903e-04,\n",
      "          3.3596e-04,  1.2855e-02,  2.5458e-04,  1.0013e-03,  5.3603e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0446], requires_grad=True)\n",
      "bias grad:  tensor([0.0053])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8594]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5293]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0650,  -322.8724,   -11.3933,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0445], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8065]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0650,  -322.8724,   -11.3933,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[9.6737e-05, 7.0661e-05, 5.1457e-05, 5.7003e-04, 2.1031e-05, 9.6728e-04,\n",
      "         4.0917e-02, 1.8391e-03, 3.8001e-02, 1.0919e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0445], requires_grad=True)\n",
      "bias grad:  tensor([0.2187])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8065]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1145]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0654,  -322.8725,   -11.3937,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0424], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8180]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0654,  -322.8725,   -11.3937,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.5572e-03, -1.1368e-04, -6.6104e-05, -7.7479e-04,  3.9567e-05,\n",
      "         -2.2175e-03, -6.3314e-02, -1.8575e-03, -3.8897e-02, -1.6597e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0424], requires_grad=True)\n",
      "bias grad:  tensor([-0.2207])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8180]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8944]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0648,  -322.8724,   -11.3933,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0446], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7285]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0648,  -322.8724,   -11.3933,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1231e-05, 0.0000e+00, 8.4734e-05, 9.9009e-04, 6.0046e-04, 1.0119e-03,\n",
      "         4.9285e-02, 3.1006e-03, 6.1373e-02, 1.5267e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0446], requires_grad=True)\n",
      "bias grad:  tensor([0.3619])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7285]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0111]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0653,  -322.8725,   -11.3939,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0409], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7274]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0653,  -322.8725,   -11.3939,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[1.2100e-03, 1.8307e-05, 2.5498e-05, 1.6300e-04, 2.7820e-04, 1.8558e-03,\n",
      "         4.4289e-02, 1.1115e-03, 1.3293e-02, 1.1761e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0409], requires_grad=True)\n",
      "bias grad:  tensor([0.0907])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7274]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4204]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0657,  -322.8725,   -11.3940,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0400], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6854]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0657,  -322.8725,   -11.3940,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[1.3922e-03, 3.7952e-05, 5.8560e-05, 6.1456e-04, 3.2440e-04, 2.3940e-03,\n",
      "         6.7212e-02, 1.9076e-03, 3.5996e-02, 1.1407e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0400], requires_grad=True)\n",
      "bias grad:  tensor([0.2123])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6854]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1744]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0664,  -322.8725,   -11.3944,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0379], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7028]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0664,  -322.8725,   -11.3944,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[5.5592e-05, 4.0031e-05, 1.4687e-04, 1.5329e-03, 6.8601e-04, 2.1015e-03,\n",
      "         9.5530e-02, 4.2697e-03, 8.6728e-02, 2.4762e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0379], requires_grad=True)\n",
      "bias grad:  tensor([0.5447])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7028]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0976]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0673,  -322.8725,   -11.3952,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0325], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7126]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0673,  -322.8725,   -11.3952,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[4.4662e-03, 0.0000e+00, 6.4648e-05, 8.1621e-04, 6.7471e-04, 1.0670e-03,\n",
      "         5.0475e-02, 2.2545e-03, 5.1563e-02, 1.1520e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0325], requires_grad=True)\n",
      "bias grad:  tensor([0.2932])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7126]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2035]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0678,  -322.8726,   -11.3958,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0295], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7329]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0678,  -322.8726,   -11.3958,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5194e-03, 0.0000e+00, 5.3209e-05, 5.4170e-04, 5.6932e-04, 8.1368e-04,\n",
      "         4.3778e-02, 2.3055e-03, 4.0569e-02, 8.4543e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0295], requires_grad=True)\n",
      "bias grad:  tensor([0.2331])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7329]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4872]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0683,  -322.8726,   -11.3962,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0272], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6842]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0683,  -322.8726,   -11.3962,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0023, 0.0003, 0.0003, 0.0033, 0.0009, 0.0076, 0.2320, 0.0077, 0.1504,\n",
      "         0.0025]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0272], requires_grad=True)\n",
      "bias grad:  tensor([0.9229])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6842]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6325]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0706,  -322.8727,   -11.3977,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0180], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8475]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0706,  -322.8727,   -11.3977,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.6154e-04,  0.0000e+00,  3.5048e-05,  3.3912e-04,  2.8794e-04,\n",
      "          5.7119e-04,  2.7049e-02,  1.6051e-03,  2.6212e-02,  4.6868e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0180], requires_grad=True)\n",
      "bias grad:  tensor([0.1536])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8475]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2106]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0709,  -322.8727,   -11.3979,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0164], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8264]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0709,  -322.8727,   -11.3979,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[6.5580e-04, 4.0813e-05, 8.6548e-05, 1.0988e-03, 6.5157e-04, 9.8774e-04,\n",
      "         5.4950e-02, 2.7822e-03, 6.3127e-02, 1.7430e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0164], requires_grad=True)\n",
      "bias grad:  tensor([0.3783])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8264]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1861]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0714,  -322.8727,   -11.3986,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0127], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8450]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0714,  -322.8727,   -11.3986,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.1128e-04, -3.4661e-05,  3.9895e-05,  4.8805e-04,  3.1151e-04,\n",
      "          8.6309e-04,  3.1069e-02,  1.9966e-03,  3.7608e-02,  1.7233e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0127], requires_grad=True)\n",
      "bias grad:  tensor([0.2119])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8450]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6664]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0717,  -322.8728,   -11.3989,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0105], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7784]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0717,  -322.8728,   -11.3989,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[2.1549e-03, 1.3553e-05, 8.9184e-05, 8.5929e-04, 4.5278e-04, 2.7746e-03,\n",
      "         7.7578e-02, 2.7395e-03, 5.8552e-02, 1.6098e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0105], requires_grad=True)\n",
      "bias grad:  tensor([0.3322])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7784]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0944]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0725,  -322.8728,   -11.3995,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0072], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7689]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0725,  -322.8728,   -11.3995,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.5418e-03, -3.6405e-05, -3.3249e-05, -6.3010e-04, -3.8604e-04,\n",
      "         -2.7197e-04, -2.2068e-02, -7.9462e-04, -2.4125e-02,  2.7007e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0072], requires_grad=True)\n",
      "bias grad:  tensor([-0.1422])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7689]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8048]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0723,  -322.8728,   -11.3993,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0086], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6884]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0723,  -322.8728,   -11.3993,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7712e-03, 0.0000e+00, 2.5739e-05, 3.0737e-04, 2.5908e-04, 2.3943e-04,\n",
      "         2.1392e-02, 3.8668e-04, 1.4194e-02, 8.0194e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0086], requires_grad=True)\n",
      "bias grad:  tensor([0.0898])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6884]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3831]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0725,  -322.8728,   -11.3994,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0077], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7267]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0725,  -322.8728,   -11.3994,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[5.3201e-03, 3.3107e-05, 1.2738e-04, 1.6025e-03, 1.2214e-03, 1.7163e-03,\n",
      "         8.9132e-02, 4.6244e-03, 9.9533e-02, 3.1327e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0077], requires_grad=True)\n",
      "bias grad:  tensor([0.5874])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7267]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0245]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0734,  -322.8729,   -11.4004,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0019], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7292]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0734,  -322.8729,   -11.4004,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9448e-02,  0.0000e+00, -1.8996e-05, -7.3139e-04, -1.0254e-03,\n",
      "         -4.1939e-04, -1.9221e-02, -1.1973e-03, -3.4032e-02, -2.8843e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0019], requires_grad=True)\n",
      "bias grad:  tensor([-0.1886])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7292]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3585]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0732,  -322.8729,   -11.4001,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0038], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6933]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0732,  -322.8729,   -11.4001,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8753e-03,  1.8405e-05,  5.6007e-05,  5.0678e-04,  1.2280e-04,\n",
      "          1.4727e-03,  4.5539e-02,  1.8913e-03,  3.4287e-02,  1.3222e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0038], requires_grad=True)\n",
      "bias grad:  tensor([0.2049])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6933]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1327]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0736,  -322.8729,   -11.4004,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0017], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6801]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0736,  -322.8729,   -11.4004,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.8738e-05,  0.0000e+00, -9.5612e-05, -4.7979e-04,  5.7557e-05,\n",
      "         -5.1808e-03, -1.2629e-01, -2.7136e-03, -4.4796e-02,  6.5556e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0017], requires_grad=True)\n",
      "bias grad:  tensor([-0.2868])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6801]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1824]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0724,  -322.8729,   -11.4000,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0046], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5618]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0724,  -322.8729,   -11.4000,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.6669e-03,  3.2942e-05,  2.4658e-05,  8.6879e-04,  1.0155e-03,\n",
      "         -2.7095e-03, -3.6311e-02,  1.2329e-03,  4.1557e-02,  2.0000e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0046], requires_grad=True)\n",
      "bias grad:  tensor([0.2273])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5618]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2842]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0720,  -322.8729,   -11.4004,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0023], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5902]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0720,  -322.8729,   -11.4004,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.9272e-03, -6.9523e-05, -3.3122e-05, -2.9877e-04,  1.6848e-04,\n",
      "         -1.7184e-03, -4.5549e-02, -4.2630e-04, -1.0349e-02,  3.6026e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0023], requires_grad=True)\n",
      "bias grad:  tensor([-0.0787])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5902]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8834]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0716,  -322.8729,   -11.4003,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0031], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5019]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0716,  -322.8729,   -11.4003,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.7825e-04, -1.8881e-04, -6.1054e-05, -5.0917e-04, -1.5111e-05,\n",
      "         -3.9036e-03, -8.5078e-02, -2.0943e-03, -3.1745e-02, -3.1685e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0031], requires_grad=True)\n",
      "bias grad:  tensor([-0.1980])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5019]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7243]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0707,  -322.8728,   -11.4000,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0051], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4295]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0707,  -322.8728,   -11.4000,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0051, 0.0000, 0.0002, 0.0026, 0.0005, 0.0014, 0.0947, 0.0047, 0.1335,\n",
      "         0.0027]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0051], requires_grad=True)\n",
      "bias grad:  tensor([0.7660])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4295]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.9453]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0717,  -322.8729,   -11.4013,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0026], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7240]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0717,  -322.8729,   -11.4013,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.4282e-03,  3.3768e-05, -3.7322e-05, -6.2024e-04, -4.6939e-04,\n",
      "         -5.0176e-04, -2.9942e-02, -1.3065e-03, -2.9899e-02, -1.0791e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0026], requires_grad=True)\n",
      "bias grad:  tensor([-0.1727])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7240]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2100]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0714,  -322.8729,   -11.4010,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0009], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7030]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0714,  -322.8729,   -11.4010,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[4.3430e-04, 4.0534e-05, 9.9121e-05, 1.2163e-03, 6.4481e-04, 3.1943e-03,\n",
      "         9.6654e-02, 3.5561e-03, 6.5226e-02, 1.9157e-03]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias before:  Parameter containing:\n",
      "tensor([-0.0009], requires_grad=True)\n",
      "bias grad:  tensor([0.4148])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7030]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2737]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0723,  -322.8729,   -11.4017,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0050], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7304]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0723,  -322.8729,   -11.4017,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[4.5850e-03, 0.0000e+00, 8.6401e-05, 1.1999e-03, 8.9933e-04, 5.5536e-04,\n",
      "         6.0029e-02, 3.2120e-03, 7.3359e-02, 1.4582e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0050], requires_grad=True)\n",
      "bias grad:  tensor([0.4263])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7304]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0086]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0729,  -322.8730,   -11.4024,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0093], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7295]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0729,  -322.8730,   -11.4024,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.0475e-03,  0.0000e+00,  1.8590e-05,  1.0615e-04, -6.9108e-06,\n",
      "          3.7900e-04,  1.7976e-02,  6.2363e-04,  1.1571e-02,  5.7545e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0093], requires_grad=True)\n",
      "bias grad:  tensor([0.0661])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7295]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1733]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0731,  -322.8730,   -11.4025,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0099], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7122]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0731,  -322.8730,   -11.4025,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.6656e-05,  7.2277e-05,  3.7104e-05,  3.8129e-04, -1.7254e-04,\n",
      "          7.8936e-04,  3.1584e-02,  1.2455e-03,  2.5815e-02,  7.6260e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0099], requires_grad=True)\n",
      "bias grad:  tensor([0.1489])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7122]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1953]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0734,  -322.8730,   -11.4028,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0114], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7317]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0734,  -322.8730,   -11.4028,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3293e-03, -9.3122e-05, -5.3418e-05, -6.1154e-04,  7.0547e-05,\n",
      "         -1.8134e-03, -5.0194e-02, -1.4297e-03, -3.0565e-02, -2.3056e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0114], requires_grad=True)\n",
      "bias grad:  tensor([-0.1732])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7317]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6369]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0729,  -322.8730,   -11.4025,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0097], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6680]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0729,  -322.8730,   -11.4025,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.9155e-04,  0.0000e+00,  7.5796e-05,  8.7682e-04,  5.4030e-04,\n",
      "          8.5360e-04,  4.1056e-02,  2.7894e-03,  5.4621e-02,  1.3833e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0097], requires_grad=True)\n",
      "bias grad:  tensor([0.3211])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6680]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0065]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0733,  -322.8730,   -11.4030,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0129], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6687]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0733,  -322.8730,   -11.4030,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0478e-03,  1.7130e-05,  5.7124e-06, -1.3114e-04, -7.4950e-05,\n",
      "          1.7101e-03,  2.9015e-02,  3.3391e-04, -4.9232e-03,  7.5540e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0129], requires_grad=True)\n",
      "bias grad:  tensor([-0.0144])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6687]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3969]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0736,  -322.8730,   -11.4030,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0128], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6290]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0736,  -322.8730,   -11.4030,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4971e-03, 4.6283e-05, 6.5392e-05, 7.1924e-04, 4.0414e-04, 2.8699e-03,\n",
      "         7.9165e-02, 2.1789e-03, 4.0988e-02, 1.2154e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0128], requires_grad=True)\n",
      "bias grad:  tensor([0.2427])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6290]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2509]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0744,  -322.8730,   -11.4034,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0152], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6541]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0744,  -322.8730,   -11.4034,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3980e-04, 3.9404e-05, 1.3037e-04, 1.3460e-03, 5.4063e-04, 1.8564e-03,\n",
      "         8.3748e-02, 3.5311e-03, 7.5061e-02, 2.0266e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0152], requires_grad=True)\n",
      "bias grad:  tensor([0.4675])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6541]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2935]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0753,  -322.8730,   -11.4041,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0199], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6834]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0753,  -322.8730,   -11.4041,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[5.2029e-03, 0.0000e+00, 5.9110e-05, 7.6028e-04, 6.9800e-04, 1.1767e-03,\n",
      "         5.2054e-02, 2.0873e-03, 4.8162e-02, 1.0671e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0199], requires_grad=True)\n",
      "bias grad:  tensor([0.2738])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6834]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1671]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0758,  -322.8731,   -11.4046,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0226], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7001]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0758,  -322.8731,   -11.4046,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[1.4766e-03, 0.0000e+00, 3.1048e-05, 3.0031e-04, 2.2186e-04, 6.9575e-04,\n",
      "         3.0464e-02, 1.4044e-03, 2.2786e-02, 2.1857e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0226], requires_grad=True)\n",
      "bias grad:  tensor([0.1297])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7001]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2131]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0761,  -322.8731,   -11.4048,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0239], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6788]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0761,  -322.8731,   -11.4048,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0020, 0.0003, 0.0003, 0.0032, 0.0008, 0.0076, 0.2263, 0.0073, 0.1419,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0239], requires_grad=True)\n",
      "bias grad:  tensor([0.8747])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6788]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5563]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0783,  -322.8731,   -11.4062,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0326], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8345]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0783,  -322.8731,   -11.4062,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8228e-03,  0.0000e+00,  7.3445e-06, -8.9486e-05,  2.6425e-06,\n",
      "          5.2963e-04,  1.1482e-02,  5.0949e-04,  2.5832e-03,  1.3373e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0326], requires_grad=True)\n",
      "bias grad:  tensor([0.0164])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8345]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2821]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0785,  -322.8731,   -11.4063,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0328], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8063]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0785,  -322.8731,   -11.4063,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[3.0710e-05, 5.2359e-05, 8.0560e-05, 1.0077e-03, 5.8813e-04, 9.4734e-04,\n",
      "         5.1082e-02, 2.6630e-03, 5.8257e-02, 1.7280e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0328], requires_grad=True)\n",
      "bias grad:  tensor([0.3516])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8063]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0801]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0790,  -322.8732,   -11.4069,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0363], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8143]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0790,  -322.8732,   -11.4069,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.4967e-04, -3.3399e-05,  3.2410e-05,  3.8677e-04,  2.5751e-04,\n",
      "          6.3309e-04,  2.3252e-02,  1.7194e-03,  3.1591e-02,  1.5966e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0363], requires_grad=True)\n",
      "bias grad:  tensor([0.1774])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8143]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6720]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0792,  -322.8732,   -11.4072,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0381], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7471]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0792,  -322.8732,   -11.4072,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[1.2409e-03, 1.4202e-06, 5.7843e-05, 4.6322e-04, 2.0768e-04, 2.2478e-03,\n",
      "         5.6889e-02, 1.6486e-03, 3.4402e-02, 1.0711e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0381], requires_grad=True)\n",
      "bias grad:  tensor([0.1943])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7471]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1478]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8732,   -11.4075,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0400], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7323]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8732,   -11.4075,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.4167e-03, -2.8117e-05, -1.2172e-05, -3.1165e-04, -1.5750e-04,\n",
      "         -1.1914e-04, -1.0379e-02, -1.7034e-04, -7.0469e-03,  4.1094e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0400], requires_grad=True)\n",
      "bias grad:  tensor([-0.0429])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7323]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5815]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0797,  -322.8732,   -11.4074,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0396], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6741]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0797,  -322.8732,   -11.4074,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.8889e-03,  0.0000e+00,  6.2550e-06,  3.3766e-05,  9.9304e-05,\n",
      "          1.1101e-04,  1.0113e-02, -2.9784e-04, -1.4705e-03, -2.5274e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0396], requires_grad=True)\n",
      "bias grad:  tensor([-0.0014])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6741]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2925]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8732,   -11.4074,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0396], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7034]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8732,   -11.4074,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[5.0838e-03, 2.5554e-05, 1.1705e-04, 1.5050e-03, 1.1949e-03, 1.5757e-03,\n",
      "         8.3460e-02, 4.3145e-03, 9.2556e-02, 2.9613e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0396], requires_grad=True)\n",
      "bias grad:  tensor([0.5465])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7034]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0410]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0806,  -322.8733,   -11.4084,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0451], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7075]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0806,  -322.8733,   -11.4084,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7485e-02,  0.0000e+00, -6.0062e-06, -5.2179e-04, -7.8305e-04,\n",
      "         -2.6957e-04, -1.2465e-02, -6.4222e-04, -2.2219e-02, -1.3721e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0451], requires_grad=True)\n",
      "bias grad:  tensor([-0.1212])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7075]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3110]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0805,  -322.8733,   -11.4081,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0439], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6764]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0805,  -322.8733,   -11.4081,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.9698e-03,  1.5367e-05,  4.6883e-05,  4.3041e-04,  1.5316e-04,\n",
      "          1.3118e-03,  3.9652e-02,  1.5972e-03,  2.8974e-02,  1.0167e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0439], requires_grad=True)\n",
      "bias grad:  tensor([0.1721])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6764]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0505]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0809,  -322.8733,   -11.4084,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0456], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6713]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0809,  -322.8733,   -11.4084,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.1915e-04,  0.0000e+00, -1.0973e-04, -6.7166e-04, -1.0127e-04,\n",
      "         -5.3282e-03, -1.3514e-01, -3.2663e-03, -5.7047e-02, -2.5286e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0456], requires_grad=True)\n",
      "bias grad:  tensor([-0.3577])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6713]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1048]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0795,  -322.8733,   -11.4079,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0420], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5609]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0795,  -322.8733,   -11.4079,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.9272e-03,  2.7021e-05, -3.6298e-06,  5.2704e-04,  8.4566e-04,\n",
      "         -3.2819e-03, -5.8693e-02,  2.8667e-04,  2.2155e-02, -2.7883e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0420], requires_grad=True)\n",
      "bias grad:  tensor([0.1105])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5609]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1546]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0789,  -322.8733,   -11.4081,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0431], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5763]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0789,  -322.8733,   -11.4081,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.5390e-03, -6.1131e-05, -4.7618e-05, -4.6866e-04,  1.3407e-04,\n",
      "         -1.9961e-03, -5.6135e-02, -9.3274e-04, -2.0116e-02,  2.6733e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0431], requires_grad=True)\n",
      "bias grad:  tensor([-0.1363])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5763]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8623]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0784,  -322.8733,   -11.4079,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0417], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4901]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0784,  -322.8733,   -11.4079,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.5323e-04, -1.9510e-04, -6.9683e-05, -5.5499e-04,  1.6528e-05,\n",
      "         -3.9885e-03, -9.2986e-02, -2.1897e-03, -3.4519e-02, -4.6119e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0417], requires_grad=True)\n",
      "bias grad:  tensor([-0.2186])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4901]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6849]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0774,  -322.8732,   -11.4075,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0396], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4216]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0774,  -322.8732,   -11.4075,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0053, 0.0000, 0.0002, 0.0027, 0.0006, 0.0015, 0.1014, 0.0050, 0.1416,\n",
      "         0.0028]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0396], requires_grad=True)\n",
      "bias grad:  tensor([0.8120])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4216]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.1235]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0785,  -322.8733,   -11.4089,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0477], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7340]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0785,  -322.8733,   -11.4089,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.2447e-03,  2.8112e-05, -5.9756e-05, -9.2346e-04, -6.8524e-04,\n",
      "         -8.4584e-04, -4.9860e-02, -2.1875e-03, -4.7604e-02, -4.7122e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0477], requires_grad=True)\n",
      "bias grad:  tensor([-0.2779])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7340]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1655]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0780,  -322.8733,   -11.4085,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0449], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7174]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0780,  -322.8733,   -11.4085,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8889e-04,  4.0243e-05,  9.5044e-05,  1.1455e-03,  5.7613e-04,\n",
      "          3.2358e-03,  9.5258e-02,  3.3595e-03,  5.9759e-02,  1.9538e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0449], requires_grad=True)\n",
      "bias grad:  tensor([0.3924])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7174]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2309]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0789,  -322.8733,   -11.4091,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0488], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7405]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0789,  -322.8733,   -11.4091,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[3.9019e-03, 0.0000e+00, 8.4480e-05, 1.1120e-03, 7.4637e-04, 4.5867e-04,\n",
      "         6.4831e-02, 3.0370e-03, 6.8546e-02, 1.5182e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0488], requires_grad=True)\n",
      "bias grad:  tensor([0.3972])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7405]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0729]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0796,  -322.8733,   -11.4098,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0528], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7332]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0796,  -322.8733,   -11.4098,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.9410e-04,  0.0000e+00,  1.1563e-05, -5.8420e-06, -7.4550e-05,\n",
      "          3.0451e-04,  1.3718e-02,  3.8627e-04,  5.4268e-03,  4.6913e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0528], requires_grad=True)\n",
      "bias grad:  tensor([0.0308])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7332]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2892]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0797,  -322.8733,   -11.4098,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0531], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7043]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0797,  -322.8733,   -11.4098,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.8375e-04,  8.4683e-05,  4.3073e-05,  4.8612e-04, -5.3805e-05,\n",
      "          7.8053e-04,  3.2169e-02,  1.4978e-03,  3.1174e-02,  7.9649e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0531], requires_grad=True)\n",
      "bias grad:  tensor([0.1790])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7043]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2614]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0800,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0549], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7304]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0800,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.2489e-03, -9.0881e-05, -5.3612e-05, -6.3042e-04,  5.7984e-05,\n",
      "         -1.9901e-03, -5.3536e-02, -1.4865e-03, -3.0584e-02, -7.9002e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0549], requires_grad=True)\n",
      "bias grad:  tensor([-0.1739])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7304]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7311]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0795,  -322.8733,   -11.4098,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0532], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6573]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0795,  -322.8733,   -11.4098,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.5073e-04,  0.0000e+00,  8.6748e-05,  9.8088e-04,  5.3074e-04,\n",
      "          1.0192e-03,  4.9068e-02,  3.1466e-03,  6.1344e-02,  1.7011e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0532], requires_grad=True)\n",
      "bias grad:  tensor([0.3624])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6573]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0328]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0800,  -322.8734,   -11.4104,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0568], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6540]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0800,  -322.8734,   -11.4104,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[1.4670e-03, 1.8210e-05, 1.3992e-05, 6.7893e-05, 2.4362e-04, 1.5257e-03,\n",
      "         3.3152e-02, 7.6052e-04, 7.6349e-03, 9.3028e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0568], requires_grad=True)\n",
      "bias grad:  tensor([0.0521])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6540]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3901]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0803,  -322.8734,   -11.4105,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0573], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6150]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0803,  -322.8734,   -11.4105,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1655e-03, 3.7245e-05, 6.5470e-05, 7.5468e-04, 4.8350e-04, 2.4409e-03,\n",
      "         7.1985e-02, 2.2334e-03, 4.3155e-02, 1.3705e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0573], requires_grad=True)\n",
      "bias grad:  tensor([0.2575])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6150]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1858]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0810,  -322.8734,   -11.4109,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0599], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6336]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0810,  -322.8734,   -11.4109,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0389e-04, 3.1186e-05, 1.3058e-04, 1.3350e-03, 5.6957e-04, 1.7806e-03,\n",
      "         8.3163e-02, 3.6334e-03, 7.4647e-02, 2.0817e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0599], requires_grad=True)\n",
      "bias grad:  tensor([0.4714])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6336]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2095]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0819,  -322.8734,   -11.4117,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0646], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6545]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0819,  -322.8734,   -11.4117,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[5.3125e-03, 0.0000e+00, 6.6881e-05, 8.5194e-04, 7.2379e-04, 1.2242e-03,\n",
      "         5.5281e-02, 2.2864e-03, 5.3370e-02, 1.1733e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0646], requires_grad=True)\n",
      "bias grad:  tensor([0.3032])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6545]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1877]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0824,  -322.8734,   -11.4122,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0676], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6733]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0824,  -322.8734,   -11.4122,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[1.4591e-03, 0.0000e+00, 4.5064e-05, 4.6426e-04, 3.2602e-04, 7.4609e-04,\n",
      "         3.6393e-02, 1.7530e-03, 3.2871e-02, 8.0790e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0676], requires_grad=True)\n",
      "bias grad:  tensor([0.1874])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6733]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2244]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0828,  -322.8735,   -11.4125,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0695], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6509]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0828,  -322.8735,   -11.4125,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0018, 0.0003, 0.0003, 0.0033, 0.0009, 0.0078, 0.2335, 0.0076, 0.1476,\n",
      "         0.0024]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0695], requires_grad=True)\n",
      "bias grad:  tensor([0.9083])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6509]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6473]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0851,  -322.8735,   -11.4140,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0786], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8156]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0851,  -322.8735,   -11.4140,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1276e-03,  0.0000e+00,  1.4352e-05,  2.1933e-05,  1.3486e-04,\n",
      "          4.6322e-04,  1.5471e-02,  8.2971e-04,  8.9386e-03,  2.1334e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0786], requires_grad=True)\n",
      "bias grad:  tensor([0.0521])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8156]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3275]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0853,  -322.8735,   -11.4141,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0791], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7829]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0853,  -322.8735,   -11.4141,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.9321e-05,  4.8705e-05,  6.5674e-05,  8.3594e-04,  5.0912e-04,\n",
      "          8.1578e-04,  4.2606e-02,  2.2128e-03,  4.7967e-02,  1.3998e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0791], requires_grad=True)\n",
      "bias grad:  tensor([0.2916])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7829]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1363]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8736,   -11.4146,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0820], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7965]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0857,  -322.8736,   -11.4146,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7263e-04, -2.6233e-05,  4.3545e-05,  5.4178e-04,  3.1834e-04,\n",
      "          9.0027e-04,  3.4018e-02,  2.0462e-03,  4.0187e-02,  1.7409e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0820], requires_grad=True)\n",
      "bias grad:  tensor([0.2264])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7965]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5452]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0860,  -322.8736,   -11.4150,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0843], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7420]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0860,  -322.8736,   -11.4150,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[8.0918e-04, 1.9826e-06, 6.4670e-05, 5.3641e-04, 2.2765e-04, 2.5093e-03,\n",
      "         6.4815e-02, 1.9088e-03, 3.8212e-02, 1.1758e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0843], requires_grad=True)\n",
      "bias grad:  tensor([0.2169])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7420]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0973]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0867,  -322.8736,   -11.4154,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0864], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7322]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0867,  -322.8736,   -11.4154,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.5416e-03, -3.5205e-05, -4.8799e-05, -8.2326e-04, -4.7522e-04,\n",
      "         -4.1843e-04, -3.0808e-02, -1.3828e-03, -3.6204e-02,  3.4091e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0864], requires_grad=True)\n",
      "bias grad:  tensor([-0.2121])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7322]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7307]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0864,  -322.8736,   -11.4150,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0843], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6592]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0864,  -322.8736,   -11.4150,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.0121e-04,  0.0000e+00,  3.3765e-06, -2.4770e-05,  2.9588e-05,\n",
      "          1.0460e-04,  7.7605e-03, -3.5900e-04, -4.3053e-03, -3.0287e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0843], requires_grad=True)\n",
      "bias grad:  tensor([-0.0193])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6592]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2987]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0864,  -322.8736,   -11.4150,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0841], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6890]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0864,  -322.8736,   -11.4150,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[4.8448e-03, 3.6254e-05, 1.0238e-04, 1.2728e-03, 9.6618e-04, 1.3879e-03,\n",
      "         7.2479e-02, 3.6702e-03, 7.8987e-02, 2.6541e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0841], requires_grad=True)\n",
      "bias grad:  tensor([0.4672])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6890]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0771]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0872,  -322.8737,   -11.4158,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0888], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6967]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0872,  -322.8737,   -11.4158,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8923e-02,  0.0000e+00, -3.2597e-05, -8.8474e-04, -1.1747e-03,\n",
      "         -5.4510e-04, -2.4841e-02, -1.7186e-03, -4.3794e-02, -4.3631e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0888], requires_grad=True)\n",
      "bias grad:  tensor([-0.2451])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6967]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3748]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0869,  -322.8736,   -11.4153,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0864], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6593]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0869,  -322.8736,   -11.4153,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.9888e-03,  1.2514e-05,  3.7960e-05,  2.9597e-04, -8.4464e-05,\n",
      "          1.0732e-03,  2.8358e-02,  1.2078e-03,  2.0215e-02,  8.7934e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0864], requires_grad=True)\n",
      "bias grad:  tensor([0.1237])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6593]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0240]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0872,  -322.8736,   -11.4155,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0876], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6617]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0872,  -322.8736,   -11.4155,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.0681e-04,  0.0000e+00, -1.0839e-04, -6.7646e-04, -1.0528e-04,\n",
      "         -5.2003e-03, -1.3481e-01, -3.1493e-03, -5.5848e-02, -1.4928e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0876], requires_grad=True)\n",
      "bias grad:  tensor([-0.3501])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6617]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1610]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0859,  -322.8736,   -11.4150,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0841], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5456]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0859,  -322.8736,   -11.4150,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.2438e-03,  2.9348e-05,  8.0409e-06,  6.6816e-04,  1.0287e-03,\n",
      "         -2.9549e-03, -4.5875e-02,  7.2384e-04,  3.1274e-02, -1.0946e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0841], requires_grad=True)\n",
      "bias grad:  tensor([0.1632])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5456]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0866]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0854,  -322.8736,   -11.4153,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0857], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5542]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0854,  -322.8736,   -11.4153,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.1797e-03, -6.0361e-05, -3.3328e-05, -3.3488e-04,  8.3032e-05,\n",
      "         -1.7404e-03, -4.6748e-02, -5.2966e-04, -1.2129e-02,  2.5505e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0857], requires_grad=True)\n",
      "bias grad:  tensor([-0.0903])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5542]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8813]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0849,  -322.8736,   -11.4152,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0848], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4661]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0849,  -322.8736,   -11.4152,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1881e-04, -1.9968e-04, -7.1504e-05, -5.6843e-04,  2.5970e-05,\n",
      "         -4.1352e-03, -9.5479e-02, -2.2350e-03, -3.3396e-02, -3.4033e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0848], requires_grad=True)\n",
      "bias grad:  tensor([-0.2188])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4661]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7754]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0840,  -322.8736,   -11.4148,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0826], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3885]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0840,  -322.8736,   -11.4148,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0061, 0.0000, 0.0002, 0.0030, 0.0006, 0.0018, 0.1104, 0.0053, 0.1520,\n",
      "         0.0030]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0826], requires_grad=True)\n",
      "bias grad:  tensor([0.8721])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3885]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.7509]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0851,  -322.8736,   -11.4163,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0913], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7636]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0851,  -322.8736,   -11.4163,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.5317e-03,  2.7757e-05, -5.9783e-05, -9.6413e-04, -6.9839e-04,\n",
      "         -7.5453e-04, -4.5877e-02, -2.2138e-03, -4.9035e-02, -3.8587e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0913], requires_grad=True)\n",
      "bias grad:  tensor([-0.2843])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7636]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2695]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0846,  -322.8736,   -11.4158,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0885], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7367]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0846,  -322.8736,   -11.4158,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7516e-03,  3.9661e-05,  6.0858e-05,  6.9606e-04,  3.2337e-04,\n",
      "          2.4201e-03,  6.4690e-02,  2.1180e-03,  3.6595e-02,  1.2750e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0885], requires_grad=True)\n",
      "bias grad:  tensor([0.2410])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7367]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1717]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0853,  -322.8736,   -11.4162,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0909], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7539]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0853,  -322.8736,   -11.4162,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0043, 0.0000, 0.0001, 0.0014, 0.0009, 0.0007, 0.0958, 0.0039, 0.0866,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0909], requires_grad=True)\n",
      "bias grad:  tensor([0.4999])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7539]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1097]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0862,  -322.8737,   -11.4171,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0959], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7429]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0862,  -322.8737,   -11.4171,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2637e-03,  0.0000e+00, -1.3581e-06, -2.0188e-04, -1.8770e-04,\n",
      "          2.5500e-04,  6.7696e-03, -1.2673e-04, -5.4423e-03,  4.0700e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0959], requires_grad=True)\n",
      "bias grad:  tensor([-0.0312])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7429]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3810]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0863,  -322.8737,   -11.4170,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0956], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7048]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0863,  -322.8737,   -11.4170,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3847e-04,  6.4338e-05,  3.5728e-05,  3.6746e-04, -1.6261e-04,\n",
      "          7.0526e-04,  3.0175e-02,  1.2066e-03,  2.5082e-02,  7.5793e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0956], requires_grad=True)\n",
      "bias grad:  tensor([0.1445])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7048]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1630]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0866,  -322.8737,   -11.4173,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0970], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7211]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0866,  -322.8737,   -11.4173,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.3479e-04, -9.1813e-05, -5.5070e-05, -6.7318e-04, -1.7779e-05,\n",
      "         -2.0726e-03, -5.5058e-02, -1.6485e-03, -3.2957e-02,  1.1139e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0970], requires_grad=True)\n",
      "bias grad:  tensor([-0.1880])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7211]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7504]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0860,  -322.8736,   -11.4169,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0952], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6460]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0860,  -322.8736,   -11.4169,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.9078e-04,  0.0000e+00,  6.7192e-05,  7.8992e-04,  4.5762e-04,\n",
      "          6.3330e-04,  3.6302e-02,  2.5307e-03,  4.9632e-02,  1.3115e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0952], requires_grad=True)\n",
      "bias grad:  tensor([0.2887])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6460]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0090]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0864,  -322.8737,   -11.4174,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0981], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6451]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0864,  -322.8737,   -11.4174,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[9.5606e-04, 1.9775e-05, 1.0598e-05, 2.6041e-05, 1.6779e-04, 1.3617e-03,\n",
      "         2.9985e-02, 5.8019e-04, 4.1634e-03, 7.6402e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0981], requires_grad=True)\n",
      "bias grad:  tensor([0.0331])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6451]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3334]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0867,  -322.8737,   -11.4175,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0984], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6118]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0867,  -322.8737,   -11.4175,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[1.4269e-03, 3.2659e-05, 5.1742e-05, 5.6806e-04, 3.2874e-04, 2.4808e-03,\n",
      "         6.8662e-02, 1.8676e-03, 3.3724e-02, 1.0260e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0984], requires_grad=True)\n",
      "bias grad:  tensor([0.1985])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6118]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1383]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0874,  -322.8737,   -11.4178,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1004], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6256]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0874,  -322.8737,   -11.4178,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[2.3153e-04, 3.3392e-05, 1.2194e-04, 1.2593e-03, 5.0816e-04, 1.9139e-03,\n",
      "         8.1594e-02, 3.3740e-03, 7.0901e-02, 1.9735e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1004], requires_grad=True)\n",
      "bias grad:  tensor([0.4403])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6256]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2085]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0882,  -322.8737,   -11.4185,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1048], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6465]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0882,  -322.8737,   -11.4185,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[4.6228e-03, 0.0000e+00, 5.5592e-05, 7.0110e-04, 6.0207e-04, 1.0765e-03,\n",
      "         4.7858e-02, 1.8493e-03, 4.3841e-02, 1.0011e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1048], requires_grad=True)\n",
      "bias grad:  tensor([0.2488])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6465]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2444]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0887,  -322.8737,   -11.4190,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1073], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6709]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0887,  -322.8737,   -11.4190,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[2.6383e-03, 0.0000e+00, 6.2919e-05, 6.9488e-04, 6.3094e-04, 7.5666e-04,\n",
      "         4.3600e-02, 2.3503e-03, 4.7485e-02, 1.4812e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1073], requires_grad=True)\n",
      "bias grad:  tensor([0.2722])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6709]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3150]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0891,  -322.8738,   -11.4194,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1100], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6394]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0891,  -322.8738,   -11.4194,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0014, 0.0003, 0.0003, 0.0032, 0.0008, 0.0079, 0.2314, 0.0074, 0.1416,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1100], requires_grad=True)\n",
      "bias grad:  tensor([0.8763])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6394]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.8055]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0914,  -322.8738,   -11.4209,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1187], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8200]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0914,  -322.8738,   -11.4209,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6389e-03,  0.0000e+00, -1.3567e-07, -2.0126e-04, -5.0719e-05,\n",
      "          3.7737e-04,  6.4632e-03,  2.7477e-04, -3.4861e-03, -1.3789e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1187], requires_grad=True)\n",
      "bias grad:  tensor([-0.0210])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8200]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3627]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0915,  -322.8738,   -11.4208,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1185], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7837]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0915,  -322.8738,   -11.4208,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1691e-04,  4.6078e-05,  7.7362e-05,  9.8413e-04,  6.6080e-04,\n",
      "          9.1684e-04,  4.9990e-02,  2.6114e-03,  5.7945e-02,  1.7869e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1185], requires_grad=True)\n",
      "bias grad:  tensor([0.3483])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7837]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0458]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0920,  -322.8739,   -11.4214,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1220], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7883]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0920,  -322.8739,   -11.4214,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.6266e-04, -2.6684e-05,  2.9489e-05,  3.5765e-04,  2.2075e-04,\n",
      "          4.9576e-04,  2.0721e-02,  1.5577e-03,  2.8907e-02,  1.4280e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1220], requires_grad=True)\n",
      "bias grad:  tensor([0.1626])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7883]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6121]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0922,  -322.8739,   -11.4217,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1236], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7271]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0922,  -322.8739,   -11.4217,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[7.9155e-04, 3.7307e-06, 5.6044e-05, 4.3309e-04, 1.6644e-04, 2.2219e-03,\n",
      "         5.5812e-02, 1.5877e-03, 3.1945e-02, 1.0436e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1236], requires_grad=True)\n",
      "bias grad:  tensor([0.1805])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7271]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1090]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0928,  -322.8739,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1255], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7162]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0928,  -322.8739,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7691e-03, -2.9056e-05, -3.2111e-05, -6.3527e-04, -4.5617e-04,\n",
      "         -2.6352e-04, -2.2999e-02, -9.1975e-04, -2.6157e-02,  8.5149e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1255], requires_grad=True)\n",
      "bias grad:  tensor([-0.1508])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7162]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda grad:  tensor([[0.6151]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0925,  -322.8739,   -11.4218,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1239], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6547]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0925,  -322.8739,   -11.4218,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.4482e-06,  0.0000e+00, -1.0998e-05, -2.2541e-04, -6.6836e-05,\n",
      "         -1.1197e-05, -1.4998e-03, -7.7599e-04, -1.4947e-02, -4.7317e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1239], requires_grad=True)\n",
      "bias grad:  tensor([-0.0813])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6547]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2231]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0925,  -322.8739,   -11.4216,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1231], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6770]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0925,  -322.8739,   -11.4216,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[5.3207e-03, 3.3440e-05, 1.0474e-04, 1.3191e-03, 1.0097e-03, 1.4693e-03,\n",
      "         7.4820e-02, 3.7521e-03, 8.1009e-02, 2.6763e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1231], requires_grad=True)\n",
      "bias grad:  tensor([0.4792])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6770]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1204]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0933,  -322.8740,   -11.4224,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1279], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6890]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0933,  -322.8740,   -11.4224,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2432e-02,  0.0000e+00, -3.9938e-05, -1.0647e-03, -1.4088e-03,\n",
      "         -6.5877e-04, -3.0011e-02, -2.0882e-03, -5.2896e-02, -5.3152e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1279], requires_grad=True)\n",
      "bias grad:  tensor([-0.2962])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6890]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4221]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0930,  -322.8739,   -11.4219,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1250], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6468]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0930,  -322.8739,   -11.4219,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.2629e-03,  2.3534e-05,  5.1434e-05,  4.1811e-04, -6.2688e-05,\n",
      "          1.1679e-03,  3.3463e-02,  1.6021e-03,  2.8604e-02,  1.2830e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1250], requires_grad=True)\n",
      "bias grad:  tensor([0.1724])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6468]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0218]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0933,  -322.8740,   -11.4222,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1267], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6446]], requires_grad=True)\n",
      "Iteration 10 | Score: 0.5453099012374878\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0649,  -322.8724,   -11.3933,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0202e-04,  0.0000e+00, -9.7622e-05, -5.4062e-04, -1.0137e-06,\n",
      "         -4.9917e-03, -1.2473e-01, -2.7982e-03, -4.7694e-02, -4.2182e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0446], requires_grad=True)\n",
      "bias grad:  tensor([-0.3024])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8594]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.2080]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0636,  -322.8724,   -11.3928,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0476], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7386]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0636,  -322.8724,   -11.3928,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.2763e-03, -1.9679e-05, -5.3960e-05, -3.2472e-04,  4.5094e-04,\n",
      "         -3.7950e-03, -8.1455e-02, -1.3906e-03, -1.8454e-02, -6.8209e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0476], requires_grad=True)\n",
      "bias grad:  tensor([-0.1256])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7386]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9513]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0628,  -322.8724,   -11.3926,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0489], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6435]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0628,  -322.8724,   -11.3926,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.4009e-03, -6.2938e-05, -3.1639e-05, -2.9546e-04,  2.6015e-04,\n",
      "         -1.7476e-03, -4.3523e-02, -3.4512e-04, -9.0124e-03,  3.7224e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0489], requires_grad=True)\n",
      "bias grad:  tensor([-0.0720])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6435]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.0178]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0624,  -322.8724,   -11.3925,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0496], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5417]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0624,  -322.8724,   -11.3925,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[ 9.8617e-04, -1.8652e-04, -2.5429e-05, -1.3789e-04,  2.3898e-04,\n",
      "         -3.5015e-03, -6.5564e-02, -1.1449e-03, -1.0027e-02,  3.5165e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0496], requires_grad=True)\n",
      "bias grad:  tensor([-0.0648])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5417]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7129]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0617,  -322.8724,   -11.3924,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0502], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4704]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0617,  -322.8724,   -11.3924,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0045, 0.0000, 0.0002, 0.0023, 0.0005, 0.0013, 0.0881, 0.0043, 0.1241,\n",
      "         0.0026]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0502], requires_grad=True)\n",
      "bias grad:  tensor([0.7120])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4704]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.4256]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0626,  -322.8724,   -11.3937,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0431], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7130]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0626,  -322.8724,   -11.3937,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.6178e-04,  3.8359e-05, -2.2058e-05, -3.5970e-04, -3.0751e-04,\n",
      "         -3.4077e-04, -1.9947e-02, -7.2350e-04, -1.6323e-02,  3.5063e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0431], requires_grad=True)\n",
      "bias grad:  tensor([-0.0939])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7130]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0261]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0624,  -322.8724,   -11.3935,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0441], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7104]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4050,\n",
      "            -6.0624,  -322.8724,   -11.3935,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7758e-03, 4.6408e-05, 1.0944e-04, 1.3931e-03, 8.1025e-04, 3.3044e-03,\n",
      "         1.0338e-01, 3.9683e-03, 7.5679e-02, 1.9927e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0441], requires_grad=True)\n",
      "bias grad:  tensor([0.4723])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7104]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3325]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0634,  -322.8725,   -11.3943,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0393], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7436]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0634,  -322.8725,   -11.3943,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[4.8775e-03, 0.0000e+00, 8.4709e-05, 1.1652e-03, 8.6849e-04, 5.0405e-04,\n",
      "         5.9730e-02, 3.1035e-03, 7.1206e-02, 1.4785e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0393], requires_grad=True)\n",
      "bias grad:  tensor([0.4147])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7436]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0470]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0640,  -322.8725,   -11.3950,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0352], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7389]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0640,  -322.8725,   -11.3950,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4785e-03, 0.0000e+00, 3.4540e-05, 3.6128e-04, 2.1991e-04, 5.8023e-04,\n",
      "         2.8936e-02, 1.3035e-03, 2.6306e-02, 7.6945e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0352], requires_grad=True)\n",
      "bias grad:  tensor([0.1497])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7389]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1298]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0643,  -322.8725,   -11.3952,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0337], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7260]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0643,  -322.8725,   -11.3952,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.1324e-04,  6.5140e-05,  4.9784e-05,  5.3899e-04, -9.9538e-06,\n",
      "          1.0761e-03,  4.2324e-02,  1.7529e-03,  3.6302e-02,  1.0320e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0337], requires_grad=True)\n",
      "bias grad:  tensor([0.2085])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7260]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1089]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0647,  -322.8725,   -11.3956,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0316], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7369]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0647,  -322.8725,   -11.3956,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.7803e-03, -6.9492e-05, -3.3282e-05, -3.5862e-04,  2.1736e-04,\n",
      "         -1.6389e-03, -3.8925e-02, -7.9050e-04, -1.5780e-02,  1.7455e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0316], requires_grad=True)\n",
      "bias grad:  tensor([-0.0874])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7369]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5608]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0643,  -322.8725,   -11.3954,  -302.5935]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0325], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6808]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0643,  -322.8725,   -11.3954,  -302.5935]], requires_grad=True)\n",
      "weight grad:  tensor([[4.5413e-04, 0.0000e+00, 8.9115e-05, 1.0906e-03, 6.5805e-04, 8.5966e-04,\n",
      "         5.1439e-02, 3.3789e-03, 6.7622e-02, 1.6970e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0325], requires_grad=True)\n",
      "bias grad:  tensor([0.3931])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6808]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0051]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0649,  -322.8726,   -11.3961,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0286], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6813]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0649,  -322.8726,   -11.3961,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[7.6982e-04, 1.0640e-05, 2.9427e-05, 2.1014e-04, 2.2569e-04, 1.9852e-03,\n",
      "         4.4886e-02, 1.1593e-03, 1.5210e-02, 1.0594e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0286], requires_grad=True)\n",
      "bias grad:  tensor([0.0960])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6813]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3109]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0653,  -322.8726,   -11.3963,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0276], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6502]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0653,  -322.8726,   -11.3963,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[2.9139e-03, 3.9268e-05, 8.0391e-05, 9.4265e-04, 6.2744e-04, 2.8643e-03,\n",
      "         8.7063e-02, 2.9076e-03, 5.5515e-02, 1.5726e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0276], requires_grad=True)\n",
      "bias grad:  tensor([0.3270])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6502]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1953]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0662,  -322.8726,   -11.3968,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0243], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6697]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4049,\n",
      "            -6.0662,  -322.8726,   -11.3968,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[6.7276e-05, 5.6516e-05, 1.5344e-04, 1.6203e-03, 7.0137e-04, 2.3635e-03,\n",
      "         1.0261e-01, 4.4580e-03, 9.1599e-02, 2.5692e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0243], requires_grad=True)\n",
      "bias grad:  tensor([0.5690])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6697]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2124]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0672,  -322.8726,   -11.3977,  -302.5936]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0186], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6910]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0672,  -322.8726,   -11.3977,  -302.5936]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2340e-03, 0.0000e+00, 8.9049e-05, 1.0701e-03, 8.0684e-04, 1.7997e-03,\n",
      "         7.2078e-02, 3.1145e-03, 6.8569e-02, 1.6784e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0186], requires_grad=True)\n",
      "bias grad:  tensor([0.3897])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6910]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1347]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0679,  -322.8727,   -11.3984,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0147], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7044]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0679,  -322.8727,   -11.3984,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7036e-03, 0.0000e+00, 4.7992e-05, 5.1924e-04, 4.6321e-04, 7.5035e-04,\n",
      "         3.9155e-02, 2.0039e-03, 3.6465e-02, 7.0546e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0147], requires_grad=True)\n",
      "bias grad:  tensor([0.2095])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7044]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2986]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0683,  -322.8727,   -11.3988,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0126], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6746]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0683,  -322.8727,   -11.3988,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0017, 0.0003, 0.0003, 0.0033, 0.0009, 0.0076, 0.2338, 0.0078, 0.1524,\n",
      "         0.0027]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0126], requires_grad=True)\n",
      "bias grad:  tensor([0.9341])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6746]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5770]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0707,  -322.8728,   -11.4003,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0033], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8323]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0707,  -322.8728,   -11.4003,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0743e-03,  0.0000e+00,  1.9953e-05,  8.2916e-05,  1.5008e-04,\n",
      "          5.5691e-04,  1.9421e-02,  1.0451e-03,  1.2778e-02,  2.6446e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0033], requires_grad=True)\n",
      "bias grad:  tensor([0.0743])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8323]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3120]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0708,  -322.8728,   -11.4004,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([0.0026], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8011]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0708,  -322.8728,   -11.4004,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0466e-04, 4.0920e-05, 8.5092e-05, 1.0556e-03, 6.0223e-04, 9.5735e-04,\n",
      "         5.3075e-02, 2.7040e-03, 6.0119e-02, 1.6991e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([0.0026], requires_grad=True)\n",
      "bias grad:  tensor([0.3662])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8011]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1316]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0714,  -322.8728,   -11.4010,  -302.5937]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0011], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8142]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0714,  -322.8728,   -11.4010,  -302.5937]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.1655e-04, -1.9208e-05,  5.4251e-05,  6.7260e-04,  3.8300e-04,\n",
      "          9.5668e-04,  3.9667e-02,  2.4250e-03,  4.7854e-02,  1.8846e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0011], requires_grad=True)\n",
      "bias grad:  tensor([0.2707])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8142]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5461]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0718,  -322.8728,   -11.4015,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0038], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7596]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0718,  -322.8728,   -11.4015,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6304e-03, 9.2954e-06, 8.1179e-05, 7.2802e-04, 3.3030e-04, 2.8597e-03,\n",
      "         7.5910e-02, 2.4274e-03, 5.0390e-02, 1.4587e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0038], requires_grad=True)\n",
      "bias grad:  tensor([0.2863])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7596]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0659]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0725,  -322.8729,   -11.4020,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0067], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7530]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0725,  -322.8729,   -11.4020,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3970e-03, -2.1503e-05, -1.4850e-05, -3.3752e-04, -1.8212e-04,\n",
      "         -1.3544e-04, -1.0549e-02, -2.1624e-04, -9.1198e-03,  4.1080e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0067], requires_grad=True)\n",
      "bias grad:  tensor([-0.0539])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7530]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5674]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0724,  -322.8729,   -11.4019,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0061], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6963]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0724,  -322.8729,   -11.4019,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.3181e-03,  0.0000e+00,  1.2241e-05,  1.4317e-04,  2.0132e-04,\n",
      "          1.3500e-04,  1.4142e-02,  3.9993e-05,  5.3939e-03, -1.1475e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0061], requires_grad=True)\n",
      "bias grad:  tensor([0.0380])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6963]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2928]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0726,  -322.8729,   -11.4020,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0065], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7256]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0726,  -322.8729,   -11.4020,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[5.2380e-03, 2.7863e-05, 1.1850e-04, 1.4435e-03, 1.0686e-03, 1.5583e-03,\n",
      "         8.0260e-02, 4.0677e-03, 8.9935e-02, 2.9317e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0065], requires_grad=True)\n",
      "bias grad:  tensor([0.5308])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7256]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0276]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0734,  -322.8729,   -11.4029,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0118], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7283]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0734,  -322.8729,   -11.4029,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5640e-02,  0.0000e+00, -1.4152e-05, -5.7439e-04, -8.1050e-04,\n",
      "         -3.2636e-04, -1.4969e-02, -9.1882e-04, -2.6518e-02, -2.1956e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0118], requires_grad=True)\n",
      "bias grad:  tensor([-0.1468])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7283]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1623]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0732,  -322.8729,   -11.4026,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0104], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7121]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0732,  -322.8729,   -11.4026,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7100e-03,  1.7580e-05,  5.0932e-05,  4.8170e-04,  1.1401e-04,\n",
      "          1.4256e-03,  4.3133e-02,  1.7149e-03,  3.1492e-02,  1.1095e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0104], requires_grad=True)\n",
      "bias grad:  tensor([0.1886])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7121]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0386]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0737,  -322.8729,   -11.4029,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0122], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7082]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0737,  -322.8729,   -11.4029,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.3583e-04,  0.0000e+00, -1.0093e-04, -5.4356e-04,  4.9628e-05,\n",
      "         -5.1222e-03, -1.2778e-01, -2.8610e-03, -4.8522e-02, -1.4997e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0122], requires_grad=True)\n",
      "bias grad:  tensor([-0.3072])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7082]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1680]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0724,  -322.8729,   -11.4024,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0092], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5914]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0724,  -322.8729,   -11.4024,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.7730e-03,  1.6254e-05, -1.7109e-05,  2.9041e-04,  7.5482e-04,\n",
      "         -3.2574e-03, -6.1555e-02, -1.5393e-04,  1.1086e-02, -4.1938e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0092], requires_grad=True)\n",
      "bias grad:  tensor([0.0464])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5914]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1688]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0718,  -322.8729,   -11.4026,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0096], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5746]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0718,  -322.8729,   -11.4026,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.2801e-03, -5.2746e-05, -1.7632e-05, -1.3385e-04,  3.0371e-04,\n",
      "         -1.2357e-03, -2.9943e-02,  2.2421e-05, -9.9157e-04,  5.0052e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0096], requires_grad=True)\n",
      "bias grad:  tensor([-0.0228])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5746]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8458]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0715,  -322.8729,   -11.4025,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0094], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4900]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0715,  -322.8729,   -11.4025,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.4713e-04, -1.8225e-04, -3.8114e-05, -2.8406e-04,  9.0374e-05,\n",
      "         -3.6064e-03, -7.1585e-02, -1.4409e-03, -1.7498e-02,  1.6279e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0094], requires_grad=True)\n",
      "bias grad:  tensor([-0.1127])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4900]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7732]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0707,  -322.8729,   -11.4024,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0083], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4127]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0707,  -322.8729,   -11.4024,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0057, 0.0000, 0.0002, 0.0028, 0.0005, 0.0016, 0.1035, 0.0050, 0.1448,\n",
      "         0.0029]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0083], requires_grad=True)\n",
      "bias grad:  tensor([0.8318])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4127]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.5945]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0718,  -322.8730,   -11.4038,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0166], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7721]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0718,  -322.8730,   -11.4038,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.9571e-03,  2.3140e-05, -5.6953e-05, -9.1921e-04, -6.9896e-04,\n",
      "         -7.4955e-04, -4.4533e-02, -2.0623e-03, -4.6434e-02, -3.8714e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0166], requires_grad=True)\n",
      "bias grad:  tensor([-0.2700])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7721]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3324]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0713,  -322.8729,   -11.4034,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0139], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7389]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4048,\n",
      "            -6.0713,  -322.8729,   -11.4034,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.3337e-04,  4.2929e-05,  8.2235e-05,  9.8947e-04,  5.3481e-04,\n",
      "          2.6841e-03,  7.9170e-02,  2.9482e-03,  5.4396e-02,  1.5546e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0139], requires_grad=True)\n",
      "bias grad:  tensor([0.3420])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7389]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1621]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0721,  -322.8730,   -11.4039,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0173], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7551]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0721,  -322.8730,   -11.4039,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[4.1284e-03, 0.0000e+00, 8.4054e-05, 1.1378e-03, 8.0662e-04, 4.8760e-04,\n",
      "         6.1151e-02, 3.0843e-03, 6.9966e-02, 1.4741e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0173], requires_grad=True)\n",
      "bias grad:  tensor([0.4058])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7551]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0595]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0727,  -322.8730,   -11.4046,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0214], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7491]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0727,  -322.8730,   -11.4046,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[4.4101e-04, 0.0000e+00, 1.5421e-05, 6.8277e-05, 1.0051e-05, 3.4041e-04,\n",
      "         1.5835e-02, 5.7525e-04, 9.4081e-03, 4.7829e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0214], requires_grad=True)\n",
      "bias grad:  tensor([0.0533])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7491]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2499]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0729,  -322.8730,   -11.4047,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0219], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7241]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0729,  -322.8730,   -11.4047,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.6174e-04,  7.7358e-05,  4.7054e-05,  5.4311e-04, -6.5674e-07,\n",
      "          8.9050e-04,  3.7613e-02,  1.6767e-03,  3.4761e-02,  8.7352e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0219], requires_grad=True)\n",
      "bias grad:  tensor([0.1997])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7241]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1949]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0733,  -322.8730,   -11.4050,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0239], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7436]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0733,  -322.8730,   -11.4050,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.1448e-03, -9.3023e-05, -5.9864e-05, -7.0474e-04, -2.2374e-05,\n",
      "         -1.8842e-03, -5.4263e-02, -1.7876e-03, -3.7443e-02, -3.4578e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0239], requires_grad=True)\n",
      "bias grad:  tensor([-0.2122])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7436]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5756]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0727,  -322.8730,   -11.4047,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0218], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6861]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0727,  -322.8730,   -11.4047,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.3321e-04,  0.0000e+00,  7.0545e-05,  8.4283e-04,  4.7329e-04,\n",
      "          5.4879e-04,  3.5610e-02,  2.6591e-03,  5.2665e-02,  1.3706e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0218], requires_grad=True)\n",
      "bias grad:  tensor([0.3052])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6861]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0047]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0731,  -322.8730,   -11.4052,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0248], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6856]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0731,  -322.8730,   -11.4052,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.9384e-04,  1.6540e-05,  7.2361e-06, -7.2502e-05,  4.8647e-05,\n",
      "          1.5799e-03,  2.8078e-02,  4.4793e-04, -1.2157e-03,  7.6396e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0248], requires_grad=True)\n",
      "bias grad:  tensor([0.0036])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6856]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4189]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0734,  -322.8730,   -11.4052,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0249], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6437]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0734,  -322.8730,   -11.4052,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5529e-03, 3.9721e-05, 6.4675e-05, 6.9889e-04, 3.7772e-04, 2.5582e-03,\n",
      "         7.3506e-02, 2.1978e-03, 4.1385e-02, 1.2455e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0249], requires_grad=True)\n",
      "bias grad:  tensor([0.2425])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6437]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2292]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0741,  -322.8730,   -11.4056,  -302.5938]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0273], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6666]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0741,  -322.8730,   -11.4056,  -302.5938]], requires_grad=True)\n",
      "weight grad:  tensor([[2.9750e-04, 3.9294e-05, 1.3390e-04, 1.4482e-03, 6.1943e-04, 2.1443e-03,\n",
      "         9.1582e-02, 3.9144e-03, 8.1220e-02, 2.2719e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0273], requires_grad=True)\n",
      "bias grad:  tensor([0.5063])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6666]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2525]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0750,  -322.8731,   -11.4064,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0324], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6919]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0750,  -322.8731,   -11.4064,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0618e-03, 0.0000e+00, 8.9785e-05, 1.0880e-03, 9.2941e-04, 1.4254e-03,\n",
      "         6.7700e-02, 3.3415e-03, 7.2340e-02, 2.2544e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0324], requires_grad=True)\n",
      "bias grad:  tensor([0.4126])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6919]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0254]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0757,  -322.8731,   -11.4071,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0365], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6893]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0757,  -322.8731,   -11.4071,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7877e-03, 0.0000e+00, 3.0799e-05, 2.7082e-04, 2.6567e-04, 5.8596e-04,\n",
      "         2.6589e-02, 1.3567e-03, 2.2315e-02, 4.5640e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0365], requires_grad=True)\n",
      "bias grad:  tensor([0.1277])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6893]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3558]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0760,  -322.8731,   -11.4074,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0378], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6538]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0760,  -322.8731,   -11.4074,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0019, 0.0003, 0.0003, 0.0033, 0.0009, 0.0078, 0.2323, 0.0076, 0.1489,\n",
      "         0.0024]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0378], requires_grad=True)\n",
      "bias grad:  tensor([0.9149])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6538]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.7029]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0783,  -322.8732,   -11.4088,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0469], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8241]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0783,  -322.8732,   -11.4088,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2958e-03,  0.0000e+00,  1.0598e-05, -4.7232e-05,  6.5796e-05,\n",
      "          5.2375e-04,  1.3572e-02,  6.5670e-04,  5.1367e-03,  1.6380e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0469], requires_grad=True)\n",
      "bias grad:  tensor([0.0311])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8241]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3205]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8732,   -11.4089,  -302.5939]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0472], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7920]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8732,   -11.4089,  -302.5939]], requires_grad=True)\n",
      "weight grad:  tensor([[4.1851e-04, 4.5520e-05, 7.4787e-05, 9.6268e-04, 6.0778e-04, 9.2570e-04,\n",
      "         4.8374e-02, 2.5009e-03, 5.5172e-02, 1.5426e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0472], requires_grad=True)\n",
      "bias grad:  tensor([0.3338])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7920]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1074]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0789,  -322.8732,   -11.4094,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0506], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8027]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0789,  -322.8732,   -11.4094,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6208e-04, -2.5354e-05,  3.6071e-05,  4.4994e-04,  3.0394e-04,\n",
      "          6.7288e-04,  2.6768e-02,  1.8110e-03,  3.4207e-02,  1.5645e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0506], requires_grad=True)\n",
      "bias grad:  tensor([0.1933])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8027]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5929]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0792,  -322.8732,   -11.4098,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0525], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7435]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0792,  -322.8732,   -11.4098,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[6.3806e-04, 5.0806e-06, 6.4263e-05, 5.5096e-04, 2.2314e-04, 2.3885e-03,\n",
      "         6.2176e-02, 1.8922e-03, 3.8959e-02, 1.1875e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0525], requires_grad=True)\n",
      "bias grad:  tensor([0.2212])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7435]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0862]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8733,   -11.4102,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0547], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7348]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0798,  -322.8733,   -11.4102,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.6651e-03, -2.8129e-05, -3.2918e-05, -6.1092e-04, -3.9085e-04,\n",
      "         -3.0579e-04, -2.1142e-02, -9.0084e-04, -2.5039e-02,  1.5058e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0547], requires_grad=True)\n",
      "bias grad:  tensor([-0.1461])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7348]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6380]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0796,  -322.8733,   -11.4099,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0532], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6710]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0796,  -322.8733,   -11.4099,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.1226e-03,  0.0000e+00,  4.4379e-06,  6.8141e-06,  1.0027e-04,\n",
      "          1.0440e-04,  9.5631e-03, -1.9786e-04, -1.1468e-03, -2.4677e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0532], requires_grad=True)\n",
      "bias grad:  tensor([-0.0016])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6710]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2175]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0797,  -322.8733,   -11.4099,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0532], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6928]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0797,  -322.8733,   -11.4099,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2926e-03, 2.6062e-05, 1.1500e-04, 1.4007e-03, 1.0395e-03, 1.6376e-03,\n",
      "         8.1631e-02, 4.1172e-03, 8.6960e-02, 2.9808e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0532], requires_grad=True)\n",
      "bias grad:  tensor([0.5156])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6928]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0193]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0805,  -322.8733,   -11.4108,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0584], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6947]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0805,  -322.8733,   -11.4108,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3013e-02,  0.0000e+00, -5.4760e-05, -1.2614e-03, -1.6182e-03,\n",
      "         -8.0969e-04, -3.6786e-02, -2.6830e-03, -6.4699e-02, -6.9735e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0584], requires_grad=True)\n",
      "bias grad:  tensor([-0.3641])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6947]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3540]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0801,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0547], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6593]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0801,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.2303e-03,  1.5313e-05,  6.0724e-05,  6.0333e-04,  1.8655e-04,\n",
      "          1.5629e-03,  5.0353e-02,  2.0474e-03,  3.8781e-02,  1.2703e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0547], requires_grad=True)\n",
      "bias grad:  tensor([0.2314])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6593]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0420]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0806,  -322.8733,   -11.4105,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0571], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6635]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0806,  -322.8733,   -11.4105,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3768e-04,  0.0000e+00, -8.6930e-05, -4.1876e-04,  3.9190e-05,\n",
      "         -4.8288e-03, -1.1846e-01, -2.3778e-03, -3.9364e-02,  1.2542e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0571], requires_grad=True)\n",
      "bias grad:  tensor([-0.2549])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6635]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1439]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0794,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0545], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5491]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0794,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1101e-03,  2.5224e-05, -3.2822e-05,  1.4414e-04,  6.2376e-04,\n",
      "         -3.4496e-03, -7.3954e-02, -7.5582e-04, -1.3859e-04, -8.3634e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0545], requires_grad=True)\n",
      "bias grad:  tensor([-0.0193])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5491]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0663]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0787,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0543], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5558]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0787,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.0779e-03, -4.8665e-05, -1.4839e-05, -1.2245e-04,  1.8730e-04,\n",
      "         -1.2453e-03, -3.0674e-02, -7.2496e-06, -9.0872e-04,  4.3078e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0543], requires_grad=True)\n",
      "bias grad:  tensor([-0.0230])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5558]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6521]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0541], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4905]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0784,  -322.8733,   -11.4101,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.4068e-04, -1.9038e-04, -4.9577e-05, -4.1133e-04,  4.1752e-05,\n",
      "         -3.8272e-03, -8.0261e-02, -1.8138e-03, -2.6038e-02, -8.9846e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0541], requires_grad=True)\n",
      "bias grad:  tensor([-0.1603])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4905]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7982]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0776,  -322.8732,   -11.4099,  -302.5940]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0525], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4107]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0776,  -322.8732,   -11.4099,  -302.5940]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0056, 0.0000, 0.0003, 0.0032, 0.0008, 0.0019, 0.1285, 0.0064, 0.1721,\n",
      "         0.0037]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0525], requires_grad=True)\n",
      "bias grad:  tensor([0.9858])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4107]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.1930]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0789,  -322.8733,   -11.4116,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0623], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7300]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0789,  -322.8733,   -11.4116,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.5460e-03,  2.3024e-05, -5.9088e-05, -8.8710e-04, -6.0402e-04,\n",
      "         -9.4052e-04, -4.6775e-02, -2.0972e-03, -4.5236e-02, -4.4892e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0623], requires_grad=True)\n",
      "bias grad:  tensor([-0.2667])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7300]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2051]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0784,  -322.8733,   -11.4111,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0597], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7095]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4047,\n",
      "            -6.0784,  -322.8733,   -11.4111,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.1014e-04,  4.0245e-05,  7.3135e-05,  8.8689e-04,  4.2633e-04,\n",
      "          2.8329e-03,  7.7867e-02,  2.6031e-03,  4.6370e-02,  1.4125e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0597], requires_grad=True)\n",
      "bias grad:  tensor([0.3005])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7095]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2351]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0792,  -322.8733,   -11.4116,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0627], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7330]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0792,  -322.8733,   -11.4116,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4008e-03, 0.0000e+00, 9.7715e-05, 1.1959e-03, 7.0193e-04, 5.3310e-04,\n",
      "         8.5836e-02, 3.4250e-03, 7.5008e-02, 1.8617e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0627], requires_grad=True)\n",
      "bias grad:  tensor([0.4328])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7330]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0821]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0801,  -322.8733,   -11.4123,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0670], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7248]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0801,  -322.8733,   -11.4123,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3350e-04,  0.0000e+00,  1.7578e-05,  8.5469e-05,  2.3780e-05,\n",
      "          3.9562e-04,  1.7903e-02,  6.4227e-04,  1.0907e-02,  5.7544e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0670], requires_grad=True)\n",
      "bias grad:  tensor([0.0619])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7248]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3066]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0802,  -322.8733,   -11.4125,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0676], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6942]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0802,  -322.8733,   -11.4125,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.5163e-04,  6.9812e-05,  4.1604e-05,  4.4540e-04, -5.4058e-05,\n",
      "          7.5444e-04,  3.1260e-02,  1.4446e-03,  2.9799e-02,  8.0316e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0676], requires_grad=True)\n",
      "bias grad:  tensor([0.1710])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6942]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1625]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0805,  -322.8733,   -11.4128,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0693], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7104]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0805,  -322.8733,   -11.4128,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[ 9.8168e-04, -8.8834e-05, -4.5189e-05, -5.2863e-04,  6.2317e-05,\n",
      "         -1.7572e-03, -4.6184e-02, -1.2733e-03, -2.5988e-02, -4.5140e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0693], requires_grad=True)\n",
      "bias grad:  tensor([-0.1471])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7104]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5808]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0801,  -322.8733,   -11.4125,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0679], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6523]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0801,  -322.8733,   -11.4125,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[1.3587e-04, 0.0000e+00, 6.6459e-05, 8.0755e-04, 4.6302e-04, 6.9091e-04,\n",
      "         3.8795e-02, 2.4986e-03, 5.0028e-02, 1.2182e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0679], requires_grad=True)\n",
      "bias grad:  tensor([0.2913])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6523]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0410]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0805,  -322.8734,   -11.4130,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0708], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6564]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0805,  -322.8734,   -11.4130,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5289e-03,  1.7320e-05,  6.9957e-06, -8.6991e-05, -2.6810e-05,\n",
      "          1.4246e-03,  2.5442e-02,  3.6342e-04, -1.6707e-03,  7.5038e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0708], requires_grad=True)\n",
      "bias grad:  tensor([-0.0024])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6564]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3351]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0807,  -322.8734,   -11.4130,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0708], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6229]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0807,  -322.8734,   -11.4130,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[8.9269e-04, 3.3815e-05, 5.5700e-05, 5.9138e-04, 2.8166e-04, 2.4046e-03,\n",
      "         6.7168e-02, 1.8874e-03, 3.5206e-02, 1.0450e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0708], requires_grad=True)\n",
      "bias grad:  tensor([0.2050])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6229]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2494]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0814,  -322.8734,   -11.4133,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0728], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6479]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0814,  -322.8734,   -11.4133,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5977e-04, 4.4475e-05, 1.1541e-04, 1.2284e-03, 5.0649e-04, 1.7843e-03,\n",
      "         7.8094e-02, 3.3006e-03, 6.7971e-02, 1.9644e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0728], requires_grad=True)\n",
      "bias grad:  tensor([0.4297])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6479]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2334]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0822,  -322.8734,   -11.4140,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0771], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6712]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0822,  -322.8734,   -11.4140,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[4.1291e-03, 0.0000e+00, 4.0334e-05, 5.2887e-04, 4.8783e-04, 7.0955e-04,\n",
      "         3.4069e-02, 1.3193e-03, 3.2558e-02, 5.4777e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0771], requires_grad=True)\n",
      "bias grad:  tensor([0.1837])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6712]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3076]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0825,  -322.8734,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0789], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7020]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0825,  -322.8734,   -11.4143,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[9.6521e-04, 0.0000e+00, 2.9054e-05, 2.8210e-04, 1.4745e-04, 6.0617e-04,\n",
      "         2.5598e-02, 1.2870e-03, 2.0500e-02, 2.0403e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0789], requires_grad=True)\n",
      "bias grad:  tensor([0.1180])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7020]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1330]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0828,  -322.8734,   -11.4145,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0801], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6887]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0828,  -322.8734,   -11.4145,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0014, 0.0003, 0.0003, 0.0032, 0.0008, 0.0074, 0.2244, 0.0074, 0.1434,\n",
      "         0.0024]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0801], requires_grad=True)\n",
      "bias grad:  tensor([0.8820])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6887]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5059]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0850,  -322.8735,   -11.4160,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0889], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8392]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0850,  -322.8735,   -11.4160,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5676e-03,  0.0000e+00,  1.2289e-05,  1.0050e-05,  1.0446e-04,\n",
      "          4.4219e-04,  1.4422e-02,  8.0159e-04,  8.3647e-03,  1.8823e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0889], requires_grad=True)\n",
      "bias grad:  tensor([0.0485])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8392]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2797]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0852,  -322.8735,   -11.4161,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0894], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8113]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0852,  -322.8735,   -11.4161,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[2.1345e-04, 2.9696e-05, 7.1013e-05, 8.9538e-04, 5.6490e-04, 8.6746e-04,\n",
      "         4.6701e-02, 2.2941e-03, 5.1136e-02, 1.4928e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0894], requires_grad=True)\n",
      "bias grad:  tensor([0.3121])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8113]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1095]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0856,  -322.8735,   -11.4166,  -302.5941]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0925], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8222]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0856,  -322.8735,   -11.4166,  -302.5941]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1550e-03, -5.2351e-05,  2.5537e-05,  3.0050e-04,  1.9525e-04,\n",
      "          6.0545e-04,  2.0212e-02,  1.5680e-03,  2.7403e-02,  1.5844e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0925], requires_grad=True)\n",
      "bias grad:  tensor([0.1530])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8222]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7561]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0858,  -322.8735,   -11.4168,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0941], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7466]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0858,  -322.8735,   -11.4168,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[7.7830e-04, 8.7348e-06, 4.9939e-05, 3.0671e-04, 1.3124e-04, 2.1659e-03,\n",
      "         5.3153e-02, 1.3664e-03, 2.7127e-02, 1.0543e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0941], requires_grad=True)\n",
      "bias grad:  tensor([0.1521])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7466]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2743]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0864,  -322.8735,   -11.4171,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0956], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7192]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0864,  -322.8735,   -11.4171,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.1080e-03, -2.7172e-05, -3.0634e-05, -5.8736e-04, -4.0216e-04,\n",
      "         -2.8536e-04, -1.8385e-02, -7.7061e-04, -2.3018e-02,  3.0594e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0956], requires_grad=True)\n",
      "bias grad:  tensor([-0.1344])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7192]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6229]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0862,  -322.8735,   -11.4169,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0943], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6569]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0862,  -322.8735,   -11.4169,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.7849e-03,  0.0000e+00,  4.6878e-06,  2.3381e-05,  1.1199e-04,\n",
      "          8.8143e-05,  9.4834e-03, -2.6100e-04, -1.8921e-03, -2.3055e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0943], requires_grad=True)\n",
      "bias grad:  tensor([-0.0039])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6569]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2890]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0863,  -322.8735,   -11.4169,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0942], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6858]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0863,  -322.8735,   -11.4169,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4237e-03, 2.2010e-05, 8.7445e-05, 1.0623e-03, 7.8774e-04, 1.2325e-03,\n",
      "         6.1490e-02, 3.0955e-03, 6.6267e-02, 2.4270e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0942], requires_grad=True)\n",
      "bias grad:  tensor([0.3949])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6858]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0230]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0869,  -322.8736,   -11.4175,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0982], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6881]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0869,  -322.8736,   -11.4175,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4215e-02,  0.0000e+00, -3.0976e-05, -7.4420e-04, -9.6380e-04,\n",
      "         -4.7248e-04, -2.1483e-02, -1.5456e-03, -3.7808e-02, -3.9933e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0982], requires_grad=True)\n",
      "bias grad:  tensor([-0.2125])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6881]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1769]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0867,  -322.8735,   -11.4171,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0960], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6704]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0867,  -322.8735,   -11.4171,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.7411e-03,  1.7039e-05,  3.2624e-05,  2.0204e-04, -1.0304e-04,\n",
      "          1.0476e-03,  2.7200e-02,  1.0623e-03,  1.6187e-02,  8.3735e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0960], requires_grad=True)\n",
      "bias grad:  tensor([0.1000])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6704]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1473]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0869,  -322.8735,   -11.4173,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0970], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6557]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0869,  -322.8735,   -11.4173,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.2378e-04,  0.0000e+00, -1.2194e-04, -8.0188e-04, -1.7729e-04,\n",
      "         -5.4943e-03, -1.4570e-01, -3.6127e-03, -6.5445e-02, -3.7826e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0970], requires_grad=True)\n",
      "bias grad:  tensor([-0.4061])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6557]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1096]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0855,  -322.8735,   -11.4167,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0930], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5447]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0855,  -322.8735,   -11.4167,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.8726e-03,  1.8862e-05,  1.4215e-05,  7.3721e-04,  1.0223e-03,\n",
      "         -3.0908e-03, -4.7989e-02,  9.2668e-04,  3.6200e-02,  5.4055e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0930], requires_grad=True)\n",
      "bias grad:  tensor([0.1859])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5447]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0706]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0850,  -322.8735,   -11.4170,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0948], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5518]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0850,  -322.8735,   -11.4170,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.7172e-03, -6.5831e-05, -3.5031e-05, -3.7869e-04,  5.2521e-06,\n",
      "         -1.6379e-03, -4.6371e-02, -7.0463e-04, -1.5312e-02,  2.6972e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0948], requires_grad=True)\n",
      "bias grad:  tensor([-0.1067])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5518]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7726]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0845,  -322.8735,   -11.4169,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0938], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4745]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0845,  -322.8735,   -11.4169,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.2923e-04, -1.9608e-04, -6.6261e-05, -5.3619e-04, -1.4081e-05,\n",
      "         -4.0292e-03, -9.1632e-02, -2.1740e-03, -3.3546e-02, -3.6867e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0938], requires_grad=True)\n",
      "bias grad:  tensor([-0.2110])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4745]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7172]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0836,  -322.8735,   -11.4165,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0917], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4028]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0836,  -322.8735,   -11.4165,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0054, 0.0000, 0.0002, 0.0025, 0.0005, 0.0014, 0.0877, 0.0043, 0.1271,\n",
      "         0.0024]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0917], requires_grad=True)\n",
      "bias grad:  tensor([0.7303])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4028]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.4006]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0845,  -322.8735,   -11.4178,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0990], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7429]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0845,  -322.8735,   -11.4178,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.1692e-03,  2.3027e-05, -6.7829e-05, -1.0532e-03, -7.6894e-04,\n",
      "         -8.5217e-04, -5.1644e-02, -2.5262e-03, -5.5442e-02, -5.8485e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0990], requires_grad=True)\n",
      "bias grad:  tensor([-0.3215])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7429]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2662]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0840,  -322.8735,   -11.4172,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0957], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7162]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0840,  -322.8735,   -11.4172,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7815e-04,  4.1096e-05,  7.3275e-05,  8.9829e-04,  4.7521e-04,\n",
      "          2.5806e-03,  7.3831e-02,  2.6012e-03,  4.8623e-02,  1.3675e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0957], requires_grad=True)\n",
      "bias grad:  tensor([0.3045])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7162]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2282]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0847,  -322.8735,   -11.4177,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.0988], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7391]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0847,  -322.8735,   -11.4177,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[3.2988e-03, 0.0000e+00, 6.9843e-05, 9.5156e-04, 6.5001e-04, 3.7156e-04,\n",
      "         4.7363e-02, 2.5603e-03, 5.8380e-02, 1.2207e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.0988], requires_grad=True)\n",
      "bias grad:  tensor([0.3390])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7391]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0052]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0852,  -322.8735,   -11.4183,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1022], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7396]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0852,  -322.8735,   -11.4183,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6540e-03,  0.0000e+00,  4.3716e-06, -1.5208e-04, -1.4466e-04,\n",
      "          3.1922e-04,  1.0901e-02,  1.3425e-04, -1.2821e-03,  4.9090e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1022], requires_grad=True)\n",
      "bias grad:  tensor([-0.0077])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7396]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4436]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0853,  -322.8735,   -11.4183,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1021], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6952]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0853,  -322.8735,   -11.4183,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.9017e-04,  6.9806e-05,  3.5422e-05,  3.7312e-04, -1.2322e-04,\n",
      "          7.9176e-04,  3.1135e-02,  1.2339e-03,  2.5123e-02,  7.1261e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1021], requires_grad=True)\n",
      "bias grad:  tensor([0.1442])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6952]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1626]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0856,  -322.8735,   -11.4186,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1035], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7115]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0856,  -322.8735,   -11.4186,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.3980e-04, -1.1797e-04, -7.0259e-05, -8.5165e-04, -1.1775e-04,\n",
      "         -2.1419e-03, -6.3527e-02, -2.1501e-03, -4.4975e-02, -4.2486e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1035], requires_grad=True)\n",
      "bias grad:  tensor([-0.2567])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7115]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6493]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0850,  -322.8735,   -11.4181,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1010], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6466]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0850,  -322.8735,   -11.4181,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0874e-03,  0.0000e+00,  6.5226e-05,  7.3730e-04,  3.9323e-04,\n",
      "          6.9326e-04,  3.3156e-02,  2.3798e-03,  4.6551e-02,  1.2861e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1010], requires_grad=True)\n",
      "bias grad:  tensor([0.2730])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6466]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0375]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0853,  -322.8735,   -11.4186,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1037], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6428]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0853,  -322.8735,   -11.4186,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.6752e-04,  1.4848e-05,  8.1628e-06, -1.9334e-05,  1.3426e-04,\n",
      "          1.4799e-03,  3.0581e-02,  5.1176e-04,  1.0787e-03,  7.1451e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1037], requires_grad=True)\n",
      "bias grad:  tensor([0.0200])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6428]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3454]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0856,  -322.8735,   -11.4186,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1039], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6083]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4046,\n",
      "            -6.0856,  -322.8735,   -11.4186,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7136e-03, 4.1943e-05, 5.7558e-05, 6.1566e-04, 3.5037e-04, 2.5193e-03,\n",
      "         7.0656e-02, 1.9853e-03, 3.6589e-02, 1.2234e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1039], requires_grad=True)\n",
      "bias grad:  tensor([0.2158])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6083]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1668]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0863,  -322.8736,   -11.4189,  -302.5942]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1061], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6249]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0863,  -322.8736,   -11.4189,  -302.5942]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4911e-04, 3.1836e-05, 1.3063e-04, 1.3569e-03, 5.8103e-04, 1.8220e-03,\n",
      "         8.4220e-02, 3.6812e-03, 7.5939e-02, 2.1115e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1061], requires_grad=True)\n",
      "bias grad:  tensor([0.4777])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6249]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1848]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0872,  -322.8736,   -11.4197,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1108], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6434]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0872,  -322.8736,   -11.4197,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[4.6901e-03, 0.0000e+00, 5.8537e-05, 7.3182e-04, 6.0184e-04, 1.1530e-03,\n",
      "         4.9312e-02, 1.9204e-03, 4.5097e-02, 9.2062e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1108], requires_grad=True)\n",
      "bias grad:  tensor([0.2563])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6434]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2943]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0877,  -322.8736,   -11.4202,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1134], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6728]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0877,  -322.8736,   -11.4202,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3701e-03, 0.0000e+00, 5.9416e-05, 6.3011e-04, 5.7591e-04, 7.6605e-04,\n",
      "         4.3871e-02, 2.3483e-03, 4.4683e-02, 1.1756e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1134], requires_grad=True)\n",
      "bias grad:  tensor([0.2570])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6728]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3940]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0881,  -322.8737,   -11.4206,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1160], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6334]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0881,  -322.8737,   -11.4206,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0022, 0.0003, 0.0003, 0.0031, 0.0008, 0.0076, 0.2248, 0.0072, 0.1393,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1160], requires_grad=True)\n",
      "bias grad:  tensor([0.8605])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6334]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.7425]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8737,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1246], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8077]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8737,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8297e-03,  0.0000e+00,  6.0615e-06, -1.0118e-04, -5.7572e-05,\n",
      "          4.0442e-04,  8.0491e-03,  3.8694e-04,  6.7863e-04,  8.6797e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1246], requires_grad=True)\n",
      "bias grad:  tensor([0.0040])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8077]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2320]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8737,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1246], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7845]], requires_grad=True)\n",
      "Iteration 11 | Score: 0.1635158210992813\n",
      "updating best value\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8737,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[1.8607e-04, 4.1239e-05, 8.8397e-05, 1.0860e-03, 6.5012e-04, 9.6821e-04,\n",
      "         5.4885e-02, 2.8010e-03, 6.2702e-02, 1.8859e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1246], requires_grad=True)\n",
      "bias grad:  tensor([0.3803])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7845]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1241]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0910,  -322.8737,   -11.4226,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1284], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7969]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0910,  -322.8737,   -11.4226,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.3258e-04, -2.9737e-05,  3.4500e-05,  4.0574e-04,  2.6261e-04,\n",
      "          7.3711e-04,  2.7052e-02,  1.7430e-03,  3.2432e-02,  1.5529e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1284], requires_grad=True)\n",
      "bias grad:  tensor([0.1823])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7969]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6283]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0913,  -322.8738,   -11.4230,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1302], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7341]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0913,  -322.8738,   -11.4230,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[1.1291e-03, 1.2972e-05, 6.8462e-05, 5.8880e-04, 2.7366e-04, 2.4523e-03,\n",
      "         6.4835e-02, 2.0022e-03, 4.1640e-02, 1.2898e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1302], requires_grad=True)\n",
      "bias grad:  tensor([0.2363])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7341]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0840]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0919,  -322.8738,   -11.4234,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1326], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7257]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0919,  -322.8738,   -11.4234,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.5825e-03, -3.0564e-05, -3.5045e-05, -6.5379e-04, -4.1832e-04,\n",
      "         -2.8783e-04, -2.3811e-02, -8.8023e-04, -2.6666e-02,  1.2408e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1326], requires_grad=True)\n",
      "bias grad:  tensor([-0.1564])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7257]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7114]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0917,  -322.8738,   -11.4231,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1310], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6545]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0917,  -322.8738,   -11.4231,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.1638e-03,  0.0000e+00,  1.1308e-06, -3.6956e-05,  8.1861e-05,\n",
      "          7.0506e-05,  8.2048e-03, -3.0637e-04, -4.1794e-03, -2.5378e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1310], requires_grad=True)\n",
      "bias grad:  tensor([-0.0182])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6545]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1638]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0917,  -322.8738,   -11.4231,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1309], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6709]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0917,  -322.8738,   -11.4231,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6514e-03, 2.9224e-05, 9.1672e-05, 1.0761e-03, 7.7255e-04, 1.2928e-03,\n",
      "         6.4659e-02, 3.1992e-03, 6.7767e-02, 2.5207e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1309], requires_grad=True)\n",
      "bias grad:  tensor([0.4029])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6709]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0060]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0924,  -322.8738,   -11.4237,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1349], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6715]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0924,  -322.8738,   -11.4237,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9424e-02,  0.0000e+00, -5.8105e-05, -1.2104e-03, -1.5149e-03,\n",
      "         -7.9880e-04, -3.6218e-02, -2.7308e-03, -6.3603e-02, -7.1968e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1349], requires_grad=True)\n",
      "bias grad:  tensor([-0.3592])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6715]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2910]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0920,  -322.8738,   -11.4231,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1313], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6424]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0920,  -322.8738,   -11.4231,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.6092e-03,  1.4226e-05,  4.0978e-05,  2.9753e-04, -4.9155e-05,\n",
      "          1.3532e-03,  3.4070e-02,  1.3521e-03,  2.1329e-02,  9.8520e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1313], requires_grad=True)\n",
      "bias grad:  tensor([0.1304])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6424]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0762]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0924,  -322.8738,   -11.4233,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1326], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6348]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0924,  -322.8738,   -11.4233,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.4494e-04,  0.0000e+00, -1.2069e-04, -7.9615e-04, -1.8735e-04,\n",
      "         -5.5436e-03, -1.4513e-01, -3.6016e-03, -6.4925e-02, -3.7294e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1326], requires_grad=True)\n",
      "bias grad:  tensor([-0.4027])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6348]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1413]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8738,   -11.4227,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1286], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5207]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8738,   -11.4227,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.7573e-03,  4.2236e-05,  2.0020e-05,  8.3363e-04,  1.0231e-03,\n",
      "         -2.8991e-03, -4.2622e-02,  1.0541e-03,  3.9325e-02,  1.2650e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1286], requires_grad=True)\n",
      "bias grad:  tensor([0.2111])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5207]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3475]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0905,  -322.8738,   -11.4231,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1307], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5554]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0905,  -322.8738,   -11.4231,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.9472e-03, -7.4202e-05, -5.9407e-05, -6.6088e-04, -3.5130e-05,\n",
      "         -2.0957e-03, -6.3066e-02, -1.4189e-03, -3.0972e-02,  3.2624e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1307], requires_grad=True)\n",
      "bias grad:  tensor([-0.1970])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5554]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9919]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0899,  -322.8738,   -11.4228,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1287], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4562]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0899,  -322.8738,   -11.4228,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1090e-04, -1.9652e-04, -7.0993e-05, -5.5997e-04,  8.9782e-07,\n",
      "         -4.0548e-03, -9.3072e-02, -2.2250e-03, -3.5462e-02, -3.9379e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1287], requires_grad=True)\n",
      "bias grad:  tensor([-0.2169])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4562]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7502]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0889,  -322.8737,   -11.4224,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1266], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3812]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0889,  -322.8737,   -11.4224,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0058, 0.0000, 0.0003, 0.0030, 0.0006, 0.0018, 0.1164, 0.0057, 0.1579,\n",
      "         0.0033]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1266], requires_grad=True)\n",
      "bias grad:  tensor([0.9053])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3812]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.6854]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0901,  -322.8738,   -11.4240,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1356], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7498]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0901,  -322.8738,   -11.4240,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.1968e-03,  2.7612e-05, -7.8645e-05, -1.2112e-03, -8.6032e-04,\n",
      "         -1.0513e-03, -5.9370e-02, -2.8799e-03, -6.3636e-02, -6.9515e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1356], requires_grad=True)\n",
      "bias grad:  tensor([-0.3702])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7498]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3132]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0895,  -322.8738,   -11.4233,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1319], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7184]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0895,  -322.8738,   -11.4233,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0592e-03,  3.7704e-05,  6.8924e-05,  8.1812e-04,  3.9225e-04,\n",
      "          2.6344e-03,  7.3061e-02,  2.4213e-03,  4.4196e-02,  1.3488e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1319], requires_grad=True)\n",
      "bias grad:  tensor([0.2803])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7184]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2414]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0902,  -322.8738,   -11.4238,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1347], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7426]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0902,  -322.8738,   -11.4238,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6647e-03, 0.0000e+00, 5.2716e-05, 7.5113e-04, 5.4492e-04, 1.8871e-04,\n",
      "         3.5615e-02, 1.9345e-03, 4.5687e-02, 8.9748e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1347], requires_grad=True)\n",
      "bias grad:  tensor([0.2665])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7426]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0178]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0906,  -322.8738,   -11.4242,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1374], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7408]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0906,  -322.8738,   -11.4242,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.6724e-04,  0.0000e+00, -4.4571e-06, -2.5110e-04, -2.5499e-04,\n",
      "          1.8382e-04,  3.5010e-03, -2.8519e-04, -8.6082e-03,  3.3421e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1374], requires_grad=True)\n",
      "bias grad:  tensor([-0.0489])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7408]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3532]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0906,  -322.8738,   -11.4242,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1369], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7055]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0906,  -322.8738,   -11.4242,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1790e-04,  5.5946e-05,  3.6615e-05,  3.5169e-04, -1.0669e-04,\n",
      "          6.7403e-04,  2.8515e-02,  1.2421e-03,  2.5713e-02,  8.0880e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1369], requires_grad=True)\n",
      "bias grad:  tensor([0.1481])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7055]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0796]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0909,  -322.8738,   -11.4244,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1384], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7134]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0909,  -322.8738,   -11.4244,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.9340e-04, -9.7616e-05, -5.8859e-05, -6.8680e-04, -6.9105e-07,\n",
      "         -2.0459e-03, -5.5974e-02, -1.6537e-03, -3.4946e-02, -3.0387e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1384], requires_grad=True)\n",
      "bias grad:  tensor([-0.1994])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7134]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6752]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0903,  -322.8738,   -11.4241,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1364], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6459]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0903,  -322.8738,   -11.4241,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2756e-03,  0.0000e+00,  5.2796e-05,  5.6126e-04,  2.6013e-04,\n",
      "          5.5406e-04,  2.7727e-02,  1.8953e-03,  3.6249e-02,  1.1137e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1364], requires_grad=True)\n",
      "bias grad:  tensor([0.2135])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6459]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0185]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0906,  -322.8738,   -11.4244,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1385], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6441]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0906,  -322.8738,   -11.4244,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.6919e-04,  1.0843e-05,  5.4187e-06, -8.7919e-05,  7.8170e-06,\n",
      "          1.6321e-03,  2.9584e-02,  3.6512e-04, -3.2282e-03,  6.3407e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1385], requires_grad=True)\n",
      "bias grad:  tensor([-0.0055])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6441]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3049]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0909,  -322.8738,   -11.4244,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1384], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6136]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0909,  -322.8738,   -11.4244,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[2.1127e-03, 3.8756e-05, 4.9319e-05, 5.0575e-04, 2.8579e-04, 2.3638e-03,\n",
      "         6.3424e-02, 1.6395e-03, 2.8659e-02, 1.0002e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1384], requires_grad=True)\n",
      "bias grad:  tensor([0.1737])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6136]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2090]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0916,  -322.8739,   -11.4247,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1402], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6345]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0916,  -322.8739,   -11.4247,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3781e-05,  4.6436e-05,  1.2281e-04,  1.2655e-03,  5.3693e-04,\n",
      "          1.6557e-03,  7.9592e-02,  3.5262e-03,  6.9491e-02,  2.1720e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1402], requires_grad=True)\n",
      "bias grad:  tensor([0.4523])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6345]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1192]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0924,  -322.8739,   -11.4254,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1447], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6464]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0924,  -322.8739,   -11.4254,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4302e-03, 0.0000e+00, 5.6341e-05, 6.7860e-04, 5.4457e-04, 1.0638e-03,\n",
      "         4.5427e-02, 1.9071e-03, 4.3020e-02, 9.6908e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1447], requires_grad=True)\n",
      "bias grad:  tensor([0.2442])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6464]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1890]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0928,  -322.8739,   -11.4258,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1471], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6653]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0928,  -322.8739,   -11.4258,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1186e-03, 0.0000e+00, 2.6555e-05, 2.8101e-04, 3.9303e-04, 5.2634e-04,\n",
      "         2.7372e-02, 1.3997e-03, 2.2090e-02, 6.2379e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1471], requires_grad=True)\n",
      "bias grad:  tensor([0.1267])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6653]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2530]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0931,  -322.8739,   -11.4260,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1484], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6400]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0931,  -322.8739,   -11.4260,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0004, 0.0003, 0.0003, 0.0030, 0.0007, 0.0075, 0.2212, 0.0070, 0.1330,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1484], requires_grad=True)\n",
      "bias grad:  tensor([0.8242])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6400]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6015]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0953,  -322.8740,   -11.4274,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1567], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8001]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0953,  -322.8740,   -11.4274,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6868e-03,  0.0000e+00,  2.2377e-06, -1.7727e-04, -1.8173e-06,\n",
      "          4.5657e-04,  8.7909e-03,  3.6040e-04, -1.7286e-03,  6.4384e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1567], requires_grad=True)\n",
      "bias grad:  tensor([-0.0098])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8001]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3569]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0954,  -322.8740,   -11.4273,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1566], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7644]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0954,  -322.8740,   -11.4273,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[2.6736e-04, 3.7979e-05, 7.6873e-05, 9.7792e-04, 6.2103e-04, 8.9634e-04,\n",
      "         4.8139e-02, 2.5288e-03, 5.6590e-02, 1.5943e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1566], requires_grad=True)\n",
      "bias grad:  tensor([0.3408])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7644]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0800]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0959,  -322.8740,   -11.4279,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1600], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7724]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0959,  -322.8740,   -11.4279,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9943e-03, -2.8779e-05,  3.5164e-05,  3.9724e-04,  1.3215e-04,\n",
      "          7.8695e-04,  2.8927e-02,  1.7680e-03,  3.2476e-02,  1.6287e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1600], requires_grad=True)\n",
      "bias grad:  tensor([0.1820])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7724]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6541]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0961,  -322.8741,   -11.4282,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1618], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7070]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0961,  -322.8741,   -11.4282,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0989e-04,  6.7416e-06,  6.3655e-05,  5.2263e-04,  9.4814e-05,\n",
      "          2.4891e-03,  6.0546e-02,  1.8029e-03,  3.6339e-02,  1.1782e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1618], requires_grad=True)\n",
      "bias grad:  tensor([0.2062])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7070]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0022]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8741,   -11.4286,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1638], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7073]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8741,   -11.4286,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.9947e-03, -3.1951e-05, -4.0631e-05, -7.6554e-04, -5.1683e-04,\n",
      "         -3.4554e-04, -2.7627e-02, -1.2343e-03, -3.2659e-02,  3.1188e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1638], requires_grad=True)\n",
      "bias grad:  tensor([-0.1884])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7073]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7134]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0965,  -322.8741,   -11.4283,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1620], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6359]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0965,  -322.8741,   -11.4283,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1345e-04,  0.0000e+00, -4.4824e-06, -1.5694e-04, -5.0322e-05,\n",
      "          2.3597e-05,  5.3756e-04, -6.1760e-04, -1.0824e-02, -4.0356e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1620], requires_grad=True)\n",
      "bias grad:  tensor([-0.0575])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6359]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2602]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0965,  -322.8741,   -11.4282,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1614], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6619]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0965,  -322.8741,   -11.4282,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.4377e-03, 2.9813e-05, 9.4573e-05, 1.1960e-03, 9.2127e-04, 1.2603e-03,\n",
      "         6.6460e-02, 3.4246e-03, 7.4014e-02, 2.5005e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1614], requires_grad=True)\n",
      "bias grad:  tensor([0.4386])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6619]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0859]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0971,  -322.8741,   -11.4289,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1658], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6705]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0971,  -322.8741,   -11.4289,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7798e-02,  0.0000e+00, -5.4814e-05, -1.1284e-03, -1.4078e-03,\n",
      "         -7.4721e-04, -3.3870e-02, -2.5639e-03, -5.9469e-02, -6.7678e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1658], requires_grad=True)\n",
      "bias grad:  tensor([-0.3360])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6705]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2313]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8741,   -11.4283,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1624], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6474]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8741,   -11.4283,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.7841e-03,  1.4738e-05,  3.9854e-05,  3.1573e-04, -2.7761e-05,\n",
      "          1.1449e-03,  3.0171e-02,  1.3236e-03,  2.1793e-02,  9.7521e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1624], requires_grad=True)\n",
      "bias grad:  tensor([0.1328])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6474]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0426]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0971,  -322.8741,   -11.4285,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1637], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6431]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0971,  -322.8741,   -11.4285,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.8353e-04,  0.0000e+00, -1.1077e-04, -7.1413e-04, -1.4124e-04,\n",
      "         -5.2572e-03, -1.3554e-01, -3.3412e-03, -5.8989e-02, -2.4076e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1637], requires_grad=True)\n",
      "bias grad:  tensor([-0.3679])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6431]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1595]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0958,  -322.8741,   -11.4279,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1601], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5272]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0958,  -322.8741,   -11.4279,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.6472e-03,  2.6221e-05, -1.5375e-05,  3.9021e-04,  7.5980e-04,\n",
      "         -3.1928e-03, -6.3346e-02, -9.4567e-05,  1.3829e-02, -6.6219e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1601], requires_grad=True)\n",
      "bias grad:  tensor([0.0587])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5272]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2050]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0951,  -322.8741,   -11.4281,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1607], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5477]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0951,  -322.8741,   -11.4281,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.8425e-03, -8.5151e-05, -7.1315e-05, -7.3886e-04, -1.7184e-05,\n",
      "         -2.4317e-03, -7.5361e-02, -1.6734e-03, -3.4836e-02, -1.6476e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1607], requires_grad=True)\n",
      "bias grad:  tensor([-0.2242])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5477]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.0021]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0944,  -322.8740,   -11.4277,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1584], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4475]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0944,  -322.8740,   -11.4277,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.5840e-04, -2.0254e-04, -8.3779e-05, -7.4323e-04, -9.8074e-05,\n",
      "         -4.3375e-03, -1.0348e-01, -2.6368e-03, -4.3546e-02, -5.6933e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1584], requires_grad=True)\n",
      "bias grad:  tensor([-0.2761])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4475]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8384]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0933,  -322.8740,   -11.4273,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1557], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3636]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0933,  -322.8740,   -11.4273,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0060, 0.0000, 0.0002, 0.0029, 0.0005, 0.0017, 0.1063, 0.0051, 0.1469,\n",
      "         0.0030]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1557], requires_grad=True)\n",
      "bias grad:  tensor([0.8434])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3636]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.0172]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0944,  -322.8741,   -11.4288,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1641], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7653]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0944,  -322.8741,   -11.4288,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.4360e-03,  3.1100e-05, -7.6905e-05, -1.2273e-03, -9.2175e-04,\n",
      "         -8.8485e-04, -5.8442e-02, -2.9116e-03, -6.5001e-02, -6.5990e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1641], requires_grad=True)\n",
      "bias grad:  tensor([-0.3744])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7653]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3192]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0938,  -322.8740,   -11.4281,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1603], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7334]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0938,  -322.8740,   -11.4281,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3595e-03,  3.2726e-05,  5.3518e-05,  5.9516e-04,  2.4454e-04,\n",
      "          2.1991e-03,  5.9059e-02,  1.8074e-03,  3.3615e-02,  1.0510e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1603], requires_grad=True)\n",
      "bias grad:  tensor([0.2070])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7334]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1339]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0944,  -322.8741,   -11.4284,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1624], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7468]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0944,  -322.8741,   -11.4284,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5188e-03, 0.0000e+00, 6.0786e-05, 8.3681e-04, 6.0478e-04, 2.8919e-04,\n",
      "         4.2051e-02, 2.2407e-03, 5.1485e-02, 1.0976e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1624], requires_grad=True)\n",
      "bias grad:  tensor([0.2995])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7468]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0459]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0948,  -322.8741,   -11.4290,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1654], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7422]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0948,  -322.8741,   -11.4290,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7077e-03,  0.0000e+00, -9.5034e-06, -3.5999e-04, -3.0434e-04,\n",
      "          1.9256e-04,  2.7053e-03, -4.2973e-04, -1.3280e-02,  3.3424e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1654], requires_grad=True)\n",
      "bias grad:  tensor([-0.0760])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7422]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4976]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0949,  -322.8741,   -11.4288,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1646], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6925]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0949,  -322.8741,   -11.4288,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.9699e-05,  5.6779e-05,  1.3484e-05,  9.5500e-05, -3.2869e-04,\n",
      "          2.8831e-04,  1.3867e-02,  3.6856e-04,  7.6723e-03,  2.1448e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1646], requires_grad=True)\n",
      "bias grad:  tensor([0.0441])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6925]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2352]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0950,  -322.8741,   -11.4289,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1651], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7160]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0950,  -322.8741,   -11.4289,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.6575e-04, -1.1171e-04, -6.7568e-05, -8.1138e-04, -4.5984e-05,\n",
      "         -2.1028e-03, -6.0346e-02, -2.0165e-03, -4.2572e-02, -4.2554e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1651], requires_grad=True)\n",
      "bias grad:  tensor([-0.2420])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7160]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6822]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0944,  -322.8741,   -11.4285,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1627], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6478]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0944,  -322.8741,   -11.4285,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8047e-03,  0.0000e+00,  4.3351e-05,  5.0118e-04,  2.4858e-04,\n",
      "          3.8482e-04,  2.0829e-02,  1.6395e-03,  3.1995e-02,  8.4662e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1627], requires_grad=True)\n",
      "bias grad:  tensor([0.1848])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6478]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0814]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0946,  -322.8741,   -11.4288,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1645], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6559]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0946,  -322.8741,   -11.4288,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.4702e-04,  9.5512e-06,  3.5020e-06, -8.5675e-05,  1.2099e-04,\n",
      "          1.2051e-03,  2.2518e-02,  3.2456e-04, -1.8226e-03,  5.4286e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1645], requires_grad=True)\n",
      "bias grad:  tensor([-0.0024])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6559]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4113]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0948,  -322.8741,   -11.4288,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1645], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6148]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0948,  -322.8741,   -11.4288,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6200e-03, 3.4194e-05, 4.9114e-05, 5.0610e-04, 3.4567e-04, 2.2270e-03,\n",
      "         6.2969e-02, 1.8141e-03, 3.0724e-02, 1.1161e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1645], requires_grad=True)\n",
      "bias grad:  tensor([0.1852])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6148]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0907]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0955,  -322.8741,   -11.4291,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1663], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6238]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0955,  -322.8741,   -11.4291,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[2.1887e-04, 4.1883e-05, 1.2164e-04, 1.2557e-03, 5.0902e-04, 1.7966e-03,\n",
      "         7.9823e-02, 3.3734e-03, 6.9372e-02, 2.0055e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1663], requires_grad=True)\n",
      "bias grad:  tensor([0.4413])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6238]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2102]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8741,   -11.4298,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1708], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6449]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8741,   -11.4298,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5481e-03, 0.0000e+00, 7.9882e-05, 9.6140e-04, 8.1396e-04, 1.0246e-03,\n",
      "         5.5236e-02, 2.8458e-03, 6.3365e-02, 2.0157e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1708], requires_grad=True)\n",
      "bias grad:  tensor([0.3606])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6449]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0856]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8742,   -11.4304,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1744], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6534]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8742,   -11.4304,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[4.3063e-04, 0.0000e+00, 2.3605e-05, 1.7717e-04, 5.1190e-05, 5.9098e-04,\n",
      "         2.3606e-02, 9.8260e-04, 1.5592e-02, 3.0687e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1744], requires_grad=True)\n",
      "bias grad:  tensor([0.0875])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6534]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2312]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8742,   -11.4306,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1752], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6303]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8742,   -11.4306,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-0.0010,  0.0003,  0.0002,  0.0026,  0.0005,  0.0071,  0.2016,  0.0060,\n",
      "          0.1090,  0.0016]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1752], requires_grad=True)\n",
      "bias grad:  tensor([0.6852])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6303]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.4950]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0991,  -322.8742,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1821], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7798]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0991,  -322.8742,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.5151e-03,  0.0000e+00, -1.1933e-05, -3.8785e-04, -2.4381e-04,\n",
      "          3.3350e-04, -3.1948e-03, -3.2495e-04, -1.4690e-02, -1.5573e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1821], requires_grad=True)\n",
      "bias grad:  tensor([-0.0860])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7798]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3101]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0990,  -322.8742,   -11.4315,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1812], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7488]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0990,  -322.8742,   -11.4315,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.0667e-04,  4.0183e-05,  5.0795e-05,  6.2629e-04,  3.4128e-04,\n",
      "          6.3050e-04,  3.1786e-02,  1.6562e-03,  3.5418e-02,  1.0386e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1812], requires_grad=True)\n",
      "bias grad:  tensor([0.2168])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7488]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1439]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0993,  -322.8743,   -11.4319,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1834], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7632]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0993,  -322.8743,   -11.4319,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3776e-03, -3.0163e-05,  2.8152e-05,  3.2278e-04,  1.6022e-04,\n",
      "          6.2693e-04,  2.2505e-02,  1.5368e-03,  2.7574e-02,  1.5045e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1834], requires_grad=True)\n",
      "bias grad:  tensor([0.1545])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7632]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6327]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0996,  -322.8743,   -11.4321,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1849], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6999]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0996,  -322.8743,   -11.4321,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[4.7809e-04, 8.7458e-06, 5.5759e-05, 4.3434e-04, 1.6512e-04, 2.2731e-03,\n",
      "         5.7311e-02, 1.6428e-03, 3.1783e-02, 1.1210e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1849], requires_grad=True)\n",
      "bias grad:  tensor([0.1803])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6999]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0617]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1001,  -322.8743,   -11.4325,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1867], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6937]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1001,  -322.8743,   -11.4325,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.1613e-03, -2.7006e-05, -4.1367e-05, -7.3020e-04, -4.7733e-04,\n",
      "         -3.8615e-04, -2.6767e-02, -1.1905e-03, -3.1750e-02,  7.0744e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1867], requires_grad=True)\n",
      "bias grad:  tensor([-0.1848])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6937]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6195]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0999,  -322.8743,   -11.4321,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1849], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6318]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0999,  -322.8743,   -11.4321,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.1037e-04,  0.0000e+00, -1.7551e-05, -3.2743e-04, -1.3068e-04,\n",
      "         -5.2592e-05, -6.1863e-03, -1.0792e-03, -2.1838e-02, -6.5158e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1849], requires_grad=True)\n",
      "bias grad:  tensor([-0.1198])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6318]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2479]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0998,  -322.8743,   -11.4319,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1837], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6566]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0998,  -322.8743,   -11.4319,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[3.8948e-03, 2.9236e-05, 9.6607e-05, 1.1509e-03, 8.2708e-04, 1.5259e-03,\n",
      "         7.0329e-02, 3.3804e-03, 7.1526e-02, 2.5940e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1837], requires_grad=True)\n",
      "bias grad:  tensor([0.4257])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6566]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0430]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1005,  -322.8744,   -11.4326,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1880], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6609]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1005,  -322.8744,   -11.4326,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3879e-02,  0.0000e+00, -5.1703e-05, -1.2461e-03, -1.6149e-03,\n",
      "         -7.9048e-04, -3.5944e-02, -2.5833e-03, -6.3262e-02, -6.6715e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1880], requires_grad=True)\n",
      "bias grad:  tensor([-0.3555])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6609]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4169]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1002,  -322.8743,   -11.4320,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1844], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6192]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1002,  -322.8743,   -11.4320,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.8527e-03,  6.5173e-06,  4.0483e-05,  3.2021e-04, -6.5600e-05,\n",
      "          1.3098e-03,  3.2620e-02,  1.2991e-03,  2.1395e-02,  9.1508e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1844], requires_grad=True)\n",
      "bias grad:  tensor([0.1298])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6192]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0687]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1005,  -322.8743,   -11.4322,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1857], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6261]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1005,  -322.8743,   -11.4322,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.2149e-04,  0.0000e+00, -1.1277e-04, -6.9464e-04, -9.1527e-05,\n",
      "         -5.4046e-03, -1.3772e-01, -3.3386e-03, -5.8454e-02, -2.4597e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1857], requires_grad=True)\n",
      "bias grad:  tensor([-0.3660])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6261]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1272]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0991,  -322.8743,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1820], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5133]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0991,  -322.8743,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6267e-03,  1.5740e-05, -4.1138e-05,  6.2342e-05,  5.5046e-04,\n",
      "         -3.7724e-03, -8.3710e-02, -1.0089e-03, -5.1865e-03, -9.8333e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1820], requires_grad=True)\n",
      "bias grad:  tensor([-0.0528])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5133]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0923]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0983,  -322.8743,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1815], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5226]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0983,  -322.8743,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.5659e-03, -7.5413e-05, -4.1332e-05, -3.6241e-04,  2.1118e-04,\n",
      "         -2.0007e-03, -5.1123e-02, -8.3346e-04, -1.6572e-02,  2.4865e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1815], requires_grad=True)\n",
      "bias grad:  tensor([-0.1099])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5226]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6694]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0978,  -322.8743,   -11.4314,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1804], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4556]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0978,  -322.8743,   -11.4314,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.4497e-04, -1.9746e-04, -5.8717e-05, -4.4229e-04,  1.2746e-04,\n",
      "         -3.9930e-03, -8.7786e-02, -1.6487e-03, -2.3654e-02, -3.9801e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1804], requires_grad=True)\n",
      "bias grad:  tensor([-0.1591])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4556]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda grad:  tensor([[0.8901]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0969,  -322.8743,   -11.4312,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1788], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3666]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0969,  -322.8743,   -11.4312,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0058, 0.0000, 0.0002, 0.0030, 0.0006, 0.0018, 0.1115, 0.0054, 0.1531,\n",
      "         0.0031]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1788], requires_grad=True)\n",
      "bias grad:  tensor([0.8792])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3666]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.9316]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0980,  -322.8743,   -11.4327,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1876], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7598]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0980,  -322.8743,   -11.4327,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8461e-03,  1.9928e-06, -1.1175e-04, -1.7204e-03, -1.1481e-03,\n",
      "         -1.4310e-03, -7.9307e-02, -4.1275e-03, -9.0484e-02, -1.0679e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1876], requires_grad=True)\n",
      "bias grad:  tensor([-0.5294])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7598]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5447]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0972,  -322.8743,   -11.4318,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1823], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7053]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0972,  -322.8743,   -11.4318,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1682e-03,  3.4312e-05,  5.4905e-05,  5.8126e-04,  1.6900e-04,\n",
      "          2.3349e-03,  5.9819e-02,  1.8837e-03,  3.0303e-02,  1.2732e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1823], requires_grad=True)\n",
      "bias grad:  tensor([0.2060])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7053]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1681]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0978,  -322.8743,   -11.4321,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1844], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7221]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0978,  -322.8743,   -11.4321,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5236e-03, 0.0000e+00, 6.3266e-05, 8.5232e-04, 6.5569e-04, 3.2875e-04,\n",
      "         4.7948e-02, 2.3522e-03, 5.3005e-02, 1.2289e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1844], requires_grad=True)\n",
      "bias grad:  tensor([0.3069])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7221]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1164]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0983,  -322.8744,   -11.4326,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1875], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7105]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0983,  -322.8744,   -11.4326,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4732e-03,  0.0000e+00, -1.3448e-05, -3.7427e-04, -3.2734e-04,\n",
      "          1.6775e-04,  1.1441e-04, -6.2696e-04, -1.5469e-02,  2.6759e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1875], requires_grad=True)\n",
      "bias grad:  tensor([-0.0881])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7105]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3104]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0983,  -322.8744,   -11.4325,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1866], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6794]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0983,  -322.8744,   -11.4325,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.8670e-05,  6.7082e-05,  2.8780e-05,  2.5497e-04, -2.4089e-04,\n",
      "          5.5346e-04,  2.2612e-02,  9.0648e-04,  1.8931e-02,  6.2836e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1866], requires_grad=True)\n",
      "bias grad:  tensor([0.1092])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6794]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1154]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0985,  -322.8744,   -11.4327,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1877], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6910]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0985,  -322.8744,   -11.4327,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.0867e-04, -9.9113e-05, -6.9263e-05, -8.1855e-04, -8.8467e-05,\n",
      "         -2.0672e-03, -5.9852e-02, -2.1267e-03, -4.4525e-02, -4.8784e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1877], requires_grad=True)\n",
      "bias grad:  tensor([-0.2530])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6910]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5849]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0979,  -322.8743,   -11.4322,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1851], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6325]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0979,  -322.8743,   -11.4322,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8180e-03,  0.0000e+00,  4.5585e-05,  5.0467e-04,  2.7073e-04,\n",
      "          5.2463e-04,  2.4068e-02,  1.6719e-03,  3.2417e-02,  9.2173e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1851], requires_grad=True)\n",
      "bias grad:  tensor([0.1898])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6325]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0187]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0981,  -322.8744,   -11.4325,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1870], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6344]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0981,  -322.8744,   -11.4325,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.2157e-04, -3.9886e-06,  2.8118e-06, -9.1582e-05,  9.5977e-05,\n",
      "          1.3242e-03,  2.4804e-02,  3.2970e-04, -1.8366e-03,  4.7360e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1870], requires_grad=True)\n",
      "bias grad:  tensor([-0.0069])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6344]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3307]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0984,  -322.8744,   -11.4325,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1870], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6013]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0984,  -322.8744,   -11.4325,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[2.5051e-03, 3.9520e-05, 3.7727e-05, 3.9164e-04, 2.6720e-04, 2.2314e-03,\n",
      "         5.8064e-02, 1.3048e-03, 2.1970e-02, 9.6397e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1870], requires_grad=True)\n",
      "bias grad:  tensor([0.1358])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6013]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1479]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0990,  -322.8744,   -11.4327,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1883], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6161]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0990,  -322.8744,   -11.4327,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[1.3858e-04, 3.9610e-05, 1.0890e-04, 1.1391e-03, 4.7330e-04, 1.6105e-03,\n",
      "         7.1370e-02, 3.0744e-03, 6.3968e-02, 1.8127e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1883], requires_grad=True)\n",
      "bias grad:  tensor([0.3988])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6161]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2213]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0997,  -322.8744,   -11.4334,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1923], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6382]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0997,  -322.8744,   -11.4334,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7181e-03, 0.0000e+00, 6.7997e-05, 8.4606e-04, 7.6526e-04, 9.9251e-04,\n",
      "         5.0269e-02, 2.4899e-03, 5.5879e-02, 1.8011e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1923], requires_grad=True)\n",
      "bias grad:  tensor([0.3180])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6382]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0846]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1002,  -322.8744,   -11.4339,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1955], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6467]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1002,  -322.8744,   -11.4339,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.4229e-03,  0.0000e+00,  1.6649e-05,  1.0839e-04,  1.1826e-04,\n",
      "          4.3341e-04,  1.6678e-02,  9.4354e-04,  1.1052e-02, -6.3480e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1955], requires_grad=True)\n",
      "bias grad:  tensor([0.0659])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6467]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1828]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1004,  -322.8744,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1961], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6284]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1004,  -322.8744,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0005, 0.0003, 0.0002, 0.0029, 0.0006, 0.0074, 0.2167, 0.0068, 0.1277,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1961], requires_grad=True)\n",
      "bias grad:  tensor([0.7946])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6284]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5980]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1025,  -322.8745,   -11.4353,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2041], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7882]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1025,  -322.8745,   -11.4353,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8591e-03,  0.0000e+00, -6.5056e-06, -2.6766e-04, -1.3880e-04,\n",
      "          3.3017e-04,  9.7642e-04, -7.1266e-05, -8.8122e-03, -6.7625e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2041], requires_grad=True)\n",
      "bias grad:  tensor([-0.0517])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7882]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2188]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1025,  -322.8745,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2036], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7663]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1025,  -322.8745,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8697e-04,  2.8571e-05,  5.8049e-05,  7.1892e-04,  4.3832e-04,\n",
      "          6.7578e-04,  3.6976e-02,  1.8734e-03,  4.1419e-02,  1.2500e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2036], requires_grad=True)\n",
      "bias grad:  tensor([0.2525])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7663]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0740]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1029,  -322.8745,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2061], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7737]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1029,  -322.8745,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4507e-03, -4.2593e-05,  2.1769e-05,  2.4526e-04,  1.1673e-04,\n",
      "          5.8776e-04,  1.8863e-02,  1.3204e-03,  2.3041e-02,  1.3955e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2061], requires_grad=True)\n",
      "bias grad:  tensor([0.1282])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7737]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6322]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1031,  -322.8745,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2074], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7105]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1031,  -322.8745,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0750e-03, -5.9951e-07,  3.5768e-05,  1.3999e-04, -1.0719e-04,\n",
      "          2.1343e-03,  4.5443e-02,  8.2980e-04,  1.4819e-02,  7.9038e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2074], requires_grad=True)\n",
      "bias grad:  tensor([0.0832])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7105]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0902]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1035,  -322.8745,   -11.4360,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2082], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7015]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1035,  -322.8745,   -11.4360,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7845e-03, -3.1556e-05, -4.5551e-05, -8.0655e-04, -5.1130e-04,\n",
      "         -3.9792e-04, -3.0087e-02, -1.2991e-03, -3.5485e-02, -3.8841e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2082], requires_grad=True)\n",
      "bias grad:  tensor([-0.2061])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7015]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7494]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1032,  -322.8745,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2062], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6265]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1032,  -322.8745,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.0348e-04,  0.0000e+00, -1.0970e-05, -2.1806e-04, -5.2635e-05,\n",
      "         -8.5627e-06, -8.9938e-04, -8.1649e-04, -1.5180e-02, -5.1776e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2062], requires_grad=True)\n",
      "bias grad:  tensor([-0.0812])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6265]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2381]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1032,  -322.8745,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2053], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6503]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1032,  -322.8745,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[3.2251e-03, 2.2025e-05, 8.7588e-05, 1.0367e-03, 7.6318e-04, 1.3252e-03,\n",
      "         6.4278e-02, 3.1213e-03, 6.4786e-02, 2.5086e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2053], requires_grad=True)\n",
      "bias grad:  tensor([0.3873])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6503]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0099]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1039,  -322.8745,   -11.4362,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2092], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6494]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1039,  -322.8745,   -11.4362,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9718e-02,  0.0000e+00, -3.2807e-05, -9.0771e-04, -1.2095e-03,\n",
      "         -5.5676e-04, -2.5381e-02, -1.7454e-03, -4.4757e-02, -4.4186e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2092], requires_grad=True)\n",
      "bias grad:  tensor([-0.2504])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6494]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3358]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1036,  -322.8745,   -11.4357,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2067], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6158]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1036,  -322.8745,   -11.4357,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.6863e-03,  1.9004e-05,  3.2993e-05,  1.9088e-04, -1.3197e-04,\n",
      "          1.1266e-03,  2.5615e-02,  1.0302e-03,  1.5049e-02,  8.9025e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2067], requires_grad=True)\n",
      "bias grad:  tensor([0.0933])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6158]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0243]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1039,  -322.8745,   -11.4359,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2076], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6182]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1039,  -322.8745,   -11.4359,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.6684e-04,  0.0000e+00, -1.1809e-04, -7.7636e-04, -1.6589e-04,\n",
      "         -5.4746e-03, -1.4273e-01, -3.5213e-03, -6.3163e-02, -3.1761e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2076], requires_grad=True)\n",
      "bias grad:  tensor([-0.3924])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6182]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1609]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1025,  -322.8745,   -11.4353,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2037], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5021]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1025,  -322.8745,   -11.4353,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6968e-03,  2.7424e-05, -9.5039e-06,  5.0967e-04,  7.6257e-04,\n",
      "         -3.2311e-03, -6.1700e-02,  5.5276e-05,  1.7662e-02, -5.6522e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2037], requires_grad=True)\n",
      "bias grad:  tensor([0.0856])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5021]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.4665]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1018,  -322.8745,   -11.4354,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2046], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5488]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1018,  -322.8745,   -11.4354,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.7015e-03, -7.6749e-05, -6.8336e-05, -7.6281e-04, -7.8677e-05,\n",
      "         -2.2099e-03, -6.9717e-02, -1.6950e-03, -3.6632e-02, -8.8432e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2046], requires_grad=True)\n",
      "bias grad:  tensor([-0.2306])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5488]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9338]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1011,  -322.8745,   -11.4351,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2023], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4554]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1011,  -322.8745,   -11.4351,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.8646e-04, -2.0661e-04, -6.9471e-05, -5.4624e-04,  1.3348e-04,\n",
      "         -4.1546e-03, -9.6938e-02, -2.1224e-03, -3.1817e-02, -3.1591e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2023], requires_grad=True)\n",
      "bias grad:  tensor([-0.2090])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4554]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8375]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1002,  -322.8744,   -11.4347,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2002], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3716]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1002,  -322.8744,   -11.4347,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0059, 0.0000, 0.0002, 0.0027, 0.0005, 0.0014, 0.0897, 0.0044, 0.1324,\n",
      "         0.0024]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2002], requires_grad=True)\n",
      "bias grad:  tensor([0.7609])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3716]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.9730]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1011,  -322.8745,   -11.4361,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2078], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7689]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1011,  -322.8745,   -11.4361,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6240e-03,  1.3531e-05, -1.0081e-04, -1.5666e-03, -1.0858e-03,\n",
      "         -1.2150e-03, -7.1444e-02, -3.7556e-03, -8.2315e-02, -8.7053e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2078], requires_grad=True)\n",
      "bias grad:  tensor([-0.4789])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7689]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4444]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1004,  -322.8744,   -11.4352,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2030], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7245]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1004,  -322.8744,   -11.4352,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7718e-03,  3.5523e-05,  5.4918e-05,  5.7558e-04,  1.5186e-04,\n",
      "          2.4753e-03,  6.2370e-02,  1.8824e-03,  3.0544e-02,  1.2058e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2030], requires_grad=True)\n",
      "bias grad:  tensor([0.2029])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7245]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1146]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1010,  -322.8745,   -11.4356,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2050], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7359]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1010,  -322.8745,   -11.4356,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7154e-03, 0.0000e+00, 5.3237e-05, 7.2684e-04, 5.0839e-04, 1.6969e-04,\n",
      "         3.5468e-02, 1.9708e-03, 4.5088e-02, 1.0587e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2050], requires_grad=True)\n",
      "bias grad:  tensor([0.2605])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7359]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0630]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1013,  -322.8745,   -11.4360,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2076], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7296]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1013,  -322.8745,   -11.4360,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9417e-03,  0.0000e+00, -2.5130e-05, -5.5034e-04, -4.6253e-04,\n",
      "          6.9054e-05, -6.0238e-03, -1.0575e-03, -2.5409e-02,  1.3912e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2076], requires_grad=True)\n",
      "bias grad:  tensor([-0.1448])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7296]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3730]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1013,  -322.8745,   -11.4357,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2062], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6923]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1013,  -322.8745,   -11.4357,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6504e-04,  5.4992e-05,  1.6796e-05,  1.1764e-04, -3.2470e-04,\n",
      "          4.8205e-04,  1.7696e-02,  4.7542e-04,  9.6015e-03,  3.1962e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2062], requires_grad=True)\n",
      "bias grad:  tensor([0.0549])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6923]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2129]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1014,  -322.8745,   -11.4358,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2067], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7136]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1014,  -322.8745,   -11.4358,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.9109e-05, -1.2603e-04, -9.8036e-05, -1.1854e-03, -2.6498e-04,\n",
      "         -2.6476e-03, -8.2794e-02, -2.9979e-03, -6.4067e-02, -8.0771e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2067], requires_grad=True)\n",
      "bias grad:  tensor([-0.3676])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7136]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7970]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1006,  -322.8745,   -11.4352,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2031], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6339]], requires_grad=True)\n",
      "Iteration 12 | Score: 0.6124472618103027\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8737,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4651e-03,  0.0000e+00,  7.1809e-05,  7.9957e-04,  4.2211e-04,\n",
      "          8.7041e-04,  4.2642e-02,  2.6370e-03,  5.0676e-02,  1.4762e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1246], requires_grad=True)\n",
      "bias grad:  tensor([0.2989])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7845]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0705]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8737,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1276], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7774]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8737,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3789e-03,  6.2986e-06, -2.1090e-05, -4.0682e-04, -1.0173e-04,\n",
      "          9.8366e-04,  5.1068e-03, -4.0571e-04, -1.9341e-02,  2.6974e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1276], requires_grad=True)\n",
      "bias grad:  tensor([-0.1076])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7774]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5068]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8737,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1265], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7268]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8737,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[7.3169e-04, 3.8128e-05, 2.9862e-05, 2.7194e-04, 2.1243e-04, 2.0129e-03,\n",
      "         5.1999e-02, 1.2728e-03, 1.7835e-02, 7.8294e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1265], requires_grad=True)\n",
      "bias grad:  tensor([0.1078])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7268]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0764]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8737,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1276], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7191]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8737,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.4157e-04,  3.0344e-05,  1.0806e-04,  1.0724e-03,  4.6542e-04,\n",
      "          1.7420e-03,  7.4702e-02,  3.1554e-03,  6.1062e-02,  1.9341e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1276], requires_grad=True)\n",
      "bias grad:  tensor([0.3897])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7191]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0249]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0922,  -322.8738,   -11.4231,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1315], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7166]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0922,  -322.8738,   -11.4231,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5127e-03, 0.0000e+00, 4.2846e-05, 5.2157e-04, 5.1444e-04, 1.0023e-03,\n",
      "         4.1146e-02, 1.5826e-03, 3.5113e-02, 8.3501e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1315], requires_grad=True)\n",
      "bias grad:  tensor([0.1983])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7166]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0474]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0926,  -322.8738,   -11.4235,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1335], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7214]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0926,  -322.8738,   -11.4235,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[2.5693e-03, 0.0000e+00, 3.3622e-05, 2.8758e-04, 3.7171e-04, 5.4937e-04,\n",
      "         2.7755e-02, 1.4402e-03, 2.4637e-02, 6.5372e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1335], requires_grad=True)\n",
      "bias grad:  tensor([0.1420])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7214]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3992]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0929,  -322.8738,   -11.4237,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1349], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6815]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0929,  -322.8738,   -11.4237,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0008, 0.0003, 0.0003, 0.0031, 0.0008, 0.0075, 0.2225, 0.0073, 0.1403,\n",
      "         0.0025]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1349], requires_grad=True)\n",
      "bias grad:  tensor([0.8641])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6815]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.4717]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0951,  -322.8739,   -11.4251,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1436], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8286]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0951,  -322.8739,   -11.4251,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4895e-03,  0.0000e+00,  1.3688e-05, -2.1654e-05,  8.9305e-05,\n",
      "          5.6101e-04,  1.6515e-02,  7.7362e-04,  7.2204e-03,  1.9803e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1436], requires_grad=True)\n",
      "bias grad:  tensor([0.0414])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8286]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3639]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0953,  -322.8739,   -11.4252,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1440], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7922]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0953,  -322.8739,   -11.4252,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[1.8169e-04, 3.7511e-05, 7.2954e-05, 9.4246e-04, 6.3220e-04, 8.6671e-04,\n",
      "         4.7415e-02, 2.5319e-03, 5.5264e-02, 1.5811e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1440], requires_grad=True)\n",
      "bias grad:  tensor([0.3313])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7922]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0559]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0957,  -322.8739,   -11.4257,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1473], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7978]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0957,  -322.8739,   -11.4257,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0391e-03, -4.3640e-05,  2.3613e-05,  2.5849e-04,  1.2988e-04,\n",
      "          6.0004e-04,  2.0874e-02,  1.3982e-03,  2.4086e-02,  1.4377e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1473], requires_grad=True)\n",
      "bias grad:  tensor([0.1341])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7978]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6221]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0959,  -322.8739,   -11.4260,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1486], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7356]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0959,  -322.8739,   -11.4260,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1708e-04,  5.8573e-06,  6.1490e-05,  4.8783e-04,  1.3118e-04,\n",
      "          2.4263e-03,  6.0855e-02,  1.7656e-03,  3.5213e-02,  1.1868e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1486], requires_grad=True)\n",
      "bias grad:  tensor([0.1995])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7356]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0724]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0965,  -322.8739,   -11.4263,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1506], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7284]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0965,  -322.8739,   -11.4263,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.0576e-03, -4.3509e-05, -3.8302e-05, -7.2515e-04, -4.9060e-04,\n",
      "         -3.1660e-04, -2.4665e-02, -1.0661e-03, -3.0252e-02,  1.3376e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1506], requires_grad=True)\n",
      "bias grad:  tensor([-0.1757])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7284]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7601]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0963,  -322.8739,   -11.4260,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1489], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6524]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0963,  -322.8739,   -11.4260,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.3467e-04,  0.0000e+00,  2.6601e-06, -3.9652e-05,  2.3711e-05,\n",
      "          1.1971e-04,  6.3240e-03, -3.3625e-04, -4.4154e-03, -2.9092e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1489], requires_grad=True)\n",
      "bias grad:  tensor([-0.0209])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6524]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2771]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0964,  -322.8739,   -11.4260,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1487], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6801]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0964,  -322.8739,   -11.4260,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4328e-03, 1.2673e-05, 9.0911e-05, 1.0821e-03, 8.4883e-04, 1.3796e-03,\n",
      "         6.8176e-02, 3.2713e-03, 6.8796e-02, 2.5898e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1487], requires_grad=True)\n",
      "bias grad:  tensor([0.4089])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6801]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0306]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0970,  -322.8740,   -11.4267,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1527], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6770]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0970,  -322.8740,   -11.4267,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7585e-02,  0.0000e+00, -3.1892e-05, -8.4182e-04, -1.1117e-03,\n",
      "         -5.2210e-04, -2.3781e-02, -1.6599e-03, -4.1909e-02, -4.2312e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1527], requires_grad=True)\n",
      "bias grad:  tensor([-0.2348])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6770]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2809]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0968,  -322.8739,   -11.4262,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1504], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6489]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0968,  -322.8739,   -11.4262,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.6758e-03,  1.4392e-05,  2.9733e-05,  1.8501e-04, -1.0654e-04,\n",
      "          1.0778e-03,  2.5856e-02,  9.1634e-04,  1.4025e-02,  7.6063e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1504], requires_grad=True)\n",
      "bias grad:  tensor([0.0863])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6489]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0133]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0971,  -322.8739,   -11.4264,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1513], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6476]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0971,  -322.8739,   -11.4264,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.4316e-04,  0.0000e+00, -1.2197e-04, -8.1422e-04, -1.5828e-04,\n",
      "         -5.3524e-03, -1.4216e-01, -3.5985e-03, -6.5486e-02, -4.3502e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1513], requires_grad=True)\n",
      "bias grad:  tensor([-0.4057])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6476]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1760]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0956,  -322.8739,   -11.4257,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1472], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5300]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0956,  -322.8739,   -11.4257,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.5354e-03,  1.8213e-05, -2.6758e-05,  2.6557e-04,  7.0481e-04,\n",
      "         -3.6098e-03, -7.3511e-02, -4.9670e-04,  5.9199e-03, -7.4175e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1472], requires_grad=True)\n",
      "bias grad:  tensor([0.0126])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5300]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1798]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0949,  -322.8739,   -11.4258,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1473], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5480]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0949,  -322.8739,   -11.4258,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.2290e-03, -5.7131e-05, -3.6018e-05, -3.8414e-04,  1.4933e-05,\n",
      "         -1.6111e-03, -4.6467e-02, -7.6123e-04, -1.5939e-02,  1.2916e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1473], requires_grad=True)\n",
      "bias grad:  tensor([-0.1104])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5480]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7179]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0944,  -322.8739,   -11.4256,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1462], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4762]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0944,  -322.8739,   -11.4256,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.5537e-04, -1.9602e-04, -1.2957e-04, -1.1909e-03, -3.6467e-04,\n",
      "         -4.6493e-03, -1.3366e-01, -4.0766e-03, -7.4541e-02, -1.8058e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1462], requires_grad=True)\n",
      "bias grad:  tensor([-0.4506])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4762]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7021]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0931,  -322.8739,   -11.4249,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1417], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4060]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0931,  -322.8739,   -11.4249,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0045, 0.0000, 0.0002, 0.0026, 0.0005, 0.0015, 0.1041, 0.0049, 0.1374,\n",
      "         0.0029]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1417], requires_grad=True)\n",
      "bias grad:  tensor([0.7882])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4060]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.7864]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0942,  -322.8739,   -11.4263,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1496], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6846]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0942,  -322.8739,   -11.4263,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7942e-03,  2.8024e-05, -6.1972e-05, -9.4068e-04, -6.7048e-04,\n",
      "         -9.0171e-04, -4.8544e-02, -2.2155e-03, -4.8456e-02, -4.6932e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1496], requires_grad=True)\n",
      "bias grad:  tensor([-0.2833])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6846]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2155]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0937,  -322.8739,   -11.4258,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1468], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6631]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0937,  -322.8739,   -11.4258,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3790e-03,  3.0887e-05,  4.6467e-05,  4.9616e-04,  1.5518e-04,\n",
      "          2.2849e-03,  5.5824e-02,  1.6266e-03,  2.6525e-02,  9.8743e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1468], requires_grad=True)\n",
      "bias grad:  tensor([0.1742])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6631]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1997]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0942,  -322.8739,   -11.4260,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1485], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6831]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0942,  -322.8739,   -11.4260,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0027, 0.0000, 0.0001, 0.0014, 0.0009, 0.0007, 0.0943, 0.0042, 0.0888,\n",
      "         0.0024]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1485], requires_grad=True)\n",
      "bias grad:  tensor([0.5100])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6831]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1767]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0952,  -322.8740,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1536], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6654]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0952,  -322.8740,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3664e-03,  0.0000e+00,  1.3938e-06, -1.3667e-04, -1.8891e-04,\n",
      "          2.2341e-04,  6.9250e-03, -5.5127e-05, -2.8587e-03,  3.4045e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1536], requires_grad=True)\n",
      "bias grad:  tensor([-0.0161])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6654]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1445]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0952,  -322.8740,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1534], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6509]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0952,  -322.8740,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.7275e-04,  9.0037e-05,  4.2221e-05,  4.5766e-04, -1.5417e-04,\n",
      "          7.8966e-04,  3.1805e-02,  1.3992e-03,  2.9573e-02,  8.1815e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1534], requires_grad=True)\n",
      "bias grad:  tensor([0.1714])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6509]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3047]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0956,  -322.8740,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1552], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6814]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0956,  -322.8740,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.1876e-03, -9.5374e-05, -6.2325e-05, -7.1484e-04, -2.6784e-05,\n",
      "         -2.1759e-03, -6.0016e-02, -1.8596e-03, -3.7883e-02, -3.5384e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1552], requires_grad=True)\n",
      "bias grad:  tensor([-0.2160])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6814]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5358]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0950,  -322.8739,   -11.4268,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1530], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6278]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0950,  -322.8739,   -11.4268,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1858e-03,  0.0000e+00,  4.5913e-05,  5.3127e-04,  2.4978e-04,\n",
      "          3.6364e-04,  2.2512e-02,  1.7255e-03,  3.3640e-02,  9.0947e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1530], requires_grad=True)\n",
      "bias grad:  tensor([0.1944])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6278]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0431]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0952,  -322.8740,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1549], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6321]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0952,  -322.8740,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.4172e-04,  8.7963e-06, -1.1225e-05, -2.7392e-04, -3.4798e-05,\n",
      "          1.1545e-03,  1.3298e-02, -1.3788e-04, -1.3247e-02,  3.1057e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1549], requires_grad=True)\n",
      "bias grad:  tensor([-0.0687])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6321]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3338]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0953,  -322.8740,   -11.4270,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1543], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5988]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0953,  -322.8740,   -11.4270,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[2.5628e-03, 3.7688e-05, 6.5145e-05, 7.5003e-04, 5.4600e-04, 2.5883e-03,\n",
      "         7.7655e-02, 2.4539e-03, 4.5374e-02, 1.5662e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1543], requires_grad=True)\n",
      "bias grad:  tensor([0.2693])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5988]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0577]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0961,  -322.8740,   -11.4275,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1569], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6045]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0961,  -322.8740,   -11.4275,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[3.9860e-04, 4.2568e-05, 1.1115e-04, 1.1707e-03, 4.4403e-04, 1.8568e-03,\n",
      "         7.5359e-02, 3.0091e-03, 6.5125e-02, 1.7606e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1569], requires_grad=True)\n",
      "bias grad:  tensor([0.4023])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6045]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3868]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1610], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6432]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3555e-03, 0.0000e+00, 4.6909e-05, 5.5860e-04, 4.6083e-04, 1.2431e-03,\n",
      "         4.5742e-02, 1.5974e-03, 3.5987e-02, 8.2679e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1610], requires_grad=True)\n",
      "bias grad:  tensor([0.2038])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6432]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1760]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0973,  -322.8741,   -11.4285,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1630], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6608]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0973,  -322.8741,   -11.4285,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[1.8249e-03, 0.0000e+00, 3.3632e-05, 2.9186e-04, 3.0757e-04, 6.8775e-04,\n",
      "         3.0874e-02, 1.3213e-03, 2.4174e-02, 7.2368e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1630], requires_grad=True)\n",
      "bias grad:  tensor([0.1368])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6608]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3274]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0976,  -322.8741,   -11.4287,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1644], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6281]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0976,  -322.8741,   -11.4287,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0005, 0.0003, 0.0003, 0.0031, 0.0007, 0.0075, 0.2214, 0.0071, 0.1351,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1644], requires_grad=True)\n",
      "bias grad:  tensor([0.8356])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6281]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5737]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0998,  -322.8741,   -11.4301,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1727], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7854]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0998,  -322.8741,   -11.4301,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3945e-03,  0.0000e+00,  9.6802e-06, -5.8238e-05,  2.9774e-05,\n",
      "          4.0896e-04,  1.1142e-02,  5.8454e-04,  4.0964e-03,  1.1303e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1727], requires_grad=True)\n",
      "bias grad:  tensor([0.0234])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7854]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2587]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0999,  -322.8741,   -11.4301,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1730], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7596]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0999,  -322.8741,   -11.4301,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.2870e-04,  4.0525e-05,  6.5440e-05,  8.2671e-04,  4.9637e-04,\n",
      "          8.0466e-04,  4.1872e-02,  2.2325e-03,  4.8122e-02,  1.4047e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1730], requires_grad=True)\n",
      "bias grad:  tensor([0.2890])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7596]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1523]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1004,  -322.8741,   -11.4306,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1759], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7748]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1004,  -322.8741,   -11.4306,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3071e-03, -4.4690e-05,  1.8431e-05,  1.7386e-04, -2.0029e-05,\n",
      "          4.9230e-04,  1.7017e-02,  1.1895e-03,  1.9457e-02,  1.3709e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1759], requires_grad=True)\n",
      "bias grad:  tensor([0.1069])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7748]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6429]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1005,  -322.8741,   -11.4308,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1769], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7105]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1005,  -322.8741,   -11.4308,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4855e-04, 9.5814e-07, 4.8856e-05, 3.4231e-04, 1.0332e-04, 2.2373e-03,\n",
      "         5.3517e-02, 1.3292e-03, 2.6825e-02, 9.9248e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1769], requires_grad=True)\n",
      "bias grad:  tensor([0.1516])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7105]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0814]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1011,  -322.8741,   -11.4311,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1784], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7024]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1011,  -322.8741,   -11.4311,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.0020e-03, -2.9019e-05, -4.5042e-05, -7.9465e-04, -5.5557e-04,\n",
      "         -4.1588e-04, -3.0620e-02, -1.2329e-03, -3.4058e-02,  1.1638e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1784], requires_grad=True)\n",
      "bias grad:  tensor([-0.1997])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7024]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6846]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1007,  -322.8741,   -11.4307,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1764], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6339]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1007,  -322.8741,   -11.4307,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.5169e-03,  0.0000e+00,  3.7212e-06, -1.6957e-05,  7.7209e-05,\n",
      "          9.6811e-05,  8.5699e-03, -3.7919e-04, -3.8958e-03, -2.8022e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1764], requires_grad=True)\n",
      "bias grad:  tensor([-0.0151])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6339]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2760]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1008,  -322.8741,   -11.4307,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1763], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6615]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1008,  -322.8741,   -11.4307,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.6880e-03, 3.3028e-05, 9.3940e-05, 1.1620e-03, 8.9614e-04, 1.3146e-03,\n",
      "         6.8226e-02, 3.3706e-03, 7.2166e-02, 2.5246e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1763], requires_grad=True)\n",
      "bias grad:  tensor([0.4277])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6615]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0571]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1015,  -322.8742,   -11.4314,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1806], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6672]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1015,  -322.8742,   -11.4314,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9639e-02,  0.0000e+00, -3.0880e-05, -8.8203e-04, -1.1821e-03,\n",
      "         -5.3708e-04, -2.4498e-02, -1.6679e-03, -4.3219e-02, -4.2028e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1806], requires_grad=True)\n",
      "bias grad:  tensor([-0.2415])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6672]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2701]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1013,  -322.8741,   -11.4310,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1782], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6402]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1013,  -322.8741,   -11.4310,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.0509e-03,  1.5691e-05,  3.6740e-05,  2.6585e-04, -6.5002e-05,\n",
      "          1.1718e-03,  3.0397e-02,  1.1872e-03,  1.9096e-02,  8.9774e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1782], requires_grad=True)\n",
      "bias grad:  tensor([0.1173])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6402]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0289]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1016,  -322.8741,   -11.4312,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1793], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6373]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1016,  -322.8741,   -11.4312,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5838e-03,  0.0000e+00, -1.2935e-04, -9.5490e-04, -3.1936e-04,\n",
      "         -5.4532e-03, -1.4874e-01, -3.9588e-03, -7.3692e-02, -5.7866e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1793], requires_grad=True)\n",
      "bias grad:  tensor([-0.4532])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6373]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1334]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1001,  -322.8741,   -11.4304,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1748], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5240]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1001,  -322.8741,   -11.4304,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.6899e-03,  3.0100e-05, -1.2510e-05,  3.8336e-04,  8.0187e-04,\n",
      "         -3.3923e-03, -6.0911e-02, -4.6334e-05,  1.4462e-02, -2.7304e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1748], requires_grad=True)\n",
      "bias grad:  tensor([0.0707])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5240]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0581]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0995,  -322.8741,   -11.4306,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1755], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5298]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0995,  -322.8741,   -11.4306,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.6823e-03, -6.6264e-05, -5.6188e-05, -5.7513e-04, -6.0796e-05,\n",
      "         -2.0910e-03, -6.3094e-02, -1.2989e-03, -2.7347e-02, -1.9353e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1755], requires_grad=True)\n",
      "bias grad:  tensor([-0.1768])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5298]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7705]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0988,  -322.8741,   -11.4303,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1737], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4527]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0988,  -322.8741,   -11.4303,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.0712e-03, -2.0633e-04, -4.2705e-05, -2.7243e-04,  2.4648e-04,\n",
      "         -3.9712e-03, -8.1278e-02, -1.4950e-03, -1.6540e-02,  8.8000e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1737], requires_grad=True)\n",
      "bias grad:  tensor([-0.1155])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4527]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6875]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0980,  -322.8741,   -11.4301,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1726], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3840]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0980,  -322.8741,   -11.4301,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0055, 0.0000, 0.0002, 0.0028, 0.0005, 0.0017, 0.1077, 0.0053, 0.1469,\n",
      "         0.0030]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1726], requires_grad=True)\n",
      "bias grad:  tensor([0.8427])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3840]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.5238]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0991,  -322.8742,   -11.4316,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1810], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7364]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0991,  -322.8742,   -11.4316,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7632e-03,  1.8945e-05, -8.4350e-05, -1.3119e-03, -9.4446e-04,\n",
      "         -1.0607e-03, -6.1718e-02, -3.1237e-03, -6.8843e-02, -6.9514e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1810], requires_grad=True)\n",
      "bias grad:  tensor([-0.4003])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7364]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3465]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0985,  -322.8741,   -11.4309,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1770], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7017]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0985,  -322.8741,   -11.4309,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7004e-03,  3.6326e-05,  5.2429e-05,  5.8470e-04,  2.7224e-04,\n",
      "          2.1000e-03,  5.5413e-02,  1.8503e-03,  3.2167e-02,  1.0598e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1770], requires_grad=True)\n",
      "bias grad:  tensor([0.2072])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7017]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1645]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0991,  -322.8742,   -11.4312,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1791], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7182]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0991,  -322.8742,   -11.4312,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0040, 0.0000, 0.0001, 0.0012, 0.0008, 0.0005, 0.0884, 0.0035, 0.0782,\n",
      "         0.0019]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1791], requires_grad=True)\n",
      "bias grad:  tensor([0.4504])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7182]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1492]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0999,  -322.8742,   -11.4320,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1836], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7032]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0999,  -322.8742,   -11.4320,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1794e-03,  0.0000e+00, -1.5815e-05, -4.0064e-04, -3.1529e-04,\n",
      "          1.5437e-04, -1.3751e-03, -6.5481e-04, -1.6981e-02,  1.8621e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1836], requires_grad=True)\n",
      "bias grad:  tensor([-0.0970])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7032]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3679]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0999,  -322.8742,   -11.4318,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1826], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6665]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0999,  -322.8742,   -11.4318,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2490e-05,  7.1873e-05,  3.2017e-05,  3.0441e-04, -2.1042e-04,\n",
      "          6.1516e-04,  2.5366e-02,  1.0586e-03,  2.1560e-02,  6.2863e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1826], requires_grad=True)\n",
      "bias grad:  tensor([0.1237])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6665]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1932]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1002,  -322.8742,   -11.4321,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1838], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6858]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1002,  -322.8742,   -11.4321,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.4673e-04, -8.9797e-05, -5.8680e-05, -6.9587e-04, -3.4956e-05,\n",
      "         -2.0449e-03, -5.6603e-02, -1.7622e-03, -3.6256e-02, -2.9644e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1838], requires_grad=True)\n",
      "bias grad:  tensor([-0.2069])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6858]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5849]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0996,  -322.8742,   -11.4317,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1818], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6273]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0996,  -322.8742,   -11.4317,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.9087e-04,  0.0000e+00,  6.5595e-05,  7.1785e-04,  3.3603e-04,\n",
      "          8.1072e-04,  3.7737e-02,  2.3812e-03,  4.5376e-02,  1.3468e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1818], requires_grad=True)\n",
      "bias grad:  tensor([0.2686])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6273]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0107]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1000,  -322.8742,   -11.4322,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1845], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6262]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1000,  -322.8742,   -11.4322,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.7203e-04,  1.4257e-05, -7.3705e-06, -1.8361e-04,  8.5457e-05,\n",
      "          1.0975e-03,  1.6108e-02,  8.8215e-05, -6.7502e-03,  5.4633e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1845], requires_grad=True)\n",
      "bias grad:  tensor([-0.0357])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6262]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4185]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1001,  -322.8742,   -11.4321,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1841], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5844]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1001,  -322.8742,   -11.4321,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7775e-03, 3.8516e-05, 4.9376e-05, 5.1732e-04, 2.7214e-04, 2.2449e-03,\n",
      "         6.1048e-02, 1.5865e-03, 2.9663e-02, 1.0532e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1841], requires_grad=True)\n",
      "bias grad:  tensor([0.1765])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5844]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1850]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1008,  -322.8742,   -11.4324,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1859], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6029]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1008,  -322.8742,   -11.4324,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[4.4787e-04, 3.4871e-05, 1.0859e-04, 1.1383e-03, 4.3928e-04, 1.6635e-03,\n",
      "         7.2077e-02, 2.9323e-03, 6.2374e-02, 1.6762e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1859], requires_grad=True)\n",
      "bias grad:  tensor([0.3922])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6029]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3531]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1015,  -322.8743,   -11.4330,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1898], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6382]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1015,  -322.8743,   -11.4330,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2581e-03, 0.0000e+00, 6.2863e-05, 7.8282e-04, 6.6184e-04, 8.0819e-04,\n",
      "         4.4544e-02, 2.0923e-03, 4.9419e-02, 1.3371e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1898], requires_grad=True)\n",
      "bias grad:  tensor([0.2809])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6382]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2338]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1019,  -322.8743,   -11.4335,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1926], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6616]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1019,  -322.8743,   -11.4335,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7266e-03, 0.0000e+00, 4.0373e-05, 3.8819e-04, 3.7991e-04, 5.6943e-04,\n",
      "         2.9474e-02, 1.4827e-03, 2.9322e-02, 1.1324e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1926], requires_grad=True)\n",
      "bias grad:  tensor([0.1670])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6616]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3360]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1022,  -322.8743,   -11.4338,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1943], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6280]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1022,  -322.8743,   -11.4338,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[6.3719e-05, 2.9773e-04, 2.5230e-04, 2.9782e-03, 6.1068e-04, 7.6210e-03,\n",
      "         2.1916e-01, 6.7540e-03, 1.2799e-01, 1.9595e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1943], requires_grad=True)\n",
      "bias grad:  tensor([0.7969])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6280]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.7150]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1044,  -322.8744,   -11.4351,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2022], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7995]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1044,  -322.8744,   -11.4351,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6277e-03,  0.0000e+00, -1.5425e-05, -3.6527e-04, -1.5723e-04,\n",
      "          8.2137e-05, -5.3114e-03, -1.6469e-04, -1.3020e-02, -1.7292e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2022], requires_grad=True)\n",
      "bias grad:  tensor([-0.0759])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7995]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3559]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1044,  -322.8744,   -11.4349,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2015], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7639]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1044,  -322.8744,   -11.4349,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.1850e-04,  2.3303e-05,  6.5784e-05,  8.1404e-04,  5.8134e-04,\n",
      "          7.3116e-04,  4.0983e-02,  2.2030e-03,  4.8721e-02,  1.5690e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2015], requires_grad=True)\n",
      "bias grad:  tensor([0.2937])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7639]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0226]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1048,  -322.8744,   -11.4354,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2044], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7661]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1048,  -322.8744,   -11.4354,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6395e-03, -5.6892e-05,  7.5741e-06,  4.3784e-05, -2.1298e-05,\n",
      "          4.7955e-04,  1.1397e-02,  8.4915e-04,  1.2075e-02,  1.2566e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2044], requires_grad=True)\n",
      "bias grad:  tensor([0.0645])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7661]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7023]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1049,  -322.8744,   -11.4356,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2051], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6959]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1049,  -322.8744,   -11.4356,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.3708e-04, -2.9042e-07,  3.4424e-05,  1.1540e-04, -1.0849e-04,\n",
      "          1.9350e-03,  4.0949e-02,  7.8442e-04,  1.4215e-02,  7.4869e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2051], requires_grad=True)\n",
      "bias grad:  tensor([0.0785])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6959]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1740]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1053,  -322.8744,   -11.4357,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2059], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6785]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1053,  -322.8744,   -11.4357,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.2907e-03, -2.1635e-05, -4.1986e-05, -7.5954e-04, -5.9741e-04,\n",
      "         -4.3332e-04, -3.0406e-02, -1.3907e-03, -3.4572e-02, -1.0029e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2059], requires_grad=True)\n",
      "bias grad:  tensor([-0.1999])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6785]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4682]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1050,  -322.8744,   -11.4353,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2039], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6317]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1050,  -322.8744,   -11.4353,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0083e-04,  0.0000e+00, -1.2890e-05, -2.6221e-04, -1.0133e-04,\n",
      "         -1.6645e-05, -1.7522e-03, -8.9240e-04, -1.6801e-02, -5.3629e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2039], requires_grad=True)\n",
      "bias grad:  tensor([-0.0920])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6317]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1662]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1050,  -322.8744,   -11.4352,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2029], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6483]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1050,  -322.8744,   -11.4352,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0053e-03, 1.8659e-05, 8.4697e-05, 1.0618e-03, 8.4967e-04, 1.1112e-03,\n",
      "         6.0660e-02, 3.0761e-03, 6.6151e-02, 2.3784e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2029], requires_grad=True)\n",
      "bias grad:  tensor([0.3926])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6483]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0727]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1056,  -322.8744,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2069], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6556]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1056,  -322.8744,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6978e-02,  0.0000e+00, -3.0068e-05, -8.0388e-04, -1.0643e-03,\n",
      "         -4.9705e-04, -2.2645e-02, -1.5742e-03, -3.9915e-02, -4.0053e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2069], requires_grad=True)\n",
      "bias grad:  tensor([-0.2235])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6556]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3266]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1053,  -322.8744,   -11.4354,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2046], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6229]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1053,  -322.8744,   -11.4354,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2547e-03,  1.4778e-05,  3.7095e-05,  2.7716e-04, -5.7071e-05,\n",
      "          1.1478e-03,  2.9763e-02,  1.1778e-03,  1.9504e-02,  9.2281e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2046], requires_grad=True)\n",
      "bias grad:  tensor([0.1189])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6229]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0389]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1056,  -322.8744,   -11.4356,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2058], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6190]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1056,  -322.8744,   -11.4356,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.9205e-04,  0.0000e+00, -1.1816e-04, -7.7819e-04, -1.3326e-04,\n",
      "         -5.5191e-03, -1.4459e-01, -3.5766e-03, -6.3120e-02, -1.3753e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2058], requires_grad=True)\n",
      "bias grad:  tensor([-0.3932])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6190]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1899]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1042,  -322.8744,   -11.4350,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2019], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5000]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1042,  -322.8744,   -11.4350,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.3452e-03,  3.8546e-05,  3.5043e-06,  6.2773e-04,  8.4885e-04,\n",
      "         -3.1132e-03, -5.0934e-02,  4.5587e-04,  2.5583e-02, -1.0102e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2019], requires_grad=True)\n",
      "bias grad:  tensor([0.1387])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5000]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3631]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1037,  -322.8744,   -11.4353,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2033], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5363]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1037,  -322.8744,   -11.4353,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.1190e-03, -6.5047e-05, -7.5061e-05, -8.4606e-04, -1.5331e-04,\n",
      "         -2.4195e-03, -7.6165e-02, -1.9791e-03, -4.1448e-02, -3.7073e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2033], requires_grad=True)\n",
      "bias grad:  tensor([-0.2605])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5363]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9444]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1029,  -322.8743,   -11.4348,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2007], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4419]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1029,  -322.8743,   -11.4348,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.5566e-05, -2.0209e-04, -5.8117e-05, -4.7893e-04,  5.0373e-05,\n",
      "         -4.1014e-03, -8.8974e-02, -2.0237e-03, -2.9249e-02, -1.1565e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2007], requires_grad=True)\n",
      "bias grad:  tensor([-0.1833])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4419]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8272]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1020,  -322.8743,   -11.4346,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1988], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3592]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1020,  -322.8743,   -11.4346,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0060, 0.0000, 0.0002, 0.0028, 0.0004, 0.0015, 0.0920, 0.0045, 0.1371,\n",
      "         0.0026]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1988], requires_grad=True)\n",
      "bias grad:  tensor([0.7885])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3592]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.3256]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1030,  -322.8743,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2067], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7917]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1030,  -322.8743,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.3710e-03,  1.9774e-05, -9.1435e-05, -1.4464e-03, -1.0159e-03,\n",
      "         -1.1260e-03, -6.6089e-02, -3.3846e-03, -7.5452e-02, -7.7049e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2067], requires_grad=True)\n",
      "bias grad:  tensor([-0.4383])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7917]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4990]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1023,  -322.8743,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2023], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7418]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1023,  -322.8743,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8107e-03,  2.9406e-05,  5.1259e-05,  5.6832e-04,  2.2054e-04,\n",
      "          2.2624e-03,  5.7979e-02,  1.8116e-03,  3.1416e-02,  1.0380e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2023], requires_grad=True)\n",
      "bias grad:  tensor([0.1997])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7418]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1250]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1029,  -322.8743,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2043], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7543]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1029,  -322.8743,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7179e-03, 0.0000e+00, 6.3895e-05, 8.5728e-04, 6.0889e-04, 3.6823e-04,\n",
      "         4.4508e-02, 2.3760e-03, 5.3077e-02, 1.1751e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2043], requires_grad=True)\n",
      "bias grad:  tensor([0.3076])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7543]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0547]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1033,  -322.8744,   -11.4360,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2074], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7489]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1033,  -322.8744,   -11.4360,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.3150e-03,  0.0000e+00, -2.6897e-05, -5.8869e-04, -4.6429e-04,\n",
      "          2.1509e-05, -7.4849e-03, -1.0807e-03, -2.7121e-02,  4.9112e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2074], requires_grad=True)\n",
      "bias grad:  tensor([-0.1547])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7489]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5274]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1032,  -322.8744,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2059], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6961]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1032,  -322.8744,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0541e-04,  5.5580e-05,  1.7955e-05,  1.0851e-04, -3.6881e-04,\n",
      "          7.6148e-04,  2.4101e-02,  5.0739e-04,  9.8695e-03,  3.7521e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2059], requires_grad=True)\n",
      "bias grad:  tensor([0.0570])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6961]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2079]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1035,  -322.8744,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2064], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7169]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1035,  -322.8744,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.9039e-04, -1.0225e-04, -8.4040e-05, -1.0229e-03, -1.6291e-04,\n",
      "         -2.2123e-03, -6.8220e-02, -2.4601e-03, -5.3720e-02, -5.6608e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2064], requires_grad=True)\n",
      "bias grad:  tensor([-0.3073])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7169]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7458]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1028,  -322.8743,   -11.4353,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2034], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6423]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1028,  -322.8743,   -11.4353,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5926e-03,  0.0000e+00,  4.6033e-05,  4.8475e-04,  2.1574e-04,\n",
      "          5.9872e-04,  2.6712e-02,  1.6665e-03,  3.1239e-02,  1.0397e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2034], requires_grad=True)\n",
      "bias grad:  tensor([0.1856])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6423]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0213]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1031,  -322.8744,   -11.4356,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2052], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6445]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1031,  -322.8744,   -11.4356,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.3267e-04,  1.1110e-05, -5.7177e-06, -2.0971e-04,  1.0158e-05,\n",
      "          1.2911e-03,  1.8420e-02,  7.4442e-05, -8.4790e-03,  5.4728e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2052], requires_grad=True)\n",
      "bias grad:  tensor([-0.0426])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6445]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3819]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1033,  -322.8744,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2048], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6063]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1033,  -322.8744,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[8.7916e-04, 3.4148e-05, 2.8946e-05, 2.5956e-04, 1.3891e-04, 1.9420e-03,\n",
      "         4.8633e-02, 1.0670e-03, 1.5761e-02, 7.6951e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2048], requires_grad=True)\n",
      "bias grad:  tensor([0.0962])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6063]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0567]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1037,  -322.8744,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2057], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6120]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1037,  -322.8744,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4635e-04, 2.9147e-05, 1.0738e-04, 1.0974e-03, 4.3482e-04, 1.6603e-03,\n",
      "         7.2036e-02, 2.9683e-03, 6.1009e-02, 1.7513e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2057], requires_grad=True)\n",
      "bias grad:  tensor([0.3855])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6120]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2184]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1045,  -322.8744,   -11.4363,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2096], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6338]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1045,  -322.8744,   -11.4363,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7832e-03, 0.0000e+00, 8.2221e-05, 1.0118e-03, 8.0105e-04, 1.1222e-03,\n",
      "         5.6783e-02, 2.8468e-03, 6.4087e-02, 1.9686e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2096], requires_grad=True)\n",
      "bias grad:  tensor([0.3664])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6338]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1980]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1050,  -322.8744,   -11.4369,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2133], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6536]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1050,  -322.8744,   -11.4369,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.0112e-03,  0.0000e+00,  1.2131e-05,  3.9969e-05,  1.1759e-04,\n",
      "          3.4716e-04,  1.6447e-02,  7.8615e-04,  8.7315e-03, -3.6401e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2133], requires_grad=True)\n",
      "bias grad:  tensor([0.0503])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6536]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3310]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1052,  -322.8744,   -11.4370,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2138], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6205]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1052,  -322.8744,   -11.4370,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0015, 0.0003, 0.0003, 0.0033, 0.0009, 0.0079, 0.2349, 0.0076, 0.1472,\n",
      "         0.0025]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2138], requires_grad=True)\n",
      "bias grad:  tensor([0.9076])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6205]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.7210]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1075,  -322.8745,   -11.4385,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2228], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7926]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1075,  -322.8745,   -11.4385,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1399e-03,  0.0000e+00, -1.0304e-05, -3.3972e-04, -1.2305e-04,\n",
      "          2.8144e-04,  1.1653e-04, -6.3114e-05, -1.1036e-02, -1.1829e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2228], requires_grad=True)\n",
      "bias grad:  tensor([-0.0650])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7926]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3797]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1075,  -322.8745,   -11.4384,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2222], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7546]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1075,  -322.8745,   -11.4384,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.1176e-04,  2.1133e-05,  5.8521e-05,  7.2025e-04,  4.0586e-04,\n",
      "          6.9585e-04,  3.8035e-02,  1.9242e-03,  4.0856e-02,  1.1515e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2222], requires_grad=True)\n",
      "bias grad:  tensor([0.2513])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7546]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1069]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1079,  -322.8745,   -11.4388,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2247], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7653]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1079,  -322.8745,   -11.4388,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0225e-03, -3.8171e-05,  1.7267e-05,  1.8622e-04,  1.0026e-04,\n",
      "          4.3215e-04,  1.5335e-02,  1.1313e-03,  1.9329e-02,  1.3297e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2247], requires_grad=True)\n",
      "bias grad:  tensor([0.1070])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7653]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6201]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1081,  -322.8745,   -11.4390,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2258], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7033]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1081,  -322.8745,   -11.4390,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6509e-04,  4.6708e-06,  3.9054e-05,  2.2819e-04, -2.0666e-05,\n",
      "          1.9535e-03,  4.3071e-02,  1.0169e-03,  1.9639e-02,  8.4932e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2258], requires_grad=True)\n",
      "bias grad:  tensor([0.1104])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7033]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0349]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1085,  -322.8745,   -11.4392,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2269], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6998]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1085,  -322.8745,   -11.4392,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.9665e-03, -3.6422e-05, -6.2070e-05, -1.0720e-03, -7.4701e-04,\n",
      "         -5.5737e-04, -4.2701e-02, -1.9439e-03, -5.0347e-02, -2.9113e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2269], requires_grad=True)\n",
      "bias grad:  tensor([-0.2918])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6998]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7593]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1081,  -322.8745,   -11.4387,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2240], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6239]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1081,  -322.8745,   -11.4387,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.2532e-04,  0.0000e+00, -3.0510e-05, -4.7764e-04, -1.6224e-04,\n",
      "         -1.6329e-04, -1.0672e-02, -1.4682e-03, -3.0070e-02, -8.0999e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2240], requires_grad=True)\n",
      "bias grad:  tensor([-0.1666])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6239]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1880]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1080,  -322.8745,   -11.4384,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2223], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6427]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1080,  -322.8745,   -11.4384,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[4.3379e-03, 2.9753e-05, 8.7448e-05, 1.1014e-03, 8.3957e-04, 1.2094e-03,\n",
      "         6.2292e-02, 3.1743e-03, 6.7695e-02, 2.3660e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2223], requires_grad=True)\n",
      "bias grad:  tensor([0.4016])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6427]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1027]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1086,  -322.8745,   -11.4391,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2263], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6530]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1086,  -322.8745,   -11.4391,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7247e-02,  0.0000e+00, -4.1674e-05, -9.5310e-04, -1.2207e-03,\n",
      "         -6.1297e-04, -2.7844e-02, -2.0357e-03, -4.8968e-02, -5.2962e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2263], requires_grad=True)\n",
      "bias grad:  tensor([-0.2756])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6530]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1832]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1083,  -322.8745,   -11.4386,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2236], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6347]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1083,  -322.8745,   -11.4386,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.6936e-03,  1.5390e-05,  1.9671e-05,  4.6830e-05, -2.1767e-04,\n",
      "          9.5220e-04,  1.9336e-02,  5.7277e-04,  6.1084e-03,  6.2948e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2236], requires_grad=True)\n",
      "bias grad:  tensor([0.0408])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6347]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0544]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1085,  -322.8745,   -11.4386,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2240], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6292]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1085,  -322.8745,   -11.4386,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0050e-03,  0.0000e+00, -1.3769e-04, -1.0088e-03, -3.1979e-04,\n",
      "         -5.6935e-03, -1.5558e-01, -4.2172e-03, -7.8558e-02, -6.8211e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2240], requires_grad=True)\n",
      "bias grad:  tensor([-0.4811])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6292]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1171]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1070,  -322.8745,   -11.4378,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2192], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5175]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1070,  -322.8745,   -11.4378,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1110e-03,  3.4497e-05, -8.6103e-06,  4.6768e-04,  8.5809e-04,\n",
      "         -3.5773e-03, -6.5867e-02,  9.7502e-05,  1.9512e-02, -2.7845e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2192], requires_grad=True)\n",
      "bias grad:  tensor([0.0923])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5175]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1265]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1063,  -322.8745,   -11.4380,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2201], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5302]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1063,  -322.8745,   -11.4380,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.8855e-03, -7.8726e-05, -6.7519e-05, -7.1359e-04, -9.0058e-05,\n",
      "         -2.4549e-03, -7.3448e-02, -1.7090e-03, -3.4971e-02, -2.5336e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2201], requires_grad=True)\n",
      "bias grad:  tensor([-0.2221])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5302]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8395]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1056,  -322.8745,   -11.4377,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2179], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4462]], requires_grad=True)\n",
      "Iteration 13 | Score: 1.853716254234314\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8737,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6674e-03, -2.0811e-04, -1.6955e-04, -1.5415e-03, -5.4062e-04,\n",
      "         -6.4602e-03, -1.7638e-01, -5.5408e-03, -1.0016e-01, -1.8943e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1246], requires_grad=True)\n",
      "bias grad:  tensor([-0.6115])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7845]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9975]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0887,  -322.8737,   -11.4210,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1185], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6847]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0887,  -322.8737,   -11.4210,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.9548e-05,  0.0000e+00,  7.5174e-05,  6.2971e-04, -1.2793e-04,\n",
      "          2.8810e-04,  3.5340e-02,  1.6657e-03,  4.5470e-02,  1.4964e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1185], requires_grad=True)\n",
      "bias grad:  tensor([0.2602])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6847]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0212]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0890,  -322.8737,   -11.4215,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1211], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6826]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0890,  -322.8737,   -11.4215,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.7952e-03,  2.5179e-05, -7.0184e-05, -1.0672e-03, -7.5492e-04,\n",
      "         -1.0260e-03, -5.4744e-02, -2.5483e-03, -5.5515e-02, -5.6717e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1211], requires_grad=True)\n",
      "bias grad:  tensor([-0.3249])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6826]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2999]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0885,  -322.8737,   -11.4209,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1179], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6526]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0885,  -322.8737,   -11.4209,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.3506e-04,  3.6938e-05,  8.2276e-05,  9.7487e-04,  4.6809e-04,\n",
      "          2.6933e-03,  7.9881e-02,  2.9219e-03,  5.2771e-02,  1.6246e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1179], requires_grad=True)\n",
      "bias grad:  tensor([0.3361])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6526]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2598]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0893,  -322.8737,   -11.4214,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1212], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6786]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0893,  -322.8737,   -11.4214,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0041, 0.0000, 0.0001, 0.0014, 0.0009, 0.0007, 0.0971, 0.0041, 0.0892,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1212], requires_grad=True)\n",
      "bias grad:  tensor([0.5141])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6786]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1129]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0902,  -322.8737,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1264], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6673]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0902,  -322.8737,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.3241e-04,  0.0000e+00,  3.8768e-06, -9.1214e-05, -1.1178e-04,\n",
      "          2.7994e-04,  8.8705e-03,  7.6361e-05, -1.8951e-04,  3.8235e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1264], requires_grad=True)\n",
      "bias grad:  tensor([-0.0011])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6673]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda grad:  tensor([[0.2038]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0903,  -322.8737,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1263], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6469]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0903,  -322.8737,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[5.9026e-04, 8.5554e-05, 4.7973e-05, 5.5935e-04, 4.3851e-05, 7.6024e-04,\n",
      "         3.4705e-02, 1.7496e-03, 3.5955e-02, 9.5706e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1263], requires_grad=True)\n",
      "bias grad:  tensor([0.2064])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6469]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2252]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0907,  -322.8737,   -11.4227,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1284], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6695]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0907,  -322.8737,   -11.4227,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 9.1595e-04, -7.4297e-05, -5.1771e-05, -6.0978e-04, -2.9033e-05,\n",
      "         -1.8877e-03, -5.0714e-02, -1.6436e-03, -3.2871e-02, -2.3668e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1284], requires_grad=True)\n",
      "bias grad:  tensor([-0.1865])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6695]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4387]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0902,  -322.8737,   -11.4224,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1265], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6256]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0902,  -322.8737,   -11.4224,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.5129e-05,  0.0000e+00,  6.2876e-05,  7.8395e-04,  5.0361e-04,\n",
      "          6.2138e-04,  3.7535e-02,  2.4309e-03,  4.8348e-02,  1.1264e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1265], requires_grad=True)\n",
      "bias grad:  tensor([0.2810])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6256]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0252]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0905,  -322.8737,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1294], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6281]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0905,  -322.8737,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.2603e-04,  5.0046e-06,  4.9705e-06, -5.8290e-05,  8.1557e-05,\n",
      "          1.3337e-03,  2.5355e-02,  3.6615e-04, -1.6781e-03,  5.0402e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1294], requires_grad=True)\n",
      "bias grad:  tensor([0.0028])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6281]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2538]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0908,  -322.8737,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1294], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6027]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0908,  -322.8737,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[8.2137e-04, 3.1739e-05, 3.5479e-05, 3.5570e-04, 1.4758e-04, 2.0892e-03,\n",
      "         5.3339e-02, 1.1882e-03, 2.0732e-02, 7.6918e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1294], requires_grad=True)\n",
      "bias grad:  tensor([0.1223])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6027]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1355]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0913,  -322.8737,   -11.4230,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1306], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6163]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0913,  -322.8737,   -11.4230,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6506e-04, 3.9234e-05, 1.4444e-04, 1.5119e-03, 6.5424e-04, 2.0492e-03,\n",
      "         9.3443e-02, 4.1276e-03, 8.3875e-02, 2.3674e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1306], requires_grad=True)\n",
      "bias grad:  tensor([0.5338])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6163]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2769]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0923,  -322.8738,   -11.4239,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1359], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6440]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0923,  -322.8738,   -11.4239,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[4.1150e-03, 0.0000e+00, 9.0494e-05, 1.1185e-03, 8.7880e-04, 1.2960e-03,\n",
      "         6.4524e-02, 3.1963e-03, 7.1531e-02, 2.1363e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1359], requires_grad=True)\n",
      "bias grad:  tensor([0.4083])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6440]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2111]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0929,  -322.8738,   -11.4246,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1400], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6651]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0929,  -322.8738,   -11.4246,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.8382e-03,  0.0000e+00,  1.3780e-05,  8.6631e-05,  1.3402e-04,\n",
      "          4.7088e-04,  1.9707e-02,  7.9035e-04,  1.0418e-02, -1.0435e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1400], requires_grad=True)\n",
      "bias grad:  tensor([0.0586])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6651]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2412]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0931,  -322.8738,   -11.4247,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1406], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6409]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0931,  -322.8738,   -11.4247,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0014, 0.0003, 0.0003, 0.0032, 0.0008, 0.0078, 0.2306, 0.0073, 0.1416,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1406], requires_grad=True)\n",
      "bias grad:  tensor([0.8749])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6409]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.7837]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0954,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1494], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8193]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0954,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6199e-03,  0.0000e+00,  4.7036e-08, -2.2653e-04, -1.2094e-04,\n",
      "          4.7024e-04,  6.5009e-03,  2.3687e-04, -4.3074e-03,  8.5215e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1494], requires_grad=True)\n",
      "bias grad:  tensor([-0.0254])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8193]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3256]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0955,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1491], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7868]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0955,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5655e-05,  3.6880e-05,  6.9317e-05,  8.7048e-04,  5.3633e-04,\n",
      "          8.0182e-04,  4.3259e-02,  2.3548e-03,  5.0420e-02,  1.4223e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1491], requires_grad=True)\n",
      "bias grad:  tensor([0.3046])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7868]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0991]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0959,  -322.8739,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1522], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7967]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0959,  -322.8739,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6928e-03, -2.8520e-05,  3.4569e-05,  4.0558e-04,  1.3541e-04,\n",
      "          6.1399e-04,  2.5579e-02,  1.7033e-03,  3.1822e-02,  1.5314e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1522], requires_grad=True)\n",
      "bias grad:  tensor([0.1784])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7967]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5578]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8739,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1539], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7409]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8739,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4761e-04, 4.1947e-06, 5.1147e-05, 3.5849e-04, 7.0349e-05, 2.1520e-03,\n",
      "         5.1286e-02, 1.4010e-03, 2.7971e-02, 9.9003e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1539], requires_grad=True)\n",
      "bias grad:  tensor([0.1575])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7409]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1249]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0967,  -322.8739,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1555], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7284]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0967,  -322.8739,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.0671e-03, -3.7452e-05, -6.7605e-05, -1.1227e-03, -7.1676e-04,\n",
      "         -5.7106e-04, -4.4931e-02, -2.0007e-03, -5.2858e-02, -3.1042e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1555], requires_grad=True)\n",
      "bias grad:  tensor([-0.3086])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7284]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8396]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8739,   -11.4266,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1524], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6444]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8739,   -11.4266,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.1596e-04,  0.0000e+00,  4.4130e-06, -4.7438e-05,  1.1602e-05,\n",
      "          8.4593e-05,  6.1902e-03, -3.3478e-04, -4.3444e-03, -2.9862e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1524], requires_grad=True)\n",
      "bias grad:  tensor([-0.0204])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6444]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2234]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8739,   -11.4266,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1522], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6668]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8739,   -11.4266,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.4169e-03, 2.9535e-05, 9.3920e-05, 1.1565e-03, 8.5400e-04, 1.3667e-03,\n",
      "         6.7058e-02, 3.3360e-03, 7.1103e-02, 2.5088e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1522], requires_grad=True)\n",
      "bias grad:  tensor([0.4229])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6668]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0528]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8739,   -11.4273,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1565], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6720]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8739,   -11.4273,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6548e-02,  0.0000e+00, -2.5586e-05, -7.3791e-04, -9.9066e-04,\n",
      "         -4.4835e-04, -2.0454e-02, -1.3884e-03, -3.6089e-02, -3.4936e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1565], requires_grad=True)\n",
      "bias grad:  tensor([-0.2016])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6720]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2481]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8739,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1544], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6472]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8739,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.5685e-03,  1.3859e-05,  3.4483e-05,  2.6455e-04, -6.3624e-05,\n",
      "          1.1451e-03,  2.9207e-02,  1.1018e-03,  1.8243e-02,  8.0128e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1544], requires_grad=True)\n",
      "bias grad:  tensor([0.1111])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6472]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0003]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0971,  -322.8739,   -11.4271,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1555], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6473]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0971,  -322.8739,   -11.4271,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.3580e-04,  0.0000e+00, -1.1947e-04, -7.6548e-04, -1.1296e-04,\n",
      "         -5.3941e-03, -1.4169e-01, -3.4684e-03, -6.2800e-02, -3.7347e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1555], requires_grad=True)\n",
      "bias grad:  tensor([-0.3902])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6473]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1307]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0956,  -322.8739,   -11.4265,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1516], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5342]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0956,  -322.8739,   -11.4265,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.2291e-03,  2.7353e-05, -2.3772e-05,  2.0026e-04,  6.7590e-04,\n",
      "         -3.5900e-03, -6.8909e-02, -4.5711e-04,  5.3028e-03, -3.6922e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1516], requires_grad=True)\n",
      "bias grad:  tensor([0.0153])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5342]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1343]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0950,  -322.8739,   -11.4265,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1518], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5208]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0950,  -322.8739,   -11.4265,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.4447e-03, -6.2162e-05, -3.2197e-05, -3.0929e-04,  1.6910e-04,\n",
      "         -1.4918e-03, -4.0738e-02, -4.9972e-04, -1.1387e-02,  3.0730e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1518], requires_grad=True)\n",
      "bias grad:  tensor([-0.0826])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5208]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7188]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0945,  -322.8739,   -11.4264,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1510], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4489]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0945,  -322.8739,   -11.4264,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.2801e-04, -1.9316e-04, -7.3802e-05, -5.9447e-04, -2.3143e-05,\n",
      "         -4.0201e-03, -9.4361e-02, -2.2841e-03, -3.6287e-02, -5.0251e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1510], requires_grad=True)\n",
      "bias grad:  tensor([-0.2314])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4489]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7203]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0936,  -322.8739,   -11.4261,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1487], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3769]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0936,  -322.8739,   -11.4261,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0058, 0.0000, 0.0003, 0.0031, 0.0008, 0.0018, 0.1204, 0.0058, 0.1623,\n",
      "         0.0032]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1487], requires_grad=True)\n",
      "bias grad:  tensor([0.9312])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3769]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.7949]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0948,  -322.8739,   -11.4277,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1580], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7564]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0948,  -322.8739,   -11.4277,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.7593e-03,  2.6228e-05, -8.5148e-05, -1.3588e-03, -1.0020e-03,\n",
      "         -9.5404e-04, -6.2199e-02, -3.2072e-03, -7.1371e-02, -6.5551e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1580], requires_grad=True)\n",
      "bias grad:  tensor([-0.4116])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7564]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4280]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0942,  -322.8739,   -11.4270,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1539], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7135]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0942,  -322.8739,   -11.4270,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6471e-03,  3.3782e-05,  6.0660e-05,  6.8898e-04,  2.8777e-04,\n",
      "          2.5121e-03,  6.6876e-02,  2.1428e-03,  3.7095e-02,  1.2187e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1539], requires_grad=True)\n",
      "bias grad:  tensor([0.2395])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7135]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1766]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0949,  -322.8739,   -11.4273,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1563], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7312]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0949,  -322.8739,   -11.4273,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3022e-03, 0.0000e+00, 9.5818e-05, 1.1738e-03, 6.7153e-04, 4.9010e-04,\n",
      "         8.4552e-02, 3.3560e-03, 7.3601e-02, 1.8087e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1563], requires_grad=True)\n",
      "bias grad:  tensor([0.4246])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7312]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0966]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0957,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1605], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7215]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0957,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7846e-03,  0.0000e+00, -7.5300e-06, -3.1048e-04, -2.8923e-04,\n",
      "          1.8879e-04,  3.6264e-03, -3.8668e-04, -1.1065e-02,  3.3470e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1605], requires_grad=True)\n",
      "bias grad:  tensor([-0.0631])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7215]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3935]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0957,  -322.8740,   -11.4280,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1599], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6822]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0957,  -322.8740,   -11.4280,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1674e-04,  5.7859e-05,  2.1606e-05,  1.8103e-04, -2.6167e-04,\n",
      "          5.0230e-04,  2.0684e-02,  6.7337e-04,  1.3960e-02,  4.9763e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1599], requires_grad=True)\n",
      "bias grad:  tensor([0.0809])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6822]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1226]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0959,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1607], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6945]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0959,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.8057e-04, -1.1528e-04, -7.6530e-05, -9.4015e-04, -1.3396e-04,\n",
      "         -2.0492e-03, -6.3985e-02, -2.2933e-03, -4.9537e-02, -5.0905e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1607], requires_grad=True)\n",
      "bias grad:  tensor([-0.2824])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6945]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7401]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0953,  -322.8739,   -11.4276,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1579], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6204]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0953,  -322.8739,   -11.4276,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.9379e-04,  0.0000e+00,  6.8683e-05,  7.5775e-04,  3.6813e-04,\n",
      "          9.2395e-04,  4.1031e-02,  2.4941e-03,  4.7764e-02,  1.2779e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1579], requires_grad=True)\n",
      "bias grad:  tensor([0.2827])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6204]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0889]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0957,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1607], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6293]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0957,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6364e-04,  2.1606e-05,  3.2672e-06, -9.2703e-05,  2.5203e-05,\n",
      "          1.3947e-03,  2.5555e-02,  2.9545e-04, -3.1617e-03,  6.4943e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1607], requires_grad=True)\n",
      "bias grad:  tensor([-0.0085])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6293]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3379]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0960,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1606], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5955]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0960,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6937e-03, 3.3956e-05, 5.1201e-05, 5.6531e-04, 3.7477e-04, 2.2473e-03,\n",
      "         6.4102e-02, 1.8891e-03, 3.3983e-02, 1.1764e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1606], requires_grad=True)\n",
      "bias grad:  tensor([0.2015])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5955]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0242]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0966,  -322.8740,   -11.4284,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1626], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5980]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0966,  -322.8740,   -11.4284,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0744e-04, 3.4297e-05, 1.1033e-04, 1.1388e-03, 4.4420e-04, 1.7073e-03,\n",
      "         7.3104e-02, 3.0060e-03, 6.2781e-02, 1.7444e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1626], requires_grad=True)\n",
      "bias grad:  tensor([0.3964])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5980]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3343]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0973,  -322.8740,   -11.4290,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1666], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6314]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0973,  -322.8740,   -11.4290,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5627e-03, 0.0000e+00, 8.7677e-05, 1.0894e-03, 8.4109e-04, 1.0297e-03,\n",
      "         5.6860e-02, 3.0756e-03, 6.9040e-02, 2.0094e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1666], requires_grad=True)\n",
      "bias grad:  tensor([0.3941])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6314]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2036]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0979,  -322.8741,   -11.4297,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1705], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6517]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0979,  -322.8741,   -11.4297,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[1.8515e-03, 0.0000e+00, 3.5514e-05, 3.5178e-04, 2.9521e-04, 6.1229e-04,\n",
      "         2.8275e-02, 1.5449e-03, 2.5493e-02, 5.2075e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1705], requires_grad=True)\n",
      "bias grad:  tensor([0.1484])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6517]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2216]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0982,  -322.8741,   -11.4300,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1720], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6296]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0982,  -322.8741,   -11.4300,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0019, 0.0003, 0.0003, 0.0032, 0.0008, 0.0078, 0.2324, 0.0074, 0.1425,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1720], requires_grad=True)\n",
      "bias grad:  tensor([0.8809])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6296]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.8197]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1005,  -322.8741,   -11.4314,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1808], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8115]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1005,  -322.8741,   -11.4314,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0592e-03,  0.0000e+00, -7.4547e-06, -3.0022e-04, -1.1783e-04,\n",
      "          3.2533e-04,  1.2367e-03, -2.2751e-05, -9.1457e-03, -8.7130e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1808], requires_grad=True)\n",
      "bias grad:  tensor([-0.0535])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8115]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3286]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1005,  -322.8741,   -11.4313,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1803], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7787]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1005,  -322.8741,   -11.4313,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3522e-04,  2.9367e-05,  6.1836e-05,  7.9743e-04,  5.7810e-04,\n",
      "          7.5527e-04,  4.0390e-02,  2.1261e-03,  4.6710e-02,  1.3939e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1803], requires_grad=True)\n",
      "bias grad:  tensor([0.2842])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7787]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0213]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1009,  -322.8742,   -11.4318,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1831], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7808]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1009,  -322.8742,   -11.4318,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1497e-03, -4.8206e-05,  9.4371e-06,  8.3799e-05,  5.6842e-05,\n",
      "          5.1288e-04,  1.2628e-02,  9.0242e-04,  1.3451e-02,  1.2112e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1831], requires_grad=True)\n",
      "bias grad:  tensor([0.0736])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7808]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6704]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1011,  -322.8742,   -11.4319,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1838], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7138]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1011,  -322.8742,   -11.4319,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[1.5978e-04, 3.4745e-06, 4.3204e-05, 2.5640e-04, 3.9165e-05, 1.9858e-03,\n",
      "         4.6296e-02, 1.1261e-03, 2.2218e-02, 8.7375e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1838], requires_grad=True)\n",
      "bias grad:  tensor([0.1246])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7138]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1098]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1015,  -322.8742,   -11.4321,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1851], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7028]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1015,  -322.8742,   -11.4321,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7043e-03, -2.7437e-05, -4.6890e-05, -8.1119e-04, -5.2201e-04,\n",
      "         -4.0131e-04, -3.2224e-02, -1.3695e-03, -3.6441e-02, -1.1142e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1851], requires_grad=True)\n",
      "bias grad:  tensor([-0.2126])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7028]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6475]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1012,  -322.8742,   -11.4318,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1830], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6380]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1012,  -322.8742,   -11.4318,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 9.8810e-04,  0.0000e+00, -5.2046e-06, -1.2134e-04, -1.4793e-05,\n",
      "          2.8487e-05,  2.7374e-03, -6.4204e-04, -1.0548e-02, -4.5508e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1830], requires_grad=True)\n",
      "bias grad:  tensor([-0.0557])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6380]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3484]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1012,  -322.8742,   -11.4317,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1824], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6729]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1012,  -322.8742,   -11.4317,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[3.9837e-03, 2.3478e-05, 8.8325e-05, 1.0955e-03, 8.4448e-04, 1.1927e-03,\n",
      "         6.2749e-02, 3.1929e-03, 6.8128e-02, 2.4302e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1824], requires_grad=True)\n",
      "bias grad:  tensor([0.4042])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6729]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0269]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1019,  -322.8742,   -11.4323,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1865], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6756]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1019,  -322.8742,   -11.4323,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1547e-02,  0.0000e+00, -8.9332e-05, -1.6478e-03, -1.9924e-03,\n",
      "         -1.1276e-03, -5.0997e-02, -4.0050e-03, -8.9379e-02, -1.0727e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1865], requires_grad=True)\n",
      "bias grad:  tensor([-0.5071])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6756]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2680]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1013,  -322.8742,   -11.4315,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1814], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6488]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1013,  -322.8742,   -11.4315,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.3920e-03,  1.6577e-05,  3.6921e-05,  2.3552e-04, -9.2465e-05,\n",
      "          9.9189e-04,  2.6145e-02,  1.1683e-03,  1.8491e-02,  9.6604e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1814], requires_grad=True)\n",
      "bias grad:  tensor([0.1126])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6488]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1103]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1016,  -322.8742,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1825], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6377]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1016,  -322.8742,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.6730e-04,  0.0000e+00, -9.6944e-05, -5.3012e-04,  7.6896e-06,\n",
      "         -5.1284e-03, -1.2972e-01, -2.7247e-03, -4.6418e-02,  1.7414e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1825], requires_grad=True)\n",
      "bias grad:  tensor([-0.2956])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6377]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.2143]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1003,  -322.8741,   -11.4312,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1796], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5163]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1003,  -322.8741,   -11.4312,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.5922e-03,  2.7463e-05, -1.8891e-05,  3.3567e-04,  6.8674e-04,\n",
      "         -3.3346e-03, -6.7428e-02, -2.6464e-04,  1.0333e-02, -6.3211e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1796], requires_grad=True)\n",
      "bias grad:  tensor([0.0402])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5163]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1986]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0996,  -322.8741,   -11.4313,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1800], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5362]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0996,  -322.8741,   -11.4313,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.4992e-03, -6.7570e-05, -5.4348e-05, -5.9307e-04, -8.4238e-05,\n",
      "         -2.0355e-03, -6.2475e-02, -1.2914e-03, -2.7623e-02, -7.7223e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1800], requires_grad=True)\n",
      "bias grad:  tensor([-0.1794])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5362]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8372]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0990,  -322.8741,   -11.4310,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1782], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4525]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0990,  -322.8741,   -11.4310,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.8842e-04, -1.9819e-04, -9.2220e-05, -8.5692e-04, -2.1980e-04,\n",
      "         -4.3311e-03, -1.0940e-01, -2.9619e-03, -5.0756e-02, -6.6377e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1782], requires_grad=True)\n",
      "bias grad:  tensor([-0.3175])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4525]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8380]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0979,  -322.8741,   -11.4305,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1750], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3687]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0979,  -322.8741,   -11.4305,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0061, 0.0000, 0.0003, 0.0035, 0.0008, 0.0022, 0.1408, 0.0068, 0.1857,\n",
      "         0.0040]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1750], requires_grad=True)\n",
      "bias grad:  tensor([1.0644])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3687]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.0664]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0993,  -322.8742,   -11.4323,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1856], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7753]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0993,  -322.8742,   -11.4323,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2598e-03,  1.2619e-05, -9.4693e-05, -1.4352e-03, -9.8707e-04,\n",
      "         -1.3188e-03, -7.1622e-02, -3.4879e-03, -7.6159e-02, -9.5490e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1856], requires_grad=True)\n",
      "bias grad:  tensor([-0.4459])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7753]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3969]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0986,  -322.8741,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1812], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7356]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0986,  -322.8741,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3946e-03,  3.8625e-05,  5.5114e-05,  5.8416e-04,  1.7682e-04,\n",
      "          2.1584e-03,  5.7599e-02,  1.8337e-03,  3.1959e-02,  1.2166e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1812], requires_grad=True)\n",
      "bias grad:  tensor([0.2064])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7356]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1472]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0992,  -322.8742,   -11.4319,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1832], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7503]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0992,  -322.8742,   -11.4319,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5933e-03, 0.0000e+00, 4.8320e-05, 6.8826e-04, 5.0224e-04, 1.1575e-04,\n",
      "         3.3926e-02, 1.7709e-03, 4.2083e-02, 8.7387e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1832], requires_grad=True)\n",
      "bias grad:  tensor([0.2448])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7503]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0060]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0995,  -322.8742,   -11.4323,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1857], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7509]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0995,  -322.8742,   -11.4323,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7711e-03,  0.0000e+00, -2.7642e-05, -6.0669e-04, -4.8690e-04,\n",
      "          4.4622e-05, -7.8273e-03, -1.1344e-03, -2.8007e-02,  8.6967e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1857], requires_grad=True)\n",
      "bias grad:  tensor([-0.1598])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7509]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5109]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0994,  -322.8742,   -11.4320,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1841], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6998]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0994,  -322.8742,   -11.4320,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.1887e-04,  5.8383e-05,  2.8932e-05,  2.5357e-04, -2.7379e-04,\n",
      "          6.6437e-04,  2.5949e-02,  9.0453e-04,  1.8519e-02,  5.8121e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1841], requires_grad=True)\n",
      "bias grad:  tensor([0.1077])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6998]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1981]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0997,  -322.8742,   -11.4322,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1852], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7196]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0997,  -322.8742,   -11.4322,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.4268e-04, -1.2849e-04, -8.8171e-05, -1.0880e-03, -1.9565e-04,\n",
      "         -2.5013e-03, -7.6005e-02, -2.6956e-03, -5.7210e-02, -4.8447e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1852], requires_grad=True)\n",
      "bias grad:  tensor([-0.3272])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7196]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8632]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0989,  -322.8742,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1819], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6333]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0989,  -322.8742,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.1238e-04,  0.0000e+00,  7.6332e-05,  8.3988e-04,  4.8286e-04,\n",
      "          9.3845e-04,  4.4224e-02,  2.7421e-03,  5.2475e-02,  1.5081e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1819], requires_grad=True)\n",
      "bias grad:  tensor([0.3128])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6333]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0316]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0994,  -322.8742,   -11.4322,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1850], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6302]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0994,  -322.8742,   -11.4322,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.0123e-04,  1.3844e-05, -1.2955e-05, -2.7041e-04, -3.4316e-05,\n",
      "          8.6567e-04,  8.8553e-03, -2.0491e-04, -1.2661e-02,  2.9372e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1850], requires_grad=True)\n",
      "bias grad:  tensor([-0.0698])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6302]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3803]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0995,  -322.8742,   -11.4321,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1843], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5921]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0995,  -322.8742,   -11.4321,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[9.4502e-04, 2.7714e-05, 3.4658e-05, 3.5466e-04, 1.6692e-04, 1.9030e-03,\n",
      "         4.9715e-02, 1.1736e-03, 2.0841e-02, 8.2733e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1843], requires_grad=True)\n",
      "bias grad:  tensor([0.1239])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5921]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1441]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1000,  -322.8742,   -11.4323,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1856], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6065]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1000,  -322.8742,   -11.4323,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4838e-04, 2.8118e-05, 1.1780e-04, 1.2417e-03, 5.3426e-04, 1.8232e-03,\n",
      "         7.8767e-02, 3.3971e-03, 6.9438e-02, 1.9129e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1856], requires_grad=True)\n",
      "bias grad:  tensor([0.4364])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6065]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2708]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1008,  -322.8742,   -11.4330,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1899], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6336]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1008,  -322.8742,   -11.4330,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[4.1103e-03, 0.0000e+00, 5.9028e-05, 7.2835e-04, 6.6262e-04, 1.1308e-03,\n",
      "         5.0316e-02, 2.1492e-03, 4.8088e-02, 1.3138e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1899], requires_grad=True)\n",
      "bias grad:  tensor([0.2729])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6336]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0484]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1013,  -322.8743,   -11.4334,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1927], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6385]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1013,  -322.8743,   -11.4334,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[5.5708e-03, 0.0000e+00, 6.4693e-05, 7.0272e-04, 8.4713e-04, 9.6844e-04,\n",
      "         5.1679e-02, 2.7934e-03, 4.9270e-02, 1.2263e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1927], requires_grad=True)\n",
      "bias grad:  tensor([0.2878])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6385]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3941]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1018,  -322.8743,   -11.4339,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1955], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5990]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1018,  -322.8743,   -11.4339,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0006, 0.0003, 0.0003, 0.0031, 0.0007, 0.0080, 0.2309, 0.0071, 0.1340,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1955], requires_grad=True)\n",
      "bias grad:  tensor([0.8352])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5990]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.9702]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1041,  -322.8744,   -11.4353,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2039], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7961]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1041,  -322.8744,   -11.4353,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7288e-03,  0.0000e+00, -5.2283e-06, -2.2130e-04, -1.0992e-05,\n",
      "          1.9607e-04,  2.5501e-03,  2.2349e-04, -4.6181e-03, -4.7111e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2039], requires_grad=True)\n",
      "bias grad:  tensor([-0.0291])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7961]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3941]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1041,  -322.8744,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2036], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7567]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1041,  -322.8744,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.4589e-04,  3.3748e-05,  5.9854e-05,  7.4798e-04,  4.9547e-04,\n",
      "          7.0014e-04,  3.5515e-02,  1.9072e-03,  4.3361e-02,  1.2796e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2036], requires_grad=True)\n",
      "bias grad:  tensor([0.2619])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7567]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0860]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1045,  -322.8744,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2062], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7653]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1045,  -322.8744,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0137e-03, -4.0503e-05,  2.2289e-05,  2.5495e-04,  1.3878e-04,\n",
      "          6.6641e-04,  2.1079e-02,  1.3241e-03,  2.3154e-02,  1.3916e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2062], requires_grad=True)\n",
      "bias grad:  tensor([0.1291])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7653]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6032]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1047,  -322.8744,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2075], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7049]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1047,  -322.8744,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1030e-04, 9.6051e-06, 4.4354e-05, 2.9476e-04, 3.5211e-05, 2.0139e-03,\n",
      "         4.6698e-02, 1.1401e-03, 2.3231e-02, 8.8867e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2075], requires_grad=True)\n",
      "bias grad:  tensor([0.1315])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7049]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0043]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1051,  -322.8744,   -11.4361,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2088], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7054]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1051,  -322.8744,   -11.4361,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.9891e-03, -3.1788e-05, -5.1142e-05, -8.8944e-04, -6.0333e-04,\n",
      "         -4.7616e-04, -3.3020e-02, -1.5275e-03, -4.0191e-02, -5.1061e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2088], requires_grad=True)\n",
      "bias grad:  tensor([-0.2343])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7054]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7247]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1048,  -322.8744,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2065], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6329]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1048,  -322.8744,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.1110e-04,  0.0000e+00, -2.1391e-05, -3.9831e-04, -1.5957e-04,\n",
      "         -8.9853e-05, -8.2516e-03, -1.1988e-03, -2.4126e-02, -6.6713e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2065], requires_grad=True)\n",
      "bias grad:  tensor([-0.1345])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6329]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1828]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1047,  -322.8744,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2051], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6512]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1047,  -322.8744,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6728e-03, 2.5387e-05, 9.0084e-05, 1.0856e-03, 7.8662e-04, 1.4198e-03,\n",
      "         6.5643e-02, 3.1945e-03, 6.7284e-02, 2.4718e-03]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias before:  Parameter containing:\n",
      "tensor([-0.2051], requires_grad=True)\n",
      "bias grad:  tensor([0.4013])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6512]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0795]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1054,  -322.8744,   -11.4362,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2091], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6591]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1054,  -322.8744,   -11.4362,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9845e-02,  0.0000e+00, -4.1034e-05, -1.0118e-03, -1.3178e-03,\n",
      "         -6.3815e-04, -2.9030e-02, -2.0710e-03, -5.1110e-02, -5.3311e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2091], requires_grad=True)\n",
      "bias grad:  tensor([-0.2870])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6591]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3430]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1051,  -322.8744,   -11.4356,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2063], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6248]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1051,  -322.8744,   -11.4356,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.3169e-03,  1.0562e-05,  9.4313e-06, -9.0218e-05, -3.2268e-04,\n",
      "          6.8953e-04,  8.6871e-03,  1.4503e-04, -2.5174e-03,  3.9191e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2063], requires_grad=True)\n",
      "bias grad:  tensor([-0.0093])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6248]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0003]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1052,  -322.8744,   -11.4356,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2062], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6248]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1052,  -322.8744,   -11.4356,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.3778e-04,  0.0000e+00, -1.1936e-04, -7.8088e-04, -1.3543e-04,\n",
      "         -5.4646e-03, -1.4321e-01, -3.5440e-03, -6.3375e-02, -2.7994e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2062], requires_grad=True)\n",
      "bias grad:  tensor([-0.3943])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6248]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1626]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1038,  -322.8743,   -11.4350,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2022], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5086]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1038,  -322.8743,   -11.4350,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1595e-03,  2.8457e-05, -2.8387e-05,  2.0010e-04,  6.5904e-04,\n",
      "         -3.6612e-03, -7.2441e-02, -5.9139e-04,  2.8387e-03, -5.6769e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2022], requires_grad=True)\n",
      "bias grad:  tensor([0.0057])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5086]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0383]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1030,  -322.8743,   -11.4350,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2023], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5124]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1030,  -322.8743,   -11.4350,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.5891e-03, -6.6486e-05, -4.9666e-05, -5.1663e-04,  5.5754e-05,\n",
      "         -1.8123e-03, -5.3417e-02, -1.1440e-03, -2.4168e-02,  3.0876e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2023], requires_grad=True)\n",
      "bias grad:  tensor([-0.1552])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5124]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8158]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1025,  -322.8743,   -11.4348,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2007], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4308]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1025,  -322.8743,   -11.4348,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3262e-05, -1.9952e-04, -6.3673e-05, -4.4643e-04,  1.0055e-04,\n",
      "         -4.0082e-03, -9.2368e-02, -1.6801e-03, -2.5193e-02, -1.6766e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2007], requires_grad=True)\n",
      "bias grad:  tensor([-0.1705])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4308]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6715]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1016,  -322.8743,   -11.4345,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1990], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3637]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1016,  -322.8743,   -11.4345,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0056, 0.0000, 0.0002, 0.0028, 0.0004, 0.0015, 0.0972, 0.0047, 0.1399,\n",
      "         0.0027]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1990], requires_grad=True)\n",
      "bias grad:  tensor([0.8046])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3637]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.0551]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1025,  -322.8744,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2071], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7692]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1025,  -322.8744,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.0446e-03,  2.4976e-05, -8.5435e-05, -1.3720e-03, -9.8595e-04,\n",
      "         -9.3787e-04, -6.2126e-02, -3.2183e-03, -7.1880e-02, -6.9434e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2071], requires_grad=True)\n",
      "bias grad:  tensor([-0.4147])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7692]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4478]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1019,  -322.8743,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2029], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7244]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1019,  -322.8743,   -11.4352,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6591e-03,  2.9201e-05,  4.2963e-05,  4.5065e-04,  1.4264e-04,\n",
      "          2.2288e-03,  5.3447e-02,  1.4852e-03,  2.3967e-02,  9.3094e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2029], requires_grad=True)\n",
      "bias grad:  tensor([0.1599])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7244]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1331]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1025,  -322.8743,   -11.4354,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2045], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7377]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1025,  -322.8743,   -11.4354,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[2.5979e-03, 0.0000e+00, 8.7216e-05, 1.0402e-03, 5.3999e-04, 3.5929e-04,\n",
      "         7.7508e-02, 3.0229e-03, 6.5752e-02, 1.7489e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2045], requires_grad=True)\n",
      "bias grad:  tensor([0.3786])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7377]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0910]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1032,  -322.8744,   -11.4361,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2083], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7286]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1032,  -322.8744,   -11.4361,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6092e-03,  0.0000e+00, -2.1591e-05, -5.0544e-04, -4.2833e-04,\n",
      "          7.3439e-05, -4.8445e-03, -9.3583e-04, -2.2752e-02,  1.6742e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2083], requires_grad=True)\n",
      "bias grad:  tensor([-0.1296])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7286]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3989]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1032,  -322.8744,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2070], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6887]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1032,  -322.8744,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.7636e-04,  6.3675e-05,  2.9795e-05,  2.6866e-04, -2.0597e-04,\n",
      "          7.8056e-04,  2.8106e-02,  9.8798e-04,  1.9810e-02,  5.8201e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2070], requires_grad=True)\n",
      "bias grad:  tensor([0.1139])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6887]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1686]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1035,  -322.8744,   -11.4361,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2082], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7056]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1035,  -322.8744,   -11.4361,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.3706e-04, -1.0937e-04, -7.8928e-05, -9.4352e-04, -1.2678e-04,\n",
      "         -2.3626e-03, -6.9986e-02, -2.2740e-03, -4.9071e-02, -4.7826e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2082], requires_grad=True)\n",
      "bias grad:  tensor([-0.2813])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7056]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7716]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1028,  -322.8743,   -11.4356,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2054], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6284]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1028,  -322.8743,   -11.4356,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.8423e-03,  0.0000e+00,  5.1537e-05,  5.3439e-04,  2.2982e-04,\n",
      "          5.0882e-04,  2.3585e-02,  1.8564e-03,  3.4945e-02,  1.1114e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2054], requires_grad=True)\n",
      "bias grad:  tensor([0.2049])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6284]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0477]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1030,  -322.8744,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2074], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6236]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1030,  -322.8744,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1917e-03,  1.4543e-05, -3.1366e-06, -1.9086e-04, -6.8089e-05,\n",
      "          1.2526e-03,  1.8481e-02,  7.5059e-05, -8.6933e-03,  5.2690e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2074], requires_grad=True)\n",
      "bias grad:  tensor([-0.0394])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6236]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3874]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1032,  -322.8744,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2070], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5849]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1032,  -322.8744,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[2.2782e-03, 2.7220e-05, 3.7210e-05, 4.0214e-04, 2.9066e-04, 1.9106e-03,\n",
      "         5.3142e-02, 1.4104e-03, 2.3699e-02, 1.0530e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2070], requires_grad=True)\n",
      "bias grad:  tensor([0.1459])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5849]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0753]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1037,  -322.8744,   -11.4361,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2085], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5924]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1037,  -322.8744,   -11.4361,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1798e-04, 3.7823e-05, 1.1798e-04, 1.2339e-03, 4.9321e-04, 1.7402e-03,\n",
      "         7.6458e-02, 3.1872e-03, 6.8970e-02, 1.8405e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2085], requires_grad=True)\n",
      "bias grad:  tensor([0.4266])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5924]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2639]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1045,  -322.8744,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2127], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6188]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1045,  -322.8744,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4822e-03, 0.0000e+00, 8.7464e-05, 1.0784e-03, 8.2566e-04, 1.1013e-03,\n",
      "         5.7449e-02, 3.0672e-03, 6.8517e-02, 2.0294e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2127], requires_grad=True)\n",
      "bias grad:  tensor([0.3914])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6188]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2069]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1051,  -322.8744,   -11.4375,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2166], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6395]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1051,  -322.8744,   -11.4375,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[2.6833e-03, 0.0000e+00, 4.8586e-05, 5.1745e-04, 5.4007e-04, 7.1509e-04,\n",
      "         3.8409e-02, 1.8437e-03, 3.6894e-02, 1.1717e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2166], requires_grad=True)\n",
      "bias grad:  tensor([0.2103])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6395]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3004]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1054,  -322.8745,   -11.4378,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2187], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6095]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1054,  -322.8745,   -11.4378,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0003, 0.0004, 0.0003, 0.0032, 0.0008, 0.0078, 0.2292, 0.0075, 0.1407,\n",
      "         0.0028]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2187], requires_grad=True)\n",
      "bias grad:  tensor([0.8707])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6095]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6771]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1077,  -322.8745,   -11.4392,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2275], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7772]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1077,  -322.8745,   -11.4392,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9154e-03,  0.0000e+00, -2.3489e-05, -5.1006e-04, -1.5577e-04,\n",
      "          1.5239e-04, -7.0144e-03, -4.8142e-04, -2.0163e-02, -2.8250e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2275], requires_grad=True)\n",
      "bias grad:  tensor([-0.1181])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7772]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4433]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1077,  -322.8745,   -11.4390,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2263], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7328]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1077,  -322.8745,   -11.4390,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.0813e-04,  3.3028e-05,  5.8900e-05,  7.4614e-04,  4.8742e-04,\n",
      "          7.2260e-04,  3.7697e-02,  1.9158e-03,  4.3072e-02,  1.2795e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2263], requires_grad=True)\n",
      "bias grad:  tensor([0.2606])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7328]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1247]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1080,  -322.8745,   -11.4395,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2289], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7453]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1080,  -322.8745,   -11.4395,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.9753e-04, -3.8104e-05,  1.6269e-05,  1.7869e-04,  1.3776e-04,\n",
      "          4.3844e-04,  1.3433e-02,  1.1185e-03,  1.8558e-02,  1.2301e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2289], requires_grad=True)\n",
      "bias grad:  tensor([0.1033])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7453]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6557]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1082,  -322.8745,   -11.4396,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2299], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6797]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1082,  -322.8745,   -11.4396,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.5704e-04,  6.8290e-06,  6.5382e-05,  5.5305e-04,  1.4428e-04,\n",
      "          2.4924e-03,  6.3341e-02,  1.8834e-03,  3.7813e-02,  1.2187e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2299], requires_grad=True)\n",
      "bias grad:  tensor([0.2151])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6797]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0774]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1088,  -322.8746,   -11.4400,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2321], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6875]], requires_grad=True)\n",
      "Iteration 14 | Score: 0.2548876404762268\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1088,  -322.8746,   -11.4400,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8463e-03, -3.3933e-05, -5.4662e-05, -9.1703e-04, -5.6996e-04,\n",
      "         -4.6507e-04, -3.6129e-02, -1.6050e-03, -4.1814e-02, -1.4528e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2321], requires_grad=True)\n",
      "bias grad:  tensor([-0.2444])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6875]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6957]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1084,  -322.8745,   -11.4396,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2296], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6179]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1084,  -322.8745,   -11.4396,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3240e-03,  0.0000e+00, -3.5388e-05, -5.4711e-04, -2.5921e-04,\n",
      "         -1.9534e-04, -1.6515e-02, -1.5786e-03, -3.3788e-02, -8.0105e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2296], requires_grad=True)\n",
      "bias grad:  tensor([-0.1896])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6179]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1561]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1083,  -322.8745,   -11.4393,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2277], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6335]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1083,  -322.8745,   -11.4393,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6932e-03, 2.3205e-05, 8.5275e-05, 1.0518e-03, 8.0446e-04, 1.0585e-03,\n",
      "         5.8022e-02, 3.0231e-03, 6.5723e-02, 2.3333e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2277], requires_grad=True)\n",
      "bias grad:  tensor([0.3887])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6335]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0782]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1089,  -322.8745,   -11.4399,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2316], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6413]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1089,  -322.8745,   -11.4399,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6994e-02,  0.0000e+00, -4.0291e-05, -9.2966e-04, -1.1931e-03,\n",
      "         -5.9649e-04, -2.7100e-02, -1.9755e-03, -4.7666e-02, -5.1334e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2316], requires_grad=True)\n",
      "bias grad:  tensor([-0.2682])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6413]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2211]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1086,  -322.8745,   -11.4394,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2289], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6192]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1086,  -322.8745,   -11.4394,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.1703e-03,  2.0402e-05,  2.7513e-05,  1.1807e-04, -2.0574e-04,\n",
      "          1.0104e-03,  2.0868e-02,  8.3237e-04,  1.0876e-02,  8.2142e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2289], requires_grad=True)\n",
      "bias grad:  tensor([0.0688])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6192]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0165]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1088,  -322.8745,   -11.4396,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2296], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6176]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1088,  -322.8745,   -11.4396,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0856e-03,  0.0000e+00, -1.4639e-04, -1.1700e-03, -4.6687e-04,\n",
      "         -5.6685e-03, -1.5984e-01, -4.5989e-03, -8.7341e-02, -8.7796e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2296], requires_grad=True)\n",
      "bias grad:  tensor([-0.5319])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6176]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1261]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1072,  -322.8745,   -11.4387,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2243], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5050]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1072,  -322.8745,   -11.4387,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.5713e-03,  3.7854e-05, -2.4817e-05,  2.9187e-04,  7.1839e-04,\n",
      "         -3.4545e-03, -7.0453e-02, -4.5908e-04,  6.8546e-03, -7.4582e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2243], requires_grad=True)\n",
      "bias grad:  tensor([0.0235])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5050]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2949]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1065,  -322.8745,   -11.4388,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2245], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5344]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1065,  -322.8745,   -11.4388,  -302.5950]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight grad:  tensor([[ 2.9153e-03, -7.7913e-05, -7.0649e-05, -7.9687e-04, -1.5818e-04,\n",
      "         -2.2087e-03, -7.1404e-02, -1.8315e-03, -3.8522e-02, -1.2789e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2245], requires_grad=True)\n",
      "bias grad:  tensor([-0.2428])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5344]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9683]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1058,  -322.8744,   -11.4384,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2221], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4376]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1058,  -322.8744,   -11.4384,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.3666e-04, -1.9466e-04, -5.7079e-05, -4.3452e-04,  9.8728e-05,\n",
      "         -3.8863e-03, -8.7347e-02, -1.7477e-03, -2.5066e-02, -1.3519e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2221], requires_grad=True)\n",
      "bias grad:  tensor([-0.1679])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4376]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8230]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1049,  -322.8744,   -11.4381,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2204], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3553]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1049,  -322.8744,   -11.4381,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0059, 0.0000, 0.0002, 0.0028, 0.0005, 0.0016, 0.1006, 0.0048, 0.1400,\n",
      "         0.0027]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2204], requires_grad=True)\n",
      "bias grad:  tensor([0.8046])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3553]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.0714]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1059,  -322.8745,   -11.4395,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2285], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7625]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1059,  -322.8745,   -11.4395,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.0004e-03,  1.2566e-05, -9.7596e-05, -1.4958e-03, -1.0296e-03,\n",
      "         -1.3015e-03, -7.2165e-02, -3.6019e-03, -7.8698e-02, -8.8251e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2285], requires_grad=True)\n",
      "bias grad:  tensor([-0.4601])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7625]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4021]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1052,  -322.8744,   -11.4387,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2239], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7222]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1052,  -322.8744,   -11.4387,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5341e-03,  2.8471e-05,  5.4764e-05,  6.2127e-04,  2.8307e-04,\n",
      "          2.1252e-03,  5.7983e-02,  1.9150e-03,  3.3208e-02,  1.1324e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2239], requires_grad=True)\n",
      "bias grad:  tensor([0.2171])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7222]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1695]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1058,  -322.8745,   -11.4391,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2260], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7392]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1058,  -322.8745,   -11.4391,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7278e-03, 0.0000e+00, 5.7328e-05, 7.2233e-04, 4.0946e-04, 2.0764e-04,\n",
      "         4.1794e-02, 2.0741e-03, 4.5477e-02, 1.1586e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2260], requires_grad=True)\n",
      "bias grad:  tensor([0.2629])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7392]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0516]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1062,  -322.8745,   -11.4395,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2287], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7340]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1062,  -322.8745,   -11.4395,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6023e-03,  0.0000e+00, -2.9777e-05, -6.2933e-04, -5.2115e-04,\n",
      "         -2.5937e-05, -1.0286e-02, -1.2223e-03, -3.0038e-02,  1.2843e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2287], requires_grad=True)\n",
      "bias grad:  tensor([-0.1712])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7340]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4567]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1061,  -322.8745,   -11.4392,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2270], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6884]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1061,  -322.8745,   -11.4392,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0129e-03,  3.7798e-05,  4.8905e-06, -8.4794e-05, -4.8290e-04,\n",
      "          3.9425e-04,  1.0464e-02, -1.8756e-05, -1.1319e-03,  1.4858e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2270], requires_grad=True)\n",
      "bias grad:  tensor([-0.0070])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6884]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1203]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1062,  -322.8745,   -11.4392,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2269], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7004]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1062,  -322.8745,   -11.4392,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.5354e-04, -1.0846e-04, -8.3328e-05, -1.0088e-03, -1.6053e-04,\n",
      "         -2.1883e-03, -6.7720e-02, -2.4461e-03, -5.3520e-02, -6.3510e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2269], requires_grad=True)\n",
      "bias grad:  tensor([-0.3059])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7004]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7168]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1055,  -322.8745,   -11.4387,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2238], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6287]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1055,  -322.8745,   -11.4387,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2186e-03,  0.0000e+00,  3.7238e-05,  4.0986e-04,  1.9089e-04,\n",
      "          3.2043e-04,  1.3735e-02,  1.3462e-03,  2.6223e-02,  7.0858e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2238], requires_grad=True)\n",
      "bias grad:  tensor([0.1522])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6287]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1004]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1056,  -322.8745,   -11.4389,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2253], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6388]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1056,  -322.8745,   -11.4389,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0486e-03,  1.1863e-05, -2.6457e-05, -4.9465e-04, -2.2178e-04,\n",
      "          1.0878e-03,  2.9665e-03, -6.5593e-04, -2.5920e-02,  1.3187e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2253], requires_grad=True)\n",
      "bias grad:  tensor([-0.1409])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6388]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4541]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1057,  -322.8745,   -11.4387,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2239], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5933]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1057,  -322.8745,   -11.4387,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8016e-04,  4.4354e-05,  3.3026e-05,  2.5325e-04,  2.9662e-05,\n",
      "          2.3769e-03,  5.6830e-02,  1.0655e-03,  1.6296e-02,  8.6690e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2239], requires_grad=True)\n",
      "bias grad:  tensor([0.0949])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5933]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0867]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1062,  -322.8745,   -11.4388,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2249], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6020]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1062,  -322.8745,   -11.4388,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0405e-04, 2.6634e-05, 8.5533e-05, 8.6989e-04, 3.2079e-04, 1.3116e-03,\n",
      "         5.6413e-02, 2.2286e-03, 4.8321e-02, 1.3415e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2249], requires_grad=True)\n",
      "bias grad:  tensor([0.3010])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6020]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2500]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1068,  -322.8745,   -11.4393,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2279], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6270]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1068,  -322.8745,   -11.4393,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7494e-03, 0.0000e+00, 8.1726e-05, 1.0015e-03, 8.3155e-04, 1.1477e-03,\n",
      "         5.7980e-02, 2.9140e-03, 6.4954e-02, 2.0194e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2279], requires_grad=True)\n",
      "bias grad:  tensor([0.3705])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6270]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0983]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1074,  -322.8745,   -11.4400,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2316], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6369]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1074,  -322.8745,   -11.4400,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[5.8260e-03, 0.0000e+00, 3.2100e-05, 3.8060e-04, 6.7054e-04, 4.7800e-04,\n",
      "         3.1995e-02, 1.8464e-03, 2.8187e-02, 1.9416e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2316], requires_grad=True)\n",
      "bias grad:  tensor([0.1658])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6369]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2874]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1077,  -322.8745,   -11.4402,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2333], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6081]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1077,  -322.8745,   -11.4402,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0005, 0.0003, 0.0003, 0.0030, 0.0007, 0.0076, 0.2221, 0.0070, 0.1327,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2333], requires_grad=True)\n",
      "bias grad:  tensor([0.8233])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6081]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6840]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1099,  -322.8746,   -11.4416,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2415], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7765]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1099,  -322.8746,   -11.4416,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7475e-03,  0.0000e+00, -4.6779e-06, -2.4355e-04, -5.6681e-05,\n",
      "          3.5199e-04,  3.7055e-03,  6.2997e-05, -6.6811e-03, -1.2876e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2415], requires_grad=True)\n",
      "bias grad:  tensor([-0.0404])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7765]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2628]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1100,  -322.8746,   -11.4415,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2411], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7502]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1100,  -322.8746,   -11.4415,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3515e-03,  2.8099e-05,  2.8019e-05,  3.3132e-04,  1.7772e-04,\n",
      "          4.2947e-04,  1.7981e-02,  9.0169e-04,  1.8434e-02,  6.3201e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2411], requires_grad=True)\n",
      "bias grad:  tensor([0.1165])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7502]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1520]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1101,  -322.8746,   -11.4417,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2423], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7654]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1101,  -322.8746,   -11.4417,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2162e-03, -3.7973e-05,  1.0693e-05,  6.6871e-05, -1.2342e-04,\n",
      "          3.2977e-04,  1.1554e-02,  8.0613e-04,  1.1906e-02,  1.1285e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2423], requires_grad=True)\n",
      "bias grad:  tensor([0.0636])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7654]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5777]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1103,  -322.8746,   -11.4418,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2429], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7077]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1103,  -322.8746,   -11.4418,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.9425e-04, -5.9451e-07,  4.7595e-05,  3.0260e-04,  1.9349e-05,\n",
      "          2.1728e-03,  5.0398e-02,  1.2483e-03,  2.4227e-02,  9.0342e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2429], requires_grad=True)\n",
      "bias grad:  tensor([0.1362])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7077]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0989]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1108,  -322.8746,   -11.4421,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2443], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6978]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1108,  -322.8746,   -11.4421,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.3650e-03, -3.0920e-05, -6.5354e-05, -1.0932e-03, -7.8927e-04,\n",
      "         -6.3523e-04, -4.3853e-02, -2.0524e-03, -5.1908e-02, -2.6970e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2443], requires_grad=True)\n",
      "bias grad:  tensor([-0.3027])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6978]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7274]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1103,  -322.8746,   -11.4415,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2412], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6250]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1103,  -322.8746,   -11.4415,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.9048e-04,  0.0000e+00, -2.0410e-05, -3.4250e-04, -8.2856e-05,\n",
      "         -1.2072e-04, -6.1945e-03, -1.1626e-03, -2.2259e-02, -6.1247e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2412], requires_grad=True)\n",
      "bias grad:  tensor([-0.1206])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6250]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1789]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1103,  -322.8746,   -11.4413,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2400], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6429]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1103,  -322.8746,   -11.4413,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4773e-03, 2.2629e-05, 8.4790e-05, 1.0019e-03, 7.4108e-04, 1.2588e-03,\n",
      "         6.2092e-02, 2.9954e-03, 6.2611e-02, 2.4441e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2400], requires_grad=True)\n",
      "bias grad:  tensor([0.3744])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6429]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0100]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1109,  -322.8746,   -11.4419,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2438], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6439]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1109,  -322.8746,   -11.4419,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8594e-02,  0.0000e+00, -4.4599e-05, -1.0235e-03, -1.3119e-03,\n",
      "         -6.5765e-04, -2.9876e-02, -2.1817e-03, -5.2543e-02, -5.6735e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2438], requires_grad=True)\n",
      "bias grad:  tensor([-0.2957])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6439]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2581]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1106,  -322.8746,   -11.4414,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2408], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6181]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1106,  -322.8746,   -11.4414,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.2587e-03,  2.8160e-06,  1.1668e-05, -3.8008e-05, -2.3857e-04,\n",
      "          8.6550e-04,  1.4242e-02,  3.1198e-04,  3.5773e-04,  3.2104e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2408], requires_grad=True)\n",
      "bias grad:  tensor([0.0070])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6181]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0367]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1107,  -322.8746,   -11.4414,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2409], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6218]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1107,  -322.8746,   -11.4414,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2441e-03,  0.0000e+00, -1.2595e-04, -8.9230e-04, -2.3883e-04,\n",
      "         -5.5648e-03, -1.4967e-01, -3.8237e-03, -6.9864e-02, -3.4525e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2409], requires_grad=True)\n",
      "bias grad:  tensor([-0.4312])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6218]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1811]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1092,  -322.8745,   -11.4407,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2366], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5037]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1092,  -322.8745,   -11.4407,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3544e-03,  2.2317e-05, -3.7186e-05,  1.0342e-04,  5.4230e-04,\n",
      "         -3.5690e-03, -7.8680e-02, -8.9634e-04, -3.3791e-03, -9.3655e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2366], requires_grad=True)\n",
      "bias grad:  tensor([-0.0399])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5037]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2098]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1084,  -322.8745,   -11.4407,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2362], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5247]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1084,  -322.8745,   -11.4407,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.2989e-03, -8.0993e-05, -6.7209e-05, -6.5985e-04,  4.2264e-05,\n",
      "         -2.5433e-03, -7.2683e-02, -1.5070e-03, -3.1776e-02, -2.3327e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2362], requires_grad=True)\n",
      "bias grad:  tensor([-0.2030])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5247]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8858]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1077,  -322.8745,   -11.4404,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2341], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4361]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1077,  -322.8745,   -11.4404,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.5271e-04, -2.1139e-04, -1.0796e-04, -9.8232e-04, -2.1073e-04,\n",
      "         -4.6892e-03, -1.1923e-01, -3.3500e-03, -5.8475e-02, -9.5451e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2341], requires_grad=True)\n",
      "bias grad:  tensor([-0.3639])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4361]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8393]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1065,  -322.8745,   -11.4398,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2305], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3522]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1065,  -322.8745,   -11.4398,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0060, 0.0000, 0.0003, 0.0035, 0.0009, 0.0021, 0.1386, 0.0069, 0.1875,\n",
      "         0.0038]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2305], requires_grad=True)\n",
      "bias grad:  tensor([1.0745])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3522]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.9000]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1079,  -322.8746,   -11.4417,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2412], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7421]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1079,  -322.8746,   -11.4417,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.4561e-03,  1.3649e-05, -1.1061e-04, -1.6995e-03, -1.2041e-03,\n",
      "         -1.4163e-03, -8.1242e-02, -4.1499e-03, -9.0711e-02, -1.0762e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2412], requires_grad=True)\n",
      "bias grad:  tensor([-0.5284])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7421]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4807]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1071,  -322.8745,   -11.4408,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2360], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6941]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1071,  -322.8745,   -11.4408,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3612e-03,  2.6992e-05,  4.5920e-05,  4.9737e-04,  2.3711e-04,\n",
      "          1.9634e-03,  5.1274e-02,  1.6098e-03,  2.9421e-02,  8.6210e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2360], requires_grad=True)\n",
      "bias grad:  tensor([0.1785])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6941]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1274]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1076,  -322.8746,   -11.4410,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2377], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7068]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1076,  -322.8746,   -11.4410,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[2.6846e-03, 0.0000e+00, 8.8025e-05, 1.0557e-03, 6.0049e-04, 4.3095e-04,\n",
      "         7.8400e-02, 3.0993e-03, 6.7004e-02, 1.7790e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2377], requires_grad=True)\n",
      "bias grad:  tensor([0.3854])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7068]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0885]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1084,  -322.8746,   -11.4417,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2416], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6980]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1084,  -322.8746,   -11.4417,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6969e-03,  0.0000e+00, -1.5596e-05, -4.0719e-04, -3.1709e-04,\n",
      "          1.5848e-04, -2.0055e-03, -6.7283e-04, -1.7222e-02,  2.1955e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2416], requires_grad=True)\n",
      "bias grad:  tensor([-0.0983])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6980]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4000]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1084,  -322.8746,   -11.4415,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2406], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6580]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1084,  -322.8746,   -11.4415,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.2033e-04,  4.7198e-05,  1.2399e-05,  2.3882e-06, -4.0662e-04,\n",
      "          3.3520e-04,  1.1290e-02,  2.5742e-04,  4.9920e-03,  3.6138e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2406], requires_grad=True)\n",
      "bias grad:  tensor([0.0292])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6580]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0914]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1085,  -322.8746,   -11.4416,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2409], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6671]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1085,  -322.8746,   -11.4416,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.5413e-04, -9.4068e-05, -6.5856e-05, -8.1122e-04, -9.9844e-05,\n",
      "         -2.1800e-03, -6.1415e-02, -1.9398e-03, -4.0783e-02, -1.7586e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2409], requires_grad=True)\n",
      "bias grad:  tensor([-0.2341])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6671]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7612]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1079,  -322.8746,   -11.4412,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2386], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5910]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1079,  -322.8746,   -11.4412,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3840e-03,  0.0000e+00,  4.5780e-05,  5.4535e-04,  3.1656e-04,\n",
      "          3.1648e-04,  1.8242e-02,  1.7159e-03,  3.4520e-02,  8.2342e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2386], requires_grad=True)\n",
      "bias grad:  tensor([0.1982])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5910]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0863]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1081,  -322.8746,   -11.4415,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2405], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5996]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1081,  -322.8746,   -11.4415,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.7785e-04,  2.1251e-05, -2.6622e-06, -1.4531e-04,  5.6768e-05,\n",
      "          1.3187e-03,  2.1571e-02,  1.8941e-04, -6.5101e-03,  6.1109e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2405], requires_grad=True)\n",
      "bias grad:  tensor([-0.0220])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5996]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3079]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1083,  -322.8746,   -11.4415,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2403], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5688]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1083,  -322.8746,   -11.4415,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[1.8652e-03, 3.2541e-05, 3.5800e-05, 3.5467e-04, 1.2576e-04, 2.1286e-03,\n",
      "         5.2589e-02, 1.0619e-03, 1.8549e-02, 7.3155e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2403], requires_grad=True)\n",
      "bias grad:  tensor([0.1140])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5688]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3047]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1088,  -322.8746,   -11.4417,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2415], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5993]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1088,  -322.8746,   -11.4417,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[1.4241e-04, 3.2439e-05, 9.1515e-05, 9.3913e-04, 3.6193e-04, 1.5494e-03,\n",
      "         6.3259e-02, 2.5387e-03, 5.2368e-02, 1.5458e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2415], requires_grad=True)\n",
      "bias grad:  tensor([0.3296])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5993]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2225]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1094,  -322.8746,   -11.4422,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2448], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6216]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1094,  -322.8746,   -11.4422,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8055e-03, 0.0000e+00, 5.4683e-05, 6.6662e-04, 6.0887e-04, 6.2421e-04,\n",
      "         3.6778e-02, 1.9511e-03, 4.3924e-02, 1.5263e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2448], requires_grad=True)\n",
      "bias grad:  tensor([0.2505])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6216]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1722]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1098,  -322.8747,   -11.4426,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2473], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6388]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1098,  -322.8747,   -11.4426,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4545e-03, 0.0000e+00, 4.1784e-05, 3.9873e-04, 4.8544e-04, 6.8215e-04,\n",
      "         3.6310e-02, 1.7137e-03, 3.1292e-02, 9.3268e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2473], requires_grad=True)\n",
      "bias grad:  tensor([0.1797])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6388]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4545]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1102,  -322.8747,   -11.4429,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2491], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5933]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1102,  -322.8747,   -11.4429,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0003, 0.0003, 0.0002, 0.0030, 0.0006, 0.0078, 0.2217, 0.0067, 0.1258,\n",
      "         0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2491], requires_grad=True)\n",
      "bias grad:  tensor([0.7864])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5933]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.8498]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1124,  -322.8748,   -11.4442,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2569], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7783]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1124,  -322.8748,   -11.4442,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3718e-03,  0.0000e+00, -1.9826e-05, -4.6123e-04, -2.0633e-04,\n",
      "          2.3899e-04, -5.7862e-03, -4.2922e-04, -1.8150e-02, -2.3049e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2569], requires_grad=True)\n",
      "bias grad:  tensor([-0.1065])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7783]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3836]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1123,  -322.8748,   -11.4440,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2559], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7400]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1123,  -322.8748,   -11.4440,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3961e-04,  3.5847e-05,  5.6539e-05,  7.0676e-04,  4.1468e-04,\n",
      "          6.7893e-04,  3.3785e-02,  1.8355e-03,  4.0572e-02,  1.1368e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2559], requires_grad=True)\n",
      "bias grad:  tensor([0.2449])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7400]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1752]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1127,  -322.8748,   -11.4444,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2583], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7575]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1127,  -322.8748,   -11.4444,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1540e-03, -4.3797e-05,  6.2862e-06,  1.7559e-05, -1.1557e-04,\n",
      "          3.0701e-04,  8.6118e-03,  7.1626e-04,  9.3116e-03,  1.0805e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2583], requires_grad=True)\n",
      "bias grad:  tensor([0.0492])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7575]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5909]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1128,  -322.8748,   -11.4445,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2588], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6984]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1128,  -322.8748,   -11.4445,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2781e-03,  1.0213e-05,  3.6763e-05,  1.3592e-04, -1.0280e-04,\n",
      "          2.0432e-03,  4.4704e-02,  8.8590e-04,  1.5513e-02,  8.8349e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2588], requires_grad=True)\n",
      "bias grad:  tensor([0.0869])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6984]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1299]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1132,  -322.8748,   -11.4447,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2597], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6854]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1132,  -322.8748,   -11.4447,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.9555e-03, -3.7194e-05, -6.7591e-05, -1.1145e-03, -7.6016e-04,\n",
      "         -5.9991e-04, -4.5070e-02, -2.0493e-03, -5.2408e-02, -2.4326e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2597], requires_grad=True)\n",
      "bias grad:  tensor([-0.3067])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6854]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7703]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1127,  -322.8748,   -11.4441,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2566], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6084]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1127,  -322.8748,   -11.4441,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7856e-04,  0.0000e+00, -2.0922e-05, -3.5080e-04, -1.4589e-04,\n",
      "         -8.8212e-05, -7.9921e-03, -1.1554e-03, -2.2707e-02, -6.6796e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2566], requires_grad=True)\n",
      "bias grad:  tensor([-0.1265])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6084]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2132]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1127,  -322.8748,   -11.4439,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2553], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6297]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1127,  -322.8748,   -11.4439,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[3.2040e-03, 2.4878e-05, 9.2259e-05, 1.1510e-03, 9.1146e-04, 1.3957e-03,\n",
      "         7.1039e-02, 3.5371e-03, 7.1703e-02, 2.6706e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2553], requires_grad=True)\n",
      "bias grad:  tensor([0.4290])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6297]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0241]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1134,  -322.8748,   -11.4446,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2596], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6273]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1134,  -322.8748,   -11.4446,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8577e-02,  0.0000e+00, -6.7671e-05, -1.3060e-03, -1.6005e-03,\n",
      "         -8.8145e-04, -3.9902e-02, -3.0863e-03, -6.9986e-02, -8.2174e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2596], requires_grad=True)\n",
      "bias grad:  tensor([-0.3964])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6273]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1912]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1130,  -322.8748,   -11.4439,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2557], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6082]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1130,  -322.8748,   -11.4439,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.2763e-03,  5.2547e-06,  1.4253e-05, -3.1338e-05, -2.6348e-04,\n",
      "          1.0661e-03,  1.8401e-02,  4.1437e-04,  1.2348e-03,  4.2050e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2557], requires_grad=True)\n",
      "bias grad:  tensor([0.0134])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6082]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0269]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1132,  -322.8748,   -11.4439,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2558], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6055]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1132,  -322.8748,   -11.4439,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[ 9.4700e-06,  0.0000e+00, -1.0057e-04, -5.7495e-04,  9.9153e-05,\n",
      "         -5.2699e-03, -1.3104e-01, -3.0594e-03, -4.9873e-02,  3.3433e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2558], requires_grad=True)\n",
      "bias grad:  tensor([-0.3158])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6055]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.2420]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1119,  -322.8747,   -11.4434,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2526], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4813]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1119,  -322.8747,   -11.4434,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1067e-03,  3.6286e-05,  2.2811e-06,  6.6113e-04,  8.7888e-04,\n",
      "         -3.2319e-03, -5.6602e-02,  4.7796e-04,  2.7200e-02, -2.9911e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2526], requires_grad=True)\n",
      "bias grad:  tensor([0.1396])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4813]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.4603]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1113,  -322.8747,   -11.4437,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2540], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5273]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1113,  -322.8747,   -11.4437,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.9212e-03, -7.3133e-05, -6.7663e-05, -8.1554e-04, -2.1845e-04,\n",
      "         -2.1070e-03, -6.7762e-02, -1.8623e-03, -4.0065e-02, -5.7953e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2540], requires_grad=True)\n",
      "bias grad:  tensor([-0.2484])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5273]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.0010]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1106,  -322.8747,   -11.4433,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2516], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4272]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1106,  -322.8747,   -11.4433,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0499e-04, -1.9650e-04, -6.4922e-05, -5.9660e-04, -5.5733e-05,\n",
      "         -4.1013e-03, -9.2722e-02, -2.3349e-03, -3.4920e-02, -2.7641e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2516], requires_grad=True)\n",
      "bias grad:  tensor([-0.2260])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4272]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8609]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1097,  -322.8747,   -11.4430,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2493], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3411]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1097,  -322.8747,   -11.4430,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0065, 0.0000, 0.0003, 0.0032, 0.0006, 0.0018, 0.1118, 0.0055, 0.1597,\n",
      "         0.0031]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2493], requires_grad=True)\n",
      "bias grad:  tensor([0.9177])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3411]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.6983]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1108,  -322.8747,   -11.4446,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2585], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8109]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1108,  -322.8747,   -11.4446,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.7090e-03,  1.2627e-05, -9.6252e-05, -1.5662e-03, -1.1010e-03,\n",
      "         -1.0458e-03, -6.7117e-02, -3.5867e-03, -8.1117e-02, -7.8479e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2585], requires_grad=True)\n",
      "bias grad:  tensor([-0.4695])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8109]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6164]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1101,  -322.8747,   -11.4437,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2538], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7493]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1101,  -322.8747,   -11.4437,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.9004e-03,  2.8776e-05,  4.0181e-05,  4.0882e-04,  1.1548e-04,\n",
      "          2.0322e-03,  4.8679e-02,  1.3844e-03,  2.1395e-02,  8.6783e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2538], requires_grad=True)\n",
      "bias grad:  tensor([0.1458])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7493]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1294]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1106,  -322.8747,   -11.4440,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2552], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7622]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1106,  -322.8747,   -11.4440,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[1.9372e-03, 0.0000e+00, 7.5616e-05, 8.8214e-04, 4.0840e-04, 2.5158e-04,\n",
      "         6.9627e-02, 2.5936e-03, 5.6103e-02, 1.5405e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2552], requires_grad=True)\n",
      "bias grad:  tensor([0.3220])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7622]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0848]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1113,  -322.8747,   -11.4445,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2585], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7537]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1113,  -322.8747,   -11.4445,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.7655e-03,  0.0000e+00, -3.1357e-05, -6.6811e-04, -5.4864e-04,\n",
      "         -1.3613e-05, -1.0584e-02, -1.3094e-03, -3.1771e-02,  5.1052e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2585], requires_grad=True)\n",
      "bias grad:  tensor([-0.1809])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7537]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5146]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1112,  -322.8747,   -11.4442,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2566], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7023]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1112,  -322.8747,   -11.4442,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8372e-04,  5.3242e-05,  1.8086e-05,  1.0892e-04, -3.2991e-04,\n",
      "          4.8725e-04,  1.7878e-02,  5.1929e-04,  1.0232e-02,  4.1559e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2566], requires_grad=True)\n",
      "bias grad:  tensor([0.0590])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7023]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1218]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1114,  -322.8747,   -11.4443,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2572], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7145]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1114,  -322.8747,   -11.4443,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.7505e-04, -1.0104e-04, -7.8608e-05, -9.5637e-04, -1.2361e-04,\n",
      "         -2.2959e-03, -6.8868e-02, -2.2961e-03, -4.9576e-02, -3.7384e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2572], requires_grad=True)\n",
      "bias grad:  tensor([-0.2835])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7145]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8053]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1107,  -322.8747,   -11.4438,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2544], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6339]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1107,  -322.8747,   -11.4438,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2268e-03,  0.0000e+00,  3.9263e-05,  4.7024e-04,  2.3924e-04,\n",
      "          2.4232e-04,  1.6557e-02,  1.5008e-03,  2.9873e-02,  8.2886e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2544], requires_grad=True)\n",
      "bias grad:  tensor([0.1709])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6339]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0287]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1109,  -322.8747,   -11.4441,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2561], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6368]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1109,  -322.8747,   -11.4441,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8185e-03,  1.6339e-05, -2.6897e-05, -5.0331e-04, -1.6180e-04,\n",
      "          9.2043e-04,  6.3327e-04, -6.4819e-04, -2.4412e-02,  2.3701e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2561], requires_grad=True)\n",
      "bias grad:  tensor([-0.1385])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6368]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4999]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1109,  -322.8747,   -11.4439,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2547], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5868]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1109,  -322.8747,   -11.4439,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1821e-03, 3.7237e-05, 4.1690e-05, 4.5735e-04, 3.8277e-04, 2.0837e-03,\n",
      "         5.8597e-02, 1.5351e-03, 2.6218e-02, 1.0263e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2547], requires_grad=True)\n",
      "bias grad:  tensor([0.1622])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5868]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0956]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1115,  -322.8747,   -11.4441,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2564], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5964]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1115,  -322.8747,   -11.4441,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[2.2868e-04, 3.5590e-05, 8.7046e-05, 8.9950e-04, 3.3023e-04, 1.3995e-03,\n",
      "         5.8544e-02, 2.3163e-03, 4.9768e-02, 1.3905e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2564], requires_grad=True)\n",
      "bias grad:  tensor([0.3100])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5964]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3094]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1120,  -322.8748,   -11.4446,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2594], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6273]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1120,  -322.8748,   -11.4446,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5911e-03, 0.0000e+00, 7.3951e-05, 8.9167e-04, 7.7559e-04, 1.0451e-03,\n",
      "         5.3520e-02, 2.6783e-03, 5.9247e-02, 1.9390e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2594], requires_grad=True)\n",
      "bias grad:  tensor([0.3377])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6273]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0896]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1126,  -322.8748,   -11.4452,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2628], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6363]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1126,  -322.8748,   -11.4452,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2779e-04,  0.0000e+00,  4.8844e-05,  4.5856e-04,  1.9656e-04,\n",
      "          6.9265e-04,  3.2682e-02,  1.5892e-03,  3.2624e-02,  1.3984e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2628], requires_grad=True)\n",
      "bias grad:  tensor([0.1854])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6363]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2199]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1129,  -322.8748,   -11.4455,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2647], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6143]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1129,  -322.8748,   -11.4455,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-0.0002,  0.0003,  0.0002,  0.0028,  0.0006,  0.0075,  0.2135,  0.0065,\n",
      "          0.1191,  0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2647], requires_grad=True)\n",
      "bias grad:  tensor([0.7464])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6143]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5667]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1150,  -322.8749,   -11.4467,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2721], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7709]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1150,  -322.8749,   -11.4467,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2417e-03,  0.0000e+00, -1.4731e-05, -4.4060e-04, -1.8435e-04,\n",
      "          3.6618e-04, -1.6921e-03, -2.8078e-04, -1.6055e-02, -1.7765e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2721], requires_grad=True)\n",
      "bias grad:  tensor([-0.0944])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7709]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3957]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1150,  -322.8749,   -11.4466,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2712], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7314]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1150,  -322.8749,   -11.4466,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.6232e-04,  2.5692e-05,  4.6794e-05,  5.6774e-04,  2.8955e-04,\n",
      "          6.1430e-04,  3.0777e-02,  1.5422e-03,  3.1982e-02,  9.5321e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2712], requires_grad=True)\n",
      "bias grad:  tensor([0.1974])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7314]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0960]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1153,  -322.8749,   -11.4469,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2732], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7410]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1153,  -322.8749,   -11.4469,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2828e-03, -5.3621e-05,  1.2521e-07, -6.7010e-05, -1.4310e-04,\n",
      "          3.1260e-04,  6.1078e-03,  5.5392e-04,  4.9991e-03,  1.0681e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2732], requires_grad=True)\n",
      "bias grad:  tensor([0.0244])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7410]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6843]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1154,  -322.8749,   -11.4469,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2734], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6726]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1154,  -322.8749,   -11.4469,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.5455e-04,  3.3718e-06,  4.2671e-05,  2.7468e-04, -4.4856e-05,\n",
      "          2.0747e-03,  4.6330e-02,  1.0887e-03,  2.0825e-02,  8.4764e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2734], requires_grad=True)\n",
      "bias grad:  tensor([0.1180])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6726]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0380]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1158,  -322.8749,   -11.4471,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2746], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6764]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1158,  -322.8749,   -11.4471,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2339e-03, -2.9703e-05, -5.8370e-05, -9.8180e-04, -7.2474e-04,\n",
      "         -5.4725e-04, -3.9746e-02, -1.8062e-03, -4.6144e-02, -2.3277e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2746], requires_grad=True)\n",
      "bias grad:  tensor([-0.2702])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6764]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5954]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1155,  -322.8749,   -11.4467,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2719], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6168]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1155,  -322.8749,   -11.4467,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.4428e-04,  0.0000e+00, -3.6676e-05, -5.6261e-04, -2.6715e-04,\n",
      "         -1.8013e-04, -1.5905e-02, -1.6769e-03, -3.4931e-02, -9.7303e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2719], requires_grad=True)\n",
      "bias grad:  tensor([-0.1980])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6168]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2024]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1153,  -322.8748,   -11.4463,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2699], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6371]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1153,  -322.8748,   -11.4463,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[2.6898e-03, 1.5977e-05, 7.8134e-05, 9.3553e-04, 6.9379e-04, 1.0457e-03,\n",
      "         5.4793e-02, 2.8234e-03, 5.8625e-02, 2.3158e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2699], requires_grad=True)\n",
      "bias grad:  tensor([0.3505])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6371]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0104]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1158,  -322.8749,   -11.4469,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2734], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6360]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1158,  -322.8749,   -11.4469,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.4803e-02,  0.0000e+00, -7.8067e-05, -1.5931e-03, -1.9829e-03,\n",
      "         -1.0576e-03, -4.7931e-02, -3.6388e-03, -8.4145e-02, -9.6167e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2734], requires_grad=True)\n",
      "bias grad:  tensor([-0.4756])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6360]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3219]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1154,  -322.8748,   -11.4461,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2687], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6038]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1154,  -322.8748,   -11.4461,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.0443e-03,  1.7479e-05,  3.8864e-05,  2.3293e-04, -1.4852e-04,\n",
      "          9.6828e-04,  2.3178e-02,  1.2040e-03,  1.8462e-02,  1.0904e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2687], requires_grad=True)\n",
      "bias grad:  tensor([0.1124])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6038]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0578]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1156,  -322.8748,   -11.4463,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2698], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5981]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1156,  -322.8748,   -11.4463,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5022e-03,  0.0000e+00, -1.2711e-04, -8.9495e-04, -3.1045e-04,\n",
      "         -5.6622e-03, -1.5162e-01, -3.8204e-03, -7.0560e-02, -5.0351e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2698], requires_grad=True)\n",
      "bias grad:  tensor([-0.4361])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5981]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.0970]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0243,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1141,  -322.8748,   -11.4456,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2654], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4883]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0243,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1141,  -322.8748,   -11.4456,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6299e-03,  3.7696e-05,  2.1622e-05,  7.8185e-04,  8.8770e-04,\n",
      "         -2.9252e-03, -3.7174e-02,  1.0042e-03,  3.5725e-02,  5.1226e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2654], requires_grad=True)\n",
      "bias grad:  tensor([0.2048])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4883]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2579]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1137,  -322.8748,   -11.4459,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2675], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5141]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1137,  -322.8748,   -11.4459,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.2486e-03, -7.0331e-05, -6.3803e-05, -7.4454e-04, -2.1868e-04,\n",
      "         -2.0208e-03, -6.6981e-02, -1.6703e-03, -3.5828e-02, -6.7653e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2675], requires_grad=True)\n",
      "bias grad:  tensor([-0.2265])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5141]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8445]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1130,  -322.8748,   -11.4456,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2652], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4297]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1130,  -322.8748,   -11.4456,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.4878e-04, -2.0689e-04, -8.9631e-05, -8.2594e-04, -1.8459e-04,\n",
      "         -4.4684e-03, -1.0849e-01, -2.9621e-03, -5.0820e-02, -7.2439e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2652], requires_grad=True)\n",
      "bias grad:  tensor([-0.3102])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4297]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7460]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1120,  -322.8748,   -11.4451,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2621], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3551]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1120,  -322.8748,   -11.4451,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0052, 0.0000, 0.0002, 0.0028, 0.0006, 0.0016, 0.1087, 0.0052, 0.1475,\n",
      "         0.0029]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2621], requires_grad=True)\n",
      "bias grad:  tensor([0.8470])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3551]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.6242]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1130,  -322.8748,   -11.4465,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2706], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7175]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1130,  -322.8748,   -11.4465,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.1651e-03,  1.4560e-05, -8.8015e-05, -1.3640e-03, -9.8148e-04,\n",
      "         -1.1762e-03, -6.6917e-02, -3.2652e-03, -7.1553e-02, -7.6951e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2706], requires_grad=True)\n",
      "bias grad:  tensor([-0.4180])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7175]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3649]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1124,  -322.8748,   -11.4458,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2664], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6810]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1124,  -322.8748,   -11.4458,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3112e-03,  2.2405e-05,  4.8198e-05,  5.1978e-04,  1.8935e-04,\n",
      "          2.3795e-03,  5.8750e-02,  1.7234e-03,  2.8373e-02,  1.0058e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2664], requires_grad=True)\n",
      "bias grad:  tensor([0.1837])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6810]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1397]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1130,  -322.8748,   -11.4461,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2682], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6950]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1130,  -322.8748,   -11.4461,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4429e-03, 0.0000e+00, 8.0645e-05, 9.5358e-04, 5.3274e-04, 4.0741e-04,\n",
      "         7.3960e-02, 2.8220e-03, 6.0519e-02, 1.6115e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2682], requires_grad=True)\n",
      "bias grad:  tensor([0.3491])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6950]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0868]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1137,  -322.8748,   -11.4467,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2717], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6863]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1137,  -322.8748,   -11.4467,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6185e-03,  0.0000e+00, -2.3652e-05, -5.5604e-04, -4.7267e-04,\n",
      "          5.9956e-05, -5.3465e-03, -9.8853e-04, -2.5156e-02,  1.1947e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2717], requires_grad=True)\n",
      "bias grad:  tensor([-0.1434])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6863]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4563]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1136,  -322.8748,   -11.4465,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2703], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6407]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1136,  -322.8748,   -11.4465,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7014e-04,  5.6180e-05,  3.5181e-05,  3.0135e-04, -1.8645e-04,\n",
      "          7.2971e-04,  2.7105e-02,  1.1481e-03,  2.3031e-02,  7.4600e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2703], requires_grad=True)\n",
      "bias grad:  tensor([0.1329])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6407]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1105]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1139,  -322.8748,   -11.4467,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2716], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6517]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1139,  -322.8748,   -11.4467,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.4659e-05, -9.9405e-05, -7.4268e-05, -8.9913e-04, -1.2811e-04,\n",
      "         -2.0734e-03, -6.1738e-02, -2.1970e-03, -4.7684e-02, -5.2204e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2716], requires_grad=True)\n",
      "bias grad:  tensor([-0.2722])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6517]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6287]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1133,  -322.8748,   -11.4462,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2689], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5889]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1133,  -322.8748,   -11.4462,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7334e-03,  0.0000e+00,  3.7710e-05,  3.2275e-04,  2.2568e-05,\n",
      "          6.2388e-04,  1.9272e-02,  1.2618e-03,  2.2010e-02,  8.8108e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2689], requires_grad=True)\n",
      "bias grad:  tensor([0.1335])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5889]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0371]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0243,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1135,  -322.8748,   -11.4464,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2702], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5926]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0243,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1135,  -322.8748,   -11.4464,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.8606e-03,  1.7782e-05, -2.1181e-06, -9.0678e-05,  3.6810e-04,\n",
      "          8.4248e-04,  1.7102e-02,  3.9388e-04,  9.4760e-04,  7.9050e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2702], requires_grad=True)\n",
      "bias grad:  tensor([0.0119])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5926]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4544]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1137,  -322.8748,   -11.4464,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2704], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5471]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1137,  -322.8748,   -11.4464,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[2.3132e-03, 2.8950e-05, 3.7072e-05, 3.8076e-04, 2.7478e-04, 1.8429e-03,\n",
      "         5.1308e-02, 1.3376e-03, 2.2179e-02, 9.9706e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2704], requires_grad=True)\n",
      "bias grad:  tensor([0.1379])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5471]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1514]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1142,  -322.8748,   -11.4467,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2717], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5623]], requires_grad=True)\n",
      "Iteration 15 | Score: 0.7391181588172913\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8737,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7504e-04,  2.7356e-05,  9.7703e-05,  9.6563e-04,  3.9654e-04,\n",
      "          1.4923e-03,  6.6837e-02,  2.7480e-03,  5.4210e-02,  1.7095e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1246], requires_grad=True)\n",
      "bias grad:  tensor([0.3478])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7845]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0094]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0911,  -322.8737,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1281], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7854]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0911,  -322.8737,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4789e-03, 0.0000e+00, 3.0159e-05, 3.2790e-04, 4.2084e-04, 8.5410e-04,\n",
      "         3.3039e-02, 1.2850e-03, 2.5970e-02, 7.4447e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1281], requires_grad=True)\n",
      "bias grad:  tensor([0.1455])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7854]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1816]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8737,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1296], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7673]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8737,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[1.4530e-03, 0.0000e+00, 2.0342e-05, 4.8576e-05, 1.3455e-04, 5.2540e-04,\n",
      "         2.1500e-02, 9.1363e-04, 1.2785e-02, 5.0567e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1296], requires_grad=True)\n",
      "bias grad:  tensor([0.0712])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7673]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5705]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0916,  -322.8737,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1303], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7102]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0916,  -322.8737,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-0.0004,  0.0003,  0.0002,  0.0026,  0.0006,  0.0069,  0.1972,  0.0060,\n",
      "          0.1126,  0.0018]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1303], requires_grad=True)\n",
      "bias grad:  tensor([0.7024])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7102]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.2747]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0936,  -322.8738,   -11.4241,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1373], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8377]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0936,  -322.8738,   -11.4241,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8987e-03,  0.0000e+00, -4.1495e-06, -2.6685e-04, -9.2866e-05,\n",
      "          3.9348e-04,  4.1608e-03,  9.4034e-05, -6.9061e-03, -5.4561e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1373], requires_grad=True)\n",
      "bias grad:  tensor([-0.0410])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8377]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3253]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0937,  -322.8738,   -11.4240,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1369], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8052]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0937,  -322.8738,   -11.4240,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2249e-04,  4.4381e-05,  7.3325e-05,  9.3085e-04,  6.0265e-04,\n",
      "          8.8425e-04,  4.6300e-02,  2.4538e-03,  5.4286e-02,  1.6100e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1369], requires_grad=True)\n",
      "bias grad:  tensor([0.3266])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8052]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1005]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0941,  -322.8738,   -11.4245,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1401], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8152]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0941,  -322.8738,   -11.4245,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2649e-03, -3.8730e-05,  1.5148e-05,  1.6962e-04,  9.9119e-05,\n",
      "          3.1822e-04,  1.1671e-02,  1.1086e-03,  1.8311e-02,  1.3198e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1401], requires_grad=True)\n",
      "bias grad:  tensor([0.1016])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8152]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7187]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0942,  -322.8738,   -11.4247,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1412], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7433]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0942,  -322.8738,   -11.4247,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[8.4002e-05, 2.1137e-05, 5.7637e-05, 4.3088e-04, 7.2154e-05, 2.2544e-03,\n",
      "         5.4414e-02, 1.6041e-03, 3.2539e-02, 1.1973e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1412], requires_grad=True)\n",
      "bias grad:  tensor([0.1841])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7433]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0608]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0948,  -322.8739,   -11.4250,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1430], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7373]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0948,  -322.8739,   -11.4250,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.5529e-03, -3.1533e-05, -4.1033e-05, -7.3816e-04, -4.6080e-04,\n",
      "         -3.3093e-04, -2.8335e-02, -1.1697e-03, -3.1616e-02,  2.2869e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1430], requires_grad=True)\n",
      "bias grad:  tensor([-0.1836])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7373]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6128]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8739,   -11.4247,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1412], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6760]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8739,   -11.4247,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.3042e-04,  0.0000e+00, -1.7311e-05, -2.8886e-04, -7.5965e-05,\n",
      "         -6.1814e-05, -3.4957e-03, -9.4744e-04, -1.9105e-02, -5.6176e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1412], requires_grad=True)\n",
      "bias grad:  tensor([-0.1042])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6760]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1585]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8739,   -11.4245,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1401], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6918]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8739,   -11.4245,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[3.9401e-03, 2.9410e-05, 8.6011e-05, 1.0396e-03, 7.5574e-04, 1.2507e-03,\n",
      "         6.0762e-02, 2.9829e-03, 6.4470e-02, 2.3516e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1401], requires_grad=True)\n",
      "bias grad:  tensor([0.3841])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6918]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0998]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0951,  -322.8739,   -11.4252,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1440], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7018]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0951,  -322.8739,   -11.4252,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7086e-02,  0.0000e+00, -3.5624e-05, -8.7478e-04, -1.1383e-03,\n",
      "         -5.5229e-04, -2.5122e-02, -1.7946e-03, -4.4228e-02, -4.6224e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1440], requires_grad=True)\n",
      "bias grad:  tensor([-0.2484])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7018]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2937]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0948,  -322.8739,   -11.4247,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1415], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6724]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0948,  -322.8739,   -11.4247,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.6766e-03,  1.4028e-05,  3.8673e-05,  2.5483e-04, -1.0045e-04,\n",
      "          1.3094e-03,  3.2283e-02,  1.3031e-03,  1.9267e-02,  1.0036e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1415], requires_grad=True)\n",
      "bias grad:  tensor([0.1195])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6724]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1331]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0951,  -322.8739,   -11.4249,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1427], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6591]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0951,  -322.8739,   -11.4249,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.0111e-04,  0.0000e+00, -1.1968e-04, -7.6280e-04, -1.1580e-04,\n",
      "         -5.4493e-03, -1.4313e-01, -3.4795e-03, -6.2806e-02, -3.4086e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1427], requires_grad=True)\n",
      "bias grad:  tensor([-0.3903])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6591]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1481]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0937,  -322.8738,   -11.4243,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1388], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5443]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0937,  -322.8738,   -11.4243,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6119e-03,  1.8492e-05, -2.3965e-05,  2.1908e-04,  6.6065e-04,\n",
      "         -3.5842e-03, -7.1410e-02, -4.3125e-04,  6.1251e-03, -5.0582e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1388], requires_grad=True)\n",
      "bias grad:  tensor([0.0156])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5443]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0744]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0930,  -322.8738,   -11.4244,  -302.5944]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias after:  Parameter containing:\n",
      "tensor([-0.1389], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5369]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0930,  -322.8738,   -11.4244,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.0812e-03, -6.8089e-05, -4.3693e-05, -3.7632e-04,  1.1401e-04,\n",
      "         -2.1051e-03, -5.5026e-02, -8.8260e-04, -1.7512e-02, -1.5081e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1389], requires_grad=True)\n",
      "bias grad:  tensor([-0.1173])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5369]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6154]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0924,  -322.8738,   -11.4242,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1378], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4753]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0924,  -322.8738,   -11.4242,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.9454e-04, -1.9623e-04, -8.2498e-05, -7.2882e-04, -8.0867e-05,\n",
      "         -4.1979e-03, -9.9960e-02, -2.6260e-03, -4.3390e-02, -5.2550e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1378], requires_grad=True)\n",
      "bias grad:  tensor([-0.2697])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4753]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8623]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8738,   -11.4238,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1351], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3891]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8738,   -11.4238,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0053, 0.0000, 0.0002, 0.0024, 0.0003, 0.0013, 0.0847, 0.0040, 0.1226,\n",
      "         0.0024]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1351], requires_grad=True)\n",
      "bias grad:  tensor([0.7050])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3891]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.6027]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0923,  -322.8738,   -11.4250,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1421], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7494]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0923,  -322.8738,   -11.4250,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6099e-03,  2.5298e-05, -6.6752e-05, -1.1049e-03, -8.1068e-04,\n",
      "         -7.4879e-04, -5.0936e-02, -2.4942e-03, -5.6074e-02, -4.2426e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1421], requires_grad=True)\n",
      "bias grad:  tensor([-0.3238])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7494]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3740]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0918,  -322.8738,   -11.4244,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1389], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7120]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0918,  -322.8738,   -11.4244,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3349e-03,  2.9114e-05,  5.5575e-05,  6.4354e-04,  3.0097e-04,\n",
      "          2.3042e-03,  6.1067e-02,  1.9831e-03,  3.4480e-02,  1.1201e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1389], requires_grad=True)\n",
      "bias grad:  tensor([0.2224])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7120]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1750]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0924,  -322.8738,   -11.4248,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1411], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7295]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0924,  -322.8738,   -11.4248,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0098e-03, 0.0000e+00, 7.2235e-05, 9.7632e-04, 7.0639e-04, 3.8895e-04,\n",
      "         5.3469e-02, 2.6280e-03, 6.0003e-02, 1.3028e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1411], requires_grad=True)\n",
      "bias grad:  tensor([0.3486])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7295]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0308]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0929,  -322.8739,   -11.4254,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1446], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7264]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0929,  -322.8739,   -11.4254,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5303e-03,  0.0000e+00, -3.1433e-06, -2.3935e-04, -2.2617e-04,\n",
      "          2.0381e-04,  5.4292e-03, -1.7412e-04, -7.3383e-03,  3.2628e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1446], requires_grad=True)\n",
      "bias grad:  tensor([-0.0420])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7264]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3914]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0930,  -322.8739,   -11.4253,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1442], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6873]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0930,  -322.8739,   -11.4253,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.8845e-05,  6.7742e-05,  3.9638e-05,  4.0683e-04, -1.3944e-04,\n",
      "          9.3851e-04,  3.4993e-02,  1.3493e-03,  2.7573e-02,  7.8715e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1442], requires_grad=True)\n",
      "bias grad:  tensor([0.1584])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6873]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1726]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0933,  -322.8739,   -11.4256,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1457], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7045]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0933,  -322.8739,   -11.4256,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.8316e-04, -1.0277e-04, -5.5817e-05, -6.6883e-04,  2.3051e-05,\n",
      "         -1.9065e-03, -5.2690e-02, -1.5353e-03, -3.2737e-02, -2.1588e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1457], requires_grad=True)\n",
      "bias grad:  tensor([-0.1867])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7045]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7102]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0928,  -322.8738,   -11.4252,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1439], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6335]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0928,  -322.8738,   -11.4252,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0075e-03,  0.0000e+00,  5.2909e-05,  6.1107e-04,  3.2850e-04,\n",
      "          4.6410e-04,  2.5259e-02,  2.0078e-03,  3.9086e-02,  1.0119e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1439], requires_grad=True)\n",
      "bias grad:  tensor([0.2253])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6335]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0155]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0931,  -322.8739,   -11.4256,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1461], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6351]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0931,  -322.8739,   -11.4256,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.1847e-03, 2.8814e-06, 1.4527e-05, 8.3822e-05, 4.8570e-04, 1.1938e-03,\n",
      "         3.3449e-02, 8.1199e-04, 1.0644e-02, 7.4789e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1461], requires_grad=True)\n",
      "bias grad:  tensor([0.0648])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6351]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4193]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0934,  -322.8739,   -11.4257,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1468], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5931]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0934,  -322.8739,   -11.4257,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6139e-03, 3.3887e-05, 5.1563e-05, 5.4321e-04, 3.1328e-04, 2.3256e-03,\n",
      "         6.5110e-02, 1.8446e-03, 3.2516e-02, 1.2045e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1468], requires_grad=True)\n",
      "bias grad:  tensor([0.1940])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5931]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1201]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0940,  -322.8739,   -11.4261,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1487], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6051]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0940,  -322.8739,   -11.4261,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.8419e-04, 4.2375e-05, 1.2574e-04, 1.3318e-03, 5.3816e-04, 1.8920e-03,\n",
      "         8.2638e-02, 3.4984e-03, 7.3518e-02, 2.0140e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1487], requires_grad=True)\n",
      "bias grad:  tensor([0.4620])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6051]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3812]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0949,  -322.8739,   -11.4268,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1533], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6433]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0949,  -322.8739,   -11.4268,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[3.2394e-03, 0.0000e+00, 4.9810e-05, 6.1202e-04, 4.6476e-04, 1.1431e-03,\n",
      "         4.4243e-02, 1.6590e-03, 3.7777e-02, 8.0495e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1533], requires_grad=True)\n",
      "bias grad:  tensor([0.2149])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6433]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2456]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0953,  -322.8740,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1555], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6678]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0953,  -322.8740,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3833e-03, 0.0000e+00, 3.3323e-05, 3.9051e-04, 4.4699e-04, 6.1061e-04,\n",
      "         3.2717e-02, 1.6736e-03, 2.7435e-02, 1.4536e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1555], requires_grad=True)\n",
      "bias grad:  tensor([0.1581])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6678]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1611]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0956,  -322.8740,   -11.4274,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1571], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6517]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0956,  -322.8740,   -11.4274,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0009, 0.0003, 0.0003, 0.0033, 0.0008, 0.0078, 0.2350, 0.0077, 0.1480,\n",
      "         0.0026]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1571], requires_grad=True)\n",
      "bias grad:  tensor([0.9111])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6517]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6871]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0980,  -322.8741,   -11.4289,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1662], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8204]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0980,  -322.8741,   -11.4289,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2690e-03,  0.0000e+00, -1.0847e-05, -3.3849e-04, -1.3595e-04,\n",
      "          2.7995e-04, -2.5078e-04, -7.6316e-05, -1.1359e-02, -1.0303e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1662], requires_grad=True)\n",
      "bias grad:  tensor([-0.0658])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8204]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3708]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0980,  -322.8741,   -11.4288,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1655], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7833]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0980,  -322.8741,   -11.4288,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.4095e-04,  3.0457e-05,  7.0088e-05,  8.6313e-04,  4.9273e-04,\n",
      "          8.2652e-04,  4.5780e-02,  2.3008e-03,  4.9898e-02,  1.5120e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1655], requires_grad=True)\n",
      "bias grad:  tensor([0.3028])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7833]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1128]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0984,  -322.8741,   -11.4293,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1686], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7946]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0984,  -322.8741,   -11.4293,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6099e-03, -5.2407e-05,  2.2310e-06,  9.8998e-06,  7.7524e-06,\n",
      "          4.5939e-05,  6.0075e-04,  6.7762e-04,  8.8382e-03,  1.0974e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1686], requires_grad=True)\n",
      "bias grad:  tensor([0.0472])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7946]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7067]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0985,  -322.8741,   -11.4294,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1690], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7239]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0985,  -322.8741,   -11.4294,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.9050e-04,  9.5659e-06,  5.4487e-05,  3.5750e-04,  8.0725e-05,\n",
      "          2.4049e-03,  5.8617e-02,  1.5070e-03,  2.9381e-02,  1.1556e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1690], requires_grad=True)\n",
      "bias grad:  tensor([0.1659])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7239]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2160]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0990,  -322.8741,   -11.4297,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1707], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7023]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0990,  -322.8741,   -11.4297,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.9087e-03, -2.7655e-05, -4.9218e-05, -8.1008e-04, -4.8279e-04,\n",
      "         -4.4288e-04, -3.3053e-02, -1.4064e-03, -3.6400e-02, -7.8613e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1707], requires_grad=True)\n",
      "bias grad:  tensor([-0.2140])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7023]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6129]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0987,  -322.8741,   -11.4293,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1685], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6411]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0987,  -322.8741,   -11.4293,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.0118e-04,  0.0000e+00, -1.7241e-05, -2.9545e-04, -6.2444e-05,\n",
      "         -6.4215e-05, -3.2578e-03, -9.5208e-04, -1.9347e-02, -5.1821e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1685], requires_grad=True)\n",
      "bias grad:  tensor([-0.1042])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6411]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1650]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0987,  -322.8741,   -11.4291,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1675], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6576]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0987,  -322.8741,   -11.4291,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.1201e-03, 1.9884e-05, 1.0089e-04, 1.2185e-03, 9.1415e-04, 1.4091e-03,\n",
      "         7.2188e-02, 3.6019e-03, 7.5553e-02, 2.7520e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1675], requires_grad=True)\n",
      "bias grad:  tensor([0.4496])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6576]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0006]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0994,  -322.8741,   -11.4299,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1720], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6576]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0994,  -322.8741,   -11.4299,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2600e-02,  0.0000e+00, -6.7353e-05, -1.4052e-03, -1.7594e-03,\n",
      "         -9.2696e-04, -4.2030e-02, -3.1674e-03, -7.3811e-02, -8.3456e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1720], requires_grad=True)\n",
      "bias grad:  tensor([-0.4168])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6576]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3260]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0990,  -322.8741,   -11.4292,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1678], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6250]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0990,  -322.8741,   -11.4292,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.0961e-03,  1.3023e-05,  3.3552e-05,  2.3868e-04, -8.4337e-05,\n",
      "          1.2670e-03,  2.9841e-02,  1.0778e-03,  1.6638e-02,  7.6621e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1678], requires_grad=True)\n",
      "bias grad:  tensor([0.1027])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6250]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0423]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0993,  -322.8741,   -11.4293,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1689], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6293]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.0993,  -322.8741,   -11.4293,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8964e-04,  0.0000e+00, -1.1985e-04, -7.7452e-04, -1.3118e-04,\n",
      "         -5.4591e-03, -1.4261e-01, -3.5126e-03, -6.3581e-02, -3.9340e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1689], requires_grad=True)\n",
      "bias grad:  tensor([-0.3942])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6293]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1607]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0979,  -322.8741,   -11.4287,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1649], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5132]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0979,  -322.8741,   -11.4287,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.2643e-03,  2.9634e-05, -2.0627e-05,  3.5479e-04,  7.3301e-04,\n",
      "         -3.3451e-03, -6.7717e-02, -2.9163e-04,  1.0065e-02, -7.7353e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1649], requires_grad=True)\n",
      "bias grad:  tensor([0.0392])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5132]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3070]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0972,  -322.8741,   -11.4288,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1653], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5439]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0972,  -322.8741,   -11.4288,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.4677e-03, -7.3303e-05, -5.4473e-05, -6.0043e-04,  3.6846e-05,\n",
      "         -1.9584e-03, -5.8401e-02, -1.2221e-03, -2.7336e-02,  1.5378e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1653], requires_grad=True)\n",
      "bias grad:  tensor([-0.1755])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5439]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9841]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0966,  -322.8741,   -11.4285,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1636], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4455]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0966,  -322.8741,   -11.4285,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.0677e-05, -1.9878e-04, -1.1740e-04, -8.6478e-04, -1.6421e-04,\n",
      "         -5.5780e-03, -1.3779e-01, -3.6461e-03, -6.1025e-02, -9.3013e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1636], requires_grad=True)\n",
      "bias grad:  tensor([-0.3835])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4455]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6408]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0952,  -322.8741,   -11.4279,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1597], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3814]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0952,  -322.8741,   -11.4279,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0060, 0.0000, 0.0002, 0.0029, 0.0007, 0.0017, 0.1057, 0.0052, 0.1496,\n",
      "         0.0028]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1597], requires_grad=True)\n",
      "bias grad:  tensor([0.8590])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3814]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.8957]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8741,   -11.4294,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1683], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7710]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8741,   -11.4294,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8504e-03,  1.7842e-05, -8.8440e-05, -1.3938e-03, -9.9127e-04,\n",
      "         -1.0903e-03, -6.3559e-02, -3.2884e-03, -7.3014e-02, -7.7291e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1683], requires_grad=True)\n",
      "bias grad:  tensor([-0.4243])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7710]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4200]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0956,  -322.8741,   -11.4287,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1641], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7290]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0956,  -322.8741,   -11.4287,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.9112e-03,  3.5034e-05,  4.5794e-05,  4.8713e-04,  1.4285e-04,\n",
      "          2.2344e-03,  5.5132e-02,  1.5441e-03,  2.6591e-02,  9.2528e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1641], requires_grad=True)\n",
      "bias grad:  tensor([0.1690])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7290]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0941]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8741,   -11.4289,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1658], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7384]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8741,   -11.4289,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0033, 0.0000, 0.0001, 0.0013, 0.0007, 0.0006, 0.0886, 0.0036, 0.0796,\n",
      "         0.0019]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1658], requires_grad=True)\n",
      "bias grad:  tensor([0.4593])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7384]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1086]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0971,  -322.8741,   -11.4297,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1703], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7275]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0971,  -322.8741,   -11.4297,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1971e-03,  0.0000e+00, -1.0966e-05, -3.4706e-04, -2.9358e-04,\n",
      "          1.6105e-04,  1.5448e-03, -4.7735e-04, -1.3636e-02,  2.5122e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1703], requires_grad=True)\n",
      "bias grad:  tensor([-0.0778])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7275]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3954]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0971,  -322.8741,   -11.4296,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1696], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6880]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0971,  -322.8741,   -11.4296,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.5516e-04,  6.6124e-05,  3.9158e-05,  4.0016e-04, -1.3822e-04,\n",
      "          8.9413e-04,  3.4350e-02,  1.3227e-03,  2.7297e-02,  7.7911e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1696], requires_grad=True)\n",
      "bias grad:  tensor([0.1580])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6880]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda grad:  tensor([[-0.1630]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0974,  -322.8741,   -11.4299,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1712], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7043]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0974,  -322.8741,   -11.4299,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.9071e-04, -1.1477e-04, -7.6307e-05, -9.1712e-04, -1.3218e-04,\n",
      "         -2.1413e-03, -6.4907e-02, -2.3460e-03, -4.9562e-02, -5.6363e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1712], requires_grad=True)\n",
      "bias grad:  tensor([-0.2823])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7043]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6455]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8741,   -11.4294,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1683], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6397]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8741,   -11.4294,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6293e-03,  0.0000e+00,  4.5692e-05,  5.0116e-04,  2.5620e-04,\n",
      "          4.2595e-04,  2.0793e-02,  1.6862e-03,  3.2073e-02,  9.1985e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1683], requires_grad=True)\n",
      "bias grad:  tensor([0.1871])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6397]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0093]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8741,   -11.4297,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1702], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6407]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8741,   -11.4297,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9299e-04,  1.4107e-05,  3.3846e-06, -1.4892e-04,  4.1308e-05,\n",
      "          1.5403e-03,  2.5345e-02,  2.3065e-04, -4.6770e-03,  5.8729e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1702], requires_grad=True)\n",
      "bias grad:  tensor([-0.0226])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6407]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3776]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0972,  -322.8741,   -11.4296,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1700], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6029]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0972,  -322.8741,   -11.4296,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[1.8541e-03, 3.4272e-05, 4.2076e-05, 4.4996e-04, 3.0573e-04, 2.1895e-03,\n",
      "         6.1029e-02, 1.6027e-03, 2.7328e-02, 1.0327e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1700], requires_grad=True)\n",
      "bias grad:  tensor([0.1636])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6029]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0434]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0979,  -322.8742,   -11.4299,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1716], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6072]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0979,  -322.8742,   -11.4299,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3949e-04, 3.1336e-05, 1.3362e-04, 1.3905e-03, 5.7678e-04, 1.9261e-03,\n",
      "         8.6624e-02, 3.7079e-03, 7.7763e-02, 2.1798e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1716], requires_grad=True)\n",
      "bias grad:  tensor([0.4880])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6072]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2592]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0987,  -322.8742,   -11.4307,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1765], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6331]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0987,  -322.8742,   -11.4307,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7987e-03, 0.0000e+00, 6.6408e-05, 7.8925e-04, 6.7507e-04, 9.5415e-04,\n",
      "         4.8085e-02, 2.3680e-03, 5.2445e-02, 1.7956e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1765], requires_grad=True)\n",
      "bias grad:  tensor([0.2986])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6331]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0766]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0992,  -322.8742,   -11.4312,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1795], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6408]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0992,  -322.8742,   -11.4312,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0883e-03, 0.0000e+00, 6.4832e-05, 7.2567e-04, 6.2367e-04, 1.0120e-03,\n",
      "         4.8807e-02, 2.3858e-03, 4.8898e-02, 1.4181e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1795], requires_grad=True)\n",
      "bias grad:  tensor([0.2778])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6408]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2414]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0997,  -322.8743,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1823], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6167]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0997,  -322.8743,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0010, 0.0003, 0.0003, 0.0031, 0.0007, 0.0079, 0.2255, 0.0070, 0.1332,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1823], requires_grad=True)\n",
      "bias grad:  tensor([0.8287])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6167]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.8637]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1019,  -322.8743,   -11.4330,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1905], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8030]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1019,  -322.8743,   -11.4330,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1714e-03,  0.0000e+00, -1.5753e-05, -3.6431e-04, -1.4712e-04,\n",
      "          1.3821e-04, -4.6622e-03, -2.6421e-04, -1.3713e-02, -1.7195e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1905], requires_grad=True)\n",
      "bias grad:  tensor([-0.0815])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8030]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3170]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1019,  -322.8743,   -11.4329,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1897], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7713]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1019,  -322.8743,   -11.4329,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.4883e-04,  4.4011e-05,  6.6802e-05,  8.4187e-04,  5.7559e-04,\n",
      "          7.9664e-04,  4.3779e-02,  2.2775e-03,  4.9221e-02,  1.5585e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1897], requires_grad=True)\n",
      "bias grad:  tensor([0.3004])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7713]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0234]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1023,  -322.8744,   -11.4334,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1927], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7737]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1023,  -322.8744,   -11.4334,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1731e-03, -3.2542e-05,  2.5477e-05,  3.1054e-04,  1.4740e-04,\n",
      "          4.5003e-04,  1.8652e-02,  1.4050e-03,  2.5863e-02,  1.4108e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1927], requires_grad=True)\n",
      "bias grad:  tensor([0.1447])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7737]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5703]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1025,  -322.8744,   -11.4337,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1942], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7166]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1025,  -322.8744,   -11.4337,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.4266e-04,  4.8481e-07,  3.8327e-05,  1.7517e-04, -6.4452e-05,\n",
      "          2.0653e-03,  4.5516e-02,  9.2474e-04,  1.7166e-02,  8.1771e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1942], requires_grad=True)\n",
      "bias grad:  tensor([0.0961])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7166]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1077]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1030,  -322.8744,   -11.4338,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1951], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7059]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1030,  -322.8744,   -11.4338,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.0275e-03, -2.9110e-05, -5.4898e-05, -9.3392e-04, -6.0663e-04,\n",
      "         -5.0680e-04, -3.6376e-02, -1.5636e-03, -4.1874e-02, -4.9633e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1951], requires_grad=True)\n",
      "bias grad:  tensor([-0.2453])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7059]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7607]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1026,  -322.8743,   -11.4334,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1927], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6298]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1026,  -322.8743,   -11.4334,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.8916e-05,  0.0000e+00, -1.8893e-05, -3.3722e-04, -1.1503e-04,\n",
      "         -8.0612e-05, -7.2183e-03, -1.1007e-03, -2.1725e-02, -5.9826e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1927], requires_grad=True)\n",
      "bias grad:  tensor([-0.1187])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6298]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1387]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1025,  -322.8743,   -11.4332,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1915], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6437]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1025,  -322.8743,   -11.4332,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4444e-03, 2.5381e-05, 8.0462e-05, 9.7192e-04, 7.3170e-04, 1.1034e-03,\n",
      "         5.7814e-02, 2.8861e-03, 6.0507e-02, 2.3331e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1915], requires_grad=True)\n",
      "bias grad:  tensor([0.3611])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6437]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0411]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1031,  -322.8744,   -11.4338,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1951], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6478]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1031,  -322.8744,   -11.4338,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2803e-02,  0.0000e+00, -5.3235e-05, -1.2373e-03, -1.5905e-03,\n",
      "         -7.9235e-04, -3.6004e-02, -2.6183e-03, -6.3333e-02, -6.7968e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1951], requires_grad=True)\n",
      "bias grad:  tensor([-0.3563])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6478]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3686]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1028,  -322.8743,   -11.4332,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1915], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6109]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1028,  -322.8743,   -11.4332,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.3736e-03,  1.3573e-05,  4.9121e-05,  4.3205e-04,  5.0036e-05,\n",
      "          1.4829e-03,  4.0620e-02,  1.6258e-03,  2.8457e-02,  1.0643e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1915], requires_grad=True)\n",
      "bias grad:  tensor([0.1712])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6109]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0582]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1032,  -322.8744,   -11.4334,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1933], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6167]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1032,  -322.8744,   -11.4334,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0911e-04,  0.0000e+00, -1.0933e-04, -6.4934e-04, -2.3947e-05,\n",
      "         -5.4303e-03, -1.3802e-01, -3.1939e-03, -5.4980e-02, -1.9679e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1933], requires_grad=True)\n",
      "bias grad:  tensor([-0.3463])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6167]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.2011]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1018,  -322.8743,   -11.4329,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1898], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4966]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1018,  -322.8743,   -11.4329,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.8438e-03,  3.2467e-05, -1.8022e-05,  4.3350e-04,  7.9256e-04,\n",
      "         -3.3127e-03, -6.6913e-02, -2.0541e-04,  1.3126e-02, -8.1523e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1898], requires_grad=True)\n",
      "bias grad:  tensor([0.0546])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4966]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.5379]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1011,  -322.8743,   -11.4330,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1903], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5504]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1011,  -322.8743,   -11.4330,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.8965e-03, -8.7218e-05, -7.4043e-05, -8.0945e-04, -8.1960e-05,\n",
      "         -2.5334e-03, -7.7674e-02, -1.8591e-03, -3.9376e-02, -1.5821e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1903], requires_grad=True)\n",
      "bias grad:  tensor([-0.2478])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5504]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.0702]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1003,  -322.8743,   -11.4326,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1879], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4434]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1003,  -322.8743,   -11.4326,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.0398e-04, -1.9405e-04, -6.5679e-05, -4.4621e-04,  7.6768e-05,\n",
      "         -3.9364e-03, -8.6998e-02, -1.9438e-03, -2.9900e-02, -3.3962e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1879], requires_grad=True)\n",
      "bias grad:  tensor([-0.1801])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4434]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6371]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0995,  -322.8743,   -11.4323,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1861], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3797]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0995,  -322.8743,   -11.4323,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0053, 0.0000, 0.0003, 0.0031, 0.0007, 0.0020, 0.1309, 0.0062, 0.1681,\n",
      "         0.0036]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1861], requires_grad=True)\n",
      "bias grad:  tensor([0.9633])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3797]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.4148]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1008,  -322.8743,   -11.4340,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1957], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7212]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1008,  -322.8743,   -11.4340,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.3790e-03,  1.4511e-05, -8.1015e-05, -1.2694e-03, -9.1246e-04,\n",
      "         -9.8095e-04, -5.9705e-02, -3.0100e-03, -6.6373e-02, -6.7566e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1957], requires_grad=True)\n",
      "bias grad:  tensor([-0.3859])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7212]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3694]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1002,  -322.8743,   -11.4334,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1918], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6842]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1002,  -322.8743,   -11.4334,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.1543e-04,  2.9081e-05,  6.1595e-05,  7.3679e-04,  3.2360e-04,\n",
      "          2.5883e-03,  6.8931e-02,  2.2164e-03,  3.7922e-02,  1.2438e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1918], requires_grad=True)\n",
      "bias grad:  tensor([0.2494])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6842]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2260]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1009,  -322.8743,   -11.4337,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1943], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7068]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1009,  -322.8743,   -11.4337,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[3.0716e-03, 0.0000e+00, 8.7943e-05, 1.0631e-03, 6.4779e-04, 4.2829e-04,\n",
      "         7.9458e-02, 3.1231e-03, 6.7484e-02, 1.7909e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1943], requires_grad=True)\n",
      "bias grad:  tensor([0.3887])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7068]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1262]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1017,  -322.8744,   -11.4344,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1982], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6942]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1017,  -322.8744,   -11.4344,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4069e-03,  0.0000e+00, -2.2775e-05, -5.1566e-04, -4.2391e-04,\n",
      "          1.0118e-04, -5.8508e-03, -9.7446e-04, -2.3641e-02,  1.3837e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1982], requires_grad=True)\n",
      "bias grad:  tensor([-0.1347])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6942]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3825]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1016,  -322.8744,   -11.4342,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1969], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6560]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1016,  -322.8744,   -11.4342,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.3772e-05,  7.0696e-05,  1.8224e-05,  1.2528e-04, -3.4841e-04,\n",
      "          4.1929e-04,  1.5958e-02,  4.9956e-04,  1.0615e-02,  4.3418e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1969], requires_grad=True)\n",
      "bias grad:  tensor([0.0615])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6560]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1763]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1018,  -322.8744,   -11.4343,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1975], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6736]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1018,  -322.8744,   -11.4343,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.2415e-04, -9.7705e-05, -7.7005e-05, -9.2394e-04, -1.0937e-04,\n",
      "         -2.2945e-03, -6.8022e-02, -2.2968e-03, -4.8762e-02, -4.0306e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1975], requires_grad=True)\n",
      "bias grad:  tensor([-0.2783])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6736]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6895]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1011,  -322.8743,   -11.4338,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1947], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6046]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1011,  -322.8743,   -11.4338,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9829e-03,  0.0000e+00,  5.5544e-05,  6.2253e-04,  2.6568e-04,\n",
      "          4.5004e-04,  2.7484e-02,  2.0465e-03,  3.9817e-02,  1.1319e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1947], requires_grad=True)\n",
      "bias grad:  tensor([0.2309])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6046]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0458]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1014,  -322.8744,   -11.4342,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1970], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6092]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1014,  -322.8744,   -11.4342,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.6688e-04,  1.3577e-05, -1.7343e-06, -1.7484e-04, -3.3261e-05,\n",
      "          1.2452e-03,  1.9063e-02,  8.1552e-05, -7.1870e-03,  4.8123e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1970], requires_grad=True)\n",
      "bias grad:  tensor([-0.0361])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6092]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3186]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1016,  -322.8744,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1966], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5774]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1016,  -322.8744,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[2.9676e-04, 3.5870e-05, 4.9418e-05, 5.0314e-04, 1.8221e-04, 2.3356e-03,\n",
      "         6.3834e-02, 1.6100e-03, 3.0636e-02, 9.8476e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1966], requires_grad=True)\n",
      "bias grad:  tensor([0.1755])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5774]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2664]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1022,  -322.8744,   -11.4344,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1984], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6040]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1022,  -322.8744,   -11.4344,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7199e-04, 2.5980e-05, 1.0497e-04, 1.0700e-03, 4.2318e-04, 1.5092e-03,\n",
      "         6.8643e-02, 2.8625e-03, 5.9401e-02, 1.6732e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1984], requires_grad=True)\n",
      "bias grad:  tensor([0.3745])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6040]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2196]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1029,  -322.8744,   -11.4350,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2021], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6260]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1029,  -322.8744,   -11.4350,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7415e-03, 0.0000e+00, 8.4650e-05, 1.0360e-03, 7.9101e-04, 1.0853e-03,\n",
      "         5.8213e-02, 2.9231e-03, 6.6157e-02, 2.0149e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2021], requires_grad=True)\n",
      "bias grad:  tensor([0.3775])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6260]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1820]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1035,  -322.8745,   -11.4357,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2059], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6442]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1035,  -322.8745,   -11.4357,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.8804e-03,  0.0000e+00,  6.7761e-06, -3.8846e-05,  7.9498e-05,\n",
      "          4.7795e-04,  1.5995e-02,  5.8902e-04,  3.9150e-03, -1.4775e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2059], requires_grad=True)\n",
      "bias grad:  tensor([0.0223])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6442]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3362]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1036,  -322.8745,   -11.4357,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2061], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6105]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1036,  -322.8745,   -11.4357,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0007, 0.0003, 0.0003, 0.0030, 0.0007, 0.0077, 0.2212, 0.0069, 0.1292,\n",
      "         0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2061], requires_grad=True)\n",
      "bias grad:  tensor([0.8048])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6105]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.7485]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1058,  -322.8745,   -11.4370,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2142], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7854]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1058,  -322.8745,   -11.4370,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.5405e-03,  0.0000e+00, -2.2888e-05, -4.9638e-04, -2.5605e-04,\n",
      "          1.9124e-04, -8.5469e-03, -5.8193e-04, -2.0649e-02, -2.7236e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2142], requires_grad=True)\n",
      "bias grad:  tensor([-0.1216])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7854]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3454]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1057,  -322.8745,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2130], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7508]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1057,  -322.8745,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0154e-03,  2.8662e-05,  5.1000e-05,  6.3195e-04,  4.7989e-04,\n",
      "          5.9763e-04,  3.1641e-02,  1.6923e-03,  3.7645e-02,  1.2705e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2130], requires_grad=True)\n",
      "bias grad:  tensor([0.2296])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7508]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0330]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1061,  -322.8745,   -11.4372,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2153], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7541]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1061,  -322.8745,   -11.4372,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0479e-03, -3.1678e-05,  2.6376e-05,  3.1681e-04,  1.5362e-04,\n",
      "          5.5613e-04,  2.1342e-02,  1.4197e-03,  2.5778e-02,  1.3461e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2153], requires_grad=True)\n",
      "bias grad:  tensor([0.1447])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7541]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5242]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1063,  -322.8745,   -11.4374,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2167], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7017]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1063,  -322.8745,   -11.4374,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[5.0956e-04, 4.0801e-06, 4.3452e-05, 2.9204e-04, 7.7681e-05, 1.9722e-03,\n",
      "         4.6300e-02, 1.1577e-03, 2.3438e-02, 8.7944e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2167], requires_grad=True)\n",
      "bias grad:  tensor([0.1321])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7017]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0671]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1067,  -322.8745,   -11.4377,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2180], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6950]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1067,  -322.8745,   -11.4377,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.4294e-03, -2.1506e-05, -4.2193e-05, -7.6476e-04, -5.3526e-04,\n",
      "         -4.0277e-04, -2.6788e-02, -1.2412e-03, -3.3644e-02,  6.5921e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2180], requires_grad=True)\n",
      "bias grad:  tensor([-0.1939])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6950]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6298]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1065,  -322.8745,   -11.4373,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2161], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6320]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1065,  -322.8745,   -11.4373,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.4181e-04,  0.0000e+00,  3.1981e-06, -1.7702e-05,  5.8180e-05,\n",
      "          7.3861e-05,  6.4611e-03, -2.7669e-04, -3.2822e-03, -2.1987e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2161], requires_grad=True)\n",
      "bias grad:  tensor([-0.0132])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6320]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2342]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1065,  -322.8745,   -11.4373,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2160], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6555]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1065,  -322.8745,   -11.4373,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[3.8821e-03, 2.5652e-05, 9.4919e-05, 1.1349e-03, 8.0229e-04, 1.4415e-03,\n",
      "         6.7348e-02, 3.3071e-03, 6.9863e-02, 2.5549e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2160], requires_grad=True)\n",
      "bias grad:  tensor([0.4164])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6555]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0835]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1072,  -322.8746,   -11.4380,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2201], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6638]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1072,  -322.8746,   -11.4380,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5078e-02,  0.0000e+00, -2.0403e-05, -6.3666e-04, -8.6616e-04,\n",
      "         -3.8026e-04, -1.7371e-02, -1.1509e-03, -3.0681e-02, -2.8622e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2201], requires_grad=True)\n",
      "bias grad:  tensor([-0.1710])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6638]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2587]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1070,  -322.8746,   -11.4377,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2184], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6379]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1070,  -322.8746,   -11.4377,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.9890e-03,  1.8080e-05,  2.9457e-05,  1.6711e-04, -9.3464e-05,\n",
      "          1.1477e-03,  2.7010e-02,  9.3894e-04,  1.3725e-02,  7.4574e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2184], requires_grad=True)\n",
      "bias grad:  tensor([0.0847])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6379]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0305]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1073,  -322.8746,   -11.4378,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2193], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6349]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1073,  -322.8746,   -11.4378,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1238e-03,  0.0000e+00, -1.2011e-04, -7.9402e-04, -1.6338e-04,\n",
      "         -5.4650e-03, -1.4276e-01, -3.5804e-03, -6.4449e-02, -3.9670e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2193], requires_grad=True)\n",
      "bias grad:  tensor([-0.4005])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6349]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1099]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1059,  -322.8745,   -11.4372,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2153], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5239]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1059,  -322.8745,   -11.4372,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1315e-03,  2.7017e-05, -3.3196e-05,  1.7397e-04,  6.5480e-04,\n",
      "         -3.7391e-03, -7.9383e-02, -7.2628e-04,  1.3514e-03, -8.3800e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2153], requires_grad=True)\n",
      "bias grad:  tensor([-0.0151])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5239]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1533]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1051,  -322.8745,   -11.4372,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2151], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5392]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1051,  -322.8745,   -11.4372,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.0166e-03, -6.9544e-05, -6.3074e-05, -6.1093e-04,  5.1288e-05,\n",
      "         -2.4864e-03, -6.9658e-02, -1.4219e-03, -2.9065e-02, -3.6051e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2151], requires_grad=True)\n",
      "bias grad:  tensor([-0.1882])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5392]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8270]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1044,  -322.8745,   -11.4369,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2132], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4565]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1044,  -322.8745,   -11.4369,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.3032e-04, -1.9826e-04, -9.3244e-05, -8.5721e-04, -2.2821e-04,\n",
      "         -4.3584e-03, -1.0744e-01, -3.0279e-03, -5.2364e-02, -7.9267e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2132], requires_grad=True)\n",
      "bias grad:  tensor([-0.3214])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4565]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7463]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1033,  -322.8745,   -11.4364,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2100], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3819]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1033,  -322.8745,   -11.4364,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0055, 0.0000, 0.0003, 0.0031, 0.0007, 0.0019, 0.1252, 0.0061, 0.1636,\n",
      "         0.0035]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2100], requires_grad=True)\n",
      "bias grad:  tensor([0.9376])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3819]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.3696]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1046,  -322.8746,   -11.4380,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2194], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7189]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1046,  -322.8746,   -11.4380,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6311e-03,  2.8964e-05, -8.6080e-05, -1.3370e-03, -9.5377e-04,\n",
      "         -1.0691e-03, -6.3094e-02, -3.1990e-03, -7.0615e-02, -7.2492e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2194], requires_grad=True)\n",
      "bias grad:  tensor([-0.4092])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7189]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3644]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1039,  -322.8745,   -11.4373,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2153], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6824]], requires_grad=True)\n",
      "Iteration 16 | Score: 0.376995712518692\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8737,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5714e-03,  3.5375e-05,  5.0488e-05,  5.8534e-04,  2.5932e-04,\n",
      "          2.2665e-03,  5.7940e-02,  1.7617e-03,  3.1096e-02,  1.0107e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1246], requires_grad=True)\n",
      "bias grad:  tensor([0.2012])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7845]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1864]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0910,  -322.8737,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1266], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8031]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0910,  -322.8737,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[2.6819e-03, 0.0000e+00, 5.8728e-05, 8.0790e-04, 5.5340e-04, 2.7887e-04,\n",
      "         3.6649e-02, 2.1831e-03, 4.9605e-02, 1.0491e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1266], requires_grad=True)\n",
      "bias grad:  tensor([0.2885])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8031]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0349]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8738,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1295], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7997]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8738,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9289e-03,  0.0000e+00, -3.3872e-06, -2.5330e-04, -2.1331e-04,\n",
      "          2.6475e-04,  6.2515e-03, -2.1027e-04, -7.3368e-03,  4.1448e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1295], requires_grad=True)\n",
      "bias grad:  tensor([-0.0420])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7997]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4639]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8738,   -11.4227,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1291], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7533]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8738,   -11.4227,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2475e-04,  4.5681e-05,  2.1979e-05,  1.4817e-04, -2.9235e-04,\n",
      "          5.8030e-04,  2.1620e-02,  6.5086e-04,  1.3441e-02,  5.1965e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1291], requires_grad=True)\n",
      "bias grad:  tensor([0.0770])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7533]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0467]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0917,  -322.8738,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1299], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7579]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0917,  -322.8738,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.5848e-04, -1.4780e-04, -8.7993e-05, -1.0605e-03, -9.2253e-05,\n",
      "         -2.4688e-03, -7.6335e-02, -2.5188e-03, -5.4387e-02, -4.5861e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1299], requires_grad=True)\n",
      "bias grad:  tensor([-0.3103])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7579]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.0042]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8737,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1268], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6575]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8737,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2445e-03,  0.0000e+00,  6.8454e-05,  7.0208e-04,  3.7150e-04,\n",
      "          9.7504e-04,  4.1341e-02,  2.3730e-03,  4.4400e-02,  1.3658e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1268], requires_grad=True)\n",
      "bias grad:  tensor([0.2689])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6575]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0507]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0913,  -322.8738,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1295], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6524]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0913,  -322.8738,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[1.3628e-03, 1.8841e-05, 1.2890e-05, 3.2711e-05, 2.4037e-04, 1.4097e-03,\n",
      "         3.0771e-02, 6.8471e-04, 5.9802e-03, 8.8023e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1295], requires_grad=True)\n",
      "bias grad:  tensor([0.0432])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6524]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4589]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0916,  -322.8738,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1299], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6066]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0916,  -322.8738,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[2.5429e-03, 3.7666e-05, 4.6376e-05, 4.9244e-04, 2.7490e-04, 2.1624e-03,\n",
      "         5.8236e-02, 1.4641e-03, 2.7159e-02, 9.9352e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1299], requires_grad=True)\n",
      "bias grad:  tensor([0.1649])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6066]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2417]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0922,  -322.8738,   -11.4231,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1315], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6307]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0922,  -322.8738,   -11.4231,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[1.9803e-04, 3.4240e-05, 1.0877e-04, 1.1227e-03, 4.4834e-04, 1.6559e-03,\n",
      "         7.1989e-02, 2.9762e-03, 6.2519e-02, 1.7524e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1315], requires_grad=True)\n",
      "bias grad:  tensor([0.3921])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6307]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2496]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0929,  -322.8738,   -11.4237,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1355], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6557]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0929,  -322.8738,   -11.4237,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1403e-03, 0.0000e+00, 8.7482e-05, 1.0487e-03, 8.2710e-04, 1.2681e-03,\n",
      "         6.2194e-02, 3.1755e-03, 6.8803e-02, 2.2322e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1355], requires_grad=True)\n",
      "bias grad:  tensor([0.3932])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6557]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0772]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0935,  -322.8738,   -11.4244,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1394], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6634]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0935,  -322.8738,   -11.4244,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[2.3193e-03, 0.0000e+00, 3.1747e-05, 2.8992e-04, 3.2818e-04, 5.2194e-04,\n",
      "         2.7841e-02, 1.4355e-03, 2.4185e-02, 4.0397e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1394], requires_grad=True)\n",
      "bias grad:  tensor([0.1381])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6634]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3512]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0938,  -322.8738,   -11.4247,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1408], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6283]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0938,  -322.8738,   -11.4247,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0014, 0.0003, 0.0003, 0.0032, 0.0008, 0.0079, 0.2335, 0.0074, 0.1433,\n",
      "         0.0023]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1408], requires_grad=True)\n",
      "bias grad:  tensor([0.8858])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6283]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.8133]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1496], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8096]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8690e-03,  0.0000e+00,  5.3639e-06, -1.6813e-04, -2.5285e-05,\n",
      "          5.7123e-04,  1.1061e-02,  4.1218e-04, -8.1637e-04,  9.1035e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1496], requires_grad=True)\n",
      "bias grad:  tensor([-0.0044])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8096]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3535]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1496], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7743]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2846e-04,  3.5951e-05,  5.5759e-05,  7.1680e-04,  4.6065e-04,\n",
      "          7.0532e-04,  3.6975e-02,  1.8616e-03,  4.1049e-02,  1.1858e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1496], requires_grad=True)\n",
      "bias grad:  tensor([0.2494])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7743]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1402]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0966,  -322.8739,   -11.4265,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1521], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7883]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0966,  -322.8739,   -11.4265,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7722e-03, -5.3706e-05,  1.9591e-05,  2.0406e-04,  7.0055e-05,\n",
      "          3.7456e-04,  1.4687e-02,  1.2839e-03,  2.1671e-02,  1.4387e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1521], requires_grad=True)\n",
      "bias grad:  tensor([0.1194])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7883]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7090]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8739,   -11.4267,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1533], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7174]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8739,   -11.4267,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3701e-04, 1.0106e-05, 6.1640e-05, 4.6485e-04, 1.0755e-04, 2.5144e-03,\n",
      "         6.0466e-02, 1.7089e-03, 3.4592e-02, 1.2019e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1533], requires_grad=True)\n",
      "bias grad:  tensor([0.1955])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7174]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0875]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0974,  -322.8740,   -11.4271,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1552], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7086]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0974,  -322.8740,   -11.4271,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2114e-03, -3.5787e-05, -4.8046e-05, -8.5538e-04, -6.1050e-04,\n",
      "         -4.4401e-04, -3.0812e-02, -1.4813e-03, -3.9214e-02, -7.2523e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1552], requires_grad=True)\n",
      "bias grad:  tensor([-0.2272])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7086]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6464]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0971,  -322.8740,   -11.4267,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1530], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6440]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0971,  -322.8740,   -11.4267,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.4980e-03,  0.0000e+00, -1.4980e-06, -7.7870e-05,  6.6139e-05,\n",
      "          4.5478e-05,  6.0470e-03, -5.2342e-04, -7.5757e-03, -2.9207e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1530], requires_grad=True)\n",
      "bias grad:  tensor([-0.0340])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6440]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2445]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0971,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1526], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6684]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0971,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[4.3646e-03, 2.7605e-05, 9.1881e-05, 1.1519e-03, 8.8739e-04, 1.3020e-03,\n",
      "         6.6585e-02, 3.3460e-03, 7.1164e-02, 2.4951e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1526], requires_grad=True)\n",
      "bias grad:  tensor([0.4230])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6684]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0563]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0978,  -322.8740,   -11.4273,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1568], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6741]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0978,  -322.8740,   -11.4273,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9530e-02,  0.0000e+00, -6.9424e-05, -1.3519e-03, -1.6611e-03,\n",
      "         -9.0998e-04, -4.1201e-02, -3.1772e-03, -7.2275e-02, -8.4495e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1568], requires_grad=True)\n",
      "bias grad:  tensor([-0.4092])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6741]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2109]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0974,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1528], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6530]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0974,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.6780e-03,  1.2181e-05,  2.1077e-05,  6.1115e-05, -2.2833e-04,\n",
      "          9.4074e-04,  1.9225e-02,  6.1071e-04,  6.8698e-03,  5.8107e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1528], requires_grad=True)\n",
      "bias grad:  tensor([0.0460])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6530]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0485]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0976,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1532], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6481]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0976,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.9761e-04,  0.0000e+00, -1.0151e-04, -5.7099e-04,  6.8686e-06,\n",
      "         -5.2514e-03, -1.3130e-01, -2.9360e-03, -4.9829e-02,  4.9767e-05]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias before:  Parameter containing:\n",
      "tensor([-0.1532], requires_grad=True)\n",
      "bias grad:  tensor([-0.3156])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6481]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.2274]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8739,   -11.4262,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1501], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5254]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8739,   -11.4262,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.3272e-03,  2.4250e-05, -5.2482e-06,  4.9274e-04,  8.3341e-04,\n",
      "         -3.2167e-03, -5.7333e-02,  2.0529e-04,  2.0240e-02, -2.8113e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1501], requires_grad=True)\n",
      "bias grad:  tensor([0.1016])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5254]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1132]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0957,  -322.8739,   -11.4264,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1511], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5367]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0957,  -322.8739,   -11.4264,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.1370e-03, -4.7843e-05, -2.0666e-05, -2.0075e-04,  1.9366e-04,\n",
      "         -1.1690e-03, -3.3083e-02, -9.8935e-05, -4.5165e-03,  4.9479e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1511], requires_grad=True)\n",
      "bias grad:  tensor([-0.0441])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5367]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7332]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0954,  -322.8739,   -11.4263,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1506], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4634]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0954,  -322.8739,   -11.4263,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.8980e-04, -2.0441e-04, -5.0463e-05, -3.4455e-04,  1.1603e-04,\n",
      "         -4.1154e-03, -8.5166e-02, -1.4944e-03, -1.8842e-02,  1.3100e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1506], requires_grad=True)\n",
      "bias grad:  tensor([-0.1297])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4634]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8074]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0945,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1493], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3827]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0945,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0051, 0.0000, 0.0002, 0.0027, 0.0005, 0.0016, 0.1017, 0.0050, 0.1391,\n",
      "         0.0029]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1493], requires_grad=True)\n",
      "bias grad:  tensor([0.7980])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3827]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.4348]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0955,  -322.8740,   -11.4275,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1573], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7262]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0955,  -322.8740,   -11.4275,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.0833e-03,  1.4827e-05, -7.0745e-05, -1.1526e-03, -8.2324e-04,\n",
      "         -8.0309e-04, -5.1265e-02, -2.6076e-03, -5.8667e-02, -4.9905e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1573], requires_grad=True)\n",
      "bias grad:  tensor([-0.3402])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7262]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3893]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0950,  -322.8740,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1539], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6872]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0950,  -322.8740,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3369e-03,  3.8075e-05,  8.6180e-05,  9.9543e-04,  4.4206e-04,\n",
      "          3.1027e-03,  8.7222e-02,  3.0992e-03,  5.1924e-02,  1.7541e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1539], requires_grad=True)\n",
      "bias grad:  tensor([0.3438])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6872]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2719]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0959,  -322.8740,   -11.4274,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1573], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7144]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0959,  -322.8740,   -11.4274,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8001e-03, 0.0000e+00, 8.3491e-05, 1.0054e-03, 5.6507e-04, 3.8573e-04,\n",
      "         7.6334e-02, 2.9233e-03, 6.3558e-02, 1.6422e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1573], requires_grad=True)\n",
      "bias grad:  tensor([0.3660])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7144]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1134]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0967,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1610], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7031]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0967,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.9047e-05,  0.0000e+00, -6.1624e-06, -2.4147e-04, -2.0272e-04,\n",
      "          2.0658e-04,  2.2576e-03, -2.8308e-04, -8.9963e-03,  2.4751e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1610], requires_grad=True)\n",
      "bias grad:  tensor([-0.0515])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7031]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2519]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0967,  -322.8740,   -11.4280,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1605], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6779]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0967,  -322.8740,   -11.4280,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1724e-04,  6.4333e-05,  2.0741e-05,  1.6405e-04, -3.1735e-04,\n",
      "          5.3143e-04,  2.0407e-02,  6.2746e-04,  1.2583e-02,  4.0948e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1605], requires_grad=True)\n",
      "bias grad:  tensor([0.0729])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6779]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1833]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0969,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1612], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6962]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0969,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.3357e-04, -1.0909e-04, -7.7530e-05, -9.4645e-04, -1.6078e-04,\n",
      "         -2.2590e-03, -6.7466e-02, -2.3834e-03, -5.0249e-02, -4.5216e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1612], requires_grad=True)\n",
      "bias grad:  tensor([-0.2872])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6962]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7551]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8740,   -11.4276,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1584], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6207]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8740,   -11.4276,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1371e-03,  0.0000e+00,  4.6164e-05,  5.4623e-04,  2.5869e-04,\n",
      "          4.1856e-04,  2.3276e-02,  1.7094e-03,  3.4280e-02,  8.5283e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1584], requires_grad=True)\n",
      "bias grad:  tensor([0.1991])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6207]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1011]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0964,  -322.8740,   -11.4280,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1603], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6308]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0964,  -322.8740,   -11.4280,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[8.7374e-04, 2.0017e-05, 2.1724e-05, 1.3451e-04, 2.0977e-04, 1.6347e-03,\n",
      "         3.8825e-02, 9.0843e-04, 1.1085e-02, 9.7560e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1603], requires_grad=True)\n",
      "bias grad:  tensor([0.0706])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6308]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3174]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1610], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5991]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0968,  -322.8740,   -11.4281,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7264e-03, 3.3628e-05, 4.7931e-05, 4.9014e-04, 2.7633e-04, 2.2556e-03,\n",
      "         6.2755e-02, 1.6311e-03, 2.8811e-02, 1.0035e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1610], requires_grad=True)\n",
      "bias grad:  tensor([0.1727])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5991]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1609]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0975,  -322.8741,   -11.4284,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1628], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6151]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0975,  -322.8741,   -11.4284,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8668e-04, 4.3836e-05, 1.1944e-04, 1.2673e-03, 5.2724e-04, 1.8292e-03,\n",
      "         7.8858e-02, 3.4005e-03, 7.1064e-02, 1.9967e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1628], requires_grad=True)\n",
      "bias grad:  tensor([0.4425])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6151]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2389]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0982,  -322.8741,   -11.4291,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1672], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6390]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0982,  -322.8741,   -11.4291,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4914e-03, 0.0000e+00, 4.2528e-05, 5.1141e-04, 4.4590e-04, 8.3000e-04,\n",
      "         3.6561e-02, 1.4002e-03, 3.2776e-02, 6.7044e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1672], requires_grad=True)\n",
      "bias grad:  tensor([0.1851])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6390]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1969]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0986,  -322.8741,   -11.4294,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1691], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6587]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0986,  -322.8741,   -11.4294,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.5745e-03, 0.0000e+00, 3.2671e-05, 3.5249e-04, 5.5636e-04, 4.2711e-04,\n",
      "         3.0935e-02, 1.7561e-03, 2.7971e-02, 1.9058e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1691], requires_grad=True)\n",
      "bias grad:  tensor([0.1624])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6587]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3474]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0989,  -322.8741,   -11.4297,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1707], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6240]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0989,  -322.8741,   -11.4297,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0012, 0.0003, 0.0003, 0.0031, 0.0007, 0.0077, 0.2236, 0.0070, 0.1322,\n",
      "         0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1707], requires_grad=True)\n",
      "bias grad:  tensor([0.8220])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6240]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.8006]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1012,  -322.8742,   -11.4310,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1789], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8040]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1012,  -322.8742,   -11.4310,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0012e-03,  0.0000e+00, -2.9640e-07, -2.2356e-04, -5.9228e-05,\n",
      "          5.6990e-04,  8.9523e-03,  2.2869e-04, -4.4191e-03,  4.9326e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1789], requires_grad=True)\n",
      "bias grad:  tensor([-0.0245])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8040]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3495]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1012,  -322.8742,   -11.4309,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1786], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7691]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1012,  -322.8742,   -11.4309,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.3548e-04,  3.7727e-05,  6.5886e-05,  8.3865e-04,  5.6737e-04,\n",
      "          7.7390e-04,  4.2738e-02,  2.2327e-03,  4.9579e-02,  1.5356e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1786], requires_grad=True)\n",
      "bias grad:  tensor([0.2976])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7691]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0761]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1017,  -322.8742,   -11.4314,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1816], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7767]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1017,  -322.8742,   -11.4314,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1863e-03, -2.6152e-05,  1.6522e-05,  1.5612e-04, -2.1549e-05,\n",
      "          5.0477e-04,  1.7034e-02,  1.0215e-03,  1.6441e-02,  1.1734e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1816], requires_grad=True)\n",
      "bias grad:  tensor([0.0911])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7767]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5360]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1018,  -322.8742,   -11.4316,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1825], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7231]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1018,  -322.8742,   -11.4316,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[6.2267e-04, 4.9097e-06, 4.2382e-05, 2.7098e-04, 5.8659e-05, 1.9851e-03,\n",
      "         4.5527e-02, 1.1756e-03, 2.3133e-02, 9.2130e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1825], requires_grad=True)\n",
      "bias grad:  tensor([0.1300])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7231]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1461]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1023,  -322.8742,   -11.4318,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1838], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7085]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1023,  -322.8742,   -11.4318,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7281e-03, -2.6034e-05, -4.8666e-05, -8.4492e-04, -5.7895e-04,\n",
      "         -4.5701e-04, -3.4161e-02, -1.4539e-03, -3.7933e-02, -1.1070e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1838], requires_grad=True)\n",
      "bias grad:  tensor([-0.2223])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7085]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6522]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1020,  -322.8742,   -11.4315,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1816], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6433]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1020,  -322.8742,   -11.4315,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.9646e-04,  0.0000e+00, -2.9460e-05, -4.7150e-04, -1.7418e-04,\n",
      "         -1.7165e-04, -1.1937e-02, -1.3534e-03, -2.8856e-02, -7.4415e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1816], requires_grad=True)\n",
      "bias grad:  tensor([-0.1612])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6433]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1301]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1018,  -322.8742,   -11.4312,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1800], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6563]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1018,  -322.8742,   -11.4312,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[4.1130e-03, 2.6176e-05, 9.8576e-05, 1.2252e-03, 9.4910e-04, 1.2418e-03,\n",
      "         6.9124e-02, 3.6115e-03, 7.6608e-02, 2.6561e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1800], requires_grad=True)\n",
      "bias grad:  tensor([0.4536])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6563]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0035]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1025,  -322.8742,   -11.4319,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1845], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6559]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1025,  -322.8742,   -11.4319,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1174e-02,  0.0000e+00, -5.5270e-05, -1.2205e-03, -1.5501e-03,\n",
      "         -7.9242e-04, -3.5971e-02, -2.6603e-03, -6.3226e-02, -6.9551e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1845], requires_grad=True)\n",
      "bias grad:  tensor([-0.3563])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6559]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3420]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1022,  -322.8742,   -11.4313,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1810], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6217]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1022,  -322.8742,   -11.4313,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.1894e-03,  1.5871e-05,  4.6580e-05,  3.8377e-04,  4.3018e-05,\n",
      "          1.3285e-03,  3.7762e-02,  1.5435e-03,  2.6657e-02,  1.0691e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1810], requires_grad=True)\n",
      "bias grad:  tensor([0.1608])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6217]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0463]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1025,  -322.8742,   -11.4316,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1826], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6171]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1025,  -322.8742,   -11.4316,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.1418e-04,  0.0000e+00, -1.1592e-04, -7.1165e-04, -9.7638e-05,\n",
      "         -5.4852e-03, -1.4168e-01, -3.3581e-03, -5.9936e-02, -2.9131e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1826], requires_grad=True)\n",
      "bias grad:  tensor([-0.3738])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6171]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1565]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1011,  -322.8742,   -11.4310,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1788], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5015]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1011,  -322.8742,   -11.4310,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.3282e-03,  3.2058e-05, -9.3335e-06,  4.9689e-04,  8.3442e-04,\n",
      "         -3.3395e-03, -6.1847e-02,  8.4795e-05,  1.8444e-02, -4.7947e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1788], requires_grad=True)\n",
      "bias grad:  tensor([0.0923])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5015]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3732]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1005,  -322.8742,   -11.4312,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1798], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5388]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1005,  -322.8742,   -11.4312,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.2055e-03, -6.1335e-05, -5.1499e-05, -5.9371e-04, -7.5920e-05,\n",
      "         -1.8679e-03, -5.8538e-02, -1.2516e-03, -2.7134e-02,  9.8315e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1798], requires_grad=True)\n",
      "bias grad:  tensor([-0.1766])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5388]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8615]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0999,  -322.8742,   -11.4309,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1780], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4526]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0999,  -322.8742,   -11.4309,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.2907e-04, -2.0305e-04, -8.6255e-05, -7.5155e-04, -1.6384e-04,\n",
      "         -4.3550e-03, -1.0591e-01, -2.7023e-03, -4.5886e-02, -6.5296e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1780], requires_grad=True)\n",
      "bias grad:  tensor([-0.2854])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4526]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7085]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0989,  -322.8742,   -11.4304,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1751], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3818]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0989,  -322.8742,   -11.4304,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0056, 0.0000, 0.0003, 0.0032, 0.0008, 0.0020, 0.1366, 0.0065, 0.1751,\n",
      "         0.0038]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1751], requires_grad=True)\n",
      "bias grad:  tensor([1.0029])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3818]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.2878]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1002,  -322.8742,   -11.4322,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1852], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7106]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1002,  -322.8742,   -11.4322,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.9758e-03,  2.2071e-05, -9.6043e-05, -1.4658e-03, -1.0492e-03,\n",
      "         -1.2639e-03, -7.2882e-02, -3.5875e-03, -7.7937e-02, -9.0735e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1852], requires_grad=True)\n",
      "bias grad:  tensor([-0.4542])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7106]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3338]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0995,  -322.8742,   -11.4314,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1806], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6772]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0995,  -322.8742,   -11.4314,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1643e-03,  3.3330e-05,  4.5228e-05,  5.0672e-04,  1.9821e-04,\n",
      "          2.2307e-03,  5.4119e-02,  1.5753e-03,  2.6982e-02,  9.1822e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1806], requires_grad=True)\n",
      "bias grad:  tensor([0.1751])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6772]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1965]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1000,  -322.8742,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1824], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6968]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1000,  -322.8742,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0034, 0.0000, 0.0001, 0.0013, 0.0008, 0.0006, 0.0900, 0.0037, 0.0807,\n",
      "         0.0021]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1824], requires_grad=True)\n",
      "bias grad:  tensor([0.4654])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6968]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1512]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1009,  -322.8743,   -11.4325,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1870], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6817]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1009,  -322.8743,   -11.4325,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1526e-03,  0.0000e+00, -9.7501e-06, -2.9839e-04, -2.4359e-04,\n",
      "          1.8342e-04,  2.4372e-03, -4.0871e-04, -1.1475e-02,  2.3437e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1870], requires_grad=True)\n",
      "bias grad:  tensor([-0.0655])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6817]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3552]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1010,  -322.8743,   -11.4324,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1864], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6462]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1010,  -322.8743,   -11.4324,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.0392e-04,  6.5867e-05,  2.5678e-05,  2.5564e-04, -2.3244e-04,\n",
      "          5.7936e-04,  2.4003e-02,  8.2342e-04,  1.7408e-02,  5.0213e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1864], requires_grad=True)\n",
      "bias grad:  tensor([0.1005])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6462]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2187]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1012,  -322.8743,   -11.4325,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1874], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6680]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1012,  -322.8743,   -11.4325,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.4515e-04, -7.8700e-05, -4.6011e-05, -5.5194e-04, -1.2552e-05,\n",
      "         -1.6757e-03, -4.5137e-02, -1.3455e-03, -2.7575e-02, -7.0728e-05]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias before:  Parameter containing:\n",
      "tensor([-0.1874], requires_grad=True)\n",
      "bias grad:  tensor([-0.1573])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6680]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4905]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1008,  -322.8743,   -11.4323,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1858], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6190]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1008,  -322.8743,   -11.4323,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7833e-03,  0.0000e+00,  5.4095e-05,  6.0110e-04,  3.5955e-04,\n",
      "          6.3740e-04,  2.8363e-02,  2.0093e-03,  3.8245e-02,  1.0218e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1858], requires_grad=True)\n",
      "bias grad:  tensor([0.2244])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6190]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0045]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1010,  -322.8743,   -11.4326,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1881], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6195]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1010,  -322.8743,   -11.4326,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.6201e-04,  1.3774e-05,  5.8212e-06, -7.5793e-05,  1.3493e-04,\n",
      "          1.3418e-03,  2.5244e-02,  4.6631e-04,  9.3761e-05,  8.0905e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1881], requires_grad=True)\n",
      "bias grad:  tensor([0.0092])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6195]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4853]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1013,  -322.8743,   -11.4326,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1882], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5709]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1013,  -322.8743,   -11.4326,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[5.7330e-03, 3.1569e-05, 6.8143e-05, 8.4764e-04, 7.7399e-04, 2.1483e-03,\n",
      "         7.1194e-02, 2.6503e-03, 4.8531e-02, 1.7146e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1882], requires_grad=True)\n",
      "bias grad:  tensor([0.2993])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5709]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0892]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1020,  -322.8743,   -11.4331,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1911], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5798]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1020,  -322.8743,   -11.4331,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[2.5071e-04, 3.2194e-05, 1.0168e-04, 1.0498e-03, 4.0574e-04, 1.5013e-03,\n",
      "         6.6586e-02, 2.7168e-03, 5.7952e-02, 1.6084e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1911], requires_grad=True)\n",
      "bias grad:  tensor([0.3643])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5798]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2520]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1027,  -322.8744,   -11.4337,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1948], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6050]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1027,  -322.8744,   -11.4337,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7876e-03, 0.0000e+00, 7.3993e-05, 9.2416e-04, 7.2405e-04, 9.3593e-04,\n",
      "         5.0365e-02, 2.4883e-03, 5.7771e-02, 1.7837e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1948], requires_grad=True)\n",
      "bias grad:  tensor([0.3301])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6050]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3382]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1032,  -322.8744,   -11.4343,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1981], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6389]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1032,  -322.8744,   -11.4343,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.8664e-03,  0.0000e+00,  8.1043e-06,  3.7416e-06,  1.0214e-04,\n",
      "          4.6624e-04,  1.6539e-02,  5.3894e-04,  5.5902e-03, -6.6360e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1981], requires_grad=True)\n",
      "bias grad:  tensor([0.0307])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6389]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2287]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1033,  -322.8744,   -11.4343,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1984], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6160]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1033,  -322.8744,   -11.4343,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.6273e-05,  3.0942e-04,  2.6905e-04,  3.1517e-03,  7.0369e-04,\n",
      "          7.7494e-03,  2.3122e-01,  7.3698e-03,  1.3938e-01,  2.3696e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1984], requires_grad=True)\n",
      "bias grad:  tensor([0.8627])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6160]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6473]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1057,  -322.8745,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2070], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7807]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1057,  -322.8745,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1679e-03,  0.0000e+00, -2.4079e-07, -2.0516e-04, -9.4576e-05,\n",
      "          4.8595e-04,  5.4617e-03,  1.5792e-04, -4.0573e-03,  2.5419e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2070], requires_grad=True)\n",
      "bias grad:  tensor([-0.0251])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7807]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2658]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1057,  -322.8745,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2068], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7541]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1057,  -322.8745,   -11.4357,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6675e-04,  3.4123e-05,  6.6469e-05,  8.3943e-04,  5.0370e-04,\n",
      "          8.1731e-04,  4.3890e-02,  2.1913e-03,  4.8982e-02,  1.4811e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2068], requires_grad=True)\n",
      "bias grad:  tensor([0.2925])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7541]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1262]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1061,  -322.8745,   -11.4362,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2097], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7668]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1061,  -322.8745,   -11.4362,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7214e-03, -4.5796e-05,  1.1627e-05,  1.0770e-04, -3.2590e-06,\n",
      "          3.5520e-04,  1.1959e-02,  9.4038e-04,  1.4597e-02,  1.1930e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2097], requires_grad=True)\n",
      "bias grad:  tensor([0.0799])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7668]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5996]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1063,  -322.8745,   -11.4363,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2105], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7068]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1063,  -322.8745,   -11.4363,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2193e-03,  7.1388e-06,  4.8867e-05,  3.2909e-04, -3.3292e-05,\n",
      "          2.1941e-03,  5.0363e-02,  1.2921e-03,  2.5274e-02,  9.8969e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2105], requires_grad=True)\n",
      "bias grad:  tensor([0.1429])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7068]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0292]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1068,  -322.8745,   -11.4366,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2119], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7039]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1068,  -322.8745,   -11.4366,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.3112e-03, -4.5618e-05, -6.8205e-05, -1.1446e-03, -7.8192e-04,\n",
      "         -5.7495e-04, -4.4665e-02, -2.0827e-03, -5.4459e-02, -3.3080e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2119], requires_grad=True)\n",
      "bias grad:  tensor([-0.3169])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7039]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8239]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1063,  -322.8745,   -11.4360,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2088], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6215]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1063,  -322.8745,   -11.4360,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.5328e-04,  0.0000e+00, -2.7359e-05, -4.2775e-04, -1.5596e-04,\n",
      "         -1.4920e-04, -1.0086e-02, -1.3097e-03, -2.7112e-02, -7.0947e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2088], requires_grad=True)\n",
      "bias grad:  tensor([-0.1500])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6215]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1750]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1062,  -322.8745,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2073], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6390]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1062,  -322.8745,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6033e-03, 1.7094e-05, 9.1971e-05, 1.0880e-03, 8.0521e-04, 1.4692e-03,\n",
      "         6.7998e-02, 3.2167e-03, 6.8079e-02, 2.5659e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2073], requires_grad=True)\n",
      "bias grad:  tensor([0.4065])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6390]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0346]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1069,  -322.8745,   -11.4364,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2113], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6425]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1069,  -322.8745,   -11.4364,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5926e-02,  0.0000e+00, -5.2431e-05, -1.0512e-03, -1.3021e-03,\n",
      "         -7.0145e-04, -3.1779e-02, -2.4269e-03, -5.5773e-02, -6.4290e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2113], requires_grad=True)\n",
      "bias grad:  tensor([-0.3154])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6425]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1185]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1066,  -322.8745,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2082], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6306]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1066,  -322.8745,   -11.4359,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.0095e-03,  2.4583e-05,  2.4429e-05,  8.4446e-05, -1.9437e-04,\n",
      "          9.1739e-04,  1.9256e-02,  7.2664e-04,  9.0793e-03,  8.2882e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2082], requires_grad=True)\n",
      "bias grad:  tensor([0.0579])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6306]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1188]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1068,  -322.8745,   -11.4360,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2087], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6187]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1068,  -322.8745,   -11.4360,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.5359e-04,  0.0000e+00, -9.4991e-05, -5.3954e-04, -4.2417e-05,\n",
      "         -5.1661e-03, -1.2832e-01, -2.8240e-03, -4.6982e-02,  1.8790e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2087], requires_grad=True)\n",
      "bias grad:  tensor([-0.2990])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6187]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.2106]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1055,  -322.8744,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2058], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4977]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1055,  -322.8744,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.4544e-03,  3.0066e-05,  3.9180e-06,  6.0931e-04,  8.7429e-04,\n",
      "         -3.2218e-03, -5.1338e-02,  4.8704e-04,  2.5996e-02,  9.8169e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2058], requires_grad=True)\n",
      "bias grad:  tensor([0.1399])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4977]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1654]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1050,  -322.8744,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2072], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5142]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1050,  -322.8744,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.1197e-03, -6.3136e-05, -5.9615e-05, -6.5176e-04, -1.6728e-04,\n",
      "         -2.1145e-03, -6.6865e-02, -1.5068e-03, -3.1504e-02, -2.1886e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2072], requires_grad=True)\n",
      "bias grad:  tensor([-0.2021])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5142]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6974]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1043,  -322.8744,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2051], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4445]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1043,  -322.8744,   -11.4355,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.2323e-04, -2.0134e-04, -7.0651e-05, -6.7353e-04, -1.0310e-04,\n",
      "         -4.2631e-03, -9.6727e-02, -2.5224e-03, -3.9936e-02, -3.7490e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2051], requires_grad=True)\n",
      "bias grad:  tensor([-0.2502])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4445]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8525]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1033,  -322.8744,   -11.4351,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2026], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3592]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1033,  -322.8744,   -11.4351,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0062, 0.0000, 0.0003, 0.0031, 0.0006, 0.0018, 0.1186, 0.0057, 0.1619,\n",
      "         0.0033]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2026], requires_grad=True)\n",
      "bias grad:  tensor([0.9291])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3592]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.1768]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1045,  -322.8745,   -11.4367,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2119], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7769]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1045,  -322.8745,   -11.4367,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.7708e-03,  2.5958e-05, -8.9433e-05, -1.4166e-03, -1.0285e-03,\n",
      "         -1.0203e-03, -6.4970e-02, -3.3809e-03, -7.5240e-02, -7.9993e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2119], requires_grad=True)\n",
      "bias grad:  tensor([-0.4342])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7769]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4231]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1039,  -322.8744,   -11.4359,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2076], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7346]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1039,  -322.8744,   -11.4359,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2022e-03,  3.0049e-05,  4.7992e-05,  5.2744e-04,  1.8320e-04,\n",
      "          2.2710e-03,  5.7427e-02,  1.6378e-03,  2.7094e-02,  1.0376e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2076], requires_grad=True)\n",
      "bias grad:  tensor([0.1833])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7346]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1219]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1045,  -322.8745,   -11.4362,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2094], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7468]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1045,  -322.8745,   -11.4362,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[2.2289e-03, 0.0000e+00, 4.2895e-05, 5.9898e-04, 3.8057e-04, 1.2354e-04,\n",
      "         2.4962e-02, 1.5654e-03, 3.6467e-02, 7.4899e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2094], requires_grad=True)\n",
      "bias grad:  tensor([0.2128])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7468]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0695]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1047,  -322.8745,   -11.4366,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2115], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7537]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1047,  -322.8745,   -11.4366,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.1405e-03,  0.0000e+00, -2.0463e-05, -5.1629e-04, -4.2743e-04,\n",
      "          8.6123e-05, -4.0662e-03, -8.7577e-04, -2.2515e-02,  1.8918e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2115], requires_grad=True)\n",
      "bias grad:  tensor([-0.1284])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7537]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5059]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1047,  -322.8745,   -11.4363,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2103], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7031]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1047,  -322.8745,   -11.4363,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6004e-04,  5.9065e-05,  1.2299e-05,  4.1572e-05, -4.0868e-04,\n",
      "          3.9534e-04,  1.4521e-02,  2.9255e-04,  5.7513e-03,  3.3160e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2103], requires_grad=True)\n",
      "bias grad:  tensor([0.0334])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7031]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1771]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1048,  -322.8745,   -11.4364,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2106], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7208]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1048,  -322.8745,   -11.4364,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.2577e-04, -1.3175e-04, -9.7517e-05, -1.1817e-03, -2.0339e-04,\n",
      "         -2.7461e-03, -8.3985e-02, -2.9497e-03, -6.3173e-02, -6.2282e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2106], requires_grad=True)\n",
      "bias grad:  tensor([-0.3609])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7208]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8896]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1040,  -322.8745,   -11.4358,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2070], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6319]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1040,  -322.8745,   -11.4358,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9771e-03,  0.0000e+00,  5.1614e-05,  4.9803e-04,  1.9436e-04,\n",
      "          7.9094e-04,  2.7970e-02,  1.7694e-03,  3.2269e-02,  1.0178e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2070], requires_grad=True)\n",
      "bias grad:  tensor([0.1949])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6319]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0251]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1042,  -322.8745,   -11.4361,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2089], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6344]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1042,  -322.8745,   -11.4361,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.0917e-03,  5.4910e-06,  2.2705e-06, -1.1899e-04,  1.3608e-04,\n",
      "          1.3669e-03,  2.5130e-02,  2.9022e-04, -3.4705e-03,  5.0709e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2089], requires_grad=True)\n",
      "bias grad:  tensor([-0.0115])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6344]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3598]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1045,  -322.8745,   -11.4360,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2088], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5984]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1045,  -322.8745,   -11.4360,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7171e-03, 2.7793e-05, 3.6915e-05, 3.9264e-04, 2.3086e-04, 1.9603e-03,\n",
      "         5.2061e-02, 1.3282e-03, 2.2913e-02, 1.0402e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2088], requires_grad=True)\n",
      "bias grad:  tensor([0.1396])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5984]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1507]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1050,  -322.8745,   -11.4363,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2102], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6135]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1050,  -322.8745,   -11.4363,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0863e-04, 3.1087e-05, 1.0592e-04, 1.0896e-03, 4.4746e-04, 1.5984e-03,\n",
      "         7.0557e-02, 2.9655e-03, 6.0162e-02, 1.7176e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2102], requires_grad=True)\n",
      "bias grad:  tensor([0.3838])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6135]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2089]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1057,  -322.8745,   -11.4369,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2140], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6343]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1057,  -322.8745,   -11.4369,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5237e-03, 0.0000e+00, 7.2831e-05, 8.9972e-04, 7.8879e-04, 9.5756e-04,\n",
      "         5.0997e-02, 2.6470e-03, 5.8784e-02, 1.8560e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2140], requires_grad=True)\n",
      "bias grad:  tensor([0.3354])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6343]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1154]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1062,  -322.8745,   -11.4375,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2174], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6459]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1062,  -322.8745,   -11.4375,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[1.9322e-03, 0.0000e+00, 4.4256e-05, 4.3775e-04, 3.6511e-04, 6.4944e-04,\n",
      "         3.1867e-02, 1.7937e-03, 3.1910e-02, 8.1768e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2174], requires_grad=True)\n",
      "bias grad:  tensor([0.1847])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6459]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2732]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1066,  -322.8746,   -11.4378,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2192], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6186]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1066,  -322.8746,   -11.4378,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4995e-04,  2.9794e-04,  2.4173e-04,  2.8430e-03,  5.4186e-04,\n",
      "          7.5621e-03,  2.1581e-01,  6.4612e-03,  1.2039e-01,  1.7771e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2192], requires_grad=True)\n",
      "bias grad:  tensor([0.7534])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6186]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6796]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1087,  -322.8746,   -11.4390,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2268], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7865]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1087,  -322.8746,   -11.4390,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6816e-03,  0.0000e+00, -2.9442e-05, -5.7922e-04, -2.9150e-04,\n",
      "          3.3231e-05, -1.3628e-02, -7.7008e-04, -2.5223e-02, -3.7121e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2268], requires_grad=True)\n",
      "bias grad:  tensor([-0.1467])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7865]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3551]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1086,  -322.8746,   -11.4387,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2253], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7510]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1086,  -322.8746,   -11.4387,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.3952e-04,  4.0534e-05,  6.8339e-05,  8.3350e-04,  5.1816e-04,\n",
      "          8.0365e-04,  4.3462e-02,  2.1959e-03,  4.8598e-02,  1.5952e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2253], requires_grad=True)\n",
      "bias grad:  tensor([0.2959])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7510]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0554]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1090,  -322.8747,   -11.4392,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2283], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7566]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1090,  -322.8747,   -11.4392,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9466e-03, -3.2318e-05,  1.9839e-05,  2.1246e-04,  5.6737e-05,\n",
      "          4.8250e-04,  1.6396e-02,  1.2218e-03,  2.0890e-02,  1.3362e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2283], requires_grad=True)\n",
      "bias grad:  tensor([0.1161])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7566]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6224]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1092,  -322.8747,   -11.4394,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2294], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6943]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1092,  -322.8747,   -11.4394,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9340e-04,  7.1446e-06,  4.1197e-05,  2.4252e-04, -2.9044e-07,\n",
      "          1.9395e-03,  4.4122e-02,  1.0747e-03,  2.1559e-02,  8.8600e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2294], requires_grad=True)\n",
      "bias grad:  tensor([0.1211])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6943]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1345]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1096,  -322.8747,   -11.4396,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2306], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6809]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1096,  -322.8747,   -11.4396,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.3245e-03, -2.6580e-05, -5.4186e-05, -9.2243e-04, -6.2568e-04,\n",
      "         -4.7362e-04, -3.7298e-02, -1.6314e-03, -4.2729e-02, -1.9531e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2306], requires_grad=True)\n",
      "bias grad:  tensor([-0.2489])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6809]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6299]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1092,  -322.8746,   -11.4392,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2282], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6179]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1092,  -322.8746,   -11.4392,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.4732e-04,  0.0000e+00, -1.2247e-05, -1.9180e-04, -1.9499e-05,\n",
      "         -2.4924e-05,  4.5360e-04, -7.0672e-04, -1.4458e-02, -4.2318e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2282], requires_grad=True)\n",
      "bias grad:  tensor([-0.0764])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6179]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2419]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1092,  -322.8746,   -11.4391,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2274], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6421]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1092,  -322.8746,   -11.4391,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3201e-03, 2.4830e-05, 8.2074e-05, 1.0219e-03, 8.0849e-04, 1.2391e-03,\n",
      "         6.2490e-02, 3.0843e-03, 6.3639e-02, 2.3894e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2274], requires_grad=True)\n",
      "bias grad:  tensor([0.3795])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6421]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0178]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1099,  -322.8747,   -11.4397,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2312], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6438]], requires_grad=True)\n",
      "Iteration 17 | Score: 0.5089486241340637\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8737,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5628e-02,  0.0000e+00,  8.4116e-06, -2.9736e-04, -5.2705e-04,\n",
      "         -1.0715e-04, -5.1476e-03, -3.3505e-05, -9.4315e-03,  2.9348e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1246], requires_grad=True)\n",
      "bias grad:  tensor([-0.0482])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7845]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3434]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8737,   -11.4219,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1241], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7502]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8737,   -11.4219,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.7777e-03,  2.6300e-05,  1.4896e-05, -6.4522e-05, -2.1075e-04,\n",
      "          8.1935e-04,  1.6079e-02,  4.2987e-04,  2.1935e-03,  7.1571e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1241], requires_grad=True)\n",
      "bias grad:  tensor([0.0167])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7502]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2805]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0905,  -322.8737,   -11.4219,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1243], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7221]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0905,  -322.8737,   -11.4219,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.8973e-04,  0.0000e+00, -1.0125e-04, -5.9717e-04, -4.8407e-05,\n",
      "         -5.0483e-03, -1.2839e-01, -2.9671e-03, -5.1099e-02, -4.4472e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1243], requires_grad=True)\n",
      "bias grad:  tensor([-0.3224])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7221]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1686]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0893,  -322.8737,   -11.4214,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1211], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6053]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0893,  -322.8737,   -11.4214,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.4350e-03,  1.6399e-06, -4.1546e-05, -6.3530e-05,  5.6479e-04,\n",
      "         -3.7354e-03, -7.8221e-02, -9.8805e-04, -7.3874e-03, -6.7727e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1211], requires_grad=True)\n",
      "bias grad:  tensor([-0.0630])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6053]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4826]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0885,  -322.8737,   -11.4213,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1205], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5570]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0885,  -322.8737,   -11.4213,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.7049e-03, -5.8907e-05, -5.3574e-05, -5.1644e-04,  4.9808e-05,\n",
      "         -2.2506e-03, -6.2142e-02, -1.1197e-03, -2.3322e-02, -2.1823e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1205], requires_grad=True)\n",
      "bias grad:  tensor([-0.1556])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5570]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7843]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0879,  -322.8737,   -11.4211,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1189], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4786]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0879,  -322.8737,   -11.4211,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7347e-04, -1.9836e-04, -7.2572e-05, -6.1070e-04,  9.6836e-06,\n",
      "         -4.1603e-03, -9.5602e-02, -2.2413e-03, -3.4393e-02, -2.9157e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1189], requires_grad=True)\n",
      "bias grad:  tensor([-0.2246])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4786]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9523]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0869,  -322.8737,   -11.4208,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1167], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3833]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0869,  -322.8737,   -11.4208,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0053, 0.0000, 0.0002, 0.0027, 0.0004, 0.0015, 0.1014, 0.0048, 0.1384,\n",
      "         0.0030]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1167], requires_grad=True)\n",
      "bias grad:  tensor([0.7949])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3833]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.4648]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0879,  -322.8737,   -11.4222,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1246], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7298]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0879,  -322.8737,   -11.4222,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.2503e-03,  2.1855e-05, -7.4945e-05, -1.1874e-03, -8.5194e-04,\n",
      "         -9.3799e-04, -5.5928e-02, -2.7602e-03, -6.1661e-02, -6.2288e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1246], requires_grad=True)\n",
      "bias grad:  tensor([-0.3582])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7298]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3428]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0874,  -322.8737,   -11.4215,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1210], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6955]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0874,  -322.8737,   -11.4215,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.4697e-04,  3.0691e-05,  7.3431e-05,  8.6569e-04,  4.3729e-04,\n",
      "          2.6816e-03,  7.5560e-02,  2.6433e-03,  4.6765e-02,  1.4786e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1210], requires_grad=True)\n",
      "bias grad:  tensor([0.2999])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6955]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1747]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0881,  -322.8737,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1240], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7130]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0881,  -322.8737,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3116e-03, 0.0000e+00, 5.4410e-05, 7.5233e-04, 5.0131e-04, 2.0105e-04,\n",
      "         3.8324e-02, 1.9646e-03, 4.5798e-02, 9.1438e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1240], requires_grad=True)\n",
      "bias grad:  tensor([0.2675])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7130]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0008]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0885,  -322.8737,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1267], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7131]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0885,  -322.8737,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.4845e-04,  0.0000e+00,  5.1640e-06, -1.0781e-04, -1.1408e-04,\n",
      "          2.9010e-04,  9.5799e-03,  1.4492e-04, -9.9135e-05,  4.0271e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1267], requires_grad=True)\n",
      "bias grad:  tensor([-0.0008])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7131]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3315]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0886,  -322.8737,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1267], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6799]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0886,  -322.8737,   -11.4225,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.5569e-06,  6.4062e-05,  3.5137e-05,  3.6478e-04, -1.4553e-04,\n",
      "          7.4841e-04,  3.1005e-02,  1.1984e-03,  2.4815e-02,  7.2076e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1267], requires_grad=True)\n",
      "bias grad:  tensor([0.1429])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6799]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1491]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0889,  -322.8737,   -11.4227,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1281], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6949]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0889,  -322.8737,   -11.4227,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.3736e-04, -1.1373e-04, -6.8207e-05, -8.0932e-04, -5.1076e-05,\n",
      "         -2.0628e-03, -5.9291e-02, -1.9541e-03, -4.2215e-02, -4.9778e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1281], requires_grad=True)\n",
      "bias grad:  tensor([-0.2405])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6949]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7179]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0883,  -322.8737,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1257], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6231]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0883,  -322.8737,   -11.4223,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.3738e-04,  0.0000e+00,  7.0479e-05,  7.9868e-04,  4.2661e-04,\n",
      "          7.8228e-04,  3.8680e-02,  2.5890e-03,  5.0382e-02,  1.4058e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1257], requires_grad=True)\n",
      "bias grad:  tensor([0.2958])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6231]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0169]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0887,  -322.8737,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1287], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6214]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0887,  -322.8737,   -11.4228,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[7.5942e-04, 1.8714e-05, 2.2071e-05, 1.0951e-04, 2.1310e-04, 1.7892e-03,\n",
      "         4.0177e-02, 9.5466e-04, 1.0152e-02, 1.0915e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1287], requires_grad=True)\n",
      "bias grad:  tensor([0.0704])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6214]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3632]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0891,  -322.8737,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1294], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5850]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0891,  -322.8737,   -11.4229,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.4360e-04,  2.7965e-05,  2.6139e-05,  2.0343e-04, -1.8317e-05,\n",
      "          1.9902e-03,  4.5759e-02,  7.1451e-04,  1.0787e-02,  5.6430e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1294], requires_grad=True)\n",
      "bias grad:  tensor([0.0665])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5850]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2520]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0896,  -322.8737,   -11.4230,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1300], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6102]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0896,  -322.8737,   -11.4230,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[4.6914e-04, 4.3525e-05, 1.3789e-04, 1.4777e-03, 6.2818e-04, 1.9814e-03,\n",
      "         8.9063e-02, 3.9191e-03, 8.2191e-02, 2.2529e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1300], requires_grad=True)\n",
      "bias grad:  tensor([0.5151])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6102]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3073]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8738,   -11.4238,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1352], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6410]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8738,   -11.4238,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[4.7116e-03, 0.0000e+00, 5.0412e-05, 6.5502e-04, 5.6396e-04, 9.6605e-04,\n",
      "         4.2546e-02, 1.6291e-03, 3.9535e-02, 7.3689e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1352], requires_grad=True)\n",
      "bias grad:  tensor([0.2246])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6410]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3210]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8738,   -11.4242,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1374], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6731]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8738,   -11.4242,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[4.4596e-03, 0.0000e+00, 3.3771e-05, 3.3265e-04, 4.9529e-04, 5.9086e-04,\n",
      "         3.2138e-02, 1.7664e-03, 2.6500e-02, 3.4101e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1374], requires_grad=True)\n",
      "bias grad:  tensor([0.1557])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6731]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3493]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0912,  -322.8738,   -11.4245,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1390], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6382]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0912,  -322.8738,   -11.4245,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0011, 0.0004, 0.0003, 0.0032, 0.0009, 0.0077, 0.2281, 0.0075, 0.1453,\n",
      "         0.0027]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1390], requires_grad=True)\n",
      "bias grad:  tensor([0.8950])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6382]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6688]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0935,  -322.8739,   -11.4259,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1479], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8050]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0935,  -322.8739,   -11.4259,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.8383e-03,  0.0000e+00, -6.6356e-06, -3.2865e-04, -1.8526e-04,\n",
      "          3.8703e-04,  2.4076e-03,  1.6137e-05, -9.8583e-03, -8.6676e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1479], requires_grad=True)\n",
      "bias grad:  tensor([-0.0588])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8050]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3658]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0935,  -322.8739,   -11.4258,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1474], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7684]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0935,  -322.8739,   -11.4258,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.0821e-04,  3.6517e-05,  5.5753e-05,  6.9896e-04,  4.1582e-04,\n",
      "          7.0828e-04,  3.6716e-02,  1.8048e-03,  3.8988e-02,  1.1167e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1474], requires_grad=True)\n",
      "bias grad:  tensor([0.2421])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7684]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1510]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0939,  -322.8739,   -11.4262,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1498], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7836]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0939,  -322.8739,   -11.4262,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4168e-03, -3.5545e-05,  1.8782e-05,  2.0465e-04,  6.5113e-05,\n",
      "          3.3330e-04,  1.4265e-02,  1.1456e-03,  1.9627e-02,  1.2487e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1498], requires_grad=True)\n",
      "bias grad:  tensor([0.1089])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7836]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6129]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0940,  -322.8739,   -11.4264,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1509], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7223]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0940,  -322.8739,   -11.4264,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.8629e-05,  1.0760e-05,  6.7708e-05,  5.4893e-04,  1.9365e-04,\n",
      "          2.4425e-03,  6.3646e-02,  1.9531e-03,  4.0343e-02,  1.3096e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1509], requires_grad=True)\n",
      "bias grad:  tensor([0.2280])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7223]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1538]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0946,  -322.8740,   -11.4268,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1531], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7069]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0946,  -322.8740,   -11.4268,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.1451e-03, -2.7256e-05, -2.5673e-05, -5.1169e-04, -3.0202e-04,\n",
      "         -2.4558e-04, -1.6526e-02, -6.7187e-04, -1.9426e-02,  2.1774e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1531], requires_grad=True)\n",
      "bias grad:  tensor([-0.1129])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7069]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5524]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1520], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6516]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.0845e-03,  0.0000e+00, -4.3430e-06, -1.1773e-04,  2.4272e-05,\n",
      "          2.2404e-05,  4.0889e-03, -5.9375e-04, -9.5134e-03, -3.2189e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1520], requires_grad=True)\n",
      "bias grad:  tensor([-0.0469])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6516]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2349]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8740,   -11.4265,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1515], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6751]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8740,   -11.4265,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6140e-03, 2.9908e-05, 8.3211e-05, 1.0152e-03, 7.3214e-04, 1.3447e-03,\n",
      "         6.1256e-02, 2.9654e-03, 6.2109e-02, 2.3182e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1515], requires_grad=True)\n",
      "bias grad:  tensor([0.3712])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6751]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1331]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0951,  -322.8740,   -11.4272,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1553], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6884]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0951,  -322.8740,   -11.4272,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8962e-02,  0.0000e+00, -4.8867e-05, -1.0853e-03, -1.3803e-03,\n",
      "         -7.0353e-04, -3.1940e-02, -2.3577e-03, -5.6145e-02, -6.1592e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1553], requires_grad=True)\n",
      "bias grad:  tensor([-0.3164])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6884]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2896]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0948,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1521], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6595]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0948,  -322.8740,   -11.4266,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.3601e-03,  2.4993e-05,  2.9675e-05,  1.5729e-04, -1.3043e-04,\n",
      "          1.1197e-03,  2.5710e-02,  8.9366e-04,  1.3313e-02,  8.1693e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1521], requires_grad=True)\n",
      "bias grad:  tensor([0.0815])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6595]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0665]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0951,  -322.8740,   -11.4267,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1529], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6528]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0951,  -322.8740,   -11.4267,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0780e-03,  0.0000e+00, -1.2920e-04, -8.7333e-04, -2.4734e-04,\n",
      "         -5.6940e-03, -1.5118e-01, -3.8436e-03, -7.0592e-02, -5.9370e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1529], requires_grad=True)\n",
      "bias grad:  tensor([-0.4366])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6528]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.0602]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0936,  -322.8739,   -11.4260,  -302.5944]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias after:  Parameter containing:\n",
      "tensor([-0.1485], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5468]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0936,  -322.8739,   -11.4260,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.1947e-03,  2.4616e-05, -2.1547e-05,  3.0433e-04,  7.8857e-04,\n",
      "         -3.4253e-03, -6.7000e-02, -2.9627e-04,  9.6212e-03, -6.3150e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1485], requires_grad=True)\n",
      "bias grad:  tensor([0.0378])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5468]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0392]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0929,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1489], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5507]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0929,  -322.8739,   -11.4261,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.3593e-03, -6.6540e-05, -6.1477e-05, -6.0529e-04,  3.6593e-05,\n",
      "         -2.1702e-03, -6.6678e-02, -1.2985e-03, -2.8071e-02, -1.9149e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1489], requires_grad=True)\n",
      "bias grad:  tensor([-0.1831])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5507]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8360]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0922,  -322.8739,   -11.4258,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1471], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4671]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0922,  -322.8739,   -11.4258,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.9353e-04, -1.9629e-04, -7.6325e-05, -5.4590e-04,  1.1524e-04,\n",
      "         -4.0275e-03, -9.4028e-02, -2.1189e-03, -3.2709e-02, -4.7792e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1471], requires_grad=True)\n",
      "bias grad:  tensor([-0.2123])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4671]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7132]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0913,  -322.8739,   -11.4255,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1450], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3958]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0913,  -322.8739,   -11.4255,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0053, 0.0000, 0.0002, 0.0026, 0.0005, 0.0014, 0.0931, 0.0045, 0.1333,\n",
      "         0.0026]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1450], requires_grad=True)\n",
      "bias grad:  tensor([0.7658])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3958]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.3817]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0922,  -322.8739,   -11.4268,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1526], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7340]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0922,  -322.8739,   -11.4268,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.9364e-03,  2.4347e-05, -7.7607e-05, -1.2309e-03, -8.6482e-04,\n",
      "         -9.1440e-04, -5.6502e-02, -2.9220e-03, -6.4556e-02, -6.2469e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1526], requires_grad=True)\n",
      "bias grad:  tensor([-0.3732])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7340]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3732]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0916,  -322.8739,   -11.4262,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1489], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6967]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0916,  -322.8739,   -11.4262,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.1911e-04,  2.9608e-05,  5.8089e-05,  6.8018e-04,  3.2133e-04,\n",
      "          2.3681e-03,  6.3456e-02,  2.0935e-03,  3.7529e-02,  1.1358e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1489], requires_grad=True)\n",
      "bias grad:  tensor([0.2368])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6967]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1533]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0923,  -322.8739,   -11.4266,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1513], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7120]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0923,  -322.8739,   -11.4266,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7080e-03, 0.0000e+00, 5.1699e-05, 7.0634e-04, 5.4650e-04, 2.5628e-04,\n",
      "         3.5399e-02, 1.9720e-03, 4.4035e-02, 1.0124e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1513], requires_grad=True)\n",
      "bias grad:  tensor([0.2558])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7120]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0510]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0926,  -322.8740,   -11.4270,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1538], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7069]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0926,  -322.8740,   -11.4270,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3557e-03,  0.0000e+00, -1.2899e-05, -3.6062e-04, -3.2150e-04,\n",
      "          1.4991e-04,  1.3815e-04, -5.9494e-04, -1.5014e-02,  2.3337e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1538], requires_grad=True)\n",
      "bias grad:  tensor([-0.0855])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7069]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3141]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0926,  -322.8740,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1530], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6755]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0926,  -322.8740,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.9399e-06,  7.5669e-05,  1.7873e-05,  1.3844e-04, -3.3597e-04,\n",
      "          3.0573e-04,  1.3658e-02,  5.1246e-04,  1.0559e-02,  3.7985e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1530], requires_grad=True)\n",
      "bias grad:  tensor([0.0608])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6755]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2692]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0928,  -322.8740,   -11.4270,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1536], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7024]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0928,  -322.8740,   -11.4270,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.3050e-04, -9.9847e-05, -5.1145e-05, -6.2880e-04,  4.6960e-05,\n",
      "         -2.0579e-03, -5.4092e-02, -1.4253e-03, -2.9197e-02,  2.1816e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1536], requires_grad=True)\n",
      "bias grad:  tensor([-0.1660])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7024]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8584]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0922,  -322.8740,   -11.4267,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1519], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6166]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0922,  -322.8740,   -11.4267,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7498e-03,  0.0000e+00,  5.8003e-05,  6.5591e-04,  3.4811e-04,\n",
      "          6.2382e-04,  3.0470e-02,  2.1611e-03,  4.1885e-02,  1.1683e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1519], requires_grad=True)\n",
      "bias grad:  tensor([0.2441])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6166]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0033]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0925,  -322.8740,   -11.4271,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1544], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6169]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0925,  -322.8740,   -11.4271,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0288e-03,  4.4178e-06, -1.5669e-05, -3.2695e-04, -1.0613e-04,\n",
      "          9.6905e-04,  9.0936e-03, -3.2132e-04, -1.6638e-02,  1.8256e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1544], requires_grad=True)\n",
      "bias grad:  tensor([-0.0870])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6169]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3404]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0926,  -322.8740,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1535], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5828]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0926,  -322.8740,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[2.5402e-03, 3.2197e-05, 3.8815e-05, 4.1176e-04, 2.5368e-04, 2.0718e-03,\n",
      "         5.5082e-02, 1.3367e-03, 2.2964e-02, 9.9254e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1535], requires_grad=True)\n",
      "bias grad:  tensor([0.1420])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5828]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1761]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0932,  -322.8740,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1549], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6005]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0932,  -322.8740,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0489e-04, 3.9682e-05, 1.4167e-04, 1.4977e-03, 6.6775e-04, 2.0124e-03,\n",
      "         9.1512e-02, 4.1422e-03, 8.2900e-02, 2.3650e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1549], requires_grad=True)\n",
      "bias grad:  tensor([0.5313])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6005]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2465]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0941,  -322.8740,   -11.4280,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1602], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6251]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0941,  -322.8740,   -11.4280,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.3706e-03, 0.0000e+00, 4.2052e-05, 5.4214e-04, 4.8140e-04, 7.8354e-04,\n",
      "         3.7495e-02, 1.3692e-03, 3.3535e-02, 6.5822e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1602], requires_grad=True)\n",
      "bias grad:  tensor([0.1903])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6251]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2911]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0945,  -322.8740,   -11.4283,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1621], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6542]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0945,  -322.8740,   -11.4283,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[8.0624e-04, 0.0000e+00, 3.8619e-05, 3.6243e-04, 1.9145e-04, 5.9993e-04,\n",
      "         3.0358e-02, 1.4986e-03, 2.7359e-02, 7.2384e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1621], requires_grad=True)\n",
      "bias grad:  tensor([0.1554])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6542]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2369]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0948,  -322.8740,   -11.4286,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1637], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6305]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0948,  -322.8740,   -11.4286,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0008, 0.0003, 0.0003, 0.0031, 0.0007, 0.0076, 0.2237, 0.0071, 0.1340,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1637], requires_grad=True)\n",
      "bias grad:  tensor([0.8307])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6305]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6309]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8741,   -11.4299,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1720], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7936]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8741,   -11.4299,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7297e-03,  0.0000e+00, -6.8713e-06, -2.9243e-04, -1.5151e-04,\n",
      "          3.3286e-04,  1.5120e-03,  5.7111e-05, -8.4502e-03, -6.1113e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1720], requires_grad=True)\n",
      "bias grad:  tensor([-0.0486])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7936]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3533]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8741,   -11.4299,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1715], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7583]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8741,   -11.4299,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.6067e-05,  4.3815e-05,  6.8461e-05,  8.5400e-04,  4.8358e-04,\n",
      "          8.1212e-04,  4.2518e-02,  2.1571e-03,  4.8547e-02,  1.3875e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1715], requires_grad=True)\n",
      "bias grad:  tensor([0.2938])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7583]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1906]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0974,  -322.8741,   -11.4303,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1744], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7773]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0974,  -322.8741,   -11.4303,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7031e-03, -3.0308e-05,  2.8196e-05,  3.1166e-04,  1.0832e-04,\n",
      "          6.9428e-04,  2.3592e-02,  1.5198e-03,  2.7070e-02,  1.4949e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1744], requires_grad=True)\n",
      "bias grad:  tensor([0.1512])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7773]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6470]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0977,  -322.8741,   -11.4306,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1759], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7127]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0977,  -322.8741,   -11.4306,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8156e-05, 4.7023e-06, 4.3392e-05, 2.9689e-04, 6.7104e-05, 1.9297e-03,\n",
      "         4.5672e-02, 1.2367e-03, 2.4672e-02, 9.5152e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1759], requires_grad=True)\n",
      "bias grad:  tensor([0.1389])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7127]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1313]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0981,  -322.8741,   -11.4309,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1773], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6995]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0981,  -322.8741,   -11.4309,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.3103e-03, -2.8449e-05, -4.0434e-05, -7.3193e-04, -4.7606e-04,\n",
      "         -3.7113e-04, -2.9184e-02, -1.2170e-03, -3.0986e-02,  2.3668e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1773], requires_grad=True)\n",
      "bias grad:  tensor([-0.1808])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6995]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5884]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0978,  -322.8741,   -11.4306,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1755], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6407]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0978,  -322.8741,   -11.4306,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.3005e-04,  0.0000e+00, -1.0268e-05, -1.9890e-04, -3.4472e-05,\n",
      "         -3.1543e-05, -3.2732e-04, -8.0127e-04, -1.3850e-02, -4.9519e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1755], requires_grad=True)\n",
      "bias grad:  tensor([-0.0746])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6407]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3201]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0978,  -322.8741,   -11.4304,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1748], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6727]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0978,  -322.8741,   -11.4304,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4653e-03, 2.2096e-05, 8.0411e-05, 1.0014e-03, 7.8063e-04, 1.1116e-03,\n",
      "         5.8959e-02, 3.0069e-03, 6.2231e-02, 2.3448e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1748], requires_grad=True)\n",
      "bias grad:  tensor([0.3713])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6727]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0297]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0984,  -322.8741,   -11.4310,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1785], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6757]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0984,  -322.8741,   -11.4310,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2858e-02,  0.0000e+00, -8.3825e-05, -1.6139e-03, -1.9764e-03,\n",
      "         -1.0900e-03, -4.9340e-02, -3.8195e-03, -8.6537e-02, -1.0173e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1785], requires_grad=True)\n",
      "bias grad:  tensor([-0.4902])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6757]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3352]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0979,  -322.8741,   -11.4302,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1736], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6421]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0979,  -322.8741,   -11.4302,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.2874e-03,  2.0748e-05,  3.7971e-05,  2.6343e-04, -1.0511e-04,\n",
      "          1.2842e-03,  3.2236e-02,  1.1710e-03,  1.9164e-02,  9.3974e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1736], requires_grad=True)\n",
      "bias grad:  tensor([0.1170])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6421]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0192]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0983,  -322.8741,   -11.4304,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1748], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6402]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0983,  -322.8741,   -11.4304,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0249e-03,  0.0000e+00, -1.2882e-04, -8.9193e-04, -2.2145e-04,\n",
      "         -5.6564e-03, -1.5177e-01, -3.8723e-03, -7.0711e-02, -4.0690e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1748], requires_grad=True)\n",
      "bias grad:  tensor([-0.4365])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6402]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1769]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0967,  -322.8741,   -11.4297,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1704], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5225]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0967,  -322.8741,   -11.4297,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.7455e-03,  2.3336e-05, -3.5089e-05,  1.2059e-04,  6.4819e-04,\n",
      "         -3.6429e-03, -7.5229e-02, -8.0841e-04, -1.5730e-03, -7.6906e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1704], requires_grad=True)\n",
      "bias grad:  tensor([-0.0250])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5225]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0263]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0960,  -322.8741,   -11.4296,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1701], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5199]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0960,  -322.8741,   -11.4296,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.9593e-03, -7.0754e-05, -4.2422e-05, -4.1370e-04,  3.1934e-05,\n",
      "         -1.9664e-03, -5.3664e-02, -9.2622e-04, -1.8558e-02,  6.9717e-06]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1701], requires_grad=True)\n",
      "bias grad:  tensor([-0.1248])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5199]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6308]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0955,  -322.8741,   -11.4295,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1689], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4568]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0955,  -322.8741,   -11.4295,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1120e-03, -2.0248e-04, -9.6758e-05, -9.2095e-04, -2.6112e-04,\n",
      "         -4.4744e-03, -1.1387e-01, -3.1188e-03, -5.3739e-02, -7.4255e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1689], requires_grad=True)\n",
      "bias grad:  tensor([-0.3396])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4568]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8325]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0943,  -322.8741,   -11.4289,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1655], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3736]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0943,  -322.8741,   -11.4289,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0060, 0.0000, 0.0002, 0.0029, 0.0005, 0.0017, 0.1042, 0.0050, 0.1455,\n",
      "         0.0030]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1655], requires_grad=True)\n",
      "bias grad:  tensor([0.8356])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3736]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.0355]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0954,  -322.8741,   -11.4304,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1739], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7771]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0954,  -322.8741,   -11.4304,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.5662e-03,  8.4216e-06, -9.7378e-05, -1.5650e-03, -1.1042e-03,\n",
      "         -1.0709e-03, -6.7340e-02, -3.6416e-03, -8.1870e-02, -8.5580e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1739], requires_grad=True)\n",
      "bias grad:  tensor([-0.4743])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7771]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5616]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0947,  -322.8741,   -11.4296,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1691], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7210]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0947,  -322.8741,   -11.4296,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3198e-03,  3.9335e-05,  6.7276e-05,  7.7892e-04,  3.6320e-04,\n",
      "          2.4726e-03,  6.9045e-02,  2.3452e-03,  4.2258e-02,  1.3597e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1691], requires_grad=True)\n",
      "bias grad:  tensor([0.2699])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7210]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1983]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0954,  -322.8741,   -11.4300,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1718], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7408]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0954,  -322.8741,   -11.4300,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8858e-03, 0.0000e+00, 4.1821e-05, 6.0198e-04, 4.2604e-04, 1.1913e-04,\n",
      "         2.5722e-02, 1.5501e-03, 3.6543e-02, 7.1019e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1718], requires_grad=True)\n",
      "bias grad:  tensor([0.2142])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7408]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0167]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0956,  -322.8741,   -11.4303,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1740], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7425]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0956,  -322.8741,   -11.4303,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2309e-03,  0.0000e+00, -3.1036e-05, -6.3635e-04, -4.9246e-04,\n",
      "          4.2602e-05, -1.0050e-02, -1.2594e-03, -3.0260e-02,  3.5979e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1740], requires_grad=True)\n",
      "bias grad:  tensor([-0.1726])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7425]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4447]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0955,  -322.8741,   -11.4300,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1722], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6980]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0955,  -322.8741,   -11.4300,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.0161e-04,  4.0537e-05,  2.4934e-05,  1.8997e-04, -2.5084e-04,\n",
      "          6.3621e-04,  2.3421e-02,  7.6832e-04,  1.5520e-02,  5.0699e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1722], requires_grad=True)\n",
      "bias grad:  tensor([0.0895])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6980]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0881]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0958,  -322.8741,   -11.4302,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1731], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7068]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0958,  -322.8741,   -11.4302,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.4003e-04, -1.1432e-04, -8.5350e-05, -1.0276e-03, -1.3567e-04,\n",
      "         -2.1885e-03, -6.9045e-02, -2.4313e-03, -5.3720e-02, -6.1311e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1731], requires_grad=True)\n",
      "bias grad:  tensor([-0.3072])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7068]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7848]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0951,  -322.8741,   -11.4297,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1700], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6283]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0951,  -322.8741,   -11.4297,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0974e-03,  0.0000e+00,  7.5869e-05,  7.8012e-04,  3.8812e-04,\n",
      "          1.2670e-03,  5.0978e-02,  2.6021e-03,  4.9136e-02,  1.4849e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1700], requires_grad=True)\n",
      "bias grad:  tensor([0.2997])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6283]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0389]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0956,  -322.8741,   -11.4302,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1730], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6322]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0956,  -322.8741,   -11.4302,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.0154e-05,  1.7084e-05, -6.5982e-06, -2.2130e-04,  2.0809e-05,\n",
      "          1.2812e-03,  1.6731e-02,  5.8365e-05, -9.1688e-03,  5.8322e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1730], requires_grad=True)\n",
      "bias grad:  tensor([-0.0458])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6322]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4121]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0958,  -322.8741,   -11.4301,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1726], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5910]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0958,  -322.8741,   -11.4301,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[1.2587e-03, 3.2172e-05, 3.4862e-05, 3.3580e-04, 1.8937e-04, 1.9565e-03,\n",
      "         5.1557e-02, 1.1796e-03, 1.9612e-02, 7.5569e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1726], requires_grad=True)\n",
      "bias grad:  tensor([0.1185])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5910]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1380]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8741,   -11.4303,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1738], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6048]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8741,   -11.4303,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[2.9487e-04, 3.6718e-05, 1.1804e-04, 1.2409e-03, 5.2411e-04, 1.6143e-03,\n",
      "         7.4479e-02, 3.2476e-03, 6.9660e-02, 1.7957e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1738], requires_grad=True)\n",
      "bias grad:  tensor([0.4294])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6048]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2777]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8742,   -11.4310,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1781], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6326]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8742,   -11.4310,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2744e-03, 0.0000e+00, 8.9711e-05, 1.1012e-03, 8.7475e-04, 1.1748e-03,\n",
      "         6.2384e-02, 3.1408e-03, 7.0522e-02, 2.1276e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1781], requires_grad=True)\n",
      "bias grad:  tensor([0.4030])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6326]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1218]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0976,  -322.8742,   -11.4317,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1821], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6448]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0976,  -322.8742,   -11.4317,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[6.1213e-03, 0.0000e+00, 4.4028e-05, 5.2598e-04, 7.5420e-04, 6.4413e-04,\n",
      "         3.9156e-02, 2.2235e-03, 3.6444e-02, 4.6985e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1821], requires_grad=True)\n",
      "bias grad:  tensor([0.2145])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6448]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2997]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0980,  -322.8742,   -11.4320,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1842], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6148]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0980,  -322.8742,   -11.4320,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0009, 0.0003, 0.0003, 0.0032, 0.0007, 0.0079, 0.2308, 0.0072, 0.1375,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1842], requires_grad=True)\n",
      "bias grad:  tensor([0.8538])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6148]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.8730]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1003,  -322.8743,   -11.4334,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1928], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8021]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1003,  -322.8743,   -11.4334,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4044e-03,  0.0000e+00, -2.1661e-06, -1.7813e-04,  1.7730e-05,\n",
      "          2.4520e-04,  4.3899e-03,  2.6184e-04, -2.6410e-03, -1.1015e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1928], requires_grad=True)\n",
      "bias grad:  tensor([-0.0163])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8021]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3198]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8743,   -11.4334,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1926], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7701]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8743,   -11.4334,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.3399e-04,  3.7819e-05,  4.7975e-05,  6.0703e-04,  4.1040e-04,\n",
      "          6.1054e-04,  3.0572e-02,  1.6476e-03,  3.4853e-02,  1.0473e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1926], requires_grad=True)\n",
      "bias grad:  tensor([0.2152])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7701]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0273]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1007,  -322.8743,   -11.4337,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1948], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7728]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1007,  -322.8743,   -11.4337,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5788e-03, -4.9333e-05,  1.8027e-05,  1.7167e-04,  5.5419e-05,\n",
      "          6.6585e-04,  1.9985e-02,  1.1718e-03,  1.9297e-02,  1.3357e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1948], requires_grad=True)\n",
      "bias grad:  tensor([0.1063])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7728]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6614]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1009,  -322.8743,   -11.4339,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1958], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7067]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1009,  -322.8743,   -11.4339,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[7.5262e-05, 7.3587e-06, 4.6153e-05, 2.8438e-04, 4.8551e-05, 2.0691e-03,\n",
      "         4.8833e-02, 1.2025e-03, 2.3876e-02, 9.2432e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1958], requires_grad=True)\n",
      "bias grad:  tensor([0.1343])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7067]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1581]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1014,  -322.8743,   -11.4341,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1972], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6909]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1014,  -322.8743,   -11.4341,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8476e-03, -2.5639e-05, -5.9483e-05, -9.8062e-04, -6.5044e-04,\n",
      "         -5.4233e-04, -4.0676e-02, -1.7040e-03, -4.5432e-02, -2.0716e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1972], requires_grad=True)\n",
      "bias grad:  tensor([-0.2666])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6909]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6670]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1010,  -322.8743,   -11.4337,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1945], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6242]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1010,  -322.8743,   -11.4337,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.1080e-04,  0.0000e+00, -1.1449e-06, -8.6904e-05,  1.7430e-05,\n",
      "          2.3291e-05,  2.1310e-03, -5.3393e-04, -7.5586e-03, -3.4279e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1945], requires_grad=True)\n",
      "bias grad:  tensor([-0.0381])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6242]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2638]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1010,  -322.8743,   -11.4336,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1941], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6506]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1010,  -322.8743,   -11.4336,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0162e-03, 2.8085e-05, 9.2410e-05, 1.1208e-03, 8.3675e-04, 1.4204e-03,\n",
      "         6.8055e-02, 3.2902e-03, 6.9839e-02, 2.5328e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1941], requires_grad=True)\n",
      "bias grad:  tensor([0.4164])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6506]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0535]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1017,  -322.8743,   -11.4343,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1983], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6559]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1017,  -322.8743,   -11.4343,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4873e-02,  0.0000e+00, -1.7967e-05, -6.0152e-04, -8.2730e-04,\n",
      "         -3.5413e-04, -1.6196e-02, -1.0506e-03, -2.8630e-02, -2.5852e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1983], requires_grad=True)\n",
      "bias grad:  tensor([-0.1592])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6559]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2647]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1015,  -322.8743,   -11.4340,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1967], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6294]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1015,  -322.8743,   -11.4340,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.4109e-03,  9.8260e-06,  2.3677e-05,  1.0247e-04, -1.4556e-04,\n",
      "          1.1871e-03,  2.4719e-02,  7.3753e-04,  8.8976e-03,  5.7084e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1967], requires_grad=True)\n",
      "bias grad:  tensor([0.0573])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6294]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0179]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1018,  -322.8743,   -11.4341,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1973], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6277]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1018,  -322.8743,   -11.4341,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.6008e-04,  0.0000e+00, -1.0512e-04, -6.7689e-04, -1.0068e-04,\n",
      "         -5.1118e-03, -1.3213e-01, -3.1654e-03, -5.5348e-02, -3.4977e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1973], requires_grad=True)\n",
      "bias grad:  tensor([-0.3467])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6277]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.2142]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8743,   -11.4336,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1938], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5062]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8743,   -11.4336,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.1105e-03,  3.6348e-05, -2.5695e-05,  2.9406e-04,  7.4006e-04,\n",
      "         -3.5002e-03, -7.1741e-02, -4.7046e-04,  7.0293e-03, -7.9199e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1938], requires_grad=True)\n",
      "bias grad:  tensor([0.0203])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5062]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3436]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0997,  -322.8743,   -11.4336,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1940], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5406]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0997,  -322.8743,   -11.4336,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.7331e-03, -7.1130e-05, -7.2526e-05, -7.9001e-04, -8.1950e-05,\n",
      "         -2.3115e-03, -7.3060e-02, -1.8416e-03, -3.8644e-02, -2.8482e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1940], requires_grad=True)\n",
      "bias grad:  tensor([-0.2430])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5406]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9287]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0990,  -322.8743,   -11.4333,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1916], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4477]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0990,  -322.8743,   -11.4333,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 9.5322e-05, -1.8620e-04, -7.1675e-05, -6.1379e-04, -3.6973e-05,\n",
      "         -3.8797e-03, -9.1193e-02, -2.2912e-03, -3.7416e-02, -4.9463e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1916], requires_grad=True)\n",
      "bias grad:  tensor([-0.2340])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4477]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7687]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0981,  -322.8742,   -11.4329,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1892], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3708]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0981,  -322.8742,   -11.4329,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0058, 0.0000, 0.0003, 0.0031, 0.0008, 0.0018, 0.1207, 0.0059, 0.1624,\n",
      "         0.0032]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1892], requires_grad=True)\n",
      "bias grad:  tensor([0.9312])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3708]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.7767]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0993,  -322.8743,   -11.4345,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1985], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7485]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0993,  -322.8743,   -11.4345,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.8247e-03,  8.0064e-06, -1.0125e-04, -1.5667e-03, -1.0926e-03,\n",
      "         -1.3116e-03, -7.4742e-02, -3.7384e-03, -8.1988e-02, -9.4405e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1985], requires_grad=True)\n",
      "bias grad:  tensor([-0.4795])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7485]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4636]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0985,  -322.8743,   -11.4337,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1938], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7022]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0985,  -322.8743,   -11.4337,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3845e-03,  2.3583e-05,  5.0407e-05,  5.5434e-04,  2.1574e-04,\n",
      "          2.1712e-03,  5.6708e-02,  1.7893e-03,  3.1263e-02,  1.0754e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1938], requires_grad=True)\n",
      "bias grad:  tensor([0.1968])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7022]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2024]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0991,  -322.8743,   -11.4340,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1957], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7224]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0991,  -322.8743,   -11.4340,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5681e-03, 0.0000e+00, 9.3266e-05, 1.1420e-03, 7.1007e-04, 4.8729e-04,\n",
      "         8.4008e-02, 3.2956e-03, 7.1892e-02, 1.8323e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1957], requires_grad=True)\n",
      "bias grad:  tensor([0.4148])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7224]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1265]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0999,  -322.8743,   -11.4347,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1999], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7098]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0999,  -322.8743,   -11.4347,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0415e-03,  0.0000e+00, -1.7228e-05, -4.3384e-04, -3.8070e-04,\n",
      "          7.7846e-05, -2.7044e-03, -7.4453e-04, -1.9092e-02,  1.5466e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1999], requires_grad=True)\n",
      "bias grad:  tensor([-0.1087])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7098]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3767]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0999,  -322.8743,   -11.4345,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1988], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6721]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0999,  -322.8743,   -11.4345,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.9422e-04,  5.4558e-05,  7.4661e-06, -1.1994e-05, -4.3305e-04,\n",
      "          3.1866e-04,  1.1080e-02,  1.0342e-04,  2.0358e-03,  2.0536e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1988], requires_grad=True)\n",
      "bias grad:  tensor([0.0120])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6721]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1979]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1000,  -322.8743,   -11.4345,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1989], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6919]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1000,  -322.8743,   -11.4345,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0826e-04, -1.2612e-04, -8.6918e-05, -1.0791e-03, -2.1476e-04,\n",
      "         -2.2544e-03, -7.1488e-02, -2.6239e-03, -5.7110e-02, -6.0675e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1989], requires_grad=True)\n",
      "bias grad:  tensor([-0.3265])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6919]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7959]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0993,  -322.8743,   -11.4340,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1956], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6123]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0993,  -322.8743,   -11.4340,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4965e-03,  0.0000e+00,  4.0379e-05,  4.3453e-04,  2.2109e-04,\n",
      "          5.1539e-04,  2.3464e-02,  1.4784e-03,  2.7930e-02,  7.8736e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1956], requires_grad=True)\n",
      "bias grad:  tensor([0.1647])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6123]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0696]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0995,  -322.8743,   -11.4342,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1973], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6193]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0995,  -322.8743,   -11.4342,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.4558e-04, -1.0968e-06, -1.6427e-05, -3.4164e-04, -6.5876e-05,\n",
      "          9.9158e-04,  8.4689e-03, -3.3196e-04, -1.7730e-02,  8.3563e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1973], requires_grad=True)\n",
      "bias grad:  tensor([-0.0905])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6193]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3521]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0996,  -322.8743,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1964], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5840]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0996,  -322.8743,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[1.9878e-03, 3.1033e-05, 6.1194e-05, 7.1525e-04, 5.2557e-04, 2.3588e-03,\n",
      "         7.2522e-02, 2.3279e-03, 4.3630e-02, 1.3226e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1964], requires_grad=True)\n",
      "bias grad:  tensor([0.2561])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5840]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0674]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1004,  -322.8743,   -11.4345,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1989], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5908]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1004,  -322.8743,   -11.4345,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0001e-04, 3.0168e-05, 1.0865e-04, 1.1275e-03, 4.6658e-04, 1.6837e-03,\n",
      "         7.1986e-02, 3.0255e-03, 6.3879e-02, 1.7262e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1989], requires_grad=True)\n",
      "bias grad:  tensor([0.3933])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5908]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2367]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1011,  -322.8744,   -11.4351,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2029], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6145]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1011,  -322.8744,   -11.4351,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[4.5052e-03, 0.0000e+00, 8.3110e-05, 1.0361e-03, 8.2900e-04, 1.0227e-03,\n",
      "         5.6660e-02, 2.7782e-03, 6.4793e-02, 1.9560e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2029], requires_grad=True)\n",
      "bias grad:  tensor([0.3700])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6145]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda grad:  tensor([[-0.3022]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1016,  -322.8744,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2066], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6447]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1016,  -322.8744,   -11.4358,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[9.6600e-04, 0.0000e+00, 2.3607e-05, 2.0337e-04, 1.8026e-04, 3.2181e-04,\n",
      "         1.9161e-02, 1.0620e-03, 1.7569e-02, 3.4110e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2066], requires_grad=True)\n",
      "bias grad:  tensor([0.0998])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6447]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2452]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.1018,  -322.8744,   -11.4360,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2076], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6202]], requires_grad=True)\n",
      "Iteration 18 | Score: 0.5389605164527893\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8737,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-0.0005,  0.0003,  0.0002,  0.0025,  0.0006,  0.0064,  0.1889,  0.0059,\n",
      "          0.1129,  0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1246], requires_grad=True)\n",
      "bias grad:  tensor([0.6989])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7845]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.9304]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0923,  -322.8738,   -11.4231,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1316], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8775]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0923,  -322.8738,   -11.4231,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9035e-03,  0.0000e+00, -1.2339e-05, -3.7810e-04, -9.1418e-05,\n",
      "          3.6975e-04,  8.8570e-04, -1.2210e-04, -1.2506e-02, -1.1658e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1316], requires_grad=True)\n",
      "bias grad:  tensor([-0.0715])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8775]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4637]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0923,  -322.8738,   -11.4230,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1309], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8312]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0923,  -322.8738,   -11.4230,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4909e-04, 3.4985e-05, 6.7891e-05, 8.7475e-04, 5.9016e-04, 7.9924e-04,\n",
      "         4.4077e-02, 2.2594e-03, 5.0618e-02, 1.4509e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1309], requires_grad=True)\n",
      "bias grad:  tensor([0.3063])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8312]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0924]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0928,  -322.8738,   -11.4235,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1340], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8404]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0928,  -322.8738,   -11.4235,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5617e-03, -4.6685e-05,  2.0794e-05,  2.2858e-04,  1.3265e-04,\n",
      "          6.5554e-04,  1.9219e-02,  1.3710e-03,  2.3292e-02,  1.5548e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1340], requires_grad=True)\n",
      "bias grad:  tensor([0.1293])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8404]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7594]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0930,  -322.8738,   -11.4237,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1352], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7645]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0930,  -322.8738,   -11.4237,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[4.9755e-04, 1.1519e-06, 5.7127e-05, 4.6443e-04, 1.2593e-04, 2.3335e-03,\n",
      "         5.6700e-02, 1.6676e-03, 3.3564e-02, 1.0827e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1352], requires_grad=True)\n",
      "bias grad:  tensor([0.1902])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7645]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0168]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0935,  -322.8738,   -11.4241,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1372], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7628]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0935,  -322.8738,   -11.4241,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.5203e-03, -4.9219e-05, -6.2555e-05, -1.1138e-03, -7.7764e-04,\n",
      "         -5.0126e-04, -4.2516e-02, -1.8652e-03, -5.0485e-02, -1.6602e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1372], requires_grad=True)\n",
      "bias grad:  tensor([-0.2935])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7628]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9675]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0931,  -322.8738,   -11.4236,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1342], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6660]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0931,  -322.8738,   -11.4236,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.5419e-04,  0.0000e+00, -2.0674e-05, -3.3612e-04, -9.2472e-05,\n",
      "         -8.4701e-05, -5.2002e-03, -1.1419e-03, -2.2348e-02, -7.0691e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1342], requires_grad=True)\n",
      "bias grad:  tensor([-0.1229])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6660]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1785]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0931,  -322.8738,   -11.4234,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1330], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6839]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0931,  -322.8738,   -11.4234,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[5.1844e-03, 3.3585e-05, 1.1064e-04, 1.3722e-03, 1.0258e-03, 1.5582e-03,\n",
      "         7.7840e-02, 3.9233e-03, 8.4919e-02, 2.7761e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1330], requires_grad=True)\n",
      "bias grad:  tensor([0.5016])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6839]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1070]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0938,  -322.8738,   -11.4242,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1380], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6946]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0938,  -322.8738,   -11.4242,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5564e-02,  0.0000e+00, -2.3340e-05, -6.8514e-04, -9.2267e-04,\n",
      "         -4.1465e-04, -1.8922e-02, -1.2774e-03, -3.3394e-02, -3.2059e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1380], requires_grad=True)\n",
      "bias grad:  tensor([-0.1865])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6946]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2847]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0936,  -322.8738,   -11.4239,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1361], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6661]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0936,  -322.8738,   -11.4239,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.3873e-03,  1.2888e-05,  3.1479e-05,  1.8224e-04, -1.3855e-04,\n",
      "          1.1689e-03,  2.6549e-02,  9.7232e-04,  1.4155e-02,  7.9951e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1361], requires_grad=True)\n",
      "bias grad:  tensor([0.0876])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6661]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0473]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0939,  -322.8738,   -11.4240,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1370], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6614]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0939,  -322.8738,   -11.4240,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.2804e-04,  0.0000e+00, -1.0990e-04, -6.8622e-04, -1.4030e-04,\n",
      "         -5.2986e-03, -1.3735e-01, -3.1883e-03, -5.7004e-02, -2.1792e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1370], requires_grad=True)\n",
      "bias grad:  tensor([-0.3566])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6614]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1900]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0925,  -322.8738,   -11.4234,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1334], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5424]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0925,  -322.8738,   -11.4234,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.1650e-03,  2.4880e-05, -2.7051e-05,  2.2024e-04,  6.8503e-04,\n",
      "         -3.4522e-03, -7.1673e-02, -5.6250e-04,  4.4817e-03, -7.1925e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1334], requires_grad=True)\n",
      "bias grad:  tensor([0.0064])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5424]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0267]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0918,  -322.8738,   -11.4235,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1335], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5451]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0918,  -322.8738,   -11.4235,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.5791e-03, -6.2762e-05, -3.5035e-05, -3.2416e-04,  1.4269e-04,\n",
      "         -1.6239e-03, -4.4568e-02, -5.6999e-04, -1.2859e-02,  2.2517e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1335], requires_grad=True)\n",
      "bias grad:  tensor([-0.0909])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5451]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7145]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8738,   -11.4234,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1326], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4736]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0914,  -322.8738,   -11.4234,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.3152e-04, -1.8861e-04, -4.8014e-05, -3.7512e-04,  6.3762e-05,\n",
      "         -3.7423e-03, -8.1394e-02, -1.7559e-03, -2.2660e-02, -6.0326e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1326], requires_grad=True)\n",
      "bias grad:  tensor([-0.1546])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4736]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6233]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0906,  -322.8738,   -11.4231,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1311], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4113]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0906,  -322.8738,   -11.4231,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0048, 0.0000, 0.0002, 0.0025, 0.0006, 0.0014, 0.0923, 0.0046, 0.1304,\n",
      "         0.0026]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1311], requires_grad=True)\n",
      "bias grad:  tensor([0.7485])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4113]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.8595]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0915,  -322.8738,   -11.4244,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1385], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6972]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0915,  -322.8738,   -11.4244,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.1228e-03,  2.3791e-05, -7.3117e-05, -1.1536e-03, -8.6636e-04,\n",
      "         -8.3129e-04, -5.5501e-02, -2.7784e-03, -6.1497e-02, -6.3072e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1385], requires_grad=True)\n",
      "bias grad:  tensor([-0.3546])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6972]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2435]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8738,   -11.4238,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1350], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6729]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0909,  -322.8738,   -11.4238,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6668e-03,  3.9025e-05,  6.5279e-05,  7.3850e-04,  2.9728e-04,\n",
      "          2.5979e-03,  6.9426e-02,  2.3039e-03,  4.0330e-02,  1.3051e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1350], requires_grad=True)\n",
      "bias grad:  tensor([0.2571])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6729]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2086]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0916,  -322.8738,   -11.4242,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1376], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6938]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0916,  -322.8738,   -11.4242,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[2.3478e-03, 0.0000e+00, 8.4913e-05, 1.0019e-03, 5.2772e-04, 3.9280e-04,\n",
      "         7.5606e-02, 2.9550e-03, 6.3613e-02, 1.7198e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1376], requires_grad=True)\n",
      "bias grad:  tensor([0.3665])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6938]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1181]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0924,  -322.8739,   -11.4249,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1412], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6819]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0924,  -322.8739,   -11.4249,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.7447e-04,  0.0000e+00,  1.0586e-05,  2.0056e-07, -7.8583e-05,\n",
      "          3.2179e-04,  1.3353e-02,  3.0589e-04,  5.1290e-03,  4.7997e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1412], requires_grad=True)\n",
      "bias grad:  tensor([0.0294])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6819]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1997]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0925,  -322.8739,   -11.4249,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1415], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6620]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0925,  -322.8739,   -11.4249,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3688e-04,  7.3922e-05,  3.8646e-05,  3.9391e-04, -1.5867e-04,\n",
      "          7.7036e-04,  3.1028e-02,  1.2884e-03,  2.6939e-02,  8.0857e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1415], requires_grad=True)\n",
      "bias grad:  tensor([0.1555])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6620]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2196]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0928,  -322.8739,   -11.4252,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1431], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6839]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0928,  -322.8739,   -11.4252,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.3200e-04, -1.0760e-04, -6.8767e-05, -8.0555e-04, -8.4613e-05,\n",
      "         -2.2227e-03, -6.3313e-02, -2.0654e-03, -4.2843e-02, -4.0148e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1431], requires_grad=True)\n",
      "bias grad:  tensor([-0.2447])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6839]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6475]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0922,  -322.8738,   -11.4248,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1406], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6192]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0922,  -322.8738,   -11.4248,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1367e-03,  0.0000e+00,  7.5333e-05,  8.0284e-04,  4.2453e-04,\n",
      "          1.0107e-03,  4.1767e-02,  2.6444e-03,  5.0642e-02,  1.4528e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1406], requires_grad=True)\n",
      "bias grad:  tensor([0.3029])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6192]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0003]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0926,  -322.8739,   -11.4253,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1437], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6192]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0926,  -322.8739,   -11.4253,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8832e-03,  1.0279e-05, -1.0336e-05, -3.0403e-04, -1.5822e-04,\n",
      "          1.2755e-03,  1.5060e-02, -2.1252e-04, -1.5526e-02,  3.1789e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1437], requires_grad=True)\n",
      "bias grad:  tensor([-0.0783])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6192]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3667]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0928,  -322.8739,   -11.4251,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1429], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5825]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0928,  -322.8739,   -11.4251,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7674e-03, 4.0055e-05, 6.0717e-05, 6.6565e-04, 4.2331e-04, 2.4609e-03,\n",
      "         7.3000e-02, 2.1499e-03, 4.0537e-02, 1.3242e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1429], requires_grad=True)\n",
      "bias grad:  tensor([0.2374])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5825]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1625]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0935,  -322.8739,   -11.4255,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1453], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5987]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0935,  -322.8739,   -11.4255,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.6133e-04, 3.9635e-05, 1.2948e-04, 1.3752e-03, 5.5890e-04, 1.8010e-03,\n",
      "         8.3111e-02, 3.5574e-03, 7.6011e-02, 2.0503e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1453], requires_grad=True)\n",
      "bias grad:  tensor([0.4756])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5987]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3832]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0943,  -322.8739,   -11.4263,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1500], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6371]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0943,  -322.8739,   -11.4263,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.8814e-03, 0.0000e+00, 9.2004e-05, 1.1388e-03, 9.5656e-04, 1.3294e-03,\n",
      "         6.7034e-02, 3.2983e-03, 7.3748e-02, 2.2169e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1500], requires_grad=True)\n",
      "bias grad:  tensor([0.4209])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6371]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0733]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0950,  -322.8740,   -11.4270,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1542], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6444]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0950,  -322.8740,   -11.4270,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6411e-03, 0.0000e+00, 2.5989e-05, 2.7749e-04, 2.4515e-04, 4.0696e-04,\n",
      "         2.3930e-02, 1.2388e-03, 2.0567e-02, 1.6067e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1542], requires_grad=True)\n",
      "bias grad:  tensor([0.1174])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6444]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1772]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0952,  -322.8740,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1554], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6267]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0952,  -322.8740,   -11.4272,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0009, 0.0003, 0.0003, 0.0031, 0.0007, 0.0077, 0.2253, 0.0071, 0.1346,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1554], requires_grad=True)\n",
      "bias grad:  tensor([0.8350])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6267]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6679]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0975,  -322.8740,   -11.4286,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1637], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7935]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0975,  -322.8740,   -11.4286,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6953e-03,  0.0000e+00, -4.6653e-06, -2.5212e-04, -1.1706e-05,\n",
      "          3.0934e-04,  4.3431e-03,  1.9734e-04, -5.4154e-03, -4.7449e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1637], requires_grad=True)\n",
      "bias grad:  tensor([-0.0324])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7935]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4058]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0975,  -322.8740,   -11.4285,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1634], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7529]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0975,  -322.8740,   -11.4285,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.7225e-04,  2.7429e-05,  6.3681e-05,  7.7816e-04,  5.0023e-04,\n",
      "          7.3088e-04,  3.9831e-02,  1.9714e-03,  4.5108e-02,  1.4339e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1634], requires_grad=True)\n",
      "bias grad:  tensor([0.2741])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7529]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0918]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0979,  -322.8741,   -11.4290,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1662], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7621]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0979,  -322.8741,   -11.4290,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4935e-03, -3.0430e-05,  2.4124e-05,  2.6340e-04,  9.9547e-05,\n",
      "          5.6248e-04,  2.0254e-02,  1.3210e-03,  2.3256e-02,  1.3083e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1662], requires_grad=True)\n",
      "bias grad:  tensor([0.1299])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7621]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5516]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0981,  -322.8741,   -11.4292,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1675], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7069]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0981,  -322.8741,   -11.4292,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[4.8184e-04, 1.5190e-06, 4.7070e-05, 3.4755e-04, 6.4083e-05, 2.0637e-03,\n",
      "         4.8069e-02, 1.2894e-03, 2.5863e-02, 9.0454e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1675], requires_grad=True)\n",
      "bias grad:  tensor([0.1461])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7069]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0422]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0986,  -322.8741,   -11.4294,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1689], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7111]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0986,  -322.8741,   -11.4294,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.3155e-03, -3.4690e-05, -4.0436e-05, -7.2148e-04, -4.6719e-04,\n",
      "         -3.6689e-04, -2.6885e-02, -1.1512e-03, -3.0421e-02,  9.5272e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1689], requires_grad=True)\n",
      "bias grad:  tensor([-0.1787])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7111]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7028]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0983,  -322.8741,   -11.4291,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1671], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6408]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0983,  -322.8741,   -11.4291,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.6995e-04,  0.0000e+00, -3.6563e-06, -1.3992e-04, -2.2545e-05,\n",
      "          3.6399e-05,  2.0934e-03, -6.8376e-04, -1.1007e-02, -4.1837e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1671], requires_grad=True)\n",
      "bias grad:  tensor([-0.0564])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6408]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3002]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0984,  -322.8741,   -11.4290,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1666], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6709]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0984,  -322.8741,   -11.4290,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[3.9794e-03, 3.2978e-05, 8.3985e-05, 1.0413e-03, 7.7305e-04, 1.2960e-03,\n",
      "         6.1977e-02, 3.0429e-03, 6.3822e-02, 2.3288e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1666], requires_grad=True)\n",
      "bias grad:  tensor([0.3806])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6709]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1200]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0990,  -322.8741,   -11.4297,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1704], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6829]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0228,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0990,  -322.8741,   -11.4297,  -302.5946]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight grad:  tensor([[-2.1208e-02,  0.0000e+00, -6.7905e-05, -1.3763e-03, -1.7099e-03,\n",
      "         -9.1550e-04, -4.1486e-02, -3.1567e-03, -7.2822e-02, -8.3500e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1704], requires_grad=True)\n",
      "bias grad:  tensor([-0.4117])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6829]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2217]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0986,  -322.8741,   -11.4289,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1663], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6607]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0986,  -322.8741,   -11.4289,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.7701e-03,  1.0674e-05,  3.0673e-05,  1.6058e-04, -1.5072e-04,\n",
      "          1.1401e-03,  2.6327e-02,  9.6773e-04,  1.3402e-02,  7.6291e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1663], requires_grad=True)\n",
      "bias grad:  tensor([0.0843])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6607]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1187]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0988,  -322.8741,   -11.4291,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1671], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6488]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0988,  -322.8741,   -11.4291,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.3890e-04,  0.0000e+00, -8.0380e-05, -3.1515e-04,  2.5149e-04,\n",
      "         -5.1567e-03, -1.1953e-01, -2.3560e-03, -3.3722e-02,  7.0970e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1671], requires_grad=True)\n",
      "bias grad:  tensor([-0.2233])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6488]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.2614]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0976,  -322.8740,   -11.4287,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1649], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5227]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0976,  -322.8740,   -11.4287,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.8114e-03,  3.2576e-05, -1.1132e-05,  4.7051e-04,  8.4600e-04,\n",
      "         -3.3375e-03, -6.2183e-02,  4.0999e-05,  1.7462e-02, -4.9983e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1649], requires_grad=True)\n",
      "bias grad:  tensor([0.0839])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5227]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3224]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0970,  -322.8740,   -11.4289,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1657], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5549]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0970,  -322.8740,   -11.4289,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.5773e-03, -7.2171e-05, -6.4161e-05, -6.9271e-04, -3.2009e-05,\n",
      "         -2.2824e-03, -6.7887e-02, -1.5294e-03, -3.2718e-02, -1.2719e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1657], requires_grad=True)\n",
      "bias grad:  tensor([-0.2087])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5549]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9873]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8740,   -11.4286,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1636], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4562]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0963,  -322.8740,   -11.4286,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.2055e-04, -1.7892e-04, -5.6943e-05, -4.5534e-04,  2.1064e-06,\n",
      "         -3.6729e-03, -7.9822e-02, -1.9157e-03, -2.8514e-02, -2.2406e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1636], requires_grad=True)\n",
      "bias grad:  tensor([-0.1778])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4562]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7081]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0955,  -322.8740,   -11.4283,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1618], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3854]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0955,  -322.8740,   -11.4283,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0054, 0.0000, 0.0002, 0.0027, 0.0003, 0.0015, 0.0985, 0.0047, 0.1372,\n",
      "         0.0029]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1618], requires_grad=True)\n",
      "bias grad:  tensor([0.7885])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3854]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.6824]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0965,  -322.8740,   -11.4297,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1697], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7536]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0965,  -322.8740,   -11.4297,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.9721e-03,  2.1002e-05, -8.2691e-05, -1.2574e-03, -8.5513e-04,\n",
      "         -1.2468e-03, -6.3448e-02, -2.9848e-03, -6.5258e-02, -7.2614e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1697], requires_grad=True)\n",
      "bias grad:  tensor([-0.3832])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7536]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4025]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0959,  -322.8740,   -11.4290,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1659], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7134]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0959,  -322.8740,   -11.4290,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2314e-03,  3.2585e-05,  6.3896e-05,  7.3905e-04,  3.7242e-04,\n",
      "          2.3003e-03,  6.4530e-02,  2.2791e-03,  4.1057e-02,  1.2471e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1659], requires_grad=True)\n",
      "bias grad:  tensor([0.2582])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7134]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1421]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0965,  -322.8740,   -11.4294,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1685], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7276]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0965,  -322.8740,   -11.4294,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0029, 0.0000, 0.0001, 0.0012, 0.0007, 0.0006, 0.0869, 0.0036, 0.0773,\n",
      "         0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1685], requires_grad=True)\n",
      "bias grad:  tensor([0.4452])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7276]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1368]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0974,  -322.8741,   -11.4302,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1729], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7139]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0974,  -322.8741,   -11.4302,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.4479e-03,  0.0000e+00, -1.2727e-05, -3.9512e-04, -3.6300e-04,\n",
      "          1.2185e-04,  4.0199e-04, -5.9005e-04, -1.5898e-02,  2.7657e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1729], requires_grad=True)\n",
      "bias grad:  tensor([-0.0906])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7139]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4222]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0974,  -322.8741,   -11.4300,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1720], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6717]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0974,  -322.8741,   -11.4300,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.0319e-04,  6.7658e-05,  2.9097e-05,  2.8174e-04, -1.9820e-04,\n",
      "          6.0856e-04,  2.3489e-02,  9.3234e-04,  1.9526e-02,  5.8086e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1720], requires_grad=True)\n",
      "bias grad:  tensor([0.1125])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6717]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2206]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0976,  -322.8741,   -11.4302,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1731], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6937]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0976,  -322.8741,   -11.4302,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5346e-06, -9.6470e-05, -6.4638e-05, -7.9131e-04, -1.2887e-04,\n",
      "         -2.0956e-03, -5.9644e-02, -1.9834e-03, -4.1375e-02, -3.0852e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1731], requires_grad=True)\n",
      "bias grad:  tensor([-0.2370])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6937]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6249]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8740,   -11.4298,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1708], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6313]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0970,  -322.8740,   -11.4298,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3279e-03,  0.0000e+00,  5.9631e-05,  6.8607e-04,  3.7407e-04,\n",
      "          6.4559e-04,  3.1928e-02,  2.1838e-03,  4.3185e-02,  1.1062e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1708], requires_grad=True)\n",
      "bias grad:  tensor([0.2530])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6313]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0173]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0974,  -322.8741,   -11.4303,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1733], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6330]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0974,  -322.8741,   -11.4303,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6501e-04,  1.5129e-05, -7.6121e-06, -2.3580e-04, -4.4441e-05,\n",
      "          1.2220e-03,  1.6048e-02, -7.2749e-05, -1.1061e-02,  3.9776e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1733], requires_grad=True)\n",
      "bias grad:  tensor([-0.0576])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6330]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3718]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0975,  -322.8741,   -11.4301,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1727], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5958]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0975,  -322.8741,   -11.4301,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[ 5.5658e-04,  3.0073e-05,  2.4073e-05,  1.9142e-04, -3.9987e-06,\n",
      "          1.8889e-03,  4.3675e-02,  6.8786e-04,  1.0283e-02,  5.6184e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1727], requires_grad=True)\n",
      "bias grad:  tensor([0.0631])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5958]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2196]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0980,  -322.8741,   -11.4303,  -302.5946]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1734], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6178]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0980,  -322.8741,   -11.4303,  -302.5946]], requires_grad=True)\n",
      "weight grad:  tensor([[2.9137e-04, 3.7911e-05, 1.2545e-04, 1.3486e-03, 6.0541e-04, 1.8878e-03,\n",
      "         8.3256e-02, 3.7235e-03, 7.5473e-02, 2.0876e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1734], requires_grad=True)\n",
      "bias grad:  tensor([0.4748])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6178]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2202]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0988,  -322.8741,   -11.4310,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1781], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6398]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0988,  -322.8741,   -11.4310,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5990e-03, 0.0000e+00, 7.9343e-05, 9.5432e-04, 7.7529e-04, 1.1804e-03,\n",
      "         5.8191e-02, 2.7835e-03, 6.2329e-02, 2.0155e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1781], requires_grad=True)\n",
      "bias grad:  tensor([0.3551])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6398]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1659]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0994,  -322.8741,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1817], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6564]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0994,  -322.8741,   -11.4316,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.3911e-04,  0.0000e+00,  7.7198e-06,  3.3612e-06, -3.5199e-05,\n",
      "          4.9678e-04,  1.5315e-02,  4.8710e-04,  4.5956e-03, -2.9469e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1817], requires_grad=True)\n",
      "bias grad:  tensor([0.0241])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6564]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1179]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0995,  -322.8741,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1819], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6446]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0995,  -322.8741,   -11.4317,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0007, 0.0003, 0.0002, 0.0029, 0.0007, 0.0073, 0.2107, 0.0066, 0.1264,\n",
      "         0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1819], requires_grad=True)\n",
      "bias grad:  tensor([0.7835])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6446]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.5192]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1016,  -322.8742,   -11.4329,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1897], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7965]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0229,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1016,  -322.8742,   -11.4329,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.8178e-03,  0.0000e+00, -1.6069e-05, -4.2726e-04, -2.4031e-04,\n",
      "          2.8314e-04, -4.1459e-03, -3.3751e-04, -1.6584e-02, -1.6727e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1897], requires_grad=True)\n",
      "bias grad:  tensor([-0.0960])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7965]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3156]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1016,  -322.8742,   -11.4328,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1888], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7649]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1016,  -322.8742,   -11.4328,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6347e-04, 3.7443e-05, 7.4830e-05, 9.4128e-04, 5.6333e-04, 8.6956e-04,\n",
      "         4.7364e-02, 2.3437e-03, 5.3486e-02, 1.5121e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1888], requires_grad=True)\n",
      "bias grad:  tensor([0.3248])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7649]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1908]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1021,  -322.8742,   -11.4333,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1920], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7840]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1021,  -322.8742,   -11.4333,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2346e-03, -4.0217e-05,  2.3161e-05,  2.6146e-04,  1.3738e-04,\n",
      "          4.8601e-04,  1.7606e-02,  1.4131e-03,  2.4553e-02,  1.5148e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1920], requires_grad=True)\n",
      "bias grad:  tensor([0.1367])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7840]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6705]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1022,  -322.8742,   -11.4336,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1934], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7170]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1022,  -322.8742,   -11.4336,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[2.7011e-05, 1.0983e-05, 4.7581e-05, 3.1658e-04, 2.7052e-05, 2.2346e-03,\n",
      "         5.1200e-02, 1.2183e-03, 2.3954e-02, 9.6058e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1934], requires_grad=True)\n",
      "bias grad:  tensor([0.1359])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7170]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0072]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1027,  -322.8742,   -11.4338,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1948], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7163]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1027,  -322.8742,   -11.4338,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.5365e-03, -4.3555e-05, -5.5624e-05, -9.5319e-04, -6.3051e-04,\n",
      "         -4.7767e-04, -3.4654e-02, -1.6592e-03, -4.3589e-02, -6.7269e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1948], requires_grad=True)\n",
      "bias grad:  tensor([-0.2537])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7163]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7779]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1024,  -322.8742,   -11.4334,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1922], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6385]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1024,  -322.8742,   -11.4334,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.3618e-03,  0.0000e+00, -1.6943e-06, -1.0720e-04,  2.8256e-05,\n",
      "          5.7200e-05,  4.1526e-03, -5.8277e-04, -8.5296e-03, -3.7129e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1922], requires_grad=True)\n",
      "bias grad:  tensor([-0.0421])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6385]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2576]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1024,  -322.8742,   -11.4333,  -302.5947]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1918], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6642]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1024,  -322.8742,   -11.4333,  -302.5947]], requires_grad=True)\n",
      "weight grad:  tensor([[4.0716e-03, 2.8525e-05, 9.0981e-05, 1.1282e-03, 8.6928e-04, 1.3540e-03,\n",
      "         6.6850e-02, 3.2990e-03, 7.0353e-02, 2.4704e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1918], requires_grad=True)\n",
      "bias grad:  tensor([0.4174])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6642]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0624]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1031,  -322.8742,   -11.4340,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1960], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6705]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0230,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1031,  -322.8742,   -11.4340,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7233e-02,  0.0000e+00, -5.5630e-05, -1.1239e-03, -1.3951e-03,\n",
      "         -7.4831e-04, -3.3907e-02, -2.5828e-03, -5.9516e-02, -6.8349e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1960], requires_grad=True)\n",
      "bias grad:  tensor([-0.3365])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6705]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1521]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1028,  -322.8742,   -11.4334,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1926], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6552]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1028,  -322.8742,   -11.4334,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.6582e-03,  2.0646e-05,  1.8302e-05, -4.6015e-05, -3.3752e-04,\n",
      "          1.0195e-03,  1.6390e-02,  4.6628e-04,  1.8936e-03,  6.9324e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1926], requires_grad=True)\n",
      "bias grad:  tensor([0.0170])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6552]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1820]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1029,  -322.8742,   -11.4334,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1928], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6370]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1029,  -322.8742,   -11.4334,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2548e-03,  0.0000e+00, -1.1954e-04, -8.0833e-04, -2.2230e-04,\n",
      "         -5.4247e-03, -1.4380e-01, -3.5530e-03, -6.4602e-02, -3.6440e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1928], requires_grad=True)\n",
      "bias grad:  tensor([-0.4007])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6370]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1670]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1015,  -322.8741,   -11.4328,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1888], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5204]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1015,  -322.8741,   -11.4328,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.8402e-03,  3.1121e-05, -3.2246e-05,  1.9704e-04,  6.2438e-04,\n",
      "         -3.6583e-03, -7.7711e-02, -7.4057e-04,  1.1064e-03, -8.4982e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1888], requires_grad=True)\n",
      "bias grad:  tensor([-0.0124])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5204]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2320]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1007,  -322.8741,   -11.4328,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1886], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5436]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1007,  -322.8741,   -11.4328,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.0772e-03, -6.6786e-05, -5.7101e-05, -6.1402e-04,  2.3935e-05,\n",
      "         -2.1019e-03, -6.2353e-02, -1.3367e-03, -2.8306e-02, -6.2168e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1886], requires_grad=True)\n",
      "bias grad:  tensor([-0.1832])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5436]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9586]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1001,  -322.8741,   -11.4325,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1868], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4477]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1001,  -322.8741,   -11.4325,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.7042e-05, -1.8430e-04, -5.6587e-05, -4.8042e-04, -3.1708e-05,\n",
      "         -3.7504e-03, -8.5302e-02, -1.9205e-03, -2.8984e-02, -1.5240e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1868], requires_grad=True)\n",
      "bias grad:  tensor([-0.1853])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4477]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7360]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0992,  -322.8741,   -11.4322,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1850], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3741]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0992,  -322.8741,   -11.4322,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0058, 0.0000, 0.0002, 0.0030, 0.0006, 0.0018, 0.1115, 0.0054, 0.1522,\n",
      "         0.0030]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1850], requires_grad=True)\n",
      "bias grad:  tensor([0.8741])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3741]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.9809]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8742,   -11.4337,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1937], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7722]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1004,  -322.8742,   -11.4337,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2789e-03,  1.3489e-05, -9.6539e-05, -1.5182e-03, -1.0523e-03,\n",
      "         -1.1858e-03, -6.9004e-02, -3.5815e-03, -7.9533e-02, -8.4064e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1937], requires_grad=True)\n",
      "bias grad:  tensor([-0.4627])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7722]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5175]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0997,  -322.8741,   -11.4329,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1891], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7204]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.0997,  -322.8741,   -11.4329,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7249e-03,  2.4818e-05,  5.0808e-05,  5.4252e-04,  1.7998e-04,\n",
      "          2.4575e-03,  6.0969e-02,  1.7559e-03,  2.6894e-02,  1.1821e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1891], requires_grad=True)\n",
      "bias grad:  tensor([0.1892])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7204]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1340]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1003,  -322.8742,   -11.4332,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1910], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7338]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1003,  -322.8742,   -11.4332,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[2.3668e-03, 0.0000e+00, 4.7551e-05, 6.4980e-04, 4.4018e-04, 1.6302e-04,\n",
      "         2.9626e-02, 1.7571e-03, 4.0071e-02, 9.0342e-04]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias before:  Parameter containing:\n",
      "tensor([-0.1910], requires_grad=True)\n",
      "bias grad:  tensor([0.2332])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7338]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0257]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1006,  -322.8742,   -11.4336,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1933], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7313]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1006,  -322.8742,   -11.4336,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7723e-03,  0.0000e+00, -2.1430e-05, -5.0380e-04, -4.0686e-04,\n",
      "          8.1085e-05, -4.9494e-03, -9.0334e-04, -2.2604e-02,  1.7149e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1933], requires_grad=True)\n",
      "bias grad:  tensor([-0.1290])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7313]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4639]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1005,  -322.8742,   -11.4334,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1920], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6849]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1005,  -322.8742,   -11.4334,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0379e-04,  6.6469e-05,  2.1383e-05,  1.6204e-04, -3.2972e-04,\n",
      "          5.6298e-04,  2.0655e-02,  6.4129e-04,  1.2807e-02,  4.5998e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1920], requires_grad=True)\n",
      "bias grad:  tensor([0.0741])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6849]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1700]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1007,  -322.8742,   -11.4335,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1927], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7019]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1007,  -322.8742,   -11.4335,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.8230e-04, -1.2429e-04, -8.0254e-05, -9.8879e-04, -1.7814e-04,\n",
      "         -2.2465e-03, -6.9651e-02, -2.4407e-03, -5.2176e-02, -5.0902e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1927], requires_grad=True)\n",
      "bias grad:  tensor([-0.2984])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7019]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7643]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1000,  -322.8742,   -11.4330,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1898], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6254]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1000,  -322.8742,   -11.4330,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1068e-03,  0.0000e+00,  5.5202e-05,  5.7970e-04,  2.5471e-04,\n",
      "          4.6698e-04,  2.3989e-02,  1.9815e-03,  3.7368e-02,  1.1458e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1898], requires_grad=True)\n",
      "bias grad:  tensor([0.2191])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6254]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0285]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1003,  -322.8742,   -11.4333,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1920], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6226]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1003,  -322.8742,   -11.4333,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.9405e-04,  9.6790e-06, -2.6456e-06, -1.5887e-04,  5.5053e-05,\n",
      "          1.2131e-03,  2.1159e-02,  1.5192e-04, -6.0989e-03,  4.9645e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1920], requires_grad=True)\n",
      "bias grad:  tensor([-0.0276])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6226]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3408]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1005,  -322.8742,   -11.4333,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1917], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5885]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4042,\n",
      "            -6.1005,  -322.8742,   -11.4333,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[5.5649e-04, 3.4990e-05, 4.4164e-05, 4.4785e-04, 2.4508e-04, 2.4766e-03,\n",
      "         6.5878e-02, 1.6139e-03, 2.7607e-02, 9.5442e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1917], requires_grad=True)\n",
      "bias grad:  tensor([0.1618])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5885]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0700]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1011,  -322.8742,   -11.4336,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1933], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5955]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1011,  -322.8742,   -11.4336,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[1.2146e-04, 2.6554e-05, 1.0069e-04, 1.0234e-03, 4.3392e-04, 1.4747e-03,\n",
      "         6.6294e-02, 2.8359e-03, 5.6670e-02, 1.6307e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1933], requires_grad=True)\n",
      "bias grad:  tensor([0.3636])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5955]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2099]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1018,  -322.8743,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1969], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6165]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1018,  -322.8743,   -11.4341,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[4.4115e-03, 0.0000e+00, 7.4730e-05, 9.2842e-04, 7.9309e-04, 1.1216e-03,\n",
      "         5.7506e-02, 2.6355e-03, 5.9653e-02, 1.9069e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1969], requires_grad=True)\n",
      "bias grad:  tensor([0.3413])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6165]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1528]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1024,  -322.8743,   -11.4347,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2003], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6318]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1024,  -322.8743,   -11.4347,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[5.7080e-03, 0.0000e+00, 3.3154e-05, 4.2688e-04, 6.9523e-04, 5.1254e-04,\n",
      "         3.1993e-02, 1.9189e-03, 2.9546e-02, 7.9138e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2003], requires_grad=True)\n",
      "bias grad:  tensor([0.1741])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6318]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1740]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1027,  -322.8743,   -11.4350,  -302.5948]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2021], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6144]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1027,  -322.8743,   -11.4350,  -302.5948]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0012, 0.0003, 0.0002, 0.0029, 0.0006, 0.0074, 0.2107, 0.0063, 0.1211,\n",
      "         0.0017]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2021], requires_grad=True)\n",
      "bias grad:  tensor([0.7563])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6144]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.7593]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1048,  -322.8744,   -11.4362,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2096], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7903]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1048,  -322.8744,   -11.4362,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.2286e-03,  0.0000e+00, -1.8695e-05, -4.5065e-04, -2.2266e-04,\n",
      "          2.1885e-04, -6.3190e-03, -4.5454e-04, -1.8068e-02, -2.3614e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2096], requires_grad=True)\n",
      "bias grad:  tensor([-0.1060])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7903]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3253]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1047,  -322.8744,   -11.4360,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2086], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7578]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1047,  -322.8744,   -11.4360,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.8955e-04,  3.7471e-05,  6.5157e-05,  8.0749e-04,  4.5733e-04,\n",
      "          7.7692e-04,  4.1063e-02,  2.1068e-03,  4.5988e-02,  1.3186e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2086], requires_grad=True)\n",
      "bias grad:  tensor([0.2796])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7578]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1446]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1052,  -322.8744,   -11.4365,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2114], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7722]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0231,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1052,  -322.8744,   -11.4365,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3558e-03, -4.5078e-05,  2.6132e-05,  2.8956e-04,  1.3526e-04,\n",
      "          6.1315e-04,  2.1951e-02,  1.5145e-03,  2.6256e-02,  1.4713e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2114], requires_grad=True)\n",
      "bias grad:  tensor([0.1466])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7722]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6603]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1054,  -322.8744,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2129], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7062]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1054,  -322.8744,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0947e-03,  6.4882e-06,  4.6581e-05,  2.8227e-04, -5.2078e-05,\n",
      "          2.2064e-03,  4.9364e-02,  1.1952e-03,  2.3069e-02,  9.6305e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2129], requires_grad=True)\n",
      "bias grad:  tensor([0.1299])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7062]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0721]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1059,  -322.8744,   -11.4370,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2141], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6990]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1059,  -322.8744,   -11.4370,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.7278e-03, -2.8048e-05, -4.5395e-05, -8.0101e-04, -5.3276e-04,\n",
      "         -4.1794e-04, -3.1728e-02, -1.2545e-03, -3.3970e-02,  7.9973e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2141], requires_grad=True)\n",
      "bias grad:  tensor([-0.1995])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6990]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7450]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1056,  -322.8744,   -11.4367,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2122], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6245]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1056,  -322.8744,   -11.4367,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 4.0859e-04,  0.0000e+00, -9.7613e-06, -2.0394e-04, -4.0249e-05,\n",
      "         -1.6105e-05, -1.6320e-03, -7.8808e-04, -1.4419e-02, -4.5940e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2122], requires_grad=True)\n",
      "bias grad:  tensor([-0.0767])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6245]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2505]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1055,  -322.8744,   -11.4365,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2114], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6495]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1055,  -322.8744,   -11.4365,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4298e-03, 2.2997e-05, 8.1414e-05, 9.6726e-04, 7.0228e-04, 1.1637e-03,\n",
      "         5.8334e-02, 2.8672e-03, 5.9716e-02, 2.3646e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2114], requires_grad=True)\n",
      "bias grad:  tensor([0.3577])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6495]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0436]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1061,  -322.8745,   -11.4371,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2150], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6539]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0232,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1061,  -322.8745,   -11.4371,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9455e-02,  0.0000e+00, -4.6732e-05, -1.0717e-03, -1.3735e-03,\n",
      "         -6.8877e-04, -3.1289e-02, -2.2854e-03, -5.5029e-02, -5.9438e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2150], requires_grad=True)\n",
      "bias grad:  tensor([-0.3097])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6539]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3014]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1058,  -322.8744,   -11.4366,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2119], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6238]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1058,  -322.8744,   -11.4366,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.4584e-03,  2.1884e-05,  4.1228e-05,  3.0299e-04, -7.2368e-05,\n",
      "          1.0727e-03,  2.7945e-02,  1.3398e-03,  2.1813e-02,  1.1229e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2119], requires_grad=True)\n",
      "bias grad:  tensor([0.1330])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6238]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0629]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1061,  -322.8744,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2132], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6175]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1061,  -322.8744,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0550e-03,  0.0000e+00, -1.3287e-04, -9.5475e-04, -2.9561e-04,\n",
      "         -5.7664e-03, -1.5442e-01, -4.1142e-03, -7.5116e-02, -5.2313e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2132], requires_grad=True)\n",
      "bias grad:  tensor([-0.4615])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6175]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.0921]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1045,  -322.8744,   -11.4360,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2086], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5083]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1045,  -322.8744,   -11.4360,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.0712e-03,  2.2967e-05, -3.3107e-05,  1.3807e-04,  6.0268e-04,\n",
      "         -3.6265e-03, -7.5307e-02, -7.6907e-04, -7.1857e-04, -7.1193e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2086], requires_grad=True)\n",
      "bias grad:  tensor([-0.0210])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5083]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0662]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1038,  -322.8744,   -11.4360,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2084], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5149]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1038,  -322.8744,   -11.4360,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.9376e-03, -6.9436e-05, -1.8849e-05, -2.6315e-04,  6.2663e-05,\n",
      "         -7.9465e-04, -2.7479e-02, -2.7549e-04, -7.7877e-03,  8.8210e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2084], requires_grad=True)\n",
      "bias grad:  tensor([-0.0605])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5149]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8600]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1035,  -322.8744,   -11.4359,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2078], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4289]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1035,  -322.8744,   -11.4359,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2392e-05, -1.9687e-04, -5.0726e-05, -4.4936e-04,  2.5502e-05,\n",
      "         -3.9765e-03, -8.5614e-02, -1.8756e-03, -2.5855e-02, -6.4006e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2078], requires_grad=True)\n",
      "bias grad:  tensor([-0.1727])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4289]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8682]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1027,  -322.8744,   -11.4357,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2060], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3420]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1027,  -322.8744,   -11.4357,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0070, 0.0000, 0.0003, 0.0037, 0.0009, 0.0022, 0.1394, 0.0069, 0.1907,\n",
      "         0.0038]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2060], requires_grad=True)\n",
      "bias grad:  tensor([1.0937])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3420]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.8204]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1041,  -322.8744,   -11.4376,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2170], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8241]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0233,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1041,  -322.8744,   -11.4376,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.2919e-03,  1.2275e-05, -1.0084e-04, -1.6003e-03, -1.1085e-03,\n",
      "         -1.2232e-03, -7.2112e-02, -3.7414e-03, -8.3422e-02, -8.4972e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2170], requires_grad=True)\n",
      "bias grad:  tensor([-0.4851])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8241]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6115]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1033,  -322.8744,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2121], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7629]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1033,  -322.8744,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.0139e-03,  2.6662e-05,  5.2678e-05,  5.3400e-04,  1.8984e-04,\n",
      "          2.2240e-03,  5.8191e-02,  1.8321e-03,  3.0418e-02,  1.1250e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2121], requires_grad=True)\n",
      "bias grad:  tensor([0.1950])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7629]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0642]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1039,  -322.8744,   -11.4371,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2141], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7694]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1039,  -322.8744,   -11.4371,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0624e-03, 0.0000e+00, 4.5319e-05, 5.8124e-04, 3.2212e-04, 6.9099e-05,\n",
      "         3.4326e-02, 1.6141e-03, 3.6450e-02, 9.0593e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2141], requires_grad=True)\n",
      "bias grad:  tensor([0.2112])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7694]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0297]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1043,  -322.8745,   -11.4374,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2162], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7664]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1043,  -322.8745,   -11.4374,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.8938e-03,  0.0000e+00, -2.1890e-05, -5.1754e-04, -4.1797e-04,\n",
      "          9.7721e-05, -3.9298e-03, -9.1692e-04, -2.2835e-02,  1.7830e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2162], requires_grad=True)\n",
      "bias grad:  tensor([-0.1303])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7664]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4973]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1042,  -322.8745,   -11.4372,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2149], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7167]], requires_grad=True)\n",
      "Iteration 19 | Score: 0.21257470548152924\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1042,  -322.8745,   -11.4372,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.5149e-04,  3.8147e-05,  1.2692e-05,  2.5500e-05, -3.7834e-04,\n",
      "          3.4126e-04,  1.3751e-02,  2.9695e-04,  5.8911e-03,  3.7435e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2149], requires_grad=True)\n",
      "bias grad:  tensor([0.0348])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7167]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0585]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1044,  -322.8745,   -11.4373,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2152], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7225]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1044,  -322.8745,   -11.4373,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.0314e-04, -1.4026e-04, -9.9840e-05, -1.2434e-03, -2.9174e-04,\n",
      "         -2.5293e-03, -8.2017e-02, -3.0186e-03, -6.5602e-02, -7.5510e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2152], requires_grad=True)\n",
      "bias grad:  tensor([-0.3768])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7225]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8928]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1035,  -322.8744,   -11.4366,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2115], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6332]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1035,  -322.8744,   -11.4366,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1375e-03,  0.0000e+00,  6.4672e-05,  6.8165e-04,  3.3124e-04,\n",
      "          1.0196e-03,  3.9412e-02,  2.2656e-03,  4.3078e-02,  1.2443e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2115], requires_grad=True)\n",
      "bias grad:  tensor([0.2592])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6332]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0041]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1039,  -322.8745,   -11.4370,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2141], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6336]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1039,  -322.8745,   -11.4370,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.3075e-03,  5.2531e-06, -2.7385e-05, -4.6136e-04, -1.7418e-04,\n",
      "          8.6973e-04,  4.8480e-04, -6.3688e-04, -2.4378e-02,  2.4579e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2141], requires_grad=True)\n",
      "bias grad:  tensor([-0.1345])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6336]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3815]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1039,  -322.8745,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2127], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5955]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1039,  -322.8745,   -11.4368,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[1.7707e-03, 4.0579e-05, 5.6980e-05, 6.1627e-04, 3.8886e-04, 2.5713e-03,\n",
      "         7.3525e-02, 2.1134e-03, 3.7541e-02, 1.2721e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2127], requires_grad=True)\n",
      "bias grad:  tensor([0.2214])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5955]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0814]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1047,  -322.8745,   -11.4372,  -302.5949]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2149], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6036]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1047,  -322.8745,   -11.4372,  -302.5949]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3159e-04, 3.2863e-05, 1.3169e-04, 1.3609e-03, 5.8595e-04, 1.8398e-03,\n",
      "         8.4506e-02, 3.7102e-03, 7.5578e-02, 2.0841e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2149], requires_grad=True)\n",
      "bias grad:  tensor([0.4798])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6036]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2571]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1055,  -322.8745,   -11.4379,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2197], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6294]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1055,  -322.8745,   -11.4379,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[3.5313e-03, 0.0000e+00, 7.1652e-05, 8.5854e-04, 7.3911e-04, 9.9535e-04,\n",
      "         5.1596e-02, 2.5647e-03, 5.6953e-02, 1.8925e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2197], requires_grad=True)\n",
      "bias grad:  tensor([0.3247])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6294]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0841]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1060,  -322.8745,   -11.4385,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2230], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6378]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1060,  -322.8745,   -11.4385,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1516e-03, 0.0000e+00, 5.5350e-05, 6.2733e-04, 6.4089e-04, 8.3411e-04,\n",
      "         4.3321e-02, 2.1363e-03, 4.2680e-02, 1.2212e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2230], requires_grad=True)\n",
      "bias grad:  tensor([0.2439])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6378]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1975]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1065,  -322.8746,   -11.4389,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2254], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6180]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1065,  -322.8746,   -11.4389,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[8.0567e-05, 3.1667e-04, 2.5046e-04, 2.9752e-03, 6.3598e-04, 7.6453e-03,\n",
      "         2.2137e-01, 6.8710e-03, 1.2854e-01, 2.1084e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2254], requires_grad=True)\n",
      "bias grad:  tensor([0.8002])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6180]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6457]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1087,  -322.8746,   -11.4402,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2334], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7826]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1087,  -322.8746,   -11.4402,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1773e-03,  0.0000e+00, -1.9063e-05, -4.3265e-04, -1.6965e-04,\n",
      "          1.9067e-04, -5.6026e-03, -3.9354e-04, -1.7038e-02, -2.0220e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2334], requires_grad=True)\n",
      "bias grad:  tensor([-0.1006])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7826]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3271]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1086,  -322.8746,   -11.4400,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2324], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7499]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1086,  -322.8746,   -11.4400,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.5481e-04,  3.0488e-05,  5.7240e-05,  7.1652e-04,  4.5880e-04,\n",
      "          7.1202e-04,  3.8065e-02,  1.9282e-03,  4.1676e-02,  1.2981e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2324], requires_grad=True)\n",
      "bias grad:  tensor([0.2532])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7499]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0688]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1090,  -322.8747,   -11.4404,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2349], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7568]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1090,  -322.8747,   -11.4404,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6449e-03, -3.6476e-05,  1.4982e-05,  1.3809e-04,  1.4999e-05,\n",
      "          4.0523e-04,  1.4159e-02,  1.0169e-03,  1.6419e-02,  1.2156e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2349], requires_grad=True)\n",
      "bias grad:  tensor([0.0903])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7568]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6022]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1091,  -322.8747,   -11.4406,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2358], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6965]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1091,  -322.8747,   -11.4406,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[1.3746e-05, 5.0447e-06, 5.2787e-05, 3.8096e-04, 8.0253e-05, 2.3527e-03,\n",
      "         5.6017e-02, 1.4481e-03, 2.8960e-02, 1.0498e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2358], requires_grad=True)\n",
      "bias grad:  tensor([0.1642])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6965]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0511]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1097,  -322.8747,   -11.4409,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2375], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6914]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1097,  -322.8747,   -11.4409,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.0637e-03, -3.9572e-05, -6.0430e-05, -1.0102e-03, -6.2799e-04,\n",
      "         -5.4115e-04, -4.0329e-02, -1.7875e-03, -4.6393e-02, -1.6654e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2375], requires_grad=True)\n",
      "bias grad:  tensor([-0.2708])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6914]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8032]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1093,  -322.8746,   -11.4404,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2348], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6111]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1093,  -322.8746,   -11.4404,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.6372e-04,  0.0000e+00, -1.7296e-05, -3.4036e-04, -1.7110e-04,\n",
      "         -3.2864e-05, -5.3973e-03, -1.0814e-03, -2.1466e-02, -6.1028e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2348], requires_grad=True)\n",
      "bias grad:  tensor([-0.1195])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6111]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2300]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1093,  -322.8746,   -11.4402,  -302.5950]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2336], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6341]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1093,  -322.8746,   -11.4402,  -302.5950]], requires_grad=True)\n",
      "weight grad:  tensor([[3.4850e-03, 2.9271e-05, 8.3739e-05, 1.0145e-03, 7.6108e-04, 1.1108e-03,\n",
      "         5.9227e-02, 3.0077e-03, 6.3471e-02, 2.3703e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2336], requires_grad=True)\n",
      "bias grad:  tensor([0.3775])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6341]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0040]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1098,  -322.8747,   -11.4409,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2374], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6345]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0234,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1098,  -322.8747,   -11.4409,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9937e-02,  0.0000e+00, -5.5754e-05, -1.1947e-03, -1.5061e-03,\n",
      "         -7.8218e-04, -3.5485e-02, -2.6505e-03, -6.2342e-02, -6.9583e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2374], requires_grad=True)\n",
      "bias grad:  tensor([-0.3517])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6345]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2136]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1095,  -322.8746,   -11.4402,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2338], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6131]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1095,  -322.8746,   -11.4402,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.9965e-03,  1.6612e-05,  3.8061e-05,  3.3246e-04, -1.7485e-05,\n",
      "          1.1960e-03,  3.2098e-02,  1.2085e-03,  2.1594e-02,  7.9864e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2338], requires_grad=True)\n",
      "bias grad:  tensor([0.1304])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6131]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1466]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1098,  -322.8746,   -11.4405,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2351], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6278]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1098,  -322.8746,   -11.4405,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.3420e-04,  0.0000e+00, -1.1820e-04, -7.8126e-04, -8.0056e-05,\n",
      "         -5.5293e-03, -1.4422e-01, -3.6385e-03, -6.3387e-02, -4.0837e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2351], requires_grad=True)\n",
      "bias grad:  tensor([-0.3942])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6278]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.2283]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1084,  -322.8746,   -11.4398,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2312], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5050]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1084,  -322.8746,   -11.4398,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.8866e-03,  4.2734e-05, -1.3361e-05,  4.2971e-04,  8.1292e-04,\n",
      "         -3.3767e-03, -6.3721e-02, -6.5048e-05,  1.5365e-02, -4.8217e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2312], requires_grad=True)\n",
      "bias grad:  tensor([0.0735])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5050]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2556]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1077,  -322.8746,   -11.4400,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2319], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5305]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1077,  -322.8746,   -11.4400,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.7586e-03, -6.5973e-05, -6.2396e-05, -7.0144e-04, -2.3113e-04,\n",
      "         -2.0005e-03, -6.6901e-02, -1.6094e-03, -3.4292e-02, -1.4803e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2319], requires_grad=True)\n",
      "bias grad:  tensor([-0.2173])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5305]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7389]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1071,  -322.8746,   -11.4396,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2298], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4566]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1071,  -322.8746,   -11.4396,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.5352e-04, -1.8585e-04, -8.4298e-05, -7.3280e-04, -5.8884e-05,\n",
      "         -3.9681e-03, -9.7225e-02, -2.6263e-03, -4.3568e-02, -7.0316e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2298], requires_grad=True)\n",
      "bias grad:  tensor([-0.2769])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4566]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7433]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1061,  -322.8745,   -11.4392,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2270], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3823]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1061,  -322.8745,   -11.4392,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0046, 0.0000, 0.0002, 0.0021, 0.0003, 0.0011, 0.0730, 0.0035, 0.1067,\n",
      "         0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2270], requires_grad=True)\n",
      "bias grad:  tensor([0.6138])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3823]], requires_grad=True)\n",
      "lambda grad:  tensor([[-3.2408]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1068,  -322.8746,   -11.4403,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2331], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7064]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1068,  -322.8746,   -11.4403,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2341e-03,  1.0561e-05, -1.0097e-04, -1.5319e-03, -1.0698e-03,\n",
      "         -1.3012e-03, -7.3912e-02, -3.7638e-03, -8.2038e-02, -1.0222e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2331], requires_grad=True)\n",
      "bias grad:  tensor([-0.4784])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7064]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3514]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1061,  -322.8745,   -11.4394,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2283], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6713]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1061,  -322.8745,   -11.4394,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7282e-03,  3.2089e-05,  5.7599e-05,  6.3830e-04,  2.7041e-04,\n",
      "          2.3108e-03,  6.1430e-02,  2.0328e-03,  3.4696e-02,  1.2120e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2283], requires_grad=True)\n",
      "bias grad:  tensor([0.2255])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6713]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1368]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1067,  -322.8746,   -11.4398,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2306], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6849]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1067,  -322.8746,   -11.4398,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8178e-03, 0.0000e+00, 4.5701e-05, 6.3443e-04, 4.5030e-04, 1.4216e-04,\n",
      "         3.0559e-02, 1.6930e-03, 3.9145e-02, 8.6038e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2306], requires_grad=True)\n",
      "bias grad:  tensor([0.2279])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6849]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0150]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1070,  -322.8746,   -11.4402,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2329], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6864]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1070,  -322.8746,   -11.4402,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.3359e-04,  0.0000e+00, -1.9495e-05, -4.3930e-04, -3.9351e-04,\n",
      "          2.5742e-05, -4.9914e-03, -8.3795e-04, -2.0302e-02,  6.2031e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2329], requires_grad=True)\n",
      "bias grad:  tensor([-0.1156])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6864]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2639]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1069,  -322.8746,   -11.4400,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2317], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6600]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1069,  -322.8746,   -11.4400,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.3848e-04,  5.4875e-05,  1.6445e-05,  8.8959e-05, -3.7599e-04,\n",
      "          4.4456e-04,  1.7425e-02,  4.3856e-04,  8.9342e-03,  3.8904e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2317], requires_grad=True)\n",
      "bias grad:  tensor([0.0523])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6600]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1643]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1071,  -322.8746,   -11.4401,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2323], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6765]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1071,  -322.8746,   -11.4401,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.0550e-04, -9.5747e-05, -6.5430e-05, -7.7558e-04, -5.7771e-05,\n",
      "         -2.1386e-03, -5.9639e-02, -1.9319e-03, -4.0010e-02, -2.6079e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2323], requires_grad=True)\n",
      "bias grad:  tensor([-0.2286])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6765]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6473]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1065,  -322.8746,   -11.4397,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2300], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6117]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1065,  -322.8746,   -11.4397,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8303e-03,  0.0000e+00,  3.7753e-05,  3.9507e-04,  1.6675e-04,\n",
      "          3.7024e-04,  1.7456e-02,  1.3854e-03,  2.5746e-02,  7.9985e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2300], requires_grad=True)\n",
      "bias grad:  tensor([0.1502])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6117]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0041]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1067,  -322.8746,   -11.4399,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2315], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6113]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0237,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1067,  -322.8746,   -11.4399,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.7041e-03,  7.4376e-07,  7.4755e-07, -4.3809e-05,  4.1338e-04,\n",
      "          7.7856e-04,  2.0331e-02,  4.2911e-04,  2.4473e-03,  5.1280e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2315], requires_grad=True)\n",
      "bias grad:  tensor([0.0217])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6113]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4035]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1069,  -322.8746,   -11.4399,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2317], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5710]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1069,  -322.8746,   -11.4399,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[4.3614e-03, 3.3432e-05, 2.9337e-05, 3.1240e-04, 3.2782e-04, 1.9153e-03,\n",
      "         5.0203e-02, 1.1010e-03, 1.6112e-02, 1.0421e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2317], requires_grad=True)\n",
      "bias grad:  tensor([0.1116])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5710]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0610]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1074,  -322.8746,   -11.4401,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2328], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5771]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1074,  -322.8746,   -11.4401,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[4.1208e-04, 3.2460e-05, 9.8530e-05, 1.0586e-03, 4.3801e-04, 1.3460e-03,\n",
      "         6.2195e-02, 2.7325e-03, 5.8830e-02, 1.5608e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2328], requires_grad=True)\n",
      "bias grad:  tensor([0.3651])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5771]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3495]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1080,  -322.8746,   -11.4407,  -302.5951]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2364], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6120]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1080,  -322.8746,   -11.4407,  -302.5951]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6800e-03, 0.0000e+00, 7.9526e-05, 9.7212e-04, 7.8239e-04, 9.3388e-04,\n",
      "         5.3745e-02, 2.7673e-03, 6.2784e-02, 1.9442e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2364], requires_grad=True)\n",
      "bias grad:  tensor([0.3578])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6120]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1442]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1086,  -322.8746,   -11.4413,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2400], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6264]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1086,  -322.8746,   -11.4413,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[8.7846e-04, 0.0000e+00, 2.5618e-05, 2.5458e-04, 1.4910e-04, 5.1454e-04,\n",
      "         2.3687e-02, 1.0910e-03, 1.8795e-02, 2.6977e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2400], requires_grad=True)\n",
      "bias grad:  tensor([0.1064])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6264]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1216]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1088,  -322.8746,   -11.4415,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2411], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6143]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1088,  -322.8746,   -11.4415,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7585e-04,  3.3914e-04,  2.5107e-04,  2.9742e-03,  6.5263e-04,\n",
      "          7.6973e-03,  2.2064e-01,  6.8640e-03,  1.2870e-01,  2.2536e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2411], requires_grad=True)\n",
      "bias grad:  tensor([0.8015])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6143]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6849]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1110,  -322.8747,   -11.4428,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2491], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7828]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0235,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1110,  -322.8747,   -11.4428,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.6207e-03,  0.0000e+00, -2.9261e-05, -5.7725e-04, -3.1187e-04,\n",
      "          8.6508e-05, -1.3517e-02, -8.0836e-04, -2.5613e-02, -3.5655e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2491], requires_grad=True)\n",
      "bias grad:  tensor([-0.1490])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7828]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3175]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1109,  -322.8747,   -11.4425,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2476], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7510]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1109,  -322.8747,   -11.4425,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.2844e-04,  2.6101e-05,  4.9789e-05,  6.0261e-04,  3.4162e-04,\n",
      "          6.1636e-04,  3.2531e-02,  1.5896e-03,  3.4506e-02,  1.1082e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2476], requires_grad=True)\n",
      "bias grad:  tensor([0.2123])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7510]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0983]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1112,  -322.8747,   -11.4429,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2497], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7609]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1112,  -322.8747,   -11.4429,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7225e-03, -2.9508e-05, -5.8532e-08, -6.8425e-05, -1.7628e-04,\n",
      "          4.1709e-04,  7.6274e-03,  4.8298e-04,  4.2183e-03,  1.0457e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2497], requires_grad=True)\n",
      "bias grad:  tensor([0.0207])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7609]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6129]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1113,  -322.8747,   -11.4429,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2499], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6996]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1113,  -322.8747,   -11.4429,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.4544e-04,  5.5579e-06,  4.9214e-05,  3.3733e-04,  6.4976e-05,\n",
      "          2.1062e-03,  5.0321e-02,  1.3465e-03,  2.7554e-02,  1.0449e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2499], requires_grad=True)\n",
      "bias grad:  tensor([0.1549])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6996]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1451]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1118,  -322.8747,   -11.4432,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2515], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6850]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1118,  -322.8747,   -11.4432,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.3554e-03, -2.3366e-05, -2.9680e-05, -5.8983e-04, -4.1789e-04,\n",
      "         -2.7723e-04, -1.8391e-02, -7.7018e-04, -2.2993e-02,  2.9241e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2515], requires_grad=True)\n",
      "bias grad:  tensor([-0.1335])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6850]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6149]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1116,  -322.8747,   -11.4430,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2502], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6235]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1116,  -322.8747,   -11.4430,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.0106e-04,  0.0000e+00, -1.7966e-05, -3.0510e-04, -8.1341e-05,\n",
      "         -8.4542e-05, -5.2188e-03, -1.0352e-03, -2.0038e-02, -6.0082e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2502], requires_grad=True)\n",
      "bias grad:  tensor([-0.1092])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6235]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2279]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1115,  -322.8747,   -11.4428,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2491], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6463]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1115,  -322.8747,   -11.4428,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1394e-03, 2.5979e-05, 7.8243e-05, 9.6859e-04, 7.2445e-04, 1.1526e-03,\n",
      "         5.7516e-02, 2.9275e-03, 5.9788e-02, 2.2878e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2491], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias grad:  tensor([0.3577])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6463]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0532]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1121,  -322.8748,   -11.4434,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2526], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6517]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0236,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1121,  -322.8748,   -11.4434,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7437e-02,  0.0000e+00, -3.2629e-05, -8.4704e-04, -1.1149e-03,\n",
      "         -5.2746e-04, -2.4018e-02, -1.6853e-03, -4.2316e-02, -4.3064e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2526], requires_grad=True)\n",
      "bias grad:  tensor([-0.2372])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6517]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1998]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1119,  -322.8747,   -11.4429,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2503], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6317]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1119,  -322.8747,   -11.4429,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.6986e-03,  2.5146e-05,  1.1419e-05, -8.6357e-05, -3.2379e-04,\n",
      "          7.0788e-04,  8.7929e-03,  2.6669e-04, -1.0482e-03,  5.7947e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2503], requires_grad=True)\n",
      "bias grad:  tensor([-0.0009])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6317]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0676]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1120,  -322.8747,   -11.4429,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2503], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6249]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1120,  -322.8747,   -11.4429,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.9078e-04,  0.0000e+00, -1.2255e-04, -8.2904e-04, -1.9805e-04,\n",
      "         -5.4947e-03, -1.4566e-01, -3.6921e-03, -6.6572e-02, -3.5731e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2503], requires_grad=True)\n",
      "bias grad:  tensor([-0.4123])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6249]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1433]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1105,  -322.8747,   -11.4423,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2461], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5106]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1105,  -322.8747,   -11.4423,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.6242e-03,  3.0277e-05,  6.4635e-06,  6.4832e-04,  9.1361e-04,\n",
      "         -3.1258e-03, -4.8948e-02,  5.8901e-04,  2.8238e-02,  1.2622e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2461], requires_grad=True)\n",
      "bias grad:  tensor([0.1537])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5106]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1893]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1100,  -322.8747,   -11.4426,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2477], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5295]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1100,  -322.8747,   -11.4426,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.1710e-03, -7.4930e-05, -7.5757e-05, -8.4581e-04, -1.1251e-04,\n",
      "         -2.4213e-03, -7.5602e-02, -2.0400e-03, -4.2389e-02, -3.2758e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2477], requires_grad=True)\n",
      "bias grad:  tensor([-0.2630])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5295]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9363]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1093,  -322.8747,   -11.4421,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2450], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4359]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1093,  -322.8747,   -11.4421,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.1053e-04, -2.0086e-04, -8.3542e-05, -6.9752e-04,  1.5972e-05,\n",
      "         -4.1981e-03, -1.0219e-01, -2.3505e-03, -4.0631e-02, -4.6631e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2450], requires_grad=True)\n",
      "bias grad:  tensor([-0.2517])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4359]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9097]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1082,  -322.8746,   -11.4417,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2425], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3449]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1082,  -322.8746,   -11.4417,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0063, 0.0000, 0.0003, 0.0034, 0.0008, 0.0020, 0.1326, 0.0064, 0.1782,\n",
      "         0.0035]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2425], requires_grad=True)\n",
      "bias grad:  tensor([1.0221])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3449]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.4289]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1096,  -322.8747,   -11.4435,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2528], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7878]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1096,  -322.8747,   -11.4435,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.6706e-03,  4.7182e-06, -1.1245e-04, -1.7313e-03, -1.1963e-03,\n",
      "         -1.4820e-03, -8.2809e-02, -4.1550e-03, -9.1606e-02, -1.1413e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2528], requires_grad=True)\n",
      "bias grad:  tensor([-0.5361])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7878]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5017]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1087,  -322.8747,   -11.4426,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2474], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7376]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1087,  -322.8747,   -11.4426,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.9138e-03,  2.7792e-05,  4.0851e-05,  4.0099e-04,  1.4530e-04,\n",
      "          1.8816e-03,  4.7247e-02,  1.3893e-03,  2.3804e-02,  8.8504e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2474], requires_grad=True)\n",
      "bias grad:  tensor([0.1494])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7376]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0326]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1092,  -322.8747,   -11.4428,  -302.5952]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2489], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7409]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1092,  -322.8747,   -11.4428,  -302.5952]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0036, 0.0000, 0.0001, 0.0012, 0.0008, 0.0006, 0.0881, 0.0036, 0.0779,\n",
      "         0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2489], requires_grad=True)\n",
      "bias grad:  tensor([0.4498])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7409]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1637]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1101,  -322.8747,   -11.4436,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2534], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7245]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1101,  -322.8747,   -11.4436,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1619e-03,  0.0000e+00, -1.9321e-05, -4.8575e-04, -4.0276e-04,\n",
      "          1.1632e-04, -3.8677e-03, -8.4590e-04, -2.1252e-02,  2.0149e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2534], requires_grad=True)\n",
      "bias grad:  tensor([-0.1212])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7245]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3996]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1101,  -322.8747,   -11.4434,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2522], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6846]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1101,  -322.8747,   -11.4434,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.0423e-04,  5.3853e-05,  1.1699e-05,  3.4725e-05, -3.8562e-04,\n",
      "          3.9988e-04,  1.4952e-02,  2.9358e-04,  5.5614e-03,  3.0388e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2522], requires_grad=True)\n",
      "bias grad:  tensor([0.0323])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6846]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1573]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1102,  -322.8747,   -11.4434,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2525], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7003]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1102,  -322.8747,   -11.4434,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[ 8.9754e-05, -1.0784e-04, -8.1573e-05, -9.8847e-04, -1.5317e-04,\n",
      "         -2.3669e-03, -6.9855e-02, -2.4736e-03, -5.2849e-02, -5.2137e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2525], requires_grad=True)\n",
      "bias grad:  tensor([-0.3015])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7003]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7376]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1095,  -322.8747,   -11.4429,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2495], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6265]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1095,  -322.8747,   -11.4429,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.3908e-03,  0.0000e+00,  3.7002e-05,  3.6165e-04,  1.6206e-04,\n",
      "          4.1370e-04,  1.9888e-02,  1.2943e-03,  2.3688e-02,  8.2656e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2495], requires_grad=True)\n",
      "bias grad:  tensor([0.1423])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6265]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0241]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1097,  -322.8747,   -11.4432,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2509], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6241]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1097,  -322.8747,   -11.4432,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0462e-03,  1.1147e-05, -3.6423e-05, -5.6997e-04, -2.7261e-04,\n",
      "          7.5833e-04, -6.8825e-03, -9.6025e-04, -3.0529e-02, -8.2277e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2509], requires_grad=True)\n",
      "bias grad:  tensor([-0.1739])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6241]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3612]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1096,  -322.8747,   -11.4429,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2492], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5880]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1096,  -322.8747,   -11.4429,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[5.4347e-03, 3.2143e-05, 5.8606e-05, 7.0853e-04, 7.5594e-04, 1.9351e-03,\n",
      "         6.6734e-02, 2.4373e-03, 4.2257e-02, 1.6316e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2492], requires_grad=True)\n",
      "bias grad:  tensor([0.2637])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5880]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0052]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1103,  -322.8747,   -11.4433,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2518], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5875]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1103,  -322.8747,   -11.4433,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[2.6264e-04, 2.8504e-05, 1.1226e-04, 1.1862e-03, 5.0933e-04, 1.6788e-03,\n",
      "         7.4576e-02, 3.2287e-03, 6.6124e-02, 1.8571e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2518], requires_grad=True)\n",
      "bias grad:  tensor([0.4173])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5875]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2403]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1110,  -322.8747,   -11.4439,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2560], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6115]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1110,  -322.8747,   -11.4439,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[3.6886e-03, 0.0000e+00, 3.9958e-05, 5.0710e-04, 4.9171e-04, 5.5438e-04,\n",
      "         3.1249e-02, 1.3513e-03, 3.2381e-02, 8.2620e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2560], requires_grad=True)\n",
      "bias grad:  tensor([0.1836])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6115]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2025]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1114,  -322.8747,   -11.4443,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2578], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6318]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1114,  -322.8747,   -11.4443,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[1.6301e-03, 0.0000e+00, 1.5682e-05, 9.5032e-05, 9.0614e-05, 2.9912e-04,\n",
      "         1.5099e-02, 8.1326e-04, 1.0959e-02, 7.8757e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2578], requires_grad=True)\n",
      "bias grad:  tensor([0.0635])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6318]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2335]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1115,  -322.8747,   -11.4444,  -302.5953]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2584], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6084]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1115,  -322.8747,   -11.4444,  -302.5953]], requires_grad=True)\n",
      "weight grad:  tensor([[-0.0007,  0.0003,  0.0002,  0.0029,  0.0006,  0.0075,  0.2147,  0.0066,\n",
      "          0.1223,  0.0020]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2584], requires_grad=True)\n",
      "bias grad:  tensor([0.7642])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6084]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6101]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1137,  -322.8748,   -11.4456,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2661], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7694]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1137,  -322.8748,   -11.4456,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.9788e-03,  0.0000e+00, -1.7852e-05, -4.7529e-04, -2.1994e-04,\n",
      "          3.4225e-04, -3.9597e-03, -4.9222e-04, -1.8861e-02, -2.3568e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2661], requires_grad=True)\n",
      "bias grad:  tensor([-0.1113])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7694]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2965]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1136,  -322.8748,   -11.4454,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2650], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7398]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1136,  -322.8748,   -11.4454,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.0598e-04,  2.8096e-05,  7.2514e-05,  9.4641e-04,  7.9264e-04,\n",
      "          8.7964e-04,  4.8302e-02,  2.5685e-03,  5.8398e-02,  1.9657e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2650], requires_grad=True)\n",
      "bias grad:  tensor([0.3452])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7398]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0014]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1141,  -322.8748,   -11.4460,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2684], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7399]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1141,  -322.8748,   -11.4460,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4130e-03, -4.3662e-05,  1.0829e-05,  9.6101e-05,  3.6777e-05,\n",
      "          4.6394e-04,  1.2034e-02,  9.3664e-04,  1.4133e-02,  1.2284e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2684], requires_grad=True)\n",
      "bias grad:  tensor([0.0774])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7399]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6340]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1142,  -322.8748,   -11.4461,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2692], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6765]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1142,  -322.8748,   -11.4461,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.8540e-04,  1.3140e-05,  3.4532e-05,  1.5246e-04, -9.9128e-05,\n",
      "          1.7559e-03,  3.7214e-02,  7.9666e-04,  1.5178e-02,  7.8039e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2692], requires_grad=True)\n",
      "bias grad:  tensor([0.0848])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6765]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0672]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1146,  -322.8748,   -11.4463,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2700], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6698]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1146,  -322.8748,   -11.4463,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.5041e-03, -2.9279e-05, -5.6015e-05, -9.7990e-04, -6.9206e-04,\n",
      "         -5.2735e-04, -3.7072e-02, -1.6752e-03, -4.4585e-02, -7.8016e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2700], requires_grad=True)\n",
      "bias grad:  tensor([-0.2588])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6698]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7839]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1142,  -322.8748,   -11.4458,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2675], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5914]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1142,  -322.8748,   -11.4458,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[ 7.1654e-04,  0.0000e+00, -2.0240e-05, -3.2208e-04, -5.3361e-05,\n",
      "         -1.3078e-04, -5.7843e-03, -1.1067e-03, -2.1310e-02, -5.9222e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2675], requires_grad=True)\n",
      "bias grad:  tensor([-0.1152])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5914]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1914]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1142,  -322.8748,   -11.4456,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2663], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6105]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1142,  -322.8748,   -11.4456,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[3.0778e-03, 1.5440e-05, 9.0345e-05, 1.0687e-03, 8.0477e-04, 1.5366e-03,\n",
      "         6.9226e-02, 3.2182e-03, 6.7255e-02, 2.5878e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2663], requires_grad=True)\n",
      "bias grad:  tensor([0.4029])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6105]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0066]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1149,  -322.8748,   -11.4463,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2703], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6112]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0238,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1149,  -322.8748,   -11.4463,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0141e-02,  0.0000e+00, -6.4055e-05, -1.3018e-03, -1.6185e-03,\n",
      "         -8.6524e-04, -3.9210e-02, -2.9808e-03, -6.8831e-02, -7.8821e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2703], requires_grad=True)\n",
      "bias grad:  tensor([-0.3891])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6112]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3367]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1145,  -322.8748,   -11.4456,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2664], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5775]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1145,  -322.8748,   -11.4456,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.5203e-03,  1.8549e-05,  3.2606e-05,  2.3388e-04, -8.0714e-05,\n",
      "          9.2906e-04,  2.2957e-02,  1.0199e-03,  1.6825e-02,  8.0230e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2664], requires_grad=True)\n",
      "bias grad:  tensor([0.1017])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5775]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0935]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1147,  -322.8748,   -11.4458,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2675], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5869]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1147,  -322.8748,   -11.4458,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.3054e-04,  0.0000e+00, -1.0926e-04, -6.8270e-04, -1.8435e-06,\n",
      "         -5.3733e-03, -1.3705e-01, -3.3597e-03, -5.6835e-02,  1.2541e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2675], requires_grad=True)\n",
      "bias grad:  tensor([-0.3567])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5869]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1860]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1133,  -322.8748,   -11.4452,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2639], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4683]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1133,  -322.8748,   -11.4452,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.4448e-03,  4.8267e-05,  4.7540e-07,  6.5783e-04,  8.6164e-04,\n",
      "         -3.1936e-03, -5.6245e-02,  3.8978e-04,  2.5497e-02, -3.5762e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2639], requires_grad=True)\n",
      "bias grad:  tensor([0.1329])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4683]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.7201]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1128,  -322.8748,   -11.4455,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2652], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5403]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1128,  -322.8748,   -11.4455,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[ 2.7624e-03, -9.0873e-05, -9.3089e-05, -1.0468e-03, -1.6747e-04,\n",
      "         -2.9508e-03, -9.1283e-02, -2.4604e-03, -5.2491e-02, -3.7445e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2652], requires_grad=True)\n",
      "bias grad:  tensor([-0.3237])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5403]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1650]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1119,  -322.8747,   -11.4449,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2620], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4238]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1119,  -322.8747,   -11.4449,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.2154e-04, -2.0518e-04, -8.1001e-05, -7.1663e-04, -6.1557e-05,\n",
      "         -4.4115e-03, -1.0386e-01, -2.7111e-03, -3.9887e-02, -2.9478e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2620], requires_grad=True)\n",
      "bias grad:  tensor([-0.2651])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4238]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8776]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1108,  -322.8747,   -11.4445,  -302.5954]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2593], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.3360]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1108,  -322.8747,   -11.4445,  -302.5954]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0060, 0.0000, 0.0003, 0.0031, 0.0007, 0.0019, 0.1185, 0.0056, 0.1594,\n",
      "         0.0032]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2593], requires_grad=True)\n",
      "bias grad:  tensor([0.9147])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.3360]], requires_grad=True)\n",
      "lambda grad:  tensor([[-4.2791]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1120,  -322.8748,   -11.4461,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2685], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7640]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1120,  -322.8748,   -11.4461,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.4043e-03,  1.7970e-05, -8.4473e-05, -1.3466e-03, -9.1447e-04,\n",
      "         -1.0605e-03, -6.3033e-02, -3.0956e-03, -6.9324e-02, -6.9975e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2685], requires_grad=True)\n",
      "bias grad:  tensor([-0.4039])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7640]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4828]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1114,  -322.8747,   -11.4454,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2644], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7157]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1114,  -322.8747,   -11.4454,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.8969e-03,  3.2335e-05,  4.8955e-05,  5.1116e-04,  1.8566e-04,\n",
      "          2.2030e-03,  5.4598e-02,  1.7581e-03,  2.8887e-02,  9.4362e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2644], requires_grad=True)\n",
      "bias grad:  tensor([0.1826])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7157]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda grad:  tensor([[-0.1177]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1119,  -322.8748,   -11.4457,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2663], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7274]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1119,  -322.8748,   -11.4457,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[2.4041e-03, 0.0000e+00, 8.2878e-05, 9.8863e-04, 5.1394e-04, 3.3296e-04,\n",
      "         7.4926e-02, 2.8916e-03, 6.2716e-02, 1.6595e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2663], requires_grad=True)\n",
      "bias grad:  tensor([0.3605])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7274]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1125]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1127,  -322.8748,   -11.4464,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2699], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7162]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1127,  -322.8748,   -11.4464,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.4637e-03,  0.0000e+00, -1.9062e-05, -4.5946e-04, -4.0238e-04,\n",
      "          6.8262e-05, -3.5785e-03, -8.1438e-04, -2.0381e-02,  1.1947e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2699], requires_grad=True)\n",
      "bias grad:  tensor([-0.1161])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7162]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3614]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1126,  -322.8748,   -11.4461,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2687], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6801]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1126,  -322.8748,   -11.4461,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.1082e-04,  4.1614e-05,  1.2593e-05,  3.4815e-05, -3.7265e-04,\n",
      "          4.6529e-04,  1.5058e-02,  2.8869e-04,  5.5109e-03,  2.8846e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2687], requires_grad=True)\n",
      "bias grad:  tensor([0.0328])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6801]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1468]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1128,  -322.8748,   -11.4462,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2690], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6947]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1128,  -322.8748,   -11.4462,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7592e-05, -1.2321e-04, -8.3152e-05, -1.0557e-03, -1.8407e-04,\n",
      "         -2.3296e-03, -7.1256e-02, -2.4598e-03, -5.3164e-02, -3.2479e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2690], requires_grad=True)\n",
      "bias grad:  tensor([-0.3051])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6947]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.9169]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1121,  -322.8748,   -11.4457,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2660], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6030]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1121,  -322.8748,   -11.4457,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.7147e-03,  0.0000e+00,  4.5276e-05,  3.8259e-04,  1.1012e-04,\n",
      "          9.0500e-04,  2.6181e-02,  1.4863e-03,  2.5575e-02,  9.3037e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2660], requires_grad=True)\n",
      "bias grad:  tensor([0.1591])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6030]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0167]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1123,  -322.8748,   -11.4459,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2676], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6047]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1123,  -322.8748,   -11.4459,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.6333e-03, -5.8370e-06, -1.0645e-05, -2.5959e-04,  1.7719e-04,\n",
      "          1.2047e-03,  2.0430e-02,  1.8058e-05, -1.0494e-02,  3.4900e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2676], requires_grad=True)\n",
      "bias grad:  tensor([-0.0495])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6047]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.4113]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1125,  -322.8748,   -11.4458,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2671], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5636]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0241,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1125,  -322.8748,   -11.4458,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[5.5190e-03, 2.4746e-05, 5.6921e-05, 7.0850e-04, 7.0721e-04, 1.9762e-03,\n",
      "         6.5141e-02, 2.2977e-03, 4.0605e-02, 1.5057e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2671], requires_grad=True)\n",
      "bias grad:  tensor([0.2545])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5636]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0860]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1132,  -322.8748,   -11.4462,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2696], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5722]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4041,\n",
      "            -6.1132,  -322.8748,   -11.4462,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[2.8795e-04, 1.5521e-05, 1.1062e-04, 1.0996e-03, 5.0003e-04, 1.4731e-03,\n",
      "         7.1260e-02, 3.2781e-03, 5.9764e-02, 1.8755e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2696], requires_grad=True)\n",
      "bias grad:  tensor([0.4031])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5722]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1598]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1139,  -322.8748,   -11.4468,  -302.5955]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2737], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5882]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1139,  -322.8748,   -11.4468,  -302.5955]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7683e-03, 0.0000e+00, 8.3099e-05, 1.0023e-03, 8.2964e-04, 1.5818e-03,\n",
      "         6.7030e-02, 2.9552e-03, 6.4885e-02, 2.1290e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2737], requires_grad=True)\n",
      "bias grad:  tensor([0.3708])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5882]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1073]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1146,  -322.8748,   -11.4475,  -302.5956]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2774], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5989]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1146,  -322.8748,   -11.4475,  -302.5956]], requires_grad=True)\n",
      "weight grad:  tensor([[5.0709e-03, 0.0000e+00, 5.7562e-05, 7.0685e-04, 8.2317e-04, 9.4459e-04,\n",
      "         4.9391e-02, 2.6803e-03, 4.6425e-02, 6.9694e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2774], requires_grad=True)\n",
      "bias grad:  tensor([0.2697])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5989]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1048]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1151,  -322.8749,   -11.4479,  -302.5956]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2801], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5884]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1151,  -322.8749,   -11.4479,  -302.5956]], requires_grad=True)\n",
      "weight grad:  tensor([[-0.0004,  0.0003,  0.0002,  0.0028,  0.0005,  0.0075,  0.2144,  0.0065,\n",
      "          0.1202,  0.0019]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2801], requires_grad=True)\n",
      "bias grad:  tensor([0.7527])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5884]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6224]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1172,  -322.8749,   -11.4491,  -302.5956]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2876], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7507]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1172,  -322.8749,   -11.4491,  -302.5956]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.7292e-03,  0.0000e+00, -2.3110e-05, -4.6823e-04, -1.6312e-04,\n",
      "          1.3375e-04, -8.2595e-03, -5.6132e-04, -1.9580e-02, -2.6023e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2876], requires_grad=True)\n",
      "bias grad:  tensor([-0.1159])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7507]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2790]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1171,  -322.8749,   -11.4489,  -302.5956]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2864], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7228]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0239,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1171,  -322.8749,   -11.4489,  -302.5956]], requires_grad=True)\n",
      "weight grad:  tensor([[-9.5613e-04,  2.6999e-05,  4.9965e-05,  6.1366e-04,  4.3859e-04,\n",
      "          5.7907e-04,  3.1965e-02,  1.7125e-03,  3.6391e-02,  1.2172e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2864], requires_grad=True)\n",
      "bias grad:  tensor([0.2237])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7228]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0130]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1174,  -322.8750,   -11.4493,  -302.5956]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2887], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7241]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1174,  -322.8750,   -11.4493,  -302.5956]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5606e-03, -3.6140e-05,  1.8409e-05,  1.9302e-04,  3.6894e-05,\n",
      "          4.0622e-04,  1.5623e-02,  1.1443e-03,  1.9747e-02,  1.3532e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2887], requires_grad=True)\n",
      "bias grad:  tensor([0.1089])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7241]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6006]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1176,  -322.8750,   -11.4495,  -302.5956]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2898], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6640]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1176,  -322.8750,   -11.4495,  -302.5956]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1427e-03, -8.0936e-06,  4.2024e-05,  2.5005e-04, -4.2970e-05,\n",
      "          2.2048e-03,  4.9387e-02,  1.1227e-03,  2.0786e-02,  8.5844e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2898], requires_grad=True)\n",
      "bias grad:  tensor([0.1172])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6640]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0842]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1181,  -322.8750,   -11.4497,  -302.5956]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2909], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6556]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1181,  -322.8750,   -11.4497,  -302.5956]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.6706e-03, -2.6502e-05, -5.8976e-05, -9.6251e-04, -6.2490e-04,\n",
      "         -5.2011e-04, -4.1456e-02, -1.8213e-03, -4.5507e-02, -3.1518e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2909], requires_grad=True)\n",
      "bias grad:  tensor([-0.2657])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6556]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5306]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1177,  -322.8749,   -11.4493,  -302.5956]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2883], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6025]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1177,  -322.8749,   -11.4493,  -302.5956]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.2180e-03,  0.0000e+00, -2.4481e-05, -4.6677e-04, -2.3965e-04,\n",
      "         -8.1819e-05, -1.2111e-02, -1.3505e-03, -2.8375e-02, -8.0877e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2883], requires_grad=True)\n",
      "bias grad:  tensor([-0.1602])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6025]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2494]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1176,  -322.8749,   -11.4490,  -302.5956]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2867], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6275]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1176,  -322.8749,   -11.4490,  -302.5956]], requires_grad=True)\n",
      "weight grad:  tensor([[2.5875e-03, 1.9802e-05, 7.1196e-05, 8.3519e-04, 5.8568e-04, 1.1470e-03,\n",
      "         5.2460e-02, 2.5435e-03, 5.1683e-02, 2.1734e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2867], requires_grad=True)\n",
      "bias grad:  tensor([0.3114])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6275]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0408]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1181,  -322.8750,   -11.4495,  -302.5956]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2898], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6315]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0240,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1181,  -322.8750,   -11.4495,  -302.5956]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.0966e-02,  0.0000e+00, -6.9685e-05, -1.3920e-03, -1.7225e-03,\n",
      "         -9.2986e-04, -4.2124e-02, -3.2209e-03, -7.3925e-02, -8.5366e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2898], requires_grad=True)\n",
      "bias grad:  tensor([-0.4181])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6315]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2162]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1177,  -322.8749,   -11.4488,  -302.5956]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2856], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6099]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0242,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1177,  -322.8749,   -11.4488,  -302.5956]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.5894e-03, -6.4637e-06,  2.4650e-05,  9.8201e-05, -1.7952e-04,\n",
      "          1.0795e-03,  2.2698e-02,  7.9142e-04,  9.0067e-03,  5.5627e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2856], requires_grad=True)\n",
      "bias grad:  tensor([0.0586])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6099]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0104]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0243,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1179,  -322.8749,   -11.4488,  -302.5956]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2862], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6089]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0243,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4039,\n",
      "            -6.1179,  -322.8749,   -11.4488,  -302.5956]], requires_grad=True)\n",
      "weight grad:  tensor([[-5.7500e-04,  0.0000e+00, -1.0801e-04, -6.9102e-04, -2.4222e-05,\n",
      "         -5.3890e-03, -1.3941e-01, -3.3191e-03, -5.6417e-02,  2.8426e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.2862], requires_grad=True)\n",
      "bias grad:  tensor([-0.3532])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6089]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.1974]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0243,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4040,\n",
      "            -6.1165,  -322.8749,   -11.4483,  -302.5956]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.2827], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4891]], requires_grad=True)\n",
      "Iteration 20 | Score: 1.3335561752319336\n",
      "reassigning best parameters\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0904,  -322.8737,   -11.4220,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 1.7689e-03, -3.2808e-05, -8.0701e-05, -6.9962e-04,  2.7919e-04,\n",
      "         -4.4034e-03, -1.0217e-01, -2.3032e-03, -3.7690e-02, -9.7002e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1246], requires_grad=True)\n",
      "bias grad:  tensor([-0.2419])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7845]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.2038]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0894,  -322.8737,   -11.4216,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1222], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6641]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0894,  -322.8737,   -11.4216,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[ 3.3902e-03, -9.0362e-05, -8.5929e-05, -1.0296e-03, -1.8132e-04,\n",
      "         -2.5738e-03, -8.4558e-02, -2.2289e-03, -4.8767e-02,  3.8219e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1222], requires_grad=True)\n",
      "bias grad:  tensor([-0.3063])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6641]], requires_grad=True)\n",
      "lambda grad:  tensor([[1.4679]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0886,  -322.8737,   -11.4211,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1191], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5173]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0886,  -322.8737,   -11.4211,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-7.9046e-04, -2.0131e-04, -9.1088e-05, -8.4538e-04, -1.7582e-04,\n",
      "         -4.3801e-03, -1.0753e-01, -2.9527e-03, -5.0717e-02, -6.8987e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1191], requires_grad=True)\n",
      "bias grad:  tensor([-0.3122])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5173]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.8548]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0875,  -322.8736,   -11.4206,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1160], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.4318]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0875,  -322.8736,   -11.4206,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[0.0043, 0.0000, 0.0002, 0.0020, 0.0002, 0.0011, 0.0716, 0.0034, 0.1035,\n",
      "         0.0022]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1160], requires_grad=True)\n",
      "bias grad:  tensor([0.5951])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.4318]], requires_grad=True)\n",
      "lambda grad:  tensor([[-2.6419]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0882,  -322.8737,   -11.4217,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1220], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6960]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0882,  -322.8737,   -11.4217,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-3.4708e-03,  2.3192e-05, -5.2091e-05, -8.4614e-04, -6.5538e-04,\n",
      "         -6.3486e-04, -4.0646e-02, -1.9369e-03, -4.2849e-02, -2.7090e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1220], requires_grad=True)\n",
      "bias grad:  tensor([-0.2482])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6960]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.1803]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0878,  -322.8736,   -11.4212,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1195], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6780]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0878,  -322.8736,   -11.4212,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.1106e-03,  3.8644e-05,  7.3055e-05,  8.6032e-04,  3.8215e-04,\n",
      "          2.7617e-03,  7.6635e-02,  2.5590e-03,  4.5388e-02,  1.4771e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1195], requires_grad=True)\n",
      "bias grad:  tensor([0.2942])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6780]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2728]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0886,  -322.8737,   -11.4217,  -302.5943]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1224], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7053]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0886,  -322.8737,   -11.4217,  -302.5943]], requires_grad=True)\n",
      "weight grad:  tensor([[3.3520e-03, 0.0000e+00, 9.2732e-05, 1.1301e-03, 6.5143e-04, 4.6390e-04,\n",
      "         8.2512e-02, 3.2320e-03, 7.0827e-02, 1.7659e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1224], requires_grad=True)\n",
      "bias grad:  tensor([0.4092])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7053]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.0826]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0894,  -322.8737,   -11.4224,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1265], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6970]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0894,  -322.8737,   -11.4224,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-6.5742e-04,  0.0000e+00, -5.7373e-06, -2.6329e-04, -2.2997e-04,\n",
      "          2.6699e-04,  5.9214e-03, -2.5055e-04, -8.7456e-03,  3.4931e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1265], requires_grad=True)\n",
      "bias grad:  tensor([-0.0502])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6970]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3527]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0895,  -322.8737,   -11.4223,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1260], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6618]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0895,  -322.8737,   -11.4223,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[1.3361e-04, 6.6470e-05, 5.0143e-05, 5.4923e-04, 1.8521e-06, 1.0318e-03,\n",
      "         4.1166e-02, 1.7766e-03, 3.6453e-02, 9.8341e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1260], requires_grad=True)\n",
      "bias grad:  tensor([0.2098])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6618]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1482]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0899,  -322.8737,   -11.4227,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1281], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6766]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0899,  -322.8737,   -11.4227,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.6745e-04, -8.8372e-05, -6.3008e-05, -7.4957e-04, -6.5561e-05,\n",
      "         -1.9429e-03, -5.6308e-02, -1.8410e-03, -3.9051e-02, -3.6044e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1281], requires_grad=True)\n",
      "bias grad:  tensor([-0.2231])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6766]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.5587]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0893,  -322.8737,   -11.4223,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1259], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6207]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0893,  -322.8737,   -11.4223,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.5703e-03,  0.0000e+00,  5.8686e-05,  6.3979e-04,  3.2758e-04,\n",
      "          6.9193e-04,  3.3034e-02,  2.1004e-03,  4.0418e-02,  1.0993e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1259], requires_grad=True)\n",
      "bias grad:  tensor([0.2396])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6207]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0244]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0896,  -322.8737,   -11.4227,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1283], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6232]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0896,  -322.8737,   -11.4227,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-8.0100e-04,  8.9945e-06, -8.5612e-06, -2.3614e-04, -7.2694e-05,\n",
      "          1.3513e-03,  1.7563e-02, -4.1224e-05, -1.2070e-02,  3.8962e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1283], requires_grad=True)\n",
      "bias grad:  tensor([-0.0573])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6232]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3118]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0898,  -322.8737,   -11.4226,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1277], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.5920]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4045,\n",
      "            -6.0898,  -322.8737,   -11.4226,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[1.9021e-03, 3.5585e-05, 5.5752e-05, 6.4850e-04, 4.3252e-04, 2.3290e-03,\n",
      "         6.8353e-02, 2.0477e-03, 3.8977e-02, 1.1852e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1277], requires_grad=True)\n",
      "bias grad:  tensor([0.2278])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.5920]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1227]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0905,  -322.8737,   -11.4230,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1300], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6042]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0905,  -322.8737,   -11.4230,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[2.1655e-04, 4.2507e-05, 1.0411e-04, 1.0735e-03, 4.0407e-04, 1.7072e-03,\n",
      "         7.0415e-02, 2.8071e-03, 5.9746e-02, 1.6672e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1300], requires_grad=True)\n",
      "bias grad:  tensor([0.3713])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6042]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.3150]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0912,  -322.8738,   -11.4236,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1337], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6357]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0912,  -322.8738,   -11.4236,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[4.2633e-03, 0.0000e+00, 9.3355e-05, 1.1508e-03, 8.7771e-04, 1.2970e-03,\n",
      "         6.5830e-02, 3.2069e-03, 7.2322e-02, 2.1577e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1337], requires_grad=True)\n",
      "bias grad:  tensor([0.4139])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6357]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.1969]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0919,  -322.8738,   -11.4243,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1378], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6554]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0919,  -322.8738,   -11.4243,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[3.1677e-03, 0.0000e+00, 4.1556e-05, 4.6226e-04, 4.8347e-04, 7.8223e-04,\n",
      "         3.7456e-02, 1.9028e-03, 3.1945e-02, 4.5407e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1378], requires_grad=True)\n",
      "bias grad:  tensor([0.1850])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6554]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2251]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0922,  -322.8738,   -11.4246,  -302.5944]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1397], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6329]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4044,\n",
      "            -6.0922,  -322.8738,   -11.4246,  -302.5944]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1931e-04,  3.3563e-04,  2.7132e-04,  3.2056e-03,  7.6535e-04,\n",
      "          7.8010e-03,  2.3153e-01,  7.5309e-03,  1.4319e-01,  2.6533e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1397], requires_grad=True)\n",
      "bias grad:  tensor([0.8840])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6329]], requires_grad=True)\n",
      "lambda grad:  tensor([[-1.6845]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8739,   -11.4260,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1485], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.8014]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8739,   -11.4260,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-2.1331e-03,  0.0000e+00, -7.9330e-06, -2.9274e-04, -1.4933e-04,\n",
      "          2.6438e-04, -8.6320e-04, -5.6946e-05, -9.5310e-03, -9.3396e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1485], requires_grad=True)\n",
      "bias grad:  tensor([-0.0561])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.8014]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.2569]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8739,   -11.4259,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1480], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7757]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0945,  -322.8739,   -11.4259,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.0991e-03,  4.1287e-05,  6.0781e-05,  7.4243e-04,  4.8618e-04,\n",
      "          7.0840e-04,  3.8632e-02,  2.0481e-03,  4.3541e-02,  1.4386e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1480], requires_grad=True)\n",
      "bias grad:  tensor([0.2668])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7757]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0333]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0949,  -322.8739,   -11.4264,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1506], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7790]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0949,  -322.8739,   -11.4264,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.6871e-03, -3.3440e-05,  2.4668e-05,  2.7788e-04,  8.3068e-05,\n",
      "          4.8008e-04,  1.9178e-02,  1.3954e-03,  2.4642e-02,  1.4355e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1506], requires_grad=True)\n",
      "bias grad:  tensor([0.1374])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7790]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.6257]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0951,  -322.8739,   -11.4266,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1520], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7165]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0951,  -322.8739,   -11.4266,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[2.0962e-04, 8.9718e-06, 7.1778e-05, 6.3394e-04, 1.7925e-04, 2.5798e-03,\n",
      "         6.5352e-02, 2.0969e-03, 4.3185e-02, 1.3083e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1520], requires_grad=True)\n",
      "bias grad:  tensor([0.2451])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7165]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0627]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0958,  -322.8740,   -11.4271,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1545], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.7227]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0958,  -322.8740,   -11.4271,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-4.4696e-03, -3.0677e-05, -4.6478e-05, -7.9074e-04, -4.8409e-04,\n",
      "         -3.9549e-04, -3.0503e-02, -1.2414e-03, -3.3843e-02,  7.4139e-05]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1545], requires_grad=True)\n",
      "bias grad:  tensor([-0.1994])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.7227]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.7650]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0955,  -322.8740,   -11.4267,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1525], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6462]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0955,  -322.8740,   -11.4267,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[ 6.8817e-04,  0.0000e+00,  4.7544e-06, -4.8197e-06,  6.3933e-05,\n",
      "          1.2598e-04,  9.3970e-03, -2.0283e-04, -1.8099e-03, -1.8404e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1525], requires_grad=True)\n",
      "bias grad:  tensor([-0.0058])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6462]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.2445]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0956,  -322.8740,   -11.4267,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1524], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6707]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0226,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0956,  -322.8740,   -11.4267,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[3.7851e-03, 2.3518e-05, 8.8045e-05, 1.0673e-03, 7.8956e-04, 1.2510e-03,\n",
      "         6.2179e-02, 3.1103e-03, 6.6632e-02, 2.4205e-03]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1524], requires_grad=True)\n",
      "bias grad:  tensor([0.3965])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6707]], requires_grad=True)\n",
      "lambda grad:  tensor([[-0.0373]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8740,   -11.4274,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1564], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6744]], requires_grad=True)\n",
      "weight before:  Parameter containing:\n",
      "tensor([[   19.0225,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0962,  -322.8740,   -11.4274,  -302.5945]], requires_grad=True)\n",
      "weight grad:  tensor([[-1.8529e-02,  0.0000e+00, -3.7377e-05, -9.3328e-04, -1.2187e-03,\n",
      "         -5.8675e-04, -2.6698e-02, -1.8970e-03, -4.7013e-02, -4.8743e-04]])\n",
      "bias before:  Parameter containing:\n",
      "tensor([-0.1564], requires_grad=True)\n",
      "bias grad:  tensor([-0.2638])\n",
      "lambda before:  Parameter containing:\n",
      "tensor([[0.6744]], requires_grad=True)\n",
      "lambda grad:  tensor([[0.3074]])\n",
      "weight after:  Parameter containing:\n",
      "tensor([[   19.0227,   793.3527, -5009.5923,  2653.3940,  -651.6141,   216.4043,\n",
      "            -6.0959,  -322.8740,   -11.4269,  -302.5945]], requires_grad=True)\n",
      "bias after:  Parameter containing:\n",
      "tensor([-0.1537], requires_grad=True)\n",
      "lambda after:  Parameter containing:\n",
      "tensor([[0.6437]], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearUnknownVariance()"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_scaled_phi = oracle.Left((phi.left - y_trunc_mu) / ch.sqrt(emp_var))\n",
    "trunc_reg = TruncatedRegression(phi=emp_scaled_phi, alpha=Tensor([alpha]), unknown=True, lr=1e-2, step_lr_gamma=1.0, bs=10, n=100, tol=1e-1, steps=2000, val=int(.1*y_trunc.size(0)))\n",
    "trunc_reg.fit(x_trunc_norm, y_trunc_emp_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_, w0_ = (trunc_reg.weight * ch.sqrt(emp_var)) / beta, trunc_reg.intercept * ch.sqrt(emp_var) + y_trunc_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "\n",
    "# ax.scatter3D(x_non_trunc[:,0], x_non_trunc[:,1], y_non_trunc, color='red', label='not seen', alpha=.1)\n",
    "\n",
    "\n",
    "x_max, x_min = x_transform.max(0)[0], x_transform.min(0)[0]\n",
    "X_ = np.arange(x_min[0], x_max[0]/2, 1.0)\n",
    "Y = np.arange(x_min[1], x_max[1]/2, 1.0)\n",
    "X_, Y = np.meshgrid(X_, Y) \n",
    "\n",
    "with ch.no_grad():\n",
    "    emp = Tensor([])\n",
    "    for i in range(X_.shape[0]): \n",
    "        input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "        emp = ch.cat([emp, input_@w.T + trunc_ols.intercept_], 1)\n",
    "    ax.plot_surface(X_, Y, emp.numpy().T, alpha=.15, color='red')\n",
    "    \n",
    "    actual = Tensor([])\n",
    "    for i in range(X_.shape[0]): \n",
    "        input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "        actual = ch.cat([actual, input_@w_transform.T + gt_ols.intercept_], 1)\n",
    "    ax.plot_surface(X_, Y, actual.numpy().T, alpha=.15, color='blue')\n",
    "    \n",
    "    unknown_w_transform = w_.T@random\n",
    "    \n",
    "    pred = Tensor([])\n",
    "    for i in range(X_.shape[0]): \n",
    "        input_ = Tensor(np.hstack([X_[i].reshape(-1, 1), Y[i].reshape(-1, 1)]))\n",
    "        pred = ch.cat([pred, input_@unknown_w_transform.T + w0_], 1)\n",
    "    ax.plot_surface(X_, Y, pred.numpy().T, alpha=.15, color='green')\n",
    "\n",
    "ax.scatter3D(x_trunc_transform[:,0], x_trunc_transform[:,1], y_trunc, color='grey', label='S', alpha=.4)\n",
    "\n",
    "    \n",
    "red_patch = mpatches.Patch(color='red', label='ols')\n",
    "\n",
    "green_patch = mpatches.Patch(color='green', label='our algorithm')\n",
    "blue_patch = mpatches.Patch(color='blue', label=\"$W^{*}$\")\n",
    "plt.legend(handles=[red_patch, blue_patch, green_patch], loc=\"upper right\")\n",
    "    \n",
    "ax.view_init(5.0, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.1051)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Tensor(gt_ols.coef_) - w_.T).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.619945"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(trunc_ols.coef_ - gt_ols.coef_).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.03977319,   1.6586212 , -10.473365  ,   5.5472813 ,\n",
       "         -1.362283  ,   0.45242602,  -0.01257995,  -0.67500263,\n",
       "         -0.0237042 ,  -0.6326117 ]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_ols.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35.22532], dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_ols.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[26.8330]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.663986], dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_ols.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spawn subprocess to run truncreg experiment\n",
    "concat = ch.cat([x_trunc, y_trunc], dim=1).numpy()\n",
    "\"\"\"\n",
    "DATA FORMAT:\n",
    "    -First n-1 columns are independent variables\n",
    "    -nth column is dependent variable\n",
    "\"\"\"\n",
    "concat_df = pd.DataFrame(concat)\n",
    "concat_df.to_csv(args.out_dir + '/' + TMP_FILE) # save data to csv\n",
    "\"\"\"\n",
    "Arguments\n",
    "- c - truncation point (float)\n",
    "- dir - left or right -> type of truncation (str)\n",
    "\"\"\"\n",
    "cmd = [COMMAND, PATH2SCRIPT] + [str(17), str(x_trunc.size(1)), 'left', args.out_dir]\n",
    "\n",
    "# check_output will run the command and store the result\n",
    "st = datetime.datetime.now()\n",
    "result = subprocess.check_output(cmd, universal_newlines=True)\n",
    "trunc_res = Tensor(pd.read_csv(args.out_dir + '/' + RESULT_FILE)['x'].to_numpy())\n",
    "trunc_reg_params = ch.cat([trunc_res[1:-1].flatten(), trunc_res[0][None,...]])\n",
    "\n",
    "trunc_reg_pred = X@trunc_reg_params[:-1] + trunc_reg_params[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.1408)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trunc_reg_params[:-1] - Tensor(gt_ols.coef_)).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.1732367e-02,  2.8715198e+00, -1.6511484e+01,  3.8322721e+00,\n",
       "        -1.4202756e+00,  2.3889929e-01, -1.1430293e-02, -9.3549943e-01,\n",
       "         1.0320530e-02, -5.4784405e-01]], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_ols.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.03977319,   1.6586212 , -10.473365  ,   5.5472813 ,\n",
       "         -1.362283  ,   0.45242602,  -0.01257995,  -0.67500263,\n",
       "         -0.0237042 ,  -0.6326117 ]], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_ols.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Experiment\n",
    "For storing the experiment's hyperparameters, we use [cox](https://github.com/MadryLab/cox), MadryLab's light-weight experimental design and analysis framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Parameters({\n",
    "    \"bias\": True,\n",
    "    \"bs\": 10,\n",
    "    \"trials\": 100,\n",
    "    \"steps\": 1000,\n",
    "    \"out_dir\": '/Users/patroklos/regression', \n",
    "    \"table_name\": 'results', \n",
    "    'tol': 1e-2,\n",
    "    'n': 100,\n",
    "})\n",
    "EXP = 'AirQuality'\n",
    "mse_loss = ch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Store for Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(kwargs, X, y):\n",
    "    \"\"\"\n",
    "    Runs a trial of a truncated regression experiment. Runs a maximum \n",
    "    of three trials of an experiment. The experiment terminates when either \n",
    "    the norm of teh score is less than 3e-1, or when three trials is up. After \n",
    "    three trials it returns the best truncated regression experiment.\n",
    "    :param kwargs: keyword arguments for experiment \n",
    "    :param X: independent variable\n",
    "    :param y: dependent variable\n",
    "    :return: truncated regression experiment and time that experiment took\n",
    "    \"\"\"\n",
    "    st = datetime.datetime.now()        \n",
    "    # run procedure until get reasonable score\n",
    "    attempt, score, best_trunc_reg = 0, None, None\n",
    "    while (score is None or score.norm() > 3e-1) and attempt < 3:\n",
    "        trunc_reg = TruncatedRegression(**kwargs)\n",
    "        trunc_reg.fit(X, y)\n",
    "        grad = trunc_reg.score()\n",
    "        if score is None or grad.norm() < score.norm(): \n",
    "            score, best_trunc_reg = grad, trunc_reg\n",
    "        attempt += 1\n",
    "    total_time = int((datetime.datetime.now() - st).total_seconds())\n",
    "    return best_trunc_reg, total_time  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.9128])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in: /home/gridsan/stefanou/Regression/AirQuality/9db3846d-1128-4c80-b488-05bd4c3eb5ba\n",
      "alpha:  tensor([1.])\n",
      "ols params:  tensor([-0.0652, 12.7039])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.09644844383001328]\n",
      "Iteration: 1.0 | Score: [0.11379536986351013]\n",
      "Iteration: 2.0 | Score: [0.09146584570407867]\n",
      "Iteration: 3.0 | Score: [0.04895583540201187]\n",
      "Iteration: 4.0 | Score: [0.0071210190653800964]\n",
      "Iteration: 0.0 | Score: [-0.18954379856586456, 0.6790188550949097]\n",
      "Iteration: 1.0 | Score: [0.15723848342895508, -0.5712143182754517]\n",
      "Iteration: 2.0 | Score: [-0.22678431868553162, 0.8314092755317688]\n",
      "Iteration: 3.0 | Score: [-0.5465685129165649, 1.8951863050460815]\n",
      "Iteration: 4.0 | Score: [0.2693268358707428, -1.0397220849990845]\n",
      "Iteration: 5.0 | Score: [-0.08975881338119507, 0.34040749073028564]\n",
      "Iteration: 6.0 | Score: [-0.19855782389640808, 0.6803900599479675]\n",
      "Iteration: 7.0 | Score: [-0.14345692098140717, 0.5043009519577026]\n",
      "Iteration: 8.0 | Score: [-0.0776267945766449, 0.2546085715293884]\n",
      "Iteration: 9.0 | Score: [-0.10362359881401062, 0.3929413855075836]\n",
      "Iteration: 10.0 | Score: [-0.5120222568511963, 1.749625563621521]\n",
      "Iteration: 0.0 | Score: [-0.029896829277276993, 0.46611320972442627]\n",
      "Iteration: 1.0 | Score: [-0.07182861119508743, 0.6898664236068726]\n",
      "Iteration: 2.0 | Score: [-0.08880749344825745, 0.7334345579147339]\n",
      "Iteration: 3.0 | Score: [-0.2933974266052246, 1.4460104703903198]\n",
      "Iteration: 4.0 | Score: [-0.10961731523275375, 0.7788609266281128]\n",
      "Iteration: 5.0 | Score: [-0.2588917315006256, 1.3201229572296143]\n",
      "Iteration: 6.0 | Score: [-0.07872618734836578, 0.6533423662185669]\n",
      "Iteration: 7.0 | Score: [0.013968368992209435, 0.3294677138328552]\n",
      "Iteration: 8.0 | Score: [0.08287502825260162, 0.08534641563892365]\n",
      "Iteration: 9.0 | Score: [-0.058519307523965836, 0.5467551946640015]\n",
      "Iteration: 10.0 | Score: [-0.00792518351227045, 0.37383097410202026]\n",
      "Iteration: 0.0 | Score: [0.32064390182495117, -0.7717956304550171]\n",
      "Iteration: 1.0 | Score: [0.30113717913627625, -0.5824888348579407]\n",
      "Iteration: 2.0 | Score: [0.6633661985397339, -2.008444309234619]\n",
      "Iteration: 3.0 | Score: [-0.12960252165794373, 0.8361221551895142]\n",
      "Iteration: 4.0 | Score: [0.37802499532699585, -0.9255903363227844]\n",
      "Iteration: 5.0 | Score: [0.46002376079559326, -1.2549889087677002]\n",
      "Iteration: 6.0 | Score: [0.3842492997646332, -0.9641534090042114]\n",
      "Iteration: 7.0 | Score: [0.04670333117246628, 0.20958422124385834]\n",
      "Iteration: 8.0 | Score: [0.3216334879398346, -0.7366794347763062]\n",
      "Iteration: 9.0 | Score: [0.4116787314414978, -1.0922644138336182]\n",
      "Iteration: 10.0 | Score: [0.19194510579109192, -0.28490376472473145]\n",
      "alpha:  tensor([0.9935])\n",
      "ols params:  tensor([-0.0652, 12.7582])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.20186501741409302]\n",
      "Iteration: 1.0 | Score: [0.18514332175254822]\n",
      "Iteration: 2.0 | Score: [0.1804177463054657]\n",
      "Iteration: 3.0 | Score: [0.10263629257678986]\n",
      "Iteration: 4.0 | Score: [0.12694957852363586]\n",
      "Iteration: 5.0 | Score: [0.17097729444503784]\n",
      "Iteration: 6.0 | Score: [0.15162941813468933]\n",
      "Iteration: 7.0 | Score: [0.10814644396305084]\n",
      "Iteration: 8.0 | Score: [0.12217295914888382]\n",
      "Iteration: 9.0 | Score: [0.09494079649448395]\n",
      "Iteration: 10.0 | Score: [0.1615472137928009]\n",
      "Iteration: 0.0 | Score: [-0.3636205494403839, 1.205667495727539]\n",
      "Iteration: 1.0 | Score: [-0.8886895775794983, 3.2160041332244873]\n",
      "Iteration: 2.0 | Score: [-0.1309974044561386, 0.4871615767478943]\n",
      "Iteration: 3.0 | Score: [-0.8069979548454285, 2.94651460647583]\n",
      "Iteration: 4.0 | Score: [-0.3910585641860962, 1.4604928493499756]\n",
      "Iteration: 5.0 | Score: [-0.43222182989120483, 1.5943353176116943]\n",
      "Iteration: 6.0 | Score: [-0.21395179629325867, 0.7827233672142029]\n",
      "Iteration: 7.0 | Score: [-0.6602090001106262, 2.3925962448120117]\n",
      "Iteration: 8.0 | Score: [-0.7618749737739563, 2.7525434494018555]\n",
      "Iteration: 9.0 | Score: [-0.39898693561553955, 1.4155726432800293]\n",
      "Iteration: 10.0 | Score: [-0.2477758377790451, 0.8482266068458557]\n",
      "Iteration: 0.0 | Score: [-0.09802350401878357, 0.3323531448841095]\n",
      "Iteration: 1.0 | Score: [0.03406459838151932, -0.11978419125080109]\n",
      "Iteration: 2.0 | Score: [-0.08685009926557541, 0.3401469588279724]\n",
      "Iteration: 3.0 | Score: [-0.0461399219930172, 0.1723330318927765]\n",
      "Iteration: 4.0 | Score: [0.3960965871810913, -1.6233549118041992]\n",
      "Iteration: 5.0 | Score: [-0.10214675962924957, 0.34044545888900757]\n",
      "Iteration: 6.0 | Score: [-0.24395470321178436, 0.8633278608322144]\n",
      "Iteration: 7.0 | Score: [-0.014662235043942928, 0.02863730490207672]\n",
      "Iteration: 8.0 | Score: [0.017133284360170364, -0.12599481642246246]\n",
      "Iteration: 9.0 | Score: [-0.18384025990962982, 0.629825234413147]\n",
      "Iteration: 10.0 | Score: [-0.21413195133209229, 0.7114547491073608]\n",
      "alpha:  tensor([0.9869])\n",
      "ols params:  tensor([-0.0634, 12.7028])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [-0.0017736703157424927]\n",
      "Iteration: 1.0 | Score: [-0.024053111672401428]\n",
      "Iteration: 2.0 | Score: [-0.03994365036487579]\n",
      "Iteration: 3.0 | Score: [-0.03080463409423828]\n",
      "Iteration: 4.0 | Score: [-0.07168988883495331]\n",
      "Iteration: 5.0 | Score: [-0.05741560831665993]\n",
      "Iteration: 6.0 | Score: [-0.07977979630231857]\n",
      "Iteration: 7.0 | Score: [-0.04581540822982788]\n",
      "Iteration: 8.0 | Score: [-0.056244079023599625]\n",
      "Iteration: 9.0 | Score: [-0.005269236862659454]\n",
      "Iteration: 0.0 | Score: [-0.43588486313819885, 1.8624379634857178]\n",
      "Iteration: 1.0 | Score: [-0.6632775068283081, 2.786868095397949]\n",
      "Iteration: 2.0 | Score: [-0.5238721370697021, 2.276573657989502]\n",
      "Iteration: 3.0 | Score: [0.20644314587116241, -0.7042456269264221]\n",
      "Iteration: 4.0 | Score: [0.32044661045074463, -1.224715232849121]\n",
      "Iteration: 5.0 | Score: [-0.8144335746765137, 3.2882206439971924]\n",
      "Iteration: 6.0 | Score: [-0.683631956577301, 2.839871406555176]\n",
      "Iteration: 7.0 | Score: [-0.4622232913970947, 2.0252537727355957]\n",
      "Iteration: 8.0 | Score: [-0.5960422158241272, 2.5255236625671387]\n",
      "Iteration: 9.0 | Score: [-0.2919408082962036, 1.3638267517089844]\n",
      "Iteration: 10.0 | Score: [0.008115453645586967, 0.129575714468956]\n",
      "Iteration: 0.0 | Score: [-0.7402216792106628, 3.2339305877685547]\n",
      "Iteration: 1.0 | Score: [-0.9791361689567566, 4.155894756317139]\n",
      "Iteration: 2.0 | Score: [-1.0058612823486328, 4.227958679199219]\n",
      "Iteration: 3.0 | Score: [-0.6293082237243652, 2.842487335205078]\n",
      "Iteration: 4.0 | Score: [-0.9068729281425476, 3.8619771003723145]\n",
      "Iteration: 5.0 | Score: [-0.8061915636062622, 3.5009422302246094]\n",
      "Iteration: 6.0 | Score: [-0.7306041717529297, 3.176435947418213]\n",
      "Iteration: 7.0 | Score: [-0.19690115749835968, 1.0052764415740967]\n",
      "Iteration: 8.0 | Score: [-0.6811289191246033, 3.008513927459717]\n",
      "Iteration: 9.0 | Score: [-0.9079594612121582, 3.8189868927001953]\n",
      "Iteration: 10.0 | Score: [-0.7904258966445923, 3.4040069580078125]\n",
      "Iteration: 0.0 | Score: [-0.09572824090719223, 0.5552071928977966]\n",
      "Iteration: 1.0 | Score: [-0.11393500864505768, 0.6944220662117004]\n",
      "Iteration: 2.0 | Score: [-0.6114015579223633, 2.338088274002075]\n",
      "Iteration: 3.0 | Score: [0.43003976345062256, -1.4503294229507446]\n",
      "Iteration: 4.0 | Score: [-0.08023396134376526, 0.5088269710540771]\n",
      "Iteration: 5.0 | Score: [-0.09120631963014603, 0.5571165680885315]\n",
      "Iteration: 6.0 | Score: [-0.22077825665473938, 1.0066053867340088]\n",
      "Iteration: 7.0 | Score: [-0.5237828493118286, 2.027672052383423]\n",
      "Iteration: 8.0 | Score: [-0.1789153814315796, 0.8438647389411926]\n",
      "Iteration: 9.0 | Score: [-0.20954138040542603, 0.9648874402046204]\n",
      "Iteration: 10.0 | Score: [0.06789052486419678, -0.06983387470245361]\n",
      "alpha:  tensor([0.9804])\n",
      "ols params:  tensor([-0.0620, 12.6797])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.10757256299257278]\n",
      "Iteration: 1.0 | Score: [0.0239810012280941]\n",
      "Iteration: 2.0 | Score: [0.04356412589550018]\n",
      "Iteration: 3.0 | Score: [0.03139456734061241]\n",
      "Iteration: 4.0 | Score: [0.13083499670028687]\n",
      "Iteration: 5.0 | Score: [0.10241539031267166]\n",
      "Iteration: 6.0 | Score: [0.08343221992254257]\n",
      "Iteration: 7.0 | Score: [0.0443057119846344]\n",
      "Iteration: 8.0 | Score: [0.011398876085877419]\n",
      "Iteration: 9.0 | Score: [0.04244833439588547]\n",
      "Iteration: 10.0 | Score: [0.06972293555736542]\n",
      "Iteration: 0.0 | Score: [0.2600573003292084, -0.8089395761489868]\n",
      "Iteration: 1.0 | Score: [0.0982314795255661, -0.1755026876926422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2.0 | Score: [0.33660927414894104, -1.1059517860412598]\n",
      "Iteration: 3.0 | Score: [-0.1548558473587036, 0.737293541431427]\n",
      "Iteration: 4.0 | Score: [-0.0008948851027525961, 0.17620481550693512]\n",
      "Iteration: 5.0 | Score: [0.01255469024181366, 0.12496758252382278]\n",
      "Iteration: 6.0 | Score: [0.5440989136695862, -1.9664125442504883]\n",
      "Iteration: 7.0 | Score: [0.4126148819923401, -1.4374372959136963]\n",
      "Iteration: 8.0 | Score: [0.19856731593608856, -0.564809262752533]\n",
      "Iteration: 9.0 | Score: [0.3306387960910797, -1.1038143634796143]\n",
      "Iteration: 10.0 | Score: [0.07363545894622803, -0.13026419281959534]\n",
      "Iteration: 0.0 | Score: [0.27475398778915405, -1.0851409435272217]\n",
      "Iteration: 1.0 | Score: [0.13992717862129211, -0.5825761556625366]\n",
      "Iteration: 2.0 | Score: [0.6193742156028748, -2.443345546722412]\n",
      "Iteration: 3.0 | Score: [-0.02742133103311062, -0.016316860914230347]\n",
      "Iteration: 4.0 | Score: [0.26869598031044006, -1.1151485443115234]\n",
      "Iteration: 5.0 | Score: [0.3840940594673157, -1.572538137435913]\n",
      "Iteration: 6.0 | Score: [0.059969089925289154, -0.3414604365825653]\n",
      "Iteration: 7.0 | Score: [0.20072007179260254, -0.8921670913696289]\n",
      "Iteration: 8.0 | Score: [0.27454444766044617, -1.1478869915008545]\n",
      "Iteration: 9.0 | Score: [0.39240190386772156, -1.6314678192138672]\n",
      "Iteration: 10.0 | Score: [0.09535425156354904, -0.4890720546245575]\n",
      "Iteration: 0.0 | Score: [0.4212687313556671, -1.2924106121063232]\n",
      "Iteration: 1.0 | Score: [0.12338721752166748, -0.2453673928976059]\n",
      "Iteration: 2.0 | Score: [0.204366073012352, -0.5439528822898865]\n",
      "Iteration: 3.0 | Score: [0.7529382109642029, -2.6083450317382812]\n",
      "Iteration: 4.0 | Score: [0.17892977595329285, -0.46326345205307007]\n",
      "Iteration: 5.0 | Score: [0.2242244929075241, -0.6197872161865234]\n",
      "Iteration: 6.0 | Score: [0.3657214641571045, -1.1387957334518433]\n",
      "Iteration: 7.0 | Score: [0.38796573877334595, -1.2303377389907837]\n",
      "Iteration: 8.0 | Score: [0.13975901901721954, -0.3833938539028168]\n",
      "Iteration: 9.0 | Score: [0.270145982503891, -0.8277499079704285]\n",
      "Iteration: 10.0 | Score: [0.5727328062057495, -1.959814190864563]\n",
      "alpha:  tensor([0.9739])\n",
      "ols params:  tensor([-0.0634, 12.7296])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.11167828738689423]\n",
      "Iteration: 1.0 | Score: [0.1122845858335495]\n",
      "Iteration: 2.0 | Score: [0.10656382888555527]\n",
      "Iteration: 3.0 | Score: [0.04088352993130684]\n",
      "Iteration: 4.0 | Score: [0.060897886753082275]\n",
      "Iteration: 5.0 | Score: [0.06626981496810913]\n",
      "Iteration: 6.0 | Score: [0.09485414624214172]\n",
      "Iteration: 7.0 | Score: [0.1619684398174286]\n",
      "Iteration: 8.0 | Score: [0.0845230370759964]\n",
      "Iteration: 9.0 | Score: [0.07731552422046661]\n",
      "Iteration: 10.0 | Score: [0.1104278564453125]\n",
      "Iteration: 0.0 | Score: [0.29544755816459656, -1.0318655967712402]\n",
      "Iteration: 1.0 | Score: [0.04233908653259277, -0.07597759366035461]\n",
      "Iteration: 2.0 | Score: [0.15884722769260406, -0.5159177780151367]\n",
      "Iteration: 3.0 | Score: [-0.01565103977918625, 0.10600113123655319]\n",
      "Iteration: 4.0 | Score: [0.19188062846660614, -0.7176986336708069]\n",
      "Iteration: 5.0 | Score: [0.28948676586151123, -1.0939316749572754]\n",
      "Iteration: 6.0 | Score: [0.5430294275283813, -2.189323902130127]\n",
      "Iteration: 7.0 | Score: [0.6697668433189392, -2.7956838607788086]\n",
      "Iteration: 8.0 | Score: [0.09364674985408783, -0.39385858178138733]\n",
      "Iteration: 9.0 | Score: [0.4752073585987091, -1.8357932567596436]\n",
      "Iteration: 10.0 | Score: [0.07980785518884659, -0.3660881221294403]\n",
      "Iteration: 0.0 | Score: [0.6771867275238037, -2.5321028232574463]\n",
      "Iteration: 1.0 | Score: [0.8953714370727539, -3.3586153984069824]\n",
      "Iteration: 2.0 | Score: [0.5685101747512817, -2.1047189235687256]\n",
      "Iteration: 3.0 | Score: [0.7345201373100281, -2.812912940979004]\n",
      "Iteration: 4.0 | Score: [0.552787721157074, -2.0965442657470703]\n",
      "Iteration: 5.0 | Score: [0.5840655565261841, -2.2353978157043457]\n",
      "Iteration: 6.0 | Score: [0.5847616791725159, -2.2767791748046875]\n",
      "Iteration: 7.0 | Score: [0.8319413661956787, -3.2107129096984863]\n",
      "Iteration: 8.0 | Score: [0.683447003364563, -2.6155054569244385]\n",
      "Iteration: 9.0 | Score: [0.5816817283630371, -2.2400803565979004]\n",
      "Iteration: 10.0 | Score: [0.6550350189208984, -2.4974453449249268]\n",
      "Iteration: 0.0 | Score: [0.3387715518474579, -1.34376859664917]\n",
      "Iteration: 1.0 | Score: [0.06520785391330719, -0.3079690933227539]\n",
      "Iteration: 2.0 | Score: [0.11622589826583862, -0.4583790600299835]\n",
      "Iteration: 3.0 | Score: [0.19463308155536652, -0.801216721534729]\n",
      "Iteration: 4.0 | Score: [0.24339404702186584, -0.9721583127975464]\n",
      "Iteration: 5.0 | Score: [0.22826650738716125, -0.9466447234153748]\n",
      "Iteration: 6.0 | Score: [0.24136826395988464, -1.0587362051010132]\n",
      "Iteration: 7.0 | Score: [0.3811129033565521, -1.5481282472610474]\n",
      "Iteration: 8.0 | Score: [0.25172290205955505, -1.0822978019714355]\n",
      "Iteration: 9.0 | Score: [0.25645673274993896, -1.0727512836456299]\n",
      "Iteration: 10.0 | Score: [0.23974227905273438, -1.0156625509262085]\n",
      "alpha:  tensor([0.9673])\n",
      "ols params:  tensor([-0.0626, 12.7023])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.062117427587509155]\n",
      "Iteration: 1.0 | Score: [-0.08542206883430481]\n",
      "Iteration: 2.0 | Score: [-0.008585276082158089]\n",
      "Iteration: 0.0 | Score: [-0.15283019840717316, 0.6238312721252441]\n",
      "Iteration: 1.0 | Score: [-0.3107069134712219, 1.2210278511047363]\n",
      "Iteration: 2.0 | Score: [-0.904630720615387, 3.3242053985595703]\n",
      "Iteration: 3.0 | Score: [0.2765248417854309, -1.2291524410247803]\n",
      "Iteration: 4.0 | Score: [-0.3766891062259674, 1.4377963542938232]\n",
      "Iteration: 5.0 | Score: [-0.24106693267822266, 0.8933688998222351]\n",
      "Iteration: 6.0 | Score: [-0.147023543715477, 0.5411837100982666]\n",
      "Iteration: 7.0 | Score: [-0.3854001760482788, 1.4810917377471924]\n",
      "Iteration: 8.0 | Score: [-0.1617739051580429, 0.5873386859893799]\n",
      "Iteration: 9.0 | Score: [-0.5490784049034119, 2.0699615478515625]\n",
      "Iteration: 10.0 | Score: [-0.07130585610866547, 0.198500394821167]\n",
      "Iteration: 0.0 | Score: [-0.15063150227069855, 0.5907262563705444]\n",
      "Iteration: 1.0 | Score: [-0.8393240571022034, 3.0664114952087402]\n",
      "Iteration: 2.0 | Score: [0.05647096410393715, -0.22886672616004944]\n",
      "Iteration: 3.0 | Score: [-0.5235508680343628, 1.9670900106430054]\n",
      "Iteration: 4.0 | Score: [0.09858717024326324, -0.39167520403862]\n",
      "Iteration: 5.0 | Score: [-0.22124747931957245, 0.8797512054443359]\n",
      "Iteration: 6.0 | Score: [-0.034881580621004105, 0.14240920543670654]\n",
      "Iteration: 7.0 | Score: [-0.5135337114334106, 1.9544715881347656]\n",
      "Iteration: 8.0 | Score: [-0.5847273468971252, 2.181644916534424]\n",
      "Iteration: 9.0 | Score: [-0.20408247411251068, 0.8037540912628174]\n",
      "Iteration: 10.0 | Score: [-0.3564959466457367, 1.3353943824768066]\n",
      "Iteration: 0.0 | Score: [-0.15180125832557678, 0.5005337595939636]\n",
      "Iteration: 1.0 | Score: [-0.5002490878105164, 1.8705586194992065]\n",
      "Iteration: 2.0 | Score: [0.795079231262207, -3.704495906829834]\n",
      "Iteration: 3.0 | Score: [-0.23440979421138763, 0.812842607498169]\n",
      "Iteration: 4.0 | Score: [-0.489357590675354, 1.7725672721862793]\n",
      "Iteration: 5.0 | Score: [-0.2987481653690338, 1.062793254852295]\n",
      "Iteration: 6.0 | Score: [-0.2321544885635376, 0.8002967238426208]\n",
      "Iteration: 7.0 | Score: [-0.23047904670238495, 0.7654224634170532]\n",
      "Iteration: 8.0 | Score: [-0.3991113007068634, 1.4500136375427246]\n",
      "Iteration: 9.0 | Score: [0.24851731956005096, -1.3011784553527832]\n",
      "Iteration: 10.0 | Score: [-0.11594410985708237, 0.2847042381763458]\n",
      "alpha:  tensor([0.9346])\n",
      "ols params:  tensor([-0.0581, 12.6402])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.009100556373596191]\n",
      "Iteration: 1.0 | Score: [-0.14171482622623444]\n",
      "Iteration: 2.0 | Score: [-0.08831602334976196]\n",
      "Iteration: 3.0 | Score: [-0.08272001147270203]\n",
      "Iteration: 4.0 | Score: [-0.07521070539951324]\n",
      "Iteration: 5.0 | Score: [-0.07149948179721832]\n",
      "Iteration: 6.0 | Score: [-0.061097562313079834]\n",
      "Iteration: 7.0 | Score: [-0.020625591278076172]\n",
      "Iteration: 8.0 | Score: [-0.0917215496301651]\n",
      "Iteration: 9.0 | Score: [-0.0032677501440048218]\n",
      "Iteration: 0.0 | Score: [0.6675151586532593, -2.6218390464782715]\n",
      "Iteration: 1.0 | Score: [0.41695883870124817, -1.6063495874404907]\n",
      "Iteration: 2.0 | Score: [0.49927830696105957, -1.9604504108428955]\n",
      "Iteration: 3.0 | Score: [0.32193905115127563, -1.2857366800308228]\n",
      "Iteration: 4.0 | Score: [1.074438452720642, -4.4132184982299805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5.0 | Score: [0.4646943211555481, -1.8291903734207153]\n",
      "Iteration: 6.0 | Score: [0.4730321168899536, -1.8756872415542603]\n",
      "Iteration: 7.0 | Score: [0.3135768473148346, -1.2362128496170044]\n",
      "Iteration: 8.0 | Score: [0.8106727600097656, -3.3004698753356934]\n",
      "Iteration: 9.0 | Score: [0.24558277428150177, -0.9833738803863525]\n",
      "Iteration: 10.0 | Score: [0.9717714786529541, -4.039463043212891]\n",
      "Iteration: 0.0 | Score: [0.2988484799861908, -1.1245543956756592]\n",
      "Iteration: 1.0 | Score: [0.07745835185050964, -0.2495671510696411]\n",
      "Iteration: 2.0 | Score: [-0.15322889387607574, 0.6620206832885742]\n",
      "Iteration: 3.0 | Score: [0.5102236270904541, -2.02639102935791]\n",
      "Iteration: 4.0 | Score: [0.9766778349876404, -4.213742733001709]\n",
      "Iteration: 5.0 | Score: [0.007174776401370764, -0.009682059288024902]\n",
      "alpha:  tensor([0.8954])\n",
      "ols params:  tensor([-0.0508, 12.4823])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.16942664980888367]\n",
      "Iteration: 1.0 | Score: [0.010658908635377884]\n",
      "Iteration: 2.0 | Score: [-0.013408660888671875]\n",
      "Iteration: 3.0 | Score: [0.051256902515888214]\n",
      "Iteration: 4.0 | Score: [-0.04971747845411301]\n",
      "Iteration: 5.0 | Score: [0.031030867248773575]\n",
      "Iteration: 6.0 | Score: [0.050522997975349426]\n",
      "Iteration: 7.0 | Score: [-0.0028995536267757416]\n",
      "Iteration: 0.0 | Score: [0.07999169826507568, 0.5214139223098755]\n",
      "Iteration: 1.0 | Score: [-0.01183243840932846, 0.8558787107467651]\n",
      "Iteration: 2.0 | Score: [-0.038265470415353775, 0.9107598066329956]\n",
      "Iteration: 3.0 | Score: [-0.4219646751880646, 2.353361129760742]\n",
      "Iteration: 4.0 | Score: [0.163761168718338, 0.13187497854232788]\n",
      "Iteration: 5.0 | Score: [-0.25226572155952454, 1.7706900835037231]\n",
      "Iteration: 6.0 | Score: [-0.311406672000885, 1.9549752473831177]\n",
      "Iteration: 7.0 | Score: [0.12009574472904205, 0.2922583818435669]\n",
      "Iteration: 8.0 | Score: [0.006564401090145111, 0.7204278111457825]\n",
      "Iteration: 9.0 | Score: [-0.24866074323654175, 1.7182492017745972]\n",
      "Iteration: 10.0 | Score: [-0.0023955772630870342, 0.7507084608078003]\n",
      "Iteration: 0.0 | Score: [0.017606839537620544, 0.02693963050842285]\n",
      "Iteration: 1.0 | Score: [-0.5462058782577515, 2.1312501430511475]\n",
      "Iteration: 2.0 | Score: [0.057054564356803894, -0.18284651637077332]\n",
      "Iteration: 3.0 | Score: [-0.17013606429100037, 0.7167055606842041]\n",
      "Iteration: 4.0 | Score: [-0.6027560234069824, 2.3208134174346924]\n",
      "Iteration: 5.0 | Score: [-0.2705932557582855, 1.0916147232055664]\n",
      "Iteration: 6.0 | Score: [0.17797505855560303, -0.7053909301757812]\n",
      "Iteration: 7.0 | Score: [-0.23504018783569336, 0.9322537183761597]\n",
      "Iteration: 8.0 | Score: [-0.11498656123876572, 0.48505672812461853]\n",
      "Iteration: 9.0 | Score: [-0.23721429705619812, 0.950343132019043]\n",
      "Iteration: 10.0 | Score: [-0.14490695297718048, 0.5543062686920166]\n",
      "Iteration: 0.0 | Score: [0.06287436187267303, -0.08734230697154999]\n",
      "Iteration: 1.0 | Score: [-0.4100649058818817, 1.7405709028244019]\n",
      "Iteration: 2.0 | Score: [0.08381098508834839, -0.20364795625209808]\n",
      "Iteration: 3.0 | Score: [-0.2920076251029968, 1.274282693862915]\n",
      "Iteration: 4.0 | Score: [-0.30583059787750244, 1.3253533840179443]\n",
      "Iteration: 5.0 | Score: [-0.05576581135392189, 0.3620661795139313]\n",
      "Iteration: 6.0 | Score: [-0.2707847058773041, 1.1812833547592163]\n",
      "Iteration: 7.0 | Score: [0.3320029377937317, -1.2869426012039185]\n",
      "Iteration: 8.0 | Score: [-0.0693901926279068, 0.4163704216480255]\n",
      "Iteration: 9.0 | Score: [-0.1827487349510193, 0.8500734567642212]\n",
      "Iteration: 10.0 | Score: [-0.08810846507549286, 0.4559595286846161]\n",
      "alpha:  tensor([0.8431])\n",
      "ols params:  tensor([-0.0432, 12.4028])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.156276136636734]\n",
      "Iteration: 1.0 | Score: [-0.03707485646009445]\n",
      "Iteration: 2.0 | Score: [-0.033978208899497986]\n",
      "Iteration: 3.0 | Score: [0.019192034378647804]\n",
      "Iteration: 4.0 | Score: [-0.03050180710852146]\n",
      "Iteration: 5.0 | Score: [-0.0379054956138134]\n",
      "Iteration: 6.0 | Score: [-0.023806720972061157]\n",
      "Iteration: 7.0 | Score: [-0.01141270063817501]\n",
      "Iteration: 8.0 | Score: [-0.027165699750185013]\n",
      "Iteration: 9.0 | Score: [-0.06646464765071869]\n",
      "Iteration: 10.0 | Score: [-0.005397513508796692]\n",
      "Iteration: 0.0 | Score: [0.8624327182769775, -3.1838865280151367]\n",
      "Iteration: 1.0 | Score: [0.795172929763794, -2.9129626750946045]\n",
      "Iteration: 2.0 | Score: [1.5881304740905762, -6.488161087036133]\n",
      "Iteration: 3.0 | Score: [0.48531481623649597, -1.650407075881958]\n",
      "Iteration: 4.0 | Score: [0.8932364583015442, -3.329571008682251]\n",
      "Iteration: 5.0 | Score: [1.4074112176895142, -5.697558879852295]\n",
      "Iteration: 6.0 | Score: [0.483612060546875, -1.6646206378936768]\n",
      "Iteration: 7.0 | Score: [0.7403886318206787, -2.696106195449829]\n",
      "Iteration: 8.0 | Score: [1.3502063751220703, -5.431972980499268]\n",
      "Iteration: 9.0 | Score: [0.5316824913024902, -1.854777455329895]\n",
      "Iteration: 10.0 | Score: [0.7143248319625854, -2.5869672298431396]\n",
      "Iteration: 0.0 | Score: [0.1550249606370926, -0.6927038431167603]\n",
      "Iteration: 1.0 | Score: [0.23852583765983582, -1.1125203371047974]\n",
      "Iteration: 2.0 | Score: [0.233026921749115, -1.0614557266235352]\n",
      "Iteration: 3.0 | Score: [-0.5095797777175903, 1.921971082687378]\n",
      "Iteration: 4.0 | Score: [0.16936661303043365, -0.8221779465675354]\n",
      "Iteration: 5.0 | Score: [0.29723310470581055, -1.462714672088623]\n",
      "Iteration: 6.0 | Score: [-0.4220358729362488, 1.5972442626953125]\n",
      "Iteration: 7.0 | Score: [0.11442606151103973, -0.602064847946167]\n",
      "Iteration: 8.0 | Score: [0.2218954712152481, -1.109019160270691]\n",
      "Iteration: 9.0 | Score: [-0.3427201211452484, 1.26749587059021]\n",
      "Iteration: 10.0 | Score: [0.09530364722013474, -0.5342662930488586]\n",
      "Iteration: 0.0 | Score: [0.23606736958026886, -0.9596646428108215]\n",
      "Iteration: 1.0 | Score: [0.04074292629957199, -0.17841437458992004]\n",
      "Iteration: 2.0 | Score: [-0.38312649726867676, 1.4180058240890503]\n",
      "Iteration: 3.0 | Score: [-0.6657798290252686, 2.3547613620758057]\n",
      "Iteration: 4.0 | Score: [-0.04837142676115036, 0.1378212869167328]\n",
      "Iteration: 5.0 | Score: [-0.3613088130950928, 1.320446252822876]\n",
      "Iteration: 6.0 | Score: [-0.3968421518802643, 1.4415831565856934]\n",
      "Iteration: 7.0 | Score: [-0.02226133644580841, 0.03807824105024338]\n",
      "Iteration: 8.0 | Score: [-0.3653632700443268, 1.336402416229248]\n",
      "Iteration: 9.0 | Score: [-0.16709040105342865, 0.6108359098434448]\n",
      "Iteration: 10.0 | Score: [0.00975017435848713, -0.10350926965475082]\n",
      "alpha:  tensor([0.7843])\n",
      "ols params:  tensor([-0.0420, 12.6315])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.39487332105636597]\n",
      "Iteration: 1.0 | Score: [0.20463114976882935]\n",
      "Iteration: 2.0 | Score: [0.20575280487537384]\n",
      "Iteration: 3.0 | Score: [0.14541378617286682]\n",
      "Iteration: 4.0 | Score: [0.16833481192588806]\n",
      "Iteration: 5.0 | Score: [0.1859884262084961]\n",
      "Iteration: 6.0 | Score: [0.27018022537231445]\n",
      "Iteration: 7.0 | Score: [0.17817744612693787]\n",
      "Iteration: 8.0 | Score: [0.20158664882183075]\n",
      "Iteration: 9.0 | Score: [0.14931240677833557]\n",
      "Iteration: 10.0 | Score: [0.22802172601222992]\n",
      "Iteration: 0.0 | Score: [-0.23479801416397095, 1.6467918157577515]\n",
      "Iteration: 1.0 | Score: [-0.5784499645233154, 3.0857059955596924]\n",
      "Iteration: 2.0 | Score: [-0.21926453709602356, 1.5201270580291748]\n",
      "Iteration: 3.0 | Score: [-0.8393856883049011, 4.104382038116455]\n",
      "Iteration: 4.0 | Score: [0.003546212799847126, 0.5022553205490112]\n",
      "Iteration: 5.0 | Score: [-0.5477842688560486, 2.932506561279297]\n",
      "Iteration: 6.0 | Score: [0.07112124562263489, 0.1535482406616211]\n",
      "Iteration: 7.0 | Score: [-0.43113279342651367, 2.4387335777282715]\n",
      "Iteration: 8.0 | Score: [-0.39227020740509033, 2.2535860538482666]\n",
      "Iteration: 9.0 | Score: [-0.32864731550216675, 1.9523284435272217]\n",
      "Iteration: 10.0 | Score: [-0.4870431125164032, 2.6736717224121094]\n",
      "Iteration: 0.0 | Score: [0.35603827238082886, -1.5383262634277344]\n",
      "Iteration: 1.0 | Score: [-0.14147977530956268, 0.5591117143630981]\n",
      "Iteration: 2.0 | Score: [-0.06063441187143326, 0.25321418046951294]\n",
      "Iteration: 3.0 | Score: [0.12348046898841858, -0.5834398865699768]\n",
      "Iteration: 4.0 | Score: [0.5310724973678589, -2.4558005332946777]\n",
      "Iteration: 5.0 | Score: [0.061166491359472275, -0.2979866862297058]\n",
      "Iteration: 6.0 | Score: [0.1938713639974594, -0.8702888488769531]\n",
      "Iteration: 7.0 | Score: [0.13094061613082886, -0.6413461565971375]\n",
      "Iteration: 8.0 | Score: [0.06687171757221222, -0.343441903591156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9.0 | Score: [0.07291340827941895, -0.3887290954589844]\n",
      "Iteration: 10.0 | Score: [0.15900319814682007, -0.7718372941017151]\n",
      "Iteration: 0.0 | Score: [0.47714194655418396, -2.278228521347046]\n",
      "Iteration: 1.0 | Score: [1.153502345085144, -5.792402267456055]\n",
      "Iteration: 2.0 | Score: [0.03515354543924332, -0.303246408700943]\n",
      "Iteration: 3.0 | Score: [0.8039630055427551, -3.879667043685913]\n",
      "Iteration: 4.0 | Score: [0.1420820951461792, -0.7858402729034424]\n",
      "Iteration: 5.0 | Score: [0.26416417956352234, -1.3398635387420654]\n",
      "Iteration: 6.0 | Score: [0.6211330890655518, -3.0752830505371094]\n",
      "Iteration: 7.0 | Score: [0.050369326025247574, -0.4262453317642212]\n",
      "Iteration: 8.0 | Score: [1.2606319189071655, -6.439657211303711]\n",
      "Iteration: 9.0 | Score: [0.0353107750415802, -0.39871203899383545]\n",
      "Iteration: 10.0 | Score: [0.3273734748363495, -1.698574185371399]\n",
      "alpha:  tensor([0.6471])\n",
      "ols params:  tensor([-0.0287, 12.8165])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.056011226028203964]\n",
      "Iteration: 1.0 | Score: [-0.12690158188343048]\n",
      "Iteration: 2.0 | Score: [-0.08541202545166016]\n",
      "Iteration: 3.0 | Score: [-0.058409690856933594]\n",
      "Iteration: 4.0 | Score: [-0.1691998541355133]\n",
      "Iteration: 5.0 | Score: [-0.13675950467586517]\n",
      "Iteration: 6.0 | Score: [-0.1211855337023735]\n",
      "Iteration: 7.0 | Score: [-0.1172608882188797]\n",
      "Iteration: 8.0 | Score: [-0.1508001685142517]\n",
      "Iteration: 9.0 | Score: [-0.12228648364543915]\n",
      "Iteration: 10.0 | Score: [-0.10251744836568832]\n",
      "Iteration: 0.0 | Score: [-0.11370595544576645, 0.707099199295044]\n",
      "Iteration: 1.0 | Score: [0.05241185054183006, -0.12886875867843628]\n",
      "Iteration: 2.0 | Score: [-0.6868392825126648, 3.412102699279785]\n",
      "Iteration: 3.0 | Score: [-0.03130380064249039, 0.275299072265625]\n",
      "Iteration: 4.0 | Score: [0.1467588096857071, -0.6300439238548279]\n",
      "Iteration: 5.0 | Score: [0.13377782702445984, -0.5908454656600952]\n",
      "Iteration: 6.0 | Score: [-0.42378026247024536, 2.2018096446990967]\n",
      "Iteration: 7.0 | Score: [-0.5390218496322632, 2.744297742843628]\n",
      "Iteration: 8.0 | Score: [-0.4039326012134552, 2.1015610694885254]\n",
      "Iteration: 9.0 | Score: [-0.312090128660202, 1.6279996633529663]\n",
      "Iteration: 10.0 | Score: [-0.17971892654895782, 0.9689722061157227]\n",
      "Iteration: 0.0 | Score: [0.45888662338256836, -2.211322546005249]\n",
      "Iteration: 1.0 | Score: [-4.368763446807861, 9.879344940185547]\n",
      "Iteration: 2.0 | Score: [1.1743175983428955, -6.426070690155029]\n",
      "Iteration: 3.0 | Score: [1.5962578058242798, -8.940303802490234]\n",
      "Iteration: 4.0 | Score: [-1.830672264099121, 5.728370189666748]\n",
      "Iteration: 5.0 | Score: [-0.26422691345214844, 1.2068754434585571]\n",
      "Iteration: 6.0 | Score: [0.08749297261238098, -0.4167380630970001]\n",
      "Iteration: 7.0 | Score: [0.10857754945755005, -0.5163987278938293]\n",
      "Iteration: 8.0 | Score: [1.4112635850906372, -7.608504295349121]\n",
      "Iteration: 9.0 | Score: [-0.22632792592048645, 1.0442171096801758]\n",
      "Iteration: 10.0 | Score: [-0.003449626499786973, 0.0007551312446594238]\n",
      "Logging in: /home/gridsan/stefanou/Regression/AirQuality/73200bf5-0929-4655-8aa0-87de6c55f230\n",
      "alpha:  tensor([1.])\n",
      "ols params:  tensor([-0.0652, 12.7039])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [-0.13909189403057098]\n",
      "Iteration: 1.0 | Score: [-0.11255596578121185]\n",
      "Iteration: 2.0 | Score: [-0.08969905972480774]\n",
      "Iteration: 3.0 | Score: [-0.09300112724304199]\n",
      "Iteration: 4.0 | Score: [-0.13639071583747864]\n",
      "Iteration: 5.0 | Score: [-0.12474162131547928]\n",
      "Iteration: 6.0 | Score: [-0.17515820264816284]\n",
      "Iteration: 7.0 | Score: [-0.1934908628463745]\n",
      "Iteration: 8.0 | Score: [-0.172052800655365]\n",
      "Iteration: 9.0 | Score: [-0.1160440593957901]\n",
      "Iteration: 10.0 | Score: [-0.16469727456569672]\n",
      "Iteration: 0.0 | Score: [0.5421925783157349, -2.038680076599121]\n",
      "Iteration: 1.0 | Score: [0.14537490904331207, -0.4612028896808624]\n",
      "Iteration: 2.0 | Score: [0.35147038102149963, -1.2025277614593506]\n",
      "Iteration: 3.0 | Score: [1.191457748413086, -4.626808166503906]\n",
      "Iteration: 4.0 | Score: [0.36288416385650635, -1.3206167221069336]\n",
      "Iteration: 5.0 | Score: [0.35849207639694214, -1.313880443572998]\n",
      "Iteration: 6.0 | Score: [0.33870118856430054, -1.2377574443817139]\n",
      "Iteration: 7.0 | Score: [0.747117280960083, -2.7723805904388428]\n",
      "Iteration: 8.0 | Score: [0.4257839024066925, -1.5555375814437866]\n",
      "Iteration: 9.0 | Score: [0.44289273023605347, -1.6046168804168701]\n",
      "Iteration: 10.0 | Score: [0.801543116569519, -3.0186636447906494]\n",
      "Iteration: 0.0 | Score: [-0.5210781097412109, 1.950866460800171]\n",
      "Iteration: 1.0 | Score: [-0.5572655200958252, 2.179583787918091]\n",
      "Iteration: 2.0 | Score: [-0.5604987740516663, 2.171501636505127]\n",
      "Iteration: 3.0 | Score: [-0.6757836937904358, 2.538388252258301]\n",
      "Iteration: 4.0 | Score: [-0.5694637894630432, 2.196026086807251]\n",
      "Iteration: 5.0 | Score: [-0.36618098616600037, 1.3964043855667114]\n",
      "Iteration: 6.0 | Score: [0.14991584420204163, -0.7527930736541748]\n",
      "Iteration: 7.0 | Score: [-0.7477192878723145, 2.752359390258789]\n",
      "Iteration: 8.0 | Score: [-0.5986188650131226, 2.2443854808807373]\n",
      "Iteration: 9.0 | Score: [-0.5096338391304016, 1.901304006576538]\n",
      "Iteration: 10.0 | Score: [-0.6349362730979919, 2.385197401046753]\n",
      "Iteration: 0.0 | Score: [0.4479169547557831, -1.5856255292892456]\n",
      "Iteration: 1.0 | Score: [1.2300792932510376, -4.569495677947998]\n",
      "Iteration: 2.0 | Score: [0.41633686423301697, -1.4159122705459595]\n",
      "Iteration: 3.0 | Score: [0.2366865873336792, -0.8393734693527222]\n",
      "Iteration: 4.0 | Score: [0.2940463721752167, -1.0481412410736084]\n",
      "Iteration: 5.0 | Score: [0.2630157172679901, -0.9393510222434998]\n",
      "Iteration: 6.0 | Score: [1.0454615354537964, -3.904831647872925]\n",
      "Iteration: 7.0 | Score: [0.08914418518543243, -0.4083172678947449]\n",
      "Iteration: 8.0 | Score: [0.7077613472938538, -2.5925207138061523]\n",
      "Iteration: 9.0 | Score: [0.5593953728675842, -1.9955875873565674]\n",
      "Iteration: 10.0 | Score: [0.30403050780296326, -1.086042046546936]\n",
      "alpha:  tensor([0.9935])\n",
      "ols params:  tensor([-0.0652, 12.7582])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.32492780685424805]\n",
      "Iteration: 1.0 | Score: [0.3884936273097992]\n",
      "Iteration: 2.0 | Score: [0.3463660180568695]\n",
      "Iteration: 3.0 | Score: [0.29246342182159424]\n",
      "Iteration: 4.0 | Score: [0.29051071405410767]\n",
      "Iteration: 5.0 | Score: [0.28254419565200806]\n",
      "Iteration: 6.0 | Score: [0.33267679810523987]\n",
      "Iteration: 7.0 | Score: [0.3139861524105072]\n",
      "Iteration: 8.0 | Score: [0.319778174161911]\n",
      "Iteration: 9.0 | Score: [0.35373952984809875]\n",
      "Iteration: 10.0 | Score: [0.3225381374359131]\n",
      "Iteration: 0.0 | Score: [0.055811066180467606]\n",
      "Iteration: 1.0 | Score: [0.11513414978981018]\n",
      "Iteration: 2.0 | Score: [0.06127248704433441]\n",
      "Iteration: 3.0 | Score: [0.15124735236167908]\n",
      "Iteration: 4.0 | Score: [0.05658179149031639]\n",
      "Iteration: 5.0 | Score: [0.12168066948652267]\n",
      "Iteration: 6.0 | Score: [0.06713643670082092]\n",
      "Iteration: 7.0 | Score: [0.12237726151943207]\n",
      "Iteration: 8.0 | Score: [0.0970446988940239]\n",
      "Iteration: 9.0 | Score: [0.07532162964344025]\n",
      "Iteration: 10.0 | Score: [0.1367705911397934]\n",
      "Iteration: 0.0 | Score: [-0.018826181069016457, -0.008553892374038696]\n",
      "Iteration: 1.0 | Score: [-0.829690158367157, 2.6957597732543945]\n",
      "Iteration: 2.0 | Score: [0.1651291400194168, -0.7111674547195435]\n",
      "Iteration: 3.0 | Score: [-0.3234349489212036, 1.0920448303222656]\n",
      "Iteration: 4.0 | Score: [-0.057592831552028656, 0.1255532205104828]\n",
      "Iteration: 5.0 | Score: [0.3567124605178833, -1.4546245336532593]\n",
      "Iteration: 6.0 | Score: [-0.08095136284828186, 0.2598741352558136]\n",
      "Iteration: 7.0 | Score: [0.12723417580127716, -0.5900787711143494]\n",
      "Iteration: 8.0 | Score: [-0.3412753939628601, 1.1115846633911133]\n",
      "Iteration: 9.0 | Score: [-0.049272727221250534, 0.07161635160446167]\n",
      "Iteration: 10.0 | Score: [-0.2311464548110962, 0.6964024901390076]\n",
      "Iteration: 0.0 | Score: [0.041640836745500565, -0.3572899103164673]\n",
      "Iteration: 1.0 | Score: [-0.24994786083698273, 0.7822301387786865]\n",
      "Iteration: 2.0 | Score: [0.22267353534698486, -1.0590221881866455]\n",
      "Iteration: 3.0 | Score: [0.22052422165870667, -1.0753940343856812]\n",
      "Iteration: 4.0 | Score: [-0.04825757071375847, -0.020095601677894592]\n",
      "Iteration: 5.0 | Score: [-0.06407324969768524, 0.023913726210594177]\n",
      "Iteration: 6.0 | Score: [-0.06143689900636673, -0.017490282654762268]\n",
      "Iteration: 7.0 | Score: [-0.29984399676322937, 0.8798138499259949]\n",
      "Iteration: 8.0 | Score: [-0.27595770359039307, 0.7579998970031738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9.0 | Score: [0.07509661465883255, -0.5197127461433411]\n",
      "Iteration: 10.0 | Score: [0.28773462772369385, -1.4082082509994507]\n",
      "Iteration: 0.0 | Score: [0.10522333532571793, -0.1752428412437439]\n",
      "Iteration: 1.0 | Score: [-0.3264314532279968, 1.3203375339508057]\n",
      "Iteration: 2.0 | Score: [-0.07241564244031906, 0.45527225732803345]\n",
      "Iteration: 3.0 | Score: [0.476922869682312, -1.5777268409729004]\n",
      "Iteration: 4.0 | Score: [0.7415906190872192, -2.6766510009765625]\n",
      "Iteration: 5.0 | Score: [0.214742049574852, -0.5955715179443359]\n",
      "Iteration: 6.0 | Score: [-0.09245432913303375, 0.4929364025592804]\n",
      "Iteration: 7.0 | Score: [0.146145761013031, -0.3501329720020294]\n",
      "Iteration: 8.0 | Score: [-0.285611093044281, 1.1273788213729858]\n",
      "Iteration: 9.0 | Score: [-0.11512543261051178, 0.5783102512359619]\n",
      "Iteration: 10.0 | Score: [0.2653828263282776, -0.8171193599700928]\n",
      "alpha:  tensor([0.9869])\n",
      "ols params:  tensor([-0.0634, 12.7028])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.45951470732688904]\n",
      "Iteration: 1.0 | Score: [0.4490930140018463]\n",
      "Iteration: 2.0 | Score: [0.4229462742805481]\n",
      "Iteration: 3.0 | Score: [0.39541712403297424]\n",
      "Iteration: 4.0 | Score: [0.4025954008102417]\n",
      "Iteration: 5.0 | Score: [0.39948540925979614]\n",
      "Iteration: 6.0 | Score: [0.4221567213535309]\n",
      "Iteration: 7.0 | Score: [0.4240591526031494]\n",
      "Iteration: 8.0 | Score: [0.4430944621562958]\n",
      "Iteration: 9.0 | Score: [0.39673885703086853]\n",
      "Iteration: 10.0 | Score: [0.4072912931442261]\n",
      "Iteration: 0.0 | Score: [-0.07755422592163086]\n",
      "Iteration: 1.0 | Score: [-0.15669991075992584]\n",
      "Iteration: 2.0 | Score: [-0.030391622334718704]\n",
      "Iteration: 3.0 | Score: [-0.10116768628358841]\n",
      "Iteration: 4.0 | Score: [-0.10033728182315826]\n",
      "Iteration: 5.0 | Score: [-0.12809157371520996]\n",
      "Iteration: 6.0 | Score: [-0.12010392546653748]\n",
      "Iteration: 7.0 | Score: [-0.1266685277223587]\n",
      "Iteration: 8.0 | Score: [-0.11543068289756775]\n",
      "Iteration: 9.0 | Score: [-0.07758063077926636]\n",
      "Iteration: 10.0 | Score: [-0.14282816648483276]\n",
      "Iteration: 0.0 | Score: [0.0585082583129406, -0.3202558755874634]\n",
      "Iteration: 1.0 | Score: [0.0640294998884201, -0.2808373272418976]\n",
      "Iteration: 2.0 | Score: [-0.5148767828941345, 1.7507517337799072]\n",
      "Iteration: 3.0 | Score: [-0.48969224095344543, 1.6721947193145752]\n",
      "Iteration: 4.0 | Score: [-0.22886620461940765, 0.7897824048995972]\n",
      "Iteration: 5.0 | Score: [0.26316678524017334, -1.0820984840393066]\n",
      "Iteration: 6.0 | Score: [-0.023883305490016937, 0.03412577509880066]\n",
      "Iteration: 7.0 | Score: [0.19524449110031128, -0.833771824836731]\n",
      "Iteration: 8.0 | Score: [-0.018975693732500076, -0.030749619007110596]\n",
      "Iteration: 9.0 | Score: [-0.27101629972457886, 0.91458660364151]\n",
      "Iteration: 10.0 | Score: [-0.38224196434020996, 1.2858786582946777]\n",
      "Iteration: 0.0 | Score: [-0.2958894670009613, 1.1377480030059814]\n",
      "Iteration: 1.0 | Score: [-0.3677256107330322, 1.4620925188064575]\n",
      "Iteration: 2.0 | Score: [-0.3222416937351227, 1.2453291416168213]\n",
      "Iteration: 3.0 | Score: [-0.4835243821144104, 1.8128547668457031]\n",
      "Iteration: 4.0 | Score: [-0.22542792558670044, 0.8458698987960815]\n",
      "Iteration: 5.0 | Score: [-0.44645535945892334, 1.6931536197662354]\n",
      "Iteration: 6.0 | Score: [-0.4131019711494446, 1.533981204032898]\n",
      "Iteration: 7.0 | Score: [-0.19353266060352325, 0.7665948271751404]\n",
      "Iteration: 8.0 | Score: [-0.3205326199531555, 1.212287425994873]\n",
      "Iteration: 9.0 | Score: [-0.2886682152748108, 1.0731747150421143]\n",
      "Iteration: 10.0 | Score: [-0.44842809438705444, 1.6879419088363647]\n",
      "Iteration: 0.0 | Score: [-0.038343239575624466, 0.19835320115089417]\n",
      "Iteration: 1.0 | Score: [0.02540721744298935, 0.008792278356850147]\n",
      "Iteration: 2.0 | Score: [-0.5111592411994934, 1.8442823886871338]\n",
      "Iteration: 3.0 | Score: [-0.3590254783630371, 1.3310542106628418]\n",
      "Iteration: 4.0 | Score: [0.2774336040019989, -1.0296306610107422]\n",
      "Iteration: 5.0 | Score: [-0.1716892421245575, 0.6720236539840698]\n",
      "Iteration: 6.0 | Score: [-0.2928437292575836, 1.097785234451294]\n",
      "Iteration: 7.0 | Score: [0.09947583824396133, -0.32734107971191406]\n",
      "Iteration: 8.0 | Score: [0.028497088700532913, -0.08518374711275101]\n",
      "Iteration: 9.0 | Score: [-0.024125752970576286, 0.13598096370697021]\n",
      "Iteration: 10.0 | Score: [-0.21785205602645874, 0.8358578681945801]\n",
      "alpha:  tensor([0.9804])\n",
      "ols params:  tensor([-0.0620, 12.6797])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.4988458752632141]\n",
      "Iteration: 1.0 | Score: [0.4288235902786255]\n",
      "Iteration: 2.0 | Score: [0.4836950898170471]\n",
      "Iteration: 3.0 | Score: [0.44056108593940735]\n",
      "Iteration: 4.0 | Score: [0.4298063814640045]\n",
      "Iteration: 5.0 | Score: [0.3819506764411926]\n",
      "Iteration: 6.0 | Score: [0.4481017291545868]\n",
      "Iteration: 7.0 | Score: [0.48152443766593933]\n",
      "Iteration: 8.0 | Score: [0.4458838999271393]\n",
      "Iteration: 9.0 | Score: [0.4589066207408905]\n",
      "Iteration: 10.0 | Score: [0.41949623823165894]\n",
      "Iteration: 0.0 | Score: [0.09723145514726639]\n",
      "Iteration: 1.0 | Score: [0.09837165474891663]\n",
      "Iteration: 2.0 | Score: [0.01510322093963623]\n",
      "Iteration: 3.0 | Score: [0.01936822384595871]\n",
      "Iteration: 4.0 | Score: [0.043134428560733795]\n",
      "Iteration: 5.0 | Score: [0.04100269824266434]\n",
      "Iteration: 6.0 | Score: [0.10205833613872528]\n",
      "Iteration: 7.0 | Score: [0.0491304025053978]\n",
      "Iteration: 8.0 | Score: [0.04425752907991409]\n",
      "Iteration: 9.0 | Score: [0.08807168900966644]\n",
      "Iteration: 10.0 | Score: [0.05500601977109909]\n",
      "Iteration: 0.0 | Score: [-0.14158006012439728, 0.5284000635147095]\n",
      "Iteration: 1.0 | Score: [-0.049008410423994064, 0.3000154197216034]\n",
      "Iteration: 2.0 | Score: [-0.3476788103580475, 1.3991745710372925]\n",
      "Iteration: 3.0 | Score: [-0.389934241771698, 1.5690417289733887]\n",
      "Iteration: 4.0 | Score: [-0.20915155112743378, 0.8576570749282837]\n",
      "Iteration: 5.0 | Score: [-0.3080572485923767, 1.2112646102905273]\n",
      "Iteration: 6.0 | Score: [-0.3069627583026886, 1.2023591995239258]\n",
      "Iteration: 7.0 | Score: [0.6202166676521301, -2.6304218769073486]\n",
      "Iteration: 8.0 | Score: [0.07512133568525314, -0.30040574073791504]\n",
      "Iteration: 9.0 | Score: [-0.10025504976511002, 0.41153812408447266]\n",
      "Iteration: 10.0 | Score: [-0.3523326516151428, 1.335605502128601]\n",
      "Iteration: 0.0 | Score: [-0.20703580975532532, 1.249498963356018]\n",
      "Iteration: 1.0 | Score: [-0.1324736475944519, 1.040231466293335]\n",
      "Iteration: 2.0 | Score: [-0.44109418988227844, 2.103405237197876]\n",
      "Iteration: 3.0 | Score: [-0.583849310874939, 2.6009633541107178]\n",
      "Iteration: 4.0 | Score: [-0.5154727697372437, 2.366666793823242]\n",
      "Iteration: 5.0 | Score: [0.21881833672523499, -0.4012332558631897]\n",
      "Iteration: 6.0 | Score: [-0.3589900732040405, 1.7584834098815918]\n",
      "Iteration: 7.0 | Score: [-0.3402062654495239, 1.7112747430801392]\n",
      "Iteration: 8.0 | Score: [-0.29220274090766907, 1.5724931955337524]\n",
      "Iteration: 9.0 | Score: [-0.30030009150505066, 1.5885902643203735]\n",
      "Iteration: 10.0 | Score: [-0.4062614440917969, 1.905650019645691]\n",
      "Iteration: 0.0 | Score: [-0.39057981967926025, 1.5296214818954468]\n",
      "Iteration: 1.0 | Score: [-0.8095211982727051, 2.970524311065674]\n",
      "Iteration: 2.0 | Score: [-0.33314940333366394, 1.3188098669052124]\n",
      "Iteration: 3.0 | Score: [0.00969552993774414, -0.11561504006385803]\n",
      "Iteration: 4.0 | Score: [-0.5768042206764221, 2.1910736560821533]\n",
      "Iteration: 5.0 | Score: [-0.41184017062187195, 1.5178027153015137]\n",
      "Iteration: 6.0 | Score: [-0.4211082458496094, 1.5327810049057007]\n",
      "Iteration: 7.0 | Score: [-0.48207753896713257, 1.7205567359924316]\n",
      "Iteration: 8.0 | Score: [-0.7115160226821899, 2.632910966873169]\n",
      "Iteration: 9.0 | Score: [-0.40617483854293823, 1.4888399839401245]\n",
      "Iteration: 10.0 | Score: [-0.15538530051708221, 0.5458822250366211]\n",
      "alpha:  tensor([0.9739])\n",
      "ols params:  tensor([-0.0634, 12.7296])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [-0.002214089035987854]\n",
      "Iteration: 1.0 | Score: [-0.10577026009559631]\n",
      "Iteration: 2.0 | Score: [-0.039293691515922546]\n",
      "Iteration: 3.0 | Score: [-0.07612068206071854]\n",
      "Iteration: 4.0 | Score: [-0.054083578288555145]\n",
      "Iteration: 5.0 | Score: [-0.11678502708673477]\n",
      "Iteration: 6.0 | Score: [-0.08588224649429321]\n",
      "Iteration: 7.0 | Score: [-0.10274484008550644]\n",
      "Iteration: 8.0 | Score: [-0.08919656276702881]\n",
      "Iteration: 9.0 | Score: [-0.12812811136245728]\n",
      "Iteration: 10.0 | Score: [-0.13561874628067017]\n",
      "Iteration: 0.0 | Score: [0.20764613151550293, -0.7255950570106506]\n",
      "Iteration: 1.0 | Score: [-0.3097338080406189, 1.2399680614471436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2.0 | Score: [-0.27384042739868164, 1.0958284139633179]\n",
      "Iteration: 3.0 | Score: [0.5657801628112793, -2.0854618549346924]\n",
      "Iteration: 4.0 | Score: [1.060267448425293, -4.319414138793945]\n",
      "Iteration: 5.0 | Score: [0.5895907878875732, -2.258544445037842]\n",
      "Iteration: 6.0 | Score: [0.0014954351354390383, 0.09465604275465012]\n",
      "Iteration: 7.0 | Score: [0.22861815989017487, -0.75963294506073]\n",
      "Iteration: 8.0 | Score: [-0.12726342678070068, 0.5347368717193604]\n",
      "Iteration: 9.0 | Score: [-0.20697133243083954, 0.8449057340621948]\n",
      "Iteration: 10.0 | Score: [0.21673233807086945, -0.7680527567863464]\n",
      "Iteration: 0.0 | Score: [0.31841740012168884, -1.2106982469558716]\n",
      "Iteration: 1.0 | Score: [0.2147253006696701, -0.7237493991851807]\n",
      "Iteration: 2.0 | Score: [0.10293208062648773, -0.3162018954753876]\n",
      "Iteration: 3.0 | Score: [1.3877564668655396, -5.987754821777344]\n",
      "Iteration: 4.0 | Score: [0.0897204652428627, -0.2803143560886383]\n",
      "Iteration: 5.0 | Score: [0.021271899342536926, -0.015469253063201904]\n",
      "Iteration: 6.0 | Score: [-0.07687532156705856, 0.31653663516044617]\n",
      "Iteration: 7.0 | Score: [-0.0019883986096829176, 0.03439682722091675]\n",
      "Iteration: 8.0 | Score: [0.16101744771003723, -0.5855040550231934]\n",
      "Iteration: 9.0 | Score: [0.4084911346435547, -1.570784568786621]\n",
      "Iteration: 10.0 | Score: [1.0495692491531372, -4.480221748352051]\n",
      "alpha:  tensor([0.9673])\n",
      "ols params:  tensor([-0.0626, 12.7023])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.3166108727455139]\n",
      "Iteration: 1.0 | Score: [0.18713289499282837]\n",
      "Iteration: 2.0 | Score: [0.16285564005374908]\n",
      "Iteration: 3.0 | Score: [0.17520563304424286]\n",
      "Iteration: 4.0 | Score: [0.21098677814006805]\n",
      "Iteration: 5.0 | Score: [0.21246664226055145]\n",
      "Iteration: 6.0 | Score: [0.21488697826862335]\n",
      "Iteration: 7.0 | Score: [0.14340974390506744]\n",
      "Iteration: 8.0 | Score: [0.13473713397979736]\n",
      "Iteration: 9.0 | Score: [0.1678106188774109]\n",
      "Iteration: 10.0 | Score: [0.1985204666852951]\n",
      "Iteration: 0.0 | Score: [-0.1034918799996376, 0.778827428817749]\n",
      "Iteration: 1.0 | Score: [-0.2874835431575775, 1.4724552631378174]\n",
      "Iteration: 2.0 | Score: [0.3319042921066284, -0.9483780264854431]\n",
      "Iteration: 3.0 | Score: [-0.5587536692619324, 2.3468964099884033]\n",
      "Iteration: 4.0 | Score: [-0.2885294556617737, 1.4180731773376465]\n",
      "Iteration: 5.0 | Score: [-0.04881177470088005, 0.4965576231479645]\n",
      "Iteration: 6.0 | Score: [-0.1754942238330841, 1.0088634490966797]\n",
      "Iteration: 7.0 | Score: [-0.41321635246276855, 1.8555371761322021]\n",
      "Iteration: 8.0 | Score: [-0.2895949184894562, 1.4107457399368286]\n",
      "Iteration: 9.0 | Score: [-0.08659548312425613, 0.6616936922073364]\n",
      "Iteration: 10.0 | Score: [-0.42886677384376526, 1.908963918685913]\n",
      "Iteration: 0.0 | Score: [-0.27417922019958496, 1.2710011005401611]\n",
      "Iteration: 1.0 | Score: [-0.5655321478843689, 2.3745813369750977]\n",
      "Iteration: 2.0 | Score: [-0.5489708781242371, 2.28324556350708]\n",
      "Iteration: 3.0 | Score: [0.31374943256378174, -1.1632717847824097]\n",
      "Iteration: 4.0 | Score: [0.09901722520589828, -0.30478551983833313]\n",
      "Iteration: 5.0 | Score: [-0.1912321001291275, 0.9254970550537109]\n",
      "Iteration: 6.0 | Score: [-0.2608843147754669, 1.178302526473999]\n",
      "Iteration: 7.0 | Score: [0.2910272181034088, -1.1486449241638184]\n",
      "Iteration: 8.0 | Score: [-0.3756448030471802, 1.6447842121124268]\n",
      "Iteration: 9.0 | Score: [-0.4609512686729431, 1.9612748622894287]\n",
      "Iteration: 10.0 | Score: [0.016238955780863762, 0.026348352432250977]\n",
      "alpha:  tensor([0.9346])\n",
      "ols params:  tensor([-0.0581, 12.6402])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.03595669940114021]\n",
      "Iteration: 1.0 | Score: [-0.11014662683010101]\n",
      "Iteration: 2.0 | Score: [-0.05789487063884735]\n",
      "Iteration: 3.0 | Score: [-0.060742657631635666]\n",
      "Iteration: 4.0 | Score: [-0.08122105896472931]\n",
      "Iteration: 5.0 | Score: [-0.07337360084056854]\n",
      "Iteration: 6.0 | Score: [-0.0645093098282814]\n",
      "Iteration: 7.0 | Score: [-0.11745844781398773]\n",
      "Iteration: 8.0 | Score: [-0.0879005566239357]\n",
      "Iteration: 9.0 | Score: [-0.10621193051338196]\n",
      "Iteration: 10.0 | Score: [-0.10909882187843323]\n",
      "Iteration: 0.0 | Score: [0.2782939076423645, -0.9803182482719421]\n",
      "Iteration: 1.0 | Score: [-0.20231975615024567, 0.8413428664207458]\n",
      "Iteration: 2.0 | Score: [0.4621768593788147, -1.6911838054656982]\n",
      "Iteration: 3.0 | Score: [0.41538968682289124, -1.5322548151016235]\n",
      "Iteration: 4.0 | Score: [-0.21827375888824463, 0.8667867183685303]\n",
      "Iteration: 5.0 | Score: [0.2073211669921875, -0.6995229125022888]\n",
      "Iteration: 6.0 | Score: [0.9812319874763489, -4.071909427642822]\n",
      "Iteration: 7.0 | Score: [0.1204785406589508, -0.35839271545410156]\n",
      "Iteration: 8.0 | Score: [0.020834118127822876, -0.043681636452674866]\n",
      "Iteration: 9.0 | Score: [0.3579884171485901, -1.3237643241882324]\n",
      "Iteration: 10.0 | Score: [0.08458773046731949, -0.24922983348369598]\n",
      "Iteration: 0.0 | Score: [0.05735274776816368, -0.2541823387145996]\n",
      "Iteration: 1.0 | Score: [-0.21381881833076477, 0.8082065582275391]\n",
      "Iteration: 2.0 | Score: [0.766278088092804, -3.4219446182250977]\n",
      "Iteration: 3.0 | Score: [-0.6182695627212524, 2.249819040298462]\n",
      "Iteration: 4.0 | Score: [0.10386639833450317, -0.48106634616851807]\n",
      "Iteration: 5.0 | Score: [0.5629156827926636, -2.5350985527038574]\n",
      "Iteration: 6.0 | Score: [-0.3645499646663666, 1.3375293016433716]\n",
      "Iteration: 7.0 | Score: [-0.1130138710141182, 0.37514424324035645]\n",
      "Iteration: 8.0 | Score: [0.15009312331676483, -0.7286074161529541]\n",
      "Iteration: 9.0 | Score: [-0.04728580266237259, 0.10669392347335815]\n",
      "Iteration: 10.0 | Score: [0.11015942692756653, -0.5610105395317078]\n",
      "alpha:  tensor([0.8954])\n",
      "ols params:  tensor([-0.0508, 12.4823])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [-0.550122082233429]\n",
      "Iteration: 1.0 | Score: [-0.6238609552383423]\n",
      "Iteration: 2.0 | Score: [-0.6690084934234619]\n",
      "Iteration: 3.0 | Score: [-0.7241290807723999]\n",
      "Iteration: 4.0 | Score: [-0.6622706055641174]\n",
      "Iteration: 5.0 | Score: [-0.6895275712013245]\n",
      "Iteration: 6.0 | Score: [-0.6611045002937317]\n",
      "Iteration: 7.0 | Score: [-0.675537109375]\n",
      "Iteration: 8.0 | Score: [-0.6864936351776123]\n",
      "Iteration: 9.0 | Score: [-0.6679127216339111]\n",
      "Iteration: 10.0 | Score: [-0.6512476801872253]\n",
      "Iteration: 0.0 | Score: [0.5115619897842407]\n",
      "Iteration: 1.0 | Score: [0.3831477463245392]\n",
      "Iteration: 2.0 | Score: [0.3755781650543213]\n",
      "Iteration: 3.0 | Score: [0.34069308638572693]\n",
      "Iteration: 4.0 | Score: [0.3689964711666107]\n",
      "Iteration: 5.0 | Score: [0.38651007413864136]\n",
      "Iteration: 6.0 | Score: [0.3958706855773926]\n",
      "Iteration: 7.0 | Score: [0.32159489393234253]\n",
      "Iteration: 8.0 | Score: [0.3329726457595825]\n",
      "Iteration: 9.0 | Score: [0.3557932674884796]\n",
      "Iteration: 10.0 | Score: [0.3468128740787506]\n",
      "Iteration: 0.0 | Score: [0.46290796995162964]\n",
      "Iteration: 1.0 | Score: [0.34468966722488403]\n",
      "Iteration: 2.0 | Score: [0.397890567779541]\n",
      "Iteration: 3.0 | Score: [0.40005233883857727]\n",
      "Iteration: 4.0 | Score: [0.3555279076099396]\n",
      "Iteration: 5.0 | Score: [0.41287535429000854]\n",
      "Iteration: 6.0 | Score: [0.38469767570495605]\n",
      "Iteration: 7.0 | Score: [0.42142292857170105]\n",
      "Iteration: 8.0 | Score: [0.3547073304653168]\n",
      "Iteration: 9.0 | Score: [0.3827008903026581]\n",
      "Iteration: 10.0 | Score: [0.345215380191803]\n",
      "Iteration: 0.0 | Score: [-0.09489202499389648, 0.1406306028366089]\n",
      "Iteration: 1.0 | Score: [0.011643464677035809, -0.22077268362045288]\n",
      "Iteration: 2.0 | Score: [-0.037828266620635986, -0.06711506843566895]\n",
      "Iteration: 3.0 | Score: [-0.43555590510368347, 1.5430049896240234]\n",
      "Iteration: 4.0 | Score: [-0.04329720884561539, -0.0663311779499054]\n",
      "Iteration: 5.0 | Score: [-0.25876104831695557, 0.8390040397644043]\n",
      "Iteration: 6.0 | Score: [0.5885789394378662, -3.0007972717285156]\n",
      "Iteration: 7.0 | Score: [-0.24136057496070862, 0.7361432313919067]\n",
      "Iteration: 8.0 | Score: [-0.22975978255271912, 0.6823062896728516]\n",
      "Iteration: 9.0 | Score: [-0.16155941784381866, 0.39211606979370117]\n",
      "Iteration: 10.0 | Score: [-0.3295503854751587, 1.047762393951416]\n",
      "Iteration: 0.0 | Score: [-0.09749707579612732, 0.4278733432292938]\n",
      "Iteration: 1.0 | Score: [-0.1574995070695877, 0.6784038543701172]\n",
      "Iteration: 2.0 | Score: [-0.4697449803352356, 1.897495150566101]\n",
      "Iteration: 3.0 | Score: [0.05814146250486374, -0.2688785195350647]\n",
      "Iteration: 4.0 | Score: [0.15124446153640747, -0.6981198787689209]\n",
      "Iteration: 5.0 | Score: [-0.3147961497306824, 1.2606346607208252]\n",
      "Iteration: 6.0 | Score: [-0.25294384360313416, 1.0161762237548828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7.0 | Score: [-0.13055413961410522, 0.5088134407997131]\n",
      "Iteration: 8.0 | Score: [-0.17788071930408478, 0.693107545375824]\n",
      "Iteration: 9.0 | Score: [-0.197219118475914, 0.786125659942627]\n",
      "Iteration: 10.0 | Score: [0.22852091491222382, -1.0125045776367188]\n",
      "Iteration: 0.0 | Score: [0.7666804790496826, -2.8252274990081787]\n",
      "Iteration: 1.0 | Score: [0.07885836809873581, -0.1686730682849884]\n",
      "Iteration: 2.0 | Score: [0.5762961506843567, -2.036428451538086]\n",
      "Iteration: 3.0 | Score: [0.5095050930976868, -1.7701834440231323]\n",
      "Iteration: 4.0 | Score: [0.4614718556404114, -1.599128246307373]\n",
      "Iteration: 5.0 | Score: [0.4683491587638855, -1.6293741464614868]\n",
      "Iteration: 6.0 | Score: [1.3772670030593872, -5.675268173217773]\n",
      "Iteration: 7.0 | Score: [0.46671420335769653, -1.6578503847122192]\n",
      "Iteration: 8.0 | Score: [0.763719916343689, -2.8526406288146973]\n",
      "Iteration: 9.0 | Score: [0.5359848141670227, -1.9079339504241943]\n",
      "Iteration: 10.0 | Score: [0.6847978234291077, -2.5557610988616943]\n",
      "alpha:  tensor([0.8431])\n",
      "ols params:  tensor([-0.0432, 12.4028])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.030027076601982117]\n",
      "Iteration: 1.0 | Score: [-0.12390115857124329]\n",
      "Iteration: 2.0 | Score: [-0.06488355994224548]\n",
      "Iteration: 3.0 | Score: [-0.123936727643013]\n",
      "Iteration: 4.0 | Score: [-0.12739771604537964]\n",
      "Iteration: 5.0 | Score: [-0.09695544838905334]\n",
      "Iteration: 6.0 | Score: [-0.10490082204341888]\n",
      "Iteration: 7.0 | Score: [-0.11734835058450699]\n",
      "Iteration: 8.0 | Score: [-0.08736801892518997]\n",
      "Iteration: 9.0 | Score: [-0.12102164328098297]\n",
      "Iteration: 10.0 | Score: [-0.05037321150302887]\n",
      "Iteration: 0.0 | Score: [0.010908995755016804, 0.11734376847743988]\n",
      "Iteration: 1.0 | Score: [-0.19748921692371368, 0.97060227394104]\n",
      "Iteration: 2.0 | Score: [-0.5179188847541809, 2.194605588912964]\n",
      "Iteration: 3.0 | Score: [-0.3931061625480652, 1.7552759647369385]\n",
      "Iteration: 4.0 | Score: [-0.05822375789284706, 0.3523756265640259]\n",
      "Iteration: 5.0 | Score: [-0.3467414975166321, 1.5514791011810303]\n",
      "Iteration: 6.0 | Score: [-0.3940054178237915, 1.7280688285827637]\n",
      "Iteration: 7.0 | Score: [-0.08560283482074738, 0.45724165439605713]\n",
      "Iteration: 8.0 | Score: [-0.2376202642917633, 1.1040383577346802]\n",
      "Iteration: 9.0 | Score: [-0.36759182810783386, 1.617883563041687]\n",
      "Iteration: 10.0 | Score: [-0.023527495563030243, 0.17019981145858765]\n",
      "Iteration: 0.0 | Score: [0.3618631064891815, -1.217444658279419]\n",
      "Iteration: 1.0 | Score: [0.3790438771247864, -1.3149107694625854]\n",
      "Iteration: 2.0 | Score: [0.30674439668655396, -1.0401091575622559]\n",
      "Iteration: 3.0 | Score: [0.5874825716018677, -2.2859113216400146]\n",
      "Iteration: 4.0 | Score: [0.2653322219848633, -0.9000253677368164]\n",
      "Iteration: 5.0 | Score: [0.20759731531143188, -0.6160987019538879]\n",
      "Iteration: 6.0 | Score: [0.42467403411865234, -1.6204899549484253]\n",
      "Iteration: 7.0 | Score: [0.23844504356384277, -0.7929734587669373]\n",
      "Iteration: 8.0 | Score: [0.12655790150165558, -0.32407838106155396]\n",
      "Iteration: 9.0 | Score: [0.27605879306793213, -0.9365789890289307]\n",
      "Iteration: 10.0 | Score: [0.23454968631267548, -0.8121322393417358]\n",
      "Iteration: 0.0 | Score: [-0.20384591817855835, 1.3216848373413086]\n",
      "Iteration: 1.0 | Score: [-0.4221521317958832, 2.217456817626953]\n",
      "Iteration: 2.0 | Score: [0.309721976518631, -1.0264356136322021]\n",
      "Iteration: 3.0 | Score: [-0.5639433264732361, 2.735429525375366]\n",
      "Iteration: 4.0 | Score: [-0.28534334897994995, 1.6193692684173584]\n",
      "Iteration: 5.0 | Score: [0.15373192727565765, -0.32409876585006714]\n",
      "Iteration: 6.0 | Score: [-0.35761362314224243, 1.909423589706421]\n",
      "Iteration: 7.0 | Score: [-0.3401217460632324, 1.8569929599761963]\n",
      "Iteration: 8.0 | Score: [0.08467430621385574, -0.017908796668052673]\n",
      "Iteration: 9.0 | Score: [-0.2800258994102478, 1.5427879095077515]\n",
      "Iteration: 10.0 | Score: [-0.3699817359447479, 1.9398006200790405]\n",
      "alpha:  tensor([0.7843])\n",
      "ols params:  tensor([-0.0420, 12.6315])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.15753766894340515]\n",
      "Iteration: 1.0 | Score: [-0.05114762485027313]\n",
      "Iteration: 2.0 | Score: [-0.024490147829055786]\n",
      "Iteration: 3.0 | Score: [-0.03571483492851257]\n",
      "Iteration: 4.0 | Score: [-0.057160548865795135]\n",
      "Iteration: 5.0 | Score: [-0.031189389526844025]\n",
      "Iteration: 6.0 | Score: [-0.03188648074865341]\n",
      "Iteration: 7.0 | Score: [-0.061502307653427124]\n",
      "Iteration: 8.0 | Score: [-0.07314091920852661]\n",
      "Iteration: 9.0 | Score: [-0.015165477991104126]\n",
      "Iteration: 10.0 | Score: [-0.1002357006072998]\n",
      "Iteration: 0.0 | Score: [0.3005485534667969, -1.040075421333313]\n",
      "Iteration: 1.0 | Score: [0.2479337900876999, -0.8200583457946777]\n",
      "Iteration: 2.0 | Score: [1.521104335784912, -7.1190619468688965]\n",
      "Iteration: 3.0 | Score: [-0.5683943033218384, 2.3854033946990967]\n",
      "Iteration: 4.0 | Score: [0.08063710480928421, -0.09992969036102295]\n",
      "Iteration: 5.0 | Score: [-0.07346665114164352, 0.5254335403442383]\n",
      "Iteration: 6.0 | Score: [-0.04681844264268875, 0.3832665681838989]\n",
      "Iteration: 7.0 | Score: [0.23681975901126862, -0.7791237831115723]\n",
      "Iteration: 8.0 | Score: [0.001031320309266448, 0.20982101559638977]\n",
      "Iteration: 9.0 | Score: [0.1316833645105362, -0.3573298454284668]\n",
      "Iteration: 10.0 | Score: [0.31222620606422424, -1.1533794403076172]\n",
      "alpha:  tensor([0.6471])\n",
      "ols params:  tensor([-0.0287, 12.8165])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [-0.36512044072151184]\n",
      "Iteration: 1.0 | Score: [-0.5223405361175537]\n",
      "Iteration: 2.0 | Score: [-0.5634313225746155]\n",
      "Iteration: 3.0 | Score: [-0.5920413732528687]\n",
      "Iteration: 4.0 | Score: [-0.57902991771698]\n",
      "Iteration: 5.0 | Score: [-0.59534752368927]\n",
      "Iteration: 6.0 | Score: [-0.568892776966095]\n",
      "Iteration: 7.0 | Score: [-0.5447121858596802]\n",
      "Iteration: 8.0 | Score: [-0.5750275254249573]\n",
      "Iteration: 9.0 | Score: [-0.5486387610435486]\n",
      "Iteration: 10.0 | Score: [-0.49892014265060425]\n",
      "Iteration: 0.0 | Score: [-0.24510735273361206]\n",
      "Iteration: 1.0 | Score: [-0.5098346471786499]\n",
      "Iteration: 2.0 | Score: [-0.4745367169380188]\n",
      "Iteration: 3.0 | Score: [-0.5350337624549866]\n",
      "Iteration: 4.0 | Score: [-0.41944581270217896]\n",
      "Iteration: 5.0 | Score: [-0.44962170720100403]\n",
      "Iteration: 6.0 | Score: [-0.4626910984516144]\n",
      "Iteration: 7.0 | Score: [-0.40707698464393616]\n",
      "Iteration: 8.0 | Score: [-0.39147573709487915]\n",
      "Iteration: 9.0 | Score: [-0.4685356020927429]\n",
      "Iteration: 10.0 | Score: [-0.41361111402511597]\n",
      "Iteration: 0.0 | Score: [0.22858476638793945]\n",
      "Iteration: 1.0 | Score: [0.04816476255655289]\n",
      "Iteration: 2.0 | Score: [0.022961899638175964]\n",
      "Iteration: 3.0 | Score: [0.019589148461818695]\n",
      "Iteration: 4.0 | Score: [0.030843302607536316]\n",
      "Iteration: 5.0 | Score: [0.021267540752887726]\n",
      "Iteration: 6.0 | Score: [0.05634823814034462]\n",
      "Iteration: 7.0 | Score: [0.06454747915267944]\n",
      "Iteration: 8.0 | Score: [-0.006542965769767761]\n",
      "Iteration: 0.0 | Score: [-0.27524131536483765, 1.3426649570465088]\n",
      "Iteration: 1.0 | Score: [-0.8012521266937256, 3.7698261737823486]\n",
      "Iteration: 2.0 | Score: [-0.262935072183609, 1.2548677921295166]\n",
      "Iteration: 3.0 | Score: [-0.4915529787540436, 2.3754873275756836]\n",
      "Iteration: 4.0 | Score: [0.4026428163051605, -2.2503554821014404]\n",
      "Iteration: 5.0 | Score: [-0.8237881660461426, 3.8557088375091553]\n",
      "Iteration: 6.0 | Score: [-0.4289647042751312, 2.021116018295288]\n",
      "Iteration: 7.0 | Score: [-0.3777537941932678, 1.7328275442123413]\n",
      "Iteration: 8.0 | Score: [-0.13184019923210144, 0.5470682382583618]\n",
      "Iteration: 9.0 | Score: [-0.4302254617214203, 2.046260118484497]\n",
      "Iteration: 10.0 | Score: [-0.6338428854942322, 3.011310338973999]\n",
      "Iteration: 0.0 | Score: [0.826535701751709, -3.827604293823242]\n",
      "Iteration: 1.0 | Score: [0.07413377612829208, -0.282182514667511]\n",
      "Iteration: 2.0 | Score: [1.3419626951217651, -6.576792240142822]\n",
      "Iteration: 3.0 | Score: [0.6649447083473206, -2.995312452316284]\n",
      "Iteration: 4.0 | Score: [0.45672640204429626, -2.0091476440429688]\n",
      "Iteration: 5.0 | Score: [0.8199084997177124, -3.800609588623047]\n",
      "Iteration: 6.0 | Score: [0.49411922693252563, -2.2210562229156494]\n",
      "Iteration: 7.0 | Score: [0.4384635090827942, -1.9234243631362915]\n",
      "Iteration: 8.0 | Score: [1.1996010541915894, -5.856634616851807]\n",
      "Iteration: 9.0 | Score: [0.669942319393158, -3.0783839225769043]\n",
      "Iteration: 10.0 | Score: [0.5210952758789062, -2.3571929931640625]\n",
      "Iteration: 0.0 | Score: [0.6655603647232056, -3.1868722438812256]\n",
      "Iteration: 1.0 | Score: [0.0924592912197113, -0.4051872491836548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2.0 | Score: [1.4889674186706543, -7.603610038757324]\n",
      "Iteration: 3.0 | Score: [0.06371485441923141, -0.2723468840122223]\n",
      "Iteration: 4.0 | Score: [1.085697889328003, -5.378842353820801]\n",
      "Iteration: 5.0 | Score: [0.5602835416793823, -2.6285650730133057]\n",
      "Iteration: 6.0 | Score: [0.9216445684432983, -4.498005390167236]\n",
      "Iteration: 7.0 | Score: [-0.0020255574490875006, -0.021338999271392822]\n",
      "Iteration: 8.0 | Score: [0.32531023025512695, -1.5156763792037964]\n",
      "Iteration: 9.0 | Score: [0.4957669973373413, -2.392885684967041]\n",
      "Iteration: 10.0 | Score: [0.3574424684047699, -1.6899820566177368]\n",
      "Logging in: /home/gridsan/stefanou/Regression/AirQuality/df290e52-c227-4e83-a100-17991f89a8cb\n",
      "alpha:  tensor([1.])\n",
      "ols params:  tensor([-0.0652, 12.7039])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.20089736580848694]\n",
      "Iteration: 1.0 | Score: [0.09731356799602509]\n",
      "Iteration: 2.0 | Score: [0.09249716997146606]\n",
      "Iteration: 3.0 | Score: [0.005681954324245453]\n",
      "Iteration: 0.0 | Score: [-0.16894951462745667, 0.8116493821144104]\n",
      "Iteration: 1.0 | Score: [-0.24906623363494873, 1.1669132709503174]\n",
      "Iteration: 2.0 | Score: [0.27045249938964844, -0.7532039284706116]\n",
      "Iteration: 3.0 | Score: [0.5500307083129883, -1.8818942308425903]\n",
      "Iteration: 4.0 | Score: [-0.1481548249721527, 0.7885653376579285]\n",
      "Iteration: 5.0 | Score: [-0.160162553191185, 0.8320597410202026]\n",
      "Iteration: 6.0 | Score: [-0.2963627874851227, 1.2472844123840332]\n",
      "Iteration: 7.0 | Score: [0.06656424701213837, -0.02028181031346321]\n",
      "Iteration: 8.0 | Score: [-0.1784098893404007, 0.8441916704177856]\n",
      "Iteration: 9.0 | Score: [0.008618120104074478, 0.2102707326412201]\n",
      "Iteration: 10.0 | Score: [0.1139288991689682, -0.23173630237579346]\n",
      "alpha:  tensor([0.9935])\n",
      "ols params:  tensor([-0.0652, 12.7582])\n",
      "gt params:  tensor([[-0.0652, 12.7039]])\n",
      "Iteration: 0.0 | Score: [0.38150742650032043]\n",
      "Iteration: 1.0 | Score: [0.35026392340660095]\n",
      "Iteration: 2.0 | Score: [0.34751805663108826]\n",
      "Iteration: 3.0 | Score: [0.29637792706489563]\n",
      "Iteration: 4.0 | Score: [0.33087050914764404]\n",
      "Iteration: 5.0 | Score: [0.3720390200614929]\n",
      "Iteration: 6.0 | Score: [0.32947519421577454]\n",
      "Iteration: 7.0 | Score: [0.30951038002967834]\n",
      "Iteration: 8.0 | Score: [0.3655056357383728]\n",
      "Iteration: 9.0 | Score: [0.3052465617656708]\n",
      "Iteration: 10.0 | Score: [0.31071698665618896]\n",
      "Iteration: 0.0 | Score: [-0.11488503217697144]\n",
      "Iteration: 1.0 | Score: [-0.1670418083667755]\n",
      "Iteration: 2.0 | Score: [-0.13670292496681213]\n",
      "Iteration: 3.0 | Score: [-0.10761917382478714]\n",
      "Iteration: 4.0 | Score: [-0.18467505276203156]\n",
      "Iteration: 5.0 | Score: [-0.14930298924446106]\n",
      "Iteration: 6.0 | Score: [-0.10085786879062653]\n",
      "Iteration: 7.0 | Score: [-0.10915613174438477]\n",
      "Iteration: 8.0 | Score: [-0.25089091062545776]\n",
      "Iteration: 9.0 | Score: [-0.17025306820869446]\n",
      "Iteration: 10.0 | Score: [-0.1467101126909256]\n",
      "Iteration: 0.0 | Score: [0.06027853116393089, -0.2657046318054199]\n",
      "Iteration: 1.0 | Score: [-0.10926323384046555, 0.4194807708263397]\n",
      "Iteration: 2.0 | Score: [0.1595374047756195, -0.6011042594909668]\n",
      "Iteration: 3.0 | Score: [0.15249192714691162, -0.5829188227653503]\n",
      "Iteration: 4.0 | Score: [0.24285826086997986, -0.985242486000061]\n",
      "Iteration: 5.0 | Score: [0.39312589168548584, -1.572397232055664]\n",
      "Iteration: 6.0 | Score: [-0.01547470036894083, 0.03675501048564911]\n",
      "Iteration: 7.0 | Score: [-0.3666938543319702, 1.25896155834198]\n",
      "Iteration: 8.0 | Score: [-0.2561596632003784, 0.8886813521385193]\n",
      "Iteration: 9.0 | Score: [-0.08665858954191208, 0.2728778123855591]\n",
      "Iteration: 10.0 | Score: [0.07959204167127609, -0.3684881925582886]\n",
      "Iteration: 0.0 | Score: [0.25795334577560425, -1.3438928127288818]\n",
      "Iteration: 1.0 | Score: [0.04998553544282913, -0.5278147459030151]\n",
      "Iteration: 2.0 | Score: [0.3596680164337158, -1.783552885055542]\n",
      "Iteration: 3.0 | Score: [0.2521806061267853, -1.3677277565002441]\n",
      "Iteration: 4.0 | Score: [0.024087868630886078, -0.5349788665771484]\n",
      "Iteration: 5.0 | Score: [0.008008417673408985, -0.5129432678222656]\n",
      "Iteration: 6.0 | Score: [0.23220007121562958, -1.3375673294067383]\n",
      "Iteration: 7.0 | Score: [0.1449967920780182, -0.9932762384414673]\n",
      "Iteration: 8.0 | Score: [0.10094062983989716, -0.8210865259170532]\n",
      "Iteration: 9.0 | Score: [0.199940487742424, -1.2705512046813965]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/delphi/delphi/train.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(args, model, loaders, phi, criterion, checkpoint, parallel, cuda, dp_device_ids, store, table, update_params, disable_no_grad)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mtrain_prec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mProcedureComplete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/delphi/delphi/train.py\u001b[0m in \u001b[0;36mmodel_loop\u001b[0;34m(args, loop_type, loader, model, phi, criterion, optimizer, epoch, steps, writer, device, schedule)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/delphi/delphi/grad.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoised\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mlambda_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfiltered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-0f473ff57f56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# truncated linear regression with unknown noise variance using empirical noise variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0munknown_trunc_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_trunc_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trunc_emp_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-176-39caa1fe101d>\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(kwargs, X, y)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3e-1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrunc_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTruncatedRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtrunc_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrunc_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/delphi/delphi/stats/linear_regression.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iteration_hook'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# run PGD for parameter estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lin_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lin_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;31m# remove linear regression from computation graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/delphi/delphi/train.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(args, model, loaders, phi, criterion, checkpoint, parallel, cuda, dp_device_ids, store, table, update_params, disable_no_grad)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mtrain_prec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mProcedureComplete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ground_truth parameters\n",
    "gt = LinearRegression() \n",
    "gt.fit(ozone, wind)\n",
    "gt_params = Tensor(np.concatenate([gt.coef_, np.expand_dims(gt.intercept_, 0)], axis=1))\n",
    "gt_var = Tensor(np.var(gt.predict(ozone) - wind.numpy(), 0))\n",
    "\n",
    "C = [1.0, 2, 2.5, 3, 3.5, 4, 5, 6, 6.5, 7.0, 8.0]\n",
    "for i in range(args.trials):\n",
    "    # create store\n",
    "    store = Store(args.out_dir + EXP)\n",
    "    store.add_table(TABLE_NAME, { \n",
    "        'known_r2': float,\n",
    "        'known_param_mse': float,\n",
    "        'known_time': int,\n",
    "        'unknown_param_mse': float,\n",
    "        'unknown_var_l1': float,\n",
    "        'unknown_r2': float,\n",
    "        'unknown_time': int,\n",
    "        'ols_r2': float, \n",
    "        'ols_param_mse': float,\n",
    "        'ols_var_l1': float,\n",
    "#         'trunc_reg_param_mse': float, \n",
    "#         'trunc_var_l1': float,\n",
    "        'alpha': float, \n",
    "        'c': float, \n",
    "        'num_samples': int,\n",
    "    })\n",
    "    \n",
    "    for c in C: \n",
    "        # truncate\n",
    "        phi = oracle.Left(c)\n",
    "        indices = phi(wind).eq(1).flatten()\n",
    "        x_trunc, y_trunc = ozone[indices], wind[indices]\n",
    "        # add survival probability to hyperparameters\n",
    "        alpha = Tensor([x_trunc.size(0) / ozone.size(0)])\n",
    "        print(\"alpha: \", alpha)\n",
    "        \n",
    "        # empirical linear regression\n",
    "        ols = LinearRegression() \n",
    "        ols.fit(x_trunc, y_trunc)\n",
    "        emp_noise_var = ch.var(Tensor(ols.predict(x_trunc)) - y_trunc, dim=0)[...,None]\n",
    "        ols_params = ch.cat([Tensor(ols.coef_).T, Tensor(ols.intercept_)[..., None]]).flatten()\n",
    "        print(\"ols params: \", ols_params)\n",
    "        print(\"gt params: \", gt_params)\n",
    "        # ols results\n",
    "        store[TABLE_NAME].update_row({\n",
    "            'ols_r2': r2_score(wind.flatten(), ols.predict(ozone).flatten()), \n",
    "            'ols_var_l1': ch.abs(emp_noise_var - gt_var),\n",
    "            'ols_param_mse': mse_loss(ols_params, gt_params.flatten()),\n",
    "        })\n",
    "        \n",
    "        val = int(.1*x_trunc.size(0))\n",
    "        \n",
    "        beta = LA.norm(x_trunc, dim=-1, ord=float('inf')).max()\n",
    "        x_trunc_norm = x_trunc / beta\n",
    "        \n",
    "        # scale by the known noise variance \n",
    "        y_trunc_scaled = y_trunc / ch.sqrt(gt_var)\n",
    "        phi_scaled = oracle.Left(phi.left / ch.sqrt(gt_var))\n",
    "        \n",
    "        # standardize noised by actual noise variance\n",
    "        known_kwargs = { \n",
    "            'phi': phi_scaled, \n",
    "            'alpha': alpha, \n",
    "            'bias': args.bias, \n",
    "            'unknown': False, \n",
    "            'bs': args.bs, \n",
    "            'n': args.n, \n",
    "            'tol': args.tol, \n",
    "            'steps': args.steps, \n",
    "            'val': val\n",
    "        }\n",
    "        \n",
    "        # truncated linear regression with known noise variance using empirical noise variance\n",
    "        known_trunc_reg, total_time = run_trial(known_kwargs, x_trunc_norm, y_trunc_scaled) \n",
    "        \n",
    "        with ch.no_grad():       \n",
    "            w, w0 = (known_trunc_reg.weight * ch.sqrt(gt_var)) / beta, known_trunc_reg.intercept * ch.sqrt(gt_var) \n",
    "            known_params = ch.cat([w.flatten(), w0])\n",
    "            # known results\n",
    "            store[TABLE_NAME].update_row({\n",
    "                'known_r2': r2_score(wind.flatten(), ozone@w + w0), \n",
    "                'known_param_mse': mse_loss(known_params, gt_params.flatten()),\n",
    "                'known_time': total_time, \n",
    "            })\n",
    "            \n",
    "        \n",
    "        phi_emp_scaled = oracle.Left(phi.left / ch.sqrt(emp_noise_var))\n",
    "        y_trunc_emp_scaled = y_trunc / ch.sqrt(emp_noise_var)\n",
    "            \n",
    "        # standardize noised by actual noise variance\n",
    "        unknown_kwargs = { \n",
    "            'phi': phi_emp_scaled, \n",
    "            'alpha': alpha, \n",
    "            'bias': args.bias, \n",
    "            'unknown': True, \n",
    "            'bs': args.bs, \n",
    "            'n': args.n, \n",
    "            'tol': args.tol, \n",
    "            'steps': args.steps, \n",
    "            'val': val\n",
    "        }\n",
    "        \n",
    "        # truncated linear regression with unknown noise variance using empirical noise variance\n",
    "        unknown_trunc_reg, total_time = run_trial(unknown_kwargs, x_trunc_norm, y_trunc_emp_scaled)  \n",
    "        \n",
    "        with ch.no_grad():      \n",
    "            w, w0 = (unknown_trunc_reg.weight * unknown_trunc_reg.variance * ch.sqrt(emp_noise_var)) / beta, unknown_trunc_reg.intercept * ch.sqrt(emp_noise_var) * unknown_trunc_reg.variance \n",
    "            unknown_params = ch.cat([w, w0]).flatten()\n",
    "            # known results\n",
    "            store[TABLE_NAME].update_row({\n",
    "                'unknown_r2': r2_score(wind.flatten(), ozone@w + w0), \n",
    "                'unknown_param_mse': mse_loss(unknown_params, gt_params.flatten()),\n",
    "                'unknown_time': total_time, \n",
    "                'unknown_var_l1': ch.abs(unknown_trunc_reg.variance * emp_noise_var - gt_var)\n",
    "            })\n",
    "            \n",
    "\n",
    "        store[TABLE_NAME].append_row({ \n",
    "            'alpha': float(alpha), \n",
    "            'c': c,    \n",
    "            'num_samples': x_trunc.size(0),\n",
    "        })\n",
    "            \n",
    "    # close current store\n",
    "    store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:00<00:00, 125.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: exp_id 4074293c-02c9-424f-88b9-a20587816e0e has no table 'logs'. Skipping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>known_r2</th>\n",
       "      <th>known_param_mse</th>\n",
       "      <th>known_time</th>\n",
       "      <th>unknown_param_mse</th>\n",
       "      <th>unknown_var_l1</th>\n",
       "      <th>unknown_r2</th>\n",
       "      <th>unknown_time</th>\n",
       "      <th>ols_r2</th>\n",
       "      <th>ols_param_mse</th>\n",
       "      <th>ols_var_l1</th>\n",
       "      <th>alpha</th>\n",
       "      <th>c</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>exp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277998</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034127</td>\n",
       "      <td>1.011202</td>\n",
       "      <td>0.276445</td>\n",
       "      <td>3</td>\n",
       "      <td>0.281893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278144</td>\n",
       "      <td>0.026345</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>0.969488</td>\n",
       "      <td>0.259547</td>\n",
       "      <td>2</td>\n",
       "      <td>0.281653</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.337258</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>2.0</td>\n",
       "      <td>152</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276827</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314144</td>\n",
       "      <td>0.813266</td>\n",
       "      <td>0.263929</td>\n",
       "      <td>3</td>\n",
       "      <td>0.281247</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.334309</td>\n",
       "      <td>0.986928</td>\n",
       "      <td>2.5</td>\n",
       "      <td>151</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.278337</td>\n",
       "      <td>0.010111</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976901</td>\n",
       "      <td>0.982629</td>\n",
       "      <td>0.224470</td>\n",
       "      <td>4</td>\n",
       "      <td>0.280248</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.466569</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.278994</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>1.139410</td>\n",
       "      <td>0.231315</td>\n",
       "      <td>2</td>\n",
       "      <td>0.280879</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.420097</td>\n",
       "      <td>0.973856</td>\n",
       "      <td>3.5</td>\n",
       "      <td>149</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   known_r2  known_param_mse  known_time  unknown_param_mse  unknown_var_l1  \\\n",
       "0  0.277998         0.000010           0           0.034127        1.011202   \n",
       "1  0.278144         0.026345           0           0.015193        0.969488   \n",
       "2  0.276827         0.026245           0           0.314144        0.813266   \n",
       "3  0.278337         0.010111           1           0.976901        0.982629   \n",
       "4  0.278994         0.000388           0           0.009324        1.139410   \n",
       "\n",
       "   unknown_r2  unknown_time    ols_r2  ols_param_mse  ols_var_l1     alpha  \\\n",
       "0    0.276445             3  0.281893       0.000000    0.058253  1.000000   \n",
       "1    0.259547             2  0.281653       0.001476    0.337258  0.993464   \n",
       "2    0.263929             3  0.281247       0.000002    0.334309  0.986928   \n",
       "3    0.224470             4  0.280248       0.000297    0.466569  0.980392   \n",
       "4    0.231315             2  0.280879       0.000333    0.420097  0.973856   \n",
       "\n",
       "     c  num_samples                                exp_id  \n",
       "0  1.0          153  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "1  2.0          152  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "2  2.5          151  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "3  3.0          150  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "4  3.5          149  86c7b475-e4af-430d-9a87-3c3c058dc8cd  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = CollectionReader(args.out_dir + EXP)\n",
    "results = reader.df(TABLE_NAME)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>known_r2</th>\n",
       "      <th>known_param_mse</th>\n",
       "      <th>known_time</th>\n",
       "      <th>unknown_param_mse</th>\n",
       "      <th>unknown_var_l1</th>\n",
       "      <th>unknown_r2</th>\n",
       "      <th>unknown_time</th>\n",
       "      <th>ols_r2</th>\n",
       "      <th>ols_param_mse</th>\n",
       "      <th>ols_var_l1</th>\n",
       "      <th>alpha</th>\n",
       "      <th>c</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>exp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277998</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034127</td>\n",
       "      <td>1.011202</td>\n",
       "      <td>0.276445</td>\n",
       "      <td>3</td>\n",
       "      <td>0.281893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278144</td>\n",
       "      <td>0.026345</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>0.969488</td>\n",
       "      <td>0.259547</td>\n",
       "      <td>2</td>\n",
       "      <td>0.281653</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.337258</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>2.0</td>\n",
       "      <td>152</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276827</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314144</td>\n",
       "      <td>0.813266</td>\n",
       "      <td>0.263929</td>\n",
       "      <td>3</td>\n",
       "      <td>0.281247</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.334309</td>\n",
       "      <td>0.986928</td>\n",
       "      <td>2.5</td>\n",
       "      <td>151</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.278337</td>\n",
       "      <td>0.010111</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976901</td>\n",
       "      <td>0.982629</td>\n",
       "      <td>0.224470</td>\n",
       "      <td>4</td>\n",
       "      <td>0.280248</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.466569</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.278994</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>1.139410</td>\n",
       "      <td>0.231315</td>\n",
       "      <td>2</td>\n",
       "      <td>0.280879</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.420097</td>\n",
       "      <td>0.973856</td>\n",
       "      <td>3.5</td>\n",
       "      <td>149</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.264723</td>\n",
       "      <td>0.023325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.750131</td>\n",
       "      <td>0.222308</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280490</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.369918</td>\n",
       "      <td>0.967320</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.254123</td>\n",
       "      <td>0.089080</td>\n",
       "      <td>0</td>\n",
       "      <td>1.332225</td>\n",
       "      <td>0.517681</td>\n",
       "      <td>0.200302</td>\n",
       "      <td>2</td>\n",
       "      <td>0.273976</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.576487</td>\n",
       "      <td>0.934641</td>\n",
       "      <td>5.0</td>\n",
       "      <td>143</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.250348</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059343</td>\n",
       "      <td>0.535562</td>\n",
       "      <td>0.278821</td>\n",
       "      <td>2</td>\n",
       "      <td>0.256005</td>\n",
       "      <td>0.024653</td>\n",
       "      <td>0.611852</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>6.0</td>\n",
       "      <td>137</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.274417</td>\n",
       "      <td>0.144540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>1.632280</td>\n",
       "      <td>0.198839</td>\n",
       "      <td>2</td>\n",
       "      <td>0.217977</td>\n",
       "      <td>0.045553</td>\n",
       "      <td>0.812873</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>6.5</td>\n",
       "      <td>129</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.279306</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128093</td>\n",
       "      <td>1.627416</td>\n",
       "      <td>0.258521</td>\n",
       "      <td>2</td>\n",
       "      <td>0.180237</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>1.341405</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>7.0</td>\n",
       "      <td>120</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.240278</td>\n",
       "      <td>0.022520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135251</td>\n",
       "      <td>0.804770</td>\n",
       "      <td>0.184739</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.027911</td>\n",
       "      <td>0.007004</td>\n",
       "      <td>2.203761</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>8.0</td>\n",
       "      <td>99</td>\n",
       "      <td>86c7b475-e4af-430d-9a87-3c3c058dc8cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.281772</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027158</td>\n",
       "      <td>0.657501</td>\n",
       "      <td>0.272045</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153</td>\n",
       "      <td>a2aeb942-04a4-4120-81b0-6b0c4fdf2996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.274497</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160398</td>\n",
       "      <td>1.231968</td>\n",
       "      <td>0.273249</td>\n",
       "      <td>2</td>\n",
       "      <td>0.281653</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.337258</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>2.0</td>\n",
       "      <td>152</td>\n",
       "      <td>a2aeb942-04a4-4120-81b0-6b0c4fdf2996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.281756</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094253</td>\n",
       "      <td>1.374699</td>\n",
       "      <td>0.275908</td>\n",
       "      <td>2</td>\n",
       "      <td>0.281247</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.334309</td>\n",
       "      <td>0.986928</td>\n",
       "      <td>2.5</td>\n",
       "      <td>151</td>\n",
       "      <td>a2aeb942-04a4-4120-81b0-6b0c4fdf2996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279911</td>\n",
       "      <td>0.026527</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127854</td>\n",
       "      <td>0.308709</td>\n",
       "      <td>0.268411</td>\n",
       "      <td>2</td>\n",
       "      <td>0.280248</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.466569</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150</td>\n",
       "      <td>a2aeb942-04a4-4120-81b0-6b0c4fdf2996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    known_r2  known_param_mse  known_time  unknown_param_mse  unknown_var_l1  \\\n",
       "0   0.277998         0.000010           0           0.034127        1.011202   \n",
       "1   0.278144         0.026345           0           0.015193        0.969488   \n",
       "2   0.276827         0.026245           0           0.314144        0.813266   \n",
       "3   0.278337         0.010111           1           0.976901        0.982629   \n",
       "4   0.278994         0.000388           0           0.009324        1.139410   \n",
       "5   0.264723         0.023325           0           0.000478        0.750131   \n",
       "6   0.254123         0.089080           0           1.332225        0.517681   \n",
       "7   0.250348         0.011384           0           0.059343        0.535562   \n",
       "8   0.274417         0.144540           0           0.000659        1.632280   \n",
       "9   0.279306         0.020996           0           0.128093        1.627416   \n",
       "10  0.240278         0.022520           0           0.135251        0.804770   \n",
       "0   0.281772         0.000198           1           0.027158        0.657501   \n",
       "1   0.274497         0.020057           0           0.160398        1.231968   \n",
       "2   0.281756         0.002311           0           0.094253        1.374699   \n",
       "3   0.279911         0.026527           0           0.127854        0.308709   \n",
       "\n",
       "    unknown_r2  unknown_time    ols_r2  ols_param_mse  ols_var_l1     alpha  \\\n",
       "0     0.276445             3  0.281893       0.000000    0.058253  1.000000   \n",
       "1     0.259547             2  0.281653       0.001476    0.337258  0.993464   \n",
       "2     0.263929             3  0.281247       0.000002    0.334309  0.986928   \n",
       "3     0.224470             4  0.280248       0.000297    0.466569  0.980392   \n",
       "4     0.231315             2  0.280879       0.000333    0.420097  0.973856   \n",
       "5     0.222308             0  0.280490       0.000005    0.369918  0.967320   \n",
       "6     0.200302             2  0.273976       0.002056    0.576487  0.934641   \n",
       "7     0.278821             2  0.256005       0.024653    0.611852  0.895425   \n",
       "8     0.198839             2  0.217977       0.045553    0.812873  0.843137   \n",
       "9     0.258521             2  0.180237       0.002890    1.341405  0.784314   \n",
       "10    0.184739             2 -0.027911       0.007004    2.203761  0.647059   \n",
       "0     0.272045             0  0.281893       0.000000    0.058253  1.000000   \n",
       "1     0.273249             2  0.281653       0.001476    0.337258  0.993464   \n",
       "2     0.275908             2  0.281247       0.000002    0.334309  0.986928   \n",
       "3     0.268411             2  0.280248       0.000297    0.466569  0.980392   \n",
       "\n",
       "      c  num_samples                                exp_id  \n",
       "0   1.0          153  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "1   2.0          152  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "2   2.5          151  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "3   3.0          150  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "4   3.5          149  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "5   4.0          148  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "6   5.0          143  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "7   6.0          137  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "8   6.5          129  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "9   7.0          120  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "10  8.0           99  86c7b475-e4af-430d-9a87-3c3c058dc8cd  \n",
       "0   1.0          153  a2aeb942-04a4-4120-81b0-6b0c4fdf2996  \n",
       "1   2.0          152  a2aeb942-04a4-4120-81b0-6b0c4fdf2996  \n",
       "2   2.5          151  a2aeb942-04a4-4120-81b0-6b0c4fdf2996  \n",
       "3   3.0          150  a2aeb942-04a4-4120-81b0-6b0c4fdf2996  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results for regression parameter MSE\n",
    "# sns.lineplot(data=results, x='c', y='unknown_param_mse', label='unknown', color='blue')\n",
    "sns.lineplot(data=results, x='c', y='ols_param_mse', label='ols', color='red')\n",
    "ax = sns.lineplot(data=results, x='c', y='known_param_mse', label='known', color='orange')\n",
    "ax.set(xlabel='Truncation Parameter C', ylabel='L2 Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbS0lEQVR4nO3dfZRV1Z3m8e9jgZQBowmhSRoQKqJRJCPREtQEtNvEaHealwymIfGF8a1nWpI2TjIxbcal/tFrNI661sRMYhQ1tlEMiouIo7YxRkjbSEEwikosEdsiJEJhNIi8/+aPs6Gv5a7iAnW4deH5rFWLc/bZ55zfRannvN19FBGYmZl1dECtCzAzs57JAWFmZlkOCDMzy3JAmJlZlgPCzMyyHBBmZpZVakBIOkPSMkmtki7PLO8jaWZavkDSsNQ+TNK7kpaknx+UWaeZmb1fr7I2LKkBuBn4HNAGLJQ0JyJeqOh2AfBmRAyXNAW4FvjbtOyViBhVVn1mZta1Ms8gRgOtEbE8IjYB9wITOvSZANyZpmcBp0lSiTWZmVmVSjuDAAYBr1fMtwFjOusTEVskvQX0T8uaJP0aeBv4TkTM67gDSRcDFwP07dv3+KOOOqp7P4GZ2T5u0aJFayJiQG5ZmQGxJ1YBh0VEu6TjgQclHRMRb1d2iohbgFsAmpubo6WlpQalmpnVL0mvdbaszEtMK4EhFfODU1u2j6RewCFAe0RsjIh2gIhYBLwCHFlirWZm1kGZAbEQOEJSk6QDgSnAnA595gDnpenJwBMREZIGpJvcSPo4cASwvMRazcysg9IuMaV7CtOBR4EGYEZELJV0DdASEXOA24C7JLUCaylCBGAccI2kzcA24L9GxNqyajUzs/fTvjLct+9BmO3bNm/eTFtbGxs2bKh1KXWpsbGRwYMH07t37/e0S1oUEc25dXrqTWozs/doa2vj4IMPZtiwYfhp+F0TEbS3t9PW1kZTU1PV63moDTOrCxs2bKB///4Oh90gif79++/y2ZcDwszqhsNh9+3O350DwszMshwQZmYlueOOO5g+fXqty9htDggzM8tyQJiZVWnFihWMHDlyx/z111/PVVddxamnnsq3vvUtRo8ezZFHHsm8ee8bOo65c+dy0kknsWbNGqZNm8bXvvY1Tj75ZD7+8Y8za9YsoHja6Jvf/CYjR47kk5/8JDNnzgTgkksuYc6c4nvGkyZN4vzzzwdgxowZXHHFFaxYsYKjjz6aiy66iGOOOYbTTz+dd999d48/rx9zNbO6c+mlsGRJ925z1Ci46abdX3/Lli0888wzPPzww1x99dU8/vjjO5bNnj2bG264gYcffpgPfehDAKxatYr58+fz0ksvMX78eCZPnswDDzzAkiVLePbZZ1mzZg0nnHAC48aNY+zYscybN4/x48ezcuVKVq1aBcC8efOYMqX4fvHLL7/MPffcw49+9CO+9KUvcf/993P22Wfv/gfCZxBmZt3ii1/8IgDHH388K1as2NH+xBNPcO211zJ37twd4QAwceJEDjjgAEaMGMEf/vAHAObPn8/UqVNpaGhg4MCBnHLKKSxcuHBHQLzwwguMGDGCgQMHsmrVKp5++mlOPvlkAJqamhg1alS2ht3lMwgzqzt7cqS/J3r16sW2bdt2zFd+r6BPnz4ANDQ0sGXLlh3thx9+OMuXL+e3v/0tzc3N7+sPxaWlrgwaNIg//vGPPPLII4wbN461a9dy33330a9fPw4++GDa29vfs72GhoZuucTkMwgzsyoNHDiQN954g/b2djZu3MhDDz2003WGDh3K/fffz7nnnsvSpUu77Dt27FhmzpzJ1q1bWb16NU899RSjR48G4MQTT+Smm27accnp+uuvZ+zYsd3yuTrjMwgzsyr17t2bK6+8ktGjRzNo0CCqfUnZUUcdxd13381ZZ53Fz372s077TZo0iaeffppjjz0WSVx33XV89KMfBYrweOyxxxg+fDhDhw5l7dq1pQeEB+szs7rw4osvcvTRR9e6jLqW+zvsarA+X2IyM7MsB4SZmWU5IMzMLMsBYWZmWQ4IMzPLckCYmVmWA8LMbA/069ev1iWUxgFhZmZZDggzsyrdcMMNjBw5kpEjR3JThwGhVq1axbhx4xg1ahQjR47MDvldbzzUhpnVnxqM971o0SJuv/12FixYQEQwZswYTjnllB3Lf/KTn/D5z3+eK664gq1bt7J+/frura8GHBBmZlWYP38+kyZNom/fvkAxvHflWcIJJ5zA+eefz+bNm5k4ceKOobfrmQPCzOpPrcb77sK4ceN46qmnmDt3LtOmTeOyyy7j3HPPrXVZe8T3IMzMqjB27FgefPBB1q9fzzvvvMPs2bPfM5rqa6+9xsCBA7nooou48MILWbx4cQ2r7R4+gzAzq8Jxxx3HtGnTdryf4cILL+RTn/rUjuVPPvkk3/3ud+nduzf9+vXjxz/+ca1K7TYe7tvM6oKH+95zHu7bzMy6hQPCzMyyHBBmVjf2lUvitbA7f3cOCDOrC42NjbS3tzskdkNE0N7eTmNj4y6t56eYzKwuDB48mLa2NlavXl3rUupSY2MjgwcP3qV1HBBmVhd69+5NU1NTrcvYr/gSk5mZZZUaEJLOkLRMUqukyzPL+0iamZYvkDSsw/LDJK2T9I0y6zQzs/crLSAkNQA3A2cCI4CpkkZ06HYB8GZEDAduBK7tsPwG4P+VVaOZmXWuzDOI0UBrRCyPiE3AvcCEDn0mAHem6VnAaZIEIGki8CqwtMQazcysE2UGxCDg9Yr5ttSW7RMRW4C3gP6S+gHfAq7uageSLpbUIqnFTzaYmXWvnnqT+irgxohY11WniLglIpojonnAgAF7pzIzs/1EmY+5rgSGVMwPTm25Pm2SegGHAO3AGGCypOuAQ4FtkjZExPdKrNfMzCqUGRALgSMkNVEEwRTgyx36zAHOA54GJgNPRPE1yR2DrEu6CljncDAz27tKC4iI2CJpOvAo0ADMiIilkq4BWiJiDnAbcJekVmAtRYiYmVkP4PdBmJntx/w+CDMz22UOCDMzy3JAmJlZlgPCzMyyHBBmZpblgDAzsywHhJmZZTkgzMwsywFhZmZZDggzM8tyQJiZWZYDwszMshwQZmaW5YAwM7MsB4SZmWU5IMzMLMsBYWZmWQ4IMzPLckCYmVmWA8LMzLIcEGZmluWAMDOzLAeEmZllOSDMzCzLAWFmZlkOCDMzy3JAmJlZlgPCzMyyHBBmZpblgDAzsywHhJmZZVUVEJKGSvpsmj5I0sHllmVmZrW204CQdBEwC/hhahoMPFhiTWZm1gNUcwZxCfBp4G2AiHgZ+LMyizIzs9qrJiA2RsSm7TOSegFRzcYlnSFpmaRWSZdnlveRNDMtXyBpWGofLWlJ+nlW0qQqP4+ZmXWTagLil5L+EThI0ueAnwI/29lKkhqAm4EzgRHAVEkjOnS7AHgzIoYDNwLXpvbngeaIGAWcAfwwBZOZme0l1QTE5cBq4Dng74CHge9Usd5ooDUilqczkHuBCR36TADuTNOzgNMkKSLWR8SW1N5IlWcsZmbWfao5Kj8ImBERP4IdZwYHAet3st4g4PWK+TZgTGd9ImKLpLeA/sAaSWOAGcBQ4JyKwNhB0sXAxQCHHXZYFR/FzMyqVc0ZxM8pAmG7g4DHyynnP0TEgog4BjgB+LakxkyfWyKiOSKaBwwYUHZJZmb7lWoCojEi1m2fSdMfqGK9lcCQivnBqS3bJ91jOARor+wQES8C64CRVezTzMy6STUB8Y6k47bPSDoeeLeK9RYCR0hqknQgMAWY06HPHOC8ND0ZeCIiIq3TK+1vKHAUsKKKfZqZWTep5h7EpcBPJf0OEPBR4G93tlK6pzAdeBRooLiPsVTSNUBLRMwBbgPuktQKrKUIEYDPAJdL2gxsA/4+Itbs2kczM7M9oYidPyAkqTfwiTS7LCI2l1rVbmhubo6WlpZal2FmVlckLYqI5tyyar9bcAIwLPU/ThIR8eNuqs/MzHqgnQaEpLuAw4ElwNbUHIADwsxsH1bNGUQzMCKquRZlZmb7jGqeYnqe4sa0mZntR6o5g/gI8IKkZ4CN2xsjYnxpVZmZWc1VExBXlV2EmZn1PDsNiIj45d4oxMzMepZq3ih3oqSFktZJ2iRpq6S390ZxZmZWO9XcpP4eMBV4mWKgvgsp3vNgZmb7sGoCgohoBRoiYmtE3E7xEh8zM9uHVXOTen0abG+JpOuAVVQZLGZmVr+q+UV/Tuo3HXiHYnjuL5ZZlJmZ1V41ATExIjZExNsRcXVEXAZ8oezCzMystqoJiPMybdO6uQ4zM+thOr0HIWkq8GWgSVLli34+SPHuBjMz24d1dZP6XyluSH8E+N8V7X8CflNmUWZmVnudBkREvAa8JumzwLsRsU3SkRSv/3xubxVoZma1Uc09iKeARkmDgMconmq6o8yizMys9qoJCEXEeopHW78fEWcBx5RblpmZ1VpVASHpJOArwNzU1lBeSWZm1hNUExCXAt8GZkfEUkkfB35RalVmZlZz1Q73/cuK+eXA18osyszMaq+r70HcFBGXSvoZ8L73UfuNcmZm+7auziDuSn9evzcKMTOznqWr70EsSn/+UtKANL16bxVmZma11eVNaklXSVoDLAN+K2m1pCv3TmlmZlZLnQaEpMuATwMnRMSHI+JDwBjg05K+vrcKNDOz2ujqDOIcYGpEvLq9IT3BdDZwbtmFmZlZbXUVEL0jYk3HxnQfond5JZmZWU/QVUBs2s1lZma2D+jqMddjJb2daRfQWFI9ZmbWQ3T1mKvHWzIz249VMxaTmZnthxwQZmaW5YAwM7OsUgNC0hmSlklqlXR5ZnkfSTPT8gWShqX2z0laJOm59OdfllmnmZm9X1ffpB4i6V5J8yT9o6TeFcse3NmGJTUANwNnAiOAqZJGdOh2AfBmRAwHbgSuTe1rgL+JiE8C5/EfAweamdle0tUZxAzgSeCrwMeAX0rqn5YNrWLbo4HWiFgeEZuAe4EJHfpMAO5M07OA0yQpIn4dEb9L7UuBgyT1qWKfZmbWTboKiAER8YOIWBIRXwW+Dzwl6XAy74fIGAS8XjHfltqyfSJiC/AW0L9Dn/8MLI6IjR13IOliSS2SWlav9kCzZmbdqasvyvWW1BgRGwAi4p8l/R54FOi7N4qTdAzFZafTc8sj4hbgFoDm5uZqQsvMzKrU1RnErRSjt+4QEY8DZwHPV7HtlcCQivnBqS3bR1Iv4BCgPc0PBmYD50bEK1Xsz8zMulGnARERN6b3UXds/zUwt4ptLwSOkNQk6UBgCjCnQ585FDehASYDT0RESDo07ePyiPhVFfsyM7NutruPuV62sw7pnsJ0iktSLwL3RcRSSddI2v4+69uA/pJa0za3Pwo7HRgOXClpSfr5s92s1czMdoMidv3SvaTXI2LIznvuPc3NzdHS0lLrMszM6oqkRRHRnFu2u2cQviFsZraP6/QpJkl/Ih8EAg4qrSIzM+sRuhru++C9WYiZmfUsHqzPzMyyHBBmZpblgDAzsywHhJmZZTkgzMwsywFhZmZZDggzM8tyQJiZWZYDwszMshwQZmaW5YAwM7MsB4SZmWU5IMzMLMsBYWZmWQ4IMzPLckCYmVmWA8LMzLIcEGZmluWAMDOzLAeEmZllOSDMzCzLAWFmZlkOCDMzy3JAmJlZlgPCzMyyHBBmZpblgDAzsywHhJmZZTkgzMwsywFhZmZZDggzM8sqNSAknSFpmaRWSZdnlveRNDMtXyBpWGrvL+kXktZJ+l6ZNZqZWV5pASGpAbgZOBMYAUyVNKJDtwuANyNiOHAjcG1q3wD8T+AbZdVnZmZdK/MMYjTQGhHLI2ITcC8woUOfCcCdaXoWcJokRcQ7ETGfIijMzKwGygyIQcDrFfNtqS3bJyK2AG8B/avdgaSLJbVIalm9evUelmtmZpXq+iZ1RNwSEc0R0TxgwIBal2Nmtk8pMyBWAkMq5gentmwfSb2AQ4D2EmsyM7MqlRkQC4EjJDVJOhCYAszp0GcOcF6angw8ERFRYk1mZlalXmVtOCK2SJoOPAo0ADMiYqmka4CWiJgD3AbcJakVWEsRIgBIWgF8EDhQ0kTg9Ih4oax6zczsvUoLCICIeBh4uEPblRXTG4CzOll3WJm1mZlZ1+r6JrWZmZXHAWFmZlkOCDMzy3JAmJlZlgPCzMyyHBBmZpblgDAzsywHhJmZZTkgzMwsywFhZmZZDggzM8tyQJiZWZYDwszMshwQZmaW5YAwM7MsB4SZmWU5IMzMLMsBYWZmWQ4IMzPLckCYmVmWA8LMzLIcEGZmluWAMDOzLAeEmZllOSDMzCzLAWFmZlkOCDMzy3JAmJlZlgPCzMyyHBBmZpblgDAzsywHhJmZZTkgzMwsywFhZmZZDggzM8sqNSAknSFpmaRWSZdnlveRNDMtXyBpWMWyb6f2ZZI+X2adZmb2fqUFhKQG4GbgTGAEMFXSiA7dLgDejIjhwI3AtWndEcAU4BjgDOD7aXtmZraXlHkGMRpojYjlEbEJuBeY0KHPBODOND0LOE2SUvu9EbExIl4FWtP2zMxsL+lV4rYHAa9XzLcBYzrrExFbJL0F9E/t/9Zh3UEddyDpYuDiNLtO0rI9qPcjwJo9WH9vqqdaob7qda3lqad666lW2LN6h3a2oMyAKF1E3ALc0h3bktQSEc3dsa2y1VOtUF/1utby1FO99VQrlFdvmZeYVgJDKuYHp7ZsH0m9gEOA9irXNTOzEpUZEAuBIyQ1STqQ4qbznA595gDnpenJwBMREal9SnrKqQk4AnimxFrNzKyD0i4xpXsK04FHgQZgRkQslXQN0BIRc4DbgLsktQJrKUKE1O8+4AVgC3BJRGwtq9akWy5V7SX1VCvUV72utTz1VG891Qol1avigN3MzOy9/E1qMzPLckCYmVnWfh0QkmZIekPS87WupRqShkj6haQXJC2V9A+1rqkzkholPSPp2VTr1bWuaWckNUj6taSHal3LzkhaIek5SUsktdS6np2RdKikWZJekvSipJNqXVOOpE+kv9PtP29LurTWdXVG0tfTv6/nJd0jqbFbt78/34OQNA5YB/w4IkbWup6dkfQx4GMRsVjSwcAiYGJEvFDj0t4nfSO+b0Ssk9QbmA/8Q0T8205WrRlJlwHNwAcj4gu1rqcrklYAzRFRF1/mknQnMC8ibk1PNX4gIv5Y47K6lIb3WQmMiYjXal1PR5IGUfy7GhER76YHex6OiDu6ax/79RlERDxF8fRUXYiIVRGxOE3/CXiRzDfMe4IorEuzvdNPjz0akTQY+Gvg1lrXsq+RdAgwjuKpRSJiU08Ph+Q04JWeGA4VegEHpe+RfQD4XXdufL8OiHqWRr79FLCgxqV0Kl2yWQK8AfxLRPTYWoGbgP8BbKtxHdUK4DFJi9KQMz1ZE7AauD1dwrtVUt9aF1WFKcA9tS6iMxGxErge+HdgFfBWRDzWnftwQNQhSf2A+4FLI+LtWtfTmYjYGhGjKL4JP1pSj7yMJ+kLwBsRsajWteyCz0TEcRSjJV+SLpf2VL2A44D/GxGfAt4B3jf8f0+SLoONB35a61o6I+lDFAObNgF/DvSVdHZ37sMBUWfS9fz7gbsj4oFa11ONdDnhFxRDt/dEnwbGp+v69wJ/Kemfa1tS19LRIxHxBjCbnj3acRvQVnEGOYsiMHqyM4HFEfGHWhfShc8Cr0bE6ojYDDwAnNydO3BA1JF04/c24MWIuKHW9XRF0gBJh6bpg4DPAS/VtKhORMS3I2JwRAyjuKzwRER065FYd5LUNz2kQLpUczrQY5/Ei4jfA69L+kRqOo1ilISebCo9+PJS8u/AiZI+kH43nEZxX7Lb7NcBIeke4GngE5LaJF1Q65p24tPAORRHuNsfw/urWhfViY8Bv5D0G4pxuf4lInr846N1YiAwX9KzFGOUzY2IR2pc0858Fbg7/f8wCvin2pbTuRS6n6M4Iu+x0hnZLGAx8BzF7/NuHXJjv37M1czMOrdfn0GYmVnnHBBmZpblgDAzsywHhJmZZTkgzMwsywFhNSOpf8Xjur+XtLJi/sC9VMOhkv6+Yv7PJc3qpm0/KWlZGtH2VxXfA6gZScMkfbkbttNP0g8lvZKG+3hS0pjuqNF6DgeE1UxEtEfEqDQcxw+AG7fPR8SmNABZ2Q4FdgRERPwuIiZ34/a/EhHHAncC361mhZI/9zBglwKik3pupRjo8oiIOB74L8BH9rg661EcENajSLpD0g8kLQCuk3SVpG9ULH8+HQUPS+8V+FEaD/+x9I1tJA2X9Hg6cl8s6fB0xPvzNP+cpAlpk/8LODydtXw3bff5tJ1GSben/r+W9BepfZqkByQ9IullSddV8dGeAoan7c9LdSyWdHLa5qmpfQ7pW8aSHkxH50srB+STtC7VujR9ztHpCH65pPGpT0Pqs1DSbyT9XcXnHZs+79c765erp2L/hwNjgO9ExDaAiHg1IuZW/R/a6kNE+Mc/Nf8BrgK+AdwBPAQ0VLZX9Hue4ih4GLAFGJXa7wPOTtMLgElpupFiGOReFO95gOJItxVQ2s7zFdvfMQ/8d2BGmj6KYmiDRmAasBw4JM2/BgzJfKYnKd7ZAPBNYGaqpTG1HQG0pOlTKQaxa6pY/8Ppz4PS5+6f5gM4M03PBh6jGE79WGBJar+Y4hc4QB+ghWJQt1OBhyr20VW/99RTsc54YHat/5/xT/k/e+MU3mxX/TQitlbR79WIWJKmFwHD0hhFgyJiNkBEbIAdgxz+k4pRT7dRvEdj4E62/xng/6TtvCTpNeDItOznEfFW2vYLwFDg9cw27pb0LrCCYriJ3sD3JI0CtlZsD+CZiHi1Yv5rkial6SEUgdIObAK2D63xHLAxIjZLeo4i4KAYn+k/Sdp+ueyQtP6mDvV11a9jPbafcUBYT/ROxfQW3nsptPKVihsrprdSHGl35ivAAOD49Mt0RYdt7aqO++7s39JXImLHK0ElXQX8geJo/wBgQ0Xfdyr6nUoxWudJEbFe0pMV9W6OiO1j5GzbXktEbKu4XyDgqxHxaGUxabvvaeqi3zvkLQWOldRQZZBbnfI9COvpVpCGhpZ0HMXlj05F8aa9NkkT0zp9JH2A4sj4jRQOf0FxxA/wJ+DgTjY3jyJYkHQkcBiwbE8+TKpjVRTX7s8BGrro92YKh6OAE3dxP48C/y2dOSHpSBWD0HX8vJ3161REvEJxKepqSUrrDZP017tYo/VwDgjr6e4HPixpKTAd+G0V65xDcXnmN8C/Ah8F7gaa02WYc0lDj0dEO/CrdPO741NG3wcOSOvMBKZFxEb2zPeB81SMxHoUnR+lPwL0kvQixY3lXX2X960UN5cXp5vuP6Q4y/kNsDXdwP96F/125kKKS3Stab07KN4caPsQj+ZqZmZZPoMwM7MsB4SZmWU5IMzMLMsBYWZmWQ4IMzPLckCYmVmWA8LMzLL+P0mTxN2d/rW1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results for regression noise variance MSE\n",
    "sns.lineplot(data=results, x='c', y='unknown_var_l1', label='unknown', color=\"blue\")\n",
    "ax = sns.lineplot(data=results, x='c', y='ols_var_l1', label='ols', color=\"red\")\n",
    "ax.set(xlabel='Truncation Parameter C', ylabel='L2 Distance')\n",
    "ax.set(ylim=(0, .05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth parameters\n",
    "gt = LinearRegression() \n",
    "gt.fit(ozone, wind)\n",
    "gt_params = Tensor(np.concatenate([gt.coef_, np.expand_dims(gt.intercept_, 0)], axis=1))\n",
    "gt_var = Tensor(np.var(gt.predict(ozone) - wind.numpy(), 0))\n",
    "\n",
    "C = [1.0, 2, 2.5, 3, 3.5, 4, 5, 6, 6.5, 7.0, 8.0]\n",
    "for i in range(args.trials):\n",
    "    # create store\n",
    "    store = Store(args.out_dir + EXP)\n",
    "    store.add_table(TABLE_NAME, { \n",
    "        'known_r2': float,\n",
    "        'known_param_mse': float,\n",
    "        'known_time': int,\n",
    "        'unknown_param_mse': float,\n",
    "        'unknown_var_l1': float,\n",
    "        'unknown_r2': float,\n",
    "        'unknown_time': int,\n",
    "        'ols_r2': float, \n",
    "        'ols_param_mse': float,\n",
    "        'ols_var_l1': float,\n",
    "#         'trunc_reg_param_mse': float, \n",
    "#         'trunc_var_l1': float,\n",
    "        'alpha': float, \n",
    "        'c': float, \n",
    "        'num_samples': int,\n",
    "    })\n",
    "    \n",
    "    for c in C: \n",
    "        # truncate\n",
    "        phi = oracle.Left(c)\n",
    "        indices = phi(wind).eq(1).flatten()\n",
    "        x_trunc, y_trunc = ozone[indices], wind[indices]\n",
    "        # add survival probability to hyperparameters\n",
    "        alpha = Tensor([x_trunc.size(0) / ozone.size(0)])\n",
    "        print(\"alpha: \", alpha)\n",
    "        \n",
    "        # empirical linear regression\n",
    "        ols = LinearRegression() \n",
    "        ols.fit(x_trunc, y_trunc)\n",
    "        emp_noise_var = ch.var(Tensor(ols.predict(x_trunc)) - y_trunc, dim=0)[...,None]\n",
    "        ols_params = ch.cat([Tensor(ols.coef_).T, Tensor(ols.intercept_)[..., None]]).flatten()\n",
    "        \n",
    "        # ols results\n",
    "        store[TABLE_NAME].update_row({\n",
    "            'ols_r2': r2_score(wind.flatten(), ols.predict(ozone).flatten()), \n",
    "            'ols_var_l1': ch.abs(emp_noise_var - gt_var),\n",
    "            'ols_param_mse': mse_loss(ols_params, gt_params.flatten()),\n",
    "        })\n",
    "        \n",
    "        val = int(.1*x_trunc.size(0))\n",
    "        \n",
    "        beta = LA.norm(x_trunc, dim=-1, ord=float('inf')).max()\n",
    "        x_trunc_norm = x_trunc / beta\n",
    "        \n",
    "        # scale by the known noise variance \n",
    "        y_trunc_scaled = y_trunc / ch.sqrt(gt_var)\n",
    "        phi_scaled = oracle.Left(phi.left / ch.sqrt(gt_var))\n",
    "        \n",
    "        # standardize noised by actual noise variance\n",
    "        known_kwargs = { \n",
    "            'phi': phi_scaled, \n",
    "            'alpha': alpha, \n",
    "            'bias': args.bias, \n",
    "            'unknown': False, \n",
    "            'bs': args.bs, \n",
    "            'n': args.n, \n",
    "            'tol': args.tol, \n",
    "            'steps': args.steps, \n",
    "            'val': val\n",
    "        }\n",
    "        \n",
    "        # truncated linear regression with known noise variance using empirical noise variance\n",
    "        known_trunc_reg, total_time = run_trial(known_kwargs, x_trunc_norm, y_trunc_scaled) \n",
    "        \n",
    "        with ch.no_grad():       \n",
    "            w, w0 = (known_trunc_reg.weight * ch.sqrt(gt_var)) / beta, known_trunc_reg.intercept * ch.sqrt(gt_var) \n",
    "            known_params = ch.cat([w.flatten(), w0])\n",
    "            # known results\n",
    "            store[TABLE_NAME].update_row({\n",
    "                'known_r2': r2_score(wind.flatten(), ozone@w + w0), \n",
    "                'known_param_mse': mse_loss(known_params, gt_params.flatten()),\n",
    "                'known_time': total_time, \n",
    "            })\n",
    "            \n",
    "        \n",
    "        phi_emp_scaled = oracle.Left(phi.left / ch.sqrt(emp_noise_var))\n",
    "        y_trunc_emp_scaled = y_trunc / ch.sqrt(emp_noise_var)\n",
    "            \n",
    "        # standardize noised by actual noise variance\n",
    "        unknown_kwargs = { \n",
    "            'phi': phi_emp_scaled, \n",
    "            'alpha': alpha, \n",
    "            'bias': args.bias, \n",
    "            'unknown': True, \n",
    "            'bs': args.bs, \n",
    "            'n': args.n, \n",
    "            'tol': args.tol, \n",
    "            'steps': args.steps, \n",
    "            'val': val\n",
    "        }\n",
    "        \n",
    "        # truncated linear regression with unknown noise variance using empirical noise variance\n",
    "        unknown_trunc_reg, total_time = run_trial(unknown_kwargs, x_trunc_norm, y_trunc_emp_scaled)  \n",
    "        \n",
    "        with ch.no_grad():      \n",
    "            w, w0 = (unknown_trunc_reg.weight * unknown_trunc_reg.variance * ch.sqrt(emp_noise_var)) / beta, unknown_trunc_reg.intercept * ch.sqrt(emp_noise_var) * unknown_trunc_reg.variance \n",
    "            unknown_params = ch.cat([w, w0]).flatten()\n",
    "            # known results\n",
    "            store[TABLE_NAME].update_row({\n",
    "                'unknown_r2': r2_score(wind.flatten(), ozone@w + w0), \n",
    "                'unknown_param_mse': mse_loss(unknown_params, gt_params.flatten()),\n",
    "                'unknown_time': total_time, \n",
    "                'unknown_var_l1': ch.abs(unknown_trunc_reg.variance * emp_noise_var - gt_var)\n",
    "            })\n",
    "            \n",
    "\n",
    "        store[TABLE_NAME].append_row({ \n",
    "            'alpha': float(alpha), \n",
    "            'c': c,    \n",
    "            'num_samples': x_trunc.size(0),\n",
    "        })\n",
    "            \n",
    "    # close current store\n",
    "    store.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
