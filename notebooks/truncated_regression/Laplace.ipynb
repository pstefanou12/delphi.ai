{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess \n",
    "import torch as ch\n",
    "from torch import Tensor\n",
    "import torch.linalg as LA\n",
    "from torch.distributions import Uniform, Laplace\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "from cox.utils import Parameters\n",
    "from cox.store import Store\n",
    "\n",
    "from cox.readers import CollectionReader\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math \n",
    "\n",
    "import sys \n",
    "sys.path.append('../..')\n",
    "from delphi.stats.linear_regression import TruncatedRegression\n",
    "from delphi import oracle\n",
    "from delphi.utils import constants as consts\n",
    "from delphi.utils.helpers import setup_store_with_metadata\n",
    "\n",
    "OUT_DIR = '/home/gridsan/stefanou/Regression/'\n",
    "TABLE_NAME = 'logs'\n",
    "\n",
    "# set environment variable so that stores can create output files\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Parameters({\n",
    "    \"bias\": True,\n",
    "    \"samples\": 10000,\n",
    "    \"c\": 0,\n",
    "    \"batch_size\": 5,\n",
    "    \"lr\": 1e-1,\n",
    "    \"var_lr\": 1e-2,\n",
    "    \"var_\": 1,\n",
    "    \"trials\": 3,\n",
    "    \"norm\": False,\n",
    "    \"workers\": 8,\n",
    "    \"steps\": 1000,\n",
    "    \"x_lower\": -10,\n",
    "    \"x_upper\": 10,\n",
    "    \"lower\": -1,\n",
    "    \"upper\": 1,\n",
    "    \"device\": \"cuda\",\n",
    "    \"num_samples\": 100,\n",
    "})\n",
    "mse_loss = ch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start by generating the ground-truth for our expriment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt weight:  Parameter containing:\n",
      "tensor([[-0.7730]], requires_grad=True)\n",
      "gt bias:  Parameter containing:\n",
      "tensor([[0.5748]], requires_grad=True)\n",
      "alpha:  tensor([0.6926])\n",
      "gt ols coef:  [[-0.77721226]]\n",
      "gt ols intercept:  [0.59251046]\n",
      "trunc ols coef:  [[-0.50018835]]\n",
      "trunc ols intercept:  [1.0499281]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEWCAYAAABv+EDhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABIMklEQVR4nO2deZiU1ZX/P6eW3li62WRHUBSDSoAGxbjFfUOaJCaZjJlEf5mgM5NkMhNRjInCmMWJjiajMxOdmJjFTGJcaHCJiVsSjQs04IKCoqKs0iyNQO9V5/fH+1b329X11tJd1VXddT7PU093vet9l7rfe88591xRVQzDMIziI5DvAhiGYRj5wQTAMAyjSDEBMAzDKFJMAAzDMIoUEwDDMIwixQTAMAyjSDEBKABE5KCIHJFk/Y9F5Nu9PMfHRWRrb46RwbnuEZHv9MW5ckG+yi8il4nIs3193oGGiEwWERWRUCGes5CeswmADyKyWUSa3Mo59rkjF+dS1cGq+k6S9Veq6o25OHc+EJGxIvK/IrLdva/vuJXuMfkuWzJE5Jued6FZRCKe7+szPFavKynPO3pARBpE5K8icqWIpPW77quKMh8VcjLc+9YqIiPjlq91yzk5T0Xrc0wAknOxWznHPl/p6wKISLCvz5lLRGQE8FegAjgVGALMBv4EnOOzT0FUHKr6vdi7AFwJPO95N46NbScOffXbulhVhwCHAzcB1wB399G5+zPvAp+LfRGR43HeyaLCBKAHuF2450TkNrfl9Y6IfMxdvkVEdonIFz3b3+Oacf7ottb+JCKHe9ariEz1bPs/IvKoiBwCzog3SYhIjYisE5EPReRtETnfXX65iLzhnuMdEbkig2v6kVv2D0WkTkRO9axbKiL3icgv3GOvF5E5nvWzRGSNu+63QFmSU/0L8CHwd6r6tjo0qOrPVPV293ixFuOXROR94CkRCYjIt0TkPff+/kJEKt3tu5m33Fbe2Tkov9/9e0ZEvisizwGNwBHeMnjK8Sv365/dvw1uD+Ikz3a3iMg+EXlXRC5I5/yqul9VVwCfBb4oIse5x7rIbdl+6D7fpZ7dupVBRI4UkadEZI+I7BaRe0WkylO2a0Rkm3uvNorIWe7ygIgscd/HPe79Hp7qWj3HPUFEnnd/TztE5A4RKfGsV3F6N2+52/yXiIi7Lujes90i8g5wURq37JfAFzzfvwj8Iq5Mle47U+++d98SV9hTndPd9273WraJyHekABtzJgA950TgFWAE8GvgN8BcYCrweeAOERns2f5S4EZgJLAOuDfJsf8W+C5O67iLrVBETsB5URcDVcBpwGZ39S5gPjAUuBy4TURmp3k9q4CZwHD3en4nIt6KcIF7jVXACuAOtzwlwHKcH9Rw4HfAp5Kc52zgIVWNplGm04GPAOcBl7mfM4AjgMGxMqRJtsqfjL8DFuE8t/dSbHua+7fK7UE8734/EdiI8578ALg7VtGlg6q+BGzF6V0BHMKp6KpwKql/EJGFScogwPeBcTj3fiKwFEBEpgFfAea6vY7z6Hz3vgosxHlm44B9wH+luFYvEZzGwUjgJOAs4B/jtpmP8xubAXzGPT/Al911s4A5wCV+98fDC8BQEfmIWzH/DfCruG1uBypx3rfTce7j5Wme8x6gHac+mAWcC/x9GuXqW1TVPgk+OC/2QaDB8/myu+4y4C3PtscDCoz2LNsDzHT/vwf4jWfdYJwXfqL7XYGpnm1/EVeWe4DvuP/fCdyW5jUsB/7Z/f/jwNYMrn8f8FH3/6XAE55104Em9//TgO2AeNb/NVbeBMfdBFzp+b7AvbcHgD+4yya79+QIz3ZPAv/o+T4NaANCia7NfX5nZ7v8nm0uA571fH8G+De/MnjK8au4awzFHXOT53uFu82YJO/o2QmWvwBc57PPD2PvT6IyJNh+IbDW/X8qTiPjbCAct90bwFme72M9zyfleRKc9+s4DYXYdwVO8Xy/D1ji/v9U3Dt1brLzxe4b8C0csTsf+KNbVnXLGwRageme/a4Ankl1TmA00AKUe9Z/Dng60buTz09B2FYLmIWq+oTPug88/zcBqGr8Mm8PYEvsH1U9KCJ7cVpKW+hOomUxJgKPJlrhmgtuAI7G6d1VAK8mOZZ336uAL7llUpxehNdJttPzfyNQJo5tfhywTd032yVZ63cPTuUAgDpmiyoR+XucnpMX730YF3fc9+j8saVDtsqfjGTPLV06yqmqjW7jf7D/5gkZD+wFEJETcXwDxwElQClOLychIjIa+BGd/pkATmMAVd0kIl/HEbJjReRx4F9VdTuOD+IhEfH27CKk+XxE5GjgVpzWdAXOs62L2yz+GcbuS/zvKN3n90sc89QU4sw/OO9+mO7v3Pg0znm4u+8OT+ctQHbej6xiJqC+Y2LsH9c0NByn5ZmIZClatwBHxi8UkVLgAeAWnJ5IFY5QpDQfiGPvvxqnWz3M3Xd/OvsCO4DxcWaKSUm2fxJYKOk5Sb33IVbJeM/RjiPEh/A48Nwu/ag0jg+Zlz8Z8c+tS7mAMUm2zQoiMhenkoqZDn+NY/KaqKqVwI/pfK6JyvA9d/nxqjoUR5Q77o2q/lpVT8F5Fgr8u7tqC3CBqlZ5PmWqus3nPPH8D7ABOMo97zdJ7/0D5xlO9HxP6/mp6ns4zuALgQfjVu/G6cHEv3Pb0jjnFpwewEjPvRiqnkCBQsEEoO+4UEROcW3ONwIvqGpPWgR3A5eLyFmu4228OOGTsdZdPdDu9gbOTfOYQ3Aq03ogJCLX4/QA0uF5d9+viUhYRD4JnJBk+1uBYcAvXYejiMgQHP9DMv4P+BcRmeIK6PeA36pqO/AmTov+IhEJ43TtS3NU/kxYB/yNe9x4O3E9EMWxL/caERkqIvNx/By/UtVYz28IsFdVm13/0d+mKMMQHNPnfhEZj+Nrip1jmoic6TY2mnF6ubEW/4+B74ob3CAio0SkJoNrHYITHHDQfZ//IYPLvw/n+U0QkWHAkgz2/RJwpqoe8i5U1Yh73O+KyBD3uv6VTj+B7zlVdQfwB+A/3OcScN/10zMoV59gApCcldJ1HMBDvTjWr3HMM3uBarqbO9JCHSff5cBtOK30PwGHq+oB4Gs4L+Y+nB/6ijQP+zjwe5yK9D2cH3da4qSqrcAnceyae3GiUOJbU97tdwPz3HM8i2P7X4dTAST70f+Uzi77u+7+X3WPuR/HYfgTnBbaIRxHaNbLnyHfxumt7QOW4bwDsfM24jj6n3OjWub18BwrReQAzvO6DkdgL/es/0fg39xtrsd5P5KVYRlOWO5+4BG63otSHHPSbhxzzGHAte66H+G8b39wz/UCjkM73Wu9CuedPQD8L/DbDO7B/+K8wy8Da8jg+akTibbaZ/VXcd6ld3De1V/jvIfpnPMLOI2y13Ge//14TJ+FgnQ1fRq5QETuwXFSfivfZTEMw4hhPQDDMIwixQTAMAyjSDETkGEYRpFiPQDDMIwipV8NBBs5cqROnjw538UwDMPoV9TV1e1W1W5jY/qVAEyePJnVq/0itgzDMIxEiEjC0dFmAjIMwyhSTAAMwzCKFBMAwzCMIqVf+QAMwxj4tLW1sXXrVpqbm/NdlH5HWVkZEyZMIBwOp7W9CYBhGAXF1q1bGTJkCJMnTyaDuXCKHlVlz549bN26lSlTpqS1j5mAjH7BqhV3snPpVKI3VLJz6VRWrbgz30UyckRzczMjRoywyj9DRIQRI0Zk1HOyHoBR8KxacSfH1X2LcmkFgTHUU1n3LVYBcxekPe2x0Y+wyr9nZHrfrAdgFDwT19zsVP4eyqWViWtuzlOJDGNgYAJgFDyHab3P8t19XBKj2LnnnnvYvt1vIr/EXHbZZdx///05KlHvMAEwCp5dknh2x10yMuFyw8gVPRGAQiavAiAi/yIi60XkNRH5PxEpy2d5jMJky+zFNGlJl2VNWsKW2Yt99jCM3nHjjTcybdo0TjnlFD73uc9xyy23cP/997N69WouvfRSZs6cSVNTU5d91q1bx7x585gxYwaf+MQn2LdvX7fjLlmyhOnTpzNjxgyuuuqqvrocX/LmBHbnG/0aMF1Vm0TkPuBvgHvyVSajMJm74ApW4fgCDtPd7JKRbKlebA7gIuDrv/8663auy+oxZ46ZyQ/P/6Hv+lWrVvHAAw/w8ssv09bWxuzZs6muruaSSy7hjjvu4JZbbmHOnDnd9vvCF77A7bffzumnn87111/PsmXL+OEPO8+zZ88eHnroITZs2ICI0NDQkNXr6gn5jgIKAeUi0gZUAAOnb2VklbkLrgC3wh/jfgwjFzz33HPU1NRQVlZGWVkZF198ccp99u/fT0NDA6ef7sz7/sUvfpFPf/rTXbaprKykrKyML33pS8yfP5/58+fnpPyZkDcBUNVtInIL8D7QBPxBVf+Qr/IYhlF4JGup9zdCoRAvvfQSTz75JPfffz933HEHTz31VF7LlDcfgIgMA2qAKcA4YJCIfD7BdotEZLWIrK6vTxwNYhiGkS1OPvlkVq5cSXNzMwcPHuThhx/uWDdkyBAOHDjQbZ/KykqGDRvGX/7yFwB++ctfdvQGYhw8eJD9+/dz4YUXctttt/Hyyy/n9kLSIJ8moLOBd1WdGD8ReRD4GPAr70aqehdwF8CcOXNs/krDMHLK3LlzWbBgATNmzGD06NEcf/zxVFZWAk5I55VXXkl5eTnPP/885eXlHfv9/Oc/58orr6SxsZEjjjiCn/3sZ12Oe+DAAWpqamhubkZVufXWW/v0uhKRtzmBReRE4KfAXBwT0D3AalW93W+fOXPmqE0IYxgDmzfeeIOPfOQjeS3DwYMHGTx4MI2NjZx22mncddddzJ49O69lSpdE909E6lS1m+c6nz6AF0XkfmAN0A6sxW3pG4Zh5JNFixbx+uuv09zczBe/+MV+U/lnSl6jgFT1BuCGfJbBMAwjnl//+tf5LkKfYCOBDcMwihQTAMMwjCLFBMAwDKNIMQEwDMMoUkwADMMwPDQ0NPDf//3f+S5GB7lMJ20CYBhpYFNSFg/JBKC9vb2PS5NbTAAMIwWxKSnHUE/AnZLyuLpvmQgMUJYsWcLbb7/NzJkzWbx4Mc888wynnnoqCxYsYPr06WzevJnjjjuuY/tbbrmFpUuXAvDxj3+ca665hhNOOIGjjz66IzVEJBLhqquu4rjjjmPGjBncfnv38a75SCed72yghlHwJJ2S0lJS55avfx3WrcvuMWfOBE+a5nhuuukmXnvtNda5533mmWdYs2YNr732GlOmTGHz5s1JD9/e3s5LL73Eo48+yrJly3jiiSe466672Lx5M+vWrSMUCrF3795u++UjnbT1AAwjBTYlpXHCCScwZcqUtLb95Cc/CUB1dXWHWDzxxBNcccUVhEJOm3v48OFd9kmUTvrPf/5zl2286aQffPBBKioqenNJgPUADCMlu2QUY+guArtkpM1LkGuStNT7kkGDBnX8HwqFiEajHd+bm5u7bFtaWgpAMBjMqs8gF+mkrQdgGCl4d/gpRONyJtqUlAMXv5TPMUaPHs2uXbvYs2cPLS0tXdJF+3HOOedw5513dghCvAkoX+mkrQdgDBhWrbjTnTaynl0yii2zez9t5KoVdzJzzyMEpHNZVGHdiIs4yez/A5IRI0Zw8sknc9xxx3HBBRdw0UUXdVkfDoe5/vrrOeGEExg/fjzHHHNMymP+/d//PW+++SYzZswgHA7z5S9/ma985StdtslHOum8pYPuCZYO2vAjFqnjddY2aQmvVX+nVyKwc+nUhOafnYxizNJNPT6u4U8hpIPuz2SSDtpMQMaAIGmkTi8wB7AxkDEBKAKKYRBTrirqXTLKZ/nIXh3XMAoBE4ABzkAZxJRKxHJVUW+ZvZgmLemyzM8BXAxC21f0J9N0IZHpfcurAIhIlYjcLyIbROQNETkpn+UZiOTKNNKXpCNimVTUmTB3wRW8Vv0ddjKKqAo7GZXQrzBQhLYQKCsrY8+ePSYCGaKq7Nmzh7KysrT3yasTWER+DvxFVX8iIiVAhao2+G1vTuDMid5Q2SWCpWO5CoFlDX1ennTxRvRECRCSaLdt4h2xnfvsZpeMzEoUULqYszh7tLW1sXXr1m7x9UZqysrKmDBhAuFwuMvygpsTWEQqgdOAywBUtRVoTbaPkTn9cRBTl4gegQDdK3/obt+fu+CKjtQMY9xPX3GY1kMCoc2HszgX4bB9STgcTnvUrdE78mkCmgLUAz8TkbUi8hMRGRS/kYgsEpHVIrK6vj6xo8/wJ1emkVySyGyViEJyxBaKs9hMUUYm5FMAQsBs4H9UdRZwCFgSv5Gq3qWqc1R1zqhRiX9khj/p2rALCb+IHi+FJmKFIrQDwedj9B35HAm8Fdiqqi+63+8ngQAYvSefppGe4Ge2ihFRKTgRm7vgClZBVx9Edd+bXgrJFGUUPnkTAFXdKSJbRGSaqm4EzgJez1d5CpH+bsvtKVtmL6YyblSvlwDa4/uQy3taCELbH30+Rv7Idy6grwL3uhFA7wCX57k8BUO8I3QM9VTWfYtVUNAisGrFnXyk7tsMoqVj2SFKeaP6xrTLHWtNz6m7GknQmu1N2frrPU1XtBKJZ5OWsKV6sQmA0Y28jgNQ1XWufX+Gqi5U1e5T4BQp/dGWu2rFncyqu4bB0oIIHZ/B0sLMumsyckTOXXAFDTI44Tq/5anor/c0E6duf/T5GPnDRgIXKP0xB83ENTcTksTjSsKiGVe0m2ZfT4sGuyxr0SCbZl/fo/L53dPRWl+wUTI9Ea25C65gzNJNBJY1MGbpJqv8DV/ybQIyfOiPtlw/B2Tn+u7ilci8AU7FV6317JchNKJU6qFeO1b97qkITquawjMFmVPXyCXWAyhQkoUVFmrOGb9Y+M71XWPiE5k35tRdzay6azqWDeMAZdpKXfW/97o1m+iexihUU1ChjC8wBiYmAAWKny0XKNiBPltmL8Yvs4gq3WLiE5k3ROhmRspW5Ry7p35lLMRWdaGMLzAGJjYhTD+j0HPO+OUeUgVZtj+tbRMeN4u5i/zuoSp8UIDhtvnMcWQMDAouF5DRMwrdJuxnZ/9ARnXzXaQa8NV12+z5PvzGGUiBhoYWwvgCY2BiJqB+RqHbhDMxWWyZvbjbZOuJyNTkkcpH4jWvJeoAl0srU9fcyL6l49EbKtEbKtm3dEJBmNkMI5uYCaifkau5b7NJJiaLV757Ose3rusy4EvVGTxWQWvK/eOjiN4dfgoz9zyS9v1JarKKW96qIV6u/l7B3GfDSBc/E5AJQD9kINmEe+PTSCSGUSVhhe53PL/z+5Y3zXIVYwoPo3AxH8AAorc24WxWUN5j7ZchgFKpB7vF9Pudqzc+jURRRH5OZb8xCFNp7tbaT9T695Z359KpvteTi3QTJihGrrAeQJGRTRNSomN5adUQilIqkS7nWjfiIqbsfTaj2b4SoTdUpp0rKD7CJ1HZVSGK4xjzO258DyP+3mU7Sqs/mPyMwqeoewAPv/kwb9S/Qc0xNRw94uh8FyevJEst0JnOOL2WZqqJW0qkvduycmnlxD0POZWoO9tXfIs7UfKyRK3gWQQIJZgtLFELPj7Cx28MQtfEE92PG9/DKJdWZtUt6Wjhp+rRZNqaT5oKwgTA6CVF0QP42mNf4/aXbgfgIyM/Qs20GmqOqeGE8ScQkOIKhPKfIxhaKMmopZlJHH8q2jVAAO3waQAe09JgBmlzF0Fp0hLKaE3YUlcFxd8ctJNRHKb1aZU99vNQnHrdr2cQ69l0iFuCc26ZvTjj1nx/ndPZKCz8egBFUfv95wX/yeZ/3sx/nv+fjBsyjluev4WT7j6J8beOZ9HKRTzy5iM0txfHBNR+YaRRAglbmnPqrvZNN5Eq9UMmBIl2qfy9o52HcbBbbyJZzyNCIGnlHmt9p0Mso2lA/Cv/WHnm7qn1Fdctsxf3KLFboYf9Gv2bougBxLOvaR+PvvUotRtreWzTYxxsPcig8CDOm3oeC6ct5KKjL2J4+fAslLjw8LMp+7WmvdvEt1RT+QAS4Rel4z1Ps5QwjINpH9NL7HVOdi2xHkKyFn1Pz+3XI5Fl+1O25letuJOpa26kSg8ATtrrDcPPySis1TASUbBhoCISBFYD21R1frJtc+EEbmlv4enNT1O7oZbajbXsOLiDoAQ59fBTHVPRtBqmDJuS1XNmSrajQOLDSN8dfgpz99QmdMZ6SeTI9B5rvwwGlCo9mLAijCi8NOITzN6zootjOJ5kUTiFTLsmd2gncxBvmb2Yj9Z9s1tPp0WDrBmxwHWa9/+wXyM/FLIA/CswBxiaDwHwEtUoq7ev7hCD9fXrAZgxekaHGMweOxvpw9op11EgmbTiYy1nv/DHmEgpQjDBvACxSJzB+iGDpaXbeu92/U0AYj6A+Na6qtOSj81h4PcsJ6652Xc8QqHkeTL6LwUpACIyAfg58F3gX/MtAPFs2ruJFRtXsHzDcp7b8hxRjTJh6IQOMTh98umUBBOnF84WuU7+lulAqBhRhSbKKKeZ/TKECm1M2qr3kqqCV4U2QgmjiPKJ46iOdjHjqEIjZbRKiEo9yH4ZTIm2U0Fzt8imWDbXRIP4koW0msPX6C2FKgD3A98HhgBXJRIAEVkELAKYNGlS9Xvvvde3hXTZ3bibh998mNqNtTy+6XGa2psYWjqUC4+6kJppNVww9QIqyyqzfl6/iiFblUI2I3myyT4G00K5Gz6peStj7OfRIEPYNPvbAN3MZ9V7VnYRKz+B8xPtVSvupLru6qRRS9YDMHpDwY0DEJH5wC5VrRORj/ttp6p3AXeB0wPom9J1Z2TFSC6beRmXzbyMprYmnnjnCZZvWM7KN1fym9d+QzgQ5owpZ1AzrYYF0xYwYeiEXp9z1Yo7qSbxJFvJsmNm4jPIJCNnX1Kphwgs28aqFXcyp+7qvJUjVpGXqWOyih+FXbp0Qreeiv8o4t0dz2a01jvRSkSZlSRqqUWDaU/o7vfcbSSx4UfeegAi8n3g74B2oAwYCjyoqp/326cQRwJHohFe2PoCyzcsp3ZjLW/tfQuA6rHVLDxmITXTajjusON65DfwM89EFeqqf5DwR+znM/COvo2vHDKN5EmXdg0QJNoje37MX1BKU48jgrLNQS1l8LJdXSrUTCKJDqljMku3N6MKq32eczzJnrtFERkFaQLqKITTA0hoAvJSiALgRVXZsHsDtRsdJ/ILW18AYErVlI7BZ6dMOoVQIL2OV7JBW4G4yVViJBMNvxQGq1bcyay6JSmjgDLBa/PujcAUkkNYFV4tmclRra+nvJ74crdqiBDtGZmykgl9PH7PPVVkklEcFLcAvPoq7N8PM2fC4ME9KWKP2HFgByvfXEntxlqefOdJWiItDC8fzvyj51MzrYbzjjyPQSWDfPfviQM4E5t+RIUAzvNvpKyb4zITvK9RFCfc86Sv3QM4rdPpddf36viFQrqCFIv+iU1m39OeTLoVdSZprcEcy8VGwfkAvKjqM8AzOTvBj34Ed9/t/BKOOQZmz4Y5c6C6GmbNypkojB0ylkXVi1hUvYiDrQd5fNPj1G6sZeXGlfzi5V9QGizl7CPO7vAbjB48usv+iWauSpQnx0smNn1vqOYgmokoBHrQ4o6vZILAiXseInrDQ+ySUZSGxw+Iyh/Svzci0EI5gWXbGINTQSd05qQg3Zne/J57xCdfUjZnWDP6LwXRA0iXHvcAPvgAVq2CurrOz/btzjoRmDbNEYXq6k5RGDo0u4X30BZp49n3n+0wFW1u2IwgzJswj5ppNSw8ZiHTRk4DMs/931ubfkQ784O0EKKU9l5X3IVkxulLnF7AEDYMPzutgXaJSLcHYD4AIxkFbQJKl6z6AHbu7CoIdXWwbZuzTgSOOqpTEKqrHYHIgSioKq/uepXaDbUs37icNTvWADBtxLQOv8G8CfPSSlqXKMKkN+kOUqVtMNKjpwKYzAmcKLIHEo8xGEgTCBk9wwQgHT74oLsobN3auT6RKFQmjv3vaejd+/vfZ+VGx2/w9OanaY+2c9igw1hw9AJqjqnhrClnUR4uT3i+RC3A3uTVMfJLu8LaBAJgcwQYmWIC0FN27XKEYM0a5+/q1bBlS+f6qVO7icKqP/82Kz/QhuYGHnvrMWo31vLoW49yoPUAFeEKzjvyPGqm1TD/6PmMqBgB+DuM9zGEMm3pUpZ2FYJoUZpl+hv7GMywpU7P1NvDy2SgmWGYAGST+vruPYX33+9Y3T4sRGgcMDbY+SmXXv1AW9pbeGbzM9RurGXFxhVsO7CNgAQ4dZKTtO7i31/P1ARmoqgKddX/3tEbidLz2Hyj74llEk3HtxP7KcfMfzboy4hhApBr6uudXsKaNegvr0d2RKDBc2+HCTo2hHzhxk7z0fCepZxWVep21HUkrXt116sAHKcBaghRQ5g5BBCEfQwB6EgxbBV/YZIqlXRPczaZacgAE4A+pePH2hiFHVHYEYHtEdp3QKjBkzZgypROMYiZkEaMyPh87+x7h9sfuIa6rct5jnaiAuNVuIgSajTI2RKkpCcxiEbe2YeTg2hO3dU9Fu9YuuncpBSvd9OAC5V6wHodBYoJQB+S1El3yqc7/QmxzzvvdO58+OGdYhAbq5CmKKxacScVa27iJf2A30mAP9FIoyhDFC4gxELCXECIKhODfkG7Bni9ZAbHta7rVTSWKjSnmO4zk6CFVOYo63UUHiYAfUxGoXf79nUXhbff7lzvFYVYj2FU6ikND90wlKelnVraWUE7u0QJKXycIDWEqSHExOKYFbRf0qZCKAvO+lTpIDKNKkrHHGUO6cLCBKC/0dDQXRQ2eX5QEyd2FYXqala98FCXVtwQPcAgceY6jqK8SIRa2llOOxvdCmG2BjrEYIbrNzAGDk1aQimtSaeizDTlSDrpRizVRGFR0KkgjARUVcGZZzqfGA0NsHZtV1FYvrxjdfXQAIGxARgbZMy47UTHBGGI08IPIJxEiJMIcROwUTvFYCkt3CAtTFbpEINTCRIyMeiXxNp0H8gotlQv9p1tLJYO4jCtT5imwi8NRTrpRizVRP/ABKA/UVUFZ5zhfGLs3w9r1/Lh9y5h6M79sD0KGx1HcwBgiMC4WDhqwPl/cIBpBLmaIFdTygdEWamOqejHtPIjaWWYwkWuGJxPiMEmBv0GEcfsc5jWU7rmRsLaitI1ysibU8qvQo8i1K24s5sZKFGOKi+p8lUZhYOZgAYIXbrlLepEHsU+26Owx2MDHiKd4xPGOT2GWE/hEMof3J7Bw7SzV5RShbMIUUOIiwkx1vwG/ZbYzz2KICj7ZTBhbWMQLQl9DX6+AK+Pa78MwokCOmipJgoU8wEMcFLOA9CisDMmClHYHoHdHlEYLF17CeOCtA8RnnP9BrW08Y6bPfREDbLQFYRjzG8w4DGHbv/HfAADHL/U0W+VTHfCCEsFDg85nxitrihsj3SOV9jUjjtFAKHBwuljg5w+NsB/jCtjw1h4YEiEWmnnWmnhWlo4qmPwWYiTCBI0MRhwHKaFN2WokR3yOSXkROAXwGicKucuVf1Rsn2sB5Acb66YKJ2TvWQURtjq01OIvSaDnJ7Ch2OF58bBvWMj3Dc0SlsARqlwsSsG5xCi3MRgQJDJzGRGYVJwJiARGQuMVdU1IjIEqAMWqurrfvuYAKRm1Yo7+WjdN7tNVN4rWhU+cH0JMb9CfacoRCuED8YJL4xVHhir/Hkc7B4K50qIhYSYT4iR5jfo1+xjCMOWbk2RhtomnS9UCk4A4hGRWuAOVf2j3zYmAKnpac6YjGmL9RQ8orCrUxQOVEDdWHhuHKwdCzI2wLzKEAulhCNNDAqWZDmJXhjxiW6Ty7RqCEUplUjHsp6MBO5p+nQjPQpaAERkMvBn4DhV/TBu3SJgEcCkSZOq33vvvb4vYD8ikzmBs06b21NwTUfqikJs5sn6ClgzFt4fC4PGhpg+NsyMqmBak90YuUXVGTdQSjPDOJBwG78RxYnIxHFs8xvknoIVABEZDPwJ+K6qPphsW+sBJMbbeori/yONPeo+zQjqEYUDO9pp2hFh+C4l5BZxXznsHCuUjg0ycVyI8NgQVImlLe1DvDOPrVpxp2/iuUxmNstkJHCmI5GNzCnIKCARCQMPAPemqvyNxHRpPQkEiPr+UBtkSEda6Ezo1Zy+YYEJIZgAQyhxklO3K/s/iPDGjlYObo8wcocy9fl2wlHHb9FSDoGxQcIdYxWCJgo5JtbSnrvgCvat+beEs8hlcvszGQmc6UhkI3vkTQBERIC7gTdU9dZ8laO/M3HNzd1GZPq13jZVf5upPj/uZGS93g0JleNDzBvvvH7NKE+2t7FmVxv7tkc4agfM2RHh+OcjhGOdmTK6TrAzLgjDTBRywabZ16ecfCYZmY4E9huJbOkkck8+ewAnA38HvCoi69xl31TVR/NXpP6HX+spHsVp3a0CZtRd28Vpl2/KEM4PlXD+uBKi45SXiPA72rm8vY1QvVK9Hc7dDh/bEWXMCxECMVEopVMMYoPYhgdMFHrAKk/Kh9h7EhvpK2lkJFUFRZyRwNWZOXD9xrBYOonck3cfQCYMRB9Ab6Mf0o368dpTvecE8uc0ToM3ibDCTU3xVyKEInDOLvj89iCn7RDG7ogS+CAKMT2LiYI31YWJQkqS2dvTTf+czqQzfu97RunTjYwpWCdwJgw0AchG9EOiY8Tb7JMdc9WKO5lVtyRpdEevfABZZBdRHsZJWvcH2mkWqFJYEAlxaX2Q07ZDWWysQrwojPGYjkwUuhHvtO0649cQKrTRt9fYpCWsG3FRtxDRRJPOWLRPfjABKECyFf0Q33p6d/gpTNn7bNqtKb/Q0UKp+BNxCOWPrhispJ09opR4ktYtiAQZW4+b5sINTf0gArHxcSV07ymMKF5RaNcAa6tv6miNx1fU7epMNO99T1ShQQazYfg5zN1Tm3TSGbBon3xiAlCA+FW8fT2ZRp8NHssR7Sh/9SSte9sdeHCCZ7Kb6QSQCE5aC68o7IwThTFxWVJHBArbRpZFYq3xTAIFHNu//y3yvsuF8r4XIwUZBlrsFEr0QyInXCG3/uMJIZxGiNMIcQulvK5Rd7KbNq6TFq6jhSNVqAmGqRkd4uTRYYKzSpydo+qktfCKQl0rvOgePIwjBGM8ojByYIpCubQydc2/UaUH0wosAOcdSbap910ulPfd6MQEII8USvRDfNTHLhlJqTRlHC5aCAjCsQQ5liDfpJRtGmWl2zO4g1ZulVZGqjDfNRWdGwhRMToIo4Mwyz1IVD09BdensLYVXnLXh+nsKcTSZw8QUajSg1kT/vh3uVDed6MTMwHlmXxFP6SKPnr+Py9j3p6H+k0vIB0+RHnc7Rk8Qjv7BcoUzqEzad1hfnmKYqKww5MUb2cE2tz1IVxRCHSGpY4aGKLQE7w+BS8W7ZMfzAdgdJBONEZ/9wukog3lzx6/wfuiiMLHCHbMb3A0weQHiaoz05pXFHb4iEIsAqkIRMEiewoPEwCjg3SiMdJNKteffAV+KMo6otTSxnLaedmNZjlGAx0zn51AkEA6hvF4UYjNrRDT2hCOuSm+pxDs3zcx6lYjlsmzMDEnsNFBOrlX/Bx28QnlRLzzzEIzZVTQ3K9EQRBmEWQWQZYCmzXKCtqopZ2baeUmaWWMCgtcMTiTEGV+YhAQGBV0PjPcZRoTBY+z+ZU2WO12FYLAmEDXNBcFKArJUkW/KxM5culrjIGk9nxL+1xYWA+gCPHrAexjCC2UdZlRTOLivv0q9lic+H4ZQqUeGDBWjn0oj7p+g9/TzkGBQQrnu2JwEWGG92TmM1XYG3V6CR0RSJ6eQhAYHScKh+VPFLzVRLL5Ak762j2+x0hlejRxyB1mAjI6SPRDTDSxRwxViCIEpf+8K7mgBeUpd/DZCtrZIUpQ4bQOv0GYyb2Z7CYmCjviRKHFXR/EEYFxhSEK8URUqJeRvhV4MtPjltmLbZRwDjEBMLoQH41RSvKwz4Fg688mUZTVRFnumoped/0GMzr8BmFmEUB6Oy+yKuzTroKwIwLN7voAiXsKob5/WIlSkKwbcZE7Kr0eIfE7FFVxxwLYKOFcYQJgJCWV09cEIDmbXCdyLe08R4SowMQOv0GY0wlS0lsxiBEThR2RrsLgFYXDAl0zpY7OjyhENXXQ0z4GU6kHbZRwDjEnsJEUP6dvjAYZQpm2dBstnI5pqBjEYyoBvkEp36CUeqI8rI6p6Ke08V/SRqXCha4YXECIob0RAxEYLk5Cu2PDzjJVaIjrKbzRBmtdR7NXFGLCkEVR8HvG6fmCxEYJ54mUAiAiXwV+par7+qA8Rp5INEozRpOWsGHE2Ryz9wnK1FnfIIPZVH09QNLJQ4qh8o9nFAEup4TLKaER5Qnt9Bv8n7QTVjiTIAvcPEXje+M3iCHiTJAzLE4U9ntEYXsENrR3FYVR3p5CwAlRDfftA6vUg9RVf9tGCeeBdHoAo4FVIrIG+CnwuGbJbiQi5wM/wnFv/URVb8rGcY3M8aaDGK31RHCienbJKN4dcUpnql+3bogJAUCzlFCmrUVX0adDBcICwiwgTATleY0NPmvnn6SZfwLmuEnrFhLi2Gz4DWKIOFNpVgVguo8o7IjAxnZY54qCENdTSE8UevPsd8nIhOlIMp1YxsictHwA7vSN5wKXA3OA+4C7VfXtHp9YJAi8CZwDbAVWAZ9T1df99jEfQH5IFjYabxby0qQllGHCkAhF2UAsaV07L7rRV0eodGQwPZkgoWyJQdLCuKLgdTJvj0JjbNAHTk/BO/PamJ71FDKZqyIZy9du4+bHN7K9oYlxVeUsPm8aC2eNz7g8xUKvfACqqiKyE9iJkzx3GHC/iPxRVa/uYZlOADap6jtuAX8D1AC+AmDkB7+BY1V6wDcm/AMZxZbqxbD2V8yJvmIiEIcgfIQgHyHIEkrZoVFWuD2D/6KV26SVEd6kdYQYlCsx8PYUPuLpKXzodTRH4c24nsKouJ5CGqJwUEs5IEMYo3t63MpfvnYb1z74Kk1tjmhua2ji2gdfBTARyJB0fAD/DHwB2A38BFisqm0iEgDeAnoqAOOBLZ7vW4ETE5x/EbAIYNKkST08ldEbUjmI41GEMUs3MQY4+fWjeLbpE7kr3ABhLAGuoIQrKOEAyuMdfoM2fi5tlCmc7YrBxYQYnQ2/QTJEoFKgMgDHeEThgHZNnb2pHV72iMLIQEcvQccGkbFBKHFEoVFLuK79S9QNPYfnlpyZctSwHzc/vrGj8o/R1Bbh5sc3mgBkSDo9gOHAJ1X1Pe9CVY2KyPzcFKvLee4C7gLHBJTr8xndSeQgbtQSmrSEEdJ97MBOGcE49//tDU1sKxnJBNndbTvoHiaYLN1AsfQihiBcQphLCNNGGX/RzqR1D0s7onCSJ2ndtFRJ63pIt3suAkMFhiYQBU9PQd9pR15RBGeyGEYGaBxbweOHfZQdo6vYN3pvr8q1vaEpo+WGPykFQFVvSLLujV6cexsw0fN9grvMKDDiHXQ7GMG/t30GgJvCP6EiThhul7/l++73cVXl/ODDz3Bz+M5uo4xbNcT/RT7OWYF1jJM9bNcRPBmdyaeDf+52zN9FTuu2vBhEIYxwppt/6IeU8opnsptrpIVraGGaBqhxU1qfmG7SuhREFJ6LHsspgfW+A7iArqIwLYwq/CV6LFftvZLjP9jE8Ts3cdzOTRz/7tt88tUn+SRPEkXgsWlQXd35mTULhgzxLY/X5h8QIZLAdzmuqrzX111s5G0gmIiEcJzAZ+FU/KuAv1XV9X77mBO4MJiy5BFib82CwLNcHbqvowL/QftnWBE9BcH5QZ5xzCgeqNvGOZE/cUPoFwx3ewz7GMzSti+wInpKt+P7HTN++ZPRmR3i0cAgBushwkWUruJ9HL/BCmnjGSK0C4x2/QYLNcRZCZLWtSGESX6PDmop17V/qePZeO/7Ph3kuAw45NxzGgnTORfwX6LH8oW26xIed9TBvRy/0xGFvwnWM3bTeti+3VkpAkcf3V0Uhg7tZvNPRHk4yPc/ebyZgHwoyJHAInIh8EOcMNCfqup3k21vAlAYnHzTU2xLs7tdHg7yqerxPL2hvkvEBsA3fvcykWjxVNi5JMpBmoJ1NAZeoCm4GpUmRMsoj86mPHIi5ZG5BBma72J2EBC49TMzWTg2CGvWQF1d52fr1s4NjzqKP1RM5KXhk3ltzFTWjz6SA6WDAAiKEFW1KKA0KEgByBQTgMJg+dptfP2369LefnxVOc8tObPLskxExMgMpY3mwCs0Bl+kKfgCEdkLGqA0eiwVkXmUR08krPkfXhUOCjdf8tFuFfdjT6zjiXsfY9zbrzNnz7sctWUj4w50+pDeGTaO18ZM5bXRU/nm9Z+H2bOhsrKvi9+vMAEwekV83HWmlbcAleVhRKChsS2FEcLIFkqUVtnkisHztAXeByAcnUxF5ETKIydRokdmb/BZhsQ3DvzMPSMONXDcB287/oQPHL/ChA89kWlTpzpCUF3Ns0MP58Yd5bzZErTegYsJgNFjEv0oOyI8jH5Fm+ygKfgCjYEXaQm8DhIlGB1JefREKiInUhY9HiHcZ+UR4N2bLur4nm7PMBwQfnT2BC5s29HVfPReZ7Di5qqxvDZmKhvGHcVJnz6Hkz9zLgwfnovLKHhMAIwe4/ejjBeBcFBAoa2P7friFqT/vMmFQYT9NAVX0xh8nubAWlRaEK2gPFJNRXQe5ZE5BBiU83KM97TSvQEGyfAzH1347YcY8eZrndFHH7zNxP0fdG4wZUpXR3N1dVGIggmA0WOS/SjHV5V3c+7GTEX9580yorTQHFhHU/BFGoMvEZUG0BBl0eMdU1H0REI6KqdlqCp3eh4NTW1pbZ/It5ToXa1q+pDjd77NL2eFOnsK777bucHkyd1FYcSIXlxJ4WHpoI0e42fzT/QDhM7h+JOXPJLzshnZIUApFdETqYieyPC2CC2BN2kKPE9j8EX2lvwY+DEl0SMpj8yjIjKPsE7Out+goamNcFAIByStXmSigV+J3tWG8qG8M+tjsOTMDl/WoR27OP3QFhYN2sexO992ROGBBzp3Ovzw7qIwcmSvr7HQsB6AkZJEPoB04q5n/dsf2NeYXmvOKFzaZAuNwRdpDD5Pq7wJooSio12/wTxKo8ciWRyNPKzCGVCWqieQqAGSzF9VVR7mUGs7bZHOOq/Le7xvH6xd29lLWL0a3vbku5w0qbsojMptryhbmAnI6BU9yb64fO02Ft//cpcfXAyRrhONexlWEeaiGWP59YvvY8MECosI+9yIohdpCqwDaSOggymPzKU8Mo/y6GwC9G5ErgC3fXYmi3/3sm9PIFkDJPaubmtoSitYwa8nC0BDQ1dRqKuDt97qXD9xoiMEs2fDnDnO/4cdls5l9ikmAEaf4RULb+inVziSjSWI/SC9P2Sj8IjSRHNgLY3B52kKriIqB0HDlEc/6pqKTiTIsIyPO95N6eD33Men2QBJN6IoPhIpJfv3dxeFN9/sXD9hQveewujR6R8/B5gAGH1CJuYiPx9B/A/SfAmFjxKhJbCeRjfENBL4AFQo0aOp6PAbTEx9oBRkUlmnG1GUtAeQLh9+mFgUYvXruHFdBWHOHBjTd4PxTACMPsGv1ZVo2H464aXp2oONwkFR2mQzjcEXaAq+SGtgEwCh6Hg3omgepdFpPfIbVJWHGVQaSssUmU4PIKc5hA4c6C4KGzd2isLYsd17CuPGJT9mDzEBMPqEdFpdsR8dkDLJF0AwIARIPb7ABqcVJu1ST1PgRRqDL9IceAUkQkAr3ZHIJ1IWnUmA0h4dO5UvIP79CgeEwWWhbibJPuPAAVi3rlMQ1qyBDRsg6ibUGzMmsSj0Mu2tCYDRJ6Rrd4238ydL8wtOT6CiJOQ75iC27F9+u85EoICJcsgZfBZ40U1a14hoKWXRWU6eoshcgmSW1ycown98pvugMOgnU0ceOtRVFOrq4I03OkVh9GhHCJYuhblze3QKEwCjT0gndS8ktuUm6z342X7jf+CNre0WetpPcJLWvepJWrfHTVo3nYqok6co3aR1Ay4ddEwUvJlSf/Yzx3fQA2wgmNEnxH6APZm8I1mSuUTbJ5obNhzIT1IzI3OEsJOuOjobbbuSVnnbyVMUfIF94bvZF76bcHRSx+CzEp2K+EyFOeCmhBw0CE4+2fnkEBMAI+ssnDW+44foFxUUM+F4WXzetISx3+GgJNx+2cr13XoafZ2HyMgOglCqUyltn0pV++dpk52u3+AFPgzdz4fh+wjqcMojzuCzsuiMbknrbErIzDEBMHJKfI8gmR02tmzpivUdUT/DKsLccPGx3bZfvnabmXoGMGEdQzhSw9BIDRE+pCm4mqbgCxwKPs3B0GOIllMemeOaiuYQYLBNCdkD8uIDEJGbgYuBVuBt4HJVbUi1n/kAjBjJnM2DSoIcak3ugzD6J07SuldoCj7vSVoXpCx6PCOCH0Oa5zCp8nDOOGZUt1noemIe6hdO5DQoNB/AH4FrVbVdRP4duBa4Jk9lMfohySKN+lNgg5EZTtK6uVRE5zK8LUprYCONrqloG/8NZbCr6UjWr3ZMRWGmsK2hiWsffBUgaeUdX9nH5rP2+pjSOU5/Iu9RQCLyCeASVb001bbWAzBiHHnto74ho8bAZ1BJkMbWCJXl4Q5zYZtsdQafBV6kJbABRAlGD3PNRPM4Ysgcnr/23ITHy2TSo6yMHO5j/HoAiV3qfcv/Ax7zWykii0RktYisrq+v99vMKDKs8i9uouokjBtU2mnECOsEKtsvYUzrzUxo/gXDW79GiU7mYPBxdpVex0stn+LzD36e+1+/nwMtB7oc7+bHN3YLKPB7wwaSszlnJiAReQJIFMR7narWuttcB7QD9/odR1XvAu4CpweQg6Ia/ZDxPZiX2CgswgEnRLgngVuxsE+/yjjIMIZEzmVI5FyiNNMcWAvlq/j9pt9z76v3UhIs4awpZ1EzrYYF0xZkVKkPJGdzznoAqnq2qh6X4BOr/C8D5gOXar7tUEa/Y/F50ygPZy8HfYzxVeVsvumijoyURvYRnPt886c/yq2fmdnjex2z1aciQBkjgqdw1/yfsvOqnfzpsj/xlblfYeOejVz5yJWMu3UcuysWsz90H22yBfW0/eNHlfiFMPdX8hUFdD5wK3C6qqZt1zEfgOFl+dptLFu5PmvhoN7RpOlmkkyEd66DinCAxrZoVso3EPCzn6c7gjz+WGccM4pfvfB+t3VHHTaIxtZo0ugdVWV9/XpqN9Ryz9rfsanhZQBC0XFUROZRJSdx6eyz+dPGvQM2CihfArAJKAX2uIteUNUrU+1nAmAkIhvzBsTnmJ/+7cd6VHEnSkmQbn6kgUb81I7hgHDzpxPn7AHnOX7jvpfT8u/E7nOy557uvAEx7v7rar739K/Y3vIXWoKvoLQzqmIU84+ez8JjFnL2EWdTEa5I61iFRkEJQE8xATCS0dNWe3yeoWST1SRjfFySum0NTQTdVBjFlqlUgEBAiHgFICjcfElXAUgUevnbVVu6zSIXEBhaFmZ/U9csnqmeeXk4yKeqx2c8JuDDlg/5/abfs3zDch5961H2t+ynPFTOuUeeS820GuYfPZ9Rg/rHdJBgAmAUAT1tacfnmM80odwPPzszaeqLGMUmAonwmoD80oR8qno8j7yyo+MZVJWHWbqg+2hwSO+Zx9/3TBPHtUZa+fN7f6Z2Qy21G2vZ8uEWAhLgYxM/Rs20GhYes5Cpw6emdax8YQJgDHgS5n8PCoNKQkknlAkHJeG8xelQVR5m3Q2dseXFau5JF29vy+9eZRJn3xPfQabn8KKqrNu5juUbllO7sZaXP3D8BtNHTadmWg0102qYO34uASmECPtOCm0ksGFknWR5h/wqipKg0NrDyl+ApQuO7bJsIMWI5wJv1I7fvcrkHnqfeSbC29PnJCLMGjuLWWNnseyMZWxu2MyKjSuo3VjLD577Ad9/9vuMHTyWBdMWUDOthjOnnElpqGeT3fQF1gMwioZvLX+Ve194P2tmmESRJjaJvT/xppdk04f6TfCSjHyP5t3btJdH33qU2o21/H7T7znYepDBJYM5f+r51Eyr4aKjLmJY+bCsnjNdzARkFD09Nc8EfeY0SGRbnj2pkufe3tvzQiagPBygqR+GkqaafjGZ+aanE7ykyufTm2NnQnN7M0+/+zS1Gx2/wc6DOwlKkNMnn95hKjq86vCcnT8eEwCj6OlJlFBsIFC6+/mJRbr4TX2Zbsu2UEi3FZ8s9DNbrfR8Z/SMapRV21ZRu7GW5RuW88buNwCYOWZmhxjMHDMT6eW8v8kwATCKHr8eQFV5mAPN7b6VECTPPppN0p36MtfliReYmDM9FoaZqGUdI76FnaoC9hNmv3vR33lrz1sdPYPn3n8ORZlUOYkFRy9g4TELOe3w0wgHw6kPlAGFnAzOMPqEROkjysNBli44lv/4zEcTrlt83rSM0k4Ee9mK80ttsHDWeJ5bcibv3nQRzy050zd9QiyVxbCK5BXIsIpw0mPc9lknRUNH2oZLPsrSBccyrqqc7Q1NPL2hnk9Vj+84Ruy6x1eVd6v8r33wVbY1NKF0plRevnZbymseSDl3vBw14iiu+thV/OXyv7Dzqp3cveBuZo6Zyd1r7+bsX57NYbccxqUPXsp96+/jw5YPc1oW6wEYRUWy1mi66/zmOQY4+cjhPfYBZGKb9ouhj+0/c9kffENfYwOyoLtpya8Mqc7nRzqhnsmct5mO5u3PNLY18se3/0jtxlpWvrmS3Y27KQmWcMbkM6iZVsOnpn+KwwYd1qNjmwnIMLJEMl/C+KpyDrW0Jx134KU3FV0ywUpWRu/YhW8tf5X/e3ELEVWCInzuxIl8Z+Hx3fbpScx+shHViUZfxyKoejtwayAQiUb465a/dpiKNu3dxGOXPsb5U8/v0fFsHIBhZIlkNvjtDU3c9tmZaQ9O6k0rd+Gs8b77JCvjfleclq/dxgN12zp6MxFVHqjbxpzDh3c7bqYx+7FWvR/x5p3YtSQSmljq5/4iANlwOgcDQU49/FROPfxUbj7nZt7Y/QZHDjsy62U1H4BhZMji86Z1SxMco7I83DG5iNcuXlXub5NPZBfPZRljlW+iSVBila3fPukuT3TsGMlSKmdjcFg+ScfnkSkiwvRR03MyoMwEwDAyZOGs8Vw6b1K3CjYcEA61tne0YCOqHZXd/hQmoaa2CF//7TpOvumprAiBXxm9lW8mla2fAz3Tihzo5iQ++aanmLLkEU6+6SmqfJzXfsszIf5c2RTcGJmIaiFgJiDDSJP4rv2l8yZ1yTKZKIlc7MefbujmtoYmFv/uZZatXO87gCpdvrPweOYcPtzXHOFXpkSt+mRpNhLhd+zxVeW+ifO2NTQRDgjBuCyiAAeb21m+dluPzUCJzpWLCd77Ww/GnMCGkQbpRMEki2e/7bMzWfy7l7vkx0+XbDhBvU7W2GC1YRVhDja3dylTthyu6dwvP8dyLtI3ZCPxXCGdJ1MKchyAiHxDRFRERuazHIaRinS69n728KqKMMtWru9R5Z/oPJnitUsDHU7ffY1ttEW1w0wUH8Of6pjJzCkLZ43n+588vstYgvhj+7WKczEZe1+1zDM1leWbvJmARGQicC7QfT43wygQUs025q1AFp83LWE66vhWdk/oTUWVzCELToUbq6R6MgbBz5ySLEoJ/M1Efuk0ejMwLBNzV2/I1FSWb/LZA7gNuJrCTmliFDHxLedEeCuQRK3eQSWhlJV/OqOMe1NRpSMemfQysuXo9Gstf+7EiVlvRfdlyzx+1HahVv6Qpx6AiNQA21T15VQJkERkEbAIYNKkSX1QOsNwSNVyTlSBxLd6pyx5JOk5YmMAlq5Y7zt4rLcVVSYO6ClLHknZas2WOSVZazmZ87on9LeWeV+RMwEQkSeAMQlWXQd8E8f8kxJVvQu4CxwncNYKaBgpSFahpTt4K1nl663YD7W29+o8yUhkmvLDG7sOiSNksmlO8TMTpTIf9YRcHLO/kzMTkKqerarHxX+Ad4ApwMsishmYAKwRkURiYRh5w69Ci0V0pFOZ+CWSqyoPdzhFl61cn3BKymEV4ayYEGKmqUwS1SUz6fQ3R6fhT5+bgFT1VaAjo5ErAnNUdXdfl8UwkpGo5ZxpRZeO6cFvAvpMJqZPtxyZzJ/r1wMyc8rAwQaCGYYP8fPNBkW6tIz9KrxEuWDyGQMeI1beZP4GL8lMOmZOGRjkPRWEqk621r9RqCycNb7D5BELTUyW36UnuWD88gQlyx/UGwaVOu2+mEloWEWYcKCrechMOsVB3gXAMAqdTMIeexIiuXTBsd0q4HBAWLrg2F6UujuJBoSVh4PccPGx3PzpjyYdtGUMTMwEZBgpyCTssSchktm0qSdLRewnTktXrGfdDecmPF++59M1cosJgGGkIJOwx56GSGbDpp5qhK6fCDU0tSVMtNZXCdSM/GEmIMNIQSZhj/kMkUxlfkomQtkyZxn9CxMAw0hBOonNerJttkllfkomQol6Lf0ttbGROWYCMow0yMREk68QyVTmp4WzxvOv960jUWqiRIPE+iqBmpE/rAdgGAOEdMxPfnnpEmXftBG/Ax/rARjGACGdaKLxSWbq6snxjP6NzQhmGEVEOjN1GQMPvxnBrAdgGEWEteoNL+YDMIwiwgZ2GV6sB2AYRYIN7DLisR6AYRQJNrDLiMcEwDCKBBvYZcRjAmAYRYLfAC4b2FW85E0AROSrIrJBRNaLyA/yVQ7DKBZsYJcRT16cwCJyBlADfFRVW0TksFT7GIbROywE1IgnX1FA/wDcpKotAKq6K0/lMIyiwqZyNLzkywR0NHCqiLwoIn8Skbl+G4rIIhFZLSKr6+vr+7CIhmEYA5uc9QBE5AlgTIJV17nnHQ7MA+YC94nIEZogL4Wq3gXcBU4qiFyV1zAMo9jImQCo6tl+60TkH4AH3Qr/JRGJAiMBa+IbhmH0EfkyAS0HzgAQkaOBEmB3nspiGIZRlOTLCfxT4Kci8hrQCnwxkfnHMAzDyB15EQBVbQU+n49zG4ZhGA42EtgwDKNIsWyghpEES59sDGRMAAzDB0ufbAx0zARkGD5Y+mRjoGMCYBg+WPpkY6BjAmAYPlj6ZGOgYwJgGD5Y+mRjoGNOYMPwwdInGwMdEwDDSIKlTzYGMmYCMgzDKFJMAAzDMIoUEwDDMIwixQTAMAyjSDEBMAzDKFIsCsgwjD7FEuwVDnnpAYjITBF5QUTWuRO+n5CPchiG0bfEEuxta2hC6Uywt3zttnwXrSjJlwnoB8AyVZ0JXO9+NwxjgGMJ9gqLfAmAAkPd/yuB7Xkqh2EYfYgl2Css8uUD+DrwuIjcgiNCH/PbUEQWAYsAJk2a1CeFMwwjN4yrKmdbgsreEuzlh5z1AETkCRF5LcGnBvgH4F9UdSLwL8DdfsdR1btUdY6qzhk1alSuimsYRh9gCfYKi5z1AFT1bL91IvIL4J/dr78DfpKrchiGUThYgr3CIl8moO3A6cAzwJnAW3kqh2EYfYwl2Csc8iUAXwZ+JCIhoBnXxm8YhmH0HXkRAFV9FqjOx7kNwzAMB0sFYRiGUaSYABiGYRQpJgCGYRhFiqhqvsuQNiJSD7yX73L0gJHA7nwXog8ptusFu+Ziob9e8+Gq2m0gVb8SgP6KiKxW1Tn5LkdfUWzXC3bNxcJAu2YzARmGYRQpJgCGYRhFiglA33BXvgvQxxTb9YJdc7EwoK7ZfACGYRhFivUADMMwihQTAMMwjCLFBKAPEZFviIiKyMh8lyXXiMjNIrJBRF4RkYdEpCrfZcoVInK+iGwUkU0isiTf5ck1IjJRRJ4WkddFZL2I/HPqvfo/IhIUkbUi8nC+y5ItTAD6CBGZCJwLvJ/vsvQRfwSOU9UZwJvAtXkuT04QkSDwX8AFwHTgcyIyPb+lyjntwDdUdTowD/inIrhmcOYweSPfhcgmJgB9x23A1TjzIQ94VPUPqtrufn0BmJDP8uSQE4BNqvqOqrYCvwFq8lymnKKqO1R1jfv/AZxKcUAn+BeRCcBFDLDJq0wA+gB3GsxtqvpyvsuSJ/4f8Fi+C5EjxgNbPN+3MsArQy8iMhmYBbyY56Lkmh/iNOCieS5HVsnXhDADDhF5AhiTYNV1wDdxzD8DimTXrKq17jbX4ZgM7u3Lshm5R0QGAw8AX1fVD/NdnlwhIvOBXapaJyIfz3NxsooJQJbwmwNZRI4HpgAviwg4ppA1InKCqu7swyJmnWTzPgOIyGXAfOAsHbgDTrYBEz3fJ7jLBjQiEsap/O9V1QfzXZ4cczKwQEQuBMqAoSLyK1X9fJ7L1WtsIFgfIyKbgTmq2h8zCqaNiJwP3Aqcrqr1+S5PrnCnNX0TOAun4l8F/K2qrs9rwXKIOC2ZnwN7VfXreS5On+L2AK5S1fl5LkpWMB+AkSvuAIYAfxSRdSLy43wXKBe4ju6vAI/jOEPvG8iVv8vJwN8BZ7rPdp3bOjb6GdYDMAzDKFKsB2AYhlGkmAAYhmEUKSYAhmEYRYoJgGEYRpFiAmAYhlGkmAAYhmEUKSYAhmEYRYoJgGH0AhGZ6855UCYig9z8+Mflu1yGkQ42EMwweomIfAcnR0w5sFVVv5/nIhlGWpgAGEYvEZESnBxAzcDHVDWS5yIZRlqYCcgwes8IYDBO7qOyPJfFMNLGegCG0UtEZAXOTGBTgLGq+pU8F8kw0sLmAzCMXiAiXwDaVPXX7vzAfxWRM1X1qXyXzTBSYT0AwzCMIsV8AIZhGEWKCYBhGEaRYgJgGIZRpJgAGIZhFCkmAIZhGEWKCYBhGEaRYgJgGIZRpPx/4Dp4IB/MNz4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution for generating feature vectors\n",
    "d, k = 1, 1\n",
    "w = Uniform(-1, 1)\n",
    "m = MultivariateNormal(ch.zeros(d), ch.eye(d)/d)\n",
    "# m = Uniform(-5, 5)\n",
    "phi = oracle.Left(Tensor([0.0]))\n",
    "# phi = oracle.Identity()\n",
    "\n",
    "# generate ground truth\n",
    "gt = ch.nn.Linear(in_features=k, out_features=1)\n",
    "gt.weight = ch.nn.Parameter(w.sample(ch.Size([k, d])))\n",
    "\n",
    "# gt.bias = ch.nn.Parameter(ch.ones(1, 1)) if args.bias else None\n",
    "gt.bias = ch.nn.Parameter(w.sample(ch.Size([1, 1]))) if args.bias else None\n",
    "\n",
    "print(\"gt weight: \", gt.weight)\n",
    "print(\"gt bias: \", gt.bias)\n",
    "\n",
    "# create base classifier\n",
    "with ch.no_grad():\n",
    "    # generate data\n",
    "    X = m.sample(ch.Size([args.samples, d])) if isinstance(m, Uniform) else m.sample(ch.Size([args.samples]))\n",
    "    y = gt(X)\n",
    "\n",
    "noise_var = ch.ones(1)\n",
    "noise_scale = ch.sqrt(noise_var/2)\n",
    "laplace = Laplace(ch.zeros(1), noise_scale)\n",
    "# remove synthetic data from the computation graph\n",
    "with ch.no_grad():\n",
    "    # add noise to ground-truth pedictions\n",
    "    noised = y + laplace.sample(ch.Size([X.size(0)]))\n",
    "    # truncate based off of the standardized data\n",
    "    indices = phi(noised).flatten().nonzero(as_tuple=False).flatten()\n",
    "    y_trunc, x_trunc = noised[indices], X[indices]\n",
    "    alpha = Tensor([y_trunc.size(0) / args.samples])\n",
    "    print(\"alpha: \", alpha)\n",
    "    \n",
    "# ground-truth OLS\n",
    "gt_ols = LinearRegression()\n",
    "gt_ols.fit(X, noised)\n",
    "print(\"gt ols coef: \", gt_ols.coef_)\n",
    "print(\"gt ols intercept: \", gt_ols.intercept_)\n",
    "\n",
    "trunc_ols = LinearRegression()\n",
    "trunc_ols.fit(x_trunc, y_trunc)\n",
    "trunc_ols_pred = trunc_ols.predict(x_trunc)\n",
    "print(\"trunc ols coef: \", trunc_ols.coef_)\n",
    "print(\"trunc ols intercept: \", trunc_ols.intercept_)\n",
    "\n",
    "# data for plotting regressions\n",
    "unnorm_data = np.linspace(-5, 5, 100).reshape(100, 1)\n",
    "norm_data = np.linspace(-1, 1, 100).reshape(100, 1)\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(X, noised)\n",
    "plt.scatter(x_trunc, y_trunc)\n",
    "plt.plot(unnorm_data, gt_ols.predict(unnorm_data), color='green', label='gt ols')\n",
    "plt.plot(unnorm_data, trunc_ols.predict(unnorm_data), color='red', label='trunc ols')\n",
    "plt.legend()\n",
    "plt.title(\"Empirical and Ground Truth Dataset and Model\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to standardize our truncated dataset, so that our empirical estimates are located on the l2 ball. First we will divide all of our covariate features by $B\\sqrt{k}$, so that all of our covariate features $||x_{i}||_{2}^{2} \\leq 1$, and reside on the $\\ell_{2}$ ball. This way the norm of $w$ will be multiplied by $B\\sqrt{k}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max truncated x norm tensor(4.0143)\n",
      "beta:  tensor(4.0143)\n",
      "x max l2:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "max_x_trunc_norm = LA.norm(x_trunc, dim=-1, ord=float('inf')).max()\n",
    "print(\"max truncated x norm\", max_x_trunc_norm)\n",
    "\n",
    "beta = max_x_trunc_norm*math.sqrt(X.size(1))\n",
    "print(\"beta: \", beta)\n",
    "\n",
    "x_trunc_norm = x_trunc / beta\n",
    "print(\"x max l2: \", x_trunc_norm.norm(dim=-1).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now observe that the norm of the truncated x covariates is bounded by 1. So, now we will standardze our dependent variable so that it's ground-truth takes the form of the linear regression latent variable model with noise variance of 1. First, let's calculate the predicted values from our naive ols regression on teh truncated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will standardize our data for the case where we assume that the empirical noise variance is the underlying noise variance of the ground truth regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp noise var:  tensor([0.6316])\n",
      "trunc reg noise var:  tensor([2.0522])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emp_noise_var = (y_trunc - trunc_ols_pred).var(0)\n",
    "print(\"emp noise var: \", emp_noise_var)\n",
    "emp_noise_scale = ch.sqrt(emp_noise_var/2) \n",
    "\n",
    "emp_stand_y_trunc = y_trunc / emp_noise_scale\n",
    "trunc_noise_var = (emp_stand_y_trunc - (trunc_ols_pred / ch.sqrt(emp_noise_var))).var(0)\n",
    "print(\"trunc reg noise var: \", trunc_noise_var)\n",
    "\n",
    "new_X, emp_stand_noised = X / beta, noised / emp_noise_scale\n",
    "\n",
    "gt_emp_stand = LinearRegression()\n",
    "gt_emp_stand.fit(new_X, emp_stand_noised)\n",
    "\n",
    "trunc_emp_stand_ols = LinearRegression()\n",
    "trunc_emp_stand_ols.fit(x_trunc_norm, emp_stand_y_trunc)\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(new_X, emp_stand_noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc_norm, emp_stand_y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(norm_data, gt_emp_stand.predict(norm_data), color='green', label='gt ols')\n",
    "plt.plot(norm_data, trunc_emp_stand_ols.predict(norm_data), color='red', label='trunc ols')\n",
    "plt.legend()\n",
    "plt.title('Y Scaled by Empirical Noise Variance')\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will standardize our data for the case where we assume that wee know the underlying ground-truth noise variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trunc reg noise var:  tensor([1.2631])\n",
      "reg noise var:  tensor([2.0303])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEWCAYAAACNJFuYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABwl0lEQVR4nO29d5wdV3nw/31mbt3epVWXC7bV3WQcN1ludEyABAKhGHAcal4CmIRmiHmDA6EmfsEEY0oAJ/YPx4TQLLlgYzC2I1m2XGRp1VfaIm2/bWae3x8z9+69u3d73z3fz2ele6eemTtznnOeKqqKwWAwGAz5WDPdAIPBYDDMPoxwMBgMBsMgjHAwGAwGwyCMcDAYDAbDIIxwMBgMBsMgjHAwGAwGwyCMcFjAiMgqEVERCU32viKyX0SunHgrZz8icpOI/HAGzjtt91hELhGR56fjXONFRN4iIr+e6XbMF4xwmCFE5Ici8t0Byy4TkXYRaSyy/TIRuVtE2kSkU0SeFpF3TFuDZxARKReRLwedYa+IHBSRu0Tkgplu23CISE/enyciibzvbxnjse4QkZsn0JZ3BML8YwOWHxaRLSPtr6q/VdUzxnv+Iu1ZKiKOiJxaZN1PReRLYz2mqv67ql49OS00GOEwc3wIeLmIXAUgIjHg28Dfqmpzke1/ABwCVgK1wF8Cx6eprTOGiESB7cB64FVABXAW8BPg5UPsM+aZ0FSgqmXZP+Ag8Oq8Zf+e3W4a23sC+JiIlE/T+YZEVY8A2/Cf4xwiUgO8AvjeWI43W37z+YQRDjOEqrYDHwBuE5FS4DPAXlW9Y4hdzgfuUNVeVXVU9X9V9RfZlSJysYj8TkQ6RORQdlYhIq8Ukf8Vka5g+U1DtUlEKkXkOyLSLCJHRORmEbGDdbaIfCmYuewDXjmKyzxfRHaLyEkR+W4gAAlmPa/OO284OO7ZRY7xl8Ay4FpVfVpV3eAe3KWqN+UdQ0XkfSKyB9gTLHuPiLwoIidE5F4RWRIsH6QSE5EHROTdwed3iMjDwfWeFJEmEXl53rarReRBEekWkd8AdaO4FzlEZEswYr9RRI4B382ec8B2KiKnicj1wFvwO/YeEflZ3mabROSpYDZ5Z/YeD8GzwKPAh4doV1REvioiR4O/rwbCOdfmvG1vDJ6RbhF5XkSuCJZbIvJxEdkr/iz4P4IOvxjfY4BwAN4E7FbVXXnH6Q6eo9flnf8dIvKIiHxFRNqBmwbeQxH5WvDMd4nIEyJySd66m4K2fT84/jMicl7e+uUi8v+JSGtwHf+St+46EXk2eDZ+JSIrh7nncxdVNX8z+AfcDdwLtAPLh9nuPuAR/JdnxYB1K4Fu4M1AGH9msSlYtwV/1G0BG/BnG9cG61YBCoSC7z8FvgWUAg3AY8BfBetuAJ4DlgM1wP35+xZp737g6bztHwFuDtZ9DLgzb9vXAruGOM5P8IXiSPdRgd8E54oDW4E24BwgCnwDeKjYdQfLHgDeHXx+B5AB3gPYwF8DRwEJ1j8KfDk47qXBvf/hCO3bD1yZ95s4wC3BMeLBOR8uck2nBZ/vyN6/Acd8DFgSXPezwA1DnP8dwMPAJuAkUBMsPwxsCT5/Dvh98NvXA78D/iGvzYeDz2fgz2KX5N3PU4PPHwqOsSy4tm8BPx6iTXGgE7g4b9mjwN8En98YXJsF/DnQCzTmXY+DP8AKFbuHwFvx34UQ8LfAMSAWrLsJSOLPUmzgH4HfB+tsYCfwFfx3IZZtI/6z+iL+7DUEfBL43Uz3I1PxN+MNWOh/wCKgB/jQCNtVA18AngFcYAdwfrDu74CfjvJ8XwW+EnxeFXRAoaAdKSCet+2bgfuDz9vzOx7gakYWDvnbvwJ/ZkTwwncDFcH3u4CPDXGc+4Av5H3fBHQAXcDzecsV2Jr3/TvAP+V9L8Pv8FcxOuHwYt66kmD7xcCKoFMqzVv/I8YuHNLZjirvnOMRDm/N+/5PwDeHOH/u+MB/ALcEn/OFw17gFXn7XAPsz2tzVjicBrQAVwLhAed5Frgi73tjcN+Hek7+Dbgt+Hx6cF8ahth2B/DavOs5ONQ1DrH/SWBj8Pkm4L68dWuARPD5QqC1WJuBXwDvyvtuAX3AytG8f3Ppz6iVZhhVPY4/wn1mhO1OqurHVXUtfke+A7hHRAR/dL632H4icoGI3B9MjzvxZwDF1CAr8WcdzYFqqgN/1NcQrF+CP1rMcmAUlzdw+yXBtRzFn0m8XkSq8G0H/z5ob592/A6GYN8dqloF/Cn+yHSo8y3Jb6Oq9gTHWjqKdoM/yszu2xd8LAuOe1JVe/O2zZ1HRL4p/Ubnvx/m+K2qmhxlW0bVTvxOqmwU+3wa+GsRWTRgecE9I+83y0dVXwT+Br+DbRGRn2RVdvjP0U/znqFn8QczA8+V5XvAGwN12F8Cv1LVFgAReZuI7Mg71joKn91Dg46Wh4h8JFD/dAb7Vw7Yf+C9iwWqxuXAAVV1ihx2JfC1vDadAITRP1dzBiMc5iCq2gZ8iX51wiFgkNdHwI/w1VbLVbUS+Cb+wzyQQ/gzhzpVrQr+KgJhBNCM/9JkWTGKpg7c/mje9+/hT/vfCDyqvoGyGNuAq8W3y4xEforho/gvMgDB/rXAEXz1BPgzgiyLR3F88O9D9YD25O6Fqt6g/Ubn/zvKthK0KdceERnYnklLn6yqzwH/H/CJAasK7hmDf7P8Y/xIVS8Otld8FRn4z9HL856hKlWNDfP7Pozfwb4W/3n4HkCgx/828H6gNhgQPE3hszvkPQnsCx8D/gyoDvbvpPizP5BDwAopbuQ+hK9qzb++uKr+bhTHnVMY4TBHEJFbRGSdiITE9zb5a3zVRzv+qPtKEfmzYH2tiGwKdi0HTqhqUkQ2A39R7Pjqe0j9GvhnEakIDIunishlwSb/AXxQfJfaauDjo2j2+4Lta/A7ojvz1t2Dbw/4EPD9YY7xffwO+afB9dvBKPO8YfYB+DHwThHZFBhV/y/wB1Xdr6qt+ELircHxrmNo4VqAqh4AHgc+KyIREbkYePUIu42GncDaoL0x/FF5PseBUybhPFk+C7wTqMpb9mPgkyJSLyJ1+DOMQfEbInKGiGwN7msSSABesPqbwOezRtrgWK8dqhHq62a+jy9cqoCssb0Uv/NvDY7zTvyZw2gpx1f/tQIhEfk0vqfbaHgM/5n7goiUikhMRC4K1n0T+DsRWRu0q1JE3jiGds0ZjHCYO5TgG4w7gH34I7bXAKjqQXyd/t/ij8J2ABuD/d4LfE5EuvFf9v8Y5hxvAyLAbnz97F30q3S+DfwKvxN7En/kORI/whc4+/DVXjk/fVVN4BvjVw93rED1cnnQpp8T2Brwvbf+bJj97gM+FZyjGb/zf1PeJu8BPoqvalqLb3wdLX8BXIB/rz/D8MJtVKjqC/gG4fvwva0eHrDJd4A1gTrjnkk4XxO+e3T+DOhmfMH3FLAL/3cuFlsRxbd/teGrZhrw7V4AX8Ofqf46eOZ+j3+vhuP7+LOUO1U1FbRvN/DP+Abq4/hOFY+M4RJ/BfwSeAFfPZZkBDVUFlV18QX+afguyIfxDeKo6k/xBdlPRKQLfzZT1KV6rpP1vjAYpp1gNPcSVX3rTLfFYDAUYgJHDDNCoGp6F4P93A0GwyzAqJUM046IvAd/iv8LVX1opttjMBgGY9RKBoPBYBiEmTkYDAaDYRDzwuZQV1enq1atmulmGAwGw5ziiSeeaFPV+mLr5oVwWLVqFY8//vhMN8NgMBjmFCIyZKYDo1YyGAwGwyCMcDAYDAbDIIxwMBgMBsMgjHAwGAwGwyCMcDAYDAbDIOaFt5JhfrDroXvwHr2VqtRROqJLsC58L+svvXamm2UwLEjMzMEwK9j10D2UP/BJ4ul2euwq4ul2yh/4JLseumemm2YwLEiMcDDMCrxHbyUtUTJ2CYiQsUtISxTv0VtnumkGw4LECAfDrKAqdZSMFS9YlrHiVKaKFiIzGAxTjBEOhllBR3QJYS9RsCzsJeiMDiphbDAYpgEjHAyzAuvC9xLRFGG3D1QJu31ENIV14XtnumkGw4LEeCsZZgXrL72WXfi2h8rUUTqjS0gZbyWDYcYwwsEwa1h/6bVghIHBMCswaiWDwWAwDMIIB4PBYDAMwggHg8FgMAzCCAeDwWAwDMIIB4PBYDAMwggHg8FgMAzCCAeDwWAwDMIIB4PBYDAMwggHg8FgMAxiRoWDiNwuIi0i8nTeshoR+Y2I7An+r57JNhoMBsNCZKZnDncALxuw7OPANlU9HdgWfDcYDAbDNDKjuZVU9SERWTVg8WuBLcHn7wEPADdOX6sMhkJM+VLDQmSmZw7FWKSqzcHnY8CiYhuJyPUi8riIPN7a2jp9rTMsKEz5UsNCZTYKhxyqqoAOse42VT1PVc+rr6+f5pYZFgqmfKlhoTIbhcNxEWkECP5vmeH2GBYwpnypYaEyG4XDvcDbg89vB/5rBttiWOCY8qWGhcqMGqRF5Mf4xuc6ETkMfAb4AvAfIvIu4ADwZzPXQsNCp2/xZk7b920sxyElUbqkAk9CpEz5UsM8Z6a9ld48xKorprUhhjnHdHgQ7XroHhoP3EO7VFNBNzFNEdIT7Drlei403kqGeY4pE2qYc2Q9iNISzXkQRR74JLtgUgVEzhgdqaYb3+kh7PZRcuyxSTuHwTBbmY02B4NhWKbLg8gYow0LGTNzmOWYAKzBVKWO0mNXFSybik67I7qEeLrdF0IBxhhtWCgY4TCLmS71yWxgLEJwujpt68L3Enngk+D6wifsJYhoalhjtBHmhvmCUSvNYhZKANZYo5CtC99LRFOE3T5QJez2EdEU1iR7EK2/9Fq6t9xMIlJLqdtBIlJL95abh+zsTTS1YT5hZg6zmOlSn8wE+SPsJV4nvZSSifgJeDN2Cbi+cKRIR7z+0mvZhb++MnWUzugSUlM0Ql9/6bVF21CMAmHOyNdhMMxmjHCYxcxXnfdAdVmD20ycJBknSjJUAYwsBMfSaU8Xc0GYG7WXYbQYtdIsZrrUJ9NN/gg75nZjo8RIs9w9RMzpAuamEJzt0dRG7WUYC0Y4zGLGqvOeK2RdRGNOF0vdw1h4CBDGZal7mPJ065wUgrNdmC8UG5ZhcjBqpVnObFSfTJSsuqzBPU4YB8XCAwQlgkOVdnJgy/+bc0JwOm0h42EuqL0MswcjHCYJo8sdPVkX0RKSBfnYE0RRwMadtHs33b/LbBbm89WGZZgajHCYBOZzPEK2c12WeJYK7cHGw0M4LIvp3vqFcV1fdoSt296BAB5CijCu2FjqMUQJj3G1fb7/LmMReuOJ2zAsXIzNYRKYr7rcbOe6OPEC1dpFKLANCMoKbaZx+/vHbcxcf+m1vGifToawLxiwsNQjhMshe+WktH++/y5jNSzPVxuWYWowM4dJYL7qcrOd6xL1ryM7ns+O9iu1lyMT8OHPbPkEJ7b/LWXaSwgXB5sTUklmyycmpf35v0vM6abW8w3d6hxi10P3zNlOcSLxFLNZ7WWYXRjhMAnMV11utnMN4SKD1io2OqwALKb6AHLLvOgSDqx+MyXHHssZcCfTJpD9XWx1aXSP4iF42HiIP9JmbqqX5utgxDC7MMJhEhiNLncuGqyznauLRQivYJ0NuMiQAnDXQ/dQG8wKwrhU97WR3v5+MsTotitz6pDKA/fQveVmVk3Bvcj+LjVeW671FspxezGuhOZs5PJ8HYwYZhfG5jAJjKTLnavBR1m/fafIvAF84TCUD3/4gc9To51YKBlsLJRq7aFCO6bNBpD9XWz1sFAcCdFsN5IMVczpkfZsj6cwzA/MzGGSGE6XO1dz7mS9iuq3XU8GzRmkFUgSolOqhpz9LHcP4GDjiT/+8BBQJYpTsN1Ud9LrL72WnY/eOmikXe60Uaq9HPjcujkzk8sy2+MpDPMDIxymgbmsIx6qcw27fSQitTQOu7cO+CaD5iDToQ4ZqPYrd9pY5LVyXOrnrIurMSwbphojHKaBua4jHo9//OHQSlY4TdiBe6qFAoqDRdjtmxQ/+9HacQaOtEu1l+NST3fEL/2ZP5Pbha8SW+4eyF1H+rJPzBmhYTBMFqI6OQFHM8l5552njz/++Ew3Y0jyg7HyO8W55GOe7YhH61W066F7aNz+Aaq1G1AUwcWmW0ppsxYRIzEm76SBgqBv8WYaD9wzrnt64HPr/Jmc5M1jVKnJNKNAjXbiYON7ZHl0SBVtW780Z34rg2G0iMgTqnpe0XVGOEwPY+1c5wPP/8P5NLqHCKlLWiK0W/W4YpOI1LLxxl+P+jjFhOtS5zDtUp0b/UO/qmukY++85eqiarJat4WwZrDQnK3EUg9PhKb4hjG3ea55pxkWHsMJB6NWmiYmU0c8VR1PsdF5ybHHBp1ntOePaYJD4dMGjdDHamvxHr0VSx0avJNEnDRpiRAmQwXddNMvHEZjx9n10D3E0idZ6ewn5YRplXpcO0JEU6QJU0KSDHb/ucUipBkqU0dHfd1TnbbDCB7DdGBmDnOMqVJRDTxuvtG2O1yXO0/zymuHVOcABZ1WLH0SwStqyB7LKLz5plOp1C48LDzx02zESOFhsSe6NrddebqVUnrpsSqLdpr512h7Geq1hahmaJZ6UnY5y5wDRMjgYJORMNA/czhqLSdGYlT3faiZyVivuxjzQUVpmD2YmcM8YiS32PGOKgcet0K7cbH80bnUY6tDjdvGsn3/Sh9RWu1FZIJYBVzfiJvtPLOj5TK3A0HoZmRD9nDtjpD225h1ixULR21CuITdPmw3zWI9Rpw0CaJ0eFJ0tJ5/jRkbDlFJeaaVOu8ERynlmLWYZd5homRQBQ8LG49uqohrL9V6Iqci66GECu2mftv17Hz01oL2NiReJE6KqJMmJRHarTqSdnnBrGayfqe54hZtmHsY4TDHGM4tdiLqjIHHjWgaB5uIpok5XTS6zXgIFn5AWaPbTDPkAspWpV/gSGh5QafVA3hqkYpUD/LHz+8cE8Sp804WRE5n2w1wmvYRxcFVhzShoP6DRYeU4KnFSj2KhUcGiwgZVushep0oJ6W6oNMsdu+qvRPESbPS2Y8EHlUu4gsIhAwh0hKh0WvORYpHNU0lPaSDxCID23uK9vozJmxC6tDoNtPmpTgZXwFMTO00l92iDXMLIxzmGMO6xQ4YVdrqUuO1FR3djnTctESIqK/fr/XagvA3Ai8eP6it1mvjCBW50pgZK547np/oroW4pniOc+necjMbB0SMZzvH5ekXCePQp2UFs5GK+/+eBq8lFzhn4xEnTS9x2qQ219keSK9ihdNEGA8FPCBGmjptJ5xID3mNlenjlJFCISg6BCA4CDbKEWsx3aE6lmdexA6yMmVjNRSI4NBDrHD0DrRb1dR5J3KGbUsdavQEnRd+wb93Exj9z3W3aMPcwQiHOcZwMQcVD3yyIAupn2zOT7E90uh04HG7pJxF2koX5dRrOy6Sy5xaQhIPwdFMLnXD4dBKwl4CWx0a3OOUksBDSBAddO6BnWMYFxeLRe4xHK+ViKYBJU5mUDsVsHAI4xBNneQUdx99EsVGc507EMRVQCkJdt5yNQ2JF1mlfZSQJuFG6KKcxdpSeA8AFyWM4iFUqK9SC6mLIliBS67kzkUurC87ehegO1RHxo0FWWDTpCVMgnjuvo9m9L/roXuIPPh5ljl+vMUheyWZLZ8wNRkM04bJrTQF7HroHnbecjUHPreOnbdcPak5lIrlcWpe6Xe4dW4LyzMv5tJTZ6svpCUyYh6jgcc9GVvBk6f8NSfjK/AQJEhd52GRIAJAGA9PLbq33Ez6sk9Q5naw1D1CLKjwJihhHGx1Cs6drSGdJSURbDxKSBJSB0WKCgbwu/4oDopiiUefxIhoJsi12u9coYEKLK4pqhMHqdTuQAgptno0aisWkMQO7pKPHXxOEQ6ElD+LygoEzTuLi2Dh+vciGL13RJcQ9hIkQ+UciZxCU/RMWuxGWuKn5tqW3Saf/NH/rofuoW77R1jhNOXOucptonb73wKYmgyGacF4K00y0+1NUuCB46ZZqs3B6NojQxgLzSWbywZ6tcRPHdYQWsyldf2+23LJ6/yiPA5uoGJ6sWSTP6J98PM0uoco0yQuFmlCWIE6xsFCsdh3xW14A9JxxJwuVrkHUKCPGHFSg7LA5uMBe0OnBbOUY5SSBAg6UgsLpZcoITKEgu5cA3VROPfd394hRGyAIFIgTYikxDgSOYWY081KtwkQ+iROWDNEyQTbRGmxGws8top5RDXZp5DZ8omcvWW4Z2TnLVezOvEUlg6It0BoKhlbvIXBMBzGW2kamW5vkvzz2eqScW1KSSJACJc+YmTHxeVOG+XaTXe6HUctVieeIrrtXezf/nFSdjkxTZCUOLXuCXrsqoK02imJYuMS0QxuMOFUhDBO7jgecNRaikc7IXUQlAgZQEgTztVRaF55LZUH7smpRlzxDbtZlZU9QplQAVY6+7FxyRAiQZgYGSzAwyNJiBAZYri4gRoIlBgEarb+KbNFBi/4nj2rL0RcWqQcVHHFpkMqKdU+wpomJVG6KKNU+0gQR7FIEqfigU/SEV1C88prqTn4K5Z5R0gR5rAswRKvoIbEcInzqlJHiWraF6eqeFiksQmBMTwbpg0jHCaRXQ/dw2l9OxA80m6UdqueZKh8Sr1JsvrrrI0hOyrOdoAlpFju7ifjRoiRJkmIErebGu3AQ3ARlusx0k4bR60lNHqHiKhDYoBxGKDFbiRjl7A0vQ9RAiOti6X+GD1GipXeATxsrLwMrll9fbaOQsmxx+jecnOuc0wSJ0OYOKlh5gv9CL4BGQi8ivo7dwVieUnGBwqagXrU/O/Z9mb/L9VewpkMLfFTab7wU0Bhh55NkV23/SOU0kNIHaoTbfQ27aPLruZAaFWB4Th/kDBcUGRS4tg5seb/6/92UWN4NkwbRjhMEllVgYuFhQQujEdpZgmu2KN6qcfj+571XsnaGGKkCzpKX+8PFilcLKI4LNXjeIGbZoRM0Nm6LPJasAKjc9YTCfzRfdoNE9EUuBDVNG4wa8gQwhMLW52cEVjxcBEiQVfvACekMqfaqkwd9Yv75KlYCNprMzJeIGyyZAVBdv/xKkqz98wO1FLtdkOuTkLudxjwezz/D+dTpR242DgSxlKPKjqocjrYFzmzYNv8QUL2t25I7CVCmjRhWuKnYV34XsIKHjZ2ViqTFfbeuGs2DPdsmYhrQzFmrc1BRPYD3fjjVmcovRiM3+ZwInGCXcd38dJlLyUaio67rdAfFWsHfu3ZcbMnFiesuhFtDsPpoYFhX+zyBz7JIreZDGHKSCAQFPb0jbJezsPG/3/g6Nl3/xQsoJdosI3SFPU7t2x0r3Xhe/EevZXT+nbgikVUM74xWV3ipApG3vnHThFGsWi2Gwl7qYIo5mjqJJZ4LHMOEsHPa1S8tFA/GWzsIN4iS9YcPZJKajRkVU8ALhZHZBGrbnoOGNyRntH3JA4WnvSLNUtdYqTZFzq1aJR03+LNbNj3bcJksPD8uhdYtEktnhUi6vXRRymNeowYaQRf1dUpZdTddHjM1zPSs2Uirhcuc9nmcLmqtk3VwX+x5xe89advJR6Kc/GKi9m6eitbV2/l3MZzsa3RjGH7yap3MiI0A7VeGxFNI+qN6kUbylZRLPI43y00q78u3/4BStX3gPHH64VdtAAZhGiRztMflWaFh+R0+agWuEquHzDar/HaCGuaSJ4aZ2DHLkCMDGksFrtHCeFx3KrP2TzKNEEvMVwsBHLxFMN18mHcQWutwP10MsgKz6wb8Apt5tHvfZKy1ecNCl4L4/j3TFN5+/nquuxMK7/TbQ+M+xL8JtlZWxqhgm5aZDHV2kYF3cTIBIZ9G0GIa4ZdD90z5k57WDsYmIhrQ1Fmu3CYUl59xqv5rzf9F9ubtrOtaRt/t+3vAKiMVnLZqsu4YvUVbF29lbX1axEZvuPJD05Khir84LBsPp1RvGRD+b6fkn6OjIQKMpumJUrkwc/zXFB34BSgzaojRYRK7SZGKudw2e+XL8N6APmjft+A3CWlxDTBmemnUeCIFKrEsgJJ7v97VuiREa8NIIJHhDR9RLHUpVGP4QUOslkDut/e0VHs17AmYdZQeDzItuj8ff9CZ1M5vZRSQooGp4lQoPaJ5O61j43iYtG88lpKjj1WYHQuefRWQnikCeWisMF3HlBNY7tpSkgjgQD0hatDBpsWq3ZcnfZwcRUCJuLaUJTZLBwU+LWIKPAtVb1tsk9QEa3gNWe8htec8RoAjvcc54H9D+SExb3P3wtAQ2mDP6tYtZUrTrmC1VWrBwmLiQYnFYt8Lc+0EcHBVQtHQjk7xgmpZJG242Ll6g40eC30SgmtUsNSbSGbBsLFJoKLgxIbofO08OODq7QLgDQ2LiEa9RgN295N8/YP5/TiAKXaM6pry+J3dh5LguCzrCor/04OVElNzlxg4tgo5dpNNV0Fgmxg2/NdZEuOPTbI7fTAA58kKVFC6uBh5YS4hUdaItRrKwmJEFUHKyiS5NuHwnSH6sbVaY8UVW0irg3FmM02h6WqekREGoDfAB9Q1Yfy1l8PXA+wYsWKcw8cODDpbTjQcSAnKLY3bae5pxmAlZUrcyqorau3sqS8P3hpvDUbiumFlziHgg5HCvzdo0EiOgebkJ+rFD8PkEWflJAmTIQMaSK0xE+lL1LHpo5fD/LnHwqP/pKeaWwi+IFpPVJKi72YiKaIen0s0vYxd9753kCzpeOfbLI2Cw+hVWppiZ+aE6hLtn+Acu0aNCoToI8wETwOWsuoVd8d2BMLVAnhcji0YlyZXY3NwTAUc77Yj4jcBPSo6peKrZ+OIDhV5fn259m2bxvb92/n/qb7OZk8CcBZdWflBMWWVVuoideM+rj5Bs6kxFElVyWtIbGXPkpoDLyLsl46JSRxgoyhWfNy1oicwWZPZE3BS+49eiuLEy/QoCdH3a6sgXeggTjfNTUbH2Dwyf4++QIQIEGEhMRJE8bCoUE7cu63WRwgQZwwDq1WHRmJsdQ9HKT283IG65Eq0g3leTTcwGUhFqIy+Mw54SAipYClqt3B598An1PVXxbbfjzCYaLue5567Dy2k21N29jWtI2HDjxEX6YPQTi78Wy2rvKFxSUrL6EsUjZkG0aKlM16QGUN3E5gqi0lmeu48zsjF6FXSolqmgw2R+3lVHonqNf2op5KAxnNiH4+j/onwlD3Jf8N838/X4iEArtCijApiXIkcgrl6VZq9SQ9UkKdnsj9XkksTkoN7Vv/ecjn1NR6MIyVuSgcTgF+GnwNAT9S1c8Ptf1YhcNUvERpN81jRx5j275t3L//fh49/ChpN03ICnHB0gvYunorV6y+osBtdqSiMEO1s7l8Axd0/LxgdJr/2Y+18AKdtr88FGQsHa5Tzz+WYWwUu7fFlmVdnDOB6s93U/VTkL8YXQOqLMrsp0p7sfBydiXFok1qOBlfUaBWyh/klHmd9FI6rtKphoXJnBMOY2WswiHbKWtviPjhblKLStAKj0SsbtJeor5MH48cfITtTdvZvn87jx99HE+9ArfZs7bdxmq7EdvKG8+rUup2sOrTTwOFU/4kcURgpdOU61gMs4P+WJHh4zScQHDnb5P9dsBehSs2tW4LJdpHRiK5bSz1cCREh1Vd8GzkDx5OST8bxJMs8QMOIcindZSW+GlFA+7MjGJhM5fjHKaErGtf5b5Wlv3nCwB4IYtMXQSeegusXdv/t3o12GOLeQAoCZdw1alXcdWpVwHQkezgoQMP5WwWWbfZcvcg53uVbJYqLrAqOculIDtnNm2zP7Z08YIo58nGqIomRjZWZDQqOWvA92yQ2wr3QBDaJziEghKlQfU7hJimCryIBsYvpCRGRNMF0e3lmTYqtJdM8iCVgRdanCSZxEG8SaxrbZh/LOiZg+NGiR3vI3q8l/jxLkJtLhWJEjh0qH/jWAzOPLNQYKxZM26hkeV4z3G+94t/4sndt/M7+jgUeCDVYnN+w4Vsrl7Py5/7ORu0Bw+bGOlJif4dCqNSmhhZD6Wxqu0UcBTCwcIeYli4gRrQVyl5YgWur0LTFb5Ht/forZzV9wR9EqXdaiAZKqcyfYxGbQnqUggpQlhAq1VHhXbnvJ+ys5AWe3GBCnMqU2gUy/Rbcuwxk7JjhjFqpQGMaHPo6oLdu/2/Z57x/3bvHlloZGca1uh9eLIvTXdyP9tCYf5YW8eTvXtybrMr1OJSolylylZCLDX+QfOCrLtwfz4qv1ZGigghnJyHko1HKPj8x6qXU3bun1G7/W8p015KSObiJNwgpYjkHY8gDvuAtZxGrxlHAkVB4BrbFDmDUreD7i03j8oGN14BMvB9K8+0sUhbOW7V0x2qM4bzGcQIhyKMy32vqwuefbZfYGT/Duflu4nHC4XGmjVjFhqqyvbPvYSnvSPcLw4P4XBS/N/pTLXYis1WDbGFEDVmrD9nGexMILnU5Ypf1CgT1IzoohzPCoHnsFjbcLCxg7TkA0kSIiORXExMQqJ4QT3rYjMHKBIIN8CQPREnjoGOF0vT+3IlaI9ETil6PsP0YGwORRguZfKQVFTABRf4f/l0dvpCI3+m8cAD8MMf9m8Tj8NZZ/ULizz11K6H7x00IltmVXGZ18r71Q9Be1pdtuOwXRzuIMOtVgZROBuLrYTYqiEuxqbMCIs5RX60dTaLbgQHUHolzqHI6cScLmq9NmJuiggZkoTxxCKmxdOhxHCIab9dqkwTOEEadUf9JH9dlBctL5tlYAqNidQpGZi+I+tmna20V+x8hplnwQqHSaWyEl76Uv8vn6zQyFdNDRAaXjTCS2osUg0lJBrKqavfizZ/DKdSArWCSxg4B5tzsPmIRkmjPKYu23HZLg5fJ82XrDQhhQuwczOLl2ITNcJiTtCf/LDfSN0qDVSmj7FYWxE055ocxUFVRm2DyrrLhvBzOHVICSfjK3Kz5Z0DKvPB4BQao6l7PRQD03ekJJKbOQx1PsPMs2DVSjNKntBoveNzlDSfJNKWItzZP5LSEKTrY1j1EKpTtN5CG2ysKoEBeZ36UB7BZZs43I/DE3h4AnGFS7C5XENsJcQ5WEHFZMNcwKFfAEz0V3OweCG6jvJ0ay5lejYiv9Jrp0J7abeqh7QBDFQNxZwu6t3j2Hi5MrGjDc4zNofZg7E5zGIOfG6dPyITwUo6RFt876mG5qOk20JEWlOEu/KERhios9F6C6mzoN6CBhvyhEYHyoM4bBeX+3F4Wnz1Q6XCZYTYqjZbCbEWK8igZFgItEoVNdqJhdJHjDAZFIsj0kiYDPXaip8a0aLNqiMhpcRJkCBO3OtlsR4nJWG6KKdOT6LAUWsJrhUesXMfaOPLeiuZlB0zixEOs5ihoqQVi6gmsNShuq+NstYEtHrBnwutHtLd/9tpCF9Q1NvB/8HnKuG4KPfnzSz2BcbtRSpcHswsriDEasQIi3lO1isKfPtGmhApidJu1bHUPYIbJFkpIYkitEs5FZpAgXappkK7KSVJkgjH7CUkQ+WAMSjPVYxBehYzVKrv7i03c6Lpcdbvu41QDLzlIVg+IIAqqTlBkRMaTQ7yVJ7QCMOiOos31du8qd6C+hiH64VfVbk8YHlsw+Enlm+8XKmSM25fjs0S4zY77/BjMfyZpGLl6kjUem0oECcTOMT6dUDqtQsXyBChjD4ORU/n1NSzZCQEKEvT+4hqmpRESCRGn9jRMPsxM4dZwMB6wln8FAphWq3F1HqtlGnPqGosU0xoDJxphIFALdVSL/yxHv67weM/qlxOBjLhLLW4HJsrArfZajOrmPPkJ2nMlo9NEcmVIx24TX+NCj9q+8XoWSxN7yOufbiEc9mC/SSCFvuu+JZRD80hjFppDpA12lnq0OAdJ4QGFcV8v/e2XBGfCTBKodFXZ9FUD39oUP6nXnmiAQ5Vwtlicblxm51zDJVaPT9lykiJA/3SpxZ7omspT7eyRI+TJoQiRIPa3wnCHA6t4oxP/TF3jJFSiJsI6ZnFCIc5QNb20OgcpoRUrpYC+KO2PqKUkJr0UpgAJBTa8oRGSyA0evrPlQ7Dvnr4Yz3sqofn6yFab3FWlc1Wwlxg3GZnLSOlEh+u+JKXtz6DzcHQaiKaotzrJKppSkjhIaQIo/j1sF+44js5AVA0q/DKa2k8cM+kZkU2wmZ8GJvDHCDrRx4PBAN5xXY8IE6KJBFKSE3+yeMCgU0jH80TGuFWjzNaXF6y18Pame1WPHrCHs/WZ/jPekjWC1V1Nqc3hFlXaWOLsVnMBoYSDC5WLpW74lcaH/iLWUBKLVwJAUIiUkvqwvfS+eitrE48RZ9GC6oUpgjnAuOGCpx7SdP3aLcbxhVQV4x8IdRjVxFPtxMxSQUnjBEOM8TAkU5M4pQ7bXkFfBQNpvIEyw7ZK3mJ+8L0jc+LCA0hEBqBSirU5rIyEBqVO/3qyeDQE4aj9eDUW1TX2yyqDyH1NlQOjtMwTB/ZGYLg1/gg933wjDQbkOdKiFZ7Ed1bbmZjtnocEN32LjKEQP0qhBbKcWmgIfEiO2+5OkgMGKPHLaGMvpzhukT7OGatLDjXRCKkJxK9bRgaIxxmgGIjnRr3OJXal/MSyb6w6SCd2sHQas781B9JfKY2qButg1RMXt6+A9UEk5qSOy6wIgQrIApkS8toQjnR6rC31aGr1SXW5nHKXo/GnR4E9avTEfDqLKIDXW6N0JhS8iOvR7s9wfYx0oNUPusvvZbnHvg8S9xDhHBJS4R2q46wl6JCe+lOt9MnUWKapIJeUoTIECKiaSz8VOIFRYkmECE9kehtw9AY4TADFBvpRByHNBYeYUpJ5ra18DghtaQv+wQAB+xTWOU2kcIOsnL6KJAmTJQ0GSxAsPHwENLYCEKY9NT+4HGhZkWYmhXh3KL9ePwgkWFfm0NPq8uyVljb4rFhr0fDzv5dNUzxOA0jNCYFGfD/SOTPMAToaXp80Cg8s+UTnBhgU1ikzbRbNWTsEtq1gZXufjQoiepiA0K7VFGjJ0i6pQU2h9SF7x3XtQ1MzwEmHcdkYITDDFBspBMO6gkfjL4kl2gtomkUKSgqn9nyCU4EKZuzMwUCN0MHi3CQckFRkoRxxS8ak5EQIXWhSBbPqWQVFqviUVgeRZcrz+GxHZdbxeF/Ew5LW2FtK1zSAue1Kqv2ZojlC40IgcutERoTZSx3y1dm+njA+n23seuh8wbNHnZBQeRzt9tBd6gOgGSoHNcNZatS4EiIdquepF2Gl2kmEanN7ZeagAF5qFih8Qobg4/xVholk+kNUSwqenlqDwgcipyeWzZU1Gl/XMSLuZw4GQ2zVJsDs6ISCopP+u6GFs12I8sDFcBs6VJdlJ34gXh+anKXPoGaPri2RXhFq8V5rcLSVsUe4D1lhMbkU7zmNSSJYKM8X3LOiBHQY03PPZb3arhtx5WC32BcWSfKRHLZj/Z4ZW4HgtBtV47pHNmX4rS+Hbhi0WotBmCRe4wSEngICaKEcQkHdadna9eZRvkDLvfjcr84/A6XjEA4yDb7ioTFy1os1rVCqFX7XW57iwiNhkBoZD9XGKExEsXsVIrkUmzk16/OUqzCW+OBe7A8hwq6KdEENh6tUkl7eHnBcw2M+r2a7HfQ4GOEwwQZKv/RRHLJFBvpAOMe/eQn8Mvil41sJY1NSqKUaS82kK0CMJsFBRRmm92Ow5NBttkShYvzs832CfaAwL5hhUZ+wkIjNIYkX1g4WHRJGUe3fqNgtF40jqF8Axs6tmHhkJIoKaKUaR9dUkpL/LTcs75k+wco0T5SEvPVTaHyId+rqXgHDSbOYcJMhTfEkMWGxjkKKmaUq6CbXmIcivqqqrNSu4LKxD6zfVhQgnAVIa5S/zHtQHlQHbYF2Wb/zkoBKSpLYUtpiK0rQ2wlwpog26z2ef2BfW1BcN8eB9kxQGgMVE3VW0ZoUDhwsPFwCFGeFz8QfuDz1LstxEijQIIoJ61qXtL5W46ElhWk9467CSq0hxZ843bjgXso1QRpwoTUodE9SjNLSNplRd8r45E0/RjhMArmgjdEMaNcVDMclv42enn1AYZKqTCbqUJ4LWFeq7431HH1ctlmt+PwX0ECwUUqbMXm8pIQV6wMsXpl4WNeIDSyMw0jNIZFEUo1QafU4D16K7uAM929WIGDgwWUkaTEa0axSLgxGpwmQsH6TGDtiqfbOW3ft2mXapISzZUuRT1qvVZaxC76Xs2Fd3C+YYTDKJgL3hDFPEea1MISj5jTTa3XipXLxlk4KpyLggJgERZvwuJNgbDYrx7bcbhfXLbh8ONAWKwakG22scSClRYUxmEZoTEE2Uj9UhKc6ryI4+wnte2vsYs4N/jPkccSbQkibvxnLYJDgggZuwTL8e0R7VYdjW4zqO9yHdXkkO/VXHgH5xvG5jBKZps3xGi8PHY9dA912z9ClXbgYhEnNcjf3Qs+5QfUDRQeLhZWbsu5geK7zW7D5YGgjsXJ4ALWBNlmt44222wxoTHQphEF6gYIjQYLyuen0BhNQJ2bc6v2t3WxeD66jqXpvcQ0zd7oWf31sTVFr8QLbBoDmW3v4HzAGKTnGWPx3Hjuc+fnolj9QCQLF5sIGVwsIjgoUtD5Z5OtDSdA5hr5brPbxeG3gdusKJyDn232iiDbbOloxWCfBy2BPaPVzX0uKjQarELX23k804D+3E12MFv1ECzg2eh6yjOt1HgnOBpabjyPZhhjkJ5njCWXTJwEhyKngQgxp5tG9ygEyfwE8gLpfPqT/vmfOqQMC6VMe6fhyqYOG+EcbM7B5qMa9d1m1WV74Db7NdJ8yUrn3Ga3BjOLl2ITGUpYlFiwyoJVhYu1mNB43kH+dwihUW/1f54HM43sVSYkRlhTRHFzM4jyTCuehNh1yvUFZUInEgRnmBqMcJiDjMVzI9+QlwyV08wS6r1jqPqmxAgeitBLjIzYVKhforRLSnmh8hJK0m00JPZSRh/kqQjmOhGESwhxCSE+o1F6UR5Rl+2BcfsfSPM5K01c4ZK8UqpnY2GPdAeGEhq9RdRTxYRGMZvGHBEaHn4ZUguPiKYIB1lfszPRZV4zx6WWstXnsf7tN4/p2CYt9/RihMMcZDjPjYFV5ZaixDVDu1dNd6gOV2x6KUPFnw30BbXlbJQWq4E2sfHUIhWtZkn3UyQljgJ9xCgjMUNXPPWUIlxNiKsDt9mTgdvs9gFus1UKWwgFMRZ2zm12dCex/L9VhYvnk9Cw8POBOUAkL1VLfuW5ej0B2z8yppTao0nLbYTH5GJsDnOQkYqoWOpQ57Xntu+SEso0QbeU0xI/lWjqJJZ4LHcOksEGESwNct9QwzI9yoHQKjJWnOWZF4moQ5tU06gtc9KraTI4hu82m51ZNIn/3ixW4fK8gLxTJvMOFRMarR7SN/uFhub9rznhmfVeUnolRrO9nGSkelSd+UhBcCaCenwYm8M8o5jbaurC91IS2CIavJN4WHhiYalHDIejoeW5F+nA59bRY1WRkojvZ47giUVE09TTSkrCZOwSYk43JZpEUBq0nXapolY7BkVW+1UcfOPjfBUei7F4MxZvDtxmm3Jusw7bcQvcZrOlVLdi0ziROzLamUaLB88NmGnEGOw9NY1Co1AcaIHTq++2mmGVs48DrBo0EwAGzQCqUkdxPKHBPZarC9FOTU6Vamo6TD5GOMxRikVYH3jgk/TYVUScNI74P62HENF0gU0iq5bK9zMHxRE7CJxbmme89s3VNh5lmqBZFlFBF1FNBXUl/A4gq1ueLzaJkViNxbuI8C6NoCjPar/b7E/J8F3Lr19xllo54/ao3GZHw2SrpxosKJtaoSFB8SpByRAmhEOCKLa6NGSaiGgaR2xk+9+jljVIfaSew1Jtw8Emg01IHZbSzH5WAyaCeiowwmEeke3009kZgVhYKGmJFESTZgOK0hKlWRZRr61Ecdhv+1FhgkeDeyxXGzhGyp+JABV0kSZcUEsiS74rLBQG1mUFx3ycWQjCGmzWYPMBjeCi7AhmFtvF4btk+Fcrk3ObzQbkjcltdjQMJzQGek8NNdNoGDDTmCSh4acA95+MMBlA6ZJylrqHggzCSkQzlHGEhBv1C11JhHarnrREWUx7v0+dCGjgHBE0zURQTz4jCgcR+QDwQ1U9OQ3tMUyAbKffJeXUaTuW+i9jF+W5aNKs0S7qJSinkzRhmko25PS9Wd1tVJNkCGPhpz7IEPJr0qlHBGfINmRnDv316HwcFs5IxEY4F5tzB7jNbhOHB3D5Kmm+OFa32YlQasFqi2CQ7aOK9urgmcazDvLkMEKjbuwzjfzZZPap8LCp1TbCgQecv40GledS9EpJf84lazFRTXPYWkqttudSgB+XRUTVd5IwEdSTz2je10XAH0XkSeB24Fc6DVZsEXkZ8DXABv5NVb8w1eec6+TbIsKJDBHSpAlzMr4ilwkza7Q7EW7MvUD5gsEXHH1YKDHS9Emc49ZikqGKnAHwrL4nhszomn35BwbMhSgsPbmQyLnNBp5QvSgPqxvYK/rdZrPZZrcGxu1Ruc2OFxG/gy+bgNAoZggvIjSy3zKEgmBMP0Quixs8TdnomtwMNMi5VK8t9EgJrhXmiH1Kbr+w20dPpBYY2g5njNHjZ1TeSiIiwNXAO4HzgP8AvqOqe6ekUSI28AJwFXAY+CPwZlXdXWz7heatNF6G8/iwLnxvgbdHeaaNRdrKcaue7lBdgffHku0foEq7RxUxnR9tvVDsEWPlJMqD+G6z23HYLf6MrzJwm906HrfZyUYVigmNVg9JjE9o5ONiBdYtP2twLzFcBAslgsNvFr2LdW3/M+neSA/vaeX2R5o4eCLBipo41120motPrx95x3nChL2VVFVF5BhwDF9DUA3cJSK/UdWPTV5Tc2wGXlTVfQAi8hPgtUBR4WAYHcMZ7ToHeHt0R+ohDaXai+eGCkZijzY9zuZ93xjxfH4XJ6SwieLkBETWMGkEhU81wrWEuTbwhDqWl232/iLZZrMzi9XTacGZ4plGf5I+JRFUO4+RxsHmWV3J15Kv5IPrNrJiz/cmbWbw8J5WPvuz3cTCFrWlYVq7U3z2Z7v5zKvXLCgBMRSjsTl8CHgb0Ab8G/BRVc2IiAXsAaZCOCwFDuV9PwxcMKBd1wPXA6xYsWIKmjD/GMpo1xpaTHXfYVq9CgjsCSKQsqvxJDSo+teFb7+Ztk/fQaX0BCqCrB7Z1yUTlClVhAwh0oQRlCgufsysBDUAhDQWUdwg9042ecfCZji32W15brOr89xmL5+o2+x4mSShEWqwSNdFsOuF1oYKjpXUE5cUMdJ8nTfheB4/7Tqd2yexsM/tjzQRC1uURv1u0P/f4fZHmoxwYHQzhxrgT1X1QP5CVfVE5FVT06yRUdXbgNvAVyvNVDvmEsWMdiEvxfflFbxO76WWDvqIA74WwXYSNEcaBjq/APC0nEYtHSyjlRAOXhDnkCHECS1jkZzkuFZTI93ESOEQps2roEKShMSlT2MoEBGXLo2yTxt5iXUYQQmTyZbryc0wkkSIkJnTyf/Gy0C32d3BzOJ+cfj/yHB74DabzTZ7hYa4bLLcZkfAj3ERQgNngnlCI7U6RBjHF11ZoTHQe+oZh2jSv46V9LAsfpDuulL+t/4sTqtvwqt1aVl1Guj5k+Zye/BEgtrScMGykojNwRPzNxPAWBhROKjqZ4ZZ9+zkNifHEWB53vdlwTLDBChmtLsr/Gr2hzfx3eY0nwp9H9RPlVFCkrik+Yb7ci4scqxtla/nbZ3f5KSWslhOBtk3lZNahYvN153XcYH1PC42h7SB77gvA+Cm0PdJeJH+c5DmJudt/M5bz59Yu7gp9H1s3JxQIXCntVAEl0iRGgILCUFYi81abN6f5za7bQi32XFlmx0lCrRpOd92X8nL7T+yVg4QxkGBpIYJi4eLsE8bqaaHxXISyZ9pnOIfo10r+FDmvezpXsbLrXbK9u5hRXMTp7Ud5Ozdz3B58g/9J/1mDaxZA2vX9v+tWQOLFo0oNAbaF8qiNn1pNzdzAOhLu6yoiU/qfZqrzMr0GSISwjdIX4EvFP4I/IWqPlNse2OQHj9XfvlBakvD/KHpJH9i7eJd9i9ZLi0c0gZ+yCv4rbuOS19SN8hg9/CeVu688we8IXMvp+pBYmRIEeFgeBXfca7hvtTaoucbeI7vuC/jd976YdcDuWU9xFiux6i1eoMaAcJJr4QyK53nYtuvnpK8JS7Z3D/zlzTKH3L2Cpff45IRCCu8FDtXx2Kg26wCR7WGB70NvNL6AxWSKBAlDkJKQ4TFw0bJYPOst4IvuX825O/XozEQv0LcIW3g994Z/Jn9EKdIc84zaZ8u4TPO23PHCNtCWTRETzKD44GoUtvbwUvaDnBG+yHeU9tH4+F98Mwz0NHR38CamkJhMUBo5NsXSiK+UGjvSSMCNaWR3LJkxltQNoc5Wc9BRF4BfBXflfV2Vf38UNsa4TB+rrvjMfa19rC/ffBU2rZ89dLaJRVFX55inh4AN979FM2dSbzZ+WgtKDySpKxnSFpPkbR3kpa9IIpolKi3hpi3kZi7kYieggRJGGcSEQhZfpCb6/UHVGaJhiwuOq2W6/5kFReXu76QeOYZ2L3b/3vmGTiZF5IVCI377TpeqF1By4pTObzkFDrLq+lNu1gCtWVR461UbN1sFQ5jwQiH8fPwnlau/8ETpB0XZ+CbCDSUhzmlvjz3vTflUF8e5fZ3bC56vOvueIzW7hSOp+xv6yPtenieLkBLwezEpYeUtYukvZOk9RQZ6yAAlpYS9dYTczcS8zYQ1hUz5zY7AqvrSghZVvERvip/+N0z/PaeB4jveZ61HYc5u/so1rO7KU/05DbrKq3kSOMqXqxfyav/4qr+mUZDw6zKcjvVGOFgyFFstP+xu56iN+3Qm3Jxg+G+Jb6q4fxV1b6eOEBVOXgiwVmN5Rw8kaA0YiEi9KR8Xe1zzd0sr4kjInQmMjx3rJvJesRCwUzGnfuP7KzB5SRJeycJaycp6ykc6zgAllYFgiIrLBbPcEv7qSoJs7w6XnSQMlB9dLwrSUt3Gtf1WJo4yQWJY5x54hDLjjbReGQfq47tpyRPaFBbW6Ca2lWxhO+cjPO0E2dFbcm8m1kY4WAABr84WTVRadTG9bTAMNebcjjakWRJVaxg+bHOBEc7kkRDFinHI+MptsBpDWWEbYu9rb1UxEIkHY++lEvaLTIdGQfVJWHqyqJkXJcD7QkzE5kiMnLMV0FZO0nZT+GKr6IJeYtygiLmbsSmesbaGLEtzl5RSXtvhvs+fFnBuuzMtTQaoqMvzYH2PlTBssD1wPU8oiEbx1NsS/jg5adywxml/SqprIpqgE2jq7SSg4tX0dSwkjVXXsipl1/gC5GGhmm++snFpOw2AEP7dasqyYwHOAVC4z2XrObuJ48ULD/akfRjGhR/lhGM5A+d6GP9sirKohbHulJYDNYXTwRLhNefs5TH9p8oah8xTA5hXUzYXUy5ezWaUTJyiKS1k6S9kz77EXpCfpxB2FsR2Cs2EPXWY1M2bW3MuB47DnVSFg3x8J7WgpF8vnvqsc4UlgiWLTiu0lAe5nBHkr60S0U8RE1phLv/9yjrlq3h4iuvhCuv7D+JKh/+6v9Q+uLznNZ6kGXNTSxrbuLyHdspe/Re+Idgu7q6QiN49q9+7s8ujHBYQAzl193em+GmV68pmkZg3dLKguUvHO8hZAm25Sc7yKqfEhlfFPQm/Zw5Uph3L7dsrBPVrEIrZMPXt7/oGysN04IgRHQFEXcFFe6rUVzS0hTYK3bSY/+a7tDPQIWInpqzV0S9tVjEpqxdCqQcj5ST5q3feYyyiMXmU2q57qLVrKiJ52YOScclbAmep0TDFt1Jl3jYRhXOaqwA/Bly0aA3EZ7SMmo3vJQ90u/MrZ4Hzc3ceXFl4SzjRz+Czs7+/eeB0DDCYQGR/+Jkyfp1X3x6fVFd6sDlaz79y6CHFywRPFVU+214fY6HJf6spDftklVbegolYV99lSxm+R6CbD6m1u40lkDfZE5HDGNCsInqaUSd06jk9SgZUtbz/szCeoqu0H/RJXeDhoh6Z/gqKG8jUe8MhPDIJxgnPWmPZ4528tmf7eb15yzNzXZjIYtkxkNEaKyM0dTWiwVEw/1eWcMFvRV9XzIe9atXwFWb4aqr+m147X1ssHq5rrqPdR1H+gXHUEJjoOCYhULDCIcFxHUXreazP9vNQPVR1gV1NLxkURnPNncjnhK2haTjeyKVhG16Uw4ohEO+pLAF0nmduaeKq8rq2jiHO5JkRmlZVnx5ZFxjZxdCmJi3jpi3DnjLALfZp+gM/YRO+XHgNrs2sFdsIqKrJ91ttq07TUN5jMf2n+AzwSy4rSdNIpNGUJpae8l4igisrOyf1QwX9FbsfTnR6w9Srvzyg5RGLNp60tSURqgti7AnbfN/TpTxmVdv4eK/CTp7VTh6dLA944c/hK6u/pPV1/vC4uqr4e//flLvzXgxBukFxkSzUD68p5Ub736KzqSD43i5dKvVpRHOaiznQHsfh08mEIG04+U6dAHiEZsPbj2NG7acxjcfeJGv3LeHtOtNmjeTYXbR7zbrG7iLu81uJKzLJ8Vt9szFZTgeOSP1w3ta+dhdT9GdzJDxFFRxPFheE6ehPDqqoLf896UsatPSlaK2zA+a2320i7SrnFJfSmXcnxmN5OqdQxWOHCkUGLt3+wLi3/5twvditBhvJcOEGChQNq+q4bH9J4oKmKzwONaZxFV/9mBbwin1pYRtq+DFyR73wedbjXvqAsB3m30qUEPtzLnN2lpN1N0wYbfZsliIzauqc89XvudSlmOdCbqTLtWlkTEPjgYeb8ehDiwgErY5c7EfC6SqRb2oZivGW8kwboqlNb77ySNDjrYuPr2eW16/get/8ASeKrGQzeLKKFUlkVyMRP62F59ez5/84zY/cC6wXxjmJzbVlLqXUer6HWe+22zS3klf6EEg323W94Yardtsb9Lh2eZurrvjMa67aHVRB4xFFTFC9vg674HHi4Vs0q5HKtOvO51PuZnMzMEwLMVGX70pB9sSakojQ6qnhttPVdnT0gv4NgxVpSvp0NKdoi/t5gSE0O/hFLLA8QY5QBnmCUqh22zK2oUn/jOS7zYb89ZjDeE2GwsJG5dX5fImdacc0o5HPNw/QMmqfa67aPWY1asDn+mOvjRNbX2EQxZrG8vnZG4mo1YyjJtsYr78KOmOvjR7W3s5c3H5kAnLigXcnehNk0i79KZd7Gz+HIWyaIhoyMrpclu6UxzvShELW2Qcj76MRzxis6wqRjLj0tKdJh62ae9Nz9RtMUwx/W6zO0haT5GynkElBWoFbrMbBrnNLq+OsbS6JNdp57tTi0B5zKYn5QuLRMaloTzCoorYqDv1oZL3NVREcxkC5loEtREOhnFTbAbw9NEuRJW1Sytzy4oZ4gbaKtp7Uuxr7cVT3w4BfiCdWMJp9aVDzkSGMqL76ijftjHQkyk/G6th7tPvNhtEb1vPgziB2+yZxL0N1IbP4ezF57PnWDLn6FBXFqa508/1BbC4Ikoi45LKeIhAbWmEnpRLIuNSFg3xtTdtGlFAzKeyokY4GMZNsdHSc8e6OaWuhOrSaG670Rjirvzygxw+2UfYktxMRIGM47GspmTYfYu9lLc/0sTuo120dKdy8RBZIWGLycE0nxkq26wtMaLuWsp0A6VsIqKnYEuIZMbFVT9o0wv+Vz/AH1v8VOGKsKKmZE6phSaKMUgbxs3Fp9fn/MazHXP2BctnNIa4FTVxjncm/JlDMLT3PCUUsobdd6hav68/Zym/33eCiG0RtgVP/chZ11MjGOY5FjHi3rnEvXPB6XebzYSeold20mJ/199Oy4h564laGwrcZvOfXz/iWimJCLGwZcqEBhjhYBiRgVHS2c56rMF01120mueau2nvTfvqnsDmUFcSHnLfh/e08qGf7KAn5RCP2DRWxgKfcofH9p+gMh4mkXZIOh62+KVF4xGbRNo1KqUFhE0ZJd6FkL6QOgsS3glS9lMkradIWDvpizzqbxe4zcYDb6iQLsodQ0RMmdA8jFrJMC7Gq3t9eE8rX/zVcwXeSh+5+oyi+2aF0METff60P7AtrKoroSIWor03Q2nE4vlj3aRdzakLwpbgqq/qMjOIhYevJrIK0rQMdJv1pAPw3WbjupFyNhHXjZzVsHx0QWzzBGNzMMxJslXqDp9M4nqKZQkhgXg0xPLqOLYlHDrRx4levzB9/pNcVxqmI+HkDJGGhUW+TWFghuCs22zG3kmftZOk9TSe+DUdSq1VnN94CVZ6PU7iLE6tbRg26HO8zBbDthEOhjnJhf+4jY6+NBrYEqBfAJREbBZXRGntTpFxFcfTnCCw8FN1pB0XR8eeCdYwv8j3XIvafjZhx1PCtkVDeYQTiRRdzh4iJU/T4e3gpLPLd5vFotw6HTuznhUl53Na1XmkM+ExxzIUyzBw95NHBtVVmQlDuDFIG+Ykacd3R4yErFyaZvBf9obyCIdOJhD8usKRkIXjKcmMi6e+gTzr5x4LW0G9CsNCRIGQLTRWRGnrSZPM+JmDI7avfrxgVR2bV72Eu5/cRHPXG6h3UyTleXpkBwndSbd1Dx2pu3j6eIjayDqq7bP5v9su4J5T3knEjgx77mLOFF/f/iKLKqKURv19s3VVZpsh3AgHw6wlGrLoTfmxEI6nOVVB2BYWV8Y51pkk6SgZ1w+qi4QsIrblJ/wDJBAMlkhBLYlQsG0y7ebUDXZWDTGOmhOGqWdgeRABKuMh+tIerueNaFsKBa7NIsLK2nhB8FvWLToWtnBdJWxHibCBUm89ifRfEItk6PaeoaziWY6nn+CFxB28kPgu1bd8mEtWXMLW1Vu5YvUVbFq8CdsqzDZbrMCW6yknetMsqujPDjsbDeFGOBhmLWc2ltPU1svJvgx9QVR1yBZiYZuOvnSBO6LrKX3poNBQ8BcJWYRtC4CIJaRcv6RpPGzhKUSD0dyJPoclVXHKojbNHX0c786MqZ2CfyzH9QVY2ljBx0TYEhxPh/Uui4Qs4mGLqpIwYdvO1W3IuC4dfRk6E86w+6ddpb4sQm1pZFAlxKzKp7Y0TDSIyrctIVtXynOj1EbO58yKrQCcTJzECT/DmlUH2b5/OzfedyMAVbEqtqzawhWrr2Dr6q2cVXdW0fxO8bCVK46VZTbmZDLCwTBryebTX14dR1VzUa2LK6Mcau/DCfLzW/QHvFnizwKEIOZBFc/T/uA4S8h4/QkBw7bFSxZXFGTy7Nrb7qu0GF0NiVjYImRbuMEMxg7Olw3ME/x/jG28OBlPKYlYJNNegeE4+1uWxcKcvaJq2CqFtpUmbAvHulKDju/n6BL2tPSyfmlFwbrsiH1FTZymtl4c16Mv7WKJr4qKBurK6pIwqv4AxHNL+ewr3pFTATV3N7O9aTv377+fbU3buOe5ewBYXLaYEm8jrd0bWVFyAaWhRgCqSsKku9P0psZfV2U6MAZpw6wma8x77lg3HX0ZGsojREMWLxz3XWGzaqNExiUkYNkWsZBNxvVI5KmNwBciti0srYoNmVPnTwIjeCLQS1sCw5krBCiP+aqCcMiiKh6iO+kSDVukMh6RkMWiiii7j3bh5AmpiTCe1CBFqrbOKqIhi7JoCNtS0g4kHZdYyKaqJMQp9WUjupZmdfv72nr92uYB2XsVtoWQbXFqfemgZJD15VE2r6rhn3/zgh8rI/7AwlNYXRvnz89fMSZvpaaTTWxr2sb2pu388sXfcDLZBkCpvYSa0NlUyjm89eyX8/xR23grTTVGOCwMsoLi9/tOkMq4hAMbA0B30kEEKmJhFldG2dvSk+vU8zuI6tIwjkvRfP4P72nlujv+6Ks4dHSdadYgDtBYFSNkWUW9TrI5qjr60hw+mZxQR10sQn0oYiEL25Kcym22ve2W+AJ+SVUJN716TUFxnrAllMfC/NMbNow6huZDP9mRS8go+DPFkCWEbeHUhjJ6U25RL6HbH2liX2sPHX1OTjBFwzLkszJaVJUfPv4w//roPezrfoxOdwdp9d1m19avZevqrWxdvZXLVl5GdXx0qcknEyMcDPOKK7/8ICELDrQn/NG9JfSmHFThjMVlVJVE2HW4k96gQ8waoAVfQNSVx4rmcXrtv/yW3c3dOIGOSij0j88nOxLPjnijYYszF5fnVAP51cNUlZbuNJ2JDIsqokRDFnuO90woQG+0AiJiC0uqYrT3pEk53qyyh2TVbWFbCFkWpzeUcvhkkpTr4TgeoZBFZSzELa8vLhyKxQoA3Hj3U7T1pP0ULSK4nlJbGuGf3rABoGh8wcDsw52JDE2tvSiwaXllgSAZ6hijwfVcnmx+ku1N29m+fzu/PfBbEk4CSyzOaTyHN655Ix+76GMTvbWjxggHw7wiOwp3PKW5MxkUW/FVNi9ZVEZJxGbHoU7Sjkc03D+7UFXSrnLm4jJqy6KDXu41n/5l7hx+idPh1UC2JXzvnecXTS0SC1tkXI+mtj4AVtXGSTkeLd1pqkrCdCcy9KSmLsVHthZGxBZqSqP0pBy6ks6o9o3YftthamcaWQErwNKqKJ0JZ9RlN4slhMzvvL/06+d54bg/Qj+9oZSPXnPmsB34wOzDzx3rJpl2iYVtzmwsz7XFtmTI2cd41EIpJ8UfjvyB7U3b2da0jVOrT+WOa+8Y83HGi4lzMMwrsobqWNjijEVluRf09ecszemGy6IhwiVCZ8LJRVdnglFzW4/v6ZSfxC/bqaBKyLYIRXyXxGyHGrWFtNvvUSPAuiXlgzqEfNfF5451EwpcXo53pVlcGcUW6OjzvaGsScgcawWN6Te4w9KqOF1Jh2TaxbKEeGRstS8sC6xsYaU8w3rIYlKDCvMPk41mtwWaO5M54TCUi2cxF9Gs59Ht79g85o46+0xl84UlAqP04sr+zMMlEZtdR7oK7BYTjVGIhqJcuvJSLl15KTdtuYnZNFg3wsEw5yiWKTY7+r8h2KY/OSC0dqdy9awbyqPU5LkzOp7S3JXk+h88gS2QcBURX5h4ngZ6a9+jBoKa2IEa5KPXnDmobfmui6mMRygIoOhNZTjQ7iIiuUy0IwmG/BQQ+cRCFmnXY0VNnFjY5lhniq5kJgj4s1lSFWcJ/aPu3+87kfPgGk3XkwmMsaVRm2XVcY51pXKj6K7k4FQlo8WWQE2Xd01Ze1BvyqU0avuZdUdRdrOYi+hEYgUGPlNl0RDlMZuqkv4gt6zdpiRSGMswmTEK+UW1ZhojHAxzkoGZYoutf/05S/n69hcJ2RblgY/8kY4klSV+p9KZyLC/rQ9B8fAFx+GTSTxVXMfvwMtjIXpSTq5j8xQ8R3ndeb5b4nV3PFYgoFbUxIOUHh4Z1yOZ0Zy/vBW8+LEgu+yzzd1Dtj8clEUthmUJlZEwiypiiAhVJRE6+tIcaO8jlfF4trmLZMb31X/l+kZ+v++Er2MaBX4gmEc05LvnVpVE6Eu7dPZlSAXuvWNBpL/ORixsk3I8nLzRseILQSFIlOhBOGTl3EaHcvHM3ufSaIiOvjTHOlO5gj0P72kd1yg+/5nKDi4Gupue3lBKX9ot8HiajTEKk4E10w0wGKaKx/af4NT6Us5eUcWZjRUsrowTC1kc7kgCvvrCEn+05sc9xFlWHaMkEmJZTQmbV1Wzuq6EFTVxSqNhwiGLyniYlbVxnjvWxWd/tpvW7lSBemrzqhrae/wylSHLz+Pjqv/Xl/YrjpVH/ZGnNUR/HbZgRW2pH8MhvkHdDj5vWl7JbX95LmevqMqNZAGqSiKUx2w8VZIZj3jYzxt095NHWFwR9VVr0j9SH5KgrY7nx5V0JjK0dqcJhyRXvQ/8iOPs8YR+r6Mslvgd+JmLywnbli8kgmvJknPJDaLeHc+vzHZafSntvRnqy6ND6vKvu2g1yYzHsc4EB9r7SGZcBKiIh/jsz3bz8J7Wka50WLIzifryaEFbPnrNmSQzXuAAofSmnFkZozAZmJmDYd5STPWwpCrGvrY+/6UOdPKqmtMtL6qIEbL7K9pd+eUHWVQRY3Flf6emqkPqnh/bf4KGiihdKYd0xitQ5fiJ3yyOd/kj3ZDl2zFyxuOQhSAsroyysraEz75m7bBeMQNravSkPFbWlhSkZehNOVhiUVsa4WRff14hT30h5AY2hOzEwvGUiG2Rcj0iYeFoRwJVxRbhlIaSIJisx7c7qB+EGLItFldE6Uo6OK7iqbKytoSG8ih9aZe6sghdiQxpV4mHbRQNtvNVTbGQhaN+LfHRuq1mO+8P/WQHnlJQ66M3NTl5ioaanQ6l0pxvGOFgmLfkqx6yREI2axrLqS2Lsre1F1tgaU1JTrc8UEVQ7Bgt3SlSGZc9x3tyKqLKeLhA97ysKsaB9gRuYNjN2Q4EnMATKGpb2IEtwwMcVzl9USkVsRAHTySGVZ0Vs7u096RpKI8WbFcSsWnvzfBPb9iQCyZMZTxO9qZRBE81UOn4AsJTxRLBFr+u9zNHuyiN2CyujOXu0Wn1pRw8kaAyHs655zaUR6mMD3YMWFET58aX+baZoby4IiG7qMfPSGmtLz69nurSCKc1lBbo6qc6T9FIKs35wrwVDplMhsOHD5NMJme6KYZpIhaLsWzZMsJhf7Yw0ANloNthVq8ctofWcQ88Rkt3isMnE34aDtcjlfDoSmRYVh2nMh7OCZbH9p/0DcrBcbK69+yI2RJYWVvCsU7fPmFZguNqbuQ7Gh32wE5qoDsm9Au7gfr063/wBI5bOLMhEBCWbbFucSn3vO/ioscM2xYvPaWG29+xecgOfF3e8tsfaeK6i1YXCLOzGst9tUzao748OqjjH6o07EABUkx4z1cbwHQzb+McmpqaKC8vp7a2dlZ5ABimBlWlvb2d7u5uVq/u79xHGn2OpuhK/jYne9PYlnKyN4PjFXoALamKccvr/UCrd97xR8K2RSpIIS6SjaQWbFsQVdYurcwZkjVIBLiipmTcfvPD+f4PFCJPH+mgtTszyMC8uCJKeSw8SICOxa9/PPsMpJhQKhbzMNS5Bs5e5qvqZ6LMqTgHEbkJeA+QtSj9var+z1iPk0wmWbVqlREMCwQRoba2ltbWQkPkaLyaRuo08re58ssP0tadJBKyCQVBdagf/1BXFsltt6axnH2tvbnZQ8S2AkGiZBwl43o8fbSLZVUxFlVEaelOUxoNFR1Fj5bhXHzzOXgiQdpRIrbgKAW5iDKuFnTiWa+vb/+2ia5khopYmPdcMnz7hotBGOm6soL4t3vaKIn4brnDxTwUu+b8YjrDzToMwzPrhEPAV1T1SxM9iBEMC4vp+L1X1MQ5dKKPiC3YlkXY9jvXkC30pvt9Tz96zZm5EW3acTnakSQRuJc2VvopNI52JHmxpZd42PeCyqbfmEgHNhphl7uGkEU0uGfZa6gujQyaWd395BGWVMU4LeK7cd795BHWLa0c8jzjjUHInwWURnw7xP62PlbVlVAZDw+pLiqmXhuvcJpLTHWpUePKajCMgesuWh3YG/zZghtkWq0JkrP5yfse46af7aY0agdR0ML5q2tYu6SclywqY3FlnOrSKMtqSnLuoVnd+WS4YU70GvLJnwWICKXRELGwxe2PNA15/BU18QI3WxidHSD/XIsrY0GBJuVoR2JMLqMHTySmNFBtNpAVpANdqSfz2ZmtwuH9IvKUiNwuIkVTFYrI9SLyuIg8PlCVMNu54447OHr06Jj2ecc73sFdd901RS0yjJaLT6/ng1tPw7KEtONHQC+ujBKyLDavqil4Yf0CRB43vXoNt79jM71pr6DTau5MYosffZ3teDOuy4d+soMrv/wg193x2JQIiuGuYWDnO56ONhuDMNZYgPxzVZVEWFlbQixs0Zd2i8Y8ZAXxwHuVFU6diQzPHetm56FOnmnupixqFz3vRBiqDVPNeIT2WJkR4SAi94nI00X+Xgv8P+BUYBPQDPxzsWOo6m2qep6qnldfP7emiuMRDoaZJb8TeGz/CT649TQuOq2W+vIYq+tK+cyr1/DY/hPDvrADR9SpjAdBAB5AR1+a410pelJOwWjwmw+8OOkd0A1bTuO2vzx30DUMVEuMZxYwVADZaNRdAwP7lteUcMnpdYPyJQ03cr7uotWc6E2zr7WXdMavJZ5xPFq6UpPaeU/H6H0opmN2NCM2B1W9cjTbici3gf+e6Pn+5pd/w45jOyZ6mAI2Ld7EV1/21WG3+Yd/+Ad++MMfUl9fz/Llyzn33HNZtWoVjz/+OG95y1uIx+M8+uijxOP9L9qOHTu44YYb6Ovr49RTT+X222+nurpw8vTxj3+ce++9l1AoxNVXX82XvjRh84xhGIq5Vd795JFBHd5NP9s9rK496xbbnUzQ0Zch6fgdYU2QzuNYZwoNArqywqU7meDr21/k1PrSSTeuDnRvvf2RJj5211OkHL9I0VmN5Tnj7kB34JFmAeOJBRjK9bjYuUZKvJcNvMt4Ssy2WFzjV/2bTLvDRAzvE2U6XHhnnVpJRBrzvr4OeHqm2jIR/vjHP3L33Xezc+dOfvGLX5B1tX3DG97Aeeedx7//+7+zY8eOAsEA8La3vY1bbrmFp556ivXr1/PZz362YH17ezs//elPeeaZZ3jqqaf45Cc/OW3XtFAZ7RR+uFF2tvM90Zvm4IkEPSmHkrCFLUJrT5qTvX5uIIDGyv4I546+DK6nU6o+yAq/prZeTvT65Ss7+tI8c7STr29/kbaeFEc7khw6mRj1LGDg8Ucz8xnLjGOkkXNv2mPNkgo2La/izMZyqkoikz6ynknbxnhVd2NhNnor/ZOIbML3ANwP/NVEDzjSCH8qeOSRR3jta19LLBYjFovx6le/esR9Ojs76ejo4LLL/NQNb3/723njG99YsE1lZSWxWIx3vetdvOpVr+JVr3rVlLTfUOhWOTBKuFgnMNTIN2uLiIUtHM/z3VoFltf46SgOnUxw6GSSsmiIingo57oJkMh4BTmLhjr3RMgKv0Mn/frLjqc4npLIpAlbQcGg6niu8xmrYBhNMFuW0c44Rho5T8fIeiYD8EbrtjwRZt3MQVX/UlXXq+oGVX2NqjbPdJtmE6FQiMcee4w3vOEN/Pd//zcve9nLZrpJ85J8fXJJ4FZ5oL2Pjj6/LkKxTmCokW++LSLt+LWmLRGOdaaojIdZ21jOkqo4X3vTJkKWVTAatC2hpjRScJ7J7oCyI+C+lEva9YscZcl40JlwyLjeuGYsU2U4HWnkPB0j6+k4x3BcfHo9t79jM/d9+LJx1bAYiVknHOYLF110ET/72c9IJpP09PTw3//dbzopLy+nu3twuubKykqqq6v57W9/C8APfvCD3CwiS09PD52dnbziFa/gK1/5Cjt37pzaC1mg5HdqS6riiAiqcKwzOWwnUOyFzVc/RMMWXpAhNWtzyE9x8ZlXr8ES2HWki72tvSyuiJJ2prYDyqrDvCGyJShwoL2PtOPybHP3mIzjU6V6GUkFNV6j+GS2Ya4zG9VK84Lzzz+f17zmNWzYsIFFixaxfv16KisrAd8t9YYbbihqkP7e976XM0ifcsopfPe73y04bnd3N6997WtJJpOoKl/+8pen9boWCvmBXJXxMKvqSnx/+8CtcixT+Hz1Q2NljP1tfbieEgtbRTv7tp60n2vJ8WjpSRO1/XTZ7b2ZKVEf9KvDihcX8lNyCwdPJBCRQd45w3WIU6l6mYzo96luw1xm3uZWevbZZznrrLNmqEU+PT09lJWV0dfXx6WXXsptt93GOeecM6Ntmu9M1u8+2tw+o2Fg/p+W7hTHu3yV0lmNhVHR1/7rwzzb7JcXzVajczzlrMZy7nnfxRO+ruHa+KGf7KArmcmVUwWCSnhCxBYSGY9VdYNTgg93TyYjz5Jh6hgut5JRK00h119/PZs2beKcc87h9a9/vREMc4jJ1CcPVD+srivltr88l0f/7opBuuIXjvf4pUgtyXXMtvjLp5KLT6/na2/axKraUsqjNiURm1jYCgoOCZZtEQlZRVOCD6cimu+ql/mMUStNIT/60Y9mugmGcZLt1L74q+fYdaQLgJcsKhv1/sXy3ox6xjEwR9Q05QjLv+bdzd1EwzaraksI2xbJjEdJxBpXicz5rHqZz5iZg8EwDH1pj1PrS1m/tALX01FFwE4kcvb0hlJcT3E9DWoq+3+nN5RO1iWNSG1ZlLqyKFHboivpLMgSmQYjHAyGIRmvG+ZE3Dc/es2Z1JZGsIKcS5b4dZU/es2Zk3VZQ5Iv1FbUxFlSFaM0EsrZRIyKaGFh1EoGwxCMN/X0ePcDXwWTLek52cFNI6V4zgq1jOvx/LEEScclbAlf/NVzBS6ixdoy1emjDdOPEQ4GwxCM1w1zou6bU6GjH02k8sETCWxRDp5IYIkQtgRXYXdzNw/vaR1V5TdTXGf+YNRKU0RHRwe33nrrTDcjh0n5PXbG67E005GzxRiNqmtFTZyjHUk8T0k6Hr1pl1TGxbZkWJXYdKSPNkw/RjhMEcMJB8dxprk1hvEwXh37bNTNjyZS+bqLVtObdkm7vjFcFTwFz1OebR4c0T+WYxvmHgtDrfQ3fwM7dkzuMTdtgq9+dcjVH//4x9m7dy+bNm3iqquu4pWvfCWf+tSnqK6u5rnnnuPXv/41r3rVq3j6aT/p7Je+9CV6enq46aab2LJlCxdccAH3338/HR0dfOc73+GSSy7BdV1uvPFGfvnLX2JZFu95z3v4wAc+UHBek/J7chmvime2uW+ORtV18en1lEZD9Kb8wYttCZGQn+4j7XiDjjmWYxvmHmbmMEV84Qtf4NRTT2XHjh188YtfBODJJ5/ka1/7Gi+88MKI+zuOw2OPPcZXv/rVXNru2267jf3797Njxw6eeuop3vKWtwzaz6T8NhRjtKqu8miIiG0RD9t+XYlgeTQ8dFcxG9VohomzMGYOw4zwp5PNmzezevXoXpg//dM/BeDcc89l//79ANx3333ccMMNhEL+z1ZTU1Owj0n5bRiK0aZ4PrOxnKa2Xk72ZUhlPKJhi4aSMKvrho6zmI700YbpZ2EIh1lCaWn/CxYKhfC8/ql6Mpks2DYa9dMU2LY9qTaKbMrvbdu2cdddd/Ev//IvbN++fdKOb5i9jEbVlU3Ct7w6PuWV3wyzG6NWmiKGSsudZdGiRbS0tNDe3k4qlSpI6T0UV111Fd/61rdywuLEiRMF603Kb8NEmY3GdMPMYGYOU0RtbS0XXXQR69at4+UvfzmvfOUrC9aHw2E+/elPs3nzZpYuXcqZZ44cAfvud7+bF154gQ0bNhAOh3nPe97D+9///oJtTMpvw0QwwWyGLCZlt2FeYX738WPSay88TMpug8EwIiaYzZCPEQ4GgwEwwWyGQoxwMBgMQH8t6XxMMNvCxQgHg8EAmGA2QyFGOBgMBsC4sRoKMa6sBoMhhwlmM2QxM4dZxD333MPu3btz3z/96U9z3333Tcqx9+/fz7p160bcZirqXn/1q1+lr69v0o9rMBimDiMcAh7e08p1dzzGlV9+kOvueGxU9X4nm4HC4XOf+xxXXnnloO1c1x20bDIwwsFgMGQxwoGJFYQfjh/+8Ids3ryZTZs28Vd/9Ve5Tr2srIxPfOITbNy4kZe+9KUcP36c3/3ud9x777189KMfZdOmTezdu7egQM+qVau48cYbOeecc/jP//xPfv3rX3PhhRdyzjnn8MY3vpGenp5B53/iiSfYuHEjGzdu5F//9V9zy/fv388ll1zCOeecwznnnMPvfvc7wE/l/dvf/pZNmzbxla98ZcjtmpubufTSS9m0aRPr1q3Lpeso1qavf/3rHD16lMsvv5zLL798QvfTYDBMH0Y4MDXBP88++yx33nknjzzyCDt27MC2bf793/8dgN7eXl760peyc+dOLr30Ur797W/zJ3/yJ7zmNa/hi1/8Ijt27ODUU08ddMza2lqefPJJrrzySm6++Wbuu+8+nnzySc4777yiaTDe+c538o1vfGNQ/qSGhgZ+85vf8OSTT3LnnXfywQ9+EPDTjF9yySXs2LGD//N//s+Q2/3oRz/immuuYceOHezcuZNNmzbR1tZWtE0f/OAHWbJkCffffz/333//uO+nwWCYXoxBmokVhB+Kbdu28cQTT3D++ecDkEgkaGhoACASieRSZZ977rn85je/GdUx//zP/xyA3//+9+zevZuLLroIgHQ6zYUXXliwbUdHBx0dHVx66aUA/OVf/iW/+MUvAMhkMrz//e/PCa2h6ksMtd3555/PddddRyaT4dprr2XTpk08+OCDI7bJYDDMHYxwYGoqWakqb3/72/nHf/zHQevC4TAifhmVsaTkzqb8VlWuuuoqfvzjH4+rbV/5yldYtGgRO3fuxPM8YrHYmLa79NJLeeihh/j5z3/OO97xDj784Q9TXV09oTYZDIbZhVErMTXBP1dccQV33XUXLS0tgJ9e+8CBA8PuM1Ka7ywvfelLeeSRR3jxxRcBX001cPRfVVVFVVUVDz/8MEBOpQV+UaDGxkYsy+IHP/hBzhYy8PxDbXfgwAEWLVrEe97zHt797nfz5JNPDtum0V6XwWCYPRjhwNQE/6xZs4abb76Zq6++mg0bNnDVVVfR3Nw87D5vetOb+OIXv8jZZ5/N3r17h9yuvr6eO+64gze/+c1s2LCBCy+8kOeee27Qdt/97nd53/vex6ZNm8jPvvve976X733ve2zcuJHnnnsuNyPZsGEDtm2zceNGvvKVrwy53QMPPMDGjRs5++yzufPOO/nQhz40bJuuv/56Xvayl80pg/Rs8F4zGGYSk7LbMK+YjN/dpK42LBRMym6DYQyY1NUGwwwJBxF5o4g8IyKeiJw3YN3ficiLIvK8iFwzE+0zLGxM6mqDYeZmDk8Dfwo8lL9QRNYAbwLWAi8DbhURe/DuBsPUYVJXGwwzJBxU9VlVfb7IqtcCP1HVlKo2AS8Cm6e3dYaFjkldbTDMPpvDUuBQ3vfDwbJBiMj1IvK4iDze2mo8SQyTh0ldbTBMYRCciNwHLC6y6hOq+l8TPb6q3gbcBr630kSPZzDkY1JXGxY6UzZzUNUrVXVdkb/hBMMRYHne92XBsjlHR0cHt95664y24Y477uDo0aNj2mc0qb2BgqSAk3n+kdixYwf/8z//M6nHNBgMg5ltaqV7gTeJSFREVgOnA49Ny5n3PgD//mfwL5v9//c+MKHDDSccRpsuY6JMRec80+c3wsFgmB5mypX1dSJyGLgQ+LmI/ApAVZ8B/gPYDfwSeJ+qTk3xgnz2PgC/vBF6WqC03v//lzdOSEB8/OMfZ+/evWzatImPfvSjPPDAA1xyySW85jWvYc2aNYNG6F/60pe46aabANiyZQs33ngjmzdv5iUveUkuJbbrunzkIx9h3bp1bNiwgW984xuAX/fh/PPPZ926dVx//fWoKnfddRePP/44b3nLW9i0aROJRIInnniCyy67jHPPPZdrrrkmF7E9VGrvfFSV97///ZxxxhlceeWVubQgYzl/se0Avv71r7NmzRo2bNjAm970JsBPv3HdddexefNmzj77bP7rv/6LdDrNpz/9ae688042bdrEnXfeOe7fx2AwjICqzvm/c889Vweye/fuQcuG5IdvVP3mZarffWX/3zcv85ePk6amJl27dm3u+/33368lJSW6b9++ouu/+MUv6mc+8xlVVb3sssv0wx/+sKqq/vznP9crrrhCVVVvvfVWff3rX6+ZTEZVVdvb2wv+V1V961vfqvfee2/uOH/84x9VVTWdTuuFF16oLS0tqqr6k5/8RN/5zneqqur69ev1wQcfVFXVj3zkIwXtynL33XfrlVdeqY7j6JEjR7SyslL/8z//c9TnH267xsZGTSaTqqp68uRJVVX9u7/7O/3BD36QW3b66adrT0+Pfve739X3ve99xW65qo7xdzcYFjjA4zpEvzrb1Eozw8n9ECktXBYp9ZdPIps3b2b16tG5Q/7pn/4p4Kf03r/fb8d9993HX/3VXxEK+X4ENTU1ANx///1ccMEFrF+/nu3bt/PMM88MOt7zzz/P008/zVVXXcWmTZu4+eabOXz4cNHU3sV46KGHePOb34xt2yxZsoStW7fm1o3m/MNtt2HDBt7ylrfwwx/+MHdtv/71r/nCF77Apk2b2LJlC8lkkoMHD47q3hkMholjUnYDVK/yVUnRsv5l6V5/+SSSTVwHEAqF8Dwv9z2ZTBZsG41GgZFTeieTSd773vfy+OOPs3z5cm666aZBxwJ/hrh27VoeffTRguUdHR3juZQxn3+47X7+85/z0EMP8bOf/YzPf/7z7Nq1C1Xl7rvv5owzzig4zh/+8IcJtdcwd3l4Tyu3P9LEwRMJVtTEue6i1cajbAoxMweAl74XnASkekDV/99J+MvHyUhpqhctWkRLSwvt7e2kUin++7//e8RjXnXVVXzrW9/KCYsTJ07kOti6ujp6enoKPIjy23DGGWfQ2tqaEw6ZTIZnnnlm2NTe+Vx66aXceeeduK5Lc3NzrqrbaM8/1Hae53Ho0CEuv/xybrnlFjo7O+np6eGaa67hG9/4Rs4u8b//+7+juq+G+clUlfI1DI0RDgCnboGX3QJlDdDb6v//slv85eOktraWiy66iHXr1vHRj3500PpwOMynP/1pNm/ezFVXXcWZZ5454jHf/e53s2LFCjZs2MDGjRv50Y9+RFVVFe95z3tYt24d11xzTa7yHPjupjfccAObNm3CdV3uuusubrzxRjZu3MimTZtyNaGHSu2dz+te9zpOP/101qxZw9ve9rZclbfRnj8ajRbdznVd3vrWt7J+/XrOPvtsPvjBD1JVVcWnPvUpMpkMGzZsYO3atXzqU58C4PLLL2f37t3GIL3AMMkQpx+TstswrzC/+/zkyi8/SG1pfwVF8FWl7b0Z7vvwZTPYsrmNSdltMBjmNCYZ4vRjhIPBYJj1mGSI08+8Fg7zQWVmGD3m956/mGSI08+8dWWNxWK0t7dTW1tboKc0zE9Ulfb2dmKx2Ew3xTBFmGSI08u8FQ7Lli3j8OHDmHTeC4dYLMayZctmuhkGw7xg3gqHcDg86mhkg8FgMBQyr20OBoPBYBgfRjgYDAaDYRBGOBgMBoNhEPMiQlpEWoED49y9DmibxObMR8w9Ghlzj0bG3KORme57tFJVi7qAzQvhMBFE5PGhwscNPuYejYy5RyNj7tHIzKZ7ZNRKBoPBYBiEEQ4Gg8FgGIQRDnDbTDdgDmDu0ciYezQy5h6NzKy5Rwve5mAwGAyGwZiZg8FgMBgGYYSDwWAwGAax4ISDiLxRRJ4REU9EhnQZE5GXicjzIvKiiHx8Ots404hIjYj8RkT2BP9XD7GdKyI7gr97p7udM8FIz4WIREXkzmD9H0Rk1Qw0c0YZxT16h4i05j07756Jds4UInK7iLSIyNNDrBcR+Xpw/54SkXOmu42wAIUD8DTwp8BDQ20gIjbwr8DLgTXAm0VkzfQ0b1bwcWCbqp4ObAu+FyOhqpuCv9dMX/NmhlE+F+8CTqrqacBXgFumt5UzyxjenTvznp1/m9ZGzjx3AC8bZv3LgdODv+uB/zcNbRrEghMOqvqsqj4/wmabgRdVdZ+qpoGfAK+d+tbNGl4LfC/4/D3g2plryqxiNM9F/r27C7hCFlZBkYX+7oyIqj4EnBhmk9cC31ef3wNVItI4Pa3rZ8EJh1GyFDiU9/1wsGyhsEhVm4PPx4BFQ2wXE5HHReT3InLt9DRtRhnNc5HbRlUdoBOonZbWzQ5G++68PlCZ3CUiy6enaXOGWdH/zMt6DiJyH7C4yKpPqOp/TXd7ZiPD3aP8L6qqIjKUv/NKVT0iIqcA20Vkl6runey2GuYdPwN+rKopEfkr/JnW1hluk2EA81I4qOqVEzzEESB/NLMsWDZvGO4eichxEWlU1eZgOtsyxDGOBP/vE5EHgLOB+SwcRvNcZLc5LCIhoBJon57mzQpGvEeqmn8//g34p2lo11xiVvQ/Rq1UnD8Cp4vIahGJAG8CFoQ3TsC9wNuDz28HBs22RKRaRKLB5zrgImD3tLVwZhjNc5F/794AbNeFFWk64j0aoD9/DfDsNLZvLnAv8LbAa+mlQGeemnf6UNUF9Qe8Dl+HlwKOA78Kli8B/idvu1cAL+CPhD8x0+2e5ntUi++ltAe4D6gJlp8H/Fvw+U+AXcDO4P93zXS7p+neDHougM8Brwk+x4D/BF4EHgNOmek2z8J79I/AM8Gzcz9w5ky3eZrvz4+BZiAT9EXvAm4AbgjWC77H197g3TpvJtpp0mcYDAaDYRBGrWQwGAyGQRjhYDAYDIZBGOFgMBgMhkEY4WAwGAyGQRjhYDAYDIZBGOFgMBgMhkEY4WAwGAyGQRjhYDBMASJyfpBYLiYipUENkXUz3S6DYbSYIDiDYYoQkZvxI6bjwGFV/ccZbpLBMGqMcDAYpoggt9AfgSTwJ6rqznCTDIZRY9RKBsPUUQuUAeX4MwiDYc5gZg4GwxQR1NX+CbAaaFTV989wkwyGUTMv6zkYDDONiLwNyKjqj4K6yr8Tka2qun2m22YwjAYzczAYDAbDIIzNwWAwGAyDMMLBYDAYDIMwwsFgMBgMgzDCwWAwGAyDMMLBYDAYDIMwwsFgMBgMgzDCwWAwGAyD+P8BQ/a0/xQ0SAkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stand_noised, stand_y_trunc = noised / noise_scale, y_trunc / noise_scale\n",
    "\n",
    "gt_stand = LinearRegression()\n",
    "gt_stand.fit(new_X, stand_noised)\n",
    "\n",
    "trunc_stand_ols = LinearRegression()\n",
    "trunc_stand_ols.fit(x_trunc_norm, stand_y_trunc)\n",
    "\n",
    "trunc_noise_var = (stand_y_trunc - trunc_stand_ols.predict(x_trunc_norm)).var(0)\n",
    "print(\"trunc reg noise var: \", trunc_noise_var)\n",
    "\n",
    "reg_noise_var = (stand_noised - gt_stand.predict(new_X)).var(0)\n",
    "print(\"reg noise var: \", reg_noise_var)\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(new_X, stand_noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc_norm, stand_y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(norm_data, gt_stand.predict(norm_data), color='green', label='gt ols')\n",
    "plt.plot(norm_data, trunc_stand_ols.predict(norm_data), color='red', label='trunc ols')\n",
    "plt.legend()\n",
    "plt.title(\"Y Scaled by Ground-Truth Noise Variance\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncated Regression with Known Empirical Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 steps | score: [0.08722872287034988]\n",
      "100 steps | score: [-0.15371833741664886]\n",
      "200 steps | score: [0.11577165126800537]\n",
      "300 steps | score: [0.15002448856830597]\n",
      "400 steps | score: [-0.040850937366485596]\n",
      "500 steps | score: [0.04271867498755455]\n",
      "600 steps | score: [0.01830844022333622]\n",
      "700 steps | score: [0.04730379208922386]\n",
      "800 steps | score: [-0.052826348692178726]\n",
      "900 steps | score: [0.10823661088943481]\n",
      "1000 steps | score: [0.08567563444375992]\n",
      "1100 steps | score: [-0.0640784278512001]\n",
      "1200 steps | score: [0.008505544625222683]\n"
     ]
    }
   ],
   "source": [
    "trunc_reg = TruncatedRegression(phi=phi, alpha=alpha, bias=True, unknown=False, val=100, bs=10, n=100, tol=1e-2)\n",
    "known_emp_res = trunc_reg.fit(x_trunc_norm, emp_stand_y_trunc)\n",
    "known_emp_w_unnorm = (known_emp_res.weight * emp_noise_scale) / beta\n",
    "\n",
    "known_emp_bias_unnorm = ch.zeros(1, 1)\n",
    "if args.bias: \n",
    "    known_emp_bias_unnorm = (known_emp_res.bias * emp_noise_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(new_X, emp_stand_noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc_norm, emp_stand_y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(norm_data, trunc_emp_stand_ols.predict(norm_data), color='r', label='ols')\n",
    "plt.plot(norm_data, gt_emp_stand.predict(norm_data), color='green', label='gt')\n",
    "plt.plot(norm_data, known_emp_res(Tensor(norm_data)).detach().numpy(), label='known emp', color='blue')\n",
    "plt.legend()\n",
    "plt.title(\"Empirical Known Noise Variance Results - Normalized\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.plot(unnorm_data, trunc_ols.predict(unnorm_data), color='red', label='ols')\n",
    "plt.plot(unnorm_data, (Tensor(unnorm_data)@known_emp_w_unnorm + known_emp_bias_unnorm).detach().numpy(), label='known', color='blue')\n",
    "plt.plot(unnorm_data, gt_ols.predict(unnorm_data), color='green', label='gt')\n",
    "plt.scatter(X, noised, label='entire dataset')\n",
    "plt.scatter(x_trunc, y_trunc, label='truncated dataset')\n",
    "plt.legend()\n",
    "plt.title(\"Empirical Known Noise Variance Results - UnNormalized\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncated Regression with Known Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 steps | score: [0.1404706835746765]\n",
      "100 steps | score: [-0.20729883015155792]\n",
      "200 steps | score: [-0.019203443080186844]\n",
      "300 steps | score: [0.15922656655311584]\n",
      "400 steps | score: [0.26590561866760254]\n",
      "500 steps | score: [-0.19839715957641602]\n",
      "600 steps | score: [-0.07279006391763687]\n",
      "700 steps | score: [0.047994550317525864]\n",
      "800 steps | score: [0.07560958713293076]\n",
      "900 steps | score: [0.0676669031381607]\n",
      "1000 steps | score: [-0.28352153301239014]\n",
      "1100 steps | score: [0.052644044160842896]\n",
      "1200 steps | score: [-0.017157278954982758]\n",
      "1300 steps | score: [-0.22028736770153046]\n",
      "1400 steps | score: [-0.1377340853214264]\n",
      "1500 steps | score: [0.0061187297105789185]\n"
     ]
    }
   ],
   "source": [
    "trunc_reg = TruncatedRegression(phi=phi, alpha=alpha, bias=args.bias, unknown=False, val=100, bs=1, n=100, tol=1e-2, steps=2000)\n",
    "known_res = trunc_reg.fit(x_trunc_norm, stand_y_trunc)\n",
    "known_weight_unnorm = (known_res.weight * noise_scale) / beta\n",
    "\n",
    "known_bias_unnorm = ch.zeros(1, 1)\n",
    "if args.bias:  \n",
    "    known_bias_unnorm = known_res.bias * noise_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(new_X, stand_noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc_norm, stand_y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(norm_data, trunc_stand_ols.predict(norm_data), color='r', label='ols')\n",
    "plt.plot(norm_data, gt_stand.predict(norm_data), color='green', label='gt')\n",
    "plt.plot(norm_data, known_res(Tensor(norm_data)).detach().numpy(), label='known', color='blue')\n",
    "plt.legend()\n",
    "plt.title(\"Known Noise Variance - Normalized\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(X, noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc, y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(unnorm_data, trunc_ols.predict(unnorm_data), color='r', label='ols')\n",
    "plt.plot(unnorm_data, gt_ols.predict(unnorm_data), color='green', label='gt')\n",
    "plt.plot(unnorm_data, (Tensor(unnorm_data)@known_weight_unnorm + known_bias_unnorm).detach().numpy(), label='known', color='blue')\n",
    "plt.legend()\n",
    "plt.title(\"Known Noise Variance - UnNormalized\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncated Regression with Unknown Noise Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 steps | score: [0.2905574440956116, -0.20666351914405823]\n",
      "100 steps | score: [-0.27120140194892883, -3.2981948852539062]\n",
      "200 steps | score: [-1.2057424783706665, 2.8927805423736572]\n",
      "300 steps | score: [-0.8965381383895874, 2.547687530517578]\n",
      "400 steps | score: [-1.3437919616699219, 3.0747432708740234]\n",
      "500 steps | score: [-0.338600754737854, 1.6003186702728271]\n",
      "600 steps | score: [-0.18581794202327728, 1.1041582822799683]\n",
      "700 steps | score: [-2.0519609451293945, 3.499739170074463]\n",
      "800 steps | score: [-0.5100373029708862, 1.8548325300216675]\n",
      "900 steps | score: [-0.8865644335746765, 2.509981870651245]\n",
      "1000 steps | score: [-0.5900213122367859, 2.0247135162353516]\n",
      "1100 steps | score: [0.15984177589416504, 0.3845093250274658]\n",
      "1200 steps | score: [0.22827421128749847, 0.23511837422847748]\n",
      "1300 steps | score: [-0.3410768210887909, 1.496913194656372]\n",
      "1400 steps | score: [-0.5526643395423889, 1.8662344217300415]\n",
      "1500 steps | score: [0.03078850731253624, 0.7469772100448608]\n",
      "1600 steps | score: [0.3207339644432068, -0.07735451310873032]\n",
      "1700 steps | score: [0.08289414644241333, 0.4445505142211914]\n",
      "1800 steps | score: [-7.331491360673681e-05, 0.7884536981582642]\n",
      "1900 steps | score: [3.7120587825775146, -16.00615882873535]\n",
      "2000 steps | score: [0.1520119160413742, 0.47450709342956543]\n",
      "2100 steps | score: [0.42264631390571594, -0.3584215044975281]\n",
      "2200 steps | score: [0.13948450982570648, 0.34743204712867737]\n",
      "2300 steps | score: [-0.13141636550426483, 1.0118039846420288]\n",
      "2400 steps | score: [-0.05583800747990608, 0.7816806435585022]\n",
      "2500 steps | score: [-0.037316374480724335, 0.6529505252838135]\n",
      "2600 steps | score: [-0.08239049464464188, 0.7700093388557434]\n",
      "2700 steps | score: [0.09528686851263046, 0.22621750831604004]\n",
      "2800 steps | score: [-0.1221969798207283, 0.8119499683380127]\n",
      "2900 steps | score: [-0.0310097374022007, 0.5819554328918457]\n",
      "3000 steps | score: [0.5751413702964783, -1.3699575662612915]\n",
      "3100 steps | score: [-0.09480074793100357, 0.7463727593421936]\n",
      "3200 steps | score: [-0.1033899262547493, 0.7528668642044067]\n",
      "3300 steps | score: [0.3166261613368988, -0.569666862487793]\n",
      "3400 steps | score: [0.09277021139860153, 0.11154335737228394]\n",
      "3500 steps | score: [0.003292296314612031, 0.37338003516197205]\n",
      "3600 steps | score: [-0.021146630868315697, 0.4938583970069885]\n",
      "3700 steps | score: [0.3947943449020386, -0.9203724265098572]\n",
      "3800 steps | score: [0.07384838908910751, 0.1224624514579773]\n",
      "3900 steps | score: [-0.1356445848941803, 0.8010411858558655]\n",
      "4000 steps | score: [-0.07301203906536102, 0.5931289196014404]\n",
      "4100 steps | score: [-0.06994166225194931, 0.5720142126083374]\n",
      "4200 steps | score: [0.06643223762512207, 0.12924602627754211]\n",
      "4300 steps | score: [0.0693226233124733, 0.10894773155450821]\n",
      "4400 steps | score: [0.41528117656707764, -1.0349681377410889]\n",
      "4500 steps | score: [0.2099645882844925, -0.34716105461120605]\n",
      "4600 steps | score: [0.0612940676510334, 0.14870496094226837]\n",
      "4700 steps | score: [0.1767122894525528, -0.28655731678009033]\n",
      "4800 steps | score: [0.02568897232413292, 0.23491927981376648]\n",
      "4900 steps | score: [-0.07936576008796692, 0.5495424270629883]\n",
      "5000 steps | score: [0.13787201046943665, -0.11901440471410751]\n",
      "5100 steps | score: [0.01289855595678091, 0.26444748044013977]\n",
      "5200 steps | score: [0.1283319741487503, -0.11445106565952301]\n",
      "5300 steps | score: [0.05236974358558655, 0.1701764166355133]\n",
      "5400 steps | score: [0.06662695854902267, 0.09563997387886047]\n",
      "5500 steps | score: [0.1621263474225998, -0.24337178468704224]\n",
      "5600 steps | score: [0.13766305148601532, -0.11745505034923553]\n",
      "5700 steps | score: [0.11207661032676697, -0.05391528829932213]\n",
      "5800 steps | score: [0.05760804936289787, 0.10534490644931793]\n",
      "5900 steps | score: [0.08087275177240372, 0.055032141506671906]\n",
      "6000 steps | score: [0.06122555956244469, 0.08053059130907059]\n",
      "6100 steps | score: [0.07670783996582031, 0.07161639630794525]\n",
      "6200 steps | score: [0.024156158789992332, 0.18201306462287903]\n",
      "6300 steps | score: [-0.011759869754314423, 0.3349982798099518]\n",
      "6400 steps | score: [0.018555156886577606, 0.2433529645204544]\n",
      "6500 steps | score: [0.02688414417207241, 0.17840102314949036]\n",
      "6600 steps | score: [0.024951178580522537, 0.20934873819351196]\n",
      "6700 steps | score: [0.010258366353809834, 0.2601652443408966]\n",
      "6800 steps | score: [0.022181227803230286, 0.21813899278640747]\n",
      "6900 steps | score: [0.044136691838502884, 0.15982478857040405]\n"
     ]
    }
   ],
   "source": [
    "trunc_reg = TruncatedRegression(phi=phi, alpha=alpha, bias=True, unknown=True, bs=1, n=100, tol=5e-2, val=100, steps=2000)\n",
    "unknown_res = trunc_reg.fit(x_trunc_norm, emp_stand_y_trunc)\n",
    "unknown_var = unknown_res.lambda_.inverse()\n",
    "unknown_weight_unnorm, unknown_bias_unnorm = (((unknown_res.weight * unknown_var) * emp_noise_scale) / beta).detach().numpy(), ((unknown_res.bias * unknown_var) * emp_noise_scale).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEWCAYAAACNJFuYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAB1FklEQVR4nO29eZwcZZ34//5U9Tn3feQ+OUJIJgECCIGQEEJcD/BY9eeqyCLrqquuC6LrASp+14NV1F3WdRXwWBWFFS/uHIRLIMSEkHAkmck9yVyZzNVXVT2/P6q6p2eme67Mnef9ek3SXVVd9XR19/N5PrcopdBoNBqNJh1jvAeg0Wg0momHFg4ajUaj6YMWDhqNRqPpgxYOGo1Go+mDFg4ajUaj6YMWDhqNRqPpgxYOUxgRuVdEbh/vcYwFIrJSRF4f73H0h4i8X0QeG+9xTCVEZLOI3OA9HvH7KyJzRESJiG8kzzsZ0MJhAuN9KRf02nabiPxivMY0WojIdd77/Wyv7YdFZNVAr1dKPaWUOnMExzNdRCwRmZ9h3+9E5I6hnlMp9b9KqatGZoRjg4jsF5EGEclN23aDiGwex2FlZDLe34mMFg6aiUQL8FkRyR/vgSiljgAbgA+kbxeREuDNwE+Hcr5JvvI0gU+d6knERc85kwT9QU1iRGSVt7L+F291Vy8iH85ybL6IbBKR73s/0ntF5D9F5M8i0i4iz6evkkXkTSLyooic9P5/k7f9ChHZmXbc4yLyYtrzp0TkGu/xfhG5SURe9s5zn4iE+nlLrwLPAZ/J8h6CInKniBz1/u4UkWD6vUg79hYROeK9t9dFZI233RCRz4nIPhFpFpHfeBN+Jn5KL+EAvBfYrZTamXaedhHZLSLXpl3/OhF5RkS+KyLNwG3etqfTjvmeiBwSkTYReUlEVqbtu80b28+88+8SkfPT9s8Ukf8TkUbvffxH2r7rReRVETkhIo+KyOx+7vlg+DZwk4gUZdqZ7bvi7dssIl8XkWeALmCepyF+TET2eO/tayIyX0Se9e7Fb0Qk4L2+WET+5L3PE97jGVnGkbq/IvJZEelI+0uIyL3evkIR+Yn3ezkiIreLiOntM0XkDhFpEpFa4G9O8d5NWrRwmPxUAYXAdODvgf8UkeL0A0SkFHcV/IxS6pOqu2bKe4GvAMXAXuDr3vElwJ+B7wOlwHeAP3vn+QuwUETKRMQPLAGmiSt8wsD5wFNpl/9b4GpgrnfsdQO8ny8Bn84yYX8BuAioAZYCK4Av9j5IRM4EPgFcoJTKB9YB+73d/wRcA1wOTANOAP+ZZSy/A8pE5NK0bR+gW2vYB6zEvf9fAX4hItVpx14I1AKVePe2Fy9676UE+CXw217C823Ar4Ei4A/Af3jvzwT+BBwA5uB+9r/29r0d+FfgHUA57mfxqyzvb7BsBTYDN/XeMcB3JckHgBuBfG/M4H4m5+F+np8FfgT8HTATWAy8zzvOAO4BZgOzgAjefegPpdS3lFJ5Sqk84GygEbjP230vYAELgGXAVcAN3r6PAG/xtp8PvGuga01ZlFL6b4L+AQpY0GvbbcAvvMercH8svrT9DcBF3uN7gbuBV4Cbe53nXuDHac/fDLzmPf4A8EKv458DrvMeP4U7+VwEPAb8BlcAXAG8nPaa/cDfpT3/FvDDLO/1OuBp7/FvgG96jw8Dq7zH+4A3p71mHbA/7V4c9h4v8O7DlYC/13VeBdakPa8GEun3sNfxPwZ+5D1eCMSBiizHbgfenvZ+DmZ7j1lefwJYmvY5P5G2bxEQ8R5fjDvZ9Rkz8DDw92nPDdwV++xhfgf3e/dxMXASV+DcAGwe5HdlM/DVDN/rS9KevwTckvb834E7s4ynBjiR9nwzcEO2+wuE08+PK6hjQDjtmPcBm7zHG4GPpu27yhtvxu/HVP7TmsPExgb8vbb5cSezJM1KKSvteReQl/b8b3B/ID/McP5jWV43je4VXpIDuCtUgCdxJ+PLvMebcVfil3vPB3ON/vgy8I8iUtlre+9xHfC29UAptRf4NO4E2yAivxaR5HGzgd+JSKuItOIKCxt30sjET4F3eyv6DwCPKqUaAETkgyKyPe1ci4GytNce6u9Nimtye9Uzx7TiaiDpr+9970Li+i5mAgd6fe5JZgPfSxtTCyB0f3bp1/9hmtnlX/sbq1LqFVxt5XO9dg30XYHM9+F42uNIhud53hhzROS/ReSAiLQBW4CipBloEPwEeF0p9U3v+Wzc31B92j36b6Ai7f2kj7f3eztt0MJhYnMQ12yQzlyG9oX9H+AR4CFJizgZgKO4P6J0ZgFHvMe9hcOTZBcOQ0Yp9Rrwf7hmpP7GNcvblukcv1RKXeodr4Dk5HAIWK+UKkr7CynXAZ2Jp3En2Lfjmj1+CuDZ8f8H13xVqpQqwtXQJH0Y2d6j51/4LK7Zrdh7/cler8/GIWCWZHZyHwL+odf7Cyulnu19oFLqo8ozvSil/t8grnsrrtklfeIf6LsC/dyHQfAvwJnAhUqpAtzvHAziPonI54AzcM2tSQ7hag5lafenQCl1jre/Hlf4Jpl1CmOf1GjhMLG5D/iiiMwQ15F6JfBW4P4hnucTwOvAHz2/wEA8BJwhIv+fiPhE5D24Zo0/efufxf3BrsA1KezCnSAuxF3ZjQRfAT6Ma29P8ivc+1EuImW4GkafsF4ROVNEVovrrI7irkQdb/cPga8nnbTeud6ebRDKtS38DFe4FAF/9Hbl4k56jd55PoyrOQyWfFy7dyPgE5EvAwWDfO0LuJPYN0QkV0RCInKJt++HwOdF5BxvXIUi8u4hjCsrnkZ2H/DJtM0DfVdOlXzcz6/V82/cOpgXich6b5zXKqUiae+hHtcU+u8iUuD9ruaLyOXeIb8BPun95orpqymdNmjhMLH5Ku5E/DSuPfpbwPs9FX/QeBPcjbj2+99L/xFDKKWacZ1y/wI0465w36KUavL2dwLbgF1Kqbj3sudwTR0NQxlbP2OoA36OOwknuR3XOfoysNMbQ6YkvyDwDaAJ1zRTAXze2/c9XOfuYyLSjutgv3CA4fwMdwV5n1Iq5o1vN65t/Dlck8i5wDNDeIuP4mp0b+BqglEGMEMlUUrZuIuEBbja5WHgPd6+3+EKsl97ZphXgPVDGNdAfJW0z2Sg78oIcCeuWbQJ97N6ZJCvew+uf+TVNNNZ0rT6QSAA7Mb9Xd2P63sCVxt8FNiB+/36vxF4D5MS8ZwuGo1Go9Gk0JqDRqPRaPqghYNGo9Fo+qCFg0aj0Wj6oIWDRqPRaPowmYuBpSgrK1Nz5swZ72FoNBrNpOKll15qUkqVZ9o3JYTDnDlz2Lp163gPQ6PRaCYVIpI1oVablTQajUbTBy0cNBqNRtMHLRw0Go1G0wctHDQajUbTBy0cNBqNRtOHcY1WEpG7cYt2NSilFnvbbsMtC9zoHfavSqmHxmeEmrFk55YHcZ67i6LYUVqD0zAu/hjnXnbNeA9LozktGW/N4V7cDmK9+a5Sqsb704LhNGDnlgfJ3/xFwvFmOswiwvFm8jd/kZ1bHhzvoWk0pyXjKhyUUltwG6loTnOc5+4iLkESZg6IkDBziEsQ57m7xntoGs1pyXhrDtn4hIi8LCJ3ew03+iAiN4rIVhHZ2tjYmOkQzSSiKHaUhNGzD1HCCFMYy9joTaPRjDITUTj8FzAft5F4PW5DlT4opX6klDpfKXV+eXnG7G/NJKI1OA2/E+mxze9EOBns0yJao9GMARNOOCiljiulbKWUg9uVacV4j0kz+hgXf4yAiuG3u0Ap/HYXARXDuPhj4z00jea0ZMIJBxGpTnt6LW6bQ80U59zLrqF91e1EAqXk2q1EAqW0r7pdRytpNOPEeIey/gpYBZSJyGHc5uGrRKQGt3n7fuAfxmt8mrHl3MuuAS0MNJoJwbgKB6XU+zJs/smYD0Sj0Wg0PZhwZiWNRqPRjD9aOGg0Go2mD1o4aDQajaYPWjhoNBqNpg9aOGg0Go2mD1o4aDQajaYPWjhoNBqNpg9aOGg0Go2mD1o4aDQajaYPWjhoNBqNpg/jWj5Do5kM6PalmtMRrTloNP2g25dqTle0cNBo+kG3L9WcrmjhoNH0g25fqjld0cJBo+kH3b5Uc7qiHdIaTT90Va1gQe3/YFgWMQnSJgU44iOm25dqpjhaOGgmJWMRQbRzy4NUH3iQZimmgHZCKoZPtbBz3o1crKOVNFMcLRw0k45kBFFcgqkIosDmL7ITRlRApJzRgWLaKQfAb3eRc+yFEbuGRjNR0T4HzaRjrCKItDNaczqjNYcJjk7A6ktR7CgdZlGPbaMxabcGpxGON7tCyEM7ozWnC1o4TGDGynwyERiKEByrSdu4+GMENn8RbFf4+J0IARXr1xmthblmqqDNShOY0yUBa6hZyMbFHyOgYvjtLlAKv91FQMUwRjiC6NzLrqF91e1EAqXk2q1EAqW0r7o962Svs6k1UwmtOUxgxsp8Mh6kr7CnOSfpJJdEoBjAFYa2KxzJMBGfe9k17MTdXxg7ysngNGKjtEI/97JrMo4hEz2EOQO/D41mIqOFwwRmqtq8e5vLKux6wkRJWEGivgJgYCE4lEl7rJgMwlybvTSDRZuVJjBjZT4Za9JX2CG7HRNFiDgz7UOErDZgcgrBiZ5Nrc1emqEwrsJBRO4WkQYReSVtW4mIPC4ie7z/i8dzjOPJUG3ek4VkiGjIamO6fRgDBwH82Ey3D5Mfb5yUQnCiC/PTxYelGRnG26x0L/AfwM/Stn0O2KCU+oaIfM57fss4jG1CMBHNJ6dK0lxWYR/Hj4XCwAEERQCLInWSA6v+a9IJwbH0hQyHyWD20kwcxlU4KKW2iMicXpvfDqzyHv8U2MwkEA7aljt4kiGiOURRadsjBFGAiT1i926sP5eJLMynqg9LMzqMt+aQiUqlVL33+BhQmekgEbkRuBFg1qxZYzS0zEz1fISdWx6kYOO/Ml0dxURhIxyWKtpXf2NY7y+5wlYbrkMAByGGH1tMDOVAD5FxauOeqp/LcITecPI2NKcvE9ohrZRSZJkplFI/Ukqdr5Q6v7y8fIxH1pOpbMvdueVBqjf+EzPVEUyUt7JXzFL1VG/8xLCdmededg17zYUk8LuCAQNDOfiwOWTOHpGxT9XPZbiO5anqw9KMDhNRczguItVKqXoRqQYaxntAAzGVbbnOc3dRqDqAbimd/L9QdXLkFGL4E6u+QMvGfyFPdeLDxsKkRQpJrPrCKY8ben4uIaudUsd1dCvrEDu3PDhpJ8VTyaeYyGYvzcRiIgqHPwAfAr7h/f/78R3OwExlW25R7CimF03UGxOnXwGYyfQBpLY5wWkcmPs+co69kHLgjqRPIPm5mMqm2j6Kg+B47yZ/EpuXpvJiRDNxGFfhICK/wnU+l4nIYeBWXKHwGxH5e+AA8LfjN8LBMRhb7mR1WLcGpzG96zBmBuueg2QVgDu3PEippxX4sSnuaiK+8RMkCNFuFqbMIYUHHqR91e3MGYV7kfxcSpwmnOQ2FMfNKmzxTdrM5am8GNFMHMbV56CUep9Sqlop5VdKzVBK/UQp1ayUWqOUWqiUulIp1TKeYxwMA9lyJ3PykXHxx7Az6g1gI1lj+P2bv06JOomBIoGJgaJYdVCgWsfMB5D8XEzlYKCwxEe9WU3UVzCpV9oTPZ9CMzUQ1+c7uTn//PPV1q1bx3sYWdnxzav6rvTsLiKBUpbe8tg4jmxw1N82j0LVRogEgutziOLjpBRRfdu+jK/pvLUCheBI9/ojV3WhEF4Pntt9oFLk2q3M+fIrGc4yMmS6//mJRnJVJx1G4aTS5JIkNdHRMMdpTh9E5CWl1PmZ9k1En8OUY7LbiBvCC2jPItyq+32l6vVM+uggY2EO6W32y7eaqHQaOS7lkzbEVTuWNaONFg5jwGS3EQ8nPv6wbzazrDpMLzzVwI1KtjDw210jEmc/WD9O78zlXNXJcSmnPeCGQKdH++zENYnNtA+k3kf88i9MGqGh0YwU2qw0BqQnY6VPipMpxnyoZoxkfkSxagcUCsHGpF1yaTIqCREZkjmktyDoqlpB9YEHh3VPD3x1savJSZoeoxQliXoUUKJOYmECChOHVimiafUdk+az0mgGS39mJS0cxojT0Ub8+tcuoNo+hE/ZxCVAs1GOLeaQfS2ZhOt06zDNUpxa/cPg/TjZfECldgN+lcBApXwlhnJwRKgLLxnymCdjdJrm9EL7HCYAI2kjHq2JJ9PqPOfYC32uM9jrh1SEQ/4FfVboQ/W1OM/dhaEsKpwTBKw4cQngJ0EB7bTTLRwG48fZueVBQvETzLb2E7P8NEo5thkgoGLE8ZNDlARm97XFwKcSFMaODvp9j3bZDi14NGOB1hwmGaNloup93nSnbbu/LHWd+tnX9GvOSZ+48pyTdEou7f6hr+7Tqb9tPoWqDQcDR9wyGyFiOBjsCZ6TOi4/3kgu2SOQ0t+j6SQoVw0EVYJ6KSdm5jPDOkCABBYmCfED3ZrDUWMmISKDuu+jGZ02FUyUmomD1hymEAOVThjuqrL3eQtUOzaGuzqXcrcxT7yT5bV3oTCISpBmVeZ2bktz5qavmMWxqHQaIQHtvrJ+HdD9jTtA3B2jZ+pxxMBSJj5s/HYXph2nSh0jTJwIQVodybhaT3+PCRMOUUh+opEyp4Wj5HLMqGKGc5ggCZQCBwMTh3aKCKtOilVLykTWQQ4Fqp3yDTey47m7eoy3IrKXMDGCVpyYBGg2yoia+T20mpH6nHQrUs1ooYXDJKO/sNhTMWf0Pm9AxbEwCSh3Yg5ZbZSpZvzYdBDApyyq7XrqITXxnew1cbUHyiEOuaoTx/b16G+QPjlGCFPmnOiROZ0cN8AC1UUQC1tZxPF5/R8MWiUHRxnMVkcxcEhgECDBXHWITivICSnuMWlmunfFTgth4sy29iNeRJWNuAICIYGPuASoduqxMfDhEFRxCukgjg8b6TPeeaoTwSGBmbpPTU6ME2G3evBIfk7pn79GM5Jo4TDJ6DcsttfkbCqbEqcp4+p2oPPGJUBAufZ9gFKnCQDLy3Z2xADlUOo00SDuxJ+10B0GR1fdztJeGePJyXFmfC9+LLpUHgkvcxobCjb9KxVOA0Es9/3gECZOJ2GapDQ12R6Iz2GWVYcfBwU4QIi4K8wi8azvsTB+nDxiKPCaDgEIFoKJ4ohRRbuvjJmJvZheVaZkroYCAlh0EOq5egeajWLKnJbUfTKURYlq4eTF3wBObfU/2cOiNZMHLRwmGf3lHBRs/mKPydktNud2WBtoddr7vG2ST6VqpI18UIqQigE2Fj5yiOIogxgmIWWnrt/63F0URw5SrFrJJYKDQRwTG6NHobvek6MfGxuDSvsYltPoaSuKMIk+41SAgYUfi2DsBPPsWrokmConjpdmZ3jPcomw45tXURHZyxzVRQ5xInaANvKpUj0L/hqAjcKPwkEoUK5JzadsFILhheRK6lqk0vqSq3fBNaEl7JAnHOPExU+EcOq+D2b1v3PLgwSe/DozLDff4pA5m8SqL+ieDJoxY0L3cxhtjhyB5cvhC1+AZ54ByxqZ8+7c8iA7vnkVB766mB3fvGpEayhlquNUP9udcMvsBmYm9qZW7W4tVSEugQHrGPU+74nQLLbN+0dOhGeRa7cSw4eB4GAQIYACwiSI4Us5Q7uqVlCpGgkT9QrdKUJYtEl+j2sne0gniUkAE4ccoviUhUIyCgZwp/4gFgqFIQ5dEiKgEl6t1e7gCncydwirGMWRgxSqdk8IKUzlUK0aMYAopneXXEzvcQx/yqQWl0BKIKi0q9gIBjbQvXpvDU7D70SI+vI5EphHXfAsGsxqGsLzU2NLHpNO+up/55YHKdt4E7OsutQ159h1lG78FwDdk0EzJpzWmkNzM+Tmwje/Cf/v/0FREVx1FaxfD1dfDVVVQz/nWHQfSw+L3bnlQaq96x2TSqareqbZhz0bvB8DRbNRBvT0TWRyhvY+b07aMRJ1CDjuStsWH5ZSqZ7PSWd0zrEXOG6UM805hniCJIFQoZqxrBOpPgpOL9NIs1HGHPsADm6l1zBx+kNQdJhFmMrCVBahXscbKDoJ4iMBKKapYyjPXOQD/MQ985OQ1BfScRsaOUQl5I2vnDy7AxAiEsSvEgS9qKa4+FOF75Kr9+TKPj0iqk4ZqR4SA63+nefuIpcObMyUE95SkKc6aXzuLjfiSQsDzSijQ1mB1lZ4/HF4+GF45BGo95qULlvmCor16+Gii8A3CFE61kX2el+vMH6MKtWYMrNE8VNvziDqy8dvd6EwCKoIhrIoUG0EVQwHHy8XrSEn3kRR7ChRCZNvt9BhFqUmr9nWfhqlhDy6CKkIPhwS+DBQxMRPUCVwgKPGdEpVMz5lIShCxAAhQhAHocUsyxgOO8eqdR3gWBnLg6ejgAQ+TGwS+DwfQwID19/QRZCE+ChWnZ5ZLWmOIvU8qSl0l/LurgTl+hxI+Rz8ToQSu5Fc1QUoYhIkRoBc1UW75NNmlqAUhImk8kNKDj7KHKuWGD1zKXqH/GZKijzw1cVU2UcxUK7fwjPPCdBgVo5qkULN6YXOkB4CSsGOHa6gePhhePZZsO3BaRU7tzzIvA03IjjEJUizUU7Ulz+qlUfTS0GErHam24fxe9VTk5OiDcQJ4sMmit+d/FWn2/xGDLf8M04PB2xAWRwxp7uhqsDM2B4QOBRYyPR4LT5lYeLgJ0GUIIAnCBQOJoa3LleuAYgEfurNamzxEQmUYlz8sdTkGCXMTPsAYWI4kJaClh3V63Fycrc9ETBcldg9h+tJOCn5xAnQEJ7fo1FR+oQOULbxJnLpwKcsLPHRSR5tZrEbsTSMRcLrX7uA+dYbnnfDFWOCQ5Qge3NqJkUlX83kQOc5DAERqKlx/z7/+b5axW9+4x6X1Cre/Ga48EJ49VnXnGRjYCBeCONR6pmGLeagokmGE/ueHr1S6jTi91bQSaFg4H7IQoxjUk61aqJARXC8ME1TJTC9jg0lTmvKAWthUuo0cQRXODRKOTPUUfx2F0EVx0bwY7krdzEwlZVyAiscbISAty63gBYpdAWNlyE9xzNhJc1wkDTnDIzjOYdTn5n3f9IcNFyUdy7TM0s1mxWpPgmpz6HX5/H61y6gSLViY2KJH0M5FNFKkdVKbeCsHsemO53TP+uohHtoHoV2Ow4mZpq5yzWAOcPu2dDfd0tnXGsycVprDnE7zsa6jayctZLcQO6Ax/enVayYtZkr5m9m1fwtLMl5JbVudsSgxSgb0GnYX+Yr0O8PO/m6GdaBVM8F29Mdkit4B4gRJEA8o9kmGelTZ86h1GnE59UYqgu6E5zf7nIjlILFLOjaji0GQZUg5oW65qgIRmqd2xMLAxuDI+YM/E6sRxZzMHYCQxxmWAcJkMh6jnSS99botc3VIAZ+/WDodjobHJFK5tz2GtB3Ij2zaxsWBo50izVD2YSIU+ubn1Fz6KpawZLa/8HA8kxpbjTUEanGNgOeCa+YEnWSEHEE19R1UvIou+3wkN/LQN8tnXF9+qLNSll45uAzXHrPpfgNPxfOuJA1c9eweu5qLppxEQEzMODrW1vhiSfgoYfgT79tpLHDLROxqPpVrp7/OOsXPMYFM17i4Nr/GvCHls1X4ShjwLINyQlrQdd2wl7cfnLqNL3Yf/AicDzNIhMOQrvk0myUM80+TAIfhwILMpbIyPfabxrKjf8PedFFydV3bxSukFAYHDfKSRCgXDWQpyJ04jp+c7yxu+Me+veyt0Zxqjgko54Uz8/7J/Lmnt9nIp1v7fN8FE7qvjoINkK9Ob3P51Y/+xrOrf1RqjNdjooiKOL4iEmQI4F5zIzvwa/i+FOC3T2fjZ/aNf895Em7Pz8YMKkbUWlODS0cshBJRHjq4FNsrNvIhroNbKvfhqMccvw5XDrrUlbPWc2aeWtYVrUM0+jf4LH9G1dx4GApm/at4uk3LmT7wcXYjo/8UDvr35Y/YARUtjLSc+Jv0GyUUKDaU0lpbZJPxMhHKXr0HWiZtY6a2h8S8LJ78Sat7hBM1a/ZxgEsfBw3yql0GvFhAUIHIXbPu4GLP3R76tidWx6kYNO/MsM5OqQJOYpJs5RSok7iIISIYtDTNASZBcx4YiOclHw6ycXApkI14/PMPpnGHsdk27yPkXPshR4+Cue5uzizaxtxfCBCroqkPp8EPuqCZ1EYP8Z01ZASTuBqRI1SzLHwGUOetLN9t3LtVgSy7tOO76mPFg6D5ETkBFsObGFD3QY21m1kV+MuAAqDhayas4rVc1ezZu4aFpUvQqTn9NVbdY90mjy/7zyeaP8Uz2+fPWAEVLbV3SzrgOs4Tis658PCh4OF2afvwP7CFdS0PobfW8kn8OFDYaEIDWCPT676lffnlofwESCBjUGrFNAQXpCye1dv/CRF6uSg/ARJkn4Q6F7pZxME2bSQ8SLhZU73lxyU/DVFsjiPD3x1MYXOCXzKwhGDsIp5bmeHdslzNYfYnlQSYTJaycIgJkFajeIhT9pac9BkQwuHYXKs4xgb6zayqW4TG/dvpPZELQCVuZWsnrs6JSzmFs8FsvdsGEwE1OzCh5m78+Y+ZogSpzkVBZMkad+P4cfnig0UQgwfh31z+moUeQupaX0sZfoZiOSKNbkCDuAmpnVILg1mFQEVI+h0UamageFN4BNt4h8pkuYz0wuajRJIdZMDmLbxn8hXbalIkHRTWByDuAQJqzhRfG6uSLIHt3JzSl7PWT7kSVv7HDTZ0MJhhNjfuj9lgtpYt5FjHccAmFM0J+WvuGLOFVTn999ZOemrePhh+OPvIzQ2u9nCi6pfY+WCZ1mzcBPz5jcSuPSjlG38DIWq3RMB7kSSQxRIrvC717EGDjYmdb65PZOrJEyR3UiFOjHo95rNwZs0gbgr2tM8xb4XtpdDnh5GnLxfnRKmkxwMLCpUaw/hKEBcCbb4sTDxe1nlhardK+2nUrkde9f8eMDAhkzBC/3lVZyOjag0Llo4ZOFUQviUUrzW9FpKWGzav4nWaCsAi8oXsXqOq1msmrOK4nBx1uvnbfoiLx8/l017L+eZN1bw10NLsB0fRUWwdi0sVt/mzbN/z4K8upTPwa9iqfIS3ZOQGxXvAB2SR1C55aLbyKdCNeHDTUobaDIfzIp+qq76TxU3jNnpc2+S98vusSeZxeA6o6MS4khgHuD2pahUDV7v7W4hc0LyqV/9H1m/o7rXg2aoaOGQgZH+IdmOzfZj21NaxVMHn6Ir0YUhBsurl6eExaWzLk2FzWayBUc6DDYduJJXg1/qka29qPo1LjnjBVYteJLV0zZQISdSggHo8Tg5STneut/nTUsDTeoT1Rk8Weh9fzPdz6RGlvw8TBQWgoPJ3uAiAELxVuaogynTnhutZNAg5ZwIz+phVurTXIncYbVO1ZyeaOGQgR3fvIqc9gZCtTFiFTnESkP4iY7YDylux3nhyAtsqN3Axv0bee7QcyScBH7Dz0UzLmL13NUsevKnnGFW40+PhEqLFEn6Ku65axdPP+6w48DZ2MpHUaiVtfM2sn7B41y94Amq8hr0an6ccUuVBAh6uRrZsDzBnV6uI6n5HTDnEPXlMzO2hxwidEn3osFQDpb4ejikey9w5sVfRWFQb05LZbajFCWJozSEF1AR2UeAOHH8qcACrVGc3kzKDGkR2Q+04wa4WNnewHApih3FbjCY+Ss3uckxhXhpGLvcB9GvwDnnuH8LFoDfP+TzB8wAl866lEtnXcqt3EpnvJNnDj3DhlrXBPW1LV/DwSFsH2SZU8CFUsSFUsgSx0hlU7/y1IOEn/w6/6/6AMYHHdqiuTxRu5on9q7m0b1X8tvd7wBgWdUOrl7wOG9e8BgXztiKz7D7G1pGxkq4TFUh5laLdQv99Uey1EfyNa7z2m0wNNM+gG0bBLCJ4fdalHrd7xBCKtYj07536fOYhAioeI/M9vxEEwWqk0T0IIWqDYAwURKRgzgjXBBSM7WYsJqDJxzOV0o1DXTssDWHrkaMJgg2dBFs6CJ8vB1/Y5zgiaibDg2uYDjjjG5hsWjRKQmNJCciJ/jZQ9/ir6/8iGfpYo/nZM7H4Pyy87mweAnr3niUFaoTB5NQr8xmpWDH8XN5eO9aHtl7Jc8eujClVVw1byNXp2kVg0GblE6N3gX9MpHNzNSlfOSKm9me8IpmuJqFgeVVZvUpCwehbs2P3Nc9dxdnd71ElwRpNiqI+vIpjB+jWjV4dWbFK7MOjUYZBao9FT6b1EIazKqUpjzaJTR6n7+ragU5x17QJTvGmUlpVhpt4dCvz+H8q+C112DXru6/3buhri6z0EgKjGEIjeSPJh49wAZ/gBfLqvhrZB91rXUAVCiDywiwVsEafMzL4lJujRbyRO0qHtq7lkf2ruVYh5ttl9Qq1i94nItmvDgsrUIzOqTnfLglxA1iBLzgASfVw9rnPX6xaD155/0tpRv/hTzVSQ5Rkt0lbMwePS2S5VAUwgFjJtVOfXc4tFL4sKkLnEmu3Ur7qtsH5X8brgDp/VvLTzRRqRo5bpT36C2uHedjz2QVDnXACdzv+X8rpX7Ua/+NwI0As2bNOu/AgQNDvsaQQ/i6urqFxu7d3YKjt9A488yeAiMpNAZT89vj6a+cwSvOEZ4Ui80kOCbu+ecoYTU+VisfV2BSnUFYpGsVD+9Zy3OHV5ySVqEZHfoGE7hlMpJFy4NeYcOoBGkjH8fwgWNRpZqwMDFJEKKvsI/iIyEBDOUQJE5EgjheP+tMmgMMnAh3KgEcvQMvpsdrU5F3yQgt7TgfHyarcJiulDoiIhXA48A/KaW2ZDp2rPIcstLVBa++2lNgZNI0zjwzo3lq57N/6rMiCzz5deZbe7xoFcUb2GzEZqNYbMai1bNNnK0MVmOyWvlYhY/iDIaN1mghj9dewcN7r+TRvVdS3+HmYWitYnxJ97+kl8oQb2+nhDkUWAhAyGqj3D5OPhEsDOL4CJIYVA0qNzHPLaNueVWgmqQUx3C7+KXay/ZTQuNU+pT0Lt8xL/YaCUxXe/EKO+qSHePDpBQO6YjIbUCHUuqOTPvHXThkIyk0MmkaHo7Ph1ViEq3IIVqRh1XuQ5WbJIoNpkljqpx2+pRvo9iOwwYsNonFU9h0CYiC5RgpzeJSTHJ7CYuR9lVohk+6cOhdukSAOmM2iFBhHyOXKDYGPhxs3CyJodS0iqRl07dKPkfCZ6c05cFM/P3VZxpoQteaw8Rl0gkHEckFDKVUu/f4ceCrSqlHMh0/YYVDNjo7U+aphrtvJae+hUBjjMCJWOoQZUK8NIhRDr5yUOUGqtxASgwwpMeUH0fxfJpm8RdsEgJ+BRdhcgUma5SPCzEJ9BIWSV9FUlhorWLiYKXVnjrVQAELgzeCi8mPN6ZKpif7SBQ6zRSoTpqN4qw+gN4TfFKTMXHYm1PTr0lW+xwmLpNROMwDfuc99QG/VEp9Pdvxk044pJG+IpO4TbAxQvB4JxX1h4k3+TMKDUpdQUG5iZQbUG6AJzQAOlE8g80GsdiIxTYclECOgksxuUL5WIOPZRhe80nv3P1oFWvnbWL9gse0VjGJaZQiStRJDBRdhPCTQGFwRKrxk6BEtRCVYK+Fh5sT0RUoY0nrhlQPiiAWNgZHjWnYhn/Ayb23fy8ZraRLdowvk044DJXJLByyqfTJXs9xCZIbaaWq8ThGo41qdJBGBxptpDUttNUTGnhCgzShccKAJ7HYKDYbsdgtbnXWIgWr8HGF8rEak0UYpOsk6b4KHQE1NUhGRQF9+kjkxxspV004GF7LVtc53ip5FKsOWiWfIAnyVScKxTGp5GSgEtBmocmKFg4TmIEqZgae/DpzrFoshLDX5S1FXEGTKyhocFKP+wiNMsP9KzehwuBYBWwsVmw0bDZhUedFQlUpYbWnWazGx9y0SCjtq5g6JAu3K89rkewjMSv2BrlEcTBSdZ+SfpD0+k/zYq955QAFW3ypOl4RglTfVjt+b0wzZLRwmOAkVe5keYMkca9zW6fk0u4v54zYTnyDcULGFTQ60OQJDe9xNk2jbqbBxlmKjSUOG4MOxzOEza7GpCpNWGhfxeQk3fHteMX/3NwKG78XFpt+DN5jtxGUn73Bsz2HcowQCboI4Xj1uxTGsDrVacYPLRwmAUkNwlAWFc5xfKl1nVvn/4g5mzl23amVyO6taWQQGo4Jry4UNp4pbJwJm4sdWr3ST4uUkXJuX54WNqt9FRObbKXVe4fS9j6mt3CwMdkTPIeQ1cZsr19ILK2eVAQ/h31zOPNLL6bOMVAJcZ0hPb5o4TAJSPoeqq3DPXopJwVEJyFyiI1oj+QUSU2j0fb+98xTJxW2wF+rYeM82HgGPDUNunxgKFhuGVxhuiao9LDZgbK1T6UGlGboZKtn1TsJL73uUzrJ0iAJTPYGFuF3Isy16khgEMIt6xHDjwL82Lyx5ic9eo1n6qNdfeDBES0troXN8NDCYRKQjFo6M56MGU8mRLk/W4UQIUieV4NpTIilaRqe0Ig3W7yQDxvnwoZ58JcZkDDB78BFbcIVCZM1fh8X5vkIGIb2VUxQFKTyJpJVYV3h0LdtqwOclFwUJu1GISeD0wjFT1BtH8JQKlUc0FCOW/8pZwlLb3ksa7BFqd1As1kxYq1JdR+L4aOFwwSk90onFD9B2GlnhlPfo4GP2z9Y8OPQKMVUea05x5U0odHZYvOM2GwocNg0DV6ahhs2G4eVx+CKVoPVCZNlOSZmmUlruJgn9l/BQ3vX6mztcWAwPT3SE/OSDmsLk7o1P+rRPe6MDX9PAl+qQ6GBol4qyaGThvACrzBgiA5yyKMr5bjOUV3sCZwzrIS6TJxK9vbpjhYOE4xMK50S+ziFqsur9d/9mcS9H99B31zO/NKLRG4t9TJdVR8Tk+OJlWSvgJ7VP8egpWdMcaLZ5slYgo0+m42FDruL3F1FEVi1H1YfgNUnhbNNA8p87PDX8HD7Oh45chXPHu7pq7h6weNcPf8JqvOPj/bIpzzpmdeDSahL/2bZQJOUUX3bvh7HvPbVC5hmH8KHTVwCNBtl+J0YpeoER3wzqLDrCamYV4LcRwIfPmwCWByVyhFrSnQq2dunO5Oyn8NUpncd/oSZQ8CyiGPg4Cc3zXRk4NAipakG9QfMecyx64hhelU5XdxwQ9fuGyCO41XpdBDi+LAxySMyuiW5g0LxNB/X4OMab9Mxx2GTZbHBttg4z+bBs91pqqrT5opamzW1z/O+uuf5fMdXaS0v5ongWh621vNI7Tp+u/taQPsqRgLp9f9ApAsSHxAn2OeYxKov0NJrkVOp6mk2SkiYOTSrCmbb+1G4VWBtTEBoliI34c7O7dnr/OKPDeu9tQan9dUcnEiP3heaoaM1h3Eg00pnXuw1FIq64NmErDZKnSYCKo5CqO2lzvct2SxY+IhjYqBSTWdi+LG9Ms2GcsghmtXpOFbU4bARi41isRE7FTY7twuuOCKs3qNYsxsqO2AHS3nIWM8j5nqeTbwJGx9F/hOsnb2J9Wc/xtULN2hfxSiS7rCO4mfvmh/3seH3znyuiOyjxV+d+m4viL3qdaVQtEkezUY5UTOPkkQ9DeH5I5IhrX0Ow0eblUaAkYyGyGQjnRnbA0KqCidkV7W78yL2pmriJJSf6aoeBTRLMVWqMRVeqDyh4Sfh1fyfGCgUr+KwAZtNvarNLooLq1sNVh8WVr3hwJECnmi/kodZz8Os5xieryL0V66ufIw3z3+UC8/ahq/ESZUR0QyNTP6IZAIcCK/nLB/Q7DPUIntD+V31d+yQy+9rAC0cTpmRXplkOl+e3YogtJuFQ7pG8kexoGs7thg0GlVeV7DjVKnjCEIXQQwcwsQnjGDIhI3ir55mkV5t1vCqzV5h+VhzQrj4sLC37lwePnIVj5xcx3P2xa5WwQmukse4Ov9Rrp72OFXTGrvLiRRLT5u0pg+9hUMyKCJZYiO9f3WSTB3eqg88iOFYFNBOjopg4tAohTT7Z/apADDY35XWDkYHLRxOkdGIhsi00gGGvfrJZKoKJU4y3TnqZsGK3/uhugymreV4k6w2u8EzQT2fVm324lSZD5MzTxbz5Mtutvajx9ZSn3BtzcvY5ukZD3Oh+Rd85apn3alyE4pEaxpZSBcWFgZtksfR1T/osVrPmMeQvyRVpC8mQWIEyVNdtEkuDeEFqe/6tI3/RI7qIiYh19zky8/6u9IRSaODFg6nyGSIhhhMTPnZsZ0oL5oJBg5rnGikV5vdhMVLadVmV3oNj65QPuT4Uh7ds45H9lzJc0e8LnjmCdaGnmC9/RDrow9ThRsBpXx0151KFxpa0+iBAhqlhIiRm1qt7/jmVVRF3qBYteHDxsLkhBTgw+6Tx9C7VHi+3UKJOkkcX3cYrDmNqJmX8Xc1GX6DkxEdrXSKTIZoCOPijxHY/EWw6bGKi+MnYYQBN9TVRA0ppHEikYtwFT6uUu7X9gSKzcpik1dt9hYjBsQoqn6WVdUv8Lcr/41vRUs4WLuGR7xs7d9G3w3AstLtrC95hPX+R7gw8hy+AwlkZ1rtKR/dgqJMCw2FkKsinJQSnOfugsuuYUbkVYpVW8px7cemQp3AAVqdYqqtNwgTSwVN2JgcM2czM7GXgLJIeL4wRwxQDqVOIw1iZvxdTYbf4FRDaw6DYLLYOzOZqpzn7qI4epAC1U6B6sgoEAaTA5GpGNtE4xhOquHRRiz296o2u8rxUX1sOS/vuypzb+3Zj3F1wWNUddV7tadsaHKQtgxCoyxN06jwzFNTWGgkP/+kOTKZ2JbtHVsYGF5mv+EFQTgI+805VNtHUtk8JgoHwUHwk+C4Wa19DmOINiuNABMtGmKwUR7P/fSLLK/9L2wMgl7F13RBkIxdSk+o621usr1XmKliz5ODrGGzXrXZCyOlqNoreW7vVT2ytZdXb+fq+W629oUztuKLWylBkRIajQ7SnkXT6O3TmIJCYzAmSds7Itnn2kFol1wAfCqRMiWVOk2EVIxOCffwafRmov0GpwJaOEwxhrKK2vHNqyiOHKSAdq9Ji5DwEuRsDAJYPVZ30NdZ7Xi1+40JFAY7VPoLmz1HGaxSPuYdW8aJPevZvDeDVpGpBlRU9SlW2Edo+Mns05jkQmMwwiGpPQjK+065BfrqzelMsw+TwMehwAKtBYwjWjhMMYYSuZHuyAtZ7VTbR3EAHxZgYHptW5IF15Lhi8l/WyUPA0We6sRk8jmxs5EeNrvRC5uNpIXNvilaSt6+qzi4dx0bMtSA6jdb+zQWGtC9uOgihOAQJJ767nQSpN43k3z7JCeNYkJEtBYwjmjhMMUYSuRG38bw7ZQ7x/ArCxvIIYHyciESYlKg3BalbZLLG4UryYk3URHZR7lq7uHMnmrEULyQioSy+Uta2OxFymTRseWovet5Zc86nh+MVpGJwQqN3j6NSSQ0kn0flGdK8qE8z0O3OdPCYGvRei7+518O6dy6LPfIo4XDFKM/zSHphE52lVMowipBs1FMu68MvxMh3z6J8rSBpK8haf+1xcRRBrFgMUWxo6mwwzzVSR4RYGoKh950onjKM0FtxGJbWtjsRdESqvddRdve9Wzduza7r2KwNaAiqtun0ehAg+cIn8SaRgK8juTJ75crONxnbuTStnn/yMUfun1Q5xuMKVULj6GjhcMUY6AmKoayKHO6S3u3SQ55KkK75NMQnk8wdgJDHGZaB0lgggiGcrDERzMlzFBHOeCbQ8IIp8IOm6SYatXQb1TTRI5kOlVOoHgSK5WQ96q4zvkiB5YdP4/cPes5umc9O4arVWSit6aRTWj0DrmtMKFwYgiNBIbnv+rWOcWr+2WJj7rwuYOazAcypepopuGhhcMUJFvYajjeTIV9DJ+ycMRITfoNZlXqh5Q0S01P1KWOA/ApCwszVeMpZLUz296PoLAxaZV8SlVrnxyJZOMYQaUiU6Y69ThsSkvIS4bNVkSKOGPfOtTe9ezZexUNQ/FVDJZImtBo8oRGo4N0TFyhYad9a9ySHCZh4uz1Lcg4mffWAioie+kil1JaUn0hminBNBRzvvyKzqAeJlo4nCYkJ/258dexvGqsKLdccl3gzJRPIvlDMpVFtV2f6gPhiEFQJThsTAcxqLaPEvAqvApuv+AWKaKANoIq5vWV6MuY9I6YYNThsMGrCZUKm1Uw7VgN1XveQseeq9l7eJS74A1VaJQbruAYA6HhmpTcBUSUAEHcisMHzdmUOo0EVBxLTOrNmcQv/0IfLWCmdQAThzj+VHMhHzb7zbmc9eUXdQb1MNEZ0qcJySzSuAS6NQcUcQn0yCZNZlPHJUi9VFKuGglisd+cDYDgUGEfS/UGDhHDwcABCmgjjr9HL4nepCdL9dYwxt/QMTrMxeAGAtygAigUu5WbkLep6hU2VW3n5GW3Q6SQGfvWkb93PY/vXcdvdr8DcLWK9QseG7qvojdhgVk+mNVzs4pkcITvs5Ad/QiN5OMREBrJMvHKy5MJEsdA0ST5TLcPee2sFAGVYJ71BpGN/4hfxd2aS8qtueRYBn4SgN8dj/KCI7yh6QzqkWdAzUFE/gn4hVLqxNgMaehozcElaXft7XNoklIcw5eqhJnusI7jTxVDS28KX2nXk8DvrdAsEvgwcVCeMzGHSMZ+wyr1v3jZES7J9LnTTaOALGGzgBxbyrQ9b0b2rufooYtxxrq3diahMZCmMUyhke6PSpohLSCQimvCC6l293cQ7lFzaZp9BAOHiIRSJcCbpRRTHOZ8+RXtcxgmp2RWEpHbgfcC24C7gUfVGNiiRORq4HuACfxYKfWNbMdq4dBNd6+HvpM/9F8iOb1PRInnW+iSMM1GGVFfQcqGe3bXS5jYfdqUJsnmmLZxhcNU1R4GSyyt2uzmZNhstBBz31rK9r6Zzr3r6OjwKsuORxe8wQiNAJmjp/oRGultbNNJ+iMMnJR22UWoh8/MUPaA/U50BvXQOWWfg4gIcBXwYeB84DfAT5RS+/p94TARERN4A1gLHAZeBN6nlNqd6XgtHAbHQCGw6YIjP9FEpWrkuFGeCoFNCpJpG/+JItWeVThAt98haR+GqW1WOhWSYbMbk9VmlQPHl+Lfs57cvX9D26GLPK3iBFcle2uPtlaRieEKjQoTCvrXNJIBDcmciBhBbK/mUoAEJ6QQwRhyv5OBeHpPI3c/U8fBlgizSsJcf8lcLl1YPvALpwgj4pAWkaW4wuFqYBNwEfC4UuqzIzXQtGtdDNymlFrnPf88gFLq3zIdr4XD4OjPaXcyg802WWa53SjssRJ77qdfZEXtDzKaiNIL9CWLbSRDGdML9yW3a/rS4oXNJmtCvRrNh9q1BPasR/auJ5aKgNrO+gXDyKsYaSIq5fxOOcKbhiY0LEzvO+LQRZhDqpxqaSFMjA4V5iuBf+aqRZXM2vPTEdMMnt7TyFf+uJuQ3yAnYNIVt4kmHG5966LTRkCcqlnpU8AHgSbgx8CDSqmEiBjAHqXU/FEY8LuAq5VSN3jPPwBcqJT6RNoxNwI3AsyaNeu8AwcOjPQwphzZNIeTZjHFsaM0OgWkYtEFAiaUSHvGaI+mL8+gUDrwpWkFDmDhI4FJDnESmPiwSXhHhUng4LadDGABQhyDIHYPDUMLjZ7Ue9VmN4jFRmVx8PhS2LMe/971WIcuRikfBaETXD2eWkUmupxugdGYFj3VmUFoVJjEy/2Y5QZHyss4ll9BWGKEiPMNrqOu4ALmluVy93UrRmx419/7Ao3tMXKD3XE5nTGL8vzgiF5nInOq0UolwDuUUj1mX6WUIyJvGYkBDgel1I+AH4GrOYzXOCYTmXo++JwYP5M3c636A6W00oXb+0EpMK0I9YEK5mQ41yuygFJamUEjPiwcDEwcEvhoUXlUygn2OdPwicVMaSJIgk7lRxBEoEuFUEBAbNpUkFpVzRnGYQS313UyuzapcUQJAIoQibG7YROEagzej8H7lR+Ausq9bKj8LptWfpsnonk01l5J2571PLD36lQE1LnVf+Wt858YE60igSCQWiikyDFgtkFstg8/VneTqaTQSDNNqT0Wwe3uZzubDmYEDtJRnsuOsjM5q3wPZmmUpjkLQF0wYiG3B1silOb6ew45YHKwJTIi55/sTMg8B21WGj16O+3u97+V7f4aiuqf4Uu+nxFRAboIkUOUsMT5lvFhfnzbzX3O86Xv/IAPnvwhpkpQJclANsUxVYqFyf32Si40XmemNHBIVfAT+2oAbstwjdusD/Kscy5vMnZym+9nmNiUSDshYuCF0yajpgJuTrfGQ6HYlUzIw2Lj8XPo2Lse9rwZDl0Mykdu6ARr523kbQueGFGtQgEnVYi77GtYb77IOXIAP5ZbYE+F6FAhSo0ODqsyTGxmSWPG6LZmVcCnrI/zascszmk9zLzGg5zRdJAFjQeY33SQ8s7W7hfk58OiRXDOOd3/n3MOzJgxoNDo7V9o6YxjO0prDpMpCU5EfLgO6TXAEVyH9P+nlNqV6XgtHIbPld95ktJcP8/XneBNxk7+3nwkNaH/gjfzlL2Yy84o6+Owe3pPI/fd93PelfgD89VBQiSIEeCgfw4/sdbxROycjNfrfY2f2FfzrHNuv/uBHtuKaKXGqEuFPbY5QYKG45mqgDTzlKRtSUZLTeVwWhvFNi8h7/FYLs/sW01873rYux48X8X8qu1cu+Bx3p6mVSjgqCrhSWcJf2M8T4FE+uSoxJSBIW43wQQmrzqzuMP+234/v784Z3KRt0joIEQFJ6iWE57zGWrVNG61PtTjHIaAKWA57udXGGnjjKaDnNF8kH8sizLtaB3s2gUNaUKuoMAVFukCY9GilNDI5F9o7ogjAiW5Ae1zyLRvIgoHABF5M3Anbijr3Uqpr2c7VguH4XP9vS9Q29jB/ua+qrRpuOalc6YVZPzxZIr0ALjlgZepPxnFmZhfrdMKRYKY8RoReZlIQ4xE7dmwd11KqyDUSXDuIXLndpEztwUzLzbeQ3ZNVAbYTnd+TJKgz+CSBaXuIqVYXCGxaxfs3u3+9RYanqbxVKCC10tn0TBrPkeq59JcXEFn3MYQKM0L6milTPsmqnAYClo4DJ+n9zRy489fIm7ZWBkavVXk+5lXnp96PpDanXTyWY5if1MXcdvBcbqd1prxxSFCzNhNJL6HyIEirL3LXWHh5VWYlQcIzTtO7rw4oWltiDHxPrW5ZTn4DCP7Cr+piZcfe5btjzxDQe0bnNl8kKpDtRSnmae6Qrkcrp7D3vLZvPk9a7q1jenTJ0TBwrFCCwdNikyr/c/e/zKdcYvOmI3tTeSGuJP5BXOKkbQfi1KKgy0Rzq7OT51jxZwSXtjfwsGWCEdb3W1FOQFORhK8dqydkfqK+TxNxp78X9kJg007UdlJV1Mb0doZOHsvhkNv8rSKNgJz3yBnbju5cy18efHxHi4ARTl+ZhaHsy5S0k1IccvmaGuUjphNdbydS+LHOavlEDPq91N9uJY5x/dT0J5W/CFpnvLMUq8UTeee1hx2qHxmleZMOc1CCwcNkD2uOzdoZnTMHW2NMq0o1GP7sZMRjrZGCfoMEo6XsGQ5zC7NoSI/yO6jbcRtRWVBkObOOJ2xkYmSKc7xU5YXJGHbHD4RxdI2q1HBooWuxOt07Q8Sr12A2nt5SquQqjcIzdtP7rw4OdXGuGkVAdNg2axCmjsTPPGZy/vsT2qvCdvhQHMXhgiW7RC3FaYBQZ+J5ShMQ/jk6gV89JzCbpNU8v9du6CxMXXOrlAuB6vmUFcxmzPXXMS8VRe6AmTatEmtaWjhoAGyx3UbAl1xp4/QeOfy6Tyw7UiP7a8fa3dDUE3De52NoyAnYHDujCJau+Lsa+wkMcLL+9LcAB9ZOZcX9rfw5OuNWnsYI+Ico7OpiUhtMYl958KhCzytohXfvB2E5h0jf7ZJIC88ZmMywF3QKLhoXkmf1XwyyOL1Yx0kbAfTcLtJdMUs14ehoCDsoyQ30K956lPff5ScvW+woOkAM47WMbO+julHainsPNl9UGFhXyf4JBIauiqrBsge193cmeC2ty7KWEZg8fTCHtvfON6BzxBMI1mb33UgRhJe85ucAIbq6HccvTOlBzoWwGfC9zfuJew3tWAYQwJUESirorgM1IpmYrF76TjgEK2dhrXvPDp2X04HQNUrBObvImdeG3lVhZhG7qiNyQHaPY100+uNPPVGI2X5Ic6uzuf6S+YyqyRMY3uMqGXj976njqMQEcI+A6Xg7OoCwF0c3f1MXUbhsMsKUXrOedRJ99yplMI63sgDlxX21DQefBB+/OPuF6cLjXThMUmEBmjhcFqR/NGkaw5dcZtZJWEuXVie8QfSe/uiLz/iGv69adsQwVY9q7PGleuzEBGSmmnSChTyzFH2IM1CySs1tsfxmUJL5ziViNAgCKFgNaEzgDPAUS/S1dhGZ12QWO184s++k/gzPlpDLRjz/kJgfi15c+OEw7MxCI3KmJSChIKWjhiN7QG+8sfdKY3Xbwi2AlEKR7nfVZQi6O/OlOkv6S3b76V8VjWsWgGrVvXw4Z3ji3JDSYRzTx7pX2j0FhjnnAPV1RNOaGjhcBpx/SVz+cofdwNWD/NRMgR1MJxRmcer9e2IozAMwWcIlqMI+QyUUnTFbVDg9wlKQbxXBJStFIun5dPQFqO+bXBhkwp3EohbWmWYSBhikldRTF4FcGE9drSe9gMJumqLSNReQHT3m4kCVG/DnLeV0Pxj5FaHCbEQwT/A2YdGzE76zCxe2N/CrW9dxLcffY1XjraDUhgiOIDjwOzCbkGVXBxlItPvpaUzjiGu6So3YNDUEackN0Bprp/auMFnGkLc+tZLuPTjaQuthoaevoxdu+B3v+spNIqKXIGxYgV897sjem+Gi/Y5nGacahXKp/c0cssDL3MyamFZDj6fQdA0mFEcojPuMKskzIHmLg60dGE7qkekkgjcsu5MPrpqAU/vaeRTv/4rrRFr0FqEZvKgFMQaAnTUmURrq7APn+H5Kk7A/A345r9CztxWcsJzCai5yAjkvZ9dnU9ByJdyVD+9p5HP3v8y7dEECUeBUlgOzCwJU5EfHFTSW/rvJS9o0tAWozTPTZpLBl/MK8+lMOwKu0FnWCvlOrzT8zR27YJwGB555JTvxWDRDmnNKdFboKSHrmYSME/vaeTvf7qVhOXW5zcETEOYVhRiXnle6oeTPO9faltcjUMzZXGiPjr359FVFyJWOxfVUeLuqNoGCzYQXLCPnCqTMOfiUzO8ak1Do3eIa6YAjGMnI7RHbYpzA0NeHPU+3/ZDrRhAwG9yVpWbC6SUyhpFNRHRDmnNsEkPfy3N9dPYHuOBbUf6XW1durCcktwAkbhF1HII+UyqCoMUhv097LtJf8bTexq57p4XdXjqFMYIWeSf1Ur+WaDUMRINBXTW5tFVW4T1zGeIPW0SC53gxPzHkAWPEJp7lJycWYScpfhUxYDnF6AjZrGvsZOmjjjX3/sCr9W3M7OXyaiyIITPHN7k3TugI+QzidsOsUS37bQ/M9VkQwsHTb/c/UwdIb+RWi0l7bp3PPZ6v+aps6vzM4bN5gVN3v4fT7GnoRNwfRg3XXUmi6cX8NqxdmKWg1I9I5qS5RQsR2dZTwVEIFDZRqCyjeKLj+JE9xDZX0ZnbR7RuqtRu95DBIhUbYOFD2POf5DQtDhhziVkL8GkuM85FW5EUkVRgMqCELWNHRxri9LYESM34KOqMEhRTiA1eQ/HvNrbQV1VGKSuqQt/mr9tqD68iYw2K2n6JRkznp4lncxlOKsqP2vBskwJdy2dcSJxm8647YbCKoWtoCwvwAcump3KqUjYDodbo0TjNj4DEg6EAyYzikJEEzYN7XHCfpPmzp4Zu0MJkdVMTJSCREMBXbVlRGoLiR+pBGV6vorHYMHD+ObvIpxTTcheSshZjEEeAJUFAeaW5dHaFedAs+vzStiKoM9ABPJDJh0xh7DfJJKwqch3BclgC+5lK95XURCkI2ZPytpM2uegGTaZ7LavHG1DlOKc6YWpbZkccb1XZ80dMWobO3EUqTwJ21GIIayYU8z1l8zNuJrLtsp7079toLE9iq3oU+QvvRqrZvJiR31E95cRqS0nUleC0+EKAqr+CgsfggWP4J/eRFgtptS/nOVVF7H3WIKE7WAYQlfMQkRSJsuqgiCRhE0s4SDiJld2xGwiCZu8oI/vvbdmQAExldqKauGgGTaZVkuvHWtnXlkOxbnB1HGDccRd+Z0nOXyiC78hKU1EAQnLYUZJTr+vzfSjvPuZOnYfbaOhPeY5vt0GQZbjOsG1C2NqkdQqIrXlRGrLiB0pAWVA6CTMfxQWPIQs2EAor4h8VUPQXoJpn0GOP0g0YWOr7u+Fp7iicMuD+023rdSskhxdsttD+xw0/XLpwnJu7ZU9nWniHYwjblZJmOMnI67m4C3tHUfh8xn9vjaTUzyZ7PSX2hYCpoHfFBwFCdvBbygSGSrMaiY36b6Kwov3pWkVFUTq3oqz629RQLRqF5GFD8LCB2H6DsKcRdBcQshemgqbTf/+KiBmKXICQshvZM2YPt3QwkEzIL2zpJOT9VCT6a6/ZC6v1bfT3Bl3zT1Jn0OOv9/X3vHY69S3RbFtRdBvUF0YIuQ3eGF/C4VhfyoqyvQysv0+Eytua5PSFMcMWeSedYzcs4710iqqiD39eXjqCxBqJzpvM5GFD8CCf8PI6yTkLCFkL/EioWbQ3TdddJvQNLRZSTMshmt7fXpPI99+9LU+0Ur9JSF9+N4X8RuCaRo4jlsKYXZpGMuB3IBBbWMn0UR3P4qkyUBEl/c+HTEFjESA1r0lRGoriNaVY3e4WdFG1R7Ugj+jFt4PM/6CaRQSdpaQRw05aimLKubrNqHJfVo4aCYyb/+Pp3jlSJtrJzaEgCmub8EQFpTn0tge43hbFLtXmKvPcLUILRxOT9J9CqIgltIqKogdKQJlIKEujHl/wVl4P2rB/0H+ccIyjfOqVmImFmNHzmFh2fQBkz6Hy0Rwbp+WwiGRSHD48GGi0eg4jUpzqkQTdne4qurxn5v7YLp5tJajsJXiQGuCHzx/gs64Q8jv1uyPe1namtOX9Mi1oClYER8ddaVEayuJ1pUTb3cDK4LVhzDO2Eh03s9RMzaDaZMrc/FZS5iZcz4LCi/AsnKG3Gc6WzvdTL1VxtoZfloKh7q6OvLz8yktLe0Ro6+ZPOxv6qQzbqXqMzlp31VD3Br9QZ9B3HJAKeKdJ9m2r56vP9VMyGekyoiH/AaO4zqrB/q261yJqYnPFKoLgjR1xIkmHAxxK7LmhfxUJCqRQ9U8ucFH6/58UAZGKIp/3suoBX8mvvBeyD+IYFDsP5NicznzCy7kdzf8PTn+nH6vO9QGW2Nt0joto5Wi0Shz5szRgmESE7Mc/KY7+ffOmg54QsEtXeBu9ecWMruoGYPu/hIhn2CK4IjqMennBEwSlp2KajK8kwd8BtFMzbQ140omoe03QDE486F4x4gIs0vDPZLfbn5XJXc/s49Ll8R4/WCM6P4yOvaW0b53CdbuFcBX8Fcdp/CcF0nMu599Vb9iX/R/Kf7mTVw04yLWzF3D6rmrWTF9BQEz0OO62SoMvHG8g3OnF/Q4dqI5w6escAC0YJjkBH1utnTAZxBLuIX5BHrkSChUn4nD9pzRQVMwDSOVcBf3Xm+I67QUn4lPKUJ+k2WzitzyHQmHmBUfkvYgQNBvYNkKnyEkbEf7OoaA3yv73u8tEygK+SjK8eM3zVTPhoRt09qV4GTE6vf1Ccf9Pswvz+0zUSdNPqW5fnLyHfxnH6PonOM4juLE4VzidRVE6ipo3vQ3qA1vwRf+H0rPrmPZFX/lSPAn3HbgNm7dfCu5/lxWzl7J6jmrWTNvDUsrl2ZtsAVu+Hem3ioThSktHDSTm9K8APWtUURcZ3TSqhRIMyW5dIuH5OTvE7AdsBwH5TV7AVdohPwmCUcR8pkU5fh6VIoFOO9rj9MeTeAoBlUMMOQ38JkGtm0jXpMjv7jZ31oHGZiEo8gJGOSHfBxv6y6JkhTilQVBWrosyvJDWbsUmkYcvyk0tMf65OB4awMOtES4YE7PpkPJ1fqskjB1TZ1YtkNX3Ha/Q6ZQML0Dq7qdxX9zlCIzh4M7C6h/pYjY/vk88u9nAO9haY3Fggv3ohY8xO7me/js3s8CUBwqpsBYyvG2GmbmrCDfNxsRoStus7Ail664w6n0VhlttHAYB/Ly8ujo6L+VpgbyQ34oguaOeMrp7Pey55L+ByOpHaZN/gUhPwnbIW51h7emU96rpk7vH6RSyl3JqoF9EAL4TcO1H4d8FIV9tEdtgn6DWMLVeioLguw+2oblqHHL2p7ovhTbgXOmFZLj76CpI54S3lWFQfymwRlVBX1s8en5N925N3AsrYlU0nYQ9BlEE07W1fqKOSU8tacJU9xEuJjlELMUc0tDvOeCWalopaWXCd/7fBmXLDDZsQMefhgeesjHgz8+C9s+i+Liz/DWKyJU12znZOV9bG58gANdm3mlC0JGKaW+5RQYy/jquvdQlTtz3KOV+mPKOqRfffVVzj777HEaUf9o4TA82qMJmjvidMQslHJ7Aidlg+245qXGQ7V86/l29jV0pPwJyQnCbwrFuX4sm6z1/J/e08j1975Iwh7AzEH3uYM+A4DqolDWhvXJGlWtXXEOn4ie0kQ9lNIgIZ9rVkv2y5hov3ZDXM1rWpFbPuWHm/fy/Y17sR1F2G+kzEiDieJJRgVter0xJdhNQwj43PwYv8+gqiCUMULo7mfqqG3soLXLImrZhHwmQb/0+11Jp7UVHn/cFRYPPwzHjrnbly1TzFlWz56CP3C8+H7aZRtR5wQA84rnpfwVV8y5gsq8yhG8s4PjtIxW6iEcPv1p2L59ZC9aUwN33jngYd/5zne4++67Abjhhhv49Kc/nRIO9fX1vOc976GtrQ3Lsviv//ovVq5cObLjnIK8fqwdEVzTEq624Hg265YjdfxwR5Sdh0/S6U2IPm+CcFf5Qll+KGsdp7f/x1Psrm/HSnMaZPqFJFfiQZ9BXtBH0G9wVlV+n2KBr9W7ZcgdpYhZDpUFQYI+gz3HO07JLzFYAREw3SZLSe0rMoHqioj3j98UfIbBwopcmjriBHwGLZ1uVJFpCJ9cvYCPrlrQ5/XZ8gR+uHkv//74G5gi+EzBsl2t81/WntHDFJX+mt7Vh09GEtQ1dqKAmpmFPQQJ0O+KXynStAp47jmwbbcT6FVXKc695Ahq/sNsbf8Tm/dvpi3WBsDiisWsm7+Ob6/99pj5SydVtJKI3AZ8BGj0Nv2rUuqh8RvR8HnppZe45557eP7551FKceGFF3L55d2T0i9/+UvWrVvHF77wBWzbpquraxxHO3lId1QnbC+SSdycB6HbLJR0FAdMd2WvlDs59lfPf09DJ37TwG+6wiebz0Hhrkp/8qHz+6wmkyYOy3Fo8fI0kiWjj7fFKMrxkxMw6YgNv8THYASDIe5f3HK1rGhicN32AqZ7X2H0NQ2lIGEpKop81DZ2ptpunl3tRvJ0xtye0B/t9bps9bZufeuilCD5n6fqaIsmKAj5+cjKuantmVb/vXs11J9086PCfhMR6dHHpDNmZ7xu8rwi7tqxpgY+//neWoXwm9/MAD7CsmUf4WNXO8y74HUaiv/Ak4c2sOP4jgkTSDPhhIPHd5VSd4zY2Qaxwh8Nnn76aa699lpyc3MBeMc73sFTTz2V2n/BBRdw/fXXk0gkuOaaa6ipqRmXcU420h3VIb/pag0KinL9tBpCc2eCvKAPf45w0utRbRhCwlaYhrBiTknWiQUApfCZBr6ASUfM6nZm0zMJb/G0/IwTTTJ88dCJGKYhmIZgO4rOqNvHorUrAXSv/k/JxOQNJjlGvwEiBgGfu2I2DCEccHtfBP2u3X3AcxpgJDPOk1nGeA2XVFocwCmSfprWiIXlKExxJ+ZkT+Zs4Z3ZQkSTRfM+uiqztpGN6y+Z26NeWMRzSlcVdlcezgmY7DzSljXiKZvJqagI3v1u9y9dq3j4Yfj2twxs+2yKis7mqqtuYf16lSr9Mt4Y4z2A05nLLruMLVu2MH36dK677jp+9rOfjfeQJgX5IT/VRSH8phs+6jcNqotCVOSHKM0L8sRnLud7760hP+T3ftyKjqjlmnXyAzyy61hqYmmLWhw6EeFgSxef+vV2qgtD2Mr1YSj6hkObAgGfO+HevO6sjOM72BIhJ2ASS7g9BQBsx6Er4Ya4Op6wstMm3mxk2pcTMDENIegzOKMqjzMq8/AZyfBeYX5FLounF7KwMo+L5pVQfzLqjts0BtWZOWE5OMq9zplVeRTl+An6DHKD/lQ02HAwxZ300l+efNwZs933IDKotpvJe5zOqeQJJKsPl+cHU4uLygK3e1z6WJLXGe51k1rF5z8PW7ZAUxP89rdw7bXu8+98RyaEYICJKxw+ISIvi8jdItK3J+AkYeXKlTz44IN0dXXR2dnJ7373ux4+hQMHDlBZWclHPvIRbrjhBrZt2zaOo51c5If8zCnL5cyqfOaU5bqRTWkkf+yFYT9xW5EXNDmjMpe8kJ9dR9tI2A4nIwn2N3WRsBz8ptARs4jE3aYvYggJy8GzSGHQvdJPWIq3LqkGXEfzld95kuvvfYGn97iW0FklYY63RUnYDh1Ri864TcxSGN7EGAqYzCweOJ699xyRNJslbAdTYE5pmKKcAEU5ARZU5BL2u4M92hrhrwdb2dfYyYo5Jd6LBzfjhPwGhkDYC88tyglQEPIRs9z75XiNlTKdLdsVkpcO+U23cm7aPuXtd2shKWxHYZpuYltnzMoa3jmrJJyarMHtTrj7aBtHWyM9PouhcOnCcu6+bkVqceE3TTq94IfkWNwQ1J7muVPJTygqgne9C+6+G44edc1PE4VxEQ4i8oSIvJLh7+3AfwHzgRqgHvj3LOe4UUS2isjWxsahfxHGguXLl3PdddexYsUKLrzwQm644QaWLVuW2r9582aWLl3KsmXLuO+++/jUpz41jqOdely6sJyS3ABnVeVzzvRCinOD5AZ9hHwGh1uj1J+MurH0Xg5F2G9SmhdgRnGIFXOKmVGSQ37QT0W+n4KwH7/PoDDsZ3ZpmNeOtfGVP+6msT3WwzT19J5GVswp4UhrFMP7dSW1EFtBJGGTH3RXnskVeG8rTdJxnsrZMCS16l46s5B7rruASxeWEfB1r2CLcgLkh0wcpYgmHMJ+g4r8AA9sO0JVQRDbcSdeQ/rXVFDuOC1HEUu4AqGxPY7fJ6lkQvAqn0q3wEqWo0geIUBu0GRWSdjVWLzx+9LOkXyklPt+LcftzLagPJfmzgTl+cGsUUrXXzKXaMKhM2ZxojNGXVMXcVulfAfJz2K49NYkkmO5ed1ZqesOJMCGighUjn3AUlYmdLSSiMwB/qSUWtzfcZMtlFUzevT+3DP1wD7RGaO2qQtDxO0Apty8idmlORSG/T062mV6vVKqj+0ZumvjANQ1ddLQHqMz1nOVGfIZrp9BKUS6k+yUcp3ngjCnLMcVCIZQkhvIGBWTqWbPvsZOKguCVBaEeozJEGhsj9MeTRCzHBKejyZguILAVsnMczdvxGcIMdshN+jDFFItNWeX5iAi7GnocCueenOHzzSoKgjSFrXoiFqpe1mRH0z1Dm+LJIjbyuvfbGHZKtWRLeQzsBSDatOZTjKo4C+1LRiGMLM4nPJVjGadoolQTXWkmGzRStVKqXrv6bXAK+M5Hs3kpncUCkDAZ7KoOp/DJ6J0xCzCfjfZqignQGfM6mEiyPT6hvYYsYTNnuMdhAIm1YUhCsP+HrbnoM8t9meKV+Yj6XgWsLxIoKBpUJEf5OhJN+/BshULK3MpDPtTbVcf/HjmyS1Th77mjjgV+cEex+UETJo7E3zrXUtSx+YFTV45chJL9Y16cpTCELce1YLyXHYdbSM3YFJVGErZ3xeU53KwJUJh2M/JSILKgiAV+UEKw2645zuXT+9R4vqWq13fTFKYJWyHuiY3Mm9OaZiAz8xYkXSgSTiZBJdJgI9mnaLeza+mKhPR5/AtEdkpIi8DVwD/PN4D0kxe0s0P6WaAm9edxffeW8Oskhxmlrgrzkwmgt6vP94W5fCJCKZXQ+lkJMHrx9o52hpJ2Z5nlYQ53OqarFLRTZ4ZJrliBnclPqMkh4KQK1j8ppFa+Q7Gjp1uI7/7uhWcVZ2f1R6efuxNV51JwGcSMI0epq1k5JRhGiyeXsCDH7+UlQvLmFmS08Mx6zcNLppXwnOfX8OPPnAec8t6moE+umoB118yl1klYQ62RLj7mTqAlJnGcuDs6nzOqsrDVpLRfJTUjDKZ7XrT2/8w2Pun6Z8JpzkopT4w3mPQTB0yrbDTV6D97cv0+raIRXGOjxOdiZRjVgGHWiLYRSq1Sn5qTxN+LzrISRYC9BmAEAoIolRqwq0qDFLX1IXfZ6CUGnadnd7hmNnOc/czdVTkBzjaGu2jOZgiFIZ83HTVmYM6Z6ZVdH85CIM18wwUqjrQ+27pjGOIaxac7Kaf8WLCCQeNZqTpzwwwGBNB+jFXfudJmtqjBLyKrnHbDfxXQFleIHXcoup8ahs7U9pDMozUMIWgadAeTfDXg62E/AYluQFKcwNUFLjOz+FOZgMJwiQHWyJUFoRobIu5juo0ARH2Gz3ex6ULy3nn8ul9Esr6G9tQJvbeJE1JT+1pIidgMq0oPGDOQ+/3nRc0PT8SWRPVNAOjhYNGMwRmlYQ51NJFwCsH7jfdaCSfKXTGu+Pzb153Vmr1HLdsjrZGiVoOs4qCROI2+UUhWrsSdMZt2qNdFIb9lOQGuOmqU1vhDkbYJf0oNl6EkbhJen6fwZmVeTR3JlLHPr2nkQe2HWFaUYgFATeM84FtR1g8vTDrdbKVqR7IB5CuceQGXD/E/qYu5pS5gQL9mYrS3/f1977Qo5HOUITTZGK0HeMT0eeg0UxYrr9krudv8MJTvUqrJV5xNuj+0XbGLI62RmmL2lwwt4R7rruA2aU5lOYFqCoMU10Uxme45T2UUiMSgjnY9xBNOPi9RLzke6guDPWZgNO1gGQZiZDfSPkRMjFcH0D6taoKQ4iX+3C0NTKkkNGRTpCbiAzFJzNctHAYB+69916OHj063sPQDINLF5bzydULMAwhbjn4TKGqMIjPMLj+krk9frQzS8JMKwqRF/SlVnXpE1cyz8JvClHLDR1N2Daf+vX2Pol1I/0ebn3rIuaV55KwHcRwu6P5DOkzAQ9nos0WBDDQxJ5+raKcALNLcwj5DbridlandbYkxK64zclIgteOtbPj0El21beTFzQzXvdUyDaG0WY4QnuoaOEwDmjhMPlInwRe2N/CJ1cv4JIFpZTnh5hblpuauAb60aavqpPlNRwFIZ9Ja1ec420xOmJWj9XgDzfvHfEJ6NKF5fz+Eyu557oLWDGnGMsh4wQ8HC0gWwLZYMxd6dcqygkwsySHlQvLuPu6FYOOZrr+krm0dMbdQn4JtwFTwnJoaIuN6OQ9Fqv3bIyFdnRa+Bw+/cin2X5s+4ies6aqhjuvvnPA4772ta/xi1/8gvLycmbOnMl5553H1q1bef/73084HOa5554jHNYhdxOZTNE3D2w7knHCG8jefv0lc/ns/S+zv6mTmGUTs9xciJklYY6djLmZ2oHuSqDt0Qjf37iX+eW5o+JcTdrqk6awz97/MjHLrXh7dnU+K+aU8MC2Iwy1Y9lwcgEGG20F/Tu9775uBWV5AdoiCbdpkGlQVeI2DRpJv8OpON5PlUz5NyMdvntaCIfx4sUXX+SBBx5gx44dJBIJli9fznnnncf555/PHXfcwfnnZ0xM1EwwhjIJ9PejfXpPI3c89joN7bFU/oNSgCFeOXEbwbX9J2ntSoy6czVTifGuOOw6epK/1LYQ9BkYIn16Vgzl/INxnA422goGFsKdcYdF0wr6ZLaP5Mp6uI73kWAognS4nBbCYTAr/NHgmWee4e1vfzuhUIhQKMRb3/rWcRmHZnikh1X2zhLONglk+9Emy4TXt0UJmIKI4ChFWV6AExGLQyei5AV9FIR9qdBNgEjCIeTvaf0d6QkovcQ4uCU93MZAcfyG1zCoOJyafIYqGLLlPGQTEIM5/0Ar57FYWY/FNbIxFEE6XLTPQaPJQLo9OccLqzzQ3EVrV3JlnXkSyGZvf2F/CyG/gW0rTNNt3WmI0B61Oac6n2lFYb733hp8htHDkZusr5TOSE9ASft1V8wmbjup/twACcfttXCoJULCtofs8Bwtx+lATu/hOsVHcgyjTe8M+ZE2ZWnhMIpccskl/PGPfyQajdLR0cGf/vQnAPLz82lvbx/n0Wn6I31Sm1YURsQt0HfsZHTASSDTjzY5AQf9bj9jcMtpRC27R4mLW9+6CENg55E29jV2UlUQJG6N7gSUdAQnhUKmTmQJ2+F4W4y/HmwdknN8tBynAzm9h+sUH8kxTHZOC7PSeHHBBRfwtre9jSVLllBZWcm5555LYWEh1113HR/96Ee1Q3oCk25PLgz7mVOW48bbe2GVQ1XhkyaI6sIQ+5u6wCvj7c8QPtrUEccwBMtyaOiIEzTdCq2nkj3dH92mMHpUW00iuGXNE6kS3rFBO8dH0/QykAlqLArkTeUifFpzGGVuuukm3njjDR599FEOHDjAeeedxzvf+U5ef/11tm/frgXDBKV3WGVh2M+sLGGVgyFpgvB5OQXiFe6bV57bY3K947HXaeqIo7yMZeUoOryy36NlPkhvjOQze/ZtSAoG21GpNqtDMRGNt+lFM3y0cBhlbrzxRmpqali+fDnvfOc7Wb58+XgPSTMIRnpSSzdBWA6smFPMPdddwO8/sbLHZP/G8Q5MrwFRcmI2xd0+mly6sJzvvbeGOaW5nF2dT1HYR8AnqR4Pfp/rJ8kdooloqptepjLarDTK/PKXvxzvIWiGQXJS+/ajr7HzSBsAZ1TmDfr12cI3BzUp9rb5j1FT4fQImKaOOHFbMb0omGras6+xk6KcnqGbgy0troXB5ENrDhpNP3TFHeaX53Lu9AJsRw0qA/ZUMmcXVuSmWnomeyrbjmJhRe5IvaVBkRv0sbAiN9UZrzw/yCdXL8jYV1mbiKYmWjhoNFkYbhjmqYRv3rzuLEpzAxgCCa/nc2lugJvXnTVSbysrvYWao6AzZnOb14fho6sWaBPRaYQ2K2k0WRhuBuypZM5eurC8R0vPkYxOGihTOSnUErbD68ciRC0bvyF8+9HXeoSIZhrLVOqrrHHRwkGjycJwwzBPNXxzNGz0g8lUPtgSwRS3xIQhkirpvbu+naf3NGYd01CzoDWTA21WmkDce++9fOITnxjvYWg8hhuxNBHDNwdj6ppVEnZbhzqKqOXQGbeJJWxMQ/o1iY1F+WjN2KOFg0aTheGGYU7E8M3BZCpff8lcOuM2cdt1hidbbTqO4tX67Bn9p0NzndOR08Ks9OlPw/btI3vOmhq4887+j9m/fz9vectbeOWVVwC444476OjoYPPmzVx44YVs2rSJ1tZWfvKTn7By5coer/3zn//M7bffzh//+EduuukmCgoK2Lp1K8eOHeNb3/oW73rXu1BK8dnPfpaHH34YEeGLX/wi73nPe/j4xz/OunXreNvb3sa1115LcXExd999N3fffTf79u3jIx/5COvXr+fSSy/l2WefZfr06fz+97/XCXkZGK6JZ6KFbw7G1HXpwnJygz46Yxbg5lgEfG65j7jl9DnnUM6tmXxozWGcsCyLF154gTvvvJOvfOUrPfb97ne/4xvf+AYPPfQQZWVlANTX1/P000/zpz/9ic997nMA/N///R/bt29nx44dPPHEE9x8883U19ezcuVKnnrqKQCOHDnC7t1uaYSnnnqKyy67DIA9e/bw8Y9/nF27dlFUVMQDDzwwVm9dMw4M1tSVH/QRMA3CftPtK+FtD/qzTxUT0YymOXVOC81hoBX+ePCOd7wDgPPOO4/9+/entm/cuJGtW7fy2GOPUVBQkNp+zTXXYBgGixYt4vjx4wA8/fTTvO9978M0TSorK7n88st58cUXWblyJXfeeSe7d+9m0aJFnDhxgvr6ep577jm+//3v09zczNy5c6mpqck4Bs3UY7Alns+qzqeuqZMTXQliCYeg36Aix8/csux5FmNRPloz9pwWwmG88Pl8OE63Oh6NRlOPg8EgAKZpYllWavv8+fOpra3ljTfe6NEMKHk89C2M1pvp06fT2trKI488wmWXXUZLSwu/+c1vyMvLIz8/n+bm5h7nM02TSETbh6c6gzF1JYvwzSwOj3rnN83ERpuVRpHKykoaGhpobm4mFoulSnb3x+zZs3nggQf44Ac/yK5du/o9duXKldx3333Ytk1jYyNbtmxhxYoVAFx00UXceeedXHbZZaxcuZI77rijj19Do+nNRHSma8aHcREOIvJuEdklIo6InN9r3+dFZK+IvC4i68ZjfCOF3+/ny1/+MitWrGDt2rWcddbgslzPOuss/vd//5d3v/vd7Nu3L+tx1157LUuWLGHp0qWsXr2ab33rW1RVVQGu4LAsiwULFrB8+XJaWlq0cNAMiE5m0ySRgUwUo3JRkbMBB/hv4Cal1FZv+yLgV8AKYBrwBHCGUsrOdi6A888/X23durXHtldffZWzzz57FEavmcjoz334pCezpZuUtOYwdRGRl5RSGZvZj4vmoJR6VSn1eoZdbwd+rZSKKaXqgL24gkKj0YwyOplNk85E8zlMBw6lPT/sbdNoNKOMTmbTpDNq0Uoi8gRQlWHXF5RSvx+B898I3Agwa9asUz2dRnPao5PZNOmMmnBQSl05jJcdAWamPZ/hbct0/h8BPwLX5zCMa2k0mjS6e0lbQwpj1UxNJppZ6Q/Ae0UkKCJzgYXAC+M8Jo3mtECHsWrSGZckOBG5FvgBUA78WUS2K6XWKaV2ichvAHf5Ah8fKFJJo9GMHDqZTZNkvKKVfqeUmqGUCiqlKpVS69L2fV0pNV8pdaZS6uHxGN948eCDD6bqIAF8+ctf5oknnhiRc+/fv5/FixcPeMxo9Ly+88476erqGvHzajSa0WOimZXGjaf3NHL9vS9w5Xee5Pp7XxhUv9+Rprdw+OpXv8qVV/Z13dj26ChTWjhoNJokWjhwag3h++MXv/gFK1asoKamhn/4h39ITep5eXl84QtfYOnSpVx00UUcP36cZ599lj/84Q/cfPPN1NTUsG/fPq677jruv/9+AObMmcMtt9zC8uXL+e1vf8tjjz3GxRdfzPLly3n3u99NR0dHn+u/9NJLLF26lKVLl/Kf//mfqe379+9n5cqVLF++nOXLl/Pss88C8LnPfY6nnnqKmpoavvvd72Y9rr6+nssuu4yamhoWL16cqgCbaUzf//73OXr0KFdccQVXXHHFKd1PjUYzdmjhwOgk/7z66qvcd999PPPMM2zfvh3TNPnf//1fADo7O7nooovYsWMHl112Gf/zP//Dm970Jt72trfx7W9/m+3btzN//vw+5ywtLWXbtm1ceeWV3H777TzxxBNs27aN888/n+985zt9jv/whz/MD37wA3bs2NFje0VFBY8//jjbtm3jvvvu45Of/CQA3/jGN1i5ciXbt2/nn//5n7Me98tf/pJ169alyoXX1NTQ1NSUcUyf/OQnmTZtGps2bWLTpk3Dvp8ajWZs0VVZObWG8NnYsGEDL730EhdccAEAkUiEiooKAAKBAG95y1sAt1z2448/Pqhzvuc97wHgL3/5C7t37+aSSy4BIB6Pc/HFF/c4trW1ldbW1lT/hg984AM8/LDrwkkkEnziE59ICa033ngj4/WyHXfBBRdw/fXXk0gkuOaaa6ipqeHJJ58ccEwajWbyoIUDo5P8o5TiQx/6EP/2b//WZ5/f70fEbaPSu2R3f+Tm5qbOvXbtWn71q18Na2zf/e53qaysZMeOHTiOQygUGtJxl112GVu2bOHPf/4z1113HZ/5zGcoLi4+pTFpNJqJhTYrMTqdrNasWcP9999PQ0MDAC0tLRw4cKDf1+Tn59Penr1Xb5KLLrqIZ555hr179wKumar36r+oqIiioiKefvppgJRJC+DkyZNUV1djGAY///nPU76Q3tfPdtyBAweorKzkIx/5CDfccAPbtm3rd0yDfV8ajWbioIUDo5P8s2jRIm6//XauuuoqlixZwtq1a6mvr+/3Ne9973v59re/zbJly/ot1V1eXs69997L+973PpYsWcLFF1/Ma6+91ue4e+65h49//OPU1NT0aBD0sY99jJ/+9KcsXbqU1157LaWRLFmyBNM0Wbp0Kd/97nezHrd582aWLl3KsmXLuO+++/jUpz7V75huvPFGrr766knlkJ4I0WsazXgyLiW7RxpdsluTZCQ+d126WnO6MOFKdms0Exldulqj0cJBo+mDLl2t0WjhoNH0YVZJmK54zyx0Xbpac7qhhYNG04vRiF7TaCYbWjhoNL3Qpas1Gp0Ep9FkRJeu1pzuaM1hlGhtbeWuu+4a1zHce++9HD16dEivGUxpb6BHUcCRvP5AbN++nYceemhEz6nRaPqihUOSfZvhf/8W/mOF+/++zad0uv6Ew2DLZZwqozE5j/f1tXDQaMYGLRzAFQSP3AIdDZBb7v7/yC2nJCA+97nPsW/fPmpqarj55pvZvHkzK1eu5G1vexuLFi3qs0K/4447uO222wBYtWoVt9xyCytWrOCMM85IlcS2bZubbrqJxYsXs2TJEn7wgx8Abt+HCy64gMWLF3PjjTeilOL+++9n69atvP/976empoZIJMJLL73E5Zdfznnnnce6detSGdvZSnuno5TiE5/4BGeeeSZXXnllqizIUK6f6TiA73//+yxatIglS5bw3ve+F3DLb1x//fWsWLGCZcuW8fvf/554PM6Xv/xl7rvvPmpqarjvvvuG/floNJoBUEpN+r/zzjtP9Wb37t19tmXlF+9W6oeXK3XP33T//fByd/swqaurU+ecc07q+aZNm1ROTo6qra3NuP/b3/62uvXWW5VSSl1++eXqM5/5jFJKqT//+c9qzZo1Siml7rrrLvXOd75TJRIJpZRSzc3NPf5XSqm/+7u/U3/4wx9S53nxxReVUkrF43F18cUXq4aGBqWUUr/+9a/Vhz/8YaWUUueee6568sknlVJK3XTTTT3GleSBBx5QV155pbIsSx05ckQVFhaq3/72t4O+fn/HVVdXq2g0qpRS6sSJE0oppT7/+c+rn//856ltCxcuVB0dHeqee+5RH//4xzPdcqXUED93jeY0B9iqssyrWnMAOLEfArk9twVy3e0jyIoVK5g7d3DhkO94xzsAt6T3/v3uOJ544gn+4R/+AZ/PjSMoKSkBYNOmTVx44YWce+65bNy4kV27dvU53+uvv84rr7zC2rVrqamp4fbbb+fw4cMZS3tnYsuWLbzvfe/DNE2mTZvG6tWrU/sGc/3+jluyZAnvf//7+cUvfpF6b4899hjf+MY3qKmpYdWqVUSjUQ4ePDioe6fRaE4dHa0EUDzHNSUF87q3xTvd7SNIsnAdgM/nw3Gc1PNoNNrj2GAwCAxc0jsajfKxj32MrVu3MnPmTG677bY+5wJXQzznnHN47rnnemxvbW0dzlsZ8vX7O+7Pf/4zW7Zs4Y9//CNf//rX2blzJ0opHnjgAc4888we53n++edPabyaycvTexq5+5k6DrZEmFUS5vpL5uqIslFEaw4AF30MrAjEOkAp938r4m4fJgOVqa6srKShoYHm5mZisRh/+tOfBjzn2rVr+e///u+UsGhpaUlNsGVlZXR0dPSIIEofw5lnnkljY2NKOCQSCXbt2tVvae90LrvsMu677z5s26a+vj7V1W2w1892nOM4HDp0iCuuuIJvfvObnDx5ko6ODtatW8cPfvCDlF/ir3/966Duq2ZqMlqtfDXZ0cIBYP4quPqbkFcBnY3u/1d/090+TEpLS7nkkktYvHgxN998c5/9fr+fL3/5y6xYsYK1a9dy1llnDXjOG264gVmzZrFkyRKWLl3KL3/5S4qKivjIRz7C4sWLWbduXarzHLjhph/96EepqanBtm3uv/9+brnlFpYuXUpNTU2qJ3S20t7pXHvttSxcuJBFixbxwQ9+MNXlbbDXDwaDGY+zbZu/+7u/49xzz2XZsmV88pOfpKioiC996UskEgmWLFnCOeecw5e+9CUArrjiCnbv3q0d0qcZuhji2KNLdmumFPpzn5pc+Z0nKc3t7qAIrqm0uTPBE5+5fBxHNrnRJbs1Gs2kRhdDHHu0cNBoNBMeXQxx7BkX4SAi7xaRXSLiiMj5advniEhERLZ7fz88letMBZOZZvDoz3vqooshjj3jFcr6CvAO4L8z7NunlKo51QuEQiGam5spLS3tYafUTE2UUjQ3NxMKhcZ7KJpRQhdDHFvGRTgopV4FRnXSnjFjBocPH6axUYe6nS6EQiFmzJgx3sPQaKYEEzEJbq6I/BVoA76olHpqOCfx+/2DzkbWaDQaTU9GTTiIyBNAVYZdX1BK/T7Ly+qBWUqpZhE5D3hQRM5RSrVlOP+NwI0As2bNGqlhazQajYZRFA5KqSuH8ZoYEPMevyQi+4AzgK0Zjv0R8CNw8xxObbQajUajSWdChbKKSLmImN7jecBCoHZ8R6XRaDSnH+OSIS0i1wI/AMqBVmC7UmqdiLwT+CqQABzgVqXUHwdxvkbgwCkMqQxoOoXXT3X0/RkYfY8GRt+jgRnrezRbKZUxBGxKlM84VURka7YUco2+P4NB36OB0fdoYCbSPZpQZiWNRqPRTAy0cNBoNBpNH7RwcPnReA9ggqPvz8DoezQw+h4NzIS5R9rnoNFoNJo+aM1Bo9FoNH3QwkGj0Wg0fTgthUO2kuEZjrtaRF4Xkb0i8rmxHON4IiIlIvK4iOzx/i/OcpydVl79D2M9zvFgoO+EiARF5D5v//MiMmcchjmuDOIeXScijWnfnRvGY5zjhYjcLSINIvJKlv0iIt/37t/LIrJ8rMcIp6lwoLtk+JZsB3iZ2v8JrAcWAe8TkUVjM7xx53PABqXUQmCD9zwTEaVUjff3trEb3vgwyO/E3wMnlFILgO8C3xzbUY4vQ/jd3Jf23fnxmA5y/LkXuLqf/etxq0MsxK0f919jMKY+nJbCQSn1qlLq9QEOWwHsVUrVKqXiwK+Bt4/+6CYEbwd+6j3+KXDN+A1lQjGY70T6vbsfWCOnV0OR0/l3MyiUUluAln4OeTvwM+XyF6BIRKrHZnTdnJbCYZBMBw6lPT/sbTsdqFRK1XuPjwGVWY4LichWEfmLiFwzNkMbVwbznUgdo5SygJNA6ZiMbmIw2N/NOz2Tyf0iMnNshjZpmBBzz0Ts5zAiDLNk+GlDf/cn/YlSSolItnjn2UqpI16RxI0islMptW+kx6qZcvwR+JVSKiYi/4Craa0e5zFpejFlhcNwSob34giQvqKZ4W2bEvR3f0TkuIhUK6XqPXW2Ics5jnj/14rIZmAZMJWFw2C+E8ljDouIDygEmsdmeBOCAe+RUir9fvwY+NYYjGsyMSHmHm1Wys6LwEIRmSsiAeC9wGkRkYP7Pj/kPf4Q0EfTEpFiEQl6j8uAS4DdYzbC8WEw34n0e/cuYKM6vTJNB7xHveznbwNeHcPxTQb+AHzQi1q6CDiZZuYdO5RSp90fcC2uHS8GHAce9bZPAx5KO+7NwBu4q+EvjPe4x/D+lOJGKe0BngBKvO3nAz/2Hr8J2Ans8P7/+/Ee9xjdmz7fCdwy82/zHoeA3wJ7gReAeeM95gl4j/4N2OV9dzYBZ433mMf4/vwKt+tlwpuH/h74KPBRb7/gRnzt835b54/HOHX5DI1Go9H0QZuVNBqNRtMHLRw0Go1G0wctHDQajUbTBy0cNBqNRtMHLRw0Go1G0wctHDQajUbTBy0cNBqNRtMHLRw0mlFARC7wCsuFRCTX6x+yeLzHpdEMFp0Ep9GMEiJyO27GdBg4rJT6t3EekkYzaLRw0GhGCa+20ItAFHiTUsoe5yFpNINGm5U0mtGjFMgD8nE1CI1m0qA1B41mlPD6av8amAtUK6U+Mc5D0mgGzZTt56DRjCci8kEgoZT6pddX+VkRWa2U2jjeY9NoBoPWHDQajUbTB+1z0Gg0Gk0ftHDQaDQaTR+0cNBoNBpNH7Rw0Gg0Gk0ftHDQaDQaTR+0cNBoNBpNH7Rw0Gg0Gk0f/n/+dSLGbzOvBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(new_X, emp_stand_noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc_norm, emp_stand_y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(norm_data, trunc_emp_stand_ols.predict(norm_data), color='r', label='ols')\n",
    "plt.plot(norm_data, gt_emp_stand.predict(norm_data), color='green', label='gt')\n",
    "plt.plot(norm_data, unknown_res(Tensor(norm_data)).detach().numpy(), label='unknown', color='blue')\n",
    "plt.legend()\n",
    "ax.set_title(\"Unknown Noise Variance - Normalized\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.scatter(X, noised, label='entire dataset', alpha=.75)\n",
    "plt.scatter(x_trunc, y_trunc, label='truncated dataset', alpha=.75)\n",
    "plt.plot(unnorm_data, trunc_ols.predict(unnorm_data), label='ols', color='red')\n",
    "plt.plot(unnorm_data, gt_ols.predict(unnorm_data), color='g', label='gt')\n",
    "plt.plot(unnorm_data, (Tensor(unnorm_data)@unknown_weight_unnorm + unknown_bias_unnorm), color='blue', label='unknown')\n",
    "plt.legend()\n",
    "ax.set_title(\"Unknown Noise Variance - UnNormalized\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncate at Zero and Run for High Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.__setattr__('bs', 10)\n",
    "args.__setattr__('steps', 2500)\n",
    "args.__setattr__('step_lr', 100)\n",
    "args.__setattr__('step_lr_gamma', .9)\n",
    "args.__setattr__('tol', 1e-2)\n",
    "args.__setattr__('trials', 20)\n",
    "args.__setattr__('samples', 5000)\n",
    "\n",
    "EXP = '5KLaplace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/b4bd8f1d-1c16-415e-973d-92ac979dc298\n",
      "gt params:  tensor([-0.4374, -0.5629])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.10800917446613312]\n",
      "100 steps | score: [0.0023618489503860474]\n",
      "0 steps | score: [0.07307607680559158, 0.04460294172167778]\n",
      "100 steps | score: [0.060631945729255676, 0.00428187008947134]\n",
      "200 steps | score: [-0.006638931576162577, -0.030606089159846306]\n",
      "300 steps | score: [0.07368598133325577, -0.0009927547071129084]\n",
      "400 steps | score: [0.03048012964427471, -0.032228849828243256]\n",
      "500 steps | score: [0.0568191222846508, 0.0187586210668087]\n",
      "600 steps | score: [0.01627260632812977, -0.030605362728238106]\n",
      "700 steps | score: [0.03499017655849457, -0.005631301552057266]\n",
      "800 steps | score: [0.03305799141526222, 0.01631498895585537]\n",
      "900 steps | score: [0.03034086711704731, 0.013808025047183037]\n",
      "1000 steps | score: [0.048484548926353455, -0.006898004561662674]\n",
      "1100 steps | score: [0.019857684150338173, -0.028092967346310616]\n",
      "1200 steps | score: [0.03340207785367966, -0.008181963115930557]\n",
      "1300 steps | score: [0.030433660373091698, 0.006521568633615971]\n",
      "1400 steps | score: [0.04499966651201248, 0.00018233922310173512]\n",
      "1500 steps | score: [0.031558841466903687, -0.02614118531346321]\n",
      "1600 steps | score: [0.032683804631233215, -0.0031394194811582565]\n",
      "1700 steps | score: [0.038168229162693024, 0.013013982214033604]\n",
      "1800 steps | score: [0.0331532247364521, 0.00951712392270565]\n",
      "1900 steps | score: [0.04053108021616936, -0.0072912839241325855]\n",
      "2000 steps | score: [0.02554001286625862, -0.006127361208200455]\n",
      "2100 steps | score: [0.037075113505125046, -0.01994064822793007]\n",
      "2200 steps | score: [0.02896464616060257, 0.005880831740796566]\n",
      "2300 steps | score: [0.038825128227472305, -0.0002861411776393652]\n",
      "2400 steps | score: [0.03302585333585739, -0.017614880576729774]\n",
      "2500 steps | score: [0.03972811624407768, -0.016867920756340027]\n",
      "2600 steps | score: [0.0377492755651474, -0.005722420755773783]\n",
      "0 steps | score: [-0.010930084623396397, 0.10314063727855682]\n",
      "100 steps | score: [-0.016514327377080917, 0.05346916988492012]\n",
      "200 steps | score: [-0.06617572158575058, 0.02421722747385502]\n",
      "300 steps | score: [0.004356393124908209, 0.05434378981590271]\n",
      "400 steps | score: [-0.03128926455974579, 0.028239605948328972]\n",
      "500 steps | score: [0.0001202159037347883, 0.07046259194612503]\n",
      "600 steps | score: [-0.049867406487464905, 0.021856311708688736]\n",
      "700 steps | score: [-0.02995702065527439, 0.04903625324368477]\n",
      "800 steps | score: [-0.03019724413752556, 0.07356270402669907]\n",
      "900 steps | score: [-0.04371722415089607, 0.06941480934619904]\n",
      "1000 steps | score: [-0.018083153292536736, 0.039776142686605453]\n",
      "1100 steps | score: [-0.044746026396751404, 0.029593389481306076]\n",
      "1200 steps | score: [-0.03391897305846214, 0.05185158550739288]\n",
      "1300 steps | score: [-0.031033415347337723, 0.058782726526260376]\n",
      "1400 steps | score: [-0.03003685176372528, 0.05403033271431923]\n",
      "1500 steps | score: [-0.02775869332253933, 0.031087417155504227]\n",
      "1600 steps | score: [-0.036313336342573166, 0.04856756329536438]\n",
      "1700 steps | score: [-0.03006913512945175, 0.06254996359348297]\n",
      "1800 steps | score: [-0.030493833124637604, 0.0596865639090538]\n",
      "1900 steps | score: [-0.018185380846261978, 0.046033430844545364]\n",
      "2000 steps | score: [-0.03566513583064079, 0.042592450976371765]\n",
      "2100 steps | score: [-0.02589728683233261, 0.03966117277741432]\n",
      "2200 steps | score: [-0.036707744002342224, 0.05571749061346054]\n",
      "2300 steps | score: [-0.025907209143042564, 0.05205059051513672]\n",
      "2400 steps | score: [-0.03605647757649422, 0.03716516122221947]\n",
      "2500 steps | score: [-0.02409343048930168, 0.035980697721242905]\n",
      "2600 steps | score: [-0.028150543570518494, 0.050101421773433685]\n",
      "0 steps | score: [0.017794305458664894, 0.11034774035215378]\n",
      "100 steps | score: [0.013742937706410885, 0.052287351340055466]\n",
      "200 steps | score: [-0.048001911491155624, 0.02285866253077984]\n",
      "300 steps | score: [0.03467819094657898, 0.05569058656692505]\n",
      "400 steps | score: [-0.012885541655123234, 0.019038908183574677]\n",
      "500 steps | score: [0.028014089912176132, 0.06536203622817993]\n",
      "600 steps | score: [-0.030580194666981697, 0.025406895205378532]\n",
      "700 steps | score: [-0.004720640368759632, 0.054438021034002304]\n",
      "800 steps | score: [-0.012528466060757637, 0.07112051546573639]\n",
      "900 steps | score: [-0.010820670053362846, 0.07164650410413742]\n",
      "1000 steps | score: [0.005850805435329676, 0.048522766679525375]\n",
      "1100 steps | score: [-0.022022675722837448, 0.024839863181114197]\n",
      "1200 steps | score: [-0.0057345726527273655, 0.04136053845286369]\n",
      "1300 steps | score: [-0.015622579492628574, 0.06516208499670029]\n",
      "1400 steps | score: [-0.005842177662998438, 0.0507797934114933]\n",
      "1500 steps | score: [-0.0037007429637014866, 0.02905244752764702]\n",
      "1600 steps | score: [-0.0037462259642779827, 0.05236050486564636]\n",
      "1700 steps | score: [0.0035268620122224092, 0.06944367289543152]\n",
      "1800 steps | score: [-0.008005180396139622, 0.06287265568971634]\n",
      "1900 steps | score: [0.006617568898946047, 0.04689484462141991]\n",
      "2000 steps | score: [-0.014494269154965878, 0.04386313632130623]\n",
      "2100 steps | score: [-0.0005666743963956833, 0.036714740097522736]\n",
      "2200 steps | score: [-0.021861042827367783, 0.05796206369996071]\n",
      "2300 steps | score: [0.0032212412916123867, 0.05532976612448692]\n",
      "2400 steps | score: [-0.006908638868480921, 0.041561152786016464]\n",
      "2500 steps | score: [0.0010252315551042557, 0.04490363597869873]\n",
      "2600 steps | score: [-0.0062409210950136185, 0.05367616191506386]\n",
      "unknown params:  tensor([-0.4024, -0.4523])\n",
      "unknown variance:  tensor([[0.8436]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4374, -0.5629])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [-0.09046975523233414]\n",
      "100 steps | score: [-0.18538890779018402]\n",
      "200 steps | score: [-0.19979019463062286]\n",
      "300 steps | score: [-0.18852433562278748]\n",
      "400 steps | score: [-0.26864001154899597]\n",
      "500 steps | score: [-0.22108298540115356]\n",
      "600 steps | score: [-0.21871602535247803]\n",
      "700 steps | score: [-0.20291507244110107]\n",
      "800 steps | score: [-0.2832619845867157]\n",
      "900 steps | score: [-0.19748574495315552]\n",
      "1000 steps | score: [-0.2468060851097107]\n",
      "1100 steps | score: [-0.19966883957386017]\n",
      "1200 steps | score: [-0.30960363149642944]\n",
      "1300 steps | score: [-0.22502107918262482]\n",
      "1400 steps | score: [-0.2472791224718094]\n",
      "1500 steps | score: [-0.20016510784626007]\n",
      "1600 steps | score: [-0.25254273414611816]\n",
      "1700 steps | score: [-0.21713560819625854]\n",
      "1800 steps | score: [-0.22805464267730713]\n",
      "1900 steps | score: [-0.21928982436656952]\n",
      "2000 steps | score: [-0.2831498086452484]\n",
      "2100 steps | score: [-0.19124877452850342]\n",
      "2200 steps | score: [-0.2314513474702835]\n",
      "2300 steps | score: [-0.21208585798740387]\n",
      "2400 steps | score: [-0.24766981601715088]\n",
      "2500 steps | score: [-0.21350160241127014]\n",
      "2600 steps | score: [-0.22121554613113403]\n",
      "2700 steps | score: [-0.21091479063034058]\n",
      "0 steps | score: [0.05904829502105713, 0.047706298530101776]\n",
      "100 steps | score: [0.015734709799289703, -0.04817536100745201]\n",
      "200 steps | score: [-0.01567044109106064, -0.04115348309278488]\n",
      "300 steps | score: [0.028009861707687378, -0.05853576958179474]\n",
      "400 steps | score: [-0.03876480087637901, 0.0037645059637725353]\n",
      "500 steps | score: [0.0012537580914795399, -0.04005012288689613]\n",
      "600 steps | score: [-0.025015784427523613, -0.02863488532602787]\n",
      "700 steps | score: [0.032914258539676666, -0.06033430993556976]\n",
      "800 steps | score: [-0.04917224496603012, 0.004697322845458984]\n",
      "900 steps | score: [0.015586971305310726, -0.037609606981277466]\n",
      "1000 steps | score: [-0.027392230927944183, -0.029980400577187538]\n",
      "1100 steps | score: [0.015047460794448853, -0.05004187673330307]\n",
      "1200 steps | score: [-0.0445585697889328, 0.0068133799359202385]\n",
      "1300 steps | score: [0.010256772860884666, -0.028701432049274445]\n",
      "1400 steps | score: [-0.024052834138274193, -0.028961673378944397]\n",
      "1500 steps | score: [0.014287907630205154, -0.043651603162288666]\n",
      "1600 steps | score: [-0.03391408547759056, 0.0001281009754166007]\n",
      "1700 steps | score: [0.00971899926662445, -0.02699805609881878]\n",
      "1800 steps | score: [-0.017798809334635735, -0.03463934361934662]\n",
      "1900 steps | score: [0.011714467778801918, -0.041194669902324677]\n",
      "2000 steps | score: [-0.028423061594367027, -0.005902307573705912]\n",
      "2100 steps | score: [0.011184196919202805, -0.033559370785951614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200 steps | score: [-0.008176207542419434, -0.040064238011837006]\n",
      "2300 steps | score: [0.003506687004119158, -0.04162737354636192]\n",
      "2400 steps | score: [-0.020158570259809494, -0.02036542259156704]\n",
      "2500 steps | score: [-0.0020073573105037212, -0.025771282613277435]\n",
      "2600 steps | score: [-0.0073486631736159325, -0.029358666390180588]\n",
      "2700 steps | score: [0.008042032830417156, -0.03985422104597092]\n",
      "0 steps | score: [0.04814913496375084, 0.13163480162620544]\n",
      "100 steps | score: [0.026316042989492416, 0.01410946249961853]\n",
      "200 steps | score: [-0.01981344074010849, 0.03518388792872429]\n",
      "300 steps | score: [0.02400747872889042, 0.008052496239542961]\n",
      "400 steps | score: [-0.04720812663435936, 0.0773547813296318]\n",
      "500 steps | score: [0.018751876428723335, 0.02832627296447754]\n",
      "600 steps | score: [-0.013638179749250412, 0.03305227681994438]\n",
      "700 steps | score: [0.029962101951241493, 0.0184052512049675]\n",
      "800 steps | score: [-0.05135536193847656, 0.07503838837146759]\n",
      "900 steps | score: [0.018475230783224106, 0.03371678292751312]\n",
      "1000 steps | score: [-0.027238579466938972, 0.04108089581131935]\n",
      "1100 steps | score: [0.017544476315379143, 0.021150341257452965]\n",
      "1200 steps | score: [-0.04347800835967064, 0.07281945645809174]\n",
      "1300 steps | score: [0.009069393388926983, 0.03633728250861168]\n",
      "1400 steps | score: [-0.011270144954323769, 0.037638451904058456]\n",
      "1500 steps | score: [0.014845229685306549, 0.021293792873620987]\n",
      "1600 steps | score: [-0.025529470294713974, 0.07111331820487976]\n",
      "1700 steps | score: [0.005210546776652336, 0.038967810571193695]\n",
      "1800 steps | score: [-0.01461897324770689, 0.03508441522717476]\n",
      "1900 steps | score: [0.009636708535254002, 0.027871133759617805]\n",
      "2000 steps | score: [-0.023982174694538116, 0.06748849898576736]\n",
      "2100 steps | score: [0.011660867370665073, 0.03740036487579346]\n",
      "2200 steps | score: [-0.006097127217799425, 0.03760329261422157]\n",
      "2300 steps | score: [0.008847621269524097, 0.022532524541020393]\n",
      "2400 steps | score: [-0.02038133703172207, 0.05556713044643402]\n",
      "2500 steps | score: [0.009314456023275852, 0.041280850768089294]\n",
      "2600 steps | score: [-0.005528973415493965, 0.03716779127717018]\n",
      "2700 steps | score: [0.00845162384212017, 0.03395140916109085]\n",
      "0 steps | score: [0.033365752547979355, 0.08810961246490479]\n",
      "100 steps | score: [-0.0027762078680098057, -0.009037377312779427]\n",
      "unknown params:  tensor([-0.4071, -0.4643])\n",
      "unknown variance:  tensor([[0.9051]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4374, -0.5629])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.11875732243061066]\n",
      "100 steps | score: [0.02986505627632141]\n",
      "200 steps | score: [-0.013053263537585735]\n",
      "300 steps | score: [-0.11162024736404419]\n",
      "400 steps | score: [0.016306204721331596]\n",
      "500 steps | score: [0.02997860498726368]\n",
      "600 steps | score: [0.006487775593996048]\n",
      "0 steps | score: [0.04836380109190941, 0.15075500309467316]\n",
      "100 steps | score: [0.00900565180927515, 0.04136011004447937]\n",
      "200 steps | score: [-0.041622407734394073, 0.06320605427026749]\n",
      "300 steps | score: [-0.09222327917814255, 0.12517137825489044]\n",
      "400 steps | score: [-0.004488196689635515, 0.03953789174556732]\n",
      "500 steps | score: [0.00915785226970911, 0.00567791610956192]\n",
      "0 steps | score: [0.07128521054983139, 0.09388089179992676]\n",
      "100 steps | score: [0.012555315159261227, -0.00390407582744956]\n",
      "200 steps | score: [-0.02603834681212902, 0.01917901448905468]\n",
      "300 steps | score: [-0.08782590180635452, 0.08459791541099548]\n",
      "400 steps | score: [0.011007762514054775, 0.006163723301142454]\n",
      "500 steps | score: [0.029574645683169365, -0.041471753269433975]\n",
      "600 steps | score: [0.017517680302262306, -0.01630791276693344]\n",
      "700 steps | score: [-0.03341471031308174, 0.05726691335439682]\n",
      "800 steps | score: [0.018896711990237236, 0.0029118633829057217]\n",
      "900 steps | score: [0.0073760999366641045, -0.02652178704738617]\n",
      "1000 steps | score: [0.059380631893873215, -0.0556468665599823]\n",
      "1100 steps | score: [-0.003937744069844484, 0.004859652370214462]\n",
      "0 steps | score: [0.10446009039878845, 0.06267967820167542]\n",
      "100 steps | score: [0.047638557851314545, -0.028883274644613266]\n",
      "200 steps | score: [0.006671541836112738, -0.013238269835710526]\n",
      "300 steps | score: [-0.052176475524902344, 0.05476473271846771]\n",
      "400 steps | score: [0.04582546651363373, -0.037505101412534714]\n",
      "500 steps | score: [0.05939251929521561, -0.0742567777633667]\n",
      "600 steps | score: [0.04244627431035042, -0.03906185179948807]\n",
      "700 steps | score: [-0.012840952724218369, 0.032284848392009735]\n",
      "800 steps | score: [0.03688148036599159, -0.02905891090631485]\n",
      "900 steps | score: [0.043363627046346664, -0.05462825298309326]\n",
      "1000 steps | score: [0.07797535508871078, -0.08146922290325165]\n",
      "1100 steps | score: [0.023152699694037437, -0.02745279297232628]\n",
      "1200 steps | score: [0.031033651903271675, -0.02527765929698944]\n",
      "1300 steps | score: [0.034169744700193405, -0.04732804745435715]\n",
      "1400 steps | score: [0.022443899884819984, -0.027867091819643974]\n",
      "1500 steps | score: [-0.01778338849544525, 0.005744628608226776]\n",
      "1600 steps | score: [0.0310357753187418, -0.03133575990796089]\n",
      "1700 steps | score: [0.005446900613605976, -0.01353769563138485]\n",
      "1800 steps | score: [0.01603451929986477, -0.019691891968250275]\n",
      "1900 steps | score: [0.005741134751588106, -0.005633815657347441]\n",
      "unknown params:  tensor([-0.4148, -0.5009])\n",
      "unknown variance:  tensor([[0.9339]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4374, -0.5629])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.14823183417320251]\n",
      "100 steps | score: [0.036246590316295624]\n",
      "200 steps | score: [0.01006089523434639]\n",
      "300 steps | score: [-0.019605619832873344]\n",
      "400 steps | score: [0.04250671714544296]\n",
      "500 steps | score: [-0.012541033327579498]\n",
      "600 steps | score: [-0.018343782052397728]\n",
      "700 steps | score: [-0.06437379121780396]\n",
      "800 steps | score: [-0.015436375513672829]\n",
      "900 steps | score: [-0.01003800705075264]\n",
      "1000 steps | score: [-0.012499451637268066]\n",
      "1100 steps | score: [-0.017484089359641075]\n",
      "1200 steps | score: [-0.015642020851373672]\n",
      "1300 steps | score: [0.020755168050527573]\n",
      "1400 steps | score: [-0.0636218786239624]\n",
      "1500 steps | score: [-0.0028812121599912643]\n",
      "0 steps | score: [0.058492787182331085, 0.06588295847177505]\n",
      "100 steps | score: [0.005639912094920874, -0.04537889361381531]\n",
      "200 steps | score: [-0.03950580209493637, -0.030475996434688568]\n",
      "300 steps | score: [-0.06320451945066452, 0.05183524638414383]\n",
      "400 steps | score: [-0.008112147450447083, -0.011397548951208591]\n",
      "500 steps | score: [-0.031577326357364655, -0.034521184861660004]\n",
      "600 steps | score: [-0.056993816047906876, -0.010168453678488731]\n",
      "700 steps | score: [-0.10082679986953735, 0.04190486669540405]\n",
      "800 steps | score: [-0.0032892508897930384, -0.0306209996342659]\n",
      "900 steps | score: [-0.03847099095582962, -0.03375432640314102]\n",
      "1000 steps | score: [-0.06018288433551788, 0.02116800658404827]\n",
      "1100 steps | score: [-0.03150567039847374, -0.0021192077547311783]\n",
      "1200 steps | score: [-0.02786942571401596, -0.03796589747071266]\n",
      "1300 steps | score: [-0.02659791149199009, -0.04016586020588875]\n",
      "1400 steps | score: [-0.08875621110200882, 0.02162148803472519]\n",
      "1500 steps | score: [-0.022970901802182198, -0.018118154257535934]\n",
      "1600 steps | score: [-0.0389663428068161, -0.03451419249176979]\n",
      "1700 steps | score: [-0.05090510472655296, -0.009313804097473621]\n",
      "1800 steps | score: [-0.04471345245838165, -0.011297771707177162]\n",
      "1900 steps | score: [-0.028892729431390762, -0.037048500031232834]\n",
      "2000 steps | score: [-0.0237786415964365, -0.03776821121573448]\n",
      "2100 steps | score: [-0.06723017990589142, 0.004109907895326614]\n",
      "2200 steps | score: [-0.0361885167658329, -0.02469605952501297]\n",
      "2300 steps | score: [-0.03827707841992378, -0.027524761855602264]\n",
      "2400 steps | score: [-0.045218538492918015, -0.014330272562801838]\n",
      "2500 steps | score: [-0.03567852824926376, -0.016428502276539803]\n",
      "2600 steps | score: [-0.030745672062039375, -0.02777412161231041]\n",
      "2700 steps | score: [-0.021258410066366196, -0.03262288495898247]\n",
      "2800 steps | score: [-0.04845171421766281, -0.010818755254149437]\n",
      "0 steps | score: [0.10175277292728424, 0.0844116061925888]\n",
      "100 steps | score: [0.043179288506507874, -0.03307978808879852]\n",
      "200 steps | score: [0.010128751397132874, -0.033419910818338394]\n",
      "300 steps | score: [-0.01364155113697052, 0.06271111220121384]\n",
      "400 steps | score: [0.03901755437254906, 0.004140810109674931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [0.005748148541897535, -0.016056548804044724]\n",
      "600 steps | score: [-0.026025034487247467, 0.014619814231991768]\n",
      "700 steps | score: [-0.05693848058581352, 0.06053105741739273]\n",
      "800 steps | score: [0.023687738925218582, -0.011191222816705704]\n",
      "900 steps | score: [0.006347586866468191, -0.022245561704039574]\n",
      "1000 steps | score: [-0.022488728165626526, 0.04260466992855072]\n",
      "1100 steps | score: [0.012871514074504375, 0.015349134802818298]\n",
      "1200 steps | score: [0.021259775385260582, -0.02692963182926178]\n",
      "1300 steps | score: [0.016095317900180817, -0.03234773129224777]\n",
      "1400 steps | score: [-0.040882814675569534, 0.030013691633939743]\n",
      "1500 steps | score: [0.018671609461307526, -0.005035941489040852]\n",
      "1600 steps | score: [0.015580099076032639, -0.03363679349422455]\n",
      "1700 steps | score: [-0.0021813372150063515, 0.007844413630664349]\n",
      "0 steps | score: [0.1009615957736969, 0.12646767497062683]\n",
      "100 steps | score: [0.05960189923644066, -0.0018642744980752468]\n",
      "200 steps | score: [0.011043182574212551, 0.01163207646459341]\n",
      "300 steps | score: [-0.0036280439235270023, 0.10031495243310928]\n",
      "400 steps | score: [0.026992948725819588, 0.05493158474564552]\n",
      "500 steps | score: [0.018379896879196167, 0.01752582937479019]\n",
      "600 steps | score: [-0.011046981438994408, 0.04264290630817413]\n",
      "700 steps | score: [-0.053125858306884766, 0.10292066633701324]\n",
      "800 steps | score: [0.02809740975499153, 0.03493659943342209]\n",
      "900 steps | score: [0.015573601238429546, 0.013830001465976238]\n",
      "1000 steps | score: [-0.02225116826593876, 0.08332642167806625]\n",
      "1100 steps | score: [0.01800275593996048, 0.04964502900838852]\n",
      "1200 steps | score: [0.017838137224316597, 0.017623823136091232]\n",
      "1300 steps | score: [0.016392026096582413, 0.009174908511340618]\n",
      "1400 steps | score: [-0.03444617614150047, 0.07389587163925171]\n",
      "1500 steps | score: [0.012479607947170734, 0.038254786282777786]\n",
      "1600 steps | score: [0.013452112674713135, 0.01122868899255991]\n",
      "1700 steps | score: [-0.0026218814309686422, 0.049564361572265625]\n",
      "1800 steps | score: [0.0071820588782429695, 0.04423818737268448]\n",
      "1900 steps | score: [0.019985664635896683, 0.018775448203086853]\n",
      "2000 steps | score: [0.024506932124495506, 0.0179294366389513]\n",
      "2100 steps | score: [-0.016567032784223557, 0.048508334904909134]\n",
      "2200 steps | score: [0.01318102702498436, 0.034074876457452774]\n",
      "2300 steps | score: [0.005582621321082115, 0.030817436054348946]\n",
      "2400 steps | score: [0.00700584938749671, 0.03380453586578369]\n",
      "2500 steps | score: [0.010862992145121098, 0.034336499869823456]\n",
      "2600 steps | score: [0.019665328785777092, 0.024381201714277267]\n",
      "2700 steps | score: [0.017001451924443245, 0.01575421169400215]\n",
      "2800 steps | score: [-0.004066361580044031, 0.045554421842098236]\n",
      "unknown params:  tensor([-0.4329, -0.5506])\n",
      "unknown variance:  tensor([[0.9719]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4374, -0.5629])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2096167802810669]\n",
      "100 steps | score: [0.0903710201382637]\n",
      "200 steps | score: [0.04784087836742401]\n",
      "300 steps | score: [0.04892658442258835]\n",
      "400 steps | score: [0.09860379993915558]\n",
      "500 steps | score: [0.03155650943517685]\n",
      "600 steps | score: [0.043013863265514374]\n",
      "700 steps | score: [0.048639215528964996]\n",
      "800 steps | score: [0.027698952704668045]\n",
      "900 steps | score: [0.052575256675481796]\n",
      "1000 steps | score: [0.05516849830746651]\n",
      "1100 steps | score: [0.04541812837123871]\n",
      "1200 steps | score: [0.07961587607860565]\n",
      "1300 steps | score: [0.0025094328448176384]\n",
      "0 steps | score: [0.05433623865246773, 0.151210218667984]\n",
      "100 steps | score: [-0.024500830098986626, 0.05774681270122528]\n",
      "200 steps | score: [-0.09988969564437866, 0.10780302435159683]\n",
      "300 steps | score: [-0.03232301026582718, 0.050486546009778976]\n",
      "400 steps | score: [-0.02557043731212616, 0.025583021342754364]\n",
      "500 steps | score: [-0.1125871017575264, 0.0937860906124115]\n",
      "600 steps | score: [-0.05910700932145119, 0.05831833928823471]\n",
      "700 steps | score: [-0.046741046011447906, 0.07228054106235504]\n",
      "800 steps | score: [-0.0675366073846817, 0.04167601093649864]\n",
      "900 steps | score: [-0.03664317727088928, 0.003119807690382004]\n",
      "1000 steps | score: [-0.016933612525463104, 0.02494766190648079]\n",
      "1100 steps | score: [-0.04758954793214798, 0.04150842875242233]\n",
      "1200 steps | score: [-0.0059406631626188755, -0.021790549159049988]\n",
      "1300 steps | score: [-0.11133495718240738, 0.1047065481543541]\n",
      "1400 steps | score: [-0.03949001431465149, 0.04400082677602768]\n",
      "1500 steps | score: [-0.04097846895456314, 0.036969639360904694]\n",
      "1600 steps | score: [-0.04167366772890091, 0.04589007794857025]\n",
      "1700 steps | score: [-0.058124084025621414, 0.06569904088973999]\n",
      "1800 steps | score: [-0.04888024553656578, 0.03482391685247421]\n",
      "1900 steps | score: [-0.07012852281332016, 0.055529214441776276]\n",
      "2000 steps | score: [-0.04932991415262222, 0.04748096689581871]\n",
      "2100 steps | score: [-0.043912142515182495, 0.03007977269589901]\n",
      "2200 steps | score: [-0.052713606506586075, 0.04081318527460098]\n",
      "2300 steps | score: [-0.07633185386657715, 0.08193440735340118]\n",
      "2400 steps | score: [-0.03376343473792076, 0.02834143675863743]\n",
      "2500 steps | score: [-0.0419808067381382, 0.03549724072217941]\n",
      "2600 steps | score: [-0.051055531948804855, 0.05348774045705795]\n",
      "0 steps | score: [0.07228655368089676, 0.1195562332868576]\n",
      "100 steps | score: [-0.023579435423016548, 0.056217193603515625]\n",
      "200 steps | score: [-0.0910797268152237, 0.0947623997926712]\n",
      "300 steps | score: [-0.007665210869163275, 0.007556423544883728]\n",
      "unknown params:  tensor([-0.4641, -0.6937])\n",
      "unknown variance:  tensor([[1.0614]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4374, -0.5629])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.4082036018371582]\n",
      "100 steps | score: [0.26953843235969543]\n",
      "200 steps | score: [0.2715672552585602]\n",
      "300 steps | score: [0.1465722769498825]\n",
      "400 steps | score: [0.24772195518016815]\n",
      "500 steps | score: [0.26228585839271545]\n",
      "600 steps | score: [0.1347721815109253]\n",
      "700 steps | score: [0.2580028772354126]\n",
      "800 steps | score: [0.23334428668022156]\n",
      "900 steps | score: [0.12386719137430191]\n",
      "1000 steps | score: [0.20783838629722595]\n",
      "1100 steps | score: [0.23970144987106323]\n",
      "1200 steps | score: [0.1318521499633789]\n",
      "1300 steps | score: [0.20545431971549988]\n",
      "1400 steps | score: [0.20943604409694672]\n",
      "1500 steps | score: [0.13541734218597412]\n",
      "1600 steps | score: [0.21665692329406738]\n",
      "1700 steps | score: [0.20579881966114044]\n",
      "1800 steps | score: [0.1639392077922821]\n",
      "1900 steps | score: [0.20917105674743652]\n",
      "2000 steps | score: [0.20404978096485138]\n",
      "2100 steps | score: [0.18336455523967743]\n",
      "2200 steps | score: [0.19944992661476135]\n",
      "2300 steps | score: [0.21206265687942505]\n",
      "2400 steps | score: [0.17483121156692505]\n",
      "2500 steps | score: [0.15872123837471008]\n",
      "2600 steps | score: [0.2111014872789383]\n",
      "0 steps | score: [0.06767894327640533, 0.1315598338842392]\n",
      "100 steps | score: [0.08934591710567474, -0.08941426873207092]\n",
      "200 steps | score: [0.03337140008807182, -0.08227220922708511]\n",
      "300 steps | score: [-0.12300597131252289, 0.14375224709510803]\n",
      "400 steps | score: [0.04817112162709236, -0.0804494097828865]\n",
      "500 steps | score: [0.025570452213287354, -0.07913009822368622]\n",
      "600 steps | score: [-0.14174078404903412, 0.1607956886291504]\n",
      "700 steps | score: [0.023076971992850304, -0.04674933850765228]\n",
      "800 steps | score: [-0.0005187000497244298, -0.04670894891023636]\n",
      "900 steps | score: [-0.1552431583404541, 0.16619381308555603]\n",
      "1000 steps | score: [-0.004410311114042997, -0.02230832166969776]\n",
      "1100 steps | score: [0.00038435187889263034, -0.04237339645624161]\n",
      "1200 steps | score: [-0.14602693915367126, 0.15096122026443481]\n",
      "1300 steps | score: [-0.01644810661673546, -0.0063731372356414795]\n",
      "1400 steps | score: [-0.01693596877157688, -0.01588439755141735]\n",
      "1500 steps | score: [-0.13110403716564178, 0.137323260307312]\n",
      "1600 steps | score: [-0.039479468017816544, 0.020687328651547432]\n",
      "1700 steps | score: [-0.02752505987882614, -0.00046181492507457733]\n",
      "1800 steps | score: [-0.11709067970514297, 0.11632256209850311]\n",
      "1900 steps | score: [-0.034483008086681366, 0.019172297790646553]\n",
      "2000 steps | score: [-0.027284717187285423, 0.005860128439962864]\n",
      "2100 steps | score: [-0.10197529941797256, 0.10360417515039444]\n",
      "2200 steps | score: [-0.04651534929871559, 0.033181194216012955]\n",
      "2300 steps | score: [-0.02843676507472992, 0.0020809900015592575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 steps | score: [-0.09386491030454636, 0.08384793996810913]\n",
      "2500 steps | score: [-0.04861754551529884, 0.03321050480008125]\n",
      "2600 steps | score: [-0.036427322775125504, 0.025137871503829956]\n",
      "0 steps | score: [0.13387474417686462, 0.02625042200088501]\n",
      "100 steps | score: [0.1355125904083252, -0.17346318066120148]\n",
      "200 steps | score: [0.07569441944360733, -0.14089953899383545]\n",
      "300 steps | score: [-0.07889747619628906, 0.06438849121332169]\n",
      "400 steps | score: [0.09399338811635971, -0.15885807573795319]\n",
      "500 steps | score: [0.07791326940059662, -0.16018088161945343]\n",
      "600 steps | score: [-0.08292219787836075, 0.07442931085824966]\n",
      "700 steps | score: [0.07894530892372131, -0.13217930495738983]\n",
      "800 steps | score: [0.06593568623065948, -0.14374837279319763]\n",
      "900 steps | score: [-0.08832760155200958, 0.07187943905591965]\n",
      "1000 steps | score: [0.053396470844745636, -0.0961046814918518]\n",
      "1100 steps | score: [0.056933656334877014, -0.1335637867450714]\n",
      "1200 steps | score: [-0.07906730473041534, 0.06519465893507004]\n",
      "1300 steps | score: [0.0350760780274868, -0.07795044034719467]\n",
      "1400 steps | score: [0.045375462621450424, -0.10358785092830658]\n",
      "1500 steps | score: [-0.06672687828540802, 0.04523774981498718]\n",
      "1600 steps | score: [0.03679917752742767, -0.08491042256355286]\n",
      "1700 steps | score: [0.04459518566727638, -0.0952252671122551]\n",
      "1800 steps | score: [-0.049665678292512894, 0.02392977476119995]\n",
      "1900 steps | score: [0.03285040333867073, -0.08222898095846176]\n",
      "2000 steps | score: [0.03199965879321098, -0.08420171588659286]\n",
      "2100 steps | score: [-0.042346592992544174, 0.011376751586794853]\n",
      "2200 steps | score: [0.023495517671108246, -0.06190521642565727]\n",
      "2300 steps | score: [0.03595408797264099, -0.08237678557634354]\n",
      "2400 steps | score: [-0.03437972068786621, 0.004627623595297337]\n",
      "2500 steps | score: [0.01826711930334568, -0.05803205445408821]\n",
      "2600 steps | score: [0.0231745857745409, -0.07079989463090897]\n",
      "0 steps | score: [0.14555247128009796, 0.10029568523168564]\n",
      "100 steps | score: [0.14540845155715942, -0.10306978225708008]\n",
      "200 steps | score: [0.10394871979951859, -0.09242179244756699]\n",
      "300 steps | score: [-0.03492923453450203, 0.10291586071252823]\n",
      "400 steps | score: [0.13483574986457825, -0.12293334305286407]\n",
      "500 steps | score: [0.10625904053449631, -0.10471729189157486]\n",
      "600 steps | score: [-0.06641850620508194, 0.13269305229187012]\n",
      "700 steps | score: [0.08983885496854782, -0.061709582805633545]\n",
      "800 steps | score: [0.09222341328859329, -0.08010196685791016]\n",
      "900 steps | score: [-0.08598639816045761, 0.15017887949943542]\n",
      "1000 steps | score: [0.061188116669654846, -0.031109491363167763]\n",
      "1100 steps | score: [0.074535071849823, -0.0687190517783165]\n",
      "1200 steps | score: [-0.07216139882802963, 0.12750042974948883]\n",
      "1300 steps | score: [0.06248205155134201, -0.04029809311032295]\n",
      "1400 steps | score: [0.04904894903302193, -0.030328143388032913]\n",
      "1500 steps | score: [-0.054885383695364, 0.10915781557559967]\n",
      "1600 steps | score: [0.046345558017492294, -0.009448742493987083]\n",
      "1700 steps | score: [0.05026980862021446, -0.02395370416343212]\n",
      "1800 steps | score: [-0.04473961517214775, 0.09805210679769516]\n",
      "1900 steps | score: [0.04661138355731964, -0.0109954122453928]\n",
      "2000 steps | score: [0.045668814331293106, -0.02514287456870079]\n",
      "2100 steps | score: [-0.017333893105387688, 0.07486046850681305]\n",
      "2200 steps | score: [0.029764411970973015, 0.004977725446224213]\n",
      "2300 steps | score: [0.047040801495313644, -0.022724928334355354]\n",
      "2400 steps | score: [-0.014858576469123363, 0.06226570904254913]\n",
      "2500 steps | score: [0.022489288821816444, 0.008236050605773926]\n",
      "2600 steps | score: [0.0325784906744957, 0.0011757425963878632]\n",
      "unknown params:  tensor([-0.4957, -0.8321])\n",
      "unknown variance:  tensor([[1.1225]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4374, -0.5629])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.22104954719543457]\n",
      "100 steps | score: [0.011121414601802826]\n",
      "200 steps | score: [0.06753674149513245]\n",
      "300 steps | score: [0.05260789394378662]\n",
      "400 steps | score: [0.04746166616678238]\n",
      "500 steps | score: [-0.016214055940508842]\n",
      "600 steps | score: [-0.007561627775430679]\n",
      "0 steps | score: [0.1458577662706375, 0.07830644398927689]\n",
      "100 steps | score: [0.005112630780786276, 0.08326420187950134]\n",
      "200 steps | score: [0.2022336721420288, -0.3038303554058075]\n",
      "300 steps | score: [0.11606456339359283, -0.1446443498134613]\n",
      "400 steps | score: [0.04212938994169235, -0.03516341373324394]\n",
      "500 steps | score: [-0.06711409240961075, 0.110557422041893]\n",
      "600 steps | score: [-0.028485743328928947, 0.06558520346879959]\n",
      "700 steps | score: [0.0027063072193413973, 0.03341112658381462]\n",
      "800 steps | score: [-0.07522919774055481, 0.1209583729505539]\n",
      "900 steps | score: [-0.024550404399633408, 0.07288004457950592]\n",
      "1000 steps | score: [0.04306189715862274, -0.05029439553618431]\n",
      "1100 steps | score: [-0.05322965607047081, 0.09601002931594849]\n",
      "1200 steps | score: [0.017875907942652702, -0.008757449686527252]\n",
      "1300 steps | score: [-0.043594829738140106, 0.081069715321064]\n",
      "1400 steps | score: [-0.02377624623477459, 0.05329592525959015]\n",
      "1500 steps | score: [-0.05418961122632027, 0.1005399227142334]\n",
      "1600 steps | score: [-0.034343644976615906, 0.07320424169301987]\n",
      "1700 steps | score: [-0.004365192726254463, 0.022045183926820755]\n",
      "1800 steps | score: [-0.028888486325740814, 0.06144597381353378]\n",
      "1900 steps | score: [-0.061509206891059875, 0.10402293503284454]\n",
      "2000 steps | score: [-0.005859930068254471, 0.03635077923536301]\n",
      "2100 steps | score: [-0.003250535810366273, 0.023292625322937965]\n",
      "2200 steps | score: [-0.04908222705125809, 0.09037428349256516]\n",
      "2300 steps | score: [0.0017941930564120412, 0.010324494913220406]\n",
      "2400 steps | score: [-0.015785491093993187, 0.03563609719276428]\n",
      "2500 steps | score: [-0.03796993941068649, 0.06532058864831924]\n",
      "2600 steps | score: [-0.003481644904240966, 0.024776723235845566]\n",
      "2700 steps | score: [-0.012556228786706924, 0.03878805413842201]\n",
      "0 steps | score: [0.09264585375785828, 0.1155230924487114]\n",
      "100 steps | score: [-0.030822839587926865, 0.10859274864196777]\n",
      "200 steps | score: [0.16002123057842255, -0.2802566587924957]\n",
      "300 steps | score: [0.046210430562496185, -0.06096966564655304]\n",
      "400 steps | score: [0.015285499393939972, -0.01801641471683979]\n",
      "500 steps | score: [-0.10442707687616348, 0.1378040462732315]\n",
      "600 steps | score: [-0.07357484847307205, 0.09498350322246552]\n",
      "700 steps | score: [-0.032992277294397354, 0.04065854847431183]\n",
      "800 steps | score: [-0.09541241824626923, 0.11753226071596146]\n",
      "900 steps | score: [-0.060150329023599625, 0.088416688144207]\n",
      "1000 steps | score: [0.003331561805680394, -0.020343124866485596]\n",
      "1100 steps | score: [-0.07704458385705948, 0.103245809674263]\n",
      "1200 steps | score: [0.0023076061625033617, -0.006710339337587357]\n",
      "0 steps | score: [0.14337372779846191, 0.04318513348698616]\n",
      "100 steps | score: [-0.009623699821531773, 0.0645044595003128]\n",
      "200 steps | score: [0.22034458816051483, -0.36572763323783875]\n",
      "300 steps | score: [0.10774660110473633, -0.16687613725662231]\n",
      "400 steps | score: [0.041932329535484314, -0.07108260691165924]\n",
      "500 steps | score: [-0.07292360812425613, 0.07927396893501282]\n",
      "600 steps | score: [-0.04109633341431618, 0.04316001385450363]\n",
      "700 steps | score: [0.003427359974011779, -0.014103950932621956]\n",
      "800 steps | score: [-0.06560136377811432, 0.07036890834569931]\n",
      "900 steps | score: [-0.029958639293909073, 0.02814459800720215]\n",
      "1000 steps | score: [0.03135107457637787, -0.05953734740614891]\n",
      "1100 steps | score: [-0.05860554799437523, 0.06851809471845627]\n",
      "1200 steps | score: [0.010102477855980396, -0.023775499314069748]\n",
      "1300 steps | score: [-0.04575672373175621, 0.040348492562770844]\n",
      "1400 steps | score: [-0.023936845362186432, 0.01573459431529045]\n",
      "1500 steps | score: [-0.05060300976037979, 0.051301371306180954]\n",
      "1600 steps | score: [-0.04159636050462723, 0.03760454058647156]\n",
      "1700 steps | score: [-0.015883011743426323, -0.005415957421064377]\n",
      "1800 steps | score: [-0.04171189293265343, 0.03956502303481102]\n",
      "1900 steps | score: [-0.06539126485586166, 0.06671613454818726]\n",
      "2000 steps | score: [-0.0011886300053447485, -0.015512913465499878]\n",
      "2100 steps | score: [-0.025164496153593063, 0.010124662891030312]\n",
      "2200 steps | score: [-0.04925336316227913, 0.05121099576354027]\n",
      "2300 steps | score: [0.002197231398895383, -0.01881302520632744]\n",
      "2400 steps | score: [-0.013789386488497257, 0.003483084961771965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 steps | score: [-0.03662975877523422, 0.04035717248916626]\n",
      "2600 steps | score: [-0.010737303644418716, -0.0033096875995397568]\n",
      "2700 steps | score: [-0.024548832327127457, 0.012561189010739326]\n",
      "unknown params:  tensor([-0.5349, -1.0584])\n",
      "unknown variance:  tensor([[1.2461]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4374, -0.5629])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2799234390258789]\n",
      "100 steps | score: [0.14207258820533752]\n",
      "200 steps | score: [0.017057005316019058]\n",
      "300 steps | score: [0.10568779706954956]\n",
      "400 steps | score: [0.08192579448223114]\n",
      "500 steps | score: [0.08118375390768051]\n",
      "600 steps | score: [0.16840630769729614]\n",
      "700 steps | score: [0.022722195833921432]\n",
      "800 steps | score: [0.12728381156921387]\n",
      "900 steps | score: [0.12014348804950714]\n",
      "1000 steps | score: [0.061829522252082825]\n",
      "1100 steps | score: [0.11143083870410919]\n",
      "1200 steps | score: [0.07291217893362045]\n",
      "1300 steps | score: [0.0729978084564209]\n",
      "1400 steps | score: [0.10067496448755264]\n",
      "1500 steps | score: [0.09340284764766693]\n",
      "1600 steps | score: [0.10588256269693375]\n",
      "1700 steps | score: [0.08701515197753906]\n",
      "1800 steps | score: [0.10684116184711456]\n",
      "1900 steps | score: [0.1075589582324028]\n",
      "2000 steps | score: [0.05482466146349907]\n",
      "2100 steps | score: [0.11019517481327057]\n",
      "2200 steps | score: [0.07126136124134064]\n",
      "2300 steps | score: [0.13089591264724731]\n",
      "2400 steps | score: [0.07883687317371368]\n",
      "2500 steps | score: [0.05787631496787071]\n",
      "2600 steps | score: [0.08659449219703674]\n",
      "0 steps | score: [0.134861558675766, 0.05637675151228905]\n",
      "100 steps | score: [0.023368513211607933, 0.08235502243041992]\n",
      "200 steps | score: [-0.029821712523698807, 0.0707075297832489]\n",
      "300 steps | score: [0.040978241711854935, -0.07598140835762024]\n",
      "400 steps | score: [-0.008867766708135605, 0.013605613261461258]\n",
      "500 steps | score: [-0.08649256825447083, 0.1424817591905594]\n",
      "600 steps | score: [0.041921187192201614, -0.05030438303947449]\n",
      "700 steps | score: [-0.13646674156188965, 0.21100544929504395]\n",
      "800 steps | score: [-0.04346753656864166, 0.06842672824859619]\n",
      "900 steps | score: [0.01408915501087904, -0.013350378721952438]\n",
      "1000 steps | score: [-0.09226386994123459, 0.1411152184009552]\n",
      "1100 steps | score: [-0.01465050969272852, 0.04091767221689224]\n",
      "1200 steps | score: [-0.0242132768034935, 0.019728153944015503]\n",
      "1300 steps | score: [-0.04194342717528343, 0.06035781651735306]\n",
      "1400 steps | score: [-0.046496931463479996, 0.08012650907039642]\n",
      "1500 steps | score: [-0.01401207223534584, 0.012668672949075699]\n",
      "1600 steps | score: [-0.0690368115901947, 0.1030452772974968]\n",
      "1700 steps | score: [-0.04712889343500137, 0.06659309566020966]\n",
      "1800 steps | score: [-0.026301739737391472, 0.029428603127598763]\n",
      "1900 steps | score: [0.017282510176301003, -0.03858644515275955]\n",
      "2000 steps | score: [-0.03811104595661163, 0.05013827979564667]\n",
      "2100 steps | score: [-0.036394525319337845, 0.05437352508306503]\n",
      "2200 steps | score: [-0.07182923704385757, 0.1084204912185669]\n",
      "2300 steps | score: [0.0012358245439827442, -0.007782828062772751]\n",
      "0 steps | score: [0.24533803761005402, -0.10144126415252686]\n",
      "100 steps | score: [0.10618020594120026, -0.051358308643102646]\n",
      "200 steps | score: [0.03900277242064476, -0.027872417122125626]\n",
      "300 steps | score: [0.11548032611608505, -0.1806049942970276]\n",
      "400 steps | score: [0.09884576499462128, -0.13738468289375305]\n",
      "500 steps | score: [0.0265877116471529, -0.033233337104320526]\n",
      "600 steps | score: [0.10671129077672958, -0.14792564511299133]\n",
      "700 steps | score: [-0.06706635653972626, 0.10246672481298447]\n",
      "800 steps | score: [0.045170120894908905, -0.07371517270803452]\n",
      "900 steps | score: [0.07194577157497406, -0.10918562859296799]\n",
      "1000 steps | score: [-0.009660623036324978, 0.017453515902161598]\n",
      "1100 steps | score: [0.057360921055078506, -0.07869962602853775]\n",
      "1200 steps | score: [0.07227077335119247, -0.13165409862995148]\n",
      "1300 steps | score: [0.06647063046693802, -0.09814964234828949]\n",
      "1400 steps | score: [0.044319573789834976, -0.05805807188153267]\n",
      "1500 steps | score: [0.06470649689435959, -0.11973898112773895]\n",
      "1600 steps | score: [0.018051357939839363, -0.022062096744775772]\n",
      "1700 steps | score: [0.03515932336449623, -0.05261583253741264]\n",
      "1800 steps | score: [0.08676862716674805, -0.13555899262428284]\n",
      "1900 steps | score: [0.09957955032587051, -0.1689876914024353]\n",
      "2000 steps | score: [0.04948829486966133, -0.08803626894950867]\n",
      "2100 steps | score: [0.06346189975738525, -0.09943310916423798]\n",
      "2200 steps | score: [0.021924380213022232, -0.0332484170794487]\n",
      "2300 steps | score: [0.08842354267835617, -0.13860422372817993]\n",
      "2400 steps | score: [0.0343388095498085, -0.05774248391389847]\n",
      "2500 steps | score: [0.0334596261382103, -0.05330105125904083]\n",
      "2600 steps | score: [0.058695707470178604, -0.09964253008365631]\n",
      "0 steps | score: [0.2025216668844223, -0.07222175598144531]\n",
      "100 steps | score: [0.08861498534679413, -0.04029444605112076]\n",
      "200 steps | score: [0.004619752522557974, -0.0016199834644794464]\n",
      "unknown params:  tensor([-0.5045, -1.1139])\n",
      "unknown variance:  tensor([[1.4092]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4374, -0.5629])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.32044556736946106]\n",
      "100 steps | score: [0.1525609791278839]\n",
      "200 steps | score: [0.09677302837371826]\n",
      "300 steps | score: [0.1591475009918213]\n",
      "400 steps | score: [0.06492286175489426]\n",
      "500 steps | score: [0.14329922199249268]\n",
      "600 steps | score: [0.0935949981212616]\n",
      "700 steps | score: [0.12262120842933655]\n",
      "800 steps | score: [0.13573682308197021]\n",
      "900 steps | score: [0.09606019407510757]\n",
      "1000 steps | score: [0.14210151135921478]\n",
      "1100 steps | score: [0.11627212166786194]\n",
      "1200 steps | score: [0.14162415266036987]\n",
      "1300 steps | score: [0.08459019660949707]\n",
      "1400 steps | score: [0.14873559772968292]\n",
      "1500 steps | score: [0.09613202512264252]\n",
      "1600 steps | score: [0.142467200756073]\n",
      "1700 steps | score: [0.132675901055336]\n",
      "1800 steps | score: [0.12098962068557739]\n",
      "1900 steps | score: [0.08879806846380234]\n",
      "2000 steps | score: [0.11707398295402527]\n",
      "2100 steps | score: [0.15856391191482544]\n",
      "2200 steps | score: [0.10198050737380981]\n",
      "2300 steps | score: [0.14026156067848206]\n",
      "2400 steps | score: [0.126224085688591]\n",
      "2500 steps | score: [0.1131751760840416]\n",
      "0 steps | score: [0.20629411935806274, -0.0844934806227684]\n",
      "100 steps | score: [0.13920962810516357, -0.09774260222911835]\n",
      "200 steps | score: [-0.03606883063912392, 0.11568410694599152]\n",
      "300 steps | score: [0.003637568559497595, 0.043291449546813965]\n",
      "400 steps | score: [-0.0810796469449997, 0.16562114655971527]\n",
      "500 steps | score: [0.0763176679611206, -0.13181591033935547]\n",
      "600 steps | score: [-0.14598962664604187, 0.2604663670063019]\n",
      "700 steps | score: [0.08994819968938828, -0.15999090671539307]\n",
      "800 steps | score: [-0.036907121539115906, 0.0879632979631424]\n",
      "900 steps | score: [0.00561835803091526, -0.005145733244717121]\n",
      "0 steps | score: [0.18958641588687897, -0.059552136808633804]\n",
      "100 steps | score: [0.12895973026752472, -0.08771203458309174]\n",
      "200 steps | score: [-0.041797440499067307, 0.11041240394115448]\n",
      "300 steps | score: [-0.019023356959223747, 0.06305474042892456]\n",
      "400 steps | score: [-0.09138675779104233, 0.17005547881126404]\n",
      "500 steps | score: [0.0759119912981987, -0.1340254843235016]\n",
      "600 steps | score: [-0.15702131390571594, 0.27496659755706787]\n",
      "700 steps | score: [0.03412150219082832, -0.06986968219280243]\n",
      "800 steps | score: [-0.06678775697946548, 0.13010665774345398]\n",
      "900 steps | score: [-0.007199607323855162, -0.0043616220355033875]\n",
      "0 steps | score: [0.1982349455356598, -0.0904933363199234]\n",
      "100 steps | score: [0.12913082540035248, -0.09820783138275146]\n",
      "200 steps | score: [-0.020937811583280563, 0.07847528159618378]\n",
      "300 steps | score: [0.029660912230610847, -0.026521138846874237]\n",
      "400 steps | score: [-0.09155295789241791, 0.16345489025115967]\n",
      "500 steps | score: [0.08657719194889069, -0.16560912132263184]\n",
      "600 steps | score: [-0.16245326399803162, 0.25577205419540405]\n",
      "700 steps | score: [0.08626294136047363, -0.18368175625801086]\n",
      "800 steps | score: [-0.06388028711080551, 0.10600683093070984]\n",
      "900 steps | score: [-0.007755235303193331, 0.003749084658920765]\n",
      "unknown params:  tensor([-0.6094, -1.5336])\n",
      "unknown variance:  tensor([[1.5654]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4374, -0.5629])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.34436893463134766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [0.08125409483909607]\n",
      "200 steps | score: [0.05458087474107742]\n",
      "300 steps | score: [0.034909866750240326]\n",
      "400 steps | score: [0.051588013768196106]\n",
      "500 steps | score: [0.07414565235376358]\n",
      "600 steps | score: [0.06067764759063721]\n",
      "700 steps | score: [0.03996093571186066]\n",
      "800 steps | score: [0.08332690596580505]\n",
      "900 steps | score: [0.046340446919202805]\n",
      "1000 steps | score: [0.056646183133125305]\n",
      "1100 steps | score: [0.0584883838891983]\n",
      "1200 steps | score: [0.06939209252595901]\n",
      "1300 steps | score: [0.032997824251651764]\n",
      "1400 steps | score: [0.0785936564207077]\n",
      "1500 steps | score: [0.04321208596229553]\n",
      "1600 steps | score: [0.04621436446905136]\n",
      "1700 steps | score: [0.048020996153354645]\n",
      "1800 steps | score: [0.06276429444551468]\n",
      "1900 steps | score: [0.01072094589471817]\n",
      "2000 steps | score: [0.05107581615447998]\n",
      "2100 steps | score: [0.04808400571346283]\n",
      "2200 steps | score: [0.0392538420855999]\n",
      "2300 steps | score: [0.056227970868349075]\n",
      "2400 steps | score: [0.02884824573993683]\n",
      "2500 steps | score: [0.03219301253557205]\n",
      "0 steps | score: [0.184731125831604, -0.11596982926130295]\n",
      "100 steps | score: [0.011224694550037384, 0.10383331775665283]\n",
      "200 steps | score: [-0.032983679324388504, 0.13184475898742676]\n",
      "300 steps | score: [-0.03971972316503525, 0.10849188268184662]\n",
      "400 steps | score: [-0.0719296857714653, 0.15214522182941437]\n",
      "500 steps | score: [-0.08238089829683304, 0.16855747997760773]\n",
      "600 steps | score: [0.014853019267320633, -0.039747487753629684]\n",
      "700 steps | score: [-0.1647924929857254, 0.3042488098144531]\n",
      "800 steps | score: [0.0721350684762001, -0.17033188045024872]\n",
      "900 steps | score: [-0.10188456624746323, 0.1875675767660141]\n",
      "1000 steps | score: [0.01296782586723566, -0.0404696986079216]\n",
      "1100 steps | score: [-0.06209435686469078, 0.12269236147403717]\n",
      "1200 steps | score: [0.050924550741910934, -0.12031462788581848]\n",
      "1300 steps | score: [-0.10639255493879318, 0.2006182074546814]\n",
      "1400 steps | score: [0.014181897044181824, -0.03910335898399353]\n",
      "1500 steps | score: [0.020909685641527176, -0.05049131065607071]\n",
      "1600 steps | score: [0.026742227375507355, -0.06352872401475906]\n",
      "1700 steps | score: [-0.0436554029583931, 0.061920974403619766]\n",
      "1800 steps | score: [-0.009783382527530193, 0.006630346179008484]\n",
      "0 steps | score: [0.14875319600105286, 0.004422450438141823]\n",
      "100 steps | score: [-0.000350465124938637, 0.18121832609176636]\n",
      "200 steps | score: [-0.10537143051624298, 0.3172866702079773]\n",
      "300 steps | score: [-0.0614982508122921, 0.20159828662872314]\n",
      "400 steps | score: [-0.07915562391281128, 0.217658132314682]\n",
      "500 steps | score: [-0.11621017754077911, 0.2788088321685791]\n",
      "600 steps | score: [-0.04348697513341904, 0.12941646575927734]\n",
      "700 steps | score: [-0.1917165368795395, 0.4090062975883484]\n",
      "800 steps | score: [0.020588306710124016, -0.0026168888434767723]\n",
      "900 steps | score: [-0.13022196292877197, 0.31474077701568604]\n",
      "1000 steps | score: [-0.008019369095563889, 0.05428292602300644]\n",
      "1100 steps | score: [-0.09436212480068207, 0.22669240832328796]\n",
      "1200 steps | score: [0.02202465757727623, -0.007715404033660889]\n",
      "1300 steps | score: [-0.11347813159227371, 0.2700248658657074]\n",
      "1400 steps | score: [0.02394237369298935, -0.006798123940825462]\n",
      "1500 steps | score: [-0.008832119405269623, 0.05484919622540474]\n",
      "1600 steps | score: [-0.0066266111098229885, 0.04074462130665779]\n",
      "1700 steps | score: [-0.06251663714647293, 0.16230376064777374]\n",
      "1800 steps | score: [-0.038500357419252396, 0.11950395256280899]\n",
      "1900 steps | score: [-0.02359185181558132, 0.08331175148487091]\n",
      "2000 steps | score: [-0.04947900027036667, 0.13180582225322723]\n",
      "2100 steps | score: [0.019084440544247627, -0.01126704178750515]\n",
      "2200 steps | score: [-0.05159691721200943, 0.14596261084079742]\n",
      "2300 steps | score: [0.002025614259764552, 0.03206929564476013]\n",
      "2400 steps | score: [-0.07550933212041855, 0.1809639036655426]\n",
      "2500 steps | score: [-0.02578503079712391, 0.09155823290348053]\n",
      "0 steps | score: [0.12464525550603867, 0.023174064233899117]\n",
      "100 steps | score: [-0.013378525152802467, 0.17606468498706818]\n",
      "200 steps | score: [-0.09224391728639603, 0.262226939201355]\n",
      "300 steps | score: [-0.10584448277950287, 0.2526261806488037]\n",
      "400 steps | score: [-0.11381660401821136, 0.25307759642601013]\n",
      "500 steps | score: [-0.16949462890625, 0.3484788239002228]\n",
      "600 steps | score: [-0.07025231420993805, 0.15373778343200684]\n",
      "700 steps | score: [-0.1902795135974884, 0.3851681351661682]\n",
      "800 steps | score: [-0.0023226800840348005, 0.012707976624369621]\n",
      "900 steps | score: [-0.14995554089546204, 0.298678457736969]\n",
      "1000 steps | score: [0.006485203746706247, -0.005897918716073036]\n",
      "unknown params:  tensor([-0.5114, -1.3404])\n",
      "unknown variance:  tensor([[1.6046]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/0fc7dc4d-b2a4-4321-94cc-dcf791a269ce\n",
      "gt params:  tensor([-0.4275, -0.5885])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.21546490490436554]\n",
      "100 steps | score: [0.02805829420685768]\n",
      "200 steps | score: [0.022411970421671867]\n",
      "300 steps | score: [0.11092211306095123]\n",
      "400 steps | score: [0.15819348394870758]\n",
      "500 steps | score: [0.04298045113682747]\n",
      "600 steps | score: [0.12414704263210297]\n",
      "700 steps | score: [0.1134595274925232]\n",
      "800 steps | score: [0.19421829283237457]\n",
      "900 steps | score: [0.08682563155889511]\n",
      "1000 steps | score: [0.08533138036727905]\n",
      "1100 steps | score: [0.07908667623996735]\n",
      "1200 steps | score: [0.0691535621881485]\n",
      "1300 steps | score: [0.14621992409229279]\n",
      "1400 steps | score: [0.07405314594507217]\n",
      "1500 steps | score: [0.077071413397789]\n",
      "1600 steps | score: [0.09486404061317444]\n",
      "1700 steps | score: [0.17529453337192535]\n",
      "1800 steps | score: [0.11506351083517075]\n",
      "1900 steps | score: [0.10662409663200378]\n",
      "2000 steps | score: [0.08857710659503937]\n",
      "2100 steps | score: [0.08122050017118454]\n",
      "2200 steps | score: [0.12357617914676666]\n",
      "2300 steps | score: [0.09406420588493347]\n",
      "2400 steps | score: [0.09348258376121521]\n",
      "2500 steps | score: [0.07098366320133209]\n",
      "2600 steps | score: [0.1259341984987259]\n",
      "0 steps | score: [-0.0211141649633646, 0.1232886090874672]\n",
      "100 steps | score: [-0.07069630175828934, 0.13170099258422852]\n",
      "200 steps | score: [-0.09064168483018875, 0.08546140789985657]\n",
      "300 steps | score: [-0.02741807885468006, 0.04139735922217369]\n",
      "400 steps | score: [0.018184030428528786, 0.07991478592157364]\n",
      "500 steps | score: [-0.07298902422189713, 0.03808191791176796]\n",
      "600 steps | score: [-0.029818972572684288, 0.05860815942287445]\n",
      "700 steps | score: [-0.056817617267370224, 0.01325158216059208]\n",
      "800 steps | score: [-0.0012372659984976053, 0.035036612302064896]\n",
      "900 steps | score: [-0.04164782911539078, 0.050630029290914536]\n",
      "1000 steps | score: [-0.039454136043787, 0.07712047547101974]\n",
      "1100 steps | score: [-0.05310243368148804, 0.06463988125324249]\n",
      "1200 steps | score: [-0.052951645106077194, 0.0380118303000927]\n",
      "1300 steps | score: [-0.0076407697051763535, 0.06566281616687775]\n",
      "1400 steps | score: [-0.05902591347694397, 0.05263683572411537]\n",
      "1500 steps | score: [-0.041808921843767166, 0.06571830064058304]\n",
      "1600 steps | score: [-0.061601195484399796, 0.03606487065553665]\n",
      "1700 steps | score: [-0.02263893187046051, 0.043986789882183075]\n",
      "1800 steps | score: [-0.03212461248040199, 0.05120318382978439]\n",
      "1900 steps | score: [-0.04389442130923271, 0.06333426386117935]\n",
      "2000 steps | score: [-0.05290192738175392, 0.06290217489004135]\n",
      "2100 steps | score: [-0.049713850021362305, 0.05472250655293465]\n",
      "2200 steps | score: [-0.026097489520907402, 0.05961984023451805]\n",
      "2300 steps | score: [-0.047345589846372604, 0.05052448809146881]\n",
      "2400 steps | score: [-0.03477824479341507, 0.06971009075641632]\n",
      "2500 steps | score: [-0.04723086580634117, 0.052689991891384125]\n",
      "2600 steps | score: [-0.03167938068509102, 0.054909683763980865]\n",
      "0 steps | score: [0.023670867085456848, 0.03909460827708244]\n",
      "100 steps | score: [-0.04464248567819595, 0.05534449592232704]\n",
      "200 steps | score: [-0.06745308637619019, 0.019250549376010895]\n",
      "300 steps | score: [0.005086380988359451, -0.030282005667686462]\n",
      "400 steps | score: [0.04328567162156105, -0.001056217122823]\n",
      "500 steps | score: [-0.04523194581270218, -0.04116799682378769]\n",
      "600 steps | score: [0.003887110622599721, -0.0069192079827189445]\n",
      "0 steps | score: [0.05900541692972183, 0.029884953051805496]\n",
      "100 steps | score: [-0.023647719994187355, 0.05089733749628067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [-0.021074026823043823, 0.012776762247085571]\n",
      "300 steps | score: [0.029574427753686905, -0.028560690581798553]\n",
      "400 steps | score: [0.08186457306146622, 0.0020208191126585007]\n",
      "500 steps | score: [-0.008974355645477772, -0.03958665579557419]\n",
      "600 steps | score: [0.04408886283636093, -0.021602429449558258]\n",
      "700 steps | score: [0.005046686623245478, -0.06929760426282883]\n",
      "800 steps | score: [0.06388121843338013, -0.04340746998786926]\n",
      "900 steps | score: [0.014332312159240246, -0.035921111702919006]\n",
      "1000 steps | score: [0.02444910630583763, -0.010088495910167694]\n",
      "1100 steps | score: [0.011182236485183239, -0.016255035996437073]\n",
      "1200 steps | score: [0.01592368446290493, -0.029161933809518814]\n",
      "1300 steps | score: [0.06059366837143898, -0.008174222894012928]\n",
      "1400 steps | score: [0.006291549187153578, -0.0267921332269907]\n",
      "1500 steps | score: [0.02623584493994713, -0.009227970615029335]\n",
      "1600 steps | score: [-0.004414016846567392, -0.03884739428758621]\n",
      "1700 steps | score: [0.04235826060175896, -0.02581416815519333]\n",
      "1800 steps | score: [0.029212454333901405, -0.030137665569782257]\n",
      "1900 steps | score: [0.01995067670941353, -0.013380954973399639]\n",
      "2000 steps | score: [0.013598157092928886, -0.015548067167401314]\n",
      "2100 steps | score: [0.02019316516816616, -0.02344922535121441]\n",
      "2200 steps | score: [0.0439322255551815, -0.014268571510910988]\n",
      "2300 steps | score: [0.020134318619966507, -0.025680851191282272]\n",
      "2400 steps | score: [0.03074941225349903, -0.01046256348490715]\n",
      "2500 steps | score: [0.017891760915517807, -0.025482960045337677]\n",
      "2600 steps | score: [0.033168990164995193, -0.02756737917661667]\n",
      "unknown params:  tensor([-0.3961, -0.4801])\n",
      "unknown variance:  tensor([[0.8424]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4275, -0.5885])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.23540997505187988]\n",
      "100 steps | score: [0.08822683990001678]\n",
      "200 steps | score: [0.09464031457901001]\n",
      "300 steps | score: [0.023546457290649414]\n",
      "400 steps | score: [0.06051235646009445]\n",
      "500 steps | score: [0.05908810719847679]\n",
      "600 steps | score: [0.033737681806087494]\n",
      "700 steps | score: [0.06404004245996475]\n",
      "800 steps | score: [0.05736292153596878]\n",
      "900 steps | score: [0.0403929129242897]\n",
      "1000 steps | score: [0.0752769336104393]\n",
      "1100 steps | score: [0.04187428206205368]\n",
      "1200 steps | score: [0.08966135233640671]\n",
      "1300 steps | score: [0.03388161212205887]\n",
      "1400 steps | score: [0.08022051304578781]\n",
      "1500 steps | score: [0.07573553174734116]\n",
      "1600 steps | score: [0.10919711738824844]\n",
      "1700 steps | score: [0.0659031793475151]\n",
      "1800 steps | score: [0.07051154226064682]\n",
      "1900 steps | score: [0.08762030303478241]\n",
      "2000 steps | score: [0.10652924329042435]\n",
      "2100 steps | score: [0.054363004863262177]\n",
      "2200 steps | score: [0.05694950371980667]\n",
      "2300 steps | score: [0.06964069604873657]\n",
      "2400 steps | score: [0.11920159310102463]\n",
      "2500 steps | score: [0.07432617247104645]\n",
      "2600 steps | score: [0.09635855257511139]\n",
      "2700 steps | score: [0.08488709479570389]\n",
      "2800 steps | score: [0.1123850867152214]\n",
      "0 steps | score: [0.10364153981208801, 0.12583740055561066]\n",
      "100 steps | score: [0.0282796211540699, 0.003299103584140539]\n",
      "200 steps | score: [0.03325987234711647, 0.00045223720371723175]\n",
      "300 steps | score: [-0.022046715021133423, 0.08282285183668137]\n",
      "400 steps | score: [0.01284819282591343, 0.06455916911363602]\n",
      "500 steps | score: [0.004207609221339226, 0.04350430518388748]\n",
      "600 steps | score: [-0.006565815303474665, 0.04499846324324608]\n",
      "700 steps | score: [-0.011162840761244297, 0.06843695789575577]\n",
      "800 steps | score: [0.03451504558324814, 0.047162771224975586]\n",
      "900 steps | score: [-0.008667577989399433, 0.05762655660510063]\n",
      "1000 steps | score: [0.03083406388759613, 0.03314385563135147]\n",
      "1100 steps | score: [0.007052682805806398, 0.05416712909936905]\n",
      "1200 steps | score: [0.04424169659614563, 0.04471038654446602]\n",
      "1300 steps | score: [-0.00045775517355650663, 0.049031440168619156]\n",
      "1400 steps | score: [0.02670525759458542, 0.030220139771699905]\n",
      "1500 steps | score: [0.017640970647335052, 0.041863664984703064]\n",
      "1600 steps | score: [0.04569268971681595, 0.04044511169195175]\n",
      "1700 steps | score: [0.006539267022162676, 0.03817078843712807]\n",
      "1800 steps | score: [0.01861327514052391, 0.03887931630015373]\n",
      "1900 steps | score: [0.01732107624411583, 0.03184715285897255]\n",
      "2000 steps | score: [0.048534393310546875, 0.030013026669621468]\n",
      "2100 steps | score: [0.017711328342556953, 0.03111758828163147]\n",
      "2200 steps | score: [0.015019509941339493, 0.04168286919593811]\n",
      "2300 steps | score: [0.025590330362319946, 0.02703026868402958]\n",
      "2400 steps | score: [0.043941937386989594, 0.031804993748664856]\n",
      "2500 steps | score: [0.0271147508174181, 0.026684191077947617]\n",
      "2600 steps | score: [0.026240229606628418, 0.039402544498443604]\n",
      "2700 steps | score: [0.024933727458119392, 0.02385367453098297]\n",
      "2800 steps | score: [0.04432361572980881, 0.025622840970754623]\n",
      "0 steps | score: [0.07303795218467712, 0.056044913828372955]\n",
      "100 steps | score: [-0.005835125222802162, -0.041754305362701416]\n",
      "200 steps | score: [0.010338528081774712, -0.05137873440980911]\n",
      "300 steps | score: [-0.03572846204042435, 0.02555658109486103]\n",
      "400 steps | score: [-0.009753372520208359, 0.006625399924814701]\n",
      "0 steps | score: [0.0455685593187809, 0.15066319704055786]\n",
      "100 steps | score: [-0.0277711134403944, 0.03502295911312103]\n",
      "200 steps | score: [-0.015510729514062405, 0.026704415678977966]\n",
      "300 steps | score: [-0.06848550587892532, 0.10164546221494675]\n",
      "400 steps | score: [-0.03991738334298134, 0.08934000134468079]\n",
      "500 steps | score: [-0.052493561059236526, 0.061549991369247437]\n",
      "600 steps | score: [-0.044094715267419815, 0.06661021709442139]\n",
      "700 steps | score: [-0.05533817782998085, 0.09657134115695953]\n",
      "800 steps | score: [-0.02592005580663681, 0.07370530813932419]\n",
      "900 steps | score: [-0.05413391813635826, 0.078024722635746]\n",
      "1000 steps | score: [-0.011819974519312382, 0.05360814929008484]\n",
      "1100 steps | score: [-0.03805546462535858, 0.07971180230379105]\n",
      "1200 steps | score: [-0.0037672643084079027, 0.07107315212488174]\n",
      "1300 steps | score: [-0.05694880709052086, 0.0715227946639061]\n",
      "1400 steps | score: [-0.018752239644527435, 0.055922940373420715]\n",
      "1500 steps | score: [-0.030798576772212982, 0.06917111575603485]\n",
      "1600 steps | score: [-0.0036431425251066685, 0.06416086852550507]\n",
      "1700 steps | score: [-0.030638189986348152, 0.05785669758915901]\n",
      "1800 steps | score: [-0.02301955409348011, 0.06327834725379944]\n",
      "1900 steps | score: [-0.023490415886044502, 0.06473434716463089]\n",
      "2000 steps | score: [0.003450482850894332, 0.049810741096735]\n",
      "2100 steps | score: [-0.027358543127775192, 0.055861521512269974]\n",
      "2200 steps | score: [-0.02588783949613571, 0.06482826173305511]\n",
      "2300 steps | score: [-0.02144290693104267, 0.04953744262456894]\n",
      "2400 steps | score: [0.0008649801020510495, 0.04976576939225197]\n",
      "2500 steps | score: [-0.011461563408374786, 0.05255679041147232]\n",
      "2600 steps | score: [-0.022254446521401405, 0.06328491866588593]\n",
      "2700 steps | score: [-0.017302539199590683, 0.04648569971323013]\n",
      "2800 steps | score: [-0.0005966795142740011, 0.04757041484117508]\n",
      "unknown params:  tensor([-0.4059, -0.4970])\n",
      "unknown variance:  tensor([[0.8877]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4275, -0.5885])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.11096076667308807]\n",
      "100 steps | score: [0.05793183296918869]\n",
      "200 steps | score: [-0.05937500670552254]\n",
      "300 steps | score: [0.09789176285266876]\n",
      "400 steps | score: [-0.08006107062101364]\n",
      "500 steps | score: [-0.05702327936887741]\n",
      "600 steps | score: [-0.01527656614780426]\n",
      "700 steps | score: [0.05498507246375084]\n",
      "800 steps | score: [-0.0492556132376194]\n",
      "900 steps | score: [0.003307987004518509]\n",
      "0 steps | score: [0.07519611716270447, 0.09951179474592209]\n",
      "100 steps | score: [0.025333385914564133, 0.03648298978805542]\n",
      "200 steps | score: [-0.038648635149002075, 0.01712273620069027]\n",
      "300 steps | score: [0.10029179602861404, -0.055616289377212524]\n",
      "400 steps | score: [-0.03163841366767883, -0.03890906646847725]\n",
      "500 steps | score: [-0.0024573407135903835, 0.014652268961071968]\n",
      "600 steps | score: [-0.011895302683115005, -0.028651516884565353]\n",
      "700 steps | score: [0.051365453749895096, -0.024562599137425423]\n",
      "800 steps | score: [-0.021371793001890182, -0.013003593310713768]\n",
      "900 steps | score: [0.013275866396725178, 0.00790926069021225]\n",
      "1000 steps | score: [0.04100235551595688, -0.060876183211803436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 steps | score: [0.022931555286049843, 0.009307704865932465]\n",
      "1200 steps | score: [-0.03537078574299812, 0.0032762917689979076]\n",
      "1300 steps | score: [-0.04359161853790283, 0.03903575986623764]\n",
      "1400 steps | score: [-0.03915487602353096, 0.02320544421672821]\n",
      "1500 steps | score: [-0.006020339671522379, 0.012254946865141392]\n",
      "1600 steps | score: [-0.012247135862708092, 0.00822019949555397]\n",
      "1700 steps | score: [-0.029017312452197075, 0.02050386555492878]\n",
      "1800 steps | score: [0.0018254596507176757, -0.008093475364148617]\n",
      "0 steps | score: [0.09335518628358841, 0.08846491575241089]\n",
      "100 steps | score: [0.054124146699905396, 0.021373432129621506]\n",
      "200 steps | score: [-0.016682295128703117, -0.00482639204710722]\n",
      "300 steps | score: [0.12443148344755173, -0.07596299797296524]\n",
      "400 steps | score: [-0.007701450958848, -0.04550369083881378]\n",
      "500 steps | score: [0.011399307288229465, 0.005887867882847786]\n",
      "600 steps | score: [0.011091476306319237, -0.03953612968325615]\n",
      "700 steps | score: [0.07394970208406448, -0.04243706911802292]\n",
      "800 steps | score: [0.000400401942897588, -0.02539229765534401]\n",
      "900 steps | score: [0.02501002885401249, 0.0033074524253606796]\n",
      "1000 steps | score: [0.07260852307081223, -0.08195941895246506]\n",
      "1100 steps | score: [0.03951578959822655, -0.0016197445802390575]\n",
      "1200 steps | score: [-0.007707556709647179, -0.007430005818605423]\n",
      "0 steps | score: [0.0958942398428917, 0.10412192344665527]\n",
      "100 steps | score: [0.052672989666461945, 0.039321720600128174]\n",
      "200 steps | score: [-0.011051397770643234, 0.011582823470234871]\n",
      "300 steps | score: [0.13374683260917664, -0.07191227376461029]\n",
      "400 steps | score: [-0.00912405364215374, -0.02900998666882515]\n",
      "500 steps | score: [0.017049098387360573, 0.027076758444309235]\n",
      "600 steps | score: [0.016948789358139038, -0.03611808270215988]\n",
      "700 steps | score: [0.07601416856050491, -0.02589358761906624]\n",
      "800 steps | score: [0.0014165046159178019, -0.01514662429690361]\n",
      "900 steps | score: [0.03071821853518486, 0.023787841200828552]\n",
      "1000 steps | score: [0.0684930682182312, -0.061024121940135956]\n",
      "1100 steps | score: [0.032239075750112534, 0.014850173145532608]\n",
      "1200 steps | score: [-0.00703439861536026, 0.005554812960326672]\n",
      "unknown params:  tensor([-0.4225, -0.5403])\n",
      "unknown variance:  tensor([[0.9374]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4275, -0.5885])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.19893351197242737]\n",
      "100 steps | score: [0.11362099647521973]\n",
      "200 steps | score: [0.06625210493803024]\n",
      "300 steps | score: [0.1725751757621765]\n",
      "400 steps | score: [-0.02608529105782509]\n",
      "500 steps | score: [0.0017383620142936707]\n",
      "0 steps | score: [0.11775930225849152, 0.12109877169132233]\n",
      "100 steps | score: [0.1138971745967865, -0.0637902170419693]\n",
      "200 steps | score: [0.04126254841685295, -0.019910691305994987]\n",
      "300 steps | score: [0.05702783912420273, 0.0017648730427026749]\n",
      "400 steps | score: [-0.0320110060274601, 0.03982109948992729]\n",
      "500 steps | score: [-0.04851781576871872, 0.09447522461414337]\n",
      "600 steps | score: [-0.0710701122879982, 0.09734664857387543]\n",
      "700 steps | score: [-0.001003539189696312, 0.05174294859170914]\n",
      "800 steps | score: [0.04963536560535431, -0.007296963594853878]\n",
      "900 steps | score: [0.04756597802042961, -0.016319211572408676]\n",
      "1000 steps | score: [0.08714627474546432, -0.04162316024303436]\n",
      "1100 steps | score: [-0.017576325684785843, 0.035752639174461365]\n",
      "1200 steps | score: [-0.018627844750881195, 0.0635969340801239]\n",
      "1300 steps | score: [-0.010565810836851597, 0.0465974435210228]\n",
      "1400 steps | score: [0.023090781643986702, 0.023059841245412827]\n",
      "1500 steps | score: [0.02783725969493389, 0.011315112933516502]\n",
      "1600 steps | score: [0.025752810761332512, 0.006066695787012577]\n",
      "1700 steps | score: [0.06992072612047195, -0.04013904184103012]\n",
      "1800 steps | score: [0.011352716013789177, 0.023158786818385124]\n",
      "1900 steps | score: [-0.0069532450288534164, 0.046051762998104095]\n",
      "2000 steps | score: [0.015058035962283611, 0.016827598214149475]\n",
      "2100 steps | score: [0.019700096920132637, 0.02324196696281433]\n",
      "2200 steps | score: [0.03363494575023651, 0.009070945903658867]\n",
      "2300 steps | score: [0.01882230117917061, 0.017206797376275063]\n",
      "2400 steps | score: [0.051038727164268494, -0.012214167043566704]\n",
      "2500 steps | score: [0.017335183918476105, 0.01771596074104309]\n",
      "2600 steps | score: [0.01292828656733036, 0.026239454746246338]\n",
      "2700 steps | score: [0.017053134739398956, 0.01789032481610775]\n",
      "2800 steps | score: [0.028145741671323776, 0.006231470499187708]\n",
      "0 steps | score: [0.09700310230255127, 0.13136610388755798]\n",
      "100 steps | score: [0.08167781680822372, -0.04503543674945831]\n",
      "200 steps | score: [0.002740916097536683, -0.008194110356271267]\n",
      "unknown params:  tensor([-0.4344, -0.5904])\n",
      "unknown variance:  tensor([[0.9529]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4275, -0.5885])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.04434189572930336]\n",
      "100 steps | score: [-0.04277388006448746]\n",
      "200 steps | score: [0.02356506884098053]\n",
      "300 steps | score: [-0.10208439826965332]\n",
      "400 steps | score: [-0.0686866044998169]\n",
      "500 steps | score: [-0.12920142710208893]\n",
      "600 steps | score: [-0.04726535081863403]\n",
      "700 steps | score: [-0.055222973227500916]\n",
      "800 steps | score: [-0.11053197830915451]\n",
      "900 steps | score: [-0.05995720624923706]\n",
      "1000 steps | score: [-0.06170867383480072]\n",
      "1100 steps | score: [-0.08116625249385834]\n",
      "1200 steps | score: [-0.09895654022693634]\n",
      "1300 steps | score: [-0.06159650534391403]\n",
      "1400 steps | score: [-0.05569719523191452]\n",
      "1500 steps | score: [-0.06128475069999695]\n",
      "1600 steps | score: [-0.07753702998161316]\n",
      "1700 steps | score: [-0.07591570913791656]\n",
      "1800 steps | score: [-0.09362519532442093]\n",
      "1900 steps | score: [-0.06403428316116333]\n",
      "2000 steps | score: [-0.08432205021381378]\n",
      "2100 steps | score: [-0.07593301683664322]\n",
      "2200 steps | score: [-0.07034005224704742]\n",
      "2300 steps | score: [-0.052336763590574265]\n",
      "2400 steps | score: [-0.10227149724960327]\n",
      "2500 steps | score: [-0.07419947534799576]\n",
      "0 steps | score: [0.13600142300128937, 0.10309529304504395]\n",
      "100 steps | score: [0.04336324706673622, 0.028936736285686493]\n",
      "200 steps | score: [0.06104595214128494, -0.04597034677863121]\n",
      "300 steps | score: [-0.019598176702857018, 0.06042765825986862]\n",
      "400 steps | score: [0.024191197007894516, 0.008411156013607979]\n",
      "500 steps | score: [-0.020419299602508545, 0.0303341131657362]\n",
      "600 steps | score: [0.043012820184230804, -0.01980515383183956]\n",
      "700 steps | score: [0.03622883930802345, -0.004307059105485678]\n",
      "800 steps | score: [0.013708600774407387, 0.04222355782985687]\n",
      "900 steps | score: [0.09583529829978943, -0.09343297779560089]\n",
      "1000 steps | score: [0.03842344135046005, -0.006170743145048618]\n",
      "1100 steps | score: [0.0003344152064528316, 0.043174006044864655]\n",
      "1200 steps | score: [-0.04713033139705658, 0.07585219293832779]\n",
      "1300 steps | score: [4.505613833316602e-05, 0.036346450448036194]\n",
      "1400 steps | score: [0.02942732721567154, 0.01584814488887787]\n",
      "1500 steps | score: [0.07956315577030182, -0.06701681017875671]\n",
      "1600 steps | score: [0.016465142369270325, 0.013526644557714462]\n",
      "1700 steps | score: [-0.009889530949294567, 0.05382397770881653]\n",
      "1800 steps | score: [0.014232281595468521, 0.005931380670517683]\n",
      "1900 steps | score: [0.04036497697234154, -0.01364535465836525]\n",
      "2000 steps | score: [0.014785626903176308, 0.01517355814576149]\n",
      "2100 steps | score: [0.0032834031153470278, 0.03913559019565582]\n",
      "2200 steps | score: [0.02887832745909691, -0.007560592144727707]\n",
      "2300 steps | score: [0.028351815417408943, 0.001274405512958765]\n",
      "2400 steps | score: [0.003732152283191681, 0.03396414965391159]\n",
      "2500 steps | score: [-0.002987500047311187, 0.02958858385682106]\n",
      "0 steps | score: [0.13182316720485687, 0.14943933486938477]\n",
      "100 steps | score: [0.03658559173345566, 0.06657871603965759]\n",
      "200 steps | score: [0.07548080384731293, -0.018641386181116104]\n",
      "300 steps | score: [-0.028227198868989944, 0.10390260815620422]\n",
      "400 steps | score: [0.022152617573738098, 0.04659261181950569]\n",
      "500 steps | score: [-0.040226951241493225, 0.0837356373667717]\n",
      "600 steps | score: [0.040446002036333084, 0.002646549604833126]\n",
      "700 steps | score: [0.03687872365117073, 0.02647583559155464]\n",
      "800 steps | score: [0.00930709671229124, 0.07112515717744827]\n",
      "900 steps | score: [0.0906415730714798, -0.06135868653655052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 steps | score: [0.04264606162905693, 0.02630797028541565]\n",
      "1100 steps | score: [-0.007474638521671295, 0.09163299947977066]\n",
      "1200 steps | score: [-0.04005550965666771, 0.106145940721035]\n",
      "1300 steps | score: [0.0047035920433700085, 0.061447251588106155]\n",
      "1400 steps | score: [0.02458760514855385, 0.05027679726481438]\n",
      "1500 steps | score: [0.07616138458251953, -0.03141992539167404]\n",
      "1600 steps | score: [0.0057790703140199184, 0.056659676134586334]\n",
      "1700 steps | score: [-0.016934368759393692, 0.08094814419746399]\n",
      "1800 steps | score: [0.020931288599967957, 0.03107673116028309]\n",
      "1900 steps | score: [0.04878559336066246, 0.01329280436038971]\n",
      "2000 steps | score: [0.0005034834030084312, 0.05683356523513794]\n",
      "2100 steps | score: [-0.0013327546184882522, 0.06436735391616821]\n",
      "2200 steps | score: [0.03073851391673088, 0.017424335703253746]\n",
      "2300 steps | score: [0.028377806767821312, 0.03205536678433418]\n",
      "2400 steps | score: [0.00017462203686591238, 0.06912195682525635]\n",
      "2500 steps | score: [-0.0034627765417099, 0.0640021339058876]\n",
      "0 steps | score: [0.07155485451221466, 0.15328365564346313]\n",
      "100 steps | score: [-0.017495399340987206, 0.0770830363035202]\n",
      "200 steps | score: [0.028327856212854385, -0.012014498934149742]\n",
      "300 steps | score: [-0.06941007077693939, 0.10359112918376923]\n",
      "400 steps | score: [-0.021782107651233673, 0.03753817453980446]\n",
      "500 steps | score: [-0.07191962003707886, 0.06519799679517746]\n",
      "600 steps | score: [0.007766740396618843, -0.0017888625152409077]\n",
      "unknown params:  tensor([-0.4757, -0.7061])\n",
      "unknown variance:  tensor([[1.0792]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4275, -0.5885])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.1254342943429947]\n",
      "100 steps | score: [-0.02494511939585209]\n",
      "200 steps | score: [-0.09417642652988434]\n",
      "300 steps | score: [-0.031787239015102386]\n",
      "400 steps | score: [-0.07515835762023926]\n",
      "500 steps | score: [-0.10034755617380142]\n",
      "600 steps | score: [-0.06459171324968338]\n",
      "700 steps | score: [-0.10088670998811722]\n",
      "800 steps | score: [-0.14123138785362244]\n",
      "900 steps | score: [-0.07899235934019089]\n",
      "1000 steps | score: [-0.08854784816503525]\n",
      "1100 steps | score: [-0.11151500046253204]\n",
      "1200 steps | score: [-0.09830553829669952]\n",
      "1300 steps | score: [-0.086321622133255]\n",
      "1400 steps | score: [-0.09382087737321854]\n",
      "1500 steps | score: [-0.08125866204500198]\n",
      "1600 steps | score: [-0.07683518528938293]\n",
      "1700 steps | score: [-0.15153300762176514]\n",
      "1800 steps | score: [-0.08404631167650223]\n",
      "1900 steps | score: [-0.08879837393760681]\n",
      "2000 steps | score: [-0.12943992018699646]\n",
      "2100 steps | score: [-0.09561067819595337]\n",
      "2200 steps | score: [-0.09926284104585648]\n",
      "2300 steps | score: [-0.12220077216625214]\n",
      "2400 steps | score: [-0.08576713502407074]\n",
      "2500 steps | score: [-0.08541657030582428]\n",
      "2600 steps | score: [-0.08638875186443329]\n",
      "0 steps | score: [0.14638462662696838, 0.06850706785917282]\n",
      "100 steps | score: [0.12104247510433197, -0.1058255285024643]\n",
      "200 steps | score: [-0.04011673107743263, 0.02026260457932949]\n",
      "300 steps | score: [0.06769692152738571, -0.037101276218891144]\n",
      "400 steps | score: [0.02365121804177761, -0.012380335479974747]\n",
      "500 steps | score: [-0.0680345892906189, 0.07041915506124496]\n",
      "600 steps | score: [0.03029606118798256, 0.0032052244059741497]\n",
      "700 steps | score: [-0.03687412291765213, 0.0729030892252922]\n",
      "800 steps | score: [-0.06047610566020012, 0.055500440299510956]\n",
      "900 steps | score: [0.018982240930199623, -0.004303929395973682]\n",
      "1000 steps | score: [0.008791769854724407, 0.010920136235654354]\n",
      "1100 steps | score: [-0.05132155492901802, 0.06289797276258469]\n",
      "1200 steps | score: [0.0005558292614296079, 0.017128165811300278]\n",
      "1300 steps | score: [0.04213834926486015, -0.033092886209487915]\n",
      "1400 steps | score: [-0.01908949576318264, 0.02483374811708927]\n",
      "1500 steps | score: [0.0016496339812874794, 0.018386978656053543]\n",
      "1600 steps | score: [0.010362464003264904, 0.013545570895075798]\n",
      "1700 steps | score: [-0.041927944868803024, 0.05255148559808731]\n",
      "1800 steps | score: [0.014186102896928787, -0.010144946165382862]\n",
      "1900 steps | score: [-0.010620483197271824, 0.02507542073726654]\n",
      "2000 steps | score: [-0.008417245000600815, 0.007507689297199249]\n",
      "0 steps | score: [0.05413970723748207, 0.1437438279390335]\n",
      "100 steps | score: [0.02054082229733467, -0.012286893092095852]\n",
      "200 steps | score: [-0.09537765383720398, 0.06502185016870499]\n",
      "300 steps | score: [0.014401930384337902, 0.005244920961558819]\n",
      "400 steps | score: [-0.044292766600847244, 0.0337350033223629]\n",
      "500 steps | score: [-0.1422002911567688, 0.12110009044408798]\n",
      "600 steps | score: [-0.05033800005912781, 0.06066589057445526]\n",
      "700 steps | score: [-0.09813246876001358, 0.11925917118787766]\n",
      "800 steps | score: [-0.13836032152175903, 0.12353639304637909]\n",
      "900 steps | score: [-0.059010572731494904, 0.06887805461883545]\n",
      "1000 steps | score: [-0.05544675886631012, 0.06954696774482727]\n",
      "1100 steps | score: [-0.13506180047988892, 0.12074310332536697]\n",
      "1200 steps | score: [-0.07220426946878433, 0.07513409107923508]\n",
      "1300 steps | score: [-0.03853156790137291, 0.022188596427440643]\n",
      "1400 steps | score: [-0.09684523195028305, 0.08645711839199066]\n",
      "1500 steps | score: [-0.0734810158610344, 0.0635175034403801]\n",
      "1600 steps | score: [-0.068385548889637, 0.07264123111963272]\n",
      "1700 steps | score: [-0.1135970950126648, 0.1059907078742981]\n",
      "1800 steps | score: [-0.05968700349330902, 0.04642299562692642]\n",
      "1900 steps | score: [-0.08468937873840332, 0.0792464166879654]\n",
      "2000 steps | score: [-0.08254211395978928, 0.0612524077296257]\n",
      "2100 steps | score: [-0.05510321632027626, 0.03991670161485672]\n",
      "2200 steps | score: [-0.07437695562839508, 0.06769357621669769]\n",
      "2300 steps | score: [-0.08079659938812256, 0.06540579348802567]\n",
      "2400 steps | score: [-0.0444139689207077, 0.022966738790273666]\n",
      "2500 steps | score: [-0.08186228573322296, 0.08162166178226471]\n",
      "2600 steps | score: [-0.05993407964706421, 0.03979194909334183]\n",
      "0 steps | score: [0.2008398175239563, -0.006375025026500225]\n",
      "100 steps | score: [0.15117713809013367, -0.14328628778457642]\n",
      "200 steps | score: [-0.0458218939602375, 0.012687372975051403]\n",
      "300 steps | score: [0.10749772191047668, -0.08764728158712387]\n",
      "400 steps | score: [0.05671638995409012, -0.06389044970273972]\n",
      "500 steps | score: [-0.04112623259425163, 0.019241904839873314]\n",
      "600 steps | score: [0.05195631459355354, -0.04099474847316742]\n",
      "700 steps | score: [0.004346113186329603, 0.00887691043317318]\n",
      "unknown params:  tensor([-0.4440, -0.7557])\n",
      "unknown variance:  tensor([[0.9890]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4275, -0.5885])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.06838899850845337]\n",
      "100 steps | score: [-0.1234946921467781]\n",
      "200 steps | score: [-0.14315582811832428]\n",
      "300 steps | score: [-0.06964733451604843]\n",
      "400 steps | score: [-0.14322282373905182]\n",
      "500 steps | score: [-0.006271465681493282]\n",
      "0 steps | score: [0.08085598051548004, 0.14219985902309418]\n",
      "100 steps | score: [-0.10635003447532654, 0.22601938247680664]\n",
      "200 steps | score: [-0.04023367911577225, 0.0477953776717186]\n",
      "300 steps | score: [-0.06501231342554092, 0.14295168220996857]\n",
      "400 steps | score: [-0.07532904297113419, 0.1209370344877243]\n",
      "500 steps | score: [-0.011696786619722843, 0.030765395611524582]\n",
      "600 steps | score: [-0.06153302267193794, 0.12630534172058105]\n",
      "700 steps | score: [0.09638968855142593, -0.16515564918518066]\n",
      "800 steps | score: [-0.04033622890710831, 0.08829352259635925]\n",
      "900 steps | score: [-0.03554413095116615, 0.08159516006708145]\n",
      "1000 steps | score: [-0.09313543140888214, 0.1310034692287445]\n",
      "1100 steps | score: [-0.07346734404563904, 0.13637833297252655]\n",
      "1200 steps | score: [-0.0907636433839798, 0.13385476171970367]\n",
      "1300 steps | score: [-0.026987159624695778, 0.039917804300785065]\n",
      "1400 steps | score: [-0.08200820535421371, 0.13555006682872772]\n",
      "1500 steps | score: [0.062466252595186234, -0.10633496940135956]\n",
      "1600 steps | score: [-0.025639640167355537, 0.051344774663448334]\n",
      "1700 steps | score: [-0.033449750393629074, 0.05826032906770706]\n",
      "1800 steps | score: [-0.058885037899017334, 0.08059848099946976]\n",
      "1900 steps | score: [-0.05400045961141586, 0.10087679326534271]\n",
      "2000 steps | score: [-0.06026051193475723, 0.0969083309173584]\n",
      "2100 steps | score: [-0.011276444420218468, 0.014262296259403229]\n",
      "2200 steps | score: [-0.07455595582723618, 0.11600323766469955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300 steps | score: [0.0008957039681263268, -0.0029586274176836014]\n",
      "0 steps | score: [0.06774666160345078, 0.12625399231910706]\n",
      "100 steps | score: [-0.1100359559059143, 0.20183658599853516]\n",
      "200 steps | score: [-0.0500609464943409, 0.01837770640850067]\n",
      "300 steps | score: [-0.10374786704778671, 0.15518133342266083]\n",
      "400 steps | score: [-0.09872203320264816, 0.11688216030597687]\n",
      "500 steps | score: [-0.019401952624320984, -0.00018163397908210754]\n",
      "600 steps | score: [-0.08609554916620255, 0.12359688431024551]\n",
      "700 steps | score: [0.09722534567117691, -0.20044271647930145]\n",
      "800 steps | score: [-0.03839152678847313, 0.05712125450372696]\n",
      "900 steps | score: [-0.06732416152954102, 0.08547656238079071]\n",
      "1000 steps | score: [-0.13097146153450012, 0.14975692331790924]\n",
      "1100 steps | score: [-0.09082235395908356, 0.12388253211975098]\n",
      "1200 steps | score: [-0.10229586809873581, 0.12911736965179443]\n",
      "1300 steps | score: [-0.04759212210774422, 0.042587023228406906]\n",
      "1400 steps | score: [-0.08844968676567078, 0.12495822459459305]\n",
      "1500 steps | score: [0.04054923728108406, -0.11366866528987885]\n",
      "1600 steps | score: [-0.047867681831121445, 0.05023009702563286]\n",
      "1700 steps | score: [-0.0712478831410408, 0.09103938937187195]\n",
      "1800 steps | score: [-0.0824633240699768, 0.08841627836227417]\n",
      "1900 steps | score: [-0.0849040076136589, 0.09823954850435257]\n",
      "2000 steps | score: [-0.094234898686409, 0.10604194551706314]\n",
      "2100 steps | score: [-0.04344334453344345, 0.02400210127234459]\n",
      "2200 steps | score: [-0.0886230617761612, 0.105923593044281]\n",
      "2300 steps | score: [-0.016895044595003128, -0.010141460224986076]\n",
      "2400 steps | score: [-0.04685243219137192, 0.04112258180975914]\n",
      "2500 steps | score: [-0.06401386857032776, 0.07340799272060394]\n",
      "2600 steps | score: [-0.05753084272146225, 0.04896799847483635]\n",
      "0 steps | score: [0.1774097979068756, 0.010942093096673489]\n",
      "100 steps | score: [-0.03695691004395485, 0.13004857301712036]\n",
      "200 steps | score: [0.016051653772592545, -0.04036584496498108]\n",
      "300 steps | score: [-0.012591024860739708, 0.05872336030006409]\n",
      "400 steps | score: [-0.0020111806225031614, 0.01107364147901535]\n",
      "500 steps | score: [0.06706292182207108, -0.08503110706806183]\n",
      "600 steps | score: [-0.009458048269152641, 0.04438648745417595]\n",
      "700 steps | score: [0.16343046724796295, -0.2587730586528778]\n",
      "800 steps | score: [0.02274717576801777, 0.002954743802547455]\n",
      "900 steps | score: [0.02436692640185356, -0.00023620761930942535]\n",
      "1000 steps | score: [-0.031627070158720016, 0.05158156529068947]\n",
      "1100 steps | score: [0.004114245995879173, 0.017074283212423325]\n",
      "1200 steps | score: [-0.02038898877799511, 0.05005559325218201]\n",
      "1300 steps | score: [0.020829414948821068, -0.016195228323340416]\n",
      "1400 steps | score: [-0.01152642909437418, 0.036276139318943024]\n",
      "1500 steps | score: [0.13593068718910217, -0.20095320045948029]\n",
      "1600 steps | score: [0.02249816805124283, -0.019919395446777344]\n",
      "1700 steps | score: [0.007862643338739872, 0.004598709754645824]\n",
      "unknown params:  tensor([-0.4864, -0.8738])\n",
      "unknown variance:  tensor([[1.0934]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4275, -0.5885])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.21900975704193115]\n",
      "100 steps | score: [-0.01654457114636898]\n",
      "200 steps | score: [0.12818095088005066]\n",
      "300 steps | score: [0.015803609043359756]\n",
      "400 steps | score: [0.03661847114562988]\n",
      "500 steps | score: [0.06951098144054413]\n",
      "600 steps | score: [-0.040825895965099335]\n",
      "700 steps | score: [0.019532807171344757]\n",
      "800 steps | score: [0.04794245958328247]\n",
      "900 steps | score: [0.01455349288880825]\n",
      "1000 steps | score: [0.02457997016608715]\n",
      "1100 steps | score: [0.005469638854265213]\n",
      "0 steps | score: [0.2436964362859726, -0.06921614706516266]\n",
      "100 steps | score: [-0.007058272138237953, 0.15311989188194275]\n",
      "200 steps | score: [0.03951628506183624, -0.003621011506766081]\n",
      "300 steps | score: [0.048745207488536835, 0.0024866703897714615]\n",
      "400 steps | score: [-0.008761382661759853, 0.05573417618870735]\n",
      "500 steps | score: [0.1266605406999588, -0.13494984805583954]\n",
      "600 steps | score: [-0.0037986603565514088, 0.06440164148807526]\n",
      "700 steps | score: [-0.033491168171167374, 0.09082912653684616]\n",
      "800 steps | score: [0.05297768861055374, -0.006373652257025242]\n",
      "900 steps | score: [0.029964452609419823, -0.0030294526368379593]\n",
      "1000 steps | score: [0.07255274057388306, -0.05964532867074013]\n",
      "1100 steps | score: [0.0864868313074112, -0.09769577533006668]\n",
      "1200 steps | score: [0.014562058262526989, 0.0444939061999321]\n",
      "1300 steps | score: [0.005284707061946392, 0.05879165977239609]\n",
      "1400 steps | score: [0.2123662531375885, -0.3305901288986206]\n",
      "1500 steps | score: [0.027573706582188606, 0.01113465242087841]\n",
      "1600 steps | score: [0.08444330096244812, -0.09132107347249985]\n",
      "1700 steps | score: [0.07760657370090485, -0.06285736709833145]\n",
      "1800 steps | score: [0.0409059152007103, -0.008678708225488663]\n",
      "1900 steps | score: [0.047720398753881454, -0.031139474362134933]\n",
      "2000 steps | score: [0.04151865467429161, -0.020339645445346832]\n",
      "2100 steps | score: [0.047387078404426575, -0.02685396373271942]\n",
      "2200 steps | score: [0.08554740995168686, -0.08569261431694031]\n",
      "2300 steps | score: [0.06182766705751419, -0.06107724457979202]\n",
      "2400 steps | score: [0.04509522765874863, -0.02360786870121956]\n",
      "2500 steps | score: [0.040814392268657684, -0.0010684877634048462]\n",
      "2600 steps | score: [0.11781792342662811, -0.14423350989818573]\n",
      "0 steps | score: [0.1530749350786209, -0.0047053685411810875]\n",
      "100 steps | score: [-0.10066038370132446, 0.22283852100372314]\n",
      "200 steps | score: [0.02666047029197216, -0.053178660571575165]\n",
      "300 steps | score: [-0.01582350954413414, 0.018379898741841316]\n",
      "400 steps | score: [-0.08638139069080353, 0.10236028581857681]\n",
      "500 steps | score: [0.0564754381775856, -0.09972843527793884]\n",
      "600 steps | score: [-0.0829753652215004, 0.12930838763713837]\n",
      "700 steps | score: [-0.11404173076152802, 0.15879572927951813]\n",
      "800 steps | score: [-0.03636600822210312, 0.05751143768429756]\n",
      "900 steps | score: [-0.029775168746709824, 0.01502606924623251]\n",
      "1000 steps | score: [0.010807422921061516, -0.030319292098283768]\n",
      "1100 steps | score: [0.028896015137434006, -0.08655843883752823]\n",
      "1200 steps | score: [-0.039725612848997116, 0.06217556446790695]\n",
      "1300 steps | score: [-0.0640014037489891, 0.09563013911247253]\n",
      "1400 steps | score: [0.12275408953428268, -0.2543617784976959]\n",
      "1500 steps | score: [-0.03580382838845253, 0.03924325481057167]\n",
      "1600 steps | score: [0.022343890741467476, -0.06589137017726898]\n",
      "1700 steps | score: [0.003377696732059121, -0.01874241605401039]\n",
      "1800 steps | score: [-0.0405779704451561, 0.04083247482776642]\n",
      "1900 steps | score: [-0.033096324652433395, 0.023545773699879646]\n",
      "2000 steps | score: [-0.019244592636823654, 0.011430840007960796]\n",
      "2100 steps | score: [-0.021766534075140953, 0.006940808147192001]\n",
      "2200 steps | score: [0.000792318198364228, -0.022899018600583076]\n",
      "2300 steps | score: [0.0046189031563699245, -0.04172177612781525]\n",
      "2400 steps | score: [-0.012418203987181187, 0.008169900625944138]\n",
      "2500 steps | score: [-0.039335962384939194, 0.04838420823216438]\n",
      "2600 steps | score: [0.04604412987828255, -0.11054673790931702]\n",
      "0 steps | score: [0.17151226103305817, -0.00961906835436821]\n",
      "100 steps | score: [-0.08003830909729004, 0.21690742671489716]\n",
      "200 steps | score: [0.04445922374725342, -0.05402549356222153]\n",
      "300 steps | score: [-0.012220383621752262, 0.0483241006731987]\n",
      "400 steps | score: [-0.07791644334793091, 0.11462251842021942]\n",
      "500 steps | score: [0.06693509966135025, -0.08782296627759933]\n",
      "600 steps | score: [-0.05489861220121384, 0.10508357733488083]\n",
      "700 steps | score: [-0.10513366013765335, 0.1574501097202301]\n",
      "800 steps | score: [-0.0077756973914802074, 0.02494167909026146]\n",
      "900 steps | score: [-0.03212600573897362, 0.04196471720933914]\n",
      "1000 steps | score: [0.03277033194899559, -0.04183146357536316]\n",
      "1100 steps | score: [0.009301393292844296, -0.019654110074043274]\n",
      "1200 steps | score: [-0.03798958659172058, 0.07469692081212997]\n",
      "1300 steps | score: [-0.057736411690711975, 0.10008598119020462]\n",
      "1400 steps | score: [0.14985622465610504, -0.2640535533428192]\n",
      "1500 steps | score: [-0.026266073808073997, 0.04320467635989189]\n",
      "1600 steps | score: [0.012455479241907597, -0.03649535030126572]\n",
      "1700 steps | score: [-0.005887203849852085, -0.004798196256160736]\n",
      "unknown params:  tensor([-0.5247, -1.1002])\n",
      "unknown variance:  tensor([[1.2206]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4275, -0.5885])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.22221164405345917]\n",
      "100 steps | score: [-0.027422163635492325]\n",
      "200 steps | score: [-0.017276255413889885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 steps | score: [-0.03250788897275925]\n",
      "400 steps | score: [-0.026205265894532204]\n",
      "500 steps | score: [-0.03202125057578087]\n",
      "600 steps | score: [0.028890008106827736]\n",
      "700 steps | score: [0.006942159030586481]\n",
      "0 steps | score: [0.1965205818414688, -0.04317520931363106]\n",
      "100 steps | score: [0.040697935968637466, 0.08518513292074203]\n",
      "200 steps | score: [-0.07241956144571304, 0.22134141623973846]\n",
      "300 steps | score: [-0.10684455186128616, 0.2548549771308899]\n",
      "400 steps | score: [-0.12497606873512268, 0.2733173966407776]\n",
      "500 steps | score: [-0.10535671561956406, 0.24705776572227478]\n",
      "600 steps | score: [0.007809856440871954, 0.026866616681218147]\n",
      "700 steps | score: [0.10593731701374054, -0.13365834951400757]\n",
      "800 steps | score: [0.312423437833786, -0.6119058132171631]\n",
      "900 steps | score: [-0.0280868299305439, 0.10428005456924438]\n",
      "1000 steps | score: [-0.08573494851589203, 0.19421318173408508]\n",
      "1100 steps | score: [0.07690942287445068, -0.09822279214859009]\n",
      "1200 steps | score: [0.030765967443585396, -0.019926954060792923]\n",
      "1300 steps | score: [-0.03962765634059906, 0.11871333420276642]\n",
      "1400 steps | score: [0.03698242828249931, -0.029627032577991486]\n",
      "1500 steps | score: [0.008470623753964901, 0.03208031505346298]\n",
      "1600 steps | score: [0.09607237577438354, -0.14388054609298706]\n",
      "1700 steps | score: [-0.02066846378147602, 0.0844777524471283]\n",
      "1800 steps | score: [-0.0015325016574934125, 0.04364998638629913]\n",
      "1900 steps | score: [-0.03841039165854454, 0.11257913708686829]\n",
      "2000 steps | score: [-0.05548718199133873, 0.14671461284160614]\n",
      "2100 steps | score: [0.036399200558662415, -0.014803539961576462]\n",
      "2200 steps | score: [-0.012523657642304897, 0.07479877024888992]\n",
      "2300 steps | score: [0.06969361752271652, -0.09293186664581299]\n",
      "2400 steps | score: [-0.012697769328951836, 0.06412323564291]\n",
      "2500 steps | score: [0.04661407321691513, -0.043361254036426544]\n",
      "unknown params:  tensor([-0.4809, -1.0570])\n",
      "unknown variance:  tensor([[1.2786]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4275, -0.5885])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.32944273948669434]\n",
      "100 steps | score: [0.10605617612600327]\n",
      "200 steps | score: [0.0617404542863369]\n",
      "300 steps | score: [0.13081425428390503]\n",
      "400 steps | score: [0.05243310332298279]\n",
      "500 steps | score: [0.02475001849234104]\n",
      "600 steps | score: [0.012901431880891323]\n",
      "700 steps | score: [0.05664785951375961]\n",
      "800 steps | score: [0.04154723882675171]\n",
      "900 steps | score: [0.09180417656898499]\n",
      "1000 steps | score: [0.02321242168545723]\n",
      "1100 steps | score: [0.036159664392471313]\n",
      "1200 steps | score: [0.0017691673710942268]\n",
      "0 steps | score: [0.33260056376457214, -0.40097522735595703]\n",
      "100 steps | score: [0.3613949120044708, -0.5797834992408752]\n",
      "200 steps | score: [0.2779105007648468, -0.45411020517349243]\n",
      "300 steps | score: [0.8630911111831665, -2.0398900508880615]\n",
      "400 steps | score: [0.04633019119501114, -0.037279073148965836]\n",
      "500 steps | score: [-0.06168945133686066, 0.13426733016967773]\n",
      "600 steps | score: [0.03611622750759125, -0.04128454998135567]\n",
      "700 steps | score: [0.19379524886608124, -0.3758449852466583]\n",
      "800 steps | score: [0.0868716835975647, -0.13764891028404236]\n",
      "900 steps | score: [0.13659892976284027, -0.25496038794517517]\n",
      "1000 steps | score: [0.05960015952587128, -0.09668135643005371]\n",
      "1100 steps | score: [0.015150939114391804, -0.015513256192207336]\n",
      "1200 steps | score: [0.11148661375045776, -0.20661427080631256]\n",
      "1300 steps | score: [0.06161774322390556, -0.10207530856132507]\n",
      "1400 steps | score: [0.19303034245967865, -0.37919312715530396]\n",
      "1500 steps | score: [0.14445480704307556, -0.2669542729854584]\n",
      "1600 steps | score: [0.19256886839866638, -0.38725876808166504]\n",
      "1700 steps | score: [0.08460954576730728, -0.1647418588399887]\n",
      "1800 steps | score: [0.11157573014497757, -0.21187712252140045]\n",
      "1900 steps | score: [0.07481949776411057, -0.13759127259254456]\n",
      "2000 steps | score: [0.26586320996284485, -0.5456799268722534]\n",
      "2100 steps | score: [0.08064980059862137, -0.15609174966812134]\n",
      "2200 steps | score: [0.12730072438716888, -0.2590239942073822]\n",
      "2300 steps | score: [0.05964500829577446, -0.10867468267679214]\n",
      "2400 steps | score: [0.08780448138713837, -0.1601637750864029]\n",
      "2500 steps | score: [0.11846521496772766, -0.22568346560001373]\n",
      "0 steps | score: [0.15668568015098572, -0.09569204598665237]\n",
      "100 steps | score: [0.2509201169013977, -0.41563189029693604]\n",
      "200 steps | score: [0.11257694661617279, -0.18447045981884003]\n",
      "300 steps | score: [0.7920694351196289, -2.0432357788085938]\n",
      "400 steps | score: [-0.11365865170955658, 0.22814355790615082]\n",
      "500 steps | score: [-0.196543350815773, 0.35993117094039917]\n",
      "600 steps | score: [-0.10693414509296417, 0.20162108540534973]\n",
      "700 steps | score: [0.02832959219813347, -0.09180434793233871]\n",
      "800 steps | score: [-0.06461012363433838, 0.10865120589733124]\n",
      "900 steps | score: [-0.010545885190367699, -0.015751566737890244]\n",
      "1000 steps | score: [-0.08953127264976501, 0.15193317830562592]\n",
      "1100 steps | score: [-0.09299144148826599, 0.16775740683078766]\n",
      "1200 steps | score: [-0.006727748084813356, 0.0010372400283813477]\n",
      "0 steps | score: [0.12684275209903717, 0.06002411991357803]\n",
      "100 steps | score: [0.20180131494998932, -0.21208488941192627]\n",
      "200 steps | score: [0.062368325889110565, 0.022577747702598572]\n",
      "300 steps | score: [0.6552452445030212, -1.528912901878357]\n",
      "400 steps | score: [-0.12563224136829376, 0.349372923374176]\n",
      "500 steps | score: [-0.21902994811534882, 0.4969453513622284]\n",
      "600 steps | score: [-0.1408916711807251, 0.3650764226913452]\n",
      "700 steps | score: [0.020507950335741043, 0.016194559633731842]\n",
      "800 steps | score: [-0.05991443619132042, 0.20741859078407288]\n",
      "900 steps | score: [-0.015155239962041378, 0.10102438926696777]\n",
      "1000 steps | score: [-0.09307779371738434, 0.26247626543045044]\n",
      "1100 steps | score: [-0.13117489218711853, 0.33494967222213745]\n",
      "1200 steps | score: [-0.02740570530295372, 0.12512262165546417]\n",
      "1300 steps | score: [-0.06188947334885597, 0.19346527755260468]\n",
      "1400 steps | score: [0.03009123168885708, -0.0032743513584136963]\n",
      "1500 steps | score: [-0.024187596514821053, 0.10671786963939667]\n",
      "1600 steps | score: [0.041468627750873566, -0.01922014355659485]\n",
      "1700 steps | score: [-0.049607012420892715, 0.17125347256660461]\n",
      "1800 steps | score: [-0.02506622113287449, 0.12221488356590271]\n",
      "1900 steps | score: [-0.08784749358892441, 0.2498069554567337]\n",
      "2000 steps | score: [0.07748347520828247, -0.10829516500234604]\n",
      "2100 steps | score: [-0.08818136155605316, 0.23891746997833252]\n",
      "2200 steps | score: [-0.001603318378329277, 0.07369602471590042]\n",
      "2300 steps | score: [-0.10024938732385635, 0.26997461915016174]\n",
      "2400 steps | score: [-0.08029379695653915, 0.22856184840202332]\n",
      "2500 steps | score: [-0.060531917959451675, 0.1854957789182663]\n",
      "unknown params:  tensor([-0.4130, -0.8002])\n",
      "unknown variance:  tensor([[1.3109]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/b385e913-2229-4a83-8a77-a9e3a68b280c\n",
      "gt params:  tensor([-0.4244, -0.5603])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.08902405202388763]\n",
      "100 steps | score: [0.07106372714042664]\n",
      "200 steps | score: [-0.07310192286968231]\n",
      "300 steps | score: [-0.013164643198251724]\n",
      "400 steps | score: [-0.08101135492324829]\n",
      "500 steps | score: [-0.01264178566634655]\n",
      "600 steps | score: [-0.01440507359802723]\n",
      "700 steps | score: [0.0016496200114488602]\n",
      "0 steps | score: [0.028436461463570595, 0.017213068902492523]\n",
      "100 steps | score: [0.058595649898052216, -0.03165040165185928]\n",
      "200 steps | score: [-0.0259881429374218, 0.012183988466858864]\n",
      "300 steps | score: [0.007643598131835461, -0.036164022982120514]\n",
      "400 steps | score: [-0.05078023672103882, -0.003750748001039028]\n",
      "500 steps | score: [0.019069388508796692, -0.07259037345647812]\n",
      "600 steps | score: [0.008615033701062202, -0.039645273238420486]\n",
      "700 steps | score: [0.011897708289325237, -0.03893640637397766]\n",
      "800 steps | score: [-0.028430191799998283, -0.013197707012295723]\n",
      "900 steps | score: [-0.031229328364133835, -0.03195634484291077]\n",
      "1000 steps | score: [0.03778959810733795, -0.03454655036330223]\n",
      "1100 steps | score: [-0.005619589705020189, -0.004010397009551525]\n",
      "0 steps | score: [0.06285247951745987, 0.04987078160047531]\n",
      "100 steps | score: [0.08582878857851028, -0.01056679431349039]\n",
      "200 steps | score: [-0.006337960250675678, 0.04469999670982361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 steps | score: [0.051709163933992386, -0.007680105976760387]\n",
      "400 steps | score: [-0.01311760675162077, 0.025646649301052094]\n",
      "500 steps | score: [0.051300156861543655, -0.04021099582314491]\n",
      "600 steps | score: [0.0412612222135067, -0.0162113755941391]\n",
      "700 steps | score: [0.04568230360746384, -0.01305769570171833]\n",
      "800 steps | score: [0.007520158309489489, 0.023475421592593193]\n",
      "900 steps | score: [-0.0001829677348723635, -0.0038872379809617996]\n",
      "0 steps | score: [0.03467293456196785, 0.015699071809649467]\n",
      "100 steps | score: [0.06856177747249603, -0.02453337237238884]\n",
      "200 steps | score: [-0.017819274216890335, 0.0067909350618720055]\n",
      "300 steps | score: [0.020962249487638474, -0.03555295988917351]\n",
      "400 steps | score: [-0.034561511129140854, -0.009440814144909382]\n",
      "500 steps | score: [0.019377006217837334, -0.06945046782493591]\n",
      "600 steps | score: [0.022650649771094322, -0.04406506568193436]\n",
      "700 steps | score: [0.01510069239884615, -0.039415303617715836]\n",
      "800 steps | score: [-0.024997686967253685, -0.007963510230183601]\n",
      "900 steps | score: [-0.02274201437830925, -0.036225493997335434]\n",
      "1000 steps | score: [0.04327445849776268, -0.027124956250190735]\n",
      "1100 steps | score: [-0.00015217361215036362, -0.004423364996910095]\n",
      "unknown params:  tensor([-0.3786, -0.4518])\n",
      "unknown variance:  tensor([[0.8403]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4244, -0.5603])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [-0.22386379539966583]\n",
      "100 steps | score: [-0.353721022605896]\n",
      "200 steps | score: [-0.33422619104385376]\n",
      "300 steps | score: [-0.3287055194377899]\n",
      "400 steps | score: [-0.3430703282356262]\n",
      "500 steps | score: [-0.3342951834201813]\n",
      "600 steps | score: [-0.3207199275493622]\n",
      "700 steps | score: [-0.35281625390052795]\n",
      "800 steps | score: [-0.3474135994911194]\n",
      "900 steps | score: [-0.31080174446105957]\n",
      "1000 steps | score: [-0.3601885437965393]\n",
      "1100 steps | score: [-0.2992924153804779]\n",
      "1200 steps | score: [-0.32531726360321045]\n",
      "1300 steps | score: [-0.2966230809688568]\n",
      "1400 steps | score: [-0.31908708810806274]\n",
      "1500 steps | score: [-0.3046737015247345]\n",
      "1600 steps | score: [-0.35133540630340576]\n",
      "1700 steps | score: [-0.30562666058540344]\n",
      "1800 steps | score: [-0.33239442110061646]\n",
      "1900 steps | score: [-0.29629167914390564]\n",
      "2000 steps | score: [-0.30771002173423767]\n",
      "2100 steps | score: [-0.30238568782806396]\n",
      "2200 steps | score: [-0.33610767126083374]\n",
      "2300 steps | score: [-0.29441002011299133]\n",
      "2400 steps | score: [-0.33718758821487427]\n",
      "2500 steps | score: [-0.3402710258960724]\n",
      "2600 steps | score: [-0.3176448345184326]\n",
      "2700 steps | score: [-0.3153133988380432]\n",
      "2800 steps | score: [-0.2975151836872101]\n",
      "0 steps | score: [0.0635920986533165, 0.08885849267244339]\n",
      "100 steps | score: [-0.030088193714618683, 0.04166817665100098]\n",
      "200 steps | score: [-0.008016349747776985, -0.02768697589635849]\n",
      "300 steps | score: [-0.018275363370776176, -0.008954864926636219]\n",
      "400 steps | score: [-0.020984545350074768, 0.022279638797044754]\n",
      "500 steps | score: [0.00013287828187458217, 0.026742173358798027]\n",
      "600 steps | score: [-0.00605553574860096, -0.004181948956102133]\n",
      "0 steps | score: [0.05353584140539169, 0.06112712621688843]\n",
      "100 steps | score: [-0.034371308982372284, 0.015891866758465767]\n",
      "200 steps | score: [-0.026675153523683548, -0.03605618327856064]\n",
      "300 steps | score: [-0.028106430545449257, -0.02773769199848175]\n",
      "400 steps | score: [-0.013124971650540829, 0.002025409135967493]\n",
      "500 steps | score: [-0.012131782248616219, 0.005525810644030571]\n",
      "600 steps | score: [-0.022717144340276718, -0.03129827603697777]\n",
      "700 steps | score: [-0.026447845622897148, -0.02737455442547798]\n",
      "800 steps | score: [-0.026823634281754494, -0.005976580083370209]\n",
      "900 steps | score: [-0.0065050795674324036, -0.008798951283097267]\n",
      "unknown params:  tensor([-0.3975, -0.4809])\n",
      "unknown variance:  tensor([[0.9245]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4244, -0.5603])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.32220324873924255]\n",
      "100 steps | score: [0.11961108446121216]\n",
      "200 steps | score: [0.11014790832996368]\n",
      "300 steps | score: [0.05071307718753815]\n",
      "400 steps | score: [0.23912504315376282]\n",
      "500 steps | score: [0.15514583885669708]\n",
      "600 steps | score: [0.2159094661474228]\n",
      "700 steps | score: [0.12790587544441223]\n",
      "800 steps | score: [0.17480841279029846]\n",
      "900 steps | score: [0.1625634729862213]\n",
      "1000 steps | score: [0.21270546317100525]\n",
      "1100 steps | score: [0.09750401228666306]\n",
      "1200 steps | score: [0.21120867133140564]\n",
      "1300 steps | score: [0.12037494778633118]\n",
      "1400 steps | score: [0.14728191494941711]\n",
      "1500 steps | score: [0.13779687881469727]\n",
      "1600 steps | score: [0.17012324929237366]\n",
      "1700 steps | score: [0.11293523758649826]\n",
      "1800 steps | score: [0.14764848351478577]\n",
      "1900 steps | score: [0.12899352610111237]\n",
      "2000 steps | score: [0.13655638694763184]\n",
      "2100 steps | score: [0.1455601453781128]\n",
      "2200 steps | score: [0.1482745110988617]\n",
      "2300 steps | score: [0.17056819796562195]\n",
      "2400 steps | score: [0.1593136489391327]\n",
      "2500 steps | score: [0.14718574285507202]\n",
      "2600 steps | score: [0.16378279030323029]\n",
      "0 steps | score: [0.03133084252476692, 0.1078609749674797]\n",
      "100 steps | score: [-0.095982126891613, 0.077837273478508]\n",
      "200 steps | score: [-0.07302301377058029, -0.005462132394313812]\n",
      "300 steps | score: [-0.10550040751695633, 0.04613041877746582]\n",
      "400 steps | score: [0.09538569301366806, -0.16460096836090088]\n",
      "500 steps | score: [-0.05987641215324402, 0.055404141545295715]\n",
      "600 steps | score: [0.020702779293060303, -0.02977989800274372]\n",
      "700 steps | score: [-0.059819433838129044, 0.014982672408223152]\n",
      "800 steps | score: [-0.02888811007142067, -0.020849384367465973]\n",
      "900 steps | score: [-0.02919544279575348, 0.024482453241944313]\n",
      "1000 steps | score: [0.0055365185253322124, -0.01755998656153679]\n",
      "1100 steps | score: [-0.0935462936758995, 0.04584130644798279]\n",
      "1200 steps | score: [0.022968096658587456, -0.027275148779153824]\n",
      "1300 steps | score: [-0.06884488463401794, 0.056676559150218964]\n",
      "1400 steps | score: [-0.045472048223018646, 0.02199562080204487]\n",
      "1500 steps | score: [-0.04227827489376068, 0.006143219769001007]\n",
      "1600 steps | score: [-0.011717691086232662, -0.010793367400765419]\n",
      "1700 steps | score: [-0.05077848583459854, 0.016174988821148872]\n",
      "1800 steps | score: [-0.048145245760679245, 0.018301913514733315]\n",
      "1900 steps | score: [-0.03986639156937599, 0.007418184541165829]\n",
      "2000 steps | score: [-0.037360504269599915, 0.007926817052066326]\n",
      "2100 steps | score: [-0.0381612703204155, 0.011559830978512764]\n",
      "2200 steps | score: [-0.041203904896974564, 0.010804267600178719]\n",
      "2300 steps | score: [-0.02123935893177986, -0.01758129708468914]\n",
      "2400 steps | score: [-0.040779564529657364, 0.008072730153799057]\n",
      "2500 steps | score: [-0.02256433665752411, -0.007456675171852112]\n",
      "2600 steps | score: [-0.04970625787973404, 0.015075207687914371]\n",
      "unknown params:  tensor([-0.4043, -0.4882])\n",
      "unknown variance:  tensor([[0.9210]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4244, -0.5603])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.17593717575073242]\n",
      "100 steps | score: [0.06918665766716003]\n",
      "200 steps | score: [0.06613918393850327]\n",
      "300 steps | score: [0.01899246871471405]\n",
      "400 steps | score: [0.08947199583053589]\n",
      "500 steps | score: [-0.011329226195812225]\n",
      "600 steps | score: [-0.0011509358882904053]\n",
      "0 steps | score: [0.12421293556690216, 0.06524451076984406]\n",
      "100 steps | score: [0.021675316616892815, 0.009165204130113125]\n",
      "200 steps | score: [0.027162736281752586, -0.019533909857273102]\n",
      "300 steps | score: [0.0035406264942139387, -0.013035668060183525]\n",
      "400 steps | score: [0.03733295947313309, -0.038841038942337036]\n",
      "500 steps | score: [-0.03466476500034332, 0.039237432181835175]\n",
      "600 steps | score: [-0.011906552128493786, 0.0012023432645946741]\n",
      "700 steps | score: [0.05585111305117607, -0.0595221221446991]\n",
      "800 steps | score: [-0.011964973993599415, 0.012994120828807354]\n",
      "900 steps | score: [0.051559753715991974, -0.04566875845193863]\n",
      "1000 steps | score: [-0.010833836160600185, 0.013274070806801319]\n",
      "1100 steps | score: [0.031804159283638, -0.04824816808104515]\n",
      "1200 steps | score: [-0.020241456106305122, 0.02860296331346035]\n",
      "1300 steps | score: [0.009799391031265259, -0.002329631708562374]\n",
      "0 steps | score: [0.1141638308763504, 0.050979793071746826]\n",
      "100 steps | score: [0.028970470651984215, -0.01759270578622818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [0.02833046205341816, -0.036410141736269]\n",
      "300 steps | score: [-0.008113857358694077, -0.02132875844836235]\n",
      "400 steps | score: [0.03191085159778595, -0.05478446185588837]\n",
      "500 steps | score: [-0.027220262214541435, 0.01908205822110176]\n",
      "600 steps | score: [-0.032986972481012344, 0.0019464027136564255]\n",
      "700 steps | score: [0.045894213020801544, -0.06313373893499374]\n",
      "800 steps | score: [-0.019829893484711647, -0.0041079409420490265]\n",
      "900 steps | score: [0.047038715332746506, -0.06694676727056503]\n",
      "1000 steps | score: [-0.014652424491941929, -0.004136070609092712]\n",
      "1100 steps | score: [0.03141668438911438, -0.07521453499794006]\n",
      "1200 steps | score: [-0.021222572773694992, 0.005314035341143608]\n",
      "1300 steps | score: [0.003446022979915142, -0.022866174578666687]\n",
      "1400 steps | score: [0.0189854484051466, -0.03973778337240219]\n",
      "1500 steps | score: [0.002970602596178651, -0.03341418504714966]\n",
      "1600 steps | score: [0.012892885133624077, -0.034785933792591095]\n",
      "1700 steps | score: [0.01099521853029728, -0.034365855157375336]\n",
      "1800 steps | score: [0.036418791860342026, -0.0735400840640068]\n",
      "1900 steps | score: [0.008360635489225388, -0.02840425819158554]\n",
      "2000 steps | score: [0.038620445877313614, -0.056025803089141846]\n",
      "2100 steps | score: [0.00573457358404994, -0.028563713654875755]\n",
      "2200 steps | score: [0.03246548771858215, -0.061366818845272064]\n",
      "2300 steps | score: [0.007018290925770998, -0.03503815084695816]\n",
      "2400 steps | score: [0.02201860584318638, -0.049469735473394394]\n",
      "2500 steps | score: [0.02498561330139637, -0.052293501794338226]\n",
      "2600 steps | score: [0.019581621512770653, -0.042688895016908646]\n",
      "2700 steps | score: [0.028440827503800392, -0.05635178089141846]\n",
      "2800 steps | score: [0.017608046531677246, -0.04608504846692085]\n",
      "unknown params:  tensor([-0.4094, -0.5295])\n",
      "unknown variance:  tensor([[0.9489]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4244, -0.5603])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2679668068885803]\n",
      "100 steps | score: [0.12229393422603607]\n",
      "200 steps | score: [0.22467699646949768]\n",
      "300 steps | score: [0.013913359493017197]\n",
      "400 steps | score: [0.15596646070480347]\n",
      "500 steps | score: [0.12644541263580322]\n",
      "600 steps | score: [0.05859634280204773]\n",
      "700 steps | score: [0.12216197699308395]\n",
      "800 steps | score: [0.06261875480413437]\n",
      "900 steps | score: [0.11965827643871307]\n",
      "1000 steps | score: [0.1319943517446518]\n",
      "1100 steps | score: [0.09022006392478943]\n",
      "1200 steps | score: [0.08958760648965836]\n",
      "1300 steps | score: [0.07909125834703445]\n",
      "1400 steps | score: [0.10395286977291107]\n",
      "1500 steps | score: [0.10497085750102997]\n",
      "1600 steps | score: [0.0747789740562439]\n",
      "1700 steps | score: [0.11674810945987701]\n",
      "1800 steps | score: [0.10365406423807144]\n",
      "1900 steps | score: [0.1011790931224823]\n",
      "2000 steps | score: [0.11400522291660309]\n",
      "2100 steps | score: [0.06791409850120544]\n",
      "2200 steps | score: [0.11122500896453857]\n",
      "2300 steps | score: [0.11137028783559799]\n",
      "2400 steps | score: [0.09779062867164612]\n",
      "2500 steps | score: [0.0865766629576683]\n",
      "0 steps | score: [0.11645803600549698, 0.033710263669490814]\n",
      "100 steps | score: [-0.0491887666285038, 0.047641411423683167]\n",
      "200 steps | score: [0.22326093912124634, -0.3522145450115204]\n",
      "300 steps | score: [-0.11869045346975327, 0.0697879046201706]\n",
      "400 steps | score: [0.056729722768068314, -0.11744780838489532]\n",
      "500 steps | score: [0.06254375725984573, -0.11079219728708267]\n",
      "600 steps | score: [-0.022247767075896263, -0.013236377388238907]\n",
      "700 steps | score: [0.07200609147548676, -0.14793965220451355]\n",
      "800 steps | score: [-0.04745367914438248, 0.009611132554709911]\n",
      "900 steps | score: [-0.012310456484556198, -0.012270865961909294]\n",
      "1000 steps | score: [0.05865652486681938, -0.13337109982967377]\n",
      "1100 steps | score: [-0.046810977160930634, 0.01238127052783966]\n",
      "1200 steps | score: [-0.025331363081932068, -0.010873587802052498]\n",
      "1300 steps | score: [-0.01052165124565363, -0.03560443967580795]\n",
      "1400 steps | score: [-0.03679553046822548, 0.0017093466594815254]\n",
      "1500 steps | score: [0.024592813104391098, -0.07425040006637573]\n",
      "1600 steps | score: [-0.020477088168263435, -0.025066694244742393]\n",
      "1700 steps | score: [-0.017234167084097862, -0.025173189118504524]\n",
      "1800 steps | score: [-0.006104776635766029, -0.036177512258291245]\n",
      "1900 steps | score: [-0.02204287424683571, -0.017018046230077744]\n",
      "2000 steps | score: [0.010051419027149677, -0.05757046490907669]\n",
      "2100 steps | score: [-0.018795808777213097, -0.02788449265062809]\n",
      "2200 steps | score: [0.0022870399989187717, -0.04886385798454285]\n",
      "2300 steps | score: [0.01084822230041027, -0.062373753637075424]\n",
      "2400 steps | score: [-0.01528309378772974, -0.03209393844008446]\n",
      "2500 steps | score: [-0.005275656469166279, -0.041111551225185394]\n",
      "0 steps | score: [0.0935852900147438, 0.08298376947641373]\n",
      "100 steps | score: [-0.03628883883357048, 0.06270471960306168]\n",
      "200 steps | score: [0.20277884602546692, -0.3020886778831482]\n",
      "300 steps | score: [-0.13607974350452423, 0.10086208581924438]\n",
      "400 steps | score: [0.05158615857362747, -0.10193983465433121]\n",
      "500 steps | score: [0.03396423161029816, -0.08009778708219528]\n",
      "600 steps | score: [-0.05122654512524605, 0.024764250963926315]\n",
      "700 steps | score: [0.05792215093970299, -0.11097659915685654]\n",
      "800 steps | score: [-0.04722480848431587, 0.037821315228939056]\n",
      "900 steps | score: [-0.028455566614866257, 0.018263820558786392]\n",
      "1000 steps | score: [0.035911910235881805, -0.09354688972234726]\n",
      "1100 steps | score: [-0.06367897987365723, 0.04844566807150841]\n",
      "1200 steps | score: [-0.0398525670170784, 0.023885123431682587]\n",
      "1300 steps | score: [-0.03029762953519821, 0.0017761411145329475]\n",
      "1400 steps | score: [-0.0474221333861351, 0.033897317945957184]\n",
      "1500 steps | score: [0.025360219180583954, -0.048913173377513885]\n",
      "1600 steps | score: [-0.03815644979476929, 0.005294122267514467]\n",
      "1700 steps | score: [-0.022334927693009377, 0.0019037257879972458]\n",
      "1800 steps | score: [-0.025684230029582977, 0.00016906345263123512]\n",
      "1900 steps | score: [-0.023654572665691376, 0.007858453318476677]\n",
      "2000 steps | score: [0.004792896099388599, -0.03481908142566681]\n",
      "2100 steps | score: [-0.04191606119275093, 0.013704982586205006]\n",
      "2200 steps | score: [-0.017307117581367493, -0.004270047880709171]\n",
      "2300 steps | score: [-0.00045827904250472784, -0.03558579087257385]\n",
      "2400 steps | score: [-0.03981202095746994, 0.02146030217409134]\n",
      "2500 steps | score: [-0.01846928708255291, -0.00342527125030756]\n",
      "0 steps | score: [0.12971363961696625, 0.06513163447380066]\n",
      "100 steps | score: [-0.019185513257980347, 0.07080773264169693]\n",
      "200 steps | score: [0.2462892085313797, -0.3423566520214081]\n",
      "300 steps | score: [-0.0923655778169632, 0.09211287647485733]\n",
      "400 steps | score: [0.11217924952507019, -0.14807511866092682]\n",
      "500 steps | score: [0.06603942066431046, -0.09527222067117691]\n",
      "600 steps | score: [-0.0003535287396516651, 0.0006080362945795059]\n",
      "unknown params:  tensor([-0.4291, -0.5951])\n",
      "unknown variance:  tensor([[1.0074]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4244, -0.5603])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.15878188610076904]\n",
      "100 steps | score: [-0.03287414461374283]\n",
      "200 steps | score: [0.041757918894290924]\n",
      "300 steps | score: [-0.04537346214056015]\n",
      "400 steps | score: [0.006415430456399918]\n",
      "0 steps | score: [0.13021956384181976, 0.08044855296611786]\n",
      "100 steps | score: [-0.006105909589678049, 0.07280794531106949]\n",
      "200 steps | score: [0.03801830857992172, -0.012023691087961197]\n",
      "300 steps | score: [-0.05560709163546562, 0.10043682903051376]\n",
      "400 steps | score: [0.023830212652683258, 0.0012403838336467743]\n",
      "500 steps | score: [0.009858720004558563, 0.012487241998314857]\n",
      "600 steps | score: [-0.03176897019147873, 0.06352411210536957]\n",
      "700 steps | score: [0.06744825094938278, -0.07265870273113251]\n",
      "800 steps | score: [0.003927393816411495, 0.017976095899939537]\n",
      "900 steps | score: [0.03257135674357414, -0.03183494135737419]\n",
      "1000 steps | score: [-0.00968798529356718, 0.011069182306528091]\n",
      "1100 steps | score: [-0.016919013112783432, 0.03411716967821121]\n",
      "1200 steps | score: [-0.028689486905932426, 0.034086279571056366]\n",
      "1300 steps | score: [-0.015474528074264526, 0.027300767600536346]\n",
      "1400 steps | score: [-0.0204745102673769, 0.03739076852798462]\n",
      "1500 steps | score: [-0.03739260509610176, 0.047897759824991226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 steps | score: [-0.032202620059251785, 0.046829551458358765]\n",
      "1700 steps | score: [-0.017497362568974495, 0.02625071443617344]\n",
      "1800 steps | score: [0.004708229098469019, 0.006174844689667225]\n",
      "0 steps | score: [0.1288031041622162, 0.08365621417760849]\n",
      "100 steps | score: [-0.013139101676642895, 0.0866432785987854]\n",
      "200 steps | score: [0.04647825285792351, -0.022749532014131546]\n",
      "300 steps | score: [-0.055074840784072876, 0.10060956329107285]\n",
      "400 steps | score: [0.026936454698443413, -0.0022534430027008057]\n",
      "500 steps | score: [0.027530670166015625, -0.016670413315296173]\n",
      "600 steps | score: [-0.02492767572402954, 0.04919370636343956]\n",
      "700 steps | score: [0.07926052063703537, -0.09688179194927216]\n",
      "800 steps | score: [0.0029798548202961683, 0.016496922820806503]\n",
      "900 steps | score: [0.054318543523550034, -0.06421039998531342]\n",
      "1000 steps | score: [0.008971595205366611, -0.004074178636074066]\n",
      "0 steps | score: [0.1935597062110901, -0.012893849052488804]\n",
      "100 steps | score: [0.02837494947016239, 0.006970393471419811]\n",
      "200 steps | score: [0.10626240074634552, -0.11714290082454681]\n",
      "300 steps | score: [-0.0024847507011145353, 0.010694988071918488]\n",
      "400 steps | score: [0.06566505879163742, -0.06357979774475098]\n",
      "500 steps | score: [0.05952456220984459, -0.06684844940900803]\n",
      "600 steps | score: [0.0018971762619912624, -0.008690869435667992]\n",
      "unknown params:  tensor([-0.4599, -0.7434])\n",
      "unknown variance:  tensor([[1.1143]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4244, -0.5603])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2526684105396271]\n",
      "100 steps | score: [0.006444133818149567]\n",
      "0 steps | score: [0.19785980880260468, -0.03422411158680916]\n",
      "100 steps | score: [-0.06657824665307999, 0.12424586713314056]\n",
      "200 steps | score: [0.11253921687602997, -0.12678846716880798]\n",
      "300 steps | score: [0.04090359807014465, -0.07283235341310501]\n",
      "400 steps | score: [0.028751635923981667, -0.03697279840707779]\n",
      "500 steps | score: [-0.02932582050561905, 0.04535385221242905]\n",
      "600 steps | score: [0.04133296757936478, -0.054556429386138916]\n",
      "700 steps | score: [0.08769144117832184, -0.12909071147441864]\n",
      "800 steps | score: [0.04273262247443199, -0.06307952105998993]\n",
      "900 steps | score: [-0.046530283987522125, 0.07509387284517288]\n",
      "1000 steps | score: [-0.030334409326314926, 0.04935188591480255]\n",
      "1100 steps | score: [0.16304045915603638, -0.25526878237724304]\n",
      "1200 steps | score: [-0.05559193342924118, 0.07383578270673752]\n",
      "1300 steps | score: [0.045225825160741806, -0.06071177124977112]\n",
      "1400 steps | score: [0.05280311778187752, -0.07564716786146164]\n",
      "1500 steps | score: [0.02856580540537834, -0.04666689783334732]\n",
      "1600 steps | score: [-0.0249255932867527, 0.033236313611269]\n",
      "1700 steps | score: [0.007153024896979332, -0.01592445559799671]\n",
      "1800 steps | score: [0.05556049197912216, -0.08130129426717758]\n",
      "1900 steps | score: [0.023949019610881805, -0.046128157526254654]\n",
      "2000 steps | score: [-0.010539412498474121, 0.002677131909877062]\n",
      "2100 steps | score: [0.0014544014120474458, -0.0008487708400934935]\n",
      "0 steps | score: [0.14725886285305023, 0.07312455773353577]\n",
      "100 steps | score: [-0.08460787683725357, 0.18842557072639465]\n",
      "200 steps | score: [0.06554016470909119, -0.03908725827932358]\n",
      "300 steps | score: [0.016115373000502586, -0.00530538335442543]\n",
      "400 steps | score: [-0.02300511673092842, 0.06731854379177094]\n",
      "500 steps | score: [-0.0829584002494812, 0.1487499624490738]\n",
      "600 steps | score: [0.02080366387963295, -0.00927651859819889]\n",
      "700 steps | score: [0.07398253679275513, -0.07588782906532288]\n",
      "800 steps | score: [0.03092530556023121, -0.018938688561320305]\n",
      "900 steps | score: [-0.08925113081932068, 0.157743439078331]\n",
      "1000 steps | score: [-0.05827973037958145, 0.12081319838762283]\n",
      "1100 steps | score: [0.13552643358707428, -0.19130641222000122]\n",
      "1200 steps | score: [-0.07447366416454315, 0.1305810958147049]\n",
      "1300 steps | score: [0.013473150320351124, 0.009567711502313614]\n",
      "1400 steps | score: [0.022505318745970726, -0.004406554624438286]\n",
      "1500 steps | score: [0.006202593445777893, 0.022163741290569305]\n",
      "1600 steps | score: [-0.06621085852384567, 0.11818323284387589]\n",
      "1700 steps | score: [-0.025315647944808006, 0.06263217329978943]\n",
      "1800 steps | score: [0.010826066136360168, 0.009188802912831306]\n",
      "1900 steps | score: [0.010978897102177143, 0.017108725383877754]\n",
      "2000 steps | score: [-0.049544841051101685, 0.09993147850036621]\n",
      "2100 steps | score: [-0.03203781321644783, 0.0729152262210846]\n",
      "2200 steps | score: [0.03663153946399689, -0.01575540564954281]\n",
      "2300 steps | score: [-0.006496374029666185, 0.03895951807498932]\n",
      "2400 steps | score: [-0.018132630735635757, 0.05800199136137962]\n",
      "2500 steps | score: [0.001176720834337175, 0.019167892634868622]\n",
      "2600 steps | score: [0.01783788949251175, -0.01033104956150055]\n",
      "2700 steps | score: [-0.008148271590471268, 0.043000102043151855]\n",
      "0 steps | score: [0.2374914288520813, -0.08168318122625351]\n",
      "100 steps | score: [-0.016532637178897858, 0.05902572721242905]\n",
      "200 steps | score: [0.15366820991039276, -0.18610148131847382]\n",
      "300 steps | score: [0.0981021597981453, -0.1508806049823761]\n",
      "400 steps | score: [0.05122359097003937, -0.0803130716085434]\n",
      "500 steps | score: [-0.017424646764993668, 0.025259045884013176]\n",
      "600 steps | score: [0.08865257352590561, -0.12769971787929535]\n",
      "700 steps | score: [0.15964026749134064, -0.22178064286708832]\n",
      "800 steps | score: [0.09973857551813126, -0.13319504261016846]\n",
      "900 steps | score: [-0.021841220557689667, 0.026058724150061607]\n",
      "1000 steps | score: [0.005751971621066332, -0.003637600690126419]\n",
      "unknown params:  tensor([-0.4590, -0.8399])\n",
      "unknown variance:  tensor([[1.1471]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4244, -0.5603])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3130589723587036]\n",
      "100 steps | score: [-0.008733082562685013]\n",
      "0 steps | score: [0.19542936980724335, -0.03811237961053848]\n",
      "100 steps | score: [-0.1216745376586914, 0.25111719965934753]\n",
      "200 steps | score: [0.07816056162118912, -0.05817914009094238]\n",
      "300 steps | score: [0.14467383921146393, -0.24426445364952087]\n",
      "400 steps | score: [0.04589017853140831, -0.05747409909963608]\n",
      "500 steps | score: [0.02195916883647442, -0.0251738540828228]\n",
      "600 steps | score: [-0.09351059049367905, 0.16019278764724731]\n",
      "700 steps | score: [0.00020068121375516057, 0.02115669846534729]\n",
      "800 steps | score: [-0.09181663393974304, 0.14344003796577454]\n",
      "900 steps | score: [0.007827204652130604, 0.0016683703288435936]\n",
      "0 steps | score: [0.12424064427614212, 0.09655492752790451]\n",
      "100 steps | score: [-0.1962006390094757, 0.385417103767395]\n",
      "200 steps | score: [0.0213940367102623, 0.0431411974132061]\n",
      "300 steps | score: [0.0720655545592308, -0.08774309605360031]\n",
      "400 steps | score: [0.02654658444225788, -0.014109477400779724]\n",
      "500 steps | score: [-0.0034638801589608192, 0.03613589331507683]\n",
      "600 steps | score: [-0.15075407922267914, 0.2676798105239868]\n",
      "700 steps | score: [-0.05435790494084358, 0.1204826831817627]\n",
      "800 steps | score: [-0.1339704692363739, 0.2404683381319046]\n",
      "900 steps | score: [-0.03814626857638359, 0.09985662996768951]\n",
      "1000 steps | score: [-0.010590802878141403, 0.02272781915962696]\n",
      "1100 steps | score: [-0.10936160385608673, 0.2012687772512436]\n",
      "1200 steps | score: [-0.0651007667183876, 0.13754473626613617]\n",
      "1300 steps | score: [-0.0760793462395668, 0.15409208834171295]\n",
      "1400 steps | score: [-0.06881244480609894, 0.14630497992038727]\n",
      "1500 steps | score: [-0.024426324293017387, 0.05340775102376938]\n",
      "1600 steps | score: [-0.0648123174905777, 0.11831944435834885]\n",
      "1700 steps | score: [-0.052359871566295624, 0.11580966413021088]\n",
      "1800 steps | score: [-0.02636881172657013, 0.05584173649549484]\n",
      "1900 steps | score: [-0.035911332815885544, 0.09090179949998856]\n",
      "2000 steps | score: [0.044001370668411255, -0.050929199904203415]\n",
      "2100 steps | score: [-0.04198065400123596, 0.0847259983420372]\n",
      "2200 steps | score: [-0.03966242074966431, 0.08667627722024918]\n",
      "2300 steps | score: [-0.03830709680914879, 0.08588512986898422]\n",
      "2400 steps | score: [-0.04374884441494942, 0.10445160418748856]\n",
      "2500 steps | score: [0.0019010788528248668, 0.02800552360713482]\n",
      "2600 steps | score: [-0.01577279344201088, 0.03954767435789108]\n",
      "unknown params:  tensor([-0.4907, -1.0099])\n",
      "unknown variance:  tensor([[1.2799]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4244, -0.5603])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.200247123837471]\n",
      "100 steps | score: [-0.09113019704818726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [-0.08152363449335098]\n",
      "300 steps | score: [-0.05699216201901436]\n",
      "400 steps | score: [-0.01316830050200224]\n",
      "500 steps | score: [-0.07868116348981857]\n",
      "600 steps | score: [-0.051705408841371536]\n",
      "700 steps | score: [0.00023100152611732483]\n",
      "0 steps | score: [0.22753269970417023, -0.1700821816921234]\n",
      "100 steps | score: [0.055873919278383255, -0.0027616024017333984]\n",
      "200 steps | score: [-0.01724453829228878, 0.07724857330322266]\n",
      "300 steps | score: [-0.021241597831249237, 0.05634414777159691]\n",
      "400 steps | score: [0.1422797441482544, -0.24267832934856415]\n",
      "500 steps | score: [-0.05777819827198982, 0.10617942363023758]\n",
      "600 steps | score: [-0.06822613626718521, 0.11620982736349106]\n",
      "700 steps | score: [-0.060141269117593765, 0.10424848645925522]\n",
      "800 steps | score: [0.13005903363227844, -0.2332839071750641]\n",
      "900 steps | score: [0.05200310796499252, -0.0981038510799408]\n",
      "1000 steps | score: [0.06457936763763428, -0.12318377196788788]\n",
      "1100 steps | score: [0.06315186619758606, -0.12468203157186508]\n",
      "1200 steps | score: [0.047644294798374176, -0.10009525716304779]\n",
      "1300 steps | score: [0.15102404356002808, -0.3060346245765686]\n",
      "1400 steps | score: [0.08533217757940292, -0.17747196555137634]\n",
      "1500 steps | score: [0.055988796055316925, -0.11096157878637314]\n",
      "1600 steps | score: [-0.02258838340640068, 0.03191318362951279]\n",
      "1700 steps | score: [0.014304177835583687, -0.026002727448940277]\n",
      "1800 steps | score: [0.025527184829115868, -0.05019006133079529]\n",
      "1900 steps | score: [0.017665987834334373, -0.042190954089164734]\n",
      "2000 steps | score: [0.0263799037784338, -0.06311827898025513]\n",
      "2100 steps | score: [0.00996333360671997, -0.029460787773132324]\n",
      "2200 steps | score: [0.10313407331705093, -0.21602748334407806]\n",
      "2300 steps | score: [0.013503416441380978, -0.03236112371087074]\n",
      "2400 steps | score: [0.1286543756723404, -0.2575686573982239]\n",
      "2500 steps | score: [0.07558000087738037, -0.15325462818145752]\n",
      "unknown params:  tensor([-0.4532, -0.9469])\n",
      "unknown variance:  tensor([[1.3414]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4244, -0.5603])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.22710967063903809]\n",
      "100 steps | score: [-0.05202466994524002]\n",
      "200 steps | score: [0.1013549268245697]\n",
      "300 steps | score: [-0.002681426703929901]\n",
      "0 steps | score: [0.21115973591804504, -0.07808230072259903]\n",
      "100 steps | score: [-0.0009672639425843954, 0.19446395337581635]\n",
      "200 steps | score: [0.35124149918556213, -0.5871054530143738]\n",
      "300 steps | score: [0.10510847717523575, -0.08035601675510406]\n",
      "400 steps | score: [-0.048667896538972855, 0.2134978324174881]\n",
      "500 steps | score: [-0.052352845668792725, 0.20694489777088165]\n",
      "600 steps | score: [0.05198449268937111, -0.0021042507141828537]\n",
      "700 steps | score: [-0.11744465678930283, 0.3320510983467102]\n",
      "800 steps | score: [0.1381179690361023, -0.20014125108718872]\n",
      "900 steps | score: [-0.05593264102935791, 0.20443743467330933]\n",
      "1000 steps | score: [-0.04492659121751785, 0.18842734396457672]\n",
      "1100 steps | score: [0.10360775887966156, -0.13193458318710327]\n",
      "1200 steps | score: [0.08185859024524689, -0.08626008033752441]\n",
      "1300 steps | score: [0.029946817085146904, 0.03589900955557823]\n",
      "1400 steps | score: [-0.07134798169136047, 0.21798068284988403]\n",
      "1500 steps | score: [-0.0310458205640316, 0.1547701060771942]\n",
      "1600 steps | score: [-0.014405956491827965, 0.12718406319618225]\n",
      "1700 steps | score: [0.009126123040914536, 0.06690380722284317]\n",
      "1800 steps | score: [0.034706439822912216, 0.014125898480415344]\n",
      "1900 steps | score: [0.21807357668876648, -0.39123067259788513]\n",
      "2000 steps | score: [0.029471207410097122, 0.02169468253850937]\n",
      "2100 steps | score: [0.08890673518180847, -0.1082184761762619]\n",
      "2200 steps | score: [0.09487106651067734, -0.11114275455474854]\n",
      "2300 steps | score: [0.11223535984754562, -0.15978668630123138]\n",
      "2400 steps | score: [-0.005714481230825186, 0.09715816378593445]\n",
      "2500 steps | score: [0.06962532550096512, -0.0615464486181736]\n",
      "2600 steps | score: [0.0321834497153759, 0.023923959583044052]\n",
      "0 steps | score: [0.111229307949543, 0.13596589863300323]\n",
      "100 steps | score: [-0.06391074508428574, 0.33369606733322144]\n",
      "200 steps | score: [0.3375276029109955, -0.553015410900116]\n",
      "300 steps | score: [0.038066934794187546, 0.08612413704395294]\n",
      "400 steps | score: [-0.12229538708925247, 0.3767860531806946]\n",
      "500 steps | score: [-0.11169582605361938, 0.3528118431568146]\n",
      "600 steps | score: [-0.015396185219287872, 0.15553918480873108]\n",
      "700 steps | score: [-0.17079627513885498, 0.45529842376708984]\n",
      "800 steps | score: [0.04386276379227638, 0.008737083524465561]\n",
      "900 steps | score: [-0.1482873409986496, 0.40767911076545715]\n",
      "1000 steps | score: [-0.10414807498455048, 0.31166326999664307]\n",
      "1100 steps | score: [0.03191728517413139, 0.04051557928323746]\n",
      "1200 steps | score: [-0.009664397686719894, 0.11524611711502075]\n",
      "1300 steps | score: [-0.07168956845998764, 0.24808967113494873]\n",
      "1400 steps | score: [-0.14646410942077637, 0.3964678645133972]\n",
      "1500 steps | score: [-0.11103224754333496, 0.32804930210113525]\n",
      "1600 steps | score: [-0.11874377727508545, 0.3441027104854584]\n",
      "1700 steps | score: [-0.1063307374715805, 0.3146464228630066]\n",
      "1800 steps | score: [-0.045458413660526276, 0.17944736778736115]\n",
      "1900 steps | score: [0.1349046677350998, -0.21446502208709717]\n",
      "2000 steps | score: [-0.055146194994449615, 0.20913438498973846]\n",
      "2100 steps | score: [0.02829713001847267, 0.03880918398499489]\n",
      "2200 steps | score: [0.003722589462995529, 0.08201542496681213]\n",
      "2300 steps | score: [0.016608817502856255, 0.05579559877514839]\n",
      "2400 steps | score: [-0.08157617598772049, 0.26846957206726074]\n",
      "2500 steps | score: [-0.01610320433974266, 0.1273648738861084]\n",
      "2600 steps | score: [-0.04321380704641342, 0.18288947641849518]\n",
      "0 steps | score: [0.1321081966161728, -0.014049512334167957]\n",
      "100 steps | score: [-0.040935054421424866, 0.20077960193157196]\n",
      "200 steps | score: [0.2070779800415039, -0.3523942232131958]\n",
      "300 steps | score: [0.045659709721803665, -0.044964250177145004]\n",
      "400 steps | score: [-0.10607745498418808, 0.24428734183311462]\n",
      "500 steps | score: [-0.14407871663570404, 0.3121143579483032]\n",
      "600 steps | score: [-0.012397999875247478, 0.0399271696805954]\n",
      "700 steps | score: [-0.17628386616706848, 0.3645838499069214]\n",
      "800 steps | score: [0.08828787505626678, -0.1652415245771408]\n",
      "900 steps | score: [-0.10192438215017319, 0.2198922038078308]\n",
      "1000 steps | score: [-0.10670638829469681, 0.23220038414001465]\n",
      "1100 steps | score: [0.062417756766080856, -0.127672016620636]\n",
      "1200 steps | score: [0.019041405990719795, -0.04067899286746979]\n",
      "1300 steps | score: [-0.06185601279139519, 0.12359137088060379]\n",
      "1400 steps | score: [-0.12486971914768219, 0.2527039051055908]\n",
      "1500 steps | score: [-0.10241685062646866, 0.20218923687934875]\n",
      "1600 steps | score: [-0.10278364270925522, 0.2140938937664032]\n",
      "1700 steps | score: [-0.07275985926389694, 0.14570055902004242]\n",
      "1800 steps | score: [-0.03293798863887787, 0.0650712326169014]\n",
      "1900 steps | score: [0.1291050761938095, -0.28565388917922974]\n",
      "2000 steps | score: [-0.020544493570923805, 0.042107269167900085]\n",
      "2100 steps | score: [0.031024713069200516, -0.06690270453691483]\n",
      "2200 steps | score: [0.014998066239058971, -0.03968144953250885]\n",
      "2300 steps | score: [0.03512728214263916, -0.08531443029642105]\n",
      "2400 steps | score: [-0.08248917758464813, 0.1612076312303543]\n",
      "2500 steps | score: [0.007510733790695667, -0.01938122697174549]\n",
      "2600 steps | score: [-0.03316808491945267, 0.07118900120258331]\n",
      "unknown params:  tensor([-0.3943, -0.8850])\n",
      "unknown variance:  tensor([[1.4079]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/3891ef6e-440c-435c-9fea-988eaa6927bf\n",
      "gt params:  tensor([-0.4349, -0.5746])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.024847514927387238]\n",
      "100 steps | score: [0.016681939363479614]\n",
      "200 steps | score: [-0.07119730114936829]\n",
      "300 steps | score: [0.0007311180233955383]\n",
      "0 steps | score: [0.005971595179289579, 0.09198887646198273]\n",
      "100 steps | score: [0.042524710297584534, -0.04421241208910942]\n",
      "200 steps | score: [-0.012077465653419495, 0.07440055161714554]\n",
      "300 steps | score: [0.043228209018707275, 0.031571730971336365]\n",
      "400 steps | score: [-0.06465882807970047, 0.06645679473876953]\n",
      "500 steps | score: [0.009351647458970547, 0.06946200877428055]\n",
      "600 steps | score: [0.018546339124441147, 0.06608067452907562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 steps | score: [-0.0458771176636219, 0.04313155263662338]\n",
      "800 steps | score: [-0.05871625989675522, -0.007171447388827801]\n",
      "900 steps | score: [-0.021356509998440742, 0.026221491396427155]\n",
      "1000 steps | score: [-0.00566124590113759, 0.04115990921854973]\n",
      "1100 steps | score: [-0.01805683970451355, 0.05211959779262543]\n",
      "1200 steps | score: [0.007173948921263218, 0.025462668389081955]\n",
      "1300 steps | score: [-0.06849070638418198, 0.04185657203197479]\n",
      "1400 steps | score: [0.015919789671897888, 0.04533044621348381]\n",
      "1500 steps | score: [-0.008180489763617516, 0.05228329077363014]\n",
      "1600 steps | score: [-0.011083617806434631, 0.04253336787223816]\n",
      "1700 steps | score: [-0.02858782559633255, 0.016665585339069366]\n",
      "1800 steps | score: [-0.02287411317229271, 0.029294835403561592]\n",
      "1900 steps | score: [-0.004402266349643469, 0.03765547275543213]\n",
      "2000 steps | score: [-0.024624258279800415, 0.03800171613693237]\n",
      "2100 steps | score: [-0.0018970777746289968, 0.029443658888339996]\n",
      "2200 steps | score: [-0.03161628916859627, 0.03290904313325882]\n",
      "2300 steps | score: [-0.004552274942398071, 0.035311441868543625]\n",
      "2400 steps | score: [-0.0066780769266188145, 0.044801414012908936]\n",
      "2500 steps | score: [-0.0065935393795371056, 0.037901632487773895]\n",
      "2600 steps | score: [-0.019224043935537338, 0.03233373910188675]\n",
      "0 steps | score: [0.07737775146961212, 0.07716049253940582]\n",
      "100 steps | score: [0.09333854168653488, -0.06088322401046753]\n",
      "200 steps | score: [0.04808732867240906, 0.06535656750202179]\n",
      "300 steps | score: [0.09659319370985031, 0.018673142418265343]\n",
      "400 steps | score: [-0.004356880206614733, 0.04887554049491882]\n",
      "500 steps | score: [0.05674939602613449, 0.06445470452308655]\n",
      "600 steps | score: [0.07086201757192612, 0.04425497353076935]\n",
      "700 steps | score: [0.01615424081683159, 0.028778856620192528]\n",
      "800 steps | score: [-0.008216582238674164, -0.021502293646335602]\n",
      "900 steps | score: [0.030181122943758965, 0.009927373379468918]\n",
      "1000 steps | score: [0.05226831138134003, 0.028393981978297234]\n",
      "1100 steps | score: [0.03903847187757492, 0.04422841966152191]\n",
      "1200 steps | score: [0.06191639229655266, 0.008704693987965584]\n",
      "1300 steps | score: [-0.00826995074748993, 0.028100579977035522]\n",
      "1400 steps | score: [0.06540587544441223, 0.029894061386585236]\n",
      "1500 steps | score: [0.046216558665037155, 0.04377017915248871]\n",
      "1600 steps | score: [0.041701193898916245, 0.02797146886587143]\n",
      "1700 steps | score: [0.02086530812084675, 0.007011866196990013]\n",
      "1800 steps | score: [0.03155933693051338, 0.016395997256040573]\n",
      "1900 steps | score: [0.04768455773591995, 0.02668832056224346]\n",
      "2000 steps | score: [0.03229105845093727, 0.02855915203690529]\n",
      "2100 steps | score: [0.0528288409113884, 0.007229026407003403]\n",
      "2200 steps | score: [0.025235192850232124, 0.021270904690027237]\n",
      "2300 steps | score: [0.04961617663502693, 0.016685128211975098]\n",
      "2400 steps | score: [0.04892405867576599, 0.029811732470989227]\n",
      "2500 steps | score: [0.04778878763318062, 0.021473996341228485]\n",
      "2600 steps | score: [0.03179316967725754, 0.014548784121870995]\n",
      "0 steps | score: [0.03236135467886925, 0.04130183160305023]\n",
      "100 steps | score: [0.04702906683087349, -0.09278826415538788]\n",
      "200 steps | score: [0.009065093472599983, 0.026183605194091797]\n",
      "300 steps | score: [0.06816032528877258, -0.010501012206077576]\n",
      "400 steps | score: [-0.045760586857795715, 0.011658217757940292]\n",
      "500 steps | score: [0.017835121601819992, 0.034226395189762115]\n",
      "600 steps | score: [0.03681936487555504, 0.015502342954277992]\n",
      "700 steps | score: [-0.033207740634679794, -0.006628342438489199]\n",
      "800 steps | score: [-0.044587790966033936, -0.0591084361076355]\n",
      "900 steps | score: [-0.0014745747903361917, -0.02038472518324852]\n",
      "1000 steps | score: [0.016806844621896744, -0.0025390549562871456]\n",
      "1100 steps | score: [0.006427489221096039, 0.008475454524159431]\n",
      "unknown params:  tensor([-0.3955, -0.4583])\n",
      "unknown variance:  tensor([[0.8355]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4349, -0.5746])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.23203875124454498]\n",
      "100 steps | score: [0.09964192658662796]\n",
      "200 steps | score: [0.007085781544446945]\n",
      "0 steps | score: [0.09696456044912338, 0.07903698086738586]\n",
      "100 steps | score: [0.05902295187115669, -0.022250056266784668]\n",
      "200 steps | score: [-0.02189837396144867, 0.03336430341005325]\n",
      "300 steps | score: [0.09933935850858688, -0.07608061283826828]\n",
      "400 steps | score: [0.05410492792725563, -0.030453067272901535]\n",
      "500 steps | score: [0.06471401453018188, -0.02248365618288517]\n",
      "600 steps | score: [-0.007290297653526068, 0.027362553402781487]\n",
      "700 steps | score: [0.07223274558782578, -0.054165277630090714]\n",
      "800 steps | score: [0.04536252096295357, -0.017883002758026123]\n",
      "900 steps | score: [0.0600605383515358, -0.027856748551130295]\n",
      "1000 steps | score: [0.025737417861819267, 0.015170831233263016]\n",
      "1100 steps | score: [0.054255906492471695, -0.024098020046949387]\n",
      "1200 steps | score: [0.01067818608134985, 0.004054276272654533]\n",
      "1300 steps | score: [0.07221329212188721, -0.04332105815410614]\n",
      "1400 steps | score: [0.02617095410823822, 0.022613216191530228]\n",
      "1500 steps | score: [0.04857567325234413, -0.021747546270489693]\n",
      "1600 steps | score: [0.009991641156375408, 3.347080200910568e-05]\n",
      "0 steps | score: [0.030754810199141502, 0.05291189253330231]\n",
      "100 steps | score: [0.002067931927740574, -0.04047560691833496]\n",
      "200 steps | score: [-0.06559742987155914, -0.0045233964920043945]\n",
      "300 steps | score: [0.04358064383268356, -0.11019331216812134]\n",
      "400 steps | score: [-0.02436656877398491, -0.052110303193330765]\n",
      "500 steps | score: [0.011145677417516708, -0.04656839370727539]\n",
      "600 steps | score: [-0.06859278678894043, -0.001863362267613411]\n",
      "700 steps | score: [0.030841588973999023, -0.08771022409200668]\n",
      "800 steps | score: [-0.020098943263292313, -0.040397368371486664]\n",
      "900 steps | score: [0.006554170977324247, -0.05132412537932396]\n",
      "1000 steps | score: [-0.031184406951069832, -0.00283904280513525]\n",
      "1100 steps | score: [-0.0027373579796403646, -0.039872173219919205]\n",
      "1200 steps | score: [-0.04718014970421791, -0.028302941471338272]\n",
      "1300 steps | score: [0.003816410666331649, -0.06096445024013519]\n",
      "1400 steps | score: [-0.03278956189751625, -0.009911507368087769]\n",
      "1500 steps | score: [-0.002925069769844413, -0.0507720485329628]\n",
      "1600 steps | score: [-0.05077818036079407, -0.023876739665865898]\n",
      "1700 steps | score: [0.007487893104553223, -0.0580056756734848]\n",
      "1800 steps | score: [-0.020813873037695885, -0.016066674143075943]\n",
      "1900 steps | score: [-0.004284934606403112, -0.03828089311718941]\n",
      "2000 steps | score: [-0.03737359121441841, -0.025009576231241226]\n",
      "2100 steps | score: [-0.013473785482347012, -0.036570142954587936]\n",
      "2200 steps | score: [-0.020591119304299355, -0.020783131942152977]\n",
      "2300 steps | score: [-0.006916378159075975, -0.04187288135290146]\n",
      "2400 steps | score: [-0.036847811192274094, -0.023384682834148407]\n",
      "2500 steps | score: [-0.012856903485953808, -0.0338750034570694]\n",
      "2600 steps | score: [-0.020157115533947945, -0.02902776002883911]\n",
      "2700 steps | score: [-0.01381510216742754, -0.031196042895317078]\n",
      "2800 steps | score: [-0.031817175447940826, -0.023987911641597748]\n",
      "unknown params:  tensor([-0.4024, -0.4894])\n",
      "unknown variance:  tensor([[0.8774]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4349, -0.5746])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.28833693265914917]\n",
      "100 steps | score: [0.16232259571552277]\n",
      "200 steps | score: [0.09991571307182312]\n",
      "300 steps | score: [0.16882795095443726]\n",
      "400 steps | score: [0.1794428676366806]\n",
      "500 steps | score: [0.22952759265899658]\n",
      "600 steps | score: [0.11655924469232559]\n",
      "700 steps | score: [0.08350025117397308]\n",
      "800 steps | score: [0.166756734251976]\n",
      "900 steps | score: [0.21367016434669495]\n",
      "1000 steps | score: [0.16710509359836578]\n",
      "1100 steps | score: [0.1320638209581375]\n",
      "1200 steps | score: [0.1922106295824051]\n",
      "1300 steps | score: [0.17203597724437714]\n",
      "1400 steps | score: [0.1954171359539032]\n",
      "1500 steps | score: [0.11347661912441254]\n",
      "1600 steps | score: [0.19551898539066315]\n",
      "1700 steps | score: [0.15802444517612457]\n",
      "1800 steps | score: [0.1571587324142456]\n",
      "1900 steps | score: [0.13292086124420166]\n",
      "2000 steps | score: [0.16138237714767456]\n",
      "2100 steps | score: [0.14566321671009064]\n",
      "2200 steps | score: [0.158447727560997]\n",
      "2300 steps | score: [0.16622725129127502]\n",
      "2400 steps | score: [0.1483360379934311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 steps | score: [0.16282522678375244]\n",
      "2600 steps | score: [0.14239782094955444]\n",
      "0 steps | score: [0.049606144428253174, 0.09888823330402374]\n",
      "100 steps | score: [-0.045643892139196396, 0.013046198524534702]\n",
      "200 steps | score: [-0.06299702823162079, 0.02919882722198963]\n",
      "300 steps | score: [-0.032347530126571655, -0.02485683374106884]\n",
      "400 steps | score: [-0.001667770673520863, -0.028945717960596085]\n",
      "500 steps | score: [-0.0006584334187209606, -0.003861796110868454]\n",
      "0 steps | score: [0.1402694433927536, 0.040697600692510605]\n",
      "100 steps | score: [0.04189411923289299, -0.038230858743190765]\n",
      "200 steps | score: [0.011634640395641327, -0.020599322393536568]\n",
      "300 steps | score: [0.044661059975624084, -0.07306914776563644]\n",
      "400 steps | score: [0.06615716964006424, -0.06618625670671463]\n",
      "500 steps | score: [0.06912264972925186, -0.055169157683849335]\n",
      "600 steps | score: [0.01507471315562725, -0.01696920581161976]\n",
      "700 steps | score: [-0.03135870397090912, -0.025659024715423584]\n",
      "800 steps | score: [0.03817670792341232, -0.03462597727775574]\n",
      "900 steps | score: [0.08404216170310974, -0.051917120814323425]\n",
      "1000 steps | score: [0.0760263204574585, -0.05881218612194061]\n",
      "1100 steps | score: [0.01573958992958069, -0.03531206399202347]\n",
      "1200 steps | score: [0.07413118332624435, -0.06524009257555008]\n",
      "1300 steps | score: [0.03999339044094086, -0.014292165637016296]\n",
      "1400 steps | score: [0.08233726024627686, -0.06938310712575912]\n",
      "1500 steps | score: [0.01561287697404623, -0.04417828097939491]\n",
      "1600 steps | score: [0.06797423213720322, -0.06551489979028702]\n",
      "1700 steps | score: [0.046205710619688034, -0.03468542546033859]\n",
      "1800 steps | score: [0.060549259185791016, -0.057948846369981766]\n",
      "1900 steps | score: [0.03602445125579834, -0.0451311431825161]\n",
      "2000 steps | score: [0.055438846349716187, -0.055456019937992096]\n",
      "2100 steps | score: [0.040593553334474564, -0.03516421839594841]\n",
      "2200 steps | score: [0.06250554323196411, -0.0574566014111042]\n",
      "2300 steps | score: [0.03826488181948662, -0.04816330596804619]\n",
      "2400 steps | score: [0.05349887162446976, -0.05341470241546631]\n",
      "2500 steps | score: [0.03585035726428032, -0.03435773402452469]\n",
      "2600 steps | score: [0.04429083690047264, -0.04919767007231712]\n",
      "0 steps | score: [0.0574442520737648, 0.09921088069677353]\n",
      "100 steps | score: [-0.02360980398952961, 0.0013697091490030289]\n",
      "200 steps | score: [-0.049202676862478256, 0.028877414762973785]\n",
      "300 steps | score: [-0.03451145067811012, -0.021280953660607338]\n",
      "400 steps | score: [0.013628767803311348, -0.024354029446840286]\n",
      "500 steps | score: [0.018103178590536118, -0.017750468105077744]\n",
      "600 steps | score: [-0.03842269256711006, 0.03912058472633362]\n",
      "700 steps | score: [-0.08233658969402313, 0.021961741149425507]\n",
      "800 steps | score: [-0.010580645874142647, 0.007215327583253384]\n",
      "900 steps | score: [0.02834276668727398, -0.012634065002202988]\n",
      "1000 steps | score: [0.023594483733177185, -0.015267432667315006]\n",
      "1100 steps | score: [-0.036881085485219955, 0.010693669319152832]\n",
      "1200 steps | score: [0.03372223302721977, -0.021736646071076393]\n",
      "1300 steps | score: [-0.016243085265159607, 0.022802766412496567]\n",
      "1400 steps | score: [0.0371156744658947, -0.0226574894040823]\n",
      "1500 steps | score: [-0.04270956665277481, 0.0066957175731658936]\n",
      "1600 steps | score: [0.013104913756251335, -0.02344513311982155]\n",
      "1700 steps | score: [-0.010756309144198895, 0.011299668811261654]\n",
      "1800 steps | score: [0.0041734566912055016, -0.013897213153541088]\n",
      "1900 steps | score: [-0.027377041056752205, 0.007483635097742081]\n",
      "2000 steps | score: [0.00469936104491353, -0.014498859643936157]\n",
      "2100 steps | score: [-0.02024957723915577, 0.009664200246334076]\n",
      "2200 steps | score: [0.005575778894126415, -0.014698650687932968]\n",
      "2300 steps | score: [-0.01619337499141693, 0.0019483701325953007]\n",
      "2400 steps | score: [-0.0039086355827748775, -0.009619683027267456]\n",
      "unknown params:  tensor([-0.4197, -0.4913])\n",
      "unknown variance:  tensor([[0.9110]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4349, -0.5746])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.07204938679933548]\n",
      "100 steps | score: [-0.1625780463218689]\n",
      "200 steps | score: [-0.10781092941761017]\n",
      "300 steps | score: [-0.17764613032341003]\n",
      "400 steps | score: [-0.1169419214129448]\n",
      "500 steps | score: [-0.09032922238111496]\n",
      "600 steps | score: [-0.07521488517522812]\n",
      "700 steps | score: [-0.17565204203128815]\n",
      "800 steps | score: [-0.10931110382080078]\n",
      "900 steps | score: [-0.1579127013683319]\n",
      "1000 steps | score: [-0.1611146777868271]\n",
      "1100 steps | score: [-0.12039954215288162]\n",
      "1200 steps | score: [-0.10285326838493347]\n",
      "1300 steps | score: [-0.09077897667884827]\n",
      "1400 steps | score: [-0.16144242882728577]\n",
      "1500 steps | score: [-0.09551174193620682]\n",
      "1600 steps | score: [-0.11810032278299332]\n",
      "1700 steps | score: [-0.08770738542079926]\n",
      "1800 steps | score: [-0.13479311764240265]\n",
      "1900 steps | score: [-0.11374962329864502]\n",
      "2000 steps | score: [-0.10288733243942261]\n",
      "2100 steps | score: [-0.14258959889411926]\n",
      "2200 steps | score: [-0.10483276844024658]\n",
      "2300 steps | score: [-0.12642569839954376]\n",
      "2400 steps | score: [-0.11989396065473557]\n",
      "2500 steps | score: [-0.15004505217075348]\n",
      "2600 steps | score: [-0.13515940308570862]\n",
      "2700 steps | score: [-0.11592499911785126]\n",
      "2800 steps | score: [-0.1228708028793335]\n",
      "0 steps | score: [0.08617629110813141, 0.16570217907428741]\n",
      "100 steps | score: [-0.06052379682660103, 0.11789687722921371]\n",
      "200 steps | score: [-0.021522268652915955, 0.06517880409955978]\n",
      "300 steps | score: [-0.08177744597196579, 0.09167873859405518]\n",
      "400 steps | score: [-0.02637866698205471, 0.10324119031429291]\n",
      "500 steps | score: [-0.0020583041477948427, 0.10061484575271606]\n",
      "600 steps | score: [0.024397287517786026, 0.0481676422059536]\n",
      "700 steps | score: [-0.036771178245544434, 0.07294273376464844]\n",
      "800 steps | score: [0.023950587958097458, 0.03395743668079376]\n",
      "900 steps | score: [-0.01272234134376049, 0.07822676002979279]\n",
      "1000 steps | score: [-0.03317556902766228, 0.051920872181653976]\n",
      "1100 steps | score: [-0.020205335691571236, 0.06782642006874084]\n",
      "1200 steps | score: [-0.004710322245955467, 0.07481475919485092]\n",
      "1300 steps | score: [0.057466059923172, -0.0015842257998883724]\n",
      "1400 steps | score: [-0.048327259719371796, 0.07566573470830917]\n",
      "1500 steps | score: [0.05075257271528244, -0.0021947636269032955]\n",
      "1600 steps | score: [-0.02097880095243454, 0.0869079977273941]\n",
      "1700 steps | score: [0.02658270113170147, 0.026446454226970673]\n",
      "1800 steps | score: [-0.0037879357114434242, 0.05520471930503845]\n",
      "1900 steps | score: [0.004915796685963869, 0.06314762681722641]\n",
      "2000 steps | score: [0.0054895272478461266, 0.049287885427474976]\n",
      "2100 steps | score: [-0.014207962900400162, 0.06220283731818199]\n",
      "2200 steps | score: [0.006487482693046331, 0.0458231046795845]\n",
      "2300 steps | score: [-0.011348378844559193, 0.07068119198083878]\n",
      "2400 steps | score: [0.023852281272411346, 0.03282764181494713]\n",
      "2500 steps | score: [-0.010160814970731735, 0.058827079832553864]\n",
      "2600 steps | score: [0.005445569287985563, 0.047250643372535706]\n",
      "2700 steps | score: [-0.01858246885240078, 0.06800846755504608]\n",
      "2800 steps | score: [-0.008666831068694592, 0.0544649213552475]\n",
      "0 steps | score: [0.05606963112950325, 0.12822981178760529]\n",
      "100 steps | score: [-0.08717089891433716, 0.07885263860225677]\n",
      "200 steps | score: [-0.03975996747612953, 0.03410137817263603]\n",
      "300 steps | score: [-0.10150498896837234, 0.04184751212596893]\n",
      "400 steps | score: [-0.04180597513914108, 0.0636558085680008]\n",
      "500 steps | score: [-0.010449569672346115, 0.05747110769152641]\n",
      "600 steps | score: [0.010938490740954876, 0.00829613208770752]\n",
      "700 steps | score: [-0.05548790842294693, 0.03289897367358208]\n",
      "800 steps | score: [0.0066267624497413635, -0.011234836652874947]\n",
      "900 steps | score: [-0.0495663620531559, 0.056478820741176605]\n",
      "1000 steps | score: [-0.04963686689734459, 0.017887746915221214]\n",
      "1100 steps | score: [-0.02498733252286911, 0.01666158065199852]\n",
      "1200 steps | score: [-0.020299619063735008, 0.03187190368771553]\n",
      "1300 steps | score: [0.042769912630319595, -0.04172350838780403]\n",
      "1400 steps | score: [-0.07319200783967972, 0.05441977083683014]\n",
      "1500 steps | score: [0.04314754158258438, -0.0513778030872345]\n",
      "1600 steps | score: [-0.041467275470495224, 0.052001990377902985]\n",
      "1700 steps | score: [0.006929604336619377, -0.01229049451649189]\n",
      "1800 steps | score: [-0.028576059266924858, 0.015078015625476837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [-0.011899138800799847, 0.014639190398156643]\n",
      "2000 steps | score: [-0.007702316157519817, 0.012507328763604164]\n",
      "2100 steps | score: [-0.03733908757567406, 0.02401188760995865]\n",
      "2200 steps | score: [-0.007063660770654678, 0.00552505673840642]\n",
      "0 steps | score: [0.08592794835567474, 0.1189027726650238]\n",
      "100 steps | score: [-0.062328848987817764, 0.06617002189159393]\n",
      "200 steps | score: [-0.014813886024057865, 0.02116483263671398]\n",
      "300 steps | score: [-0.07248825579881668, 0.031181700527668]\n",
      "400 steps | score: [-0.04199923202395439, 0.07096977531909943]\n",
      "500 steps | score: [0.011967102065682411, 0.03779572993516922]\n",
      "600 steps | score: [0.025814151391386986, 0.005711645819246769]\n",
      "700 steps | score: [-0.04031820595264435, 0.019492801278829575]\n",
      "800 steps | score: [0.01586032100021839, -0.012164436280727386]\n",
      "900 steps | score: [-0.034819647669792175, 0.046823978424072266]\n",
      "1000 steps | score: [-0.03460719436407089, 0.009212382137775421]\n",
      "1100 steps | score: [-0.01601564697921276, 0.020483532920479774]\n",
      "1200 steps | score: [-0.005019294563680887, 0.027294130995869637]\n",
      "1300 steps | score: [0.050966836512088776, -0.027509966865181923]\n",
      "1400 steps | score: [-0.049433667212724686, 0.04039362072944641]\n",
      "1500 steps | score: [0.044282376766204834, -0.045902591198682785]\n",
      "1600 steps | score: [-0.02448376826941967, 0.0437307208776474]\n",
      "1700 steps | score: [0.025035925209522247, -0.024480152875185013]\n",
      "1800 steps | score: [-0.017988702282309532, 0.019937381148338318]\n",
      "1900 steps | score: [-0.0001977771462406963, 0.016027837991714478]\n",
      "2000 steps | score: [0.0009251963347196579, 0.017514625564217567]\n",
      "2100 steps | score: [-0.017960315570235252, 0.02123129367828369]\n",
      "2200 steps | score: [0.00652762595564127, -0.002407057210803032]\n",
      "unknown params:  tensor([-0.4373, -0.5514])\n",
      "unknown variance:  tensor([[0.9578]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4349, -0.5746])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2738642692565918]\n",
      "100 steps | score: [0.07695391774177551]\n",
      "200 steps | score: [0.11631285399198532]\n",
      "300 steps | score: [0.041107822209596634]\n",
      "400 steps | score: [0.17105379700660706]\n",
      "500 steps | score: [0.03907610848546028]\n",
      "600 steps | score: [0.07921291887760162]\n",
      "700 steps | score: [0.07206534594297409]\n",
      "800 steps | score: [0.09874419867992401]\n",
      "900 steps | score: [0.09417717903852463]\n",
      "1000 steps | score: [0.1024104431271553]\n",
      "1100 steps | score: [0.10741046071052551]\n",
      "1200 steps | score: [0.14209207892417908]\n",
      "1300 steps | score: [0.04712607339024544]\n",
      "1400 steps | score: [0.06157736852765083]\n",
      "1500 steps | score: [0.04060380160808563]\n",
      "1600 steps | score: [0.05736827105283737]\n",
      "1700 steps | score: [0.11656486243009567]\n",
      "1800 steps | score: [0.09879236668348312]\n",
      "1900 steps | score: [0.09749090671539307]\n",
      "2000 steps | score: [0.08937391638755798]\n",
      "2100 steps | score: [0.10064176470041275]\n",
      "2200 steps | score: [0.09180479496717453]\n",
      "2300 steps | score: [0.07788116484880447]\n",
      "2400 steps | score: [0.10135722905397415]\n",
      "2500 steps | score: [0.08045214414596558]\n",
      "2600 steps | score: [0.07595233619213104]\n",
      "0 steps | score: [0.08565808087587357, 0.16175433993339539]\n",
      "100 steps | score: [-0.07606441527605057, 0.13053975999355316]\n",
      "200 steps | score: [-0.01254416722804308, 0.058646537363529205]\n",
      "300 steps | score: [-0.11095745116472244, 0.1376604437828064]\n",
      "400 steps | score: [0.012995736673474312, 0.04002087935805321]\n",
      "500 steps | score: [-0.04441026970744133, 0.0755920261144638]\n",
      "600 steps | score: [-0.0699915885925293, 0.083657406270504]\n",
      "700 steps | score: [-0.05041377991437912, 0.0862768143415451]\n",
      "800 steps | score: [-0.024563947692513466, 0.09560787677764893]\n",
      "900 steps | score: [0.011879010125994682, 0.0028430968523025513]\n",
      "1000 steps | score: [0.0023681242018938065, 0.01258610188961029]\n",
      "1100 steps | score: [-0.037653133273124695, 0.08410289883613586]\n",
      "1200 steps | score: [0.06672625243663788, -0.0441594198346138]\n",
      "1300 steps | score: [-0.08220033347606659, 0.10451605916023254]\n",
      "1400 steps | score: [-0.020939165726304054, 0.054593078792095184]\n",
      "1500 steps | score: [-0.05919448658823967, 0.0984123945236206]\n",
      "1600 steps | score: [-0.046657998114824295, 0.06819368153810501]\n",
      "1700 steps | score: [0.0023124662693589926, 0.025898896157741547]\n",
      "1800 steps | score: [-0.042491018772125244, 0.08519643545150757]\n",
      "1900 steps | score: [0.002698172815144062, 0.028484445065259933]\n",
      "2000 steps | score: [-0.04024113342165947, 0.07098294794559479]\n",
      "2100 steps | score: [-0.03941868990659714, 0.0807826817035675]\n",
      "2200 steps | score: [-0.010218420065939426, 0.043885793536901474]\n",
      "2300 steps | score: [-0.037136781960725784, 0.06487510353326797]\n",
      "2400 steps | score: [-0.016725458204746246, 0.04791000857949257]\n",
      "2500 steps | score: [-0.04162048175930977, 0.08342831581830978]\n",
      "2600 steps | score: [-0.05224395543336868, 0.08673187345266342]\n",
      "0 steps | score: [0.09968622028827667, 0.10319221019744873]\n",
      "100 steps | score: [-0.06368966400623322, 0.08052079379558563]\n",
      "200 steps | score: [-0.0019777133129537106, 0.016464928165078163]\n",
      "300 steps | score: [-0.08205607533454895, 0.0791109949350357]\n",
      "400 steps | score: [0.021869825199246407, -0.008893664926290512]\n",
      "500 steps | score: [-0.03906180337071419, 0.03443701192736626]\n",
      "600 steps | score: [-0.06069957837462425, 0.029801659286022186]\n",
      "700 steps | score: [-0.03518080338835716, 0.0373617485165596]\n",
      "800 steps | score: [-0.008258610032498837, 0.03990935906767845]\n",
      "900 steps | score: [0.024048415943980217, -0.05081553757190704]\n",
      "1000 steps | score: [0.014195175841450691, -0.03183679282665253]\n",
      "1100 steps | score: [-0.020963001996278763, 0.027864642441272736]\n",
      "1200 steps | score: [0.054770637303590775, -0.0736333429813385]\n",
      "1300 steps | score: [-0.05982039123773575, 0.05317838862538338]\n",
      "1400 steps | score: [-0.018711388111114502, 0.008140433579683304]\n",
      "1500 steps | score: [-0.03929850831627846, 0.042459212243556976]\n",
      "1600 steps | score: [-0.04092709720134735, 0.024334978312253952]\n",
      "1700 steps | score: [0.0006090599927119911, -0.007540606427937746]\n",
      "0 steps | score: [0.10186506062746048, 0.0803569033741951]\n",
      "100 steps | score: [-0.04325374960899353, 0.06132732704281807]\n",
      "200 steps | score: [-0.004018295090645552, -0.004535503685474396]\n",
      "unknown params:  tensor([-0.4381, -0.5898])\n",
      "unknown variance:  tensor([[0.9601]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4349, -0.5746])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.1420125961303711]\n",
      "100 steps | score: [-0.03751974180340767]\n",
      "200 steps | score: [0.07367335259914398]\n",
      "300 steps | score: [-0.03009471669793129]\n",
      "400 steps | score: [-0.06295192986726761]\n",
      "500 steps | score: [0.03234165906906128]\n",
      "600 steps | score: [-0.04248841106891632]\n",
      "700 steps | score: [-0.03379831835627556]\n",
      "800 steps | score: [0.004991494119167328]\n",
      "0 steps | score: [0.11512131243944168, 0.07279200851917267]\n",
      "100 steps | score: [-0.05928522348403931, 0.10552874207496643]\n",
      "200 steps | score: [0.08015991002321243, -0.08946540206670761]\n",
      "300 steps | score: [0.009562547318637371, -0.027583077549934387]\n",
      "400 steps | score: [-0.06917742639780045, 0.07995008677244186]\n",
      "500 steps | score: [0.10761761665344238, -0.15582163631916046]\n",
      "600 steps | score: [0.015342768281698227, -0.050720732659101486]\n",
      "700 steps | score: [-0.05701995640993118, 0.05699744075536728]\n",
      "800 steps | score: [0.107529416680336, -0.15050627291202545]\n",
      "900 steps | score: [0.015460778959095478, -0.039565540850162506]\n",
      "1000 steps | score: [-0.04336867108941078, 0.04745842143893242]\n",
      "1100 steps | score: [0.0797862559556961, -0.10585197806358337]\n",
      "1200 steps | score: [-0.008662194944918156, -0.024501733481884003]\n",
      "1300 steps | score: [-0.028830930590629578, 0.018228445202112198]\n",
      "1400 steps | score: [0.06998128443956375, -0.10473968088626862]\n",
      "1500 steps | score: [-0.014336841180920601, -0.007239510305225849]\n",
      "1600 steps | score: [-0.015691235661506653, -0.002320408821105957]\n",
      "1700 steps | score: [0.05013943836092949, -0.0894770622253418]\n",
      "1800 steps | score: [-0.009337381459772587, -0.012823144905269146]\n",
      "1900 steps | score: [-0.015289139933884144, -0.008241167291998863]\n",
      "2000 steps | score: [0.03839428722858429, -0.054245784878730774]\n",
      "2100 steps | score: [-0.010774496011435986, -0.01022273488342762]\n",
      "2200 steps | score: [-0.01635376736521721, -0.002719484269618988]\n",
      "2300 steps | score: [0.020124172791838646, -0.036282241344451904]\n",
      "2400 steps | score: [-0.010549118742346764, -0.004638868384063244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 steps | score: [-0.009385313838720322, -0.003997913561761379]\n",
      "0 steps | score: [0.17583496868610382, -0.016208050772547722]\n",
      "100 steps | score: [-0.01914992742240429, 0.052687570452690125]\n",
      "200 steps | score: [0.1499350517988205, -0.1885535567998886]\n",
      "300 steps | score: [0.03979576751589775, -0.0939721167087555]\n",
      "400 steps | score: [-0.016636041924357414, 0.007319130934774876]\n",
      "500 steps | score: [0.13469041883945465, -0.17811690270900726]\n",
      "600 steps | score: [0.04337095841765404, -0.095956951379776]\n",
      "700 steps | score: [-0.02356831729412079, 0.006198099814355373]\n",
      "800 steps | score: [0.15331989526748657, -0.20494703948497772]\n",
      "900 steps | score: [0.04404055327177048, -0.08686643838882446]\n",
      "1000 steps | score: [-0.00972731877118349, -0.010650279000401497]\n",
      "1100 steps | score: [0.12447957694530487, -0.17569652199745178]\n",
      "1200 steps | score: [0.03828626126050949, -0.082710862159729]\n",
      "1300 steps | score: [0.008061114698648453, -0.03632407262921333]\n",
      "1400 steps | score: [0.0923551470041275, -0.1418887823820114]\n",
      "1500 steps | score: [0.031787846237421036, -0.06972476094961166]\n",
      "1600 steps | score: [0.0287463441491127, -0.06136687844991684]\n",
      "1700 steps | score: [0.08959513157606125, -0.134154811501503]\n",
      "1800 steps | score: [0.01324537768959999, -0.05373936519026756]\n",
      "1900 steps | score: [0.018799899145960808, -0.05338118225336075]\n",
      "2000 steps | score: [0.07743211090564728, -0.11943388730287552]\n",
      "2100 steps | score: [0.02016824670135975, -0.054964691400527954]\n",
      "2200 steps | score: [0.02891872636973858, -0.05997104197740555]\n",
      "2300 steps | score: [0.04675678163766861, -0.08926215022802353]\n",
      "2400 steps | score: [0.018729379400610924, -0.05657153204083443]\n",
      "2500 steps | score: [0.025515811517834663, -0.06922899186611176]\n",
      "2600 steps | score: [0.048996035009622574, -0.08689460158348083]\n",
      "2700 steps | score: [0.021461693570017815, -0.06101061403751373]\n",
      "0 steps | score: [0.08788136392831802, 0.0713496133685112]\n",
      "100 steps | score: [-0.08122021704912186, 0.10008835792541504]\n",
      "200 steps | score: [0.06063735485076904, -0.09701307117938995]\n",
      "300 steps | score: [-0.017745960503816605, -0.024920279160141945]\n",
      "400 steps | score: [-0.10913624614477158, 0.0939951241016388]\n",
      "500 steps | score: [0.047671426087617874, -0.09949793666601181]\n",
      "600 steps | score: [-0.03124135173857212, -0.020928502082824707]\n",
      "700 steps | score: [-0.0861651822924614, 0.06913311779499054]\n",
      "800 steps | score: [0.06182931363582611, -0.11375036835670471]\n",
      "900 steps | score: [-0.03371003270149231, -0.010253085754811764]\n",
      "1000 steps | score: [-0.07811684906482697, 0.051126640290021896]\n",
      "1100 steps | score: [0.03691593185067177, -0.09181587398052216]\n",
      "1200 steps | score: [-0.041178200393915176, 0.0012586168013513088]\n",
      "1300 steps | score: [-0.06597200036048889, 0.032696668058633804]\n",
      "1400 steps | score: [0.02125408500432968, -0.06327623873949051]\n",
      "1500 steps | score: [-0.04674440622329712, 0.00677530886605382]\n",
      "1600 steps | score: [-0.058431971818208694, 0.030008062720298767]\n",
      "1700 steps | score: [0.0073481108993291855, -0.061158616095781326]\n",
      "1800 steps | score: [-0.05239762365818024, 0.01050539966672659]\n",
      "1900 steps | score: [-0.050815653055906296, 0.017976630479097366]\n",
      "2000 steps | score: [-0.010060066357254982, -0.028073996305465698]\n",
      "2100 steps | score: [-0.062416162341833115, 0.019262071698904037]\n",
      "2200 steps | score: [-0.05106068029999733, 0.014412352815270424]\n",
      "2300 steps | score: [-0.01664079912006855, -0.021613625809550285]\n",
      "2400 steps | score: [-0.049940623342990875, 0.013313866220414639]\n",
      "2500 steps | score: [-0.04352162778377533, 0.008416056632995605]\n",
      "2600 steps | score: [-0.016574637964367867, -0.015473161824047565]\n",
      "2700 steps | score: [-0.05152975767850876, 0.01619124412536621]\n",
      "unknown params:  tensor([-0.4783, -0.7707])\n",
      "unknown variance:  tensor([[1.0566]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4349, -0.5746])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.20780712366104126]\n",
      "100 steps | score: [-0.032687749713659286]\n",
      "200 steps | score: [0.032219551503658295]\n",
      "300 steps | score: [-0.02216869220137596]\n",
      "400 steps | score: [-0.06513212621212006]\n",
      "500 steps | score: [-0.060293152928352356]\n",
      "600 steps | score: [0.003024706616997719]\n",
      "0 steps | score: [0.17589791119098663, -0.06690789014101028]\n",
      "100 steps | score: [0.127899169921875, -0.16829416155815125]\n",
      "200 steps | score: [0.3117149770259857, -0.5740237832069397]\n",
      "300 steps | score: [0.022847888991236687, -0.09784992039203644]\n",
      "400 steps | score: [0.014077848754823208, -0.06115195155143738]\n",
      "500 steps | score: [-0.047244176268577576, -0.01614149659872055]\n",
      "600 steps | score: [0.09830605238676071, -0.21238817274570465]\n",
      "700 steps | score: [0.008577038533985615, -0.0703306794166565]\n",
      "800 steps | score: [-0.07436684519052505, 0.03774034231901169]\n",
      "900 steps | score: [0.011790470220148563, -0.07756015658378601]\n",
      "1000 steps | score: [0.11515837907791138, -0.23746037483215332]\n",
      "1100 steps | score: [0.02092641405761242, -0.10859374701976776]\n",
      "1200 steps | score: [0.04587629437446594, -0.1230098158121109]\n",
      "1300 steps | score: [0.1397264301776886, -0.2884381115436554]\n",
      "1400 steps | score: [0.019103923812508583, -0.09833085536956787]\n",
      "1500 steps | score: [-0.009185230359435081, -0.04291336610913277]\n",
      "1600 steps | score: [0.010293709114193916, -0.08852539956569672]\n",
      "1700 steps | score: [0.03555798530578613, -0.13954134285449982]\n",
      "1800 steps | score: [-0.003622644580900669, -0.06375035643577576]\n",
      "1900 steps | score: [-0.018680796027183533, -0.04092723876237869]\n",
      "2000 steps | score: [0.03763340413570404, -0.13343693315982819]\n",
      "2100 steps | score: [0.03073745407164097, -0.11795058846473694]\n",
      "2200 steps | score: [0.010526719503104687, -0.08609550446271896]\n",
      "2300 steps | score: [0.04614626616239548, -0.1290060579776764]\n",
      "2400 steps | score: [0.057571474462747574, -0.15742604434490204]\n",
      "2500 steps | score: [0.0257397573441267, -0.09884758293628693]\n",
      "2600 steps | score: [-0.002367127686738968, -0.07543015480041504]\n",
      "2700 steps | score: [0.02625875733792782, -0.12171764671802521]\n",
      "0 steps | score: [0.060719072818756104, 0.1309434473514557]\n",
      "100 steps | score: [0.04811747372150421, -0.01937396451830864]\n",
      "200 steps | score: [0.2216128259897232, -0.41781020164489746]\n",
      "300 steps | score: [-0.05163834989070892, 0.03285107761621475]\n",
      "400 steps | score: [-0.09015320986509323, 0.11126203835010529]\n",
      "500 steps | score: [-0.15079861879348755, 0.15557363629341125]\n",
      "600 steps | score: [0.001892625936307013, -0.05128128081560135]\n",
      "700 steps | score: [-0.08737283945083618, 0.09004263579845428]\n",
      "800 steps | score: [-0.16595350205898285, 0.19282519817352295]\n",
      "900 steps | score: [-0.07988369464874268, 0.07539243996143341]\n",
      "1000 steps | score: [0.03841213881969452, -0.0956142246723175]\n",
      "1100 steps | score: [-0.08273313194513321, 0.06194442883133888]\n",
      "1200 steps | score: [-0.04040355607867241, 0.029933465644717216]\n",
      "1300 steps | score: [0.051268305629491806, -0.11607912182807922]\n",
      "1400 steps | score: [-0.06922305375337601, 0.0515475831925869]\n",
      "1500 steps | score: [-0.100186787545681, 0.11705343425273895]\n",
      "1600 steps | score: [-0.06253420561552048, 0.040362581610679626]\n",
      "1700 steps | score: [-0.05066635459661484, 0.032163895666599274]\n",
      "1800 steps | score: [-0.09797421842813492, 0.10300322622060776]\n",
      "1900 steps | score: [-0.11865294724702835, 0.13563980162143707]\n",
      "2000 steps | score: [-0.05045940354466438, 0.029331285506486893]\n",
      "2100 steps | score: [-0.057789843529462814, 0.04641947150230408]\n",
      "2200 steps | score: [-0.08263419568538666, 0.07130788266658783]\n",
      "2300 steps | score: [-0.05031926929950714, 0.03236639127135277]\n",
      "2400 steps | score: [-0.01215020939707756, -0.01884223148226738]\n",
      "2500 steps | score: [-0.07398685067892075, 0.0669160932302475]\n",
      "2600 steps | score: [-0.08413183689117432, 0.07654720544815063]\n",
      "2700 steps | score: [-0.05235568434000015, 0.037371277809143066]\n",
      "0 steps | score: [0.13422410190105438, 0.1353328973054886]\n",
      "100 steps | score: [0.10324233770370483, -0.000924890860915184]\n",
      "200 steps | score: [0.2785717248916626, -0.39171385765075684]\n",
      "300 steps | score: [0.019559934735298157, 0.03604152053594589]\n",
      "400 steps | score: [-0.01970027945935726, 0.11992180347442627]\n",
      "500 steps | score: [-0.08371488004922867, 0.1680399477481842]\n",
      "600 steps | score: [0.04134359583258629, -0.013781405985355377]\n",
      "700 steps | score: [-0.026393771171569824, 0.1130680963397026]\n",
      "800 steps | score: [-0.09283582866191864, 0.18718089163303375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 steps | score: [-0.0040986244566738605, 0.0803944543004036]\n",
      "1000 steps | score: [0.09532396495342255, -0.06992156058549881]\n",
      "1100 steps | score: [-0.0020999459084123373, 0.06426741927862167]\n",
      "1200 steps | score: [0.031496841460466385, 0.02709590643644333]\n",
      "1300 steps | score: [0.0961751714348793, -0.09402450174093246]\n",
      "1400 steps | score: [0.003927231766283512, 0.059188634157180786]\n",
      "1500 steps | score: [-0.04521006718277931, 0.12591709196567535]\n",
      "1600 steps | score: [6.186225800774992e-05, 0.04954031854867935]\n",
      "1700 steps | score: [0.019377296790480614, 0.03048771806061268]\n",
      "1800 steps | score: [-0.023517681285738945, 0.0954340398311615]\n",
      "1900 steps | score: [-0.04084400832653046, 0.11538030952215195]\n",
      "2000 steps | score: [-0.005596507340669632, 0.06512275338172913]\n",
      "2100 steps | score: [-0.004426354076713324, 0.0719756931066513]\n",
      "2200 steps | score: [-0.017160965129733086, 0.09085610508918762]\n",
      "2300 steps | score: [0.010876074433326721, 0.05196228623390198]\n",
      "2400 steps | score: [0.029836952686309814, 0.010296298190951347]\n",
      "2500 steps | score: [-0.011534973978996277, 0.08672349154949188]\n",
      "2600 steps | score: [-0.014864791184663773, 0.0856512188911438]\n",
      "2700 steps | score: [0.017379626631736755, 0.032136283814907074]\n",
      "unknown params:  tensor([-0.5188, -0.9836])\n",
      "unknown variance:  tensor([[1.1692]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4349, -0.5746])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.24636919796466827]\n",
      "100 steps | score: [-0.036740493029356]\n",
      "200 steps | score: [0.03622262552380562]\n",
      "300 steps | score: [0.022283516824245453]\n",
      "400 steps | score: [-0.042318642139434814]\n",
      "500 steps | score: [-0.028764206916093826]\n",
      "600 steps | score: [-0.04263969510793686]\n",
      "700 steps | score: [-0.019928961992263794]\n",
      "800 steps | score: [0.030985865741968155]\n",
      "900 steps | score: [-0.017672337591648102]\n",
      "1000 steps | score: [-0.02877626195549965]\n",
      "1100 steps | score: [-0.0384436771273613]\n",
      "1200 steps | score: [0.011460945010185242]\n",
      "1300 steps | score: [-0.009365519508719444]\n",
      "0 steps | score: [0.15844355523586273, 0.05282743275165558]\n",
      "100 steps | score: [-0.09764055162668228, 0.27209511399269104]\n",
      "200 steps | score: [-0.035294391214847565, 0.09733861684799194]\n",
      "300 steps | score: [-0.0213888268917799, 0.09890108555555344]\n",
      "400 steps | score: [-0.03974941745400429, 0.12828843295574188]\n",
      "500 steps | score: [-0.10233369469642639, 0.18468722701072693]\n",
      "600 steps | score: [-0.07903818041086197, 0.1638973206281662]\n",
      "700 steps | score: [-0.09573939442634583, 0.1736067235469818]\n",
      "800 steps | score: [0.2481241375207901, -0.4404508173465729]\n",
      "900 steps | score: [-0.020310938358306885, 0.08329063653945923]\n",
      "1000 steps | score: [0.07811588793992996, -0.1045047864317894]\n",
      "1100 steps | score: [-0.047832101583480835, 0.1027909591794014]\n",
      "1200 steps | score: [-0.08480808883905411, 0.15538960695266724]\n",
      "1300 steps | score: [0.041181620210409164, -0.03256092593073845]\n",
      "1400 steps | score: [0.07309756428003311, -0.08525140583515167]\n",
      "1500 steps | score: [0.004407544154673815, 0.0017496906220912933]\n",
      "0 steps | score: [0.16718003153800964, 0.0008879965171217918]\n",
      "100 steps | score: [-0.11374479532241821, 0.2626602053642273]\n",
      "200 steps | score: [-0.025906287133693695, 0.0519196018576622]\n",
      "300 steps | score: [-0.03505420684814453, 0.07526348531246185]\n",
      "400 steps | score: [-0.05045657977461815, 0.10380277037620544]\n",
      "500 steps | score: [-0.1204889640212059, 0.17993101477622986]\n",
      "600 steps | score: [-0.08402549475431442, 0.1382199078798294]\n",
      "700 steps | score: [-0.10975740104913712, 0.16687576472759247]\n",
      "800 steps | score: [0.28868043422698975, -0.5511420965194702]\n",
      "900 steps | score: [0.0038781247567385435, 0.0023255501873791218]\n",
      "0 steps | score: [0.26577043533325195, -0.11273496598005295]\n",
      "100 steps | score: [-0.005267295520752668, 0.1289650797843933]\n",
      "200 steps | score: [0.053752996027469635, -0.0373576357960701]\n",
      "300 steps | score: [0.0663832426071167, -0.042750779539346695]\n",
      "400 steps | score: [0.052295323461294174, -0.02158980816602707]\n",
      "500 steps | score: [-0.018387725576758385, 0.06810744851827621]\n",
      "600 steps | score: [-0.0111406110227108, 0.05177810788154602]\n",
      "700 steps | score: [-0.013518421910703182, 0.053824253380298615]\n",
      "800 steps | score: [0.32691898941993713, -0.5618283152580261]\n",
      "900 steps | score: [0.07668184489011765, -0.07211469113826752]\n",
      "1000 steps | score: [0.1405949592590332, -0.218134343624115]\n",
      "1100 steps | score: [0.03593318536877632, -0.00912809744477272]\n",
      "1200 steps | score: [0.002917238511145115, 0.02382039651274681]\n",
      "1300 steps | score: [0.12014637887477875, -0.1795278787612915]\n",
      "1400 steps | score: [0.16333907842636108, -0.23680882155895233]\n",
      "1500 steps | score: [0.11663658916950226, -0.16686475276947021]\n",
      "1600 steps | score: [0.013726551085710526, 0.020653825253248215]\n",
      "1700 steps | score: [0.055959828197956085, -0.04706547036767006]\n",
      "1800 steps | score: [0.0987808033823967, -0.1283896118402481]\n",
      "1900 steps | score: [0.14040839672088623, -0.2007351666688919]\n",
      "2000 steps | score: [0.08192849159240723, -0.10329528898000717]\n",
      "2100 steps | score: [0.06856665015220642, -0.0682903379201889]\n",
      "2200 steps | score: [0.05942034721374512, -0.06543555110692978]\n",
      "2300 steps | score: [0.08216632902622223, -0.10421473532915115]\n",
      "2400 steps | score: [0.09370032697916031, -0.12526600062847137]\n",
      "2500 steps | score: [0.06972263008356094, -0.08941389620304108]\n",
      "2600 steps | score: [0.05779722332954407, -0.05505617707967758]\n",
      "2700 steps | score: [0.08856460452079773, -0.11060087382793427]\n",
      "unknown params:  tensor([-0.5546, -1.2346])\n",
      "unknown variance:  tensor([[1.3111]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4349, -0.5746])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.19663025438785553]\n",
      "100 steps | score: [-0.08897584676742554]\n",
      "200 steps | score: [-0.11139721423387527]\n",
      "300 steps | score: [-0.052407242357730865]\n",
      "400 steps | score: [-0.05501236021518707]\n",
      "500 steps | score: [-0.06257205456495285]\n",
      "600 steps | score: [-0.022182432934641838]\n",
      "700 steps | score: [-0.03424054756760597]\n",
      "800 steps | score: [-0.027387361973524094]\n",
      "900 steps | score: [-0.06808888167142868]\n",
      "1000 steps | score: [-0.12947878241539001]\n",
      "1100 steps | score: [-0.07264173030853271]\n",
      "1200 steps | score: [-0.0783746987581253]\n",
      "1300 steps | score: [-0.09068372845649719]\n",
      "1400 steps | score: [-0.06741635501384735]\n",
      "1500 steps | score: [-0.07391394674777985]\n",
      "1600 steps | score: [-0.06701565533876419]\n",
      "1700 steps | score: [-0.06927117705345154]\n",
      "1800 steps | score: [-0.08461952209472656]\n",
      "1900 steps | score: [-0.07558798044919968]\n",
      "2000 steps | score: [-0.07181878387928009]\n",
      "2100 steps | score: [-0.08250738680362701]\n",
      "2200 steps | score: [-0.09059455990791321]\n",
      "2300 steps | score: [-0.08876673877239227]\n",
      "2400 steps | score: [-0.0978131890296936]\n",
      "2500 steps | score: [-0.0685284361243248]\n",
      "2600 steps | score: [-0.0934748724102974]\n",
      "0 steps | score: [0.052248816937208176, 0.22575099766254425]\n",
      "100 steps | score: [-0.11109083145856857, 0.366884708404541]\n",
      "200 steps | score: [-0.2453002780675888, 0.5206528306007385]\n",
      "300 steps | score: [-0.06869127601385117, 0.2082815021276474]\n",
      "400 steps | score: [-0.18376022577285767, 0.37960171699523926]\n",
      "500 steps | score: [-0.18743804097175598, 0.3940853476524353]\n",
      "600 steps | score: [0.07668226957321167, -0.13822489976882935]\n",
      "700 steps | score: [-0.03662693500518799, 0.12592008709907532]\n",
      "800 steps | score: [0.04938315600156784, -0.05159858614206314]\n",
      "900 steps | score: [-0.1570746749639511, 0.34217846393585205]\n",
      "1000 steps | score: [-0.15127010643482208, 0.33306699991226196]\n",
      "1100 steps | score: [-0.03309791535139084, 0.09124429523944855]\n",
      "1200 steps | score: [-0.14988581836223602, 0.32643797993659973]\n",
      "1300 steps | score: [-0.12602759897708893, 0.2724243402481079]\n",
      "1400 steps | score: [-0.1305951029062271, 0.285480260848999]\n",
      "1500 steps | score: [-0.13615652918815613, 0.2920745313167572]\n",
      "1600 steps | score: [-0.1633918583393097, 0.34565621614456177]\n",
      "1700 steps | score: [-0.023501811549067497, 0.08264025300741196]\n",
      "1800 steps | score: [-0.07592906057834625, 0.1738026887178421]\n",
      "1900 steps | score: [-0.06695912778377533, 0.161173015832901]\n",
      "2000 steps | score: [-0.07261060178279877, 0.17411519587039948]\n",
      "2100 steps | score: [-0.12821179628372192, 0.27058863639831543]\n",
      "2200 steps | score: [-0.0848638266324997, 0.19352194666862488]\n",
      "2300 steps | score: [-0.11550899595022202, 0.24680180847644806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 steps | score: [-0.09686066955327988, 0.2187456488609314]\n",
      "2500 steps | score: [-0.11440691351890564, 0.2577991485595703]\n",
      "2600 steps | score: [-0.14010845124721527, 0.29905930161476135]\n",
      "0 steps | score: [0.19586122035980225, -0.033470772206783295]\n",
      "100 steps | score: [0.00955501664429903, 0.14825443923473358]\n",
      "200 steps | score: [-0.12416093796491623, 0.29724591970443726]\n",
      "300 steps | score: [-0.006666610017418861, 0.09086135029792786]\n",
      "400 steps | score: [-0.05434948578476906, 0.15000909566879272]\n",
      "500 steps | score: [-0.06972862780094147, 0.18739904463291168]\n",
      "600 steps | score: [0.19120723009109497, -0.33961009979248047]\n",
      "700 steps | score: [0.04338952526450157, -0.014905672520399094]\n",
      "800 steps | score: [0.1711229532957077, -0.28209683299064636]\n",
      "900 steps | score: [-0.038269005715847015, 0.12547066807746887]\n",
      "1000 steps | score: [-0.05520106106996536, 0.14663833379745483]\n",
      "1100 steps | score: [0.08120029419660568, -0.11768362671136856]\n",
      "1200 steps | score: [-0.04124276712536812, 0.12033825367689133]\n",
      "1300 steps | score: [-0.03018304891884327, 0.10232876241207123]\n",
      "1400 steps | score: [-0.041952572762966156, 0.1170692890882492]\n",
      "1500 steps | score: [-0.011935231275856495, 0.07420249283313751]\n",
      "1600 steps | score: [-0.04812059551477432, 0.1317456066608429]\n",
      "1700 steps | score: [0.08503543585538864, -0.12782761454582214]\n",
      "1800 steps | score: [0.047390736639499664, -0.038913294672966]\n",
      "1900 steps | score: [0.0461789071559906, -0.04256404936313629]\n",
      "2000 steps | score: [0.0218015406280756, 0.0009184889495372772]\n",
      "2100 steps | score: [-0.01903294213116169, 0.08392004668712616]\n",
      "2200 steps | score: [0.022176727652549744, -0.0027593616396188736]\n",
      "2300 steps | score: [0.0014224472688511014, 0.046161949634552]\n",
      "2400 steps | score: [0.006640364415943623, 0.02182812988758087]\n",
      "2500 steps | score: [-0.005412031896412373, 0.04966283589601517]\n",
      "2600 steps | score: [-0.02941315621137619, 0.08995377272367477]\n",
      "0 steps | score: [0.21129846572875977, -0.16490961611270905]\n",
      "100 steps | score: [0.000996802351437509, 0.0668872520327568]\n",
      "200 steps | score: [-0.11307374387979507, 0.18486332893371582]\n",
      "300 steps | score: [0.04862137511372566, -0.09647480398416519]\n",
      "400 steps | score: [-0.05263831838965416, 0.0555286705493927]\n",
      "500 steps | score: [-0.04724375158548355, 0.05822360888123512]\n",
      "600 steps | score: [0.21541143953800201, -0.4661889970302582]\n",
      "700 steps | score: [0.0863303393125534, -0.17997300624847412]\n",
      "800 steps | score: [0.17174340784549713, -0.36798685789108276]\n",
      "900 steps | score: [-0.05508020147681236, 0.053455278277397156]\n",
      "1000 steps | score: [-0.031374938786029816, 0.02029607631266117]\n",
      "1100 steps | score: [0.0877189114689827, -0.21596214175224304]\n",
      "1200 steps | score: [-0.03383297100663185, 0.009782703593373299]\n",
      "1300 steps | score: [-0.0176542941480875, -0.021640025079250336]\n",
      "1400 steps | score: [-0.030857190489768982, 0.011221349239349365]\n",
      "1500 steps | score: [-0.023859387263655663, -0.006670008413493633]\n",
      "1600 steps | score: [-0.04578766971826553, 0.03385394066572189]\n",
      "1700 steps | score: [0.11257252097129822, -0.26306939125061035]\n",
      "1800 steps | score: [0.07200851291418076, -0.1725073754787445]\n",
      "1900 steps | score: [0.06558822095394135, -0.16678038239479065]\n",
      "2000 steps | score: [0.034234218299388885, -0.1069796234369278]\n",
      "2100 steps | score: [-0.014251980930566788, -0.01929250732064247]\n",
      "2200 steps | score: [0.03904074430465698, -0.12784704566001892]\n",
      "2300 steps | score: [0.0008835189510136843, -0.05143541842699051]\n",
      "2400 steps | score: [0.044754255563020706, -0.1349920928478241]\n",
      "2500 steps | score: [0.004819338209927082, -0.06364437937736511]\n",
      "2600 steps | score: [-0.015122584067285061, -0.02112434431910515]\n",
      "unknown params:  tensor([-0.5262, -1.2621])\n",
      "unknown variance:  tensor([[1.4472]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4349, -0.5746])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3281622529029846]\n",
      "100 steps | score: [0.06945255398750305]\n",
      "200 steps | score: [0.0760270208120346]\n",
      "300 steps | score: [0.03648325800895691]\n",
      "400 steps | score: [0.043261781334877014]\n",
      "500 steps | score: [0.036659881472587585]\n",
      "600 steps | score: [0.046648263931274414]\n",
      "700 steps | score: [0.05622631311416626]\n",
      "800 steps | score: [0.046109821647405624]\n",
      "900 steps | score: [0.05337843671441078]\n",
      "1000 steps | score: [0.05926825851202011]\n",
      "1100 steps | score: [0.0880526602268219]\n",
      "1200 steps | score: [0.06164717674255371]\n",
      "1300 steps | score: [0.058494728058576584]\n",
      "1400 steps | score: [0.0627179741859436]\n",
      "1500 steps | score: [0.06512196362018585]\n",
      "1600 steps | score: [0.05131801217794418]\n",
      "1700 steps | score: [0.06128714978694916]\n",
      "1800 steps | score: [0.05852344259619713]\n",
      "1900 steps | score: [0.08329349756240845]\n",
      "2000 steps | score: [0.02921057492494583]\n",
      "2100 steps | score: [0.04482928290963173]\n",
      "2200 steps | score: [0.06488753110170364]\n",
      "2300 steps | score: [0.034312717616558075]\n",
      "2400 steps | score: [0.021229185163974762]\n",
      "2500 steps | score: [0.03730810806155205]\n",
      "2600 steps | score: [0.0485401526093483]\n",
      "0 steps | score: [0.1842179000377655, -0.05317816138267517]\n",
      "100 steps | score: [0.23083873093128204, -0.2459762543439865]\n",
      "200 steps | score: [0.1409223973751068, -0.16184459626674652]\n",
      "300 steps | score: [-0.030797641724348068, 0.16070550680160522]\n",
      "400 steps | score: [-0.010004216805100441, 0.08569260686635971]\n",
      "500 steps | score: [-0.039302293211221695, 0.1549593061208725]\n",
      "600 steps | score: [-0.04963507875800133, 0.15410205721855164]\n",
      "700 steps | score: [0.3503831923007965, -0.7463574409484863]\n",
      "800 steps | score: [0.0513731874525547, -0.06132175028324127]\n",
      "900 steps | score: [0.0737852081656456, -0.10199388861656189]\n",
      "1000 steps | score: [-0.029226873070001602, 0.10733992606401443]\n",
      "1100 steps | score: [0.24770468473434448, -0.5239412784576416]\n",
      "1200 steps | score: [0.0473647303879261, -0.05392763763666153]\n",
      "1300 steps | score: [0.07651213556528091, -0.10639962553977966]\n",
      "1400 steps | score: [-0.025616541504859924, 0.1013990044593811]\n",
      "1500 steps | score: [0.03749144449830055, -0.04134243354201317]\n",
      "1600 steps | score: [-0.07806727290153503, 0.19918309152126312]\n",
      "1700 steps | score: [-0.03840934857726097, 0.12085580825805664]\n",
      "1800 steps | score: [0.00613788329064846, 0.03287552669644356]\n",
      "1900 steps | score: [-0.04124698415398598, 0.12200051546096802]\n",
      "2000 steps | score: [-0.05813444033265114, 0.1634964644908905]\n",
      "2100 steps | score: [-0.03638778254389763, 0.10626956820487976]\n",
      "2200 steps | score: [-0.015759045258164406, 0.07623054087162018]\n",
      "2300 steps | score: [-0.010075574740767479, 0.07847990095615387]\n",
      "2400 steps | score: [-0.033689986914396286, 0.1137898862361908]\n",
      "2500 steps | score: [-0.01131234597414732, 0.05769079551100731]\n",
      "2600 steps | score: [-0.02218959853053093, 0.0902356207370758]\n",
      "0 steps | score: [0.19897697865962982, -0.11949040740728378]\n",
      "100 steps | score: [0.2397172451019287, -0.29133766889572144]\n",
      "200 steps | score: [0.12693028151988983, -0.1711810976266861]\n",
      "300 steps | score: [-0.01190260425209999, 0.08711148798465729]\n",
      "400 steps | score: [-0.026396017521619797, 0.09472927451133728]\n",
      "500 steps | score: [-0.0491202138364315, 0.1388232558965683]\n",
      "600 steps | score: [-0.047430504113435745, 0.11506527662277222]\n",
      "700 steps | score: [0.3689214289188385, -0.8029735088348389]\n",
      "800 steps | score: [0.07694188505411148, -0.1438540369272232]\n",
      "900 steps | score: [0.047055747359991074, -0.08410847187042236]\n",
      "1000 steps | score: [-0.028049135580658913, 0.08372224122285843]\n",
      "1100 steps | score: [0.2784309685230255, -0.6222233772277832]\n",
      "1200 steps | score: [0.055216290056705475, -0.09969111531972885]\n",
      "1300 steps | score: [0.07568816840648651, -0.1427372694015503]\n",
      "1400 steps | score: [-0.032006606459617615, 0.08576983958482742]\n",
      "1500 steps | score: [0.024663874879479408, -0.04722313955426216]\n",
      "1600 steps | score: [-0.06792888045310974, 0.1608484834432602]\n",
      "1700 steps | score: [-0.025227263569831848, 0.06212271749973297]\n",
      "1800 steps | score: [0.008700363337993622, -0.010253497399389744]\n",
      "1900 steps | score: [-0.05332401022315025, 0.1231653168797493]\n",
      "2000 steps | score: [-0.04234706237912178, 0.0984891802072525]\n",
      "2100 steps | score: [-0.027715541422367096, 0.07411883026361465]\n",
      "2200 steps | score: [-0.017479991540312767, 0.053873028606176376]\n",
      "2300 steps | score: [-0.0259195938706398, 0.07094073295593262]\n",
      "2400 steps | score: [-0.022313667461276054, 0.07248851656913757]\n",
      "2500 steps | score: [-0.005208947695791721, 0.015342116355895996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600 steps | score: [-0.01057853177189827, 0.03926471248269081]\n",
      "0 steps | score: [0.2322324514389038, -0.19605964422225952]\n",
      "100 steps | score: [0.2868647575378418, -0.40227246284484863]\n",
      "200 steps | score: [0.16193662583827972, -0.26058727502822876]\n",
      "300 steps | score: [0.01754169352352619, 0.01667267084121704]\n",
      "400 steps | score: [0.013904259540140629, -0.00438738614320755]\n",
      "500 steps | score: [0.007911487482488155, 0.014656435698270798]\n",
      "600 steps | score: [-0.031430017203092575, 0.06011293828487396]\n",
      "700 steps | score: [0.398136168718338, -0.8781817555427551]\n",
      "800 steps | score: [0.10215786099433899, -0.20657514035701752]\n",
      "900 steps | score: [0.06802432984113693, -0.12834639847278595]\n",
      "1000 steps | score: [0.03930144011974335, -0.07372952252626419]\n",
      "1100 steps | score: [0.25132331252098083, -0.5674919486045837]\n",
      "1200 steps | score: [0.09288300573825836, -0.1886957585811615]\n",
      "1300 steps | score: [0.12020663172006607, -0.23982366919517517]\n",
      "1400 steps | score: [-0.0091437678784132, 0.01688103750348091]\n",
      "1500 steps | score: [0.06781809031963348, -0.13278886675834656]\n",
      "1600 steps | score: [-0.046170733869075775, 0.09266512095928192]\n",
      "1700 steps | score: [0.030003881081938744, -0.058294884860515594]\n",
      "1800 steps | score: [0.08318959921598434, -0.16123023629188538]\n",
      "1900 steps | score: [-0.012764861807227135, 0.022732911631464958]\n",
      "2000 steps | score: [-0.021194063127040863, 0.04573488608002663]\n",
      "2100 steps | score: [-0.00021316441416274756, -0.006830617785453796]\n",
      "unknown params:  tensor([-0.5103, -1.3357])\n",
      "unknown variance:  tensor([[1.5841]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/5c1df0a1-51bc-4fa0-bb16-265cd7c55ccd\n",
      "gt params:  tensor([-0.4261, -0.5882])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.10202524065971375]\n",
      "100 steps | score: [0.007322065532207489]\n",
      "0 steps | score: [0.017199978232383728, 0.08503133803606033]\n",
      "100 steps | score: [0.026724129915237427, -0.012837288901209831]\n",
      "200 steps | score: [0.01044178195297718, -0.008810415863990784]\n",
      "300 steps | score: [0.014319377020001411, 0.03523771092295647]\n",
      "400 steps | score: [-0.013246949762105942, 0.06808292865753174]\n",
      "500 steps | score: [0.011787218041718006, 0.033305805176496506]\n",
      "600 steps | score: [-0.044989123940467834, 0.011148137971758842]\n",
      "700 steps | score: [0.02070503868162632, 0.05368715152144432]\n",
      "800 steps | score: [-0.02709086425602436, 0.000604639295488596]\n",
      "900 steps | score: [-0.01921781338751316, 0.0020026573911309242]\n",
      "1000 steps | score: [0.01145776268094778, 0.01860707998275757]\n",
      "1100 steps | score: [0.012093755416572094, 0.004540933296084404]\n",
      "1200 steps | score: [-0.013327145017683506, 0.03149094060063362]\n",
      "1300 steps | score: [-0.02447964809834957, 0.038088589906692505]\n",
      "1400 steps | score: [-0.019766509532928467, 0.035499341785907745]\n",
      "1500 steps | score: [-0.025681518018245697, 0.04096589237451553]\n",
      "1600 steps | score: [-0.00585104851052165, 0.04080589860677719]\n",
      "1700 steps | score: [-0.018662484362721443, 0.014276737347245216]\n",
      "1800 steps | score: [-0.021270394325256348, 0.020994087681174278]\n",
      "1900 steps | score: [-0.0019966368563473225, 0.028170986101031303]\n",
      "2000 steps | score: [-0.008640346117317677, 0.03359583020210266]\n",
      "2100 steps | score: [-0.011086204089224339, 0.03339795023202896]\n",
      "2200 steps | score: [-0.013669736683368683, 0.03511462360620499]\n",
      "2300 steps | score: [-0.011796697042882442, 0.03254478797316551]\n",
      "2400 steps | score: [-0.008938306011259556, 0.027936818078160286]\n",
      "2500 steps | score: [-0.0027016783133149147, 0.030414734035730362]\n",
      "2600 steps | score: [-0.02015143632888794, 0.026922371238470078]\n",
      "0 steps | score: [0.0025757616385817528, 0.017473701387643814]\n",
      "100 steps | score: [0.01433192752301693, -0.05661267042160034]\n",
      "200 steps | score: [-0.008188010193407536, -0.06423738598823547]\n",
      "300 steps | score: [0.007291099056601524, -0.023030918091535568]\n",
      "400 steps | score: [-0.02988700196146965, 0.018745681270956993]\n",
      "500 steps | score: [0.0035478624049574137, -0.028246253728866577]\n",
      "600 steps | score: [-0.0545000359416008, -0.04474911838769913]\n",
      "700 steps | score: [0.0077900332398712635, -0.0016874377615749836]\n",
      "0 steps | score: [-0.0010600045789033175, 0.03293826803565025]\n",
      "100 steps | score: [0.005757520906627178, -0.05591413378715515]\n",
      "200 steps | score: [-0.00807486567646265, -0.05217510834336281]\n",
      "300 steps | score: [0.003672191873192787, -0.008518031798303127]\n",
      "unknown params:  tensor([-0.3907, -0.4228])\n",
      "unknown variance:  tensor([[0.8477]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4261, -0.5882])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3311823308467865]\n",
      "100 steps | score: [0.1816277801990509]\n",
      "200 steps | score: [0.2114010751247406]\n",
      "300 steps | score: [0.1856408566236496]\n",
      "400 steps | score: [0.25064176321029663]\n",
      "500 steps | score: [0.21522197127342224]\n",
      "600 steps | score: [0.2190396785736084]\n",
      "700 steps | score: [0.16511434316635132]\n",
      "800 steps | score: [0.20160169899463654]\n",
      "900 steps | score: [0.22785356640815735]\n",
      "1000 steps | score: [0.24294574558734894]\n",
      "1100 steps | score: [0.14373989403247833]\n",
      "1200 steps | score: [0.1875569373369217]\n",
      "1300 steps | score: [0.21347501873970032]\n",
      "1400 steps | score: [0.22873368859291077]\n",
      "1500 steps | score: [0.17479071021080017]\n",
      "1600 steps | score: [0.18826359510421753]\n",
      "1700 steps | score: [0.20872507989406586]\n",
      "1800 steps | score: [0.23019899427890778]\n",
      "1900 steps | score: [0.19090577960014343]\n",
      "2000 steps | score: [0.17603735625743866]\n",
      "2100 steps | score: [0.20230956375598907]\n",
      "2200 steps | score: [0.19920960068702698]\n",
      "2300 steps | score: [0.17175397276878357]\n",
      "2400 steps | score: [0.16342802345752716]\n",
      "2500 steps | score: [0.17351463437080383]\n",
      "2600 steps | score: [0.20135769248008728]\n",
      "2700 steps | score: [0.17965732514858246]\n",
      "2800 steps | score: [0.18793189525604248]\n",
      "0 steps | score: [0.011718476191163063, 0.12544161081314087]\n",
      "100 steps | score: [-0.041043706238269806, 0.06091359257698059]\n",
      "200 steps | score: [-0.03800376132130623, 0.04792872443795204]\n",
      "300 steps | score: [-0.06326093524694443, 0.03630997985601425]\n",
      "400 steps | score: [-0.008221512660384178, -0.012097770348191261]\n",
      "500 steps | score: [-0.024719806388020515, 0.028762944042682648]\n",
      "600 steps | score: [-0.015845181420445442, 0.026477079838514328]\n",
      "700 steps | score: [-0.048289455473423004, 0.03794092684984207]\n",
      "800 steps | score: [-0.03164445236325264, 0.01153571903705597]\n",
      "900 steps | score: [-0.026612363755702972, 0.020207606256008148]\n",
      "1000 steps | score: [-0.016560804098844528, 0.03497708961367607]\n",
      "1100 steps | score: [-0.055503178387880325, 0.048092491924762726]\n",
      "1200 steps | score: [-0.04492361471056938, 0.020112231373786926]\n",
      "1300 steps | score: [-0.034106962382793427, 0.015935838222503662]\n",
      "1400 steps | score: [-0.018191955983638763, 0.02807878889143467]\n",
      "1500 steps | score: [-0.043861690908670425, 0.043266914784908295]\n",
      "1600 steps | score: [-0.04636044055223465, 0.038596633821725845]\n",
      "1700 steps | score: [-0.038860127329826355, 0.018302002921700478]\n",
      "1800 steps | score: [-0.026065248996019363, 0.02303677424788475]\n",
      "1900 steps | score: [-0.05422048643231392, 0.050888169556856155]\n",
      "2000 steps | score: [-0.060494791716337204, 0.03908543288707733]\n",
      "2100 steps | score: [-0.040278442203998566, 0.026780616492033005]\n",
      "2200 steps | score: [-0.023280231282114983, 0.028573859483003616]\n",
      "2300 steps | score: [-0.04524324834346771, 0.037774138152599335]\n",
      "2400 steps | score: [-0.046331994235515594, 0.04035726562142372]\n",
      "2500 steps | score: [-0.03433138132095337, 0.02369859255850315]\n",
      "2600 steps | score: [-0.028760043904185295, 0.031784538179636]\n",
      "2700 steps | score: [-0.04629529267549515, 0.04146278649568558]\n",
      "2800 steps | score: [-0.048571448773145676, 0.03653263673186302]\n",
      "0 steps | score: [0.11738909780979156, 0.07811622321605682]\n",
      "100 steps | score: [0.05205366387963295, 0.015533636324107647]\n",
      "200 steps | score: [0.04399048909544945, 0.003204616717994213]\n",
      "300 steps | score: [0.027127699926495552, -0.0038215629756450653]\n",
      "400 steps | score: [0.08228950947523117, -0.05655447021126747]\n",
      "500 steps | score: [0.06879106163978577, -0.010352445766329765]\n",
      "600 steps | score: [0.06552326679229736, 0.0024122782051563263]\n",
      "700 steps | score: [0.039587460458278656, 0.0063347769901156425]\n",
      "800 steps | score: [0.056376613676548004, -0.019253771752119064]\n",
      "900 steps | score: [0.0726063922047615, -0.02494306117296219]\n",
      "1000 steps | score: [0.07637228071689606, -0.006729776971042156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 steps | score: [0.025913622230291367, 0.010844973847270012]\n",
      "1200 steps | score: [0.04212379455566406, -0.009872294962406158]\n",
      "1300 steps | score: [0.05734247714281082, -0.016677962616086006]\n",
      "1400 steps | score: [0.0723162442445755, -0.007664581760764122]\n",
      "1500 steps | score: [0.04124806448817253, 0.008644785732030869]\n",
      "1600 steps | score: [0.03638654574751854, 0.006011682562530041]\n",
      "1700 steps | score: [0.05633530020713806, -0.021446354687213898]\n",
      "1800 steps | score: [0.07603399455547333, -0.00963557418435812]\n",
      "1900 steps | score: [0.041568823158741, 0.008285881951451302]\n",
      "2000 steps | score: [0.04063994064927101, 0.005690061487257481]\n",
      "2100 steps | score: [0.053257931023836136, -0.010945798829197884]\n",
      "2200 steps | score: [0.061103545129299164, -0.008221752941608429]\n",
      "2300 steps | score: [0.049423303455114365, 0.0013121897354722023]\n",
      "2400 steps | score: [0.03770788758993149, 0.008543587289750576]\n",
      "2500 steps | score: [0.04848811775445938, -0.01261947676539421]\n",
      "2600 steps | score: [0.05711748078465462, -0.009591473266482353]\n",
      "2700 steps | score: [0.048925306648015976, -0.004299946129322052]\n",
      "2800 steps | score: [0.040390495210886, -0.001476231962442398]\n",
      "0 steps | score: [0.11202085763216019, 0.03659505769610405]\n",
      "100 steps | score: [0.0349898636341095, -0.018071575090289116]\n",
      "200 steps | score: [0.04351506382226944, -0.024173522368073463]\n",
      "300 steps | score: [0.011282900348305702, -0.030455341562628746]\n",
      "400 steps | score: [0.08403941243886948, -0.08755231648683548]\n",
      "500 steps | score: [0.05418676882982254, -0.03921274468302727]\n",
      "600 steps | score: [0.06658919900655746, -0.04112869128584862]\n",
      "700 steps | score: [0.030747579410672188, -0.027959231287240982]\n",
      "800 steps | score: [0.04671378806233406, -0.05742393806576729]\n",
      "900 steps | score: [0.05318141356110573, -0.04716093838214874]\n",
      "1000 steps | score: [0.06306924670934677, -0.03727375343441963]\n",
      "1100 steps | score: [0.022303292527794838, -0.01742144115269184]\n",
      "1200 steps | score: [0.038422420620918274, -0.046229325234889984]\n",
      "1300 steps | score: [0.04123391956090927, -0.05195469781756401]\n",
      "1400 steps | score: [0.0590144544839859, -0.037781402468681335]\n",
      "1500 steps | score: [0.03268613666296005, -0.025671126320958138]\n",
      "1600 steps | score: [0.024859342724084854, -0.029611963778734207]\n",
      "1700 steps | score: [0.05009275674819946, -0.04983674734830856]\n",
      "1800 steps | score: [0.05391974374651909, -0.03928433358669281]\n",
      "1900 steps | score: [0.036169715225696564, -0.027917716652154922]\n",
      "2000 steps | score: [0.02787349373102188, -0.02633809484541416]\n",
      "2100 steps | score: [0.04196932911872864, -0.04366196691989899]\n",
      "2200 steps | score: [0.051065247505903244, -0.04307647794485092]\n",
      "2300 steps | score: [0.03995134308934212, -0.029870927333831787]\n",
      "2400 steps | score: [0.030244383960962296, -0.03280148282647133]\n",
      "2500 steps | score: [0.04219847545027733, -0.04711664095520973]\n",
      "2600 steps | score: [0.05039779469370842, -0.04568520933389664]\n",
      "2700 steps | score: [0.02977118268609047, -0.030038010329008102]\n",
      "2800 steps | score: [0.03201759606599808, -0.034100886434316635]\n",
      "unknown params:  tensor([-0.3983, -0.4624])\n",
      "unknown variance:  tensor([[0.9087]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4261, -0.5882])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.20651887357234955]\n",
      "100 steps | score: [0.09798729419708252]\n",
      "200 steps | score: [0.01165491621941328]\n",
      "300 steps | score: [0.11747623980045319]\n",
      "400 steps | score: [0.011737392283976078]\n",
      "500 steps | score: [0.1354217827320099]\n",
      "600 steps | score: [0.08736434578895569]\n",
      "700 steps | score: [0.04464804008603096]\n",
      "800 steps | score: [0.053205423057079315]\n",
      "900 steps | score: [0.0810721218585968]\n",
      "1000 steps | score: [0.088520348072052]\n",
      "1100 steps | score: [0.01852548122406006]\n",
      "1200 steps | score: [0.05848260596394539]\n",
      "1300 steps | score: [0.07938733696937561]\n",
      "1400 steps | score: [0.07511352747678757]\n",
      "1500 steps | score: [0.03987904638051987]\n",
      "1600 steps | score: [0.090497225522995]\n",
      "1700 steps | score: [0.12380436807870865]\n",
      "1800 steps | score: [0.08099343627691269]\n",
      "1900 steps | score: [0.07764878869056702]\n",
      "2000 steps | score: [0.08434302359819412]\n",
      "2100 steps | score: [0.09658528864383698]\n",
      "2200 steps | score: [0.0940762385725975]\n",
      "2300 steps | score: [0.05280260369181633]\n",
      "2400 steps | score: [0.09129494428634644]\n",
      "2500 steps | score: [0.06539922207593918]\n",
      "2600 steps | score: [0.08876322209835052]\n",
      "0 steps | score: [0.054384686052799225, 0.10902157425880432]\n",
      "100 steps | score: [-0.004459052346646786, 0.015986368060112]\n",
      "200 steps | score: [-0.07280765473842621, 0.09463325142860413]\n",
      "300 steps | score: [0.004050697200000286, -0.03153088688850403]\n",
      "400 steps | score: [-0.07401429861783981, 0.010854152962565422]\n",
      "500 steps | score: [0.04653109237551689, -0.05185014009475708]\n",
      "600 steps | score: [-0.007721207104623318, 0.03712162375450134]\n",
      "700 steps | score: [-0.057672977447509766, 0.02815079130232334]\n",
      "800 steps | score: [-0.03199902921915054, -0.012074925936758518]\n",
      "900 steps | score: [-0.035491760820150375, 0.04272979870438576]\n",
      "1000 steps | score: [0.009984553791582584, -0.009852117858827114]\n",
      "0 steps | score: [0.06656504422426224, 0.13383787870407104]\n",
      "100 steps | score: [-0.01323830708861351, 0.03847069293260574]\n",
      "200 steps | score: [-0.06542564183473587, 0.12307092547416687]\n",
      "300 steps | score: [0.012796018272638321, -0.012854312546551228]\n",
      "400 steps | score: [-0.06892847269773483, 0.022459477186203003]\n",
      "500 steps | score: [0.059343717992305756, -0.02680918574333191]\n",
      "600 steps | score: [0.00688300421461463, 0.062410105019807816]\n",
      "700 steps | score: [-0.039034172892570496, 0.03840205818414688]\n",
      "800 steps | score: [-0.02168114110827446, 0.006154270842671394]\n",
      "900 steps | score: [-0.02220025472342968, 0.06735169142484665]\n",
      "1000 steps | score: [0.026384182274341583, 0.01063503883779049]\n",
      "1100 steps | score: [-0.05319366976618767, 0.05012739822268486]\n",
      "1200 steps | score: [-0.03753789886832237, 0.039662957191467285]\n",
      "1300 steps | score: [0.0018421766581013799, 0.04217357933521271]\n",
      "1400 steps | score: [-0.01177284587174654, 0.05520138144493103]\n",
      "1500 steps | score: [-0.03454066812992096, 0.054565295577049255]\n",
      "1600 steps | score: [0.011777457781136036, 0.0037774331867694855]\n",
      "1700 steps | score: [0.01447257585823536, 0.0244287196546793]\n",
      "1800 steps | score: [-0.013915813528001308, 0.047717172652482986]\n",
      "1900 steps | score: [0.003726704977452755, 0.017012644559144974]\n",
      "2000 steps | score: [-0.004110996145755053, 0.019397813826799393]\n",
      "2100 steps | score: [-0.0005785597022622824, 0.04272647202014923]\n",
      "2200 steps | score: [-0.007428218610584736, 0.027894482016563416]\n",
      "2300 steps | score: [-0.014371531084179878, 0.025653760880231857]\n",
      "2400 steps | score: [-0.002127543091773987, 0.021068990230560303]\n",
      "2500 steps | score: [0.00037496857112273574, 0.025834202766418457]\n",
      "2600 steps | score: [-0.014603964053094387, 0.038857825100421906]\n",
      "0 steps | score: [0.049247127026319504, 0.12033993005752563]\n",
      "100 steps | score: [-0.02656698226928711, 0.03649349510669708]\n",
      "200 steps | score: [-0.06612954288721085, 0.10329769551753998]\n",
      "300 steps | score: [-0.009732305072247982, -0.011478682979941368]\n",
      "400 steps | score: [-0.07159879058599472, 0.024577828124165535]\n",
      "500 steps | score: [0.052491407841444016, -0.03252153843641281]\n",
      "600 steps | score: [-0.0125355189666152, 0.05252355337142944]\n",
      "700 steps | score: [-0.05624372512102127, 0.033867791295051575]\n",
      "800 steps | score: [-0.027043098583817482, 0.001261414960026741]\n",
      "900 steps | score: [-0.03489077463746071, 0.0513739287853241]\n",
      "1000 steps | score: [0.006293554324656725, 0.0011946745216846466]\n",
      "unknown params:  tensor([-0.4185, -0.4793])\n",
      "unknown variance:  tensor([[0.9429]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4261, -0.5882])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.25670120120048523]\n",
      "100 steps | score: [0.10952746123075485]\n",
      "200 steps | score: [0.09695880115032196]\n",
      "300 steps | score: [-0.0015828683972358704]\n",
      "0 steps | score: [0.08280026167631149, 0.10605032742023468]\n",
      "100 steps | score: [0.03944322094321251, -0.04581478238105774]\n",
      "200 steps | score: [0.04524724930524826, -0.0010514454916119576]\n",
      "300 steps | score: [-0.07965051382780075, 0.044729236513376236]\n",
      "400 steps | score: [-0.030445922166109085, -0.011165277101099491]\n",
      "500 steps | score: [0.03152371197938919, -0.004211416468024254]\n",
      "600 steps | score: [-0.011635188944637775, 0.030155308544635773]\n",
      "700 steps | score: [-0.04204214736819267, 0.022559134289622307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 steps | score: [-0.019015351310372353, 0.01955457404255867]\n",
      "900 steps | score: [-0.02837836742401123, 0.06163996458053589]\n",
      "1000 steps | score: [-0.011873778887093067, -0.009910371154546738]\n",
      "1100 steps | score: [-0.032112494111061096, -0.0025222646072506905]\n",
      "1200 steps | score: [-0.04114477336406708, 0.03975622355937958]\n",
      "1300 steps | score: [-0.004379589110612869, 0.010360096581280231]\n",
      "1400 steps | score: [-0.022877318784594536, 0.016927845776081085]\n",
      "1500 steps | score: [-0.01364226546138525, 0.0020613139495253563]\n",
      "1600 steps | score: [-0.03190034255385399, 0.038374897092580795]\n",
      "1700 steps | score: [0.00868982169777155, -0.010728335939347744]\n",
      "1800 steps | score: [-0.02358490787446499, 0.001097375527024269]\n",
      "1900 steps | score: [-0.033176131546497345, 0.02831191010773182]\n",
      "2000 steps | score: [-0.026345882564783096, 0.0273030586540699]\n",
      "2100 steps | score: [-0.0320114828646183, 0.0271003358066082]\n",
      "2200 steps | score: [-0.005477010738104582, -0.003650757484138012]\n",
      "0 steps | score: [0.06171395257115364, 0.1739329844713211]\n",
      "100 steps | score: [0.02097656950354576, 0.020303912460803986]\n",
      "200 steps | score: [0.03282621130347252, 0.06131308898329735]\n",
      "300 steps | score: [-0.11519992351531982, 0.11604883521795273]\n",
      "400 steps | score: [-0.04599199816584587, 0.05660516023635864]\n",
      "500 steps | score: [0.021535281091928482, 0.0454208105802536]\n",
      "600 steps | score: [-0.029002834111452103, 0.08657128363847733]\n",
      "700 steps | score: [-0.06317853182554245, 0.07508937269449234]\n",
      "800 steps | score: [-0.03855620697140694, 0.075125552713871]\n",
      "900 steps | score: [-0.03662847727537155, 0.11514946818351746]\n",
      "1000 steps | score: [-0.02360653318464756, 0.055675387382507324]\n",
      "1100 steps | score: [-0.05068843066692352, 0.05408278852701187]\n",
      "1200 steps | score: [-0.046139732003211975, 0.09839857369661331]\n",
      "1300 steps | score: [-0.013960211537778378, 0.06526780128479004]\n",
      "1400 steps | score: [-0.034848183393478394, 0.07125578820705414]\n",
      "1500 steps | score: [-0.013937484472990036, 0.045556094497442245]\n",
      "1600 steps | score: [-0.03978148475289345, 0.09099081158638]\n",
      "1700 steps | score: [-0.006206062156707048, 0.04647640138864517]\n",
      "1800 steps | score: [-0.033467669039964676, 0.05943016707897186]\n",
      "1900 steps | score: [-0.04369784891605377, 0.08549398183822632]\n",
      "2000 steps | score: [-0.030240049585700035, 0.07922562956809998]\n",
      "2100 steps | score: [-0.04247700423002243, 0.08103443682193756]\n",
      "2200 steps | score: [-0.019839918240904808, 0.049976374953985214]\n",
      "2300 steps | score: [-0.02766103856265545, 0.07210063189268112]\n",
      "2400 steps | score: [-0.02324228174984455, 0.06315428018569946]\n",
      "2500 steps | score: [-0.02267015352845192, 0.054921142756938934]\n",
      "2600 steps | score: [-0.026130463927984238, 0.062161751091480255]\n",
      "2700 steps | score: [-0.02642935700714588, 0.06997079402208328]\n",
      "2800 steps | score: [-0.03682953491806984, 0.06888765096664429]\n",
      "unknown params:  tensor([-0.4345, -0.5672])\n",
      "unknown variance:  tensor([[0.9970]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4261, -0.5882])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.055512480437755585]\n",
      "100 steps | score: [-0.014368243515491486]\n",
      "200 steps | score: [-0.12242092192173004]\n",
      "300 steps | score: [-0.10902746021747589]\n",
      "400 steps | score: [-0.06335507333278656]\n",
      "500 steps | score: [-0.15877306461334229]\n",
      "600 steps | score: [-0.13949474692344666]\n",
      "700 steps | score: [-0.11234357953071594]\n",
      "800 steps | score: [-0.09205608069896698]\n",
      "900 steps | score: [-0.11187565326690674]\n",
      "1000 steps | score: [-0.0963919460773468]\n",
      "1100 steps | score: [-0.1343732476234436]\n",
      "1200 steps | score: [-0.12044966220855713]\n",
      "1300 steps | score: [-0.13534219563007355]\n",
      "1400 steps | score: [-0.09658347070217133]\n",
      "1500 steps | score: [-0.12057556957006454]\n",
      "1600 steps | score: [-0.13004565238952637]\n",
      "1700 steps | score: [-0.08874735236167908]\n",
      "1800 steps | score: [-0.10365878790616989]\n",
      "1900 steps | score: [-0.10615606606006622]\n",
      "2000 steps | score: [-0.11457079648971558]\n",
      "2100 steps | score: [-0.13257287442684174]\n",
      "2200 steps | score: [-0.1284971386194229]\n",
      "2300 steps | score: [-0.1058836504817009]\n",
      "2400 steps | score: [-0.1257268786430359]\n",
      "2500 steps | score: [-0.10482893139123917]\n",
      "2600 steps | score: [-0.14055611193180084]\n",
      "0 steps | score: [0.10298310965299606, 0.11942943930625916]\n",
      "100 steps | score: [0.1205081194639206, -0.10148995369672775]\n",
      "200 steps | score: [-0.0030295506585389376, 0.03701247647404671]\n",
      "300 steps | score: [0.0005345172830857337, 0.009759636595845222]\n",
      "0 steps | score: [0.12167912721633911, 0.05970770865678787]\n",
      "100 steps | score: [0.11373607069253922, -0.12942537665367126]\n",
      "200 steps | score: [0.010870805010199547, -0.015202440321445465]\n",
      "300 steps | score: [0.016900639981031418, -0.04463342949748039]\n",
      "400 steps | score: [0.03528408333659172, -0.0607309453189373]\n",
      "500 steps | score: [-0.07678674906492233, 0.08550618588924408]\n",
      "600 steps | score: [-0.01326124370098114, -0.014900164678692818]\n",
      "700 steps | score: [-0.015866579487919807, -0.019629627466201782]\n",
      "800 steps | score: [0.06726513057947159, -0.07491538673639297]\n",
      "900 steps | score: [0.03650301322340965, -0.06980437785387039]\n",
      "1000 steps | score: [0.018676774576306343, -0.049107763916254044]\n",
      "1100 steps | score: [-0.0431131087243557, 0.03357021510601044]\n",
      "1200 steps | score: [0.03620973229408264, -0.052981212735176086]\n",
      "1300 steps | score: [0.010015711188316345, -0.03135032206773758]\n",
      "1400 steps | score: [0.05071460083127022, -0.07893474400043488]\n",
      "1500 steps | score: [0.003008909523487091, -0.012719683349132538]\n",
      "1600 steps | score: [-0.014799953438341618, -0.011207286268472672]\n",
      "1700 steps | score: [0.04238773509860039, -0.07177761197090149]\n",
      "1800 steps | score: [0.003829701105132699, -0.013812512159347534]\n",
      "1900 steps | score: [0.040665723383426666, -0.056235458701848984]\n",
      "2000 steps | score: [0.023584425449371338, -0.04813360795378685]\n",
      "2100 steps | score: [-0.0033246062230318785, -0.01389581710100174]\n",
      "2200 steps | score: [-0.004981674253940582, -0.012511525303125381]\n",
      "2300 steps | score: [0.007202144246548414, -0.029844088479876518]\n",
      "2400 steps | score: [0.015543454326689243, -0.034678999334573746]\n",
      "2500 steps | score: [0.005311754997819662, -0.01571717858314514]\n",
      "2600 steps | score: [-0.0037043634802103043, -0.012352409772574902]\n",
      "0 steps | score: [0.11065307259559631, 0.10993370413780212]\n",
      "100 steps | score: [0.11461348831653595, -0.10100254416465759]\n",
      "200 steps | score: [-0.0104782460257411, 0.039732739329338074]\n",
      "300 steps | score: [0.01865622028708458, -0.009402520954608917]\n",
      "400 steps | score: [0.06783601641654968, -0.06080511957406998]\n",
      "500 steps | score: [-0.07872205227613449, 0.13164269924163818]\n",
      "600 steps | score: [-0.02482062764465809, 0.026104046031832695]\n",
      "700 steps | score: [0.004610211122781038, 0.00013617053627967834]\n",
      "unknown params:  tensor([-0.4551, -0.6918])\n",
      "unknown variance:  tensor([[1.0703]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4261, -0.5882])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.015090957283973694]\n",
      "100 steps | score: [-0.15666335821151733]\n",
      "200 steps | score: [-0.10703213512897491]\n",
      "300 steps | score: [-0.031495727598667145]\n",
      "400 steps | score: [-0.13868707418441772]\n",
      "500 steps | score: [-0.10977189242839813]\n",
      "600 steps | score: [-0.06853245943784714]\n",
      "700 steps | score: [-0.15416620671749115]\n",
      "800 steps | score: [-0.09360532462596893]\n",
      "900 steps | score: [-0.12140670418739319]\n",
      "1000 steps | score: [-0.12412397563457489]\n",
      "1100 steps | score: [-0.09987321496009827]\n",
      "1200 steps | score: [-0.1048545241355896]\n",
      "1300 steps | score: [-0.13431377708911896]\n",
      "1400 steps | score: [-0.09577251970767975]\n",
      "1500 steps | score: [-0.12142126262187958]\n",
      "1600 steps | score: [-0.14456355571746826]\n",
      "1700 steps | score: [-0.11777012795209885]\n",
      "1800 steps | score: [-0.11045591533184052]\n",
      "1900 steps | score: [-0.13997142016887665]\n",
      "2000 steps | score: [-0.1387457400560379]\n",
      "2100 steps | score: [-0.12914344668388367]\n",
      "2200 steps | score: [-0.10794001817703247]\n",
      "2300 steps | score: [-0.13768288493156433]\n",
      "2400 steps | score: [-0.1215353012084961]\n",
      "2500 steps | score: [-0.11198455840349197]\n",
      "2600 steps | score: [-0.137108713388443]\n",
      "0 steps | score: [0.11354934424161911, 0.10635480284690857]\n",
      "100 steps | score: [-0.012673933058977127, 0.07594254612922668]\n",
      "200 steps | score: [0.005380923859775066, 0.04075699672102928]\n",
      "300 steps | score: [0.10194109380245209, -0.14992672204971313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 steps | score: [-0.04808870702981949, 0.08323059976100922]\n",
      "500 steps | score: [0.006975125055760145, 0.026289023458957672]\n",
      "600 steps | score: [0.06362360715866089, -0.09626665711402893]\n",
      "700 steps | score: [-0.07236633449792862, 0.09935548156499863]\n",
      "800 steps | score: [0.01540621928870678, 0.013739394024014473]\n",
      "900 steps | score: [0.04939575865864754, -0.07493646442890167]\n",
      "1000 steps | score: [-0.04140602797269821, 0.059183236211538315]\n",
      "1100 steps | score: [0.015330295078456402, 0.004372382536530495]\n",
      "1200 steps | score: [0.07292136549949646, -0.10165739804506302]\n",
      "1300 steps | score: [-0.05145227536559105, 0.07573491334915161]\n",
      "1400 steps | score: [0.005695521831512451, 0.014718007296323776]\n",
      "1500 steps | score: [0.025822008028626442, -0.03470122069120407]\n",
      "1600 steps | score: [-0.0348307341337204, 0.061575643718242645]\n",
      "1700 steps | score: [-0.011018458753824234, 0.03690680116415024]\n",
      "1800 steps | score: [0.0047493199817836285, -0.006431978195905685]\n",
      "0 steps | score: [0.09139198064804077, 0.13948571681976318]\n",
      "100 steps | score: [-0.007526518311351538, 0.07445186376571655]\n",
      "200 steps | score: [0.015055445954203606, 0.03259441629052162]\n",
      "300 steps | score: [0.13037841022014618, -0.1934952735900879]\n",
      "400 steps | score: [-0.050322894006967545, 0.08992870897054672]\n",
      "500 steps | score: [0.009716889820992947, 0.02393263764679432]\n",
      "600 steps | score: [0.08898051828145981, -0.13915547728538513]\n",
      "700 steps | score: [-0.0670168474316597, 0.10831862688064575]\n",
      "800 steps | score: [0.02585093304514885, 0.004541683942079544]\n",
      "900 steps | score: [0.07500676810741425, -0.1063985824584961]\n",
      "1000 steps | score: [-0.03619642183184624, 0.06914199888706207]\n",
      "1100 steps | score: [0.048684798181056976, -0.029194727540016174]\n",
      "1200 steps | score: [0.0855698212981224, -0.10563410818576813]\n",
      "1300 steps | score: [-0.035721033811569214, 0.05677429586648941]\n",
      "1400 steps | score: [0.023816892877221107, -0.0082556726410985]\n",
      "1500 steps | score: [0.03234585002064705, -0.03878622502088547]\n",
      "1600 steps | score: [-0.023042917251586914, 0.05355127155780792]\n",
      "1700 steps | score: [-0.0031571227591484785, 0.025765519589185715]\n",
      "1800 steps | score: [0.038603730499744415, -0.03943527489900589]\n",
      "1900 steps | score: [-0.02542664296925068, 0.04586929827928543]\n",
      "2000 steps | score: [-0.008087337017059326, 0.040575966238975525]\n",
      "2100 steps | score: [0.012106954120099545, -0.0030233673751354218]\n",
      "2200 steps | score: [-0.012585262767970562, 0.029514461755752563]\n",
      "2300 steps | score: [-0.013403045944869518, 0.03877188265323639]\n",
      "2400 steps | score: [0.010314950719475746, 0.0001757824793457985]\n",
      "2500 steps | score: [-0.007943147793412209, 0.02503174915909767]\n",
      "2600 steps | score: [-0.01156291551887989, 0.034521594643592834]\n",
      "unknown params:  tensor([-0.4878, -0.7920])\n",
      "unknown variance:  tensor([[1.1634]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4261, -0.5882])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.1815410852432251]\n",
      "100 steps | score: [-0.08471249043941498]\n",
      "200 steps | score: [-0.04490978270769119]\n",
      "300 steps | score: [-0.026662152260541916]\n",
      "400 steps | score: [0.006619580090045929]\n",
      "0 steps | score: [0.21305058896541595, -0.06262221187353134]\n",
      "100 steps | score: [-0.05789880082011223, 0.1326204538345337]\n",
      "200 steps | score: [0.052452653646469116, -0.05636025592684746]\n",
      "300 steps | score: [0.031004704535007477, -0.03629986569285393]\n",
      "400 steps | score: [0.12900403141975403, -0.16754187643527985]\n",
      "500 steps | score: [-0.04151783883571625, 0.043398965150117874]\n",
      "600 steps | score: [0.10514422506093979, -0.15335677564144135]\n",
      "700 steps | score: [0.09432099014520645, -0.12227446585893631]\n",
      "800 steps | score: [-0.03337531536817551, 0.03212520852684975]\n",
      "900 steps | score: [0.022457554936408997, -0.04255808889865875]\n",
      "1000 steps | score: [0.03714880347251892, -0.040880993008613586]\n",
      "1100 steps | score: [0.06013544648885727, -0.09695521742105484]\n",
      "1200 steps | score: [0.02681322768330574, -0.03389205411076546]\n",
      "1300 steps | score: [0.07495047897100449, -0.1145397201180458]\n",
      "1400 steps | score: [-0.004199243150651455, -0.005591394379734993]\n",
      "0 steps | score: [0.0976882129907608, 0.17321625351905823]\n",
      "100 steps | score: [-0.15600000321865082, 0.34398147463798523]\n",
      "200 steps | score: [-0.015065278857946396, 0.1036694198846817]\n",
      "300 steps | score: [-0.035610735416412354, 0.12373214215040207]\n",
      "400 steps | score: [0.08964156359434128, -0.04673208296298981]\n",
      "500 steps | score: [-0.10913391411304474, 0.2058451920747757]\n",
      "600 steps | score: [0.022822681814432144, 0.030509797856211662]\n",
      "700 steps | score: [0.03193017095327377, 0.038060784339904785]\n",
      "800 steps | score: [-0.09020563960075378, 0.18016581237316132]\n",
      "900 steps | score: [-0.04082626849412918, 0.11870159208774567]\n",
      "1000 steps | score: [-0.04550698399543762, 0.13115617632865906]\n",
      "1100 steps | score: [-0.010221190750598907, 0.07159075140953064]\n",
      "1200 steps | score: [-0.05145492032170296, 0.14309263229370117]\n",
      "1300 steps | score: [0.034922391176223755, -0.0022444166243076324]\n",
      "1400 steps | score: [-0.06989479809999466, 0.16216668486595154]\n",
      "1500 steps | score: [-0.09504513442516327, 0.19990447163581848]\n",
      "1600 steps | score: [-0.05594098940491676, 0.13465094566345215]\n",
      "1700 steps | score: [-0.036780718713998795, 0.1208113431930542]\n",
      "1800 steps | score: [-0.012011458165943623, 0.06692197173833847]\n",
      "1900 steps | score: [0.03610997647047043, -0.004630271345376968]\n",
      "2000 steps | score: [-0.08832520246505737, 0.18173471093177795]\n",
      "2100 steps | score: [-0.049479227513074875, 0.13022828102111816]\n",
      "2200 steps | score: [0.003068078774958849, 0.04312599450349808]\n",
      "2300 steps | score: [-0.02220444567501545, 0.09595547616481781]\n",
      "2400 steps | score: [-0.03292994946241379, 0.1022932380437851]\n",
      "2500 steps | score: [-0.0050625004805624485, 0.060903601348400116]\n",
      "2600 steps | score: [-0.03462695702910423, 0.11078459024429321]\n",
      "2700 steps | score: [-0.04564540833234787, 0.12490476667881012]\n",
      "unknown params:  tensor([-0.4653, -0.8968])\n",
      "unknown variance:  tensor([[1.1792]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4261, -0.5882])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3837506175041199]\n",
      "100 steps | score: [0.16968654096126556]\n",
      "200 steps | score: [0.2295883744955063]\n",
      "300 steps | score: [0.17318664491176605]\n",
      "400 steps | score: [0.18964184820652008]\n",
      "500 steps | score: [0.17366763949394226]\n",
      "600 steps | score: [0.18992061913013458]\n",
      "700 steps | score: [0.10323826223611832]\n",
      "800 steps | score: [0.16514085233211517]\n",
      "900 steps | score: [0.15147291123867035]\n",
      "1000 steps | score: [0.1729850172996521]\n",
      "1100 steps | score: [0.14821623265743256]\n",
      "1200 steps | score: [0.12695926427841187]\n",
      "1300 steps | score: [0.15491122007369995]\n",
      "1400 steps | score: [0.15254251658916473]\n",
      "1500 steps | score: [0.15689250826835632]\n",
      "1600 steps | score: [0.1152883768081665]\n",
      "1700 steps | score: [0.17663316428661346]\n",
      "1800 steps | score: [0.1559734344482422]\n",
      "1900 steps | score: [0.14149610698223114]\n",
      "2000 steps | score: [0.17237645387649536]\n",
      "2100 steps | score: [0.14831602573394775]\n",
      "2200 steps | score: [0.13794350624084473]\n",
      "2300 steps | score: [0.14774131774902344]\n",
      "2400 steps | score: [0.1324019879102707]\n",
      "2500 steps | score: [0.1575717329978943]\n",
      "2600 steps | score: [0.13293826580047607]\n",
      "0 steps | score: [0.13834039866924286, 0.00906762108206749]\n",
      "100 steps | score: [0.11521823704242706, -0.09468607604503632]\n",
      "200 steps | score: [0.2370694875717163, -0.4493173360824585]\n",
      "300 steps | score: [-0.08995071053504944, 0.14153383672237396]\n",
      "400 steps | score: [0.04993141442537308, -0.09147029370069504]\n",
      "500 steps | score: [-0.028166718780994415, 0.03965216875076294]\n",
      "600 steps | score: [0.14360737800598145, -0.25195029377937317]\n",
      "700 steps | score: [-0.17944583296775818, 0.24711619317531586]\n",
      "800 steps | score: [0.04800547659397125, -0.08820676803588867]\n",
      "900 steps | score: [-0.05871891230344772, 0.0889754444360733]\n",
      "1000 steps | score: [0.03631092980504036, -0.07892592251300812]\n",
      "1100 steps | score: [-0.08435364067554474, 0.13047632575035095]\n",
      "1200 steps | score: [-0.05852394923567772, 0.07082114368677139]\n",
      "1300 steps | score: [-0.07479254901409149, 0.0985645279288292]\n",
      "1400 steps | score: [0.08106444776058197, -0.16275449097156525]\n",
      "1500 steps | score: [0.0012635600287467241, -0.019642015919089317]\n",
      "1600 steps | score: [-0.014110713265836239, -0.002081146463751793]\n",
      "1700 steps | score: [0.04429261013865471, -0.11330368369817734]\n",
      "1800 steps | score: [-0.06892217695713043, 0.09975054860115051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [0.044181011617183685, -0.09449870884418488]\n",
      "2000 steps | score: [0.021780626848340034, -0.057696904987096786]\n",
      "2100 steps | score: [0.021102361381053925, -0.04273376241326332]\n",
      "2200 steps | score: [0.007810729555785656, -0.03018127754330635]\n",
      "2300 steps | score: [0.013121132738888264, -0.03756598383188248]\n",
      "2400 steps | score: [-0.0372837595641613, 0.037132199853658676]\n",
      "2500 steps | score: [0.006877873558551073, -0.02415316551923752]\n",
      "2600 steps | score: [-0.018542570993304253, 0.016346093267202377]\n",
      "unknown params:  tensor([-0.4978, -0.9764])\n",
      "unknown variance:  tensor([[1.3147]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4261, -0.5882])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.13820664584636688]\n",
      "100 steps | score: [-0.056682370603084564]\n",
      "200 steps | score: [-0.10624197125434875]\n",
      "300 steps | score: [-0.20006681978702545]\n",
      "400 steps | score: [-0.057970985770225525]\n",
      "500 steps | score: [-0.07549836486577988]\n",
      "600 steps | score: [-0.08874857425689697]\n",
      "700 steps | score: [-0.11282587051391602]\n",
      "800 steps | score: [-0.1362331211566925]\n",
      "900 steps | score: [-0.11447819322347641]\n",
      "1000 steps | score: [-0.08483763039112091]\n",
      "1100 steps | score: [-0.12116914987564087]\n",
      "1200 steps | score: [-0.1541229486465454]\n",
      "1300 steps | score: [-0.08382289111614227]\n",
      "1400 steps | score: [-0.09876842051744461]\n",
      "1500 steps | score: [-0.10033807903528214]\n",
      "1600 steps | score: [-0.11621971428394318]\n",
      "1700 steps | score: [-0.1146642342209816]\n",
      "1800 steps | score: [-0.11567375808954239]\n",
      "1900 steps | score: [-0.09945894032716751]\n",
      "2000 steps | score: [-0.10537730902433395]\n",
      "2100 steps | score: [-0.10652375221252441]\n",
      "2200 steps | score: [-0.1128985732793808]\n",
      "2300 steps | score: [-0.08036201447248459]\n",
      "2400 steps | score: [-0.08415038138628006]\n",
      "2500 steps | score: [-0.11142313480377197]\n",
      "0 steps | score: [0.11721842736005783, 0.1213558167219162]\n",
      "100 steps | score: [0.15747277438640594, -0.07079552114009857]\n",
      "200 steps | score: [0.02393859066069126, 0.08769848942756653]\n",
      "300 steps | score: [-0.24349498748779297, 0.5104997158050537]\n",
      "400 steps | score: [-0.068963922560215, 0.21367397904396057]\n",
      "500 steps | score: [0.08980382978916168, -0.10792260617017746]\n",
      "600 steps | score: [0.10109271109104156, -0.11776179820299149]\n",
      "700 steps | score: [-0.09176608175039291, 0.24293479323387146]\n",
      "800 steps | score: [-0.13455936312675476, 0.3290758430957794]\n",
      "900 steps | score: [-0.14134478569030762, 0.32327455282211304]\n",
      "1000 steps | score: [0.027530744671821594, 0.023144513368606567]\n",
      "1100 steps | score: [-0.03803936764597893, 0.1517607718706131]\n",
      "1200 steps | score: [-0.0993533581495285, 0.254151850938797]\n",
      "1300 steps | score: [0.04144703596830368, 0.0027919262647628784]\n",
      "1400 steps | score: [0.03668924793601036, -0.003323569893836975]\n",
      "1500 steps | score: [-0.054423365741968155, 0.1715894490480423]\n",
      "1600 steps | score: [-0.07827633619308472, 0.225418820977211]\n",
      "1700 steps | score: [-0.072413370013237, 0.20250864326953888]\n",
      "1800 steps | score: [-0.02982531674206257, 0.1275964081287384]\n",
      "1900 steps | score: [0.03291470184922218, 0.009982876479625702]\n",
      "2000 steps | score: [-0.06371629983186722, 0.181839719414711]\n",
      "2100 steps | score: [-0.08022836595773697, 0.21628257632255554]\n",
      "2200 steps | score: [-0.040523018687963486, 0.15741407871246338]\n",
      "2300 steps | score: [-0.02024921588599682, 0.11745615303516388]\n",
      "2400 steps | score: [-0.0269447211176157, 0.1292373687028885]\n",
      "2500 steps | score: [-0.07285435497760773, 0.20602840185165405]\n",
      "unknown params:  tensor([-0.4755, -0.9682])\n",
      "unknown variance:  tensor([[1.3975]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4261, -0.5882])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3910183310508728]\n",
      "100 steps | score: [0.10657302290201187]\n",
      "200 steps | score: [0.12697169184684753]\n",
      "300 steps | score: [0.09277781844139099]\n",
      "400 steps | score: [0.15891624987125397]\n",
      "500 steps | score: [0.14927330613136292]\n",
      "600 steps | score: [0.13105307519435883]\n",
      "700 steps | score: [0.1325681209564209]\n",
      "800 steps | score: [0.1293155997991562]\n",
      "900 steps | score: [0.1630249321460724]\n",
      "1000 steps | score: [0.15751908719539642]\n",
      "1100 steps | score: [0.1695510745048523]\n",
      "1200 steps | score: [0.12685850262641907]\n",
      "1300 steps | score: [0.15384092926979065]\n",
      "1400 steps | score: [0.10209755599498749]\n",
      "1500 steps | score: [0.1394410878419876]\n",
      "1600 steps | score: [0.155494824051857]\n",
      "1700 steps | score: [0.1347147673368454]\n",
      "1800 steps | score: [0.1288549304008484]\n",
      "1900 steps | score: [0.1543678641319275]\n",
      "2000 steps | score: [0.11394108831882477]\n",
      "2100 steps | score: [0.14831914007663727]\n",
      "2200 steps | score: [0.1468752920627594]\n",
      "2300 steps | score: [0.1591263711452484]\n",
      "2400 steps | score: [0.13276395201683044]\n",
      "2500 steps | score: [0.14387477934360504]\n",
      "2600 steps | score: [0.13701343536376953]\n",
      "0 steps | score: [0.2278119921684265, -0.2369392365217209]\n",
      "100 steps | score: [-0.19366684556007385, 0.41089797019958496]\n",
      "200 steps | score: [-0.1115482747554779, 0.24139408767223358]\n",
      "300 steps | score: [0.13838894665241241, -0.25296851992607117]\n",
      "400 steps | score: [0.20121386647224426, -0.4113389551639557]\n",
      "500 steps | score: [0.14572227001190186, -0.3012235760688782]\n",
      "600 steps | score: [0.037382639944553375, -0.08616521954536438]\n",
      "700 steps | score: [-0.056084562093019485, 0.10694944858551025]\n",
      "800 steps | score: [0.00854654423892498, -0.02608572691679001]\n",
      "900 steps | score: [0.32504865527153015, -0.7311679124832153]\n",
      "1000 steps | score: [0.10109591484069824, -0.22527338564395905]\n",
      "1100 steps | score: [0.14116978645324707, -0.305210143327713]\n",
      "1200 steps | score: [0.007208986673504114, -0.023985378444194794]\n",
      "1300 steps | score: [-0.03089030086994171, 0.044724851846694946]\n",
      "1400 steps | score: [-0.07950844615697861, 0.13854189217090607]\n",
      "1500 steps | score: [0.016838975250720978, -0.04641158878803253]\n",
      "1600 steps | score: [0.061834000051021576, -0.13997450470924377]\n",
      "1700 steps | score: [0.11904382705688477, -0.26608866453170776]\n",
      "1800 steps | score: [-0.017455527558922768, 0.02614457532763481]\n",
      "1900 steps | score: [0.03637775406241417, -0.10349631309509277]\n",
      "2000 steps | score: [0.029038889333605766, -0.07569991052150726]\n",
      "2100 steps | score: [0.05756991356611252, -0.1303490549325943]\n",
      "2200 steps | score: [0.055630508810281754, -0.12722693383693695]\n",
      "2300 steps | score: [0.050811413675546646, -0.11871760338544846]\n",
      "2400 steps | score: [0.042973607778549194, -0.10720483213663101]\n",
      "2500 steps | score: [0.09512428939342499, -0.2255248874425888]\n",
      "2600 steps | score: [0.034319326281547546, -0.09345705062150955]\n",
      "unknown params:  tensor([-0.4213, -0.8067])\n",
      "unknown variance:  tensor([[1.4170]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/3ffac098-306f-43c5-a000-e0d38d495823\n",
      "gt params:  tensor([-0.4333, -0.5862])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.07200393825769424]\n",
      "100 steps | score: [-0.08645802736282349]\n",
      "200 steps | score: [-0.06569613516330719]\n",
      "300 steps | score: [0.06457581371068954]\n",
      "400 steps | score: [-0.10523097217082977]\n",
      "500 steps | score: [0.046380896121263504]\n",
      "600 steps | score: [-0.12865540385246277]\n",
      "700 steps | score: [-0.04073867201805115]\n",
      "800 steps | score: [-0.022682394832372665]\n",
      "900 steps | score: [-0.10141085088253021]\n",
      "1000 steps | score: [-0.07640533894300461]\n",
      "1100 steps | score: [-0.0688387081027031]\n",
      "1200 steps | score: [0.007462705485522747]\n",
      "0 steps | score: [0.07082336395978928, 0.061678510159254074]\n",
      "100 steps | score: [0.005789484363049269, -0.016035480424761772]\n",
      "200 steps | score: [0.025029510259628296, 0.060633402317762375]\n",
      "300 steps | score: [0.13202084600925446, -0.011246660724282265]\n",
      "400 steps | score: [0.007038285490125418, 0.019575640559196472]\n",
      "500 steps | score: [0.07657536119222641, 0.0009279884397983551]\n",
      "600 steps | score: [0.011385209858417511, 0.020882729440927505]\n",
      "700 steps | score: [0.047723788768053055, -0.0366629995405674]\n",
      "800 steps | score: [0.05299537256360054, -0.00012959912419319153]\n",
      "900 steps | score: [-0.0075922473333776, 0.03766445070505142]\n",
      "1000 steps | score: [0.01684015616774559, -0.019833367317914963]\n",
      "1100 steps | score: [0.03992152586579323, 0.02165578119456768]\n",
      "1200 steps | score: [0.07812313735485077, -0.012104576453566551]\n",
      "1300 steps | score: [0.007495035417377949, 0.01751479133963585]\n",
      "1400 steps | score: [0.030264608561992645, 0.01723543182015419]\n",
      "1500 steps | score: [0.003929711878299713, 0.003041471354663372]\n",
      "unknown params:  tensor([-0.4036, -0.5126])\n",
      "unknown variance:  tensor([[0.8666]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4333, -0.5862])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.21544873714447021]\n",
      "100 steps | score: [0.07235288619995117]\n",
      "200 steps | score: [0.12593188881874084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 steps | score: [0.058674849569797516]\n",
      "400 steps | score: [-0.014379840344190598]\n",
      "500 steps | score: [0.03743171691894531]\n",
      "600 steps | score: [0.0923280343413353]\n",
      "700 steps | score: [0.06837701797485352]\n",
      "800 steps | score: [0.02378464862704277]\n",
      "900 steps | score: [0.0407586470246315]\n",
      "1000 steps | score: [0.08256611227989197]\n",
      "1100 steps | score: [0.07946080714464188]\n",
      "1200 steps | score: [0.023735977709293365]\n",
      "1300 steps | score: [0.0468873530626297]\n",
      "1400 steps | score: [0.06529675424098969]\n",
      "1500 steps | score: [0.09961295127868652]\n",
      "1600 steps | score: [0.028878405690193176]\n",
      "1700 steps | score: [0.02835308015346527]\n",
      "1800 steps | score: [0.08922900259494781]\n",
      "1900 steps | score: [0.09144014865159988]\n",
      "2000 steps | score: [0.03310871869325638]\n",
      "2100 steps | score: [0.07389247417449951]\n",
      "2200 steps | score: [0.05024112015962601]\n",
      "2300 steps | score: [0.10243424773216248]\n",
      "2400 steps | score: [0.06574036180973053]\n",
      "2500 steps | score: [0.06344693899154663]\n",
      "2600 steps | score: [0.0820118635892868]\n",
      "2700 steps | score: [0.10030966997146606]\n",
      "2800 steps | score: [0.045747607946395874]\n",
      "0 steps | score: [0.057446882128715515, 0.08926555514335632]\n",
      "100 steps | score: [-0.007877388037741184, 0.00630008801817894]\n",
      "0 steps | score: [0.06433779746294022, 0.07348568737506866]\n",
      "100 steps | score: [-0.01841793954372406, -0.01049265917390585]\n",
      "200 steps | score: [0.06007377430796623, -0.04480460286140442]\n",
      "300 steps | score: [-0.0022238038945943117, 0.03266920894384384]\n",
      "400 steps | score: [-0.0704810693860054, 0.03427204489707947]\n",
      "500 steps | score: [-0.031351130455732346, -0.01550896093249321]\n",
      "600 steps | score: [0.029867708683013916, -0.040376678109169006]\n",
      "700 steps | score: [0.0052312384359538555, 0.021716974675655365]\n",
      "800 steps | score: [-0.04147307574748993, 0.018328173086047173]\n",
      "900 steps | score: [0.0036260681226849556, -0.02704988792538643]\n",
      "1000 steps | score: [0.011275422759354115, -0.014879260212182999]\n",
      "1100 steps | score: [0.02139793336391449, 0.004810282960534096]\n",
      "1200 steps | score: [-0.025189612060785294, 0.01069384440779686]\n",
      "1300 steps | score: [0.004595280159264803, -0.02190033346414566]\n",
      "1400 steps | score: [0.013589595444500446, -0.023222316056489944]\n",
      "1500 steps | score: [0.0324796587228775, -0.019699079915881157]\n",
      "1600 steps | score: [-0.02267991192638874, 0.005664599593728781]\n",
      "1700 steps | score: [-0.01036058273166418, -0.01015903614461422]\n",
      "1800 steps | score: [-0.006751667708158493, -0.007772522047162056]\n",
      "0 steps | score: [0.08492762595415115, 0.04777904227375984]\n",
      "100 steps | score: [0.0005733881262131035, -0.020508917048573494]\n",
      "200 steps | score: [0.07625042647123337, -0.06775426864624023]\n",
      "300 steps | score: [0.017993278801441193, 0.013350929133594036]\n",
      "400 steps | score: [-0.04657788202166557, 0.01335148885846138]\n",
      "500 steps | score: [0.00553191127255559, -0.043301962316036224]\n",
      "600 steps | score: [0.05541766434907913, -0.07338486611843109]\n",
      "700 steps | score: [0.033750493079423904, -0.005968282464891672]\n",
      "800 steps | score: [-0.02476174756884575, -0.0035898233763873577]\n",
      "900 steps | score: [0.023030070587992668, -0.054690755903720856]\n",
      "1000 steps | score: [0.03314746543765068, -0.04163052886724472]\n",
      "1100 steps | score: [0.03968103229999542, -0.022462982684373856]\n",
      "1200 steps | score: [-0.012152166105806828, -0.0099306870251894]\n",
      "1300 steps | score: [0.01674591191112995, -0.0401410311460495]\n",
      "1400 steps | score: [0.03712839633226395, -0.04084460809826851]\n",
      "1500 steps | score: [0.04927842691540718, -0.04134489595890045]\n",
      "1600 steps | score: [0.005039284471422434, -0.020080476999282837]\n",
      "1700 steps | score: [0.02276565320789814, -0.03543109819293022]\n",
      "1800 steps | score: [0.01987273432314396, -0.03397398442029953]\n",
      "1900 steps | score: [0.042299751192331314, -0.04572373628616333]\n",
      "2000 steps | score: [0.003571011358872056, -0.01750275306403637]\n",
      "2100 steps | score: [0.0193496011197567, -0.03742636740207672]\n",
      "2200 steps | score: [0.018034810200333595, -0.031538091599941254]\n",
      "2300 steps | score: [0.041762325912714005, -0.049888238310813904]\n",
      "2400 steps | score: [0.013971134088933468, -0.023804500699043274]\n",
      "2500 steps | score: [0.01654454879462719, -0.030706990510225296]\n",
      "2600 steps | score: [0.016736742109060287, -0.03173094242811203]\n",
      "2700 steps | score: [0.03655470162630081, -0.04444974660873413]\n",
      "2800 steps | score: [0.00762298796325922, -0.02607918158173561]\n",
      "unknown params:  tensor([-0.4065, -0.4860])\n",
      "unknown variance:  tensor([[0.8842]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4333, -0.5862])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.031928759068250656]\n",
      "100 steps | score: [0.002299118787050247]\n",
      "0 steps | score: [0.0931694284081459, 0.09131810069084167]\n",
      "100 steps | score: [0.04643993824720383, -0.04196875914931297]\n",
      "200 steps | score: [0.08077802509069443, -0.004086324945092201]\n",
      "300 steps | score: [0.03184649348258972, 0.007925395853817463]\n",
      "400 steps | score: [-0.024241723120212555, 0.0401812344789505]\n",
      "500 steps | score: [-0.0006344085559248924, -0.04205793887376785]\n",
      "600 steps | score: [0.050543125718832016, -0.04371987655758858]\n",
      "700 steps | score: [-0.02813570387661457, 0.0495685413479805]\n",
      "800 steps | score: [0.03754546493291855, -0.01627221144735813]\n",
      "900 steps | score: [-0.041568852961063385, 0.010247282683849335]\n",
      "1000 steps | score: [0.05538763850927353, -0.0543271079659462]\n",
      "1100 steps | score: [-0.00701545737683773, 0.02359510026872158]\n",
      "1200 steps | score: [0.0034701211843639612, -0.0031544615048915148]\n",
      "0 steps | score: [0.0844789445400238, 0.065617136657238]\n",
      "100 steps | score: [0.03699779883027077, -0.06009500473737717]\n",
      "200 steps | score: [0.06530706584453583, -0.02635090984404087]\n",
      "300 steps | score: [0.028909247368574142, -0.017043214291334152]\n",
      "400 steps | score: [-0.02029789611697197, 0.022929061204195023]\n",
      "500 steps | score: [0.00230788835324347, -0.06595534831285477]\n",
      "600 steps | score: [0.05085140839219093, -0.07582717388868332]\n",
      "700 steps | score: [-0.04319881647825241, 0.028693856671452522]\n",
      "800 steps | score: [0.03512890636920929, -0.05046817287802696]\n",
      "900 steps | score: [-0.05264056846499443, -0.011697392910718918]\n",
      "1000 steps | score: [0.05145104601979256, -0.07648085057735443]\n",
      "1100 steps | score: [-0.010278226807713509, 0.0018592923879623413]\n",
      "1200 steps | score: [-0.006015140563249588, -0.020800866186618805]\n",
      "1300 steps | score: [-0.010446567088365555, -0.02239755168557167]\n",
      "1400 steps | score: [0.05551968887448311, -0.05586685985326767]\n",
      "1500 steps | score: [-0.02653825469315052, 0.009521889500319958]\n",
      "1600 steps | score: [0.0001899931812658906, -0.03323756903409958]\n",
      "1700 steps | score: [0.023654187098145485, -0.04172046482563019]\n",
      "1800 steps | score: [0.0054604955948889256, -0.017267197370529175]\n",
      "1900 steps | score: [-0.032086897641420364, 0.007910356856882572]\n",
      "2000 steps | score: [0.02468811720609665, -0.05617543309926987]\n",
      "2100 steps | score: [0.02568589337170124, -0.042789287865161896]\n",
      "2200 steps | score: [0.010294401086866856, -0.03298843652009964]\n",
      "2300 steps | score: [-0.02122572623193264, -0.0026386557146906853]\n",
      "2400 steps | score: [0.0023257159627974033, -0.02854744903743267]\n",
      "2500 steps | score: [0.018423113971948624, -0.04534248635172844]\n",
      "2600 steps | score: [0.009631291031837463, -0.027334004640579224]\n",
      "0 steps | score: [0.08590488880872726, 0.10363868623971939]\n",
      "100 steps | score: [0.03664648160338402, -0.02692907489836216]\n",
      "200 steps | score: [0.06965643167495728, 0.010281644761562347]\n",
      "300 steps | score: [0.022673634812235832, 0.01711588352918625]\n",
      "400 steps | score: [-0.017902454361319542, 0.04167294502258301]\n",
      "500 steps | score: [-0.008583508431911469, -0.03381612151861191]\n",
      "600 steps | score: [0.043817851692438126, -0.029744720086455345]\n",
      "700 steps | score: [-0.04114245995879173, 0.06018754467368126]\n",
      "800 steps | score: [0.03303425759077072, -0.015252718701958656]\n",
      "900 steps | score: [-0.06204479560256004, 0.02840873971581459]\n",
      "1000 steps | score: [0.035842981189489365, -0.03738775849342346]\n",
      "1100 steps | score: [-0.009661211632192135, 0.033405665308237076]\n",
      "1200 steps | score: [-0.006463998928666115, 0.008470320142805576]\n",
      "unknown params:  tensor([-0.4239, -0.5369])\n",
      "unknown variance:  tensor([[0.9249]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4333, -0.5862])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2516096830368042]\n",
      "100 steps | score: [0.18351192772388458]\n",
      "200 steps | score: [0.11096679419279099]\n",
      "300 steps | score: [0.06490245461463928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 steps | score: [0.15040825307369232]\n",
      "500 steps | score: [0.1036917120218277]\n",
      "600 steps | score: [0.12306852638721466]\n",
      "700 steps | score: [0.0012483298778533936]\n",
      "0 steps | score: [0.13728629052639008, 0.08111906051635742]\n",
      "100 steps | score: [0.1649342030286789, -0.20631222426891327]\n",
      "200 steps | score: [0.1168191060423851, -0.11792449653148651]\n",
      "300 steps | score: [-0.01933765970170498, 0.0589667409658432]\n",
      "400 steps | score: [0.09853772819042206, -0.09799471497535706]\n",
      "500 steps | score: [0.03723486140370369, -0.02424667775630951]\n",
      "600 steps | score: [0.05616588890552521, -0.03378799185156822]\n",
      "700 steps | score: [-0.009192327037453651, 0.03330394625663757]\n",
      "800 steps | score: [0.08126216381788254, -0.07648958265781403]\n",
      "900 steps | score: [0.1146727204322815, -0.11049214750528336]\n",
      "1000 steps | score: [0.002604804001748562, 0.03909526765346527]\n",
      "1100 steps | score: [0.059159211814403534, -0.045303333550691605]\n",
      "1200 steps | score: [0.05158163234591484, -0.052031148225069046]\n",
      "1300 steps | score: [0.08634140342473984, -0.0697503462433815]\n",
      "1400 steps | score: [-0.0016368187498301268, 0.029802650213241577]\n",
      "1500 steps | score: [0.05779729783535004, -0.03172474354505539]\n",
      "1600 steps | score: [0.060220867395401, -0.04991558939218521]\n",
      "1700 steps | score: [0.028135959059000015, -0.0012619218323379755]\n",
      "1800 steps | score: [0.019259633496403694, -0.006800581701099873]\n",
      "1900 steps | score: [0.030672559514641762, -0.01471048966050148]\n",
      "2000 steps | score: [0.08078411221504211, -0.06860443949699402]\n",
      "2100 steps | score: [0.005247602704912424, 0.013640142977237701]\n",
      "2200 steps | score: [0.030086670070886612, -0.00873132236301899]\n",
      "2300 steps | score: [0.04160178452730179, -0.023087453097105026]\n",
      "2400 steps | score: [0.038661833852529526, -0.020688846707344055]\n",
      "2500 steps | score: [0.020195042714476585, -0.0011557673569768667]\n",
      "2600 steps | score: [0.02502545341849327, -0.006321096792817116]\n",
      "2700 steps | score: [0.05183696001768112, -0.03684069588780403]\n",
      "2800 steps | score: [0.02816106379032135, -0.0057724760845303535]\n",
      "0 steps | score: [0.11712987720966339, -0.005337086506187916]\n",
      "100 steps | score: [0.14874723553657532, -0.2793588936328888]\n",
      "200 steps | score: [0.07961520552635193, -0.17407511174678802]\n",
      "300 steps | score: [-0.04141151160001755, -0.008856683038175106]\n",
      "400 steps | score: [0.0814913734793663, -0.16990061104297638]\n",
      "500 steps | score: [0.014638853259384632, -0.08275822550058365]\n",
      "600 steps | score: [0.03309900313615799, -0.09580458700656891]\n",
      "700 steps | score: [-0.03939168155193329, -0.03628681227564812]\n",
      "800 steps | score: [0.058304063975811005, -0.13493388891220093]\n",
      "900 steps | score: [0.09870573878288269, -0.18867170810699463]\n",
      "1000 steps | score: [-0.022102197632193565, -0.034940205514431]\n",
      "1100 steps | score: [0.037738487124443054, -0.1149461567401886]\n",
      "1200 steps | score: [0.03718055039644241, -0.12850669026374817]\n",
      "1300 steps | score: [0.06274677813053131, -0.13146167993545532]\n",
      "1400 steps | score: [-0.03641657158732414, -0.02763938158750534]\n",
      "1500 steps | score: [0.025759302079677582, -0.101883664727211]\n",
      "1600 steps | score: [0.05043776333332062, -0.12118983268737793]\n",
      "1700 steps | score: [0.011646019294857979, -0.07485456019639969]\n",
      "1800 steps | score: [-0.00244883936829865, -0.07344282418489456]\n",
      "1900 steps | score: [0.006690504495054483, -0.08969699591398239]\n",
      "2000 steps | score: [0.06532107293605804, -0.14408694207668304]\n",
      "2100 steps | score: [-0.009734740480780602, -0.06481701135635376]\n",
      "2200 steps | score: [0.011286644265055656, -0.08650672435760498]\n",
      "2300 steps | score: [0.0191970095038414, -0.09818975627422333]\n",
      "2400 steps | score: [0.017952343448996544, -0.09620510786771774]\n",
      "2500 steps | score: [-0.007053082343190908, -0.07165814936161041]\n",
      "2600 steps | score: [0.01086337212473154, -0.09016305208206177]\n",
      "2700 steps | score: [0.03447557985782623, -0.11038245260715485]\n",
      "2800 steps | score: [0.009069119580090046, -0.07943931967020035]\n",
      "0 steps | score: [0.08788492530584335, 0.08069345355033875]\n",
      "100 steps | score: [0.11515110731124878, -0.1976001113653183]\n",
      "200 steps | score: [0.08198527991771698, -0.13108520209789276]\n",
      "300 steps | score: [-0.06837663054466248, 0.06571605801582336]\n",
      "400 steps | score: [0.0520186722278595, -0.09008114039897919]\n",
      "500 steps | score: [-0.008758600801229477, -0.022816728800535202]\n",
      "600 steps | score: [0.013987088575959206, -0.025422552600502968]\n",
      "700 steps | score: [-0.05271433666348457, 0.03028850629925728]\n",
      "800 steps | score: [0.025552358478307724, -0.06498809903860092]\n",
      "900 steps | score: [0.07329955697059631, -0.10828585922718048]\n",
      "1000 steps | score: [-0.03955140709877014, 0.03368205204606056]\n",
      "1100 steps | score: [0.021604837849736214, -0.04030993580818176]\n",
      "1200 steps | score: [-0.0019601802341639996, -0.04183151200413704]\n",
      "1300 steps | score: [0.0329364575445652, -0.06023135036230087]\n",
      "1400 steps | score: [-0.05331382527947426, 0.03247831016778946]\n",
      "1500 steps | score: [0.008203446865081787, -0.03220296651124954]\n",
      "1600 steps | score: [0.02267145738005638, -0.04885130748152733]\n",
      "1700 steps | score: [-0.02277698554098606, -0.0016141445375978947]\n",
      "1800 steps | score: [-0.022119110450148582, -0.006631888449192047]\n",
      "1900 steps | score: [-0.022698387503623962, -0.010568823665380478]\n",
      "2000 steps | score: [0.0379800982773304, -0.07061363756656647]\n",
      "2100 steps | score: [-0.04069047048687935, 0.010813770815730095]\n",
      "2200 steps | score: [-0.009927036240696907, -0.01993066444993019]\n",
      "2300 steps | score: [0.0010464657098054886, -0.027269721031188965]\n",
      "2400 steps | score: [0.003461882472038269, -0.02973156049847603]\n",
      "2500 steps | score: [-0.030080847442150116, -0.0010097338818013668]\n",
      "2600 steps | score: [-0.01340150460600853, -0.0159589946269989]\n",
      "2700 steps | score: [0.014438185840845108, -0.041932474821805954]\n",
      "2800 steps | score: [-0.019436145201325417, -0.012149631977081299]\n",
      "unknown params:  tensor([-0.4333, -0.5866])\n",
      "unknown variance:  tensor([[0.9750]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4333, -0.5862])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.14600147306919098]\n",
      "100 steps | score: [0.014360889792442322]\n",
      "200 steps | score: [0.08358700573444366]\n",
      "300 steps | score: [-0.0759405791759491]\n",
      "400 steps | score: [-0.007208661176264286]\n",
      "0 steps | score: [0.11300695687532425, 0.0902668759226799]\n",
      "100 steps | score: [-0.04326244443655014, 0.031267907470464706]\n",
      "200 steps | score: [0.07116140425205231, -0.08406905829906464]\n",
      "300 steps | score: [-0.09163882583379745, 0.11461352556943893]\n",
      "400 steps | score: [0.017796389758586884, -0.06016451120376587]\n",
      "500 steps | score: [0.029086332768201828, -0.01746959611773491]\n",
      "600 steps | score: [-0.05622606724500656, 0.08018964529037476]\n",
      "700 steps | score: [-0.013529801741242409, 0.010684658773243427]\n",
      "800 steps | score: [-0.05575085058808327, 0.0534224733710289]\n",
      "900 steps | score: [-0.05428583174943924, 0.07199522852897644]\n",
      "1000 steps | score: [-0.06419772654771805, 0.07696005702018738]\n",
      "1100 steps | score: [-0.04674047231674194, 0.0378737635910511]\n",
      "1200 steps | score: [0.06853647530078888, -0.0991165041923523]\n",
      "1300 steps | score: [-0.04316774010658264, 0.04534072056412697]\n",
      "1400 steps | score: [0.06273745745420456, -0.09759849309921265]\n",
      "1500 steps | score: [0.07838039100170135, -0.10225411504507065]\n",
      "1600 steps | score: [-0.026249565184116364, 0.03587709367275238]\n",
      "1700 steps | score: [0.010161399841308594, -0.025455132126808167]\n",
      "1800 steps | score: [0.02235529199242592, -0.029534436762332916]\n",
      "1900 steps | score: [-0.018578587099909782, 0.025138650089502335]\n",
      "2000 steps | score: [-0.008425573818385601, 0.004386012442409992]\n",
      "0 steps | score: [0.1445961445569992, 0.06672411412000656]\n",
      "100 steps | score: [-0.006766629870980978, 0.0017463862895965576]\n",
      "0 steps | score: [0.0982915461063385, 0.10020817071199417]\n",
      "100 steps | score: [-0.051378149539232254, 0.029786905273795128]\n",
      "200 steps | score: [0.0419035404920578, -0.06660985946655273]\n",
      "300 steps | score: [-0.10307375341653824, 0.12115373462438583]\n",
      "400 steps | score: [-0.0029249226208776236, -0.04218437150120735]\n",
      "500 steps | score: [0.01058744452893734, -0.0023151952773332596]\n",
      "600 steps | score: [-0.0703682005405426, 0.09007104486227036]\n",
      "700 steps | score: [-0.027906015515327454, 0.013592167757451534]\n",
      "800 steps | score: [-0.0605841800570488, 0.05058315396308899]\n",
      "900 steps | score: [-0.08277511596679688, 0.08835583925247192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 steps | score: [-0.07275299727916718, 0.07121704518795013]\n",
      "1100 steps | score: [-0.0637843906879425, 0.042886145412921906]\n",
      "1200 steps | score: [0.05434728041291237, -0.08463553339242935]\n",
      "1300 steps | score: [-0.05064123496413231, 0.04550053924322128]\n",
      "1400 steps | score: [0.05471082031726837, -0.10146266967058182]\n",
      "1500 steps | score: [0.06776343286037445, -0.10746490210294724]\n",
      "1600 steps | score: [-0.04417984560132027, 0.04305990785360336]\n",
      "1700 steps | score: [-0.003635463770478964, -0.005436368752270937]\n",
      "unknown params:  tensor([-0.4642, -0.7358])\n",
      "unknown variance:  tensor([[1.0395]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4333, -0.5862])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.20380938053131104]\n",
      "100 steps | score: [-0.037273939698934555]\n",
      "200 steps | score: [0.04356137663125992]\n",
      "300 steps | score: [-0.0862526223063469]\n",
      "400 steps | score: [-0.027839265763759613]\n",
      "500 steps | score: [0.024802669882774353]\n",
      "600 steps | score: [-0.06098776310682297]\n",
      "700 steps | score: [-0.020747851580381393]\n",
      "800 steps | score: [0.008275642991065979]\n",
      "0 steps | score: [0.11376073211431503, 0.13871045410633087]\n",
      "100 steps | score: [-0.1176062673330307, 0.1653258353471756]\n",
      "200 steps | score: [0.02052178606390953, 0.006495973095297813]\n",
      "300 steps | score: [-0.1238480880856514, 0.18769598007202148]\n",
      "400 steps | score: [-0.0478583425283432, 0.04916771501302719]\n",
      "500 steps | score: [-0.018605928868055344, 0.03054714947938919]\n",
      "600 steps | score: [-0.07744549214839935, 0.1359098255634308]\n",
      "700 steps | score: [-0.010538854636251926, 0.024633415043354034]\n",
      "800 steps | score: [-0.018303902819752693, 0.04796123132109642]\n",
      "900 steps | score: [-0.060670748353004456, 0.1177000105381012]\n",
      "1000 steps | score: [0.033049676567316055, -0.0495762899518013]\n",
      "1100 steps | score: [0.024581940844655037, -0.025258231908082962]\n",
      "1200 steps | score: [-0.05680220201611519, 0.10258280485868454]\n",
      "1300 steps | score: [0.0301683209836483, -0.03796885535120964]\n",
      "1400 steps | score: [0.029981931671500206, -0.028712064027786255]\n",
      "1500 steps | score: [-0.04663773253560066, 0.09746149182319641]\n",
      "1600 steps | score: [0.018333248794078827, -0.016053948551416397]\n",
      "1700 steps | score: [0.030236737802624702, -0.021757278591394424]\n",
      "1800 steps | score: [-0.05169431120157242, 0.10630424320697784]\n",
      "1900 steps | score: [0.02350888028740883, -0.02056586742401123]\n",
      "2000 steps | score: [0.04207276180386543, -0.04392202943563461]\n",
      "2100 steps | score: [-0.04334484040737152, 0.08755341917276382]\n",
      "2200 steps | score: [0.004970037378370762, 0.01043455395847559]\n",
      "2300 steps | score: [0.03413261100649834, -0.02311217226088047]\n",
      "2400 steps | score: [-0.036246128380298615, 0.07289474457502365]\n",
      "2500 steps | score: [0.002716746646910906, 0.011765187606215477]\n",
      "2600 steps | score: [0.03064153343439102, -0.02565200813114643]\n",
      "2700 steps | score: [-0.021664554253220558, 0.05694333091378212]\n",
      "0 steps | score: [0.17440208792686462, 0.03458590805530548]\n",
      "100 steps | score: [-0.0773901492357254, 0.0853736475110054]\n",
      "200 steps | score: [0.05577078461647034, -0.06569225341081619]\n",
      "300 steps | score: [-0.09687166661024094, 0.1195107027888298]\n",
      "400 steps | score: [-0.016822902485728264, -0.0043054018169641495]\n",
      "500 steps | score: [0.014184514060616493, -0.012770997360348701]\n",
      "600 steps | score: [-0.059860993176698685, 0.07289287447929382]\n",
      "700 steps | score: [0.00786525197327137, -0.04064297676086426]\n",
      "800 steps | score: [-0.01944793574512005, 0.004099549725651741]\n",
      "900 steps | score: [-0.019945619627833366, 0.034042079001665115]\n",
      "1000 steps | score: [0.03464655205607414, -0.06770816445350647]\n",
      "1100 steps | score: [0.04018227010965347, -0.06363892555236816]\n",
      "1200 steps | score: [-0.029881184920668602, 0.04386419057846069]\n",
      "1300 steps | score: [0.052984386682510376, -0.08498802781105042]\n",
      "1400 steps | score: [0.045581839978694916, -0.06636439263820648]\n",
      "1500 steps | score: [-0.018156448379158974, 0.025473829358816147]\n",
      "1600 steps | score: [0.03667209669947624, -0.05838907137513161]\n",
      "1700 steps | score: [0.0347200371325016, -0.06882715225219727]\n",
      "1800 steps | score: [-0.028172805905342102, 0.041740305721759796]\n",
      "1900 steps | score: [0.039812978357076645, -0.06674672663211823]\n",
      "2000 steps | score: [0.05392463132739067, -0.07691453397274017]\n",
      "2100 steps | score: [-0.0242429431527853, 0.020548123866319656]\n",
      "2200 steps | score: [0.025439001619815826, -0.04516513645648956]\n",
      "2300 steps | score: [0.043745897710323334, -0.0681663453578949]\n",
      "2400 steps | score: [-0.0225620549172163, 0.013880928047001362]\n",
      "2500 steps | score: [0.02569563500583172, -0.03958718478679657]\n",
      "2600 steps | score: [0.04836535453796387, -0.06615351885557175]\n",
      "2700 steps | score: [-0.004096446558833122, 0.0037165749818086624]\n",
      "0 steps | score: [0.17639777064323425, 0.04329288750886917]\n",
      "100 steps | score: [-0.07493193447589874, 0.0856446847319603]\n",
      "200 steps | score: [0.06459429860115051, -0.055218540132045746]\n",
      "300 steps | score: [-0.08265990763902664, 0.12109667807817459]\n",
      "400 steps | score: [-0.0003608828701544553, -0.011170302517712116]\n",
      "500 steps | score: [0.028643615543842316, -0.026614602655172348]\n",
      "600 steps | score: [-0.03934898599982262, 0.07390610128641129]\n",
      "700 steps | score: [0.009000007063150406, -0.022915426641702652]\n",
      "800 steps | score: [0.01513778418302536, -0.013698888942599297]\n",
      "900 steps | score: [-0.01205581147223711, 0.03735887259244919]\n",
      "1000 steps | score: [0.07402265816926956, -0.09568289667367935]\n",
      "1100 steps | score: [0.06619256734848022, -0.07950222492218018]\n",
      "1200 steps | score: [-0.005484878085553646, 0.022889893501996994]\n",
      "1300 steps | score: [0.07473736256361008, -0.10722146183252335]\n",
      "1400 steps | score: [0.07388695329427719, -0.08669503778219223]\n",
      "1500 steps | score: [-0.006603742949664593, 0.028186392039060593]\n",
      "1600 steps | score: [0.07376575469970703, -0.0897790789604187]\n",
      "1700 steps | score: [0.07997949421405792, -0.0884326621890068]\n",
      "1800 steps | score: [-0.01965971104800701, 0.040877848863601685]\n",
      "1900 steps | score: [0.07539048790931702, -0.09211358428001404]\n",
      "2000 steps | score: [0.07831989228725433, -0.09364345669746399]\n",
      "2100 steps | score: [0.015948176383972168, 0.0006872257217764854]\n",
      "2200 steps | score: [0.0473722442984581, -0.059843625873327255]\n",
      "2300 steps | score: [0.0793343111872673, -0.0934552252292633]\n",
      "2400 steps | score: [0.0025100174825638533, 0.009779686108231544]\n",
      "unknown params:  tensor([-0.5005, -0.9003])\n",
      "unknown variance:  tensor([[1.1296]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4333, -0.5862])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.18967577815055847]\n",
      "100 steps | score: [-0.0838727056980133]\n",
      "200 steps | score: [-0.06224633380770683]\n",
      "300 steps | score: [-0.043560199439525604]\n",
      "400 steps | score: [-0.1043621078133583]\n",
      "500 steps | score: [-0.07110711187124252]\n",
      "600 steps | score: [-0.0164533331990242]\n",
      "700 steps | score: [-0.006780847907066345]\n",
      "0 steps | score: [0.19162917137145996, -0.0013568978756666183]\n",
      "100 steps | score: [-0.017842747271060944, 0.05658001825213432]\n",
      "200 steps | score: [-0.08332648873329163, 0.1356278657913208]\n",
      "300 steps | score: [0.08485379815101624, -0.10524533689022064]\n",
      "400 steps | score: [0.007461808621883392, -0.027838049456477165]\n",
      "500 steps | score: [-0.07589403539896011, 0.11404041200876236]\n",
      "600 steps | score: [0.09095864742994308, -0.1339949071407318]\n",
      "700 steps | score: [0.155370831489563, -0.2627882957458496]\n",
      "800 steps | score: [-0.04551484435796738, 0.08561241626739502]\n",
      "900 steps | score: [0.14813873171806335, -0.23651377856731415]\n",
      "1000 steps | score: [0.0571088083088398, -0.08630078285932541]\n",
      "1100 steps | score: [-0.0485667958855629, 0.07507491111755371]\n",
      "1200 steps | score: [0.006311587989330292, -0.018557563424110413]\n",
      "1300 steps | score: [-0.04437004402279854, 0.06322309374809265]\n",
      "1400 steps | score: [0.0985463410615921, -0.1569894254207611]\n",
      "1500 steps | score: [0.07560589164495468, -0.12810929119586945]\n",
      "1600 steps | score: [-0.015007046051323414, 0.025812160223722458]\n",
      "1700 steps | score: [0.03608626499772072, -0.06653334945440292]\n",
      "1800 steps | score: [0.08776262402534485, -0.15636128187179565]\n",
      "1900 steps | score: [0.019212480634450912, -0.025978857651352882]\n",
      "2000 steps | score: [0.06766393780708313, -0.11576901376247406]\n",
      "2100 steps | score: [0.07263809442520142, -0.11970766633749008]\n",
      "2200 steps | score: [-0.016224205493927002, 0.015522257424890995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300 steps | score: [0.032202139496803284, -0.048313338309526443]\n",
      "2400 steps | score: [0.03596990182995796, -0.05585642531514168]\n",
      "2500 steps | score: [0.016368739306926727, -0.019457833841443062]\n",
      "2600 steps | score: [0.03739076107740402, -0.06431606411933899]\n",
      "2700 steps | score: [0.022144587710499763, -0.034531425684690475]\n",
      "0 steps | score: [0.08065130561590195, 0.13659349083900452]\n",
      "100 steps | score: [-0.10338931530714035, 0.16974849998950958]\n",
      "200 steps | score: [-0.1779731959104538, 0.2539801299571991]\n",
      "300 steps | score: [-0.006001999601721764, 0.020862122997641563]\n",
      "400 steps | score: [-0.08591187000274658, 0.08243104070425034]\n",
      "500 steps | score: [-0.1438940167427063, 0.1948147863149643]\n",
      "600 steps | score: [-0.005236743483692408, -0.004698185250163078]\n",
      "0 steps | score: [0.17450134456157684, 0.019502243027091026]\n",
      "100 steps | score: [-0.03541693463921547, 0.08054523169994354]\n",
      "200 steps | score: [-0.09503421932458878, 0.14732736349105835]\n",
      "300 steps | score: [0.06695330142974854, -0.08042842894792557]\n",
      "400 steps | score: [-0.021799372509121895, 0.009519139304757118]\n",
      "500 steps | score: [-0.05168231576681137, 0.08036646991968155]\n",
      "600 steps | score: [0.05783788859844208, -0.08021847903728485]\n",
      "700 steps | score: [0.12590092420578003, -0.2201153039932251]\n",
      "800 steps | score: [-0.05699819326400757, 0.09294119477272034]\n",
      "900 steps | score: [0.11716701090335846, -0.1966177076101303]\n",
      "1000 steps | score: [0.04310132935643196, -0.09017615020275116]\n",
      "1100 steps | score: [-0.05136065185070038, 0.08799437433481216]\n",
      "1200 steps | score: [-0.008558693341910839, 0.0037224870175123215]\n",
      "unknown params:  tensor([-0.5497, -1.1786])\n",
      "unknown variance:  tensor([[1.2763]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4333, -0.5862])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.27684465050697327]\n",
      "100 steps | score: [0.09138372540473938]\n",
      "200 steps | score: [0.02407137304544449]\n",
      "300 steps | score: [0.06603121012449265]\n",
      "400 steps | score: [0.09872108697891235]\n",
      "500 steps | score: [0.022148121148347855]\n",
      "600 steps | score: [0.09544774144887924]\n",
      "700 steps | score: [0.049608103930950165]\n",
      "800 steps | score: [0.09630340337753296]\n",
      "900 steps | score: [0.08096630871295929]\n",
      "1000 steps | score: [0.07195413112640381]\n",
      "1100 steps | score: [0.05809703469276428]\n",
      "1200 steps | score: [0.05898749828338623]\n",
      "1300 steps | score: [0.0651465654373169]\n",
      "1400 steps | score: [0.09068675339221954]\n",
      "1500 steps | score: [0.0611572340130806]\n",
      "1600 steps | score: [0.07676530629396439]\n",
      "1700 steps | score: [0.046374235302209854]\n",
      "1800 steps | score: [0.05308224633336067]\n",
      "1900 steps | score: [0.06224202737212181]\n",
      "2000 steps | score: [0.06025618314743042]\n",
      "2100 steps | score: [0.09843948483467102]\n",
      "2200 steps | score: [0.04830123484134674]\n",
      "2300 steps | score: [0.059941984713077545]\n",
      "2400 steps | score: [0.07030267268419266]\n",
      "2500 steps | score: [0.05128663778305054]\n",
      "2600 steps | score: [0.06716297566890717]\n",
      "0 steps | score: [0.14592401683330536, 0.05489552766084671]\n",
      "100 steps | score: [0.20746643841266632, -0.2881934642791748]\n",
      "200 steps | score: [-0.13817642629146576, 0.24940425157546997]\n",
      "300 steps | score: [0.05460125952959061, -0.09702517092227936]\n",
      "400 steps | score: [-0.11159154772758484, 0.17562708258628845]\n",
      "500 steps | score: [-0.02637566439807415, 0.06458361446857452]\n",
      "600 steps | score: [0.023848336189985275, -0.056673116981983185]\n",
      "700 steps | score: [-0.02646510675549507, 0.04973911866545677]\n",
      "800 steps | score: [0.05213858559727669, -0.10935050249099731]\n",
      "900 steps | score: [-0.043171774595975876, 0.06295228004455566]\n",
      "1000 steps | score: [0.04731789603829384, -0.08865790069103241]\n",
      "1100 steps | score: [-0.014276944100856781, 0.014693963341414928]\n",
      "1200 steps | score: [-0.08983471244573593, 0.1316630095243454]\n",
      "1300 steps | score: [-0.09113157540559769, 0.12944532930850983]\n",
      "1400 steps | score: [-0.10855632275342941, 0.16921234130859375]\n",
      "1500 steps | score: [-0.0022318544797599316, 0.009779137559235096]\n",
      "0 steps | score: [0.18771176040172577, -0.030319873243570328]\n",
      "100 steps | score: [0.21951894462108612, -0.3168345093727112]\n",
      "200 steps | score: [-0.10807418823242188, 0.19028139114379883]\n",
      "300 steps | score: [0.07990922033786774, -0.14172761142253876]\n",
      "400 steps | score: [-0.03820354491472244, 0.05110330134630203]\n",
      "500 steps | score: [0.02000526711344719, -0.021900523453950882]\n",
      "600 steps | score: [0.06103897467255592, -0.12393422424793243]\n",
      "700 steps | score: [0.018826650455594063, -0.023418843746185303]\n",
      "800 steps | score: [0.09080716222524643, -0.18204347789287567]\n",
      "900 steps | score: [-0.014130305498838425, 0.0025118859484791756]\n",
      "1000 steps | score: [0.0965547189116478, -0.185127392411232]\n",
      "1100 steps | score: [0.04110115021467209, -0.09186862409114838]\n",
      "1200 steps | score: [-0.05511706322431564, 0.07407858967781067]\n",
      "1300 steps | score: [-0.04306645318865776, 0.054538048803806305]\n",
      "1400 steps | score: [-0.06181875243782997, 0.08372651040554047]\n",
      "1500 steps | score: [0.05684679374098778, -0.10568051040172577]\n",
      "1600 steps | score: [0.10163389146327972, -0.19678223133087158]\n",
      "1700 steps | score: [-0.047315813601017, 0.05795736238360405]\n",
      "1800 steps | score: [0.032696060836315155, -0.07215114682912827]\n",
      "1900 steps | score: [-0.010872256942093372, -0.008847122080624104]\n",
      "2000 steps | score: [0.046368587762117386, -0.09519761055707932]\n",
      "2100 steps | score: [0.07311135530471802, -0.1494140625]\n",
      "2200 steps | score: [-0.05756770819425583, 0.0784047544002533]\n",
      "2300 steps | score: [0.030905326828360558, -0.0664825513958931]\n",
      "2400 steps | score: [0.0084223048761487, -0.03677693009376526]\n",
      "2500 steps | score: [0.05160360410809517, -0.1122133657336235]\n",
      "2600 steps | score: [0.07712697982788086, -0.1373462826013565]\n",
      "0 steps | score: [0.2249925583600998, -0.02493363618850708]\n",
      "100 steps | score: [0.2545531392097473, -0.32177019119262695]\n",
      "200 steps | score: [-0.06171313300728798, 0.1746903657913208]\n",
      "300 steps | score: [0.08766183257102966, -0.08084750175476074]\n",
      "400 steps | score: [-0.005527843721210957, 0.05075404420495033]\n",
      "500 steps | score: [0.07496505230665207, -0.04416244104504585]\n",
      "600 steps | score: [0.10291943699121475, -0.12396273016929626]\n",
      "700 steps | score: [0.056971821933984756, -0.03222866728901863]\n",
      "800 steps | score: [0.13693082332611084, -0.18319615721702576]\n",
      "900 steps | score: [0.02943073958158493, 0.0014196038246154785]\n",
      "1000 steps | score: [0.13657572865486145, -0.16776658594608307]\n",
      "1100 steps | score: [0.06648799031972885, -0.05392621085047722]\n",
      "1200 steps | score: [-0.007263722829520702, 0.06859522312879562]\n",
      "1300 steps | score: [-0.019917083904147148, 0.07925982773303986]\n",
      "1400 steps | score: [-0.04520469903945923, 0.11408478766679764]\n",
      "1500 steps | score: [0.06904824078083038, -0.05958917737007141]\n",
      "1600 steps | score: [0.12630993127822876, -0.16420221328735352]\n",
      "1700 steps | score: [-0.011127893812954426, 0.06199175864458084]\n",
      "1800 steps | score: [0.0680151954293251, -0.06372417509555817]\n",
      "1900 steps | score: [0.017882701009511948, 0.03167888522148132]\n",
      "2000 steps | score: [0.05945878103375435, -0.051376283168792725]\n",
      "2100 steps | score: [0.10993587225675583, -0.13850995898246765]\n",
      "2200 steps | score: [-0.03687524050474167, 0.11268927156925201]\n",
      "2300 steps | score: [0.03976762667298317, -0.020936012268066406]\n",
      "2400 steps | score: [0.03478481248021126, -0.012174349278211594]\n",
      "2500 steps | score: [0.09419051557779312, -0.10561972856521606]\n",
      "2600 steps | score: [0.07948178797960281, -0.09448334574699402]\n",
      "unknown params:  tensor([-0.5752, -1.4447])\n",
      "unknown variance:  tensor([[1.4569]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4333, -0.5862])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.15346795320510864]\n",
      "100 steps | score: [-0.0773761048913002]\n",
      "200 steps | score: [-0.0983835980296135]\n",
      "300 steps | score: [-0.08153390139341354]\n",
      "400 steps | score: [-0.06871470808982849]\n",
      "500 steps | score: [-0.09357544779777527]\n",
      "600 steps | score: [-0.10680577903985977]\n",
      "700 steps | score: [-0.043756045401096344]\n",
      "800 steps | score: [-0.09835326671600342]\n",
      "900 steps | score: [-0.03696638345718384]\n",
      "1000 steps | score: [-0.02836698666214943]\n",
      "1100 steps | score: [-0.05768415331840515]\n",
      "1200 steps | score: [-0.054435938596725464]\n",
      "1300 steps | score: [-0.10017633438110352]\n",
      "1400 steps | score: [-0.09048618376255035]\n",
      "1500 steps | score: [-0.1207575723528862]\n",
      "1600 steps | score: [-0.08999349176883698]\n",
      "1700 steps | score: [-0.09987848997116089]\n",
      "1800 steps | score: [-0.09169259667396545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [-0.08016713708639145]\n",
      "2000 steps | score: [-0.08717365562915802]\n",
      "2100 steps | score: [-0.08365281671285629]\n",
      "2200 steps | score: [-0.06808160245418549]\n",
      "2300 steps | score: [-0.061160847544670105]\n",
      "2400 steps | score: [-0.07876238226890564]\n",
      "2500 steps | score: [-0.05926061421632767]\n",
      "0 steps | score: [0.21113279461860657, -0.15905454754829407]\n",
      "100 steps | score: [0.06375864893198013, -0.07477302104234695]\n",
      "200 steps | score: [-0.025277266278862953, 0.05333439260721207]\n",
      "300 steps | score: [0.3674220144748688, -0.8251473307609558]\n",
      "400 steps | score: [0.24583588540554047, -0.5395205020904541]\n",
      "500 steps | score: [-0.12108419835567474, 0.15428650379180908]\n",
      "600 steps | score: [0.034405723214149475, -0.11335575580596924]\n",
      "700 steps | score: [0.27698540687561035, -0.6083170771598816]\n",
      "800 steps | score: [-0.10953117907047272, 0.1272895187139511]\n",
      "900 steps | score: [0.1065988764166832, -0.2580426335334778]\n",
      "1000 steps | score: [0.1374448984861374, -0.34179311990737915]\n",
      "1100 steps | score: [0.067806676030159, -0.17401191592216492]\n",
      "1200 steps | score: [0.11307650804519653, -0.29290828108787537]\n",
      "1300 steps | score: [-0.040304865688085556, 0.011120401322841644]\n",
      "1400 steps | score: [0.028427425771951675, -0.12708306312561035]\n",
      "1500 steps | score: [-0.038741111755371094, 0.008110303431749344]\n",
      "1600 steps | score: [0.08464343100786209, -0.23152193427085876]\n",
      "1700 steps | score: [0.0259684007614851, -0.10487628728151321]\n",
      "1800 steps | score: [0.014739499427378178, -0.0991082713007927]\n",
      "1900 steps | score: [0.016154425218701363, -0.08771421015262604]\n",
      "2000 steps | score: [0.008090082556009293, -0.0787840336561203]\n",
      "2100 steps | score: [-0.0027017679531127214, -0.06074847653508186]\n",
      "2200 steps | score: [0.11167878657579422, -0.28071045875549316]\n",
      "2300 steps | score: [-0.00635259784758091, -0.055029381066560745]\n",
      "2400 steps | score: [0.06232047080993652, -0.19021478295326233]\n",
      "2500 steps | score: [0.08910687267780304, -0.23027829825878143]\n",
      "0 steps | score: [0.198820561170578, -0.09201172739267349]\n",
      "100 steps | score: [0.08950348943471909, -0.0706905946135521]\n",
      "200 steps | score: [-0.04262254387140274, 0.11973582953214645]\n",
      "300 steps | score: [0.30166077613830566, -0.674112856388092]\n",
      "400 steps | score: [0.2041471153497696, -0.41091376543045044]\n",
      "500 steps | score: [-0.11509119719266891, 0.18149961531162262]\n",
      "600 steps | score: [-0.009692436084151268, -0.009148044511675835]\n",
      "0 steps | score: [0.16726315021514893, 0.03466731309890747]\n",
      "100 steps | score: [0.05788537114858627, 0.05713387578725815]\n",
      "200 steps | score: [-0.052066490054130554, 0.19797591865062714]\n",
      "300 steps | score: [0.389955073595047, -0.8100842237472534]\n",
      "400 steps | score: [0.2144099324941635, -0.37428897619247437]\n",
      "500 steps | score: [-0.13119876384735107, 0.2794642448425293]\n",
      "600 steps | score: [-0.023754732683300972, 0.09886429458856583]\n",
      "700 steps | score: [0.23072806000709534, -0.4134165346622467]\n",
      "800 steps | score: [-0.1605525016784668, 0.3202682137489319]\n",
      "900 steps | score: [0.07148575037717819, -0.09204917401075363]\n",
      "1000 steps | score: [0.12961561977863312, -0.22634902596473694]\n",
      "1100 steps | score: [0.06111270934343338, -0.054404664784669876]\n",
      "1200 steps | score: [0.09490882605314255, -0.14405690133571625]\n",
      "1300 steps | score: [-0.06583569943904877, 0.16916222870349884]\n",
      "1400 steps | score: [-0.013040635734796524, 0.06136142462491989]\n",
      "1500 steps | score: [-0.07533227652311325, 0.17881076037883759]\n",
      "1600 steps | score: [0.05971153452992439, -0.08508076518774033]\n",
      "1700 steps | score: [-0.01977028325200081, 0.07778964936733246]\n",
      "1800 steps | score: [-0.007505118381232023, 0.04658113420009613]\n",
      "1900 steps | score: [0.0051271067932248116, 0.03788357600569725]\n",
      "2000 steps | score: [-0.033055342733860016, 0.09717027842998505]\n",
      "2100 steps | score: [-0.03850294277071953, 0.11842264980077744]\n",
      "2200 steps | score: [0.08614076673984528, -0.12232253700494766]\n",
      "2300 steps | score: [-0.018706955015659332, 0.08621034026145935]\n",
      "2400 steps | score: [0.03094923123717308, -0.014715859666466713]\n",
      "2500 steps | score: [0.07587533444166183, -0.10226240754127502]\n",
      "unknown params:  tensor([-0.5548, -1.6055])\n",
      "unknown variance:  tensor([[1.6845]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4333, -0.5862])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2677586078643799]\n",
      "100 steps | score: [0.059929948300123215]\n",
      "200 steps | score: [0.024516459554433823]\n",
      "300 steps | score: [0.06691815704107285]\n",
      "400 steps | score: [0.04938681796193123]\n",
      "500 steps | score: [0.012971531599760056]\n",
      "600 steps | score: [0.08233162760734558]\n",
      "700 steps | score: [0.004796307533979416]\n",
      "0 steps | score: [0.12377402931451797, -0.031603410840034485]\n",
      "100 steps | score: [0.2750125527381897, -0.49965205788612366]\n",
      "200 steps | score: [0.17267385125160217, -0.30119919776916504]\n",
      "300 steps | score: [-0.08668123930692673, 0.14311674237251282]\n",
      "400 steps | score: [0.09163137525320053, -0.21286000311374664]\n",
      "500 steps | score: [-0.20631526410579681, 0.35862022638320923]\n",
      "600 steps | score: [0.13498766720294952, -0.34369659423828125]\n",
      "700 steps | score: [-0.17748309671878815, 0.30262240767478943]\n",
      "800 steps | score: [-0.1496926099061966, 0.24852541089057922]\n",
      "900 steps | score: [-0.19498170912265778, 0.331095427274704]\n",
      "1000 steps | score: [-0.10319145768880844, 0.1386430710554123]\n",
      "1100 steps | score: [-0.18899847567081451, 0.3243328332901001]\n",
      "1200 steps | score: [0.10306628048419952, -0.3064810633659363]\n",
      "1300 steps | score: [-0.05704494193196297, 0.06265340745449066]\n",
      "1400 steps | score: [-0.05937667191028595, 0.05298766866326332]\n",
      "1500 steps | score: [0.024404097348451614, -0.11613251268863678]\n",
      "1600 steps | score: [-0.14641812443733215, 0.2314595729112625]\n",
      "1700 steps | score: [0.07043422013521194, -0.2103482484817505]\n",
      "1800 steps | score: [-0.14014481008052826, 0.22179612517356873]\n",
      "1900 steps | score: [-0.10738949477672577, 0.1603548228740692]\n",
      "2000 steps | score: [-0.13832855224609375, 0.22289471328258514]\n",
      "2100 steps | score: [-0.04220329970121384, 0.030257530510425568]\n",
      "2200 steps | score: [-0.15306566655635834, 0.24849864840507507]\n",
      "2300 steps | score: [0.0052101630717515945, -0.07853053510189056]\n",
      "2400 steps | score: [-0.06720089167356491, 0.07784831523895264]\n",
      "2500 steps | score: [0.0031485999934375286, -0.07614670693874359]\n",
      "0 steps | score: [0.21590007841587067, -0.07745291292667389]\n",
      "100 steps | score: [0.40641623735427856, -0.6254056692123413]\n",
      "200 steps | score: [0.2537553012371063, -0.35517171025276184]\n",
      "300 steps | score: [0.016371523961424828, 0.07241486757993698]\n",
      "400 steps | score: [0.18340003490447998, -0.2660970687866211]\n",
      "500 steps | score: [-0.10182720422744751, 0.2861288785934448]\n",
      "600 steps | score: [0.20436358451843262, -0.3295934796333313]\n",
      "700 steps | score: [-0.09021791815757751, 0.25248274207115173]\n",
      "800 steps | score: [-0.04936249181628227, 0.18062135577201843]\n",
      "900 steps | score: [-0.09380272030830383, 0.26995599269866943]\n",
      "1000 steps | score: [-0.013060815632343292, 0.10698194801807404]\n",
      "1100 steps | score: [-0.07828467339277267, 0.22954337298870087]\n",
      "1200 steps | score: [0.159730926156044, -0.28796517848968506]\n",
      "1300 steps | score: [0.024231331422924995, 0.034530527889728546]\n",
      "1400 steps | score: [0.02482815459370613, 0.03090287744998932]\n",
      "1500 steps | score: [0.08035114407539368, -0.09716612845659256]\n",
      "1600 steps | score: [-0.06033601239323616, 0.1868031620979309]\n",
      "1700 steps | score: [0.1394457370042801, -0.21302442252635956]\n",
      "1800 steps | score: [-0.06185734272003174, 0.19534683227539062]\n",
      "1900 steps | score: [-0.018590372055768967, 0.11655440181493759]\n",
      "2000 steps | score: [-0.05148005858063698, 0.17862199246883392]\n",
      "2100 steps | score: [0.03719140589237213, -0.005922519601881504]\n",
      "2200 steps | score: [-0.07820126414299011, 0.2207076996564865]\n",
      "2300 steps | score: [0.09035306423902512, -0.11164160072803497]\n",
      "2400 steps | score: [0.01923111081123352, 0.025197990238666534]\n",
      "2500 steps | score: [0.09878255426883698, -0.12728974223136902]\n",
      "unknown params:  tensor([-0.4713, -1.4710])\n",
      "unknown variance:  tensor([[1.7760]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/3f1af34d-41c3-4eb4-af68-18c639a941a9\n",
      "gt params:  tensor([-0.4361, -0.5929])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.19345419108867645]\n",
      "100 steps | score: [0.07717324793338776]\n",
      "200 steps | score: [0.036854468286037445]\n",
      "300 steps | score: [0.10085837543010712]\n",
      "400 steps | score: [0.08781813085079193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [0.057029418647289276]\n",
      "600 steps | score: [0.12520083785057068]\n",
      "700 steps | score: [0.07921984791755676]\n",
      "800 steps | score: [0.052522219717502594]\n",
      "900 steps | score: [0.14458471536636353]\n",
      "1000 steps | score: [0.08418747037649155]\n",
      "1100 steps | score: [0.09666040539741516]\n",
      "1200 steps | score: [0.09001298993825912]\n",
      "1300 steps | score: [0.0722803920507431]\n",
      "1400 steps | score: [0.11259683966636658]\n",
      "1500 steps | score: [0.10120467841625214]\n",
      "1600 steps | score: [0.10046158730983734]\n",
      "1700 steps | score: [0.09305234253406525]\n",
      "1800 steps | score: [0.09710028767585754]\n",
      "1900 steps | score: [0.0975317507982254]\n",
      "2000 steps | score: [0.12135912477970123]\n",
      "2100 steps | score: [0.13048169016838074]\n",
      "2200 steps | score: [0.10768599063158035]\n",
      "2300 steps | score: [0.09334376454353333]\n",
      "2400 steps | score: [0.10695146024227142]\n",
      "2500 steps | score: [0.07019725441932678]\n",
      "2600 steps | score: [0.12788061797618866]\n",
      "0 steps | score: [0.003248180029913783, 0.03774670138955116]\n",
      "100 steps | score: [-0.03621118888258934, 0.013040466234087944]\n",
      "200 steps | score: [-0.05322425812482834, -0.00702824629843235]\n",
      "300 steps | score: [-0.021829472854733467, -0.015579601749777794]\n",
      "400 steps | score: [-0.012205053120851517, 0.0067724669352173805]\n",
      "500 steps | score: [-0.042735755443573, -0.025681763887405396]\n",
      "600 steps | score: [-0.011847754940390587, -0.038382966071367264]\n",
      "700 steps | score: [-0.029915550723671913, 0.016124140471220016]\n",
      "800 steps | score: [-0.01779419369995594, -0.01863875240087509]\n",
      "900 steps | score: [0.011994182132184505, -0.040633395314216614]\n",
      "1000 steps | score: [-0.031308021396398544, 0.007159204222261906]\n",
      "1100 steps | score: [-0.013862603344023228, 0.00019632652401924133]\n",
      "1200 steps | score: [-0.020374085754156113, -0.024757759645581245]\n",
      "1300 steps | score: [-0.018302470445632935, -0.0030723940581083298]\n",
      "1400 steps | score: [-0.013735121116042137, -0.020359326153993607]\n",
      "1500 steps | score: [-0.02904166281223297, -0.011221589520573616]\n",
      "1600 steps | score: [-0.01837809942662716, -0.007332762703299522]\n",
      "1700 steps | score: [-0.01556382142007351, -0.0289902463555336]\n",
      "1800 steps | score: [-0.021006012335419655, -0.02228258177638054]\n",
      "1900 steps | score: [-0.022750556468963623, -0.003990022465586662]\n",
      "2000 steps | score: [-0.025031069293618202, -0.00990142859518528]\n",
      "2100 steps | score: [-0.004220147617161274, -0.01514961663633585]\n",
      "2200 steps | score: [-0.021432047709822655, -0.016668187454342842]\n",
      "2300 steps | score: [-0.0222817063331604, -0.008558735251426697]\n",
      "2400 steps | score: [-0.022533312439918518, -0.013585740700364113]\n",
      "2500 steps | score: [-0.016465386375784874, -0.003703854978084564]\n",
      "2600 steps | score: [-0.012326275929808617, -0.007836584001779556]\n",
      "unknown params:  tensor([-0.4008, -0.4631])\n",
      "unknown variance:  tensor([[0.8245]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4361, -0.5929])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.12066786736249924]\n",
      "100 steps | score: [-0.04824371635913849]\n",
      "200 steps | score: [-0.06383271515369415]\n",
      "300 steps | score: [0.06807298213243484]\n",
      "400 steps | score: [-0.08326996862888336]\n",
      "500 steps | score: [-0.05264725536108017]\n",
      "600 steps | score: [-0.05269573628902435]\n",
      "700 steps | score: [0.013311352580785751]\n",
      "800 steps | score: [-0.049287717789411545]\n",
      "900 steps | score: [-0.05524798482656479]\n",
      "1000 steps | score: [-0.05772169679403305]\n",
      "1100 steps | score: [0.02551315724849701]\n",
      "1200 steps | score: [-0.052205972373485565]\n",
      "1300 steps | score: [-0.06518752872943878]\n",
      "1400 steps | score: [-0.06368514150381088]\n",
      "1500 steps | score: [0.021055571734905243]\n",
      "1600 steps | score: [-0.04182194545865059]\n",
      "1700 steps | score: [-0.06656916439533234]\n",
      "1800 steps | score: [-0.0346958227455616]\n",
      "1900 steps | score: [-0.002828851342201233]\n",
      "0 steps | score: [0.017818260937929153, 0.09067843854427338]\n",
      "100 steps | score: [-0.04643454775214195, -0.009204374626278877]\n",
      "200 steps | score: [-0.06031518056988716, 0.04361356049776077]\n",
      "300 steps | score: [0.051711827516555786, -0.08327586948871613]\n",
      "400 steps | score: [-0.04960402101278305, 0.014980550855398178]\n",
      "500 steps | score: [-0.06170468032360077, 0.005911803804337978]\n",
      "600 steps | score: [-0.0563528910279274, 0.033360742032527924]\n",
      "700 steps | score: [0.040498293936252594, -0.06059398874640465]\n",
      "800 steps | score: [-0.047253530472517014, 0.009690463542938232]\n",
      "900 steps | score: [-0.06366150081157684, 0.011404315009713173]\n",
      "1000 steps | score: [-0.045829229056835175, 0.019422883167862892]\n",
      "1100 steps | score: [0.01898679882287979, -0.035887207835912704]\n",
      "1200 steps | score: [-0.04082214832305908, 0.0018978072330355644]\n",
      "1300 steps | score: [-0.05856192111968994, 0.016709374263882637]\n",
      "1400 steps | score: [-0.04722202196717262, 0.015539232641458511]\n",
      "1500 steps | score: [0.009778497740626335, -0.02712288312613964]\n",
      "1600 steps | score: [-0.03903183341026306, 0.0022924281656742096]\n",
      "1700 steps | score: [-0.0574495792388916, 0.005326937884092331]\n",
      "1800 steps | score: [-0.043015770614147186, 0.006067247129976749]\n",
      "1900 steps | score: [-0.007144429255276918, -0.019688237458467484]\n",
      "2000 steps | score: [-0.03797278553247452, -0.001496739685535431]\n",
      "2100 steps | score: [-0.04933425411581993, -0.0016564298421144485]\n",
      "2200 steps | score: [-0.04618952423334122, 0.004286743700504303]\n",
      "2300 steps | score: [-0.01452348567545414, -0.007103129755705595]\n",
      "2400 steps | score: [-0.024782724678516388, -0.005668305791914463]\n",
      "2500 steps | score: [-0.039755500853061676, -0.0018463185988366604]\n",
      "2600 steps | score: [-0.04513201117515564, 0.003947089891880751]\n",
      "2700 steps | score: [-0.023512791842222214, -0.0018673634622246027]\n",
      "2800 steps | score: [-0.033148329704999924, -0.003666540142148733]\n",
      "0 steps | score: [0.03856804966926575, 0.12878009676933289]\n",
      "100 steps | score: [-0.04035872593522072, 0.03688327595591545]\n",
      "200 steps | score: [-0.04219704866409302, 0.07158534228801727]\n",
      "300 steps | score: [0.06769692152738571, -0.04287612438201904]\n",
      "400 steps | score: [-0.031072303652763367, 0.05018854886293411]\n",
      "500 steps | score: [-0.03935790807008743, 0.046855803579092026]\n",
      "600 steps | score: [-0.03587593883275986, 0.06385696679353714]\n",
      "700 steps | score: [0.05580500513315201, -0.02398190274834633]\n",
      "800 steps | score: [-0.02478501759469509, 0.039859339594841]\n",
      "900 steps | score: [-0.04649356007575989, 0.05371938273310661]\n",
      "1000 steps | score: [-0.03010900504887104, 0.05623948946595192]\n",
      "1100 steps | score: [0.03986341506242752, -0.0039018462412059307]\n",
      "1200 steps | score: [-0.028878388926386833, 0.038567960262298584]\n",
      "1300 steps | score: [-0.0404060073196888, 0.049516379833221436]\n",
      "1400 steps | score: [-0.03051132522523403, 0.048637278378009796]\n",
      "1500 steps | score: [0.02286776341497898, 0.007480509579181671]\n",
      "1600 steps | score: [-0.014451074413955212, 0.04033658653497696]\n",
      "1700 steps | score: [-0.032924897968769073, 0.041508570313453674]\n",
      "1800 steps | score: [-0.026679472997784615, 0.04381789639592171]\n",
      "1900 steps | score: [0.016156600788235664, 0.02233652025461197]\n",
      "2000 steps | score: [-0.012963831424713135, 0.03446529060602188]\n",
      "2100 steps | score: [-0.028343722224235535, 0.04213415086269379]\n",
      "2200 steps | score: [-0.02687513269484043, 0.0386185497045517]\n",
      "2300 steps | score: [-0.0006128840614110231, 0.021104587242007256]\n",
      "2400 steps | score: [-0.012070276774466038, 0.03138627111911774]\n",
      "2500 steps | score: [-0.02495935931801796, 0.036766692996025085]\n",
      "2600 steps | score: [-0.01922423765063286, 0.03603794053196907]\n",
      "2700 steps | score: [-0.007062356453388929, 0.025093551725149155]\n",
      "2800 steps | score: [-0.014097314327955246, 0.0342433787882328]\n",
      "0 steps | score: [0.08850150555372238, 0.009760748594999313]\n",
      "100 steps | score: [0.0019679071847349405, -0.06508315354585648]\n",
      "200 steps | score: [0.0049629430286586285, -0.035674113780260086]\n",
      "300 steps | score: [0.10623997449874878, -0.1499527543783188]\n",
      "400 steps | score: [0.01111537404358387, -0.05512674152851105]\n",
      "500 steps | score: [-0.006412583403289318, -0.06297194957733154]\n",
      "600 steps | score: [0.01422006357461214, -0.04322274029254913]\n",
      "700 steps | score: [0.1017584279179573, -0.1339729279279709]\n",
      "800 steps | score: [0.011789040639996529, -0.0638267770409584]\n",
      "900 steps | score: [-0.0074065448716282845, -0.05316823720932007]\n",
      "1000 steps | score: [0.0150784682482481, -0.04945634305477142]\n",
      "1100 steps | score: [0.0908336192369461, -0.11247490346431732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 steps | score: [0.020192507654428482, -0.06398753821849823]\n",
      "1300 steps | score: [0.006586027331650257, -0.060449808835983276]\n",
      "1400 steps | score: [0.015486903488636017, -0.05665053427219391]\n",
      "1500 steps | score: [0.07788466662168503, -0.09728202223777771]\n",
      "1600 steps | score: [0.030507458373904228, -0.06700382381677628]\n",
      "1700 steps | score: [0.005247316788882017, -0.06131373345851898]\n",
      "1800 steps | score: [0.013928613625466824, -0.058060422539711]\n",
      "1900 steps | score: [0.06203743442893028, -0.08697368204593658]\n",
      "2000 steps | score: [0.0361490398645401, -0.06860685348510742]\n",
      "2100 steps | score: [0.01589396595954895, -0.05719420686364174]\n",
      "2200 steps | score: [0.01679336093366146, -0.060550302267074585]\n",
      "2300 steps | score: [0.05159313976764679, -0.0764041319489479]\n",
      "2400 steps | score: [0.0339282788336277, -0.06903054565191269]\n",
      "2500 steps | score: [0.024781618267297745, -0.06708454340696335]\n",
      "2600 steps | score: [0.014834616333246231, -0.05839980021119118]\n",
      "2700 steps | score: [0.03901991993188858, -0.07464059442281723]\n",
      "2800 steps | score: [0.0318266861140728, -0.069224052131176]\n",
      "unknown params:  tensor([-0.4131, -0.4894])\n",
      "unknown variance:  tensor([[0.8558]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4361, -0.5929])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.4633861184120178]\n",
      "100 steps | score: [0.34493547677993774]\n",
      "200 steps | score: [0.29201266169548035]\n",
      "300 steps | score: [0.2948698401451111]\n",
      "400 steps | score: [0.237469881772995]\n",
      "500 steps | score: [0.3110436797142029]\n",
      "600 steps | score: [0.3202255368232727]\n",
      "700 steps | score: [0.3285922110080719]\n",
      "800 steps | score: [0.2482173591852188]\n",
      "900 steps | score: [0.29786133766174316]\n",
      "1000 steps | score: [0.2961530089378357]\n",
      "1100 steps | score: [0.29484614729881287]\n",
      "1200 steps | score: [0.25954461097717285]\n",
      "1300 steps | score: [0.27699702978134155]\n",
      "1400 steps | score: [0.35037466883659363]\n",
      "1500 steps | score: [0.3005707859992981]\n",
      "1600 steps | score: [0.2809019088745117]\n",
      "1700 steps | score: [0.30850210785865784]\n",
      "1800 steps | score: [0.3334374725818634]\n",
      "1900 steps | score: [0.30358052253723145]\n",
      "2000 steps | score: [0.305515319108963]\n",
      "2100 steps | score: [0.31166887283325195]\n",
      "2200 steps | score: [0.33214372396469116]\n",
      "2300 steps | score: [0.2776104807853699]\n",
      "2400 steps | score: [0.2885531783103943]\n",
      "2500 steps | score: [0.3092854619026184]\n",
      "2600 steps | score: [0.3054629862308502]\n",
      "0 steps | score: [0.06296079605817795, 0.1144431009888649]\n",
      "100 steps | score: [-0.00792993325740099, 0.046068161725997925]\n",
      "200 steps | score: [-0.013098157942295074, 0.0006306092254817486]\n",
      "300 steps | score: [-0.021625902503728867, 0.017116036266088486]\n",
      "400 steps | score: [-0.0571829229593277, 0.008406936191022396]\n",
      "500 steps | score: [0.04507903754711151, -0.027602924033999443]\n",
      "600 steps | score: [-0.008099821396172047, 0.04754920303821564]\n",
      "700 steps | score: [0.009336400777101517, -0.013804453425109386]\n",
      "800 steps | score: [-0.05661704018712044, 0.018248826265335083]\n",
      "900 steps | score: [0.005019642878323793, 0.012050787918269634]\n",
      "1000 steps | score: [-0.0009257326018996537, 0.027551615610718727]\n",
      "1100 steps | score: [-0.0259026437997818, 0.019123487174510956]\n",
      "1200 steps | score: [-0.059464067220687866, 0.055314645171165466]\n",
      "1300 steps | score: [-0.013686105608940125, 0.022838499397039413]\n",
      "1400 steps | score: [0.029215583577752113, -0.02066364698112011]\n",
      "1500 steps | score: [-0.02214503474533558, 0.012892886996269226]\n",
      "1600 steps | score: [-0.021527785807847977, 0.036057546734809875]\n",
      "1700 steps | score: [-0.0011075367219746113, 0.0008564316667616367]\n",
      "0 steps | score: [0.05112121254205704, 0.14958570897579193]\n",
      "100 steps | score: [-0.018038209527730942, 0.08233412355184555]\n",
      "200 steps | score: [-0.01993543840944767, 0.032152820378541946]\n",
      "300 steps | score: [-0.019262781366705894, 0.03600664436817169]\n",
      "400 steps | score: [-0.05880432575941086, 0.03386656939983368]\n",
      "500 steps | score: [0.05120198428630829, -0.013248182833194733]\n",
      "600 steps | score: [-0.0016730877105146646, 0.07047328352928162]\n",
      "700 steps | score: [0.005242789629846811, 0.016077738255262375]\n",
      "800 steps | score: [-0.046549443155527115, 0.03434932976961136]\n",
      "900 steps | score: [0.000770458544138819, 0.018929461017251015]\n",
      "1000 steps | score: [-0.013668236322700977, 0.054495107382535934]\n",
      "1100 steps | score: [-0.030984830111265182, 0.045596446841955185]\n",
      "1200 steps | score: [-0.059144143015146255, 0.08391425758600235]\n",
      "1300 steps | score: [-0.01183766033500433, 0.04007086157798767]\n",
      "1400 steps | score: [0.033171605318784714, -0.012432077899575233]\n",
      "1500 steps | score: [-0.01874985173344612, 0.03227291256189346]\n",
      "1600 steps | score: [-0.02398787997663021, 0.05720920115709305]\n",
      "1700 steps | score: [-0.006362533196806908, 0.03125747665762901]\n",
      "1800 steps | score: [-0.009563521482050419, 0.03350776433944702]\n",
      "1900 steps | score: [-0.012407098896801472, 0.0240680743008852]\n",
      "2000 steps | score: [-0.013978593982756138, 0.03292427957057953]\n",
      "2100 steps | score: [-0.013715505599975586, 0.03961659222841263]\n",
      "2200 steps | score: [-0.0018015253590419888, 0.02950451523065567]\n",
      "2300 steps | score: [-0.01393008604645729, 0.029702158644795418]\n",
      "2400 steps | score: [-0.013213060796260834, 0.03745461627840996]\n",
      "2500 steps | score: [-0.01110065821558237, 0.04117999225854874]\n",
      "2600 steps | score: [-0.008110064081847668, 0.03513775020837784]\n",
      "0 steps | score: [0.06111283227801323, 0.09573866426944733]\n",
      "100 steps | score: [-0.015333372168242931, 0.04338334500789642]\n",
      "200 steps | score: [-0.01957288198173046, -0.008066568523645401]\n",
      "300 steps | score: [-0.018138358369469643, 0.0013377955183386803]\n",
      "400 steps | score: [-0.050115592777729034, -0.005139651242643595]\n",
      "500 steps | score: [0.040442004799842834, -0.046355150640010834]\n",
      "600 steps | score: [-0.01184917613863945, 0.039873238652944565]\n",
      "700 steps | score: [-0.004534104373306036, -0.01847201958298683]\n",
      "800 steps | score: [-0.046155963093042374, -0.020120007917284966]\n",
      "900 steps | score: [0.005490534007549286, -0.007809074595570564]\n",
      "unknown params:  tensor([-0.4253, -0.4975])\n",
      "unknown variance:  tensor([[0.8841]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4361, -0.5929])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [-0.046731188893318176]\n",
      "100 steps | score: [-0.20434856414794922]\n",
      "200 steps | score: [-0.20507772266864777]\n",
      "300 steps | score: [-0.16273167729377747]\n",
      "400 steps | score: [-0.16194923222064972]\n",
      "500 steps | score: [-0.1786365956068039]\n",
      "600 steps | score: [-0.16474591195583344]\n",
      "700 steps | score: [-0.23041805624961853]\n",
      "800 steps | score: [-0.19243870675563812]\n",
      "900 steps | score: [-0.18957549333572388]\n",
      "1000 steps | score: [-0.13947978615760803]\n",
      "1100 steps | score: [-0.16210860013961792]\n",
      "1200 steps | score: [-0.1839357167482376]\n",
      "1300 steps | score: [-0.14118847250938416]\n",
      "1400 steps | score: [-0.1994839608669281]\n",
      "1500 steps | score: [-0.21775829792022705]\n",
      "1600 steps | score: [-0.18887579441070557]\n",
      "1700 steps | score: [-0.16141155362129211]\n",
      "1800 steps | score: [-0.16497363150119781]\n",
      "1900 steps | score: [-0.17928600311279297]\n",
      "2000 steps | score: [-0.15674227476119995]\n",
      "2100 steps | score: [-0.19060705602169037]\n",
      "2200 steps | score: [-0.1866760104894638]\n",
      "2300 steps | score: [-0.18155387043952942]\n",
      "2400 steps | score: [-0.18065598607063293]\n",
      "2500 steps | score: [-0.177330881357193]\n",
      "2600 steps | score: [-0.17678503692150116]\n",
      "2700 steps | score: [-0.1802535057067871]\n",
      "0 steps | score: [0.0732613354921341, 0.12954798340797424]\n",
      "100 steps | score: [-0.03287789970636368, 0.1071191355586052]\n",
      "200 steps | score: [-0.0344102643430233, 0.039647724479436874]\n",
      "300 steps | score: [0.013649629428982735, -0.03399483859539032]\n",
      "400 steps | score: [-0.02885093353688717, 0.03619614243507385]\n",
      "500 steps | score: [-0.031509947031736374, 0.016051240265369415]\n",
      "600 steps | score: [-0.005305590108036995, -0.004519332200288773]\n",
      "0 steps | score: [0.08864787966012955, 0.12857593595981598]\n",
      "100 steps | score: [-0.015553245320916176, 0.11073389649391174]\n",
      "200 steps | score: [-0.03647232428193092, 0.046078793704509735]\n",
      "300 steps | score: [0.01465562917292118, -0.011639881879091263]\n",
      "400 steps | score: [-0.024951934814453125, 0.04968375712633133]\n",
      "500 steps | score: [-0.03106917254626751, 0.02975066937506199]\n",
      "600 steps | score: [0.0003260740195401013, -0.0010061394423246384]\n",
      "0 steps | score: [0.058470211923122406, 0.09646943211555481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [-0.05042558163404465, 0.08436741679906845]\n",
      "200 steps | score: [-0.06391123682260513, 0.02675621211528778]\n",
      "300 steps | score: [0.0009650519350543618, -0.05140933394432068]\n",
      "400 steps | score: [-0.0575576014816761, 0.026387805119156837]\n",
      "500 steps | score: [-0.05246979370713234, -0.0018803086131811142]\n",
      "600 steps | score: [-0.017357148230075836, -0.029904937371611595]\n",
      "700 steps | score: [-0.09261006116867065, 0.02963264286518097]\n",
      "800 steps | score: [-0.05379897728562355, 0.0544256791472435]\n",
      "900 steps | score: [-0.05789262428879738, 0.025663908571004868]\n",
      "1000 steps | score: [-0.014111526310443878, -0.03522072732448578]\n",
      "1100 steps | score: [-0.057440195232629776, 0.01533803902566433]\n",
      "1200 steps | score: [-0.040148358792066574, -0.003828282468020916]\n",
      "1300 steps | score: [-0.024787109345197678, -0.019005613401532173]\n",
      "1400 steps | score: [-0.06053305044770241, 0.009302601218223572]\n",
      "1500 steps | score: [-0.0644778162240982, 0.046549778431653976]\n",
      "1600 steps | score: [-0.04748259484767914, 0.014180920086801052]\n",
      "1700 steps | score: [-0.02499060332775116, -0.014146381057798862]\n",
      "1800 steps | score: [-0.04655870422720909, 0.005334618501365185]\n",
      "1900 steps | score: [-0.05696903541684151, 0.010568847879767418]\n",
      "2000 steps | score: [-0.027839118614792824, -0.016347531229257584]\n",
      "2100 steps | score: [-0.053299449384212494, 0.0028764456510543823]\n",
      "2200 steps | score: [-0.059594932943582535, 0.02217002771794796]\n",
      "2300 steps | score: [-0.058781564235687256, 0.014260105788707733]\n",
      "2400 steps | score: [-0.03379762917757034, -0.009528156369924545]\n",
      "2500 steps | score: [-0.03561672568321228, -0.0035010408610105515]\n",
      "2600 steps | score: [-0.047402627766132355, 0.008206946775317192]\n",
      "2700 steps | score: [-0.036264918744564056, -0.007985491305589676]\n",
      "unknown params:  tensor([-0.4667, -0.6092])\n",
      "unknown variance:  tensor([[0.9608]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4361, -0.5929])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.20849592983722687]\n",
      "100 steps | score: [0.06703008711338043]\n",
      "200 steps | score: [0.0390174575150013]\n",
      "300 steps | score: [0.005892282351851463]\n",
      "0 steps | score: [0.10309679061174393, 0.1434796154499054]\n",
      "100 steps | score: [0.09972735494375229, -0.027177585288882256]\n",
      "200 steps | score: [0.0021439329721033573, 0.0332363098859787]\n",
      "300 steps | score: [-0.02511335350573063, 0.05202833190560341]\n",
      "400 steps | score: [-0.005707654170691967, 0.061145782470703125]\n",
      "500 steps | score: [-0.012413322925567627, 0.055350515991449356]\n",
      "600 steps | score: [0.03508833795785904, -0.0008692936971783638]\n",
      "700 steps | score: [-0.03965732082724571, 0.0899370089173317]\n",
      "800 steps | score: [-0.02978414110839367, 0.06788850575685501]\n",
      "900 steps | score: [-0.0074600032530725, 0.03858921304345131]\n",
      "1000 steps | score: [-0.019004639238119125, 0.04888596385717392]\n",
      "1100 steps | score: [0.011939415708184242, 0.01786276325583458]\n",
      "1200 steps | score: [0.0003048206272069365, 0.019878212362527847]\n",
      "1300 steps | score: [-0.0060532852075994015, 0.019521674141287804]\n",
      "1400 steps | score: [0.005470964591950178, 0.027433544397354126]\n",
      "1500 steps | score: [-0.03968625143170357, 0.07523944228887558]\n",
      "1600 steps | score: [-0.034477200359106064, 0.06204148754477501]\n",
      "1700 steps | score: [-0.03416439890861511, 0.08206786215305328]\n",
      "1800 steps | score: [-0.02676970884203911, 0.056742362678050995]\n",
      "1900 steps | score: [-0.006309553515166044, 0.03561025857925415]\n",
      "2000 steps | score: [-0.04713430255651474, 0.08864431828260422]\n",
      "2100 steps | score: [-0.020229188725352287, 0.04172513633966446]\n",
      "2200 steps | score: [-0.012730811722576618, 0.05010666325688362]\n",
      "2300 steps | score: [-0.01632562465965748, 0.04663775861263275]\n",
      "2400 steps | score: [-0.017921453341841698, 0.042775608599185944]\n",
      "2500 steps | score: [0.007332561071962118, 0.024583812803030014]\n",
      "unknown params:  tensor([-0.4676, -0.6933])\n",
      "unknown variance:  tensor([[0.9809]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4361, -0.5929])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.09348282963037491]\n",
      "100 steps | score: [-0.0473019964993]\n",
      "200 steps | score: [-0.10314948856830597]\n",
      "300 steps | score: [-0.11932609975337982]\n",
      "400 steps | score: [-0.015723373740911484]\n",
      "500 steps | score: [-0.06018602475523949]\n",
      "600 steps | score: [-0.054380614310503006]\n",
      "700 steps | score: [-0.09638235718011856]\n",
      "800 steps | score: [-0.07540105283260345]\n",
      "900 steps | score: [-0.09684620797634125]\n",
      "1000 steps | score: [-0.08649002760648727]\n",
      "1100 steps | score: [-0.0695217177271843]\n",
      "1200 steps | score: [-0.07871811091899872]\n",
      "1300 steps | score: [-0.08810801804065704]\n",
      "1400 steps | score: [-0.047323983162641525]\n",
      "1500 steps | score: [-0.07856985926628113]\n",
      "1600 steps | score: [-0.06132499873638153]\n",
      "1700 steps | score: [-0.03901560977101326]\n",
      "1800 steps | score: [-0.08329415321350098]\n",
      "1900 steps | score: [-0.10911060869693756]\n",
      "2000 steps | score: [-0.060634784400463104]\n",
      "2100 steps | score: [-0.09854459762573242]\n",
      "2200 steps | score: [-0.06410175561904907]\n",
      "2300 steps | score: [-0.0696316808462143]\n",
      "2400 steps | score: [-0.06043582409620285]\n",
      "2500 steps | score: [-0.06505607813596725]\n",
      "2600 steps | score: [-0.071495421230793]\n",
      "0 steps | score: [0.17465193569660187, 0.012070058844983578]\n",
      "100 steps | score: [0.14447149634361267, -0.15970320999622345]\n",
      "200 steps | score: [0.05010628700256348, -0.08123854547739029]\n",
      "300 steps | score: [0.018733186647295952, -0.06644577533006668]\n",
      "400 steps | score: [0.12103456258773804, -0.16944897174835205]\n",
      "500 steps | score: [0.09269880503416061, -0.1461213380098343]\n",
      "600 steps | score: [0.14541786909103394, -0.2471836805343628]\n",
      "700 steps | score: [0.05246877670288086, -0.08417907357215881]\n",
      "800 steps | score: [0.015136145986616611, -0.03629891946911812]\n",
      "900 steps | score: [0.02100820653140545, -0.06323713064193726]\n",
      "1000 steps | score: [0.02702643908560276, -0.06124592199921608]\n",
      "1100 steps | score: [0.07004063576459885, -0.09433547407388687]\n",
      "1200 steps | score: [0.019075950607657433, -0.05143413692712784]\n",
      "1300 steps | score: [0.044336896389722824, -0.07789230346679688]\n",
      "1400 steps | score: [0.1066511794924736, -0.16177189350128174]\n",
      "1500 steps | score: [0.03419745713472366, -0.06310506165027618]\n",
      "1600 steps | score: [0.03662155941128731, -0.06874728947877884]\n",
      "1700 steps | score: [0.08494844287633896, -0.135918989777565]\n",
      "1800 steps | score: [0.0347120501101017, -0.06701365113258362]\n",
      "1900 steps | score: [0.039580654352903366, -0.07049337774515152]\n",
      "2000 steps | score: [0.05373791977763176, -0.07892528921365738]\n",
      "2100 steps | score: [0.03351437300443649, -0.060225702822208405]\n",
      "2200 steps | score: [0.025806942954659462, -0.05414853245019913]\n",
      "2300 steps | score: [0.03836551681160927, -0.06840361654758453]\n",
      "2400 steps | score: [0.029883049428462982, -0.05950930342078209]\n",
      "2500 steps | score: [0.029159454628825188, -0.05086500570178032]\n",
      "2600 steps | score: [0.0314064584672451, -0.05934491008520126]\n",
      "unknown params:  tensor([-0.5031, -0.8525])\n",
      "unknown variance:  tensor([[1.0493]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4361, -0.5929])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.10624489188194275]\n",
      "100 steps | score: [-0.08234328031539917]\n",
      "200 steps | score: [0.04048710688948631]\n",
      "300 steps | score: [-0.14367760717868805]\n",
      "400 steps | score: [-0.16125380992889404]\n",
      "500 steps | score: [-0.09357664734125137]\n",
      "600 steps | score: [-0.12702791392803192]\n",
      "700 steps | score: [-0.09523576498031616]\n",
      "800 steps | score: [-0.13630136847496033]\n",
      "900 steps | score: [-0.10773027688264847]\n",
      "1000 steps | score: [-0.01751105487346649]\n",
      "1100 steps | score: [-0.1273142546415329]\n",
      "1200 steps | score: [-0.095439612865448]\n",
      "1300 steps | score: [-0.09514841437339783]\n",
      "1400 steps | score: [-0.11964414268732071]\n",
      "1500 steps | score: [-0.11019523441791534]\n",
      "1600 steps | score: [-0.11624649912118912]\n",
      "1700 steps | score: [-0.13206812739372253]\n",
      "1800 steps | score: [-0.0740002691745758]\n",
      "1900 steps | score: [-0.09985692799091339]\n",
      "2000 steps | score: [-0.13991020619869232]\n",
      "2100 steps | score: [-0.09714532643556595]\n",
      "2200 steps | score: [-0.12029778957366943]\n",
      "2300 steps | score: [-0.09734438359737396]\n",
      "2400 steps | score: [-0.14101815223693848]\n",
      "2500 steps | score: [-0.11490215361118317]\n",
      "2600 steps | score: [-0.1013854593038559]\n",
      "0 steps | score: [0.19403550028800964, -0.005868001841008663]\n",
      "100 steps | score: [0.02797936275601387, 0.03185354545712471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [0.22990119457244873, -0.295058012008667]\n",
      "300 steps | score: [-0.022035963833332062, 0.03616567701101303]\n",
      "400 steps | score: [-0.049672625958919525, 0.08700748533010483]\n",
      "500 steps | score: [0.037459276616573334, -0.020741363987326622]\n",
      "600 steps | score: [0.04611503705382347, -0.06982869654893875]\n",
      "700 steps | score: [0.06776197999715805, -0.07946120947599411]\n",
      "800 steps | score: [-0.003638165770098567, 0.014836421236395836]\n",
      "900 steps | score: [0.057468511164188385, -0.08477085083723068]\n",
      "1000 steps | score: [0.16198419034481049, -0.2407245635986328]\n",
      "1100 steps | score: [0.02790149487555027, -0.03200012072920799]\n",
      "1200 steps | score: [0.04682724550366402, -0.06654033809900284]\n",
      "1300 steps | score: [0.0563177615404129, -0.05192343518137932]\n",
      "1400 steps | score: [-0.0016368119977414608, 0.011356319300830364]\n",
      "1500 steps | score: [0.04902535304427147, -0.06440133601427078]\n",
      "1600 steps | score: [0.024766800925135612, -0.031217027455568314]\n",
      "1700 steps | score: [0.03339705616235733, -0.03796837106347084]\n",
      "1800 steps | score: [0.09593984484672546, -0.12974506616592407]\n",
      "1900 steps | score: [0.03202228993177414, -0.03900298476219177]\n",
      "2000 steps | score: [0.018366090953350067, -0.020498033612966537]\n",
      "2100 steps | score: [0.0428340882062912, -0.04537827894091606]\n",
      "2200 steps | score: [0.00633104145526886, -0.0026717502623796463]\n",
      "0 steps | score: [0.19276733696460724, 0.05493711680173874]\n",
      "100 steps | score: [0.03151019290089607, 0.0829903781414032]\n",
      "200 steps | score: [0.2090522199869156, -0.20304054021835327]\n",
      "300 steps | score: [-0.03331393003463745, 0.10222923010587692]\n",
      "400 steps | score: [-0.06110534444451332, 0.15189312398433685]\n",
      "500 steps | score: [0.033718425780534744, 0.04248213768005371]\n",
      "600 steps | score: [0.02560054324567318, 0.020970512181520462]\n",
      "700 steps | score: [0.06617317348718643, -0.03170504420995712]\n",
      "800 steps | score: [-0.010362832807004452, 0.07809849828481674]\n",
      "900 steps | score: [0.04158124327659607, -0.006626799702644348]\n",
      "1000 steps | score: [0.13233736157417297, -0.1207105740904808]\n",
      "1100 steps | score: [0.021383505314588547, 0.024207673966884613]\n",
      "1200 steps | score: [0.04553624615073204, 0.00040243566036224365]\n",
      "1300 steps | score: [0.04503185302019119, 0.006416592746973038]\n",
      "1400 steps | score: [0.002461986616253853, 0.06229381263256073]\n",
      "1500 steps | score: [0.04995699226856232, 0.002207878977060318]\n",
      "1600 steps | score: [0.009266405366361141, 0.052104122936725616]\n",
      "1700 steps | score: [0.02335040643811226, 0.022404693067073822]\n",
      "1800 steps | score: [0.07159998267889023, -0.03582347556948662]\n",
      "1900 steps | score: [0.014648267067968845, 0.039264045655727386]\n",
      "2000 steps | score: [0.003507551271468401, 0.05522831529378891]\n",
      "2100 steps | score: [0.020625565201044083, 0.039051320403814316]\n",
      "2200 steps | score: [0.0024977801367640495, 0.058980245143175125]\n",
      "2300 steps | score: [0.02961377054452896, 0.02609638124704361]\n",
      "2400 steps | score: [0.02489577792584896, 0.02786455675959587]\n",
      "2500 steps | score: [0.030695483088493347, 0.021929249167442322]\n",
      "2600 steps | score: [0.053698763251304626, -0.015908971428871155]\n",
      "0 steps | score: [0.23309098184108734, -0.04676610976457596]\n",
      "100 steps | score: [0.08221843838691711, -0.02284877561032772]\n",
      "200 steps | score: [0.264586478471756, -0.32079628109931946]\n",
      "300 steps | score: [0.017053229734301567, 0.006613355129957199]\n",
      "400 steps | score: [-0.009138213470578194, 0.04468546435236931]\n",
      "500 steps | score: [0.08312338590621948, -0.07402538508176804]\n",
      "600 steps | score: [0.08775655180215836, -0.09987791627645493]\n",
      "700 steps | score: [0.09370431303977966, -0.10267815738916397]\n",
      "800 steps | score: [0.012601930648088455, 0.004570530727505684]\n",
      "900 steps | score: [0.08467791974544525, -0.10788194835186005]\n",
      "1000 steps | score: [0.19209899008274078, -0.2755037248134613]\n",
      "1100 steps | score: [0.06189407408237457, -0.06787770986557007]\n",
      "1200 steps | score: [0.06561703234910965, -0.07774904370307922]\n",
      "1300 steps | score: [0.0853625163435936, -0.09113238751888275]\n",
      "1400 steps | score: [0.039122384041547775, -0.032602183520793915]\n",
      "1500 steps | score: [0.09822863340377808, -0.11023277789354324]\n",
      "1600 steps | score: [0.06147187203168869, -0.06433587521314621]\n",
      "1700 steps | score: [0.08684087544679642, -0.09348133951425552]\n",
      "1800 steps | score: [0.12795132398605347, -0.1535535752773285]\n",
      "1900 steps | score: [0.06370334327220917, -0.07133392989635468]\n",
      "2000 steps | score: [0.05560223013162613, -0.05014655739068985]\n",
      "2100 steps | score: [0.08414676040410995, -0.07983900606632233]\n",
      "2200 steps | score: [0.043049827218055725, -0.037041936069726944]\n",
      "2300 steps | score: [0.08150620013475418, -0.08708275854587555]\n",
      "2400 steps | score: [0.07444225251674652, -0.07926367223262787]\n",
      "2500 steps | score: [0.08121086657047272, -0.08163925260305405]\n",
      "2600 steps | score: [0.09396678954362869, -0.11140060424804688]\n",
      "unknown params:  tensor([-0.5203, -0.9605])\n",
      "unknown variance:  tensor([[1.1105]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4361, -0.5929])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3213583827018738]\n",
      "100 steps | score: [0.0875789001584053]\n",
      "200 steps | score: [0.11032911390066147]\n",
      "300 steps | score: [0.09558389335870743]\n",
      "400 steps | score: [0.1007414236664772]\n",
      "500 steps | score: [0.12154948711395264]\n",
      "600 steps | score: [0.08544588834047318]\n",
      "700 steps | score: [0.08601861447095871]\n",
      "800 steps | score: [0.143138587474823]\n",
      "900 steps | score: [0.15082064270973206]\n",
      "1000 steps | score: [0.08430168777704239]\n",
      "1100 steps | score: [0.10966481268405914]\n",
      "1200 steps | score: [0.11226552724838257]\n",
      "1300 steps | score: [0.13893403112888336]\n",
      "1400 steps | score: [0.14063571393489838]\n",
      "1500 steps | score: [0.0730847716331482]\n",
      "1600 steps | score: [0.11420264840126038]\n",
      "1700 steps | score: [0.12567776441574097]\n",
      "1800 steps | score: [0.09395621716976166]\n",
      "1900 steps | score: [0.1009388417005539]\n",
      "2000 steps | score: [0.1153346374630928]\n",
      "2100 steps | score: [0.11974672973155975]\n",
      "2200 steps | score: [0.08317838609218597]\n",
      "2300 steps | score: [0.11553022265434265]\n",
      "2400 steps | score: [0.13435672223567963]\n",
      "2500 steps | score: [0.10984710603952408]\n",
      "2600 steps | score: [0.1135629341006279]\n",
      "0 steps | score: [0.278170645236969, -0.20611675083637238]\n",
      "100 steps | score: [0.07697146385908127, -0.05733051151037216]\n",
      "200 steps | score: [0.10009370744228363, -0.11385930329561234]\n",
      "300 steps | score: [0.07024183869361877, -0.11264205724000931]\n",
      "400 steps | score: [0.1235438659787178, -0.21564246714115143]\n",
      "500 steps | score: [0.13122382760047913, -0.2605458199977875]\n",
      "600 steps | score: [0.046729665249586105, -0.09673736989498138]\n",
      "700 steps | score: [0.06808719784021378, -0.11783013492822647]\n",
      "800 steps | score: [0.17283058166503906, -0.3261607587337494]\n",
      "900 steps | score: [0.17329418659210205, -0.31174764037132263]\n",
      "1000 steps | score: [-0.012477762997150421, -0.007759785279631615]\n",
      "1100 steps | score: [0.04535789042711258, -0.1023065596818924]\n",
      "1200 steps | score: [0.09277684986591339, -0.18681731820106506]\n",
      "1300 steps | score: [0.11100199073553085, -0.20790106058120728]\n",
      "1400 steps | score: [0.12797406315803528, -0.24511034786701202]\n",
      "1500 steps | score: [0.020296752452850342, -0.06747102737426758]\n",
      "1600 steps | score: [0.09652451425790787, -0.1912813037633896]\n",
      "1700 steps | score: [0.0928109884262085, -0.17572447657585144]\n",
      "1800 steps | score: [0.07737907767295837, -0.16220445930957794]\n",
      "1900 steps | score: [0.053166601806879044, -0.11192615330219269]\n",
      "2000 steps | score: [0.1023264154791832, -0.197348490357399]\n",
      "2100 steps | score: [0.11350573599338531, -0.20723558962345123]\n",
      "2200 steps | score: [0.01924140751361847, -0.05842254310846329]\n",
      "2300 steps | score: [0.09377416223287582, -0.17562584578990936]\n",
      "2400 steps | score: [0.0904424786567688, -0.19046476483345032]\n",
      "2500 steps | score: [0.08055710047483444, -0.15100213885307312]\n",
      "2600 steps | score: [0.09496911615133286, -0.17592592537403107]\n",
      "unknown params:  tensor([-0.5358, -1.1367])\n",
      "unknown variance:  tensor([[1.2147]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4361, -0.5929])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.25127938389778137]\n",
      "100 steps | score: [0.034626759588718414]\n",
      "200 steps | score: [0.01606770046055317]\n",
      "300 steps | score: [0.03892727196216583]\n",
      "400 steps | score: [0.02031506597995758]\n",
      "500 steps | score: [0.007286036387085915]\n",
      "0 steps | score: [0.2235478013753891, -0.1256846785545349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [0.012494928203523159, 0.09836271405220032]\n",
      "200 steps | score: [-0.06300190836191177, 0.17424558103084564]\n",
      "300 steps | score: [0.07367775589227676, -0.11390388011932373]\n",
      "400 steps | score: [-0.05598803237080574, 0.13975241780281067]\n",
      "500 steps | score: [-0.03611830621957779, 0.07630190253257751]\n",
      "600 steps | score: [0.2512679398059845, -0.47413963079452515]\n",
      "700 steps | score: [0.1611979454755783, -0.31042614579200745]\n",
      "800 steps | score: [0.049631714820861816, -0.05846976861357689]\n",
      "900 steps | score: [-0.041073430329561234, 0.09055003523826599]\n",
      "1000 steps | score: [0.10183176398277283, -0.1708257496356964]\n",
      "1100 steps | score: [0.018499238416552544, -0.017298556864261627]\n",
      "1200 steps | score: [0.07050590962171555, -0.11285124719142914]\n",
      "1300 steps | score: [0.05353672057390213, -0.08959249407052994]\n",
      "1400 steps | score: [0.06247490271925926, -0.10514966398477554]\n",
      "1500 steps | score: [0.03894215077161789, -0.05998733267188072]\n",
      "1600 steps | score: [0.045690007507801056, -0.07455429434776306]\n",
      "1700 steps | score: [0.054154086858034134, -0.10631287097930908]\n",
      "1800 steps | score: [0.05074043571949005, -0.07780569791793823]\n",
      "1900 steps | score: [0.013913046568632126, -0.03341158479452133]\n",
      "2000 steps | score: [0.016954593360424042, -0.020466327667236328]\n",
      "2100 steps | score: [0.008024702779948711, 0.0017066746950149536]\n",
      "unknown params:  tensor([-0.5028, -1.1334])\n",
      "unknown variance:  tensor([[1.2674]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4361, -0.5929])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3230329155921936]\n",
      "100 steps | score: [0.08420911431312561]\n",
      "200 steps | score: [0.047206196933984756]\n",
      "300 steps | score: [0.07155667245388031]\n",
      "400 steps | score: [0.06554316729307175]\n",
      "500 steps | score: [0.03618951886892319]\n",
      "600 steps | score: [0.01127684861421585]\n",
      "700 steps | score: [0.09118020534515381]\n",
      "800 steps | score: [0.0048815347254276276]\n",
      "0 steps | score: [0.1507861465215683, -0.0590907484292984]\n",
      "100 steps | score: [0.07283178716897964, -0.020959220826625824]\n",
      "200 steps | score: [-0.09336218982934952, 0.2451244443655014]\n",
      "300 steps | score: [0.13038131594657898, -0.23072130978107452]\n",
      "400 steps | score: [-0.07713685929775238, 0.1793723851442337]\n",
      "500 steps | score: [0.021323731169104576, -0.033124715089797974]\n",
      "600 steps | score: [-0.054790694266557693, 0.11334569752216339]\n",
      "700 steps | score: [-0.013179704546928406, 0.031245293095707893]\n",
      "800 steps | score: [0.010111414827406406, -0.03254599869251251]\n",
      "900 steps | score: [0.13642075657844543, -0.304023802280426]\n",
      "1000 steps | score: [0.08114084601402283, -0.19568699598312378]\n",
      "1100 steps | score: [-0.03464675694704056, 0.057078517973423004]\n",
      "1200 steps | score: [-0.08974235504865646, 0.15926384925842285]\n",
      "1300 steps | score: [0.2995820641517639, -0.7013559341430664]\n",
      "1400 steps | score: [-0.008991846814751625, 0.0016850382089614868]\n",
      "unknown params:  tensor([-0.4760, -1.0921])\n",
      "unknown variance:  tensor([[1.4011]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/5f790aa0-95d0-4e84-afe8-0f991752ea05\n",
      "gt params:  tensor([-0.4366, -0.5961])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.23182803392410278]\n",
      "100 steps | score: [0.1883428990840912]\n",
      "200 steps | score: [0.14297369122505188]\n",
      "300 steps | score: [0.11913228034973145]\n",
      "400 steps | score: [0.028649847954511642]\n",
      "500 steps | score: [0.089968740940094]\n",
      "600 steps | score: [0.10007928311824799]\n",
      "700 steps | score: [0.0894605740904808]\n",
      "800 steps | score: [0.11966001242399216]\n",
      "900 steps | score: [0.06316859275102615]\n",
      "1000 steps | score: [0.14338964223861694]\n",
      "1100 steps | score: [0.0802939236164093]\n",
      "1200 steps | score: [0.08261550217866898]\n",
      "1300 steps | score: [0.06850500404834747]\n",
      "1400 steps | score: [0.12123274058103561]\n",
      "1500 steps | score: [0.09925936162471771]\n",
      "1600 steps | score: [0.0826043114066124]\n",
      "1700 steps | score: [0.08690465986728668]\n",
      "1800 steps | score: [0.09104358404874802]\n",
      "1900 steps | score: [0.13691440224647522]\n",
      "2000 steps | score: [0.09101857990026474]\n",
      "2100 steps | score: [0.10649937391281128]\n",
      "2200 steps | score: [0.09211196005344391]\n",
      "2300 steps | score: [0.13268664479255676]\n",
      "2400 steps | score: [0.10749522596597672]\n",
      "2500 steps | score: [0.10686268657445908]\n",
      "2600 steps | score: [0.1166660487651825]\n",
      "0 steps | score: [0.04552420228719711, 0.027194097638130188]\n",
      "100 steps | score: [0.0668870285153389, -0.07312601059675217]\n",
      "200 steps | score: [0.0009004584280773997, 0.00944539625197649]\n",
      "0 steps | score: [0.02010362781584263, 0.05331455171108246]\n",
      "100 steps | score: [0.038149312138557434, -0.05035528168082237]\n",
      "200 steps | score: [-0.02485617995262146, 0.033581752330064774]\n",
      "300 steps | score: [0.008651825599372387, -0.002405684906989336]\n",
      "0 steps | score: [-0.019123394042253494, 0.06292229145765305]\n",
      "100 steps | score: [0.011703883297741413, -0.04606769606471062]\n",
      "200 steps | score: [-0.0627797320485115, 0.03746912255883217]\n",
      "300 steps | score: [-0.027157217264175415, 0.001902054762467742]\n",
      "400 steps | score: [-0.059286851435899734, -0.013506998308002949]\n",
      "500 steps | score: [-0.037732649594545364, 0.0318622961640358]\n",
      "600 steps | score: [-0.048459742218256, 0.01727636158466339]\n",
      "700 steps | score: [-0.0663350373506546, 0.01494770310819149]\n",
      "800 steps | score: [-0.035093847662210464, 0.026000140234827995]\n",
      "900 steps | score: [-0.06875580549240112, -0.021168354898691177]\n",
      "1000 steps | score: [-0.012510290369391441, 0.0156319011002779]\n",
      "1100 steps | score: [-0.06806130707263947, 0.02198401838541031]\n",
      "1200 steps | score: [-0.058406081050634384, -0.019769269973039627]\n",
      "1300 steps | score: [-0.06781283766031265, -0.000390069792047143]\n",
      "1400 steps | score: [-0.025739852339029312, 0.024541029706597328]\n",
      "1500 steps | score: [-0.042752597481012344, 0.0054179346188902855]\n",
      "1600 steps | score: [-0.04886562377214432, 0.01766432262957096]\n",
      "1700 steps | score: [-0.04867585003376007, 0.0015108087100088596]\n",
      "1800 steps | score: [-0.03964937850832939, -0.011712031438946724]\n",
      "1900 steps | score: [-0.02137383446097374, 0.004349556751549244]\n",
      "2000 steps | score: [-0.05041849985718727, 0.026284344494342804]\n",
      "2100 steps | score: [-0.03975476697087288, 0.008861098438501358]\n",
      "2200 steps | score: [-0.0454447902739048, 0.0009120875038206577]\n",
      "2300 steps | score: [-0.03342646360397339, 0.0057407645508646965]\n",
      "2400 steps | score: [-0.047278761863708496, 0.010240484029054642]\n",
      "2500 steps | score: [-0.050452765077352524, 0.008868875913321972]\n",
      "2600 steps | score: [-0.041870150715112686, 0.011096027679741383]\n",
      "unknown params:  tensor([-0.4046, -0.4640])\n",
      "unknown variance:  tensor([[0.8106]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4366, -0.5961])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.16152168810367584]\n",
      "100 steps | score: [0.012393996119499207]\n",
      "200 steps | score: [-0.01020156592130661]\n",
      "300 steps | score: [0.04976072162389755]\n",
      "400 steps | score: [0.02911733277142048]\n",
      "500 steps | score: [0.06297112256288528]\n",
      "600 steps | score: [-0.01833178848028183]\n",
      "700 steps | score: [0.009502924978733063]\n",
      "0 steps | score: [0.09679847210645676, 0.0875714048743248]\n",
      "100 steps | score: [0.03756037354469299, 0.036461953073740005]\n",
      "200 steps | score: [-0.006484533194452524, 0.051697149872779846]\n",
      "300 steps | score: [0.051993682980537415, -0.02061031013727188]\n",
      "400 steps | score: [0.03498590365052223, 0.00012997537851333618]\n",
      "500 steps | score: [0.07098092883825302, 0.011421057395637035]\n",
      "600 steps | score: [-0.010623501613736153, 0.06209491193294525]\n",
      "700 steps | score: [0.013996380381286144, -0.0006324192509055138]\n",
      "800 steps | score: [0.014314979314804077, 0.005738493055105209]\n",
      "900 steps | score: [0.08927922695875168, -0.01966867595911026]\n",
      "1000 steps | score: [0.003225642954930663, 0.051950350403785706]\n",
      "1100 steps | score: [0.025457721203565598, -0.020289642736315727]\n",
      "1200 steps | score: [0.031512301415205, -0.01057343278080225]\n",
      "1300 steps | score: [0.060433823615312576, -0.0045067258179187775]\n",
      "1400 steps | score: [0.015241274610161781, 0.03371996432542801]\n",
      "1500 steps | score: [0.037153277546167374, -0.014845112338662148]\n",
      "1600 steps | score: [0.03871650993824005, -0.008031398057937622]\n",
      "1700 steps | score: [0.06271537393331528, -0.00341187696903944]\n",
      "1800 steps | score: [0.013046897947788239, 0.028018023818731308]\n",
      "1900 steps | score: [0.03143955394625664, -0.003098258748650551]\n",
      "2000 steps | score: [0.03142748028039932, -0.010147231630980968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 steps | score: [0.045073483139276505, -0.003976363223046064]\n",
      "2200 steps | score: [0.015109801664948463, 0.022203773260116577]\n",
      "2300 steps | score: [0.03705662488937378, 0.0006234063766896725]\n",
      "2400 steps | score: [0.04080913960933685, -0.007074699271470308]\n",
      "2500 steps | score: [0.03885635361075401, 8.669169619679451e-05]\n",
      "2600 steps | score: [0.024572422727942467, 0.011701452545821667]\n",
      "2700 steps | score: [0.03256024420261383, 0.009930175729095936]\n",
      "0 steps | score: [0.08413027971982956, 0.07539710402488708]\n",
      "100 steps | score: [0.029538927599787712, 0.020050061866641045]\n",
      "200 steps | score: [-0.03200410678982735, 0.04570920765399933]\n",
      "300 steps | score: [0.03933366388082504, -0.035398930311203]\n",
      "400 steps | score: [0.01740529201924801, -0.004097044933587313]\n",
      "500 steps | score: [0.05764779448509216, 0.00036424025893211365]\n",
      "600 steps | score: [-0.016717977821826935, 0.04890593886375427]\n",
      "700 steps | score: [-0.0004392928385641426, -0.015067140571773052]\n",
      "800 steps | score: [0.012696972116827965, -0.020912200212478638]\n",
      "900 steps | score: [0.07280473411083221, -0.02859475277364254]\n",
      "1000 steps | score: [-0.011777525767683983, 0.04021041467785835]\n",
      "1100 steps | score: [0.011403721757233143, -0.027990061789751053]\n",
      "1200 steps | score: [0.017844602465629578, -0.01714273914694786]\n",
      "1300 steps | score: [0.043757930397987366, -0.020118651911616325]\n",
      "1400 steps | score: [-0.006913286633789539, 0.028106188401579857]\n",
      "1500 steps | score: [0.018361523747444153, -0.026122774928808212]\n",
      "1600 steps | score: [0.022664787247776985, -0.018728774040937424]\n",
      "1700 steps | score: [0.046267978847026825, -0.016697023063898087]\n",
      "1800 steps | score: [-0.0018369921017438173, 0.01387108862400055]\n",
      "1900 steps | score: [0.016718922182917595, -0.011708205565810204]\n",
      "2000 steps | score: [0.011829868890345097, -0.01858093962073326]\n",
      "2100 steps | score: [0.03383448347449303, -0.016869600862264633]\n",
      "2200 steps | score: [0.004861677065491676, 0.006153430324047804]\n",
      "0 steps | score: [0.12864366173744202, 0.04252740740776062]\n",
      "100 steps | score: [0.05627237260341644, -0.0005121291615068913]\n",
      "200 steps | score: [0.00938368123024702, 0.02760966308414936]\n",
      "300 steps | score: [0.07153581827878952, -0.05108978971838951]\n",
      "400 steps | score: [0.06062902510166168, -0.03404783084988594]\n",
      "500 steps | score: [0.09056717902421951, -0.029587868601083755]\n",
      "600 steps | score: [0.015680592507123947, 0.03099408745765686]\n",
      "700 steps | score: [0.03943800926208496, -0.04058001562952995]\n",
      "800 steps | score: [0.04171731695532799, -0.03973023593425751]\n",
      "900 steps | score: [0.11650601029396057, -0.059457384049892426]\n",
      "1000 steps | score: [0.022726111114025116, 0.017330575734376907]\n",
      "1100 steps | score: [0.047495968639850616, -0.05005783960223198]\n",
      "1200 steps | score: [0.050832584500312805, -0.037480536848306656]\n",
      "1300 steps | score: [0.08555412292480469, -0.04115965962409973]\n",
      "1400 steps | score: [0.03179282322525978, 0.0025100409984588623]\n",
      "1500 steps | score: [0.06154120713472366, -0.04584065079689026]\n",
      "1600 steps | score: [0.05784562602639198, -0.041886575520038605]\n",
      "1700 steps | score: [0.08262021839618683, -0.04364532604813576]\n",
      "1800 steps | score: [0.03609635308384895, -0.014216896146535873]\n",
      "1900 steps | score: [0.05486474186182022, -0.039048511534929276]\n",
      "2000 steps | score: [0.05784543231129646, -0.04627049341797829]\n",
      "2100 steps | score: [0.07442821562290192, -0.040211066603660583]\n",
      "2200 steps | score: [0.04039911925792694, -0.011308148503303528]\n",
      "2300 steps | score: [0.05526212975382805, -0.03527174890041351]\n",
      "2400 steps | score: [0.0645630732178688, -0.041993338614702225]\n",
      "2500 steps | score: [0.06434770673513412, -0.03696990758180618]\n",
      "2600 steps | score: [0.048268962651491165, -0.02443581074476242]\n",
      "2700 steps | score: [0.05641511455178261, -0.028345158323645592]\n",
      "unknown params:  tensor([-0.4054, -0.4929])\n",
      "unknown variance:  tensor([[0.8791]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4366, -0.5961])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3153226971626282]\n",
      "100 steps | score: [0.30743223428726196]\n",
      "200 steps | score: [0.15486833453178406]\n",
      "300 steps | score: [0.19532647728919983]\n",
      "400 steps | score: [0.3041958510875702]\n",
      "500 steps | score: [0.16294200718402863]\n",
      "600 steps | score: [0.19524434208869934]\n",
      "700 steps | score: [0.23238752782344818]\n",
      "800 steps | score: [0.20540259778499603]\n",
      "900 steps | score: [0.1212192177772522]\n",
      "1000 steps | score: [0.20033472776412964]\n",
      "1100 steps | score: [0.20240777730941772]\n",
      "1200 steps | score: [0.22295114398002625]\n",
      "1300 steps | score: [0.145425483584404]\n",
      "1400 steps | score: [0.18806827068328857]\n",
      "1500 steps | score: [0.19032202661037445]\n",
      "1600 steps | score: [0.23933081328868866]\n",
      "1700 steps | score: [0.16718590259552002]\n",
      "1800 steps | score: [0.1878458857536316]\n",
      "1900 steps | score: [0.22440429031848907]\n",
      "2000 steps | score: [0.18967430293560028]\n",
      "2100 steps | score: [0.18336130678653717]\n",
      "2200 steps | score: [0.2007741779088974]\n",
      "2300 steps | score: [0.20904864370822906]\n",
      "2400 steps | score: [0.20543842017650604]\n",
      "2500 steps | score: [0.1895657330751419]\n",
      "2600 steps | score: [0.1965765506029129]\n",
      "0 steps | score: [0.09791956841945648, 0.036860570311546326]\n",
      "100 steps | score: [0.12513062357902527, -0.08698500692844391]\n",
      "200 steps | score: [-0.011750391684472561, 0.01905633695423603]\n",
      "300 steps | score: [-0.012684906832873821, -0.022946007549762726]\n",
      "400 steps | score: [0.12544232606887817, -0.15243598818778992]\n",
      "500 steps | score: [0.01805109530687332, -0.04299864172935486]\n",
      "600 steps | score: [0.0007604355341754854, -0.041157208383083344]\n",
      "700 steps | score: [0.05343283712863922, -0.09507802128791809]\n",
      "800 steps | score: [0.011973927728831768, -0.029777411371469498]\n",
      "900 steps | score: [-0.035227589309215546, -0.016465073451399803]\n",
      "1000 steps | score: [0.04302395135164261, -0.08098562061786652]\n",
      "1100 steps | score: [-0.012374408543109894, -0.041682612150907516]\n",
      "1200 steps | score: [0.055714018642902374, -0.07080317288637161]\n",
      "1300 steps | score: [-0.027280619367957115, -0.01293496135622263]\n",
      "1400 steps | score: [0.022564757615327835, -0.0585782527923584]\n",
      "1500 steps | score: [0.013402027077972889, -0.06062702089548111]\n",
      "1600 steps | score: [0.06136198714375496, -0.06987916678190231]\n",
      "1700 steps | score: [-0.012767591513693333, -0.015120450407266617]\n",
      "1800 steps | score: [0.008657258003950119, -0.04508043825626373]\n",
      "1900 steps | score: [0.049170490354299545, -0.08259232342243195]\n",
      "2000 steps | score: [0.02583540976047516, -0.057357169687747955]\n",
      "2100 steps | score: [0.008554857224225998, -0.04592181742191315]\n",
      "2200 steps | score: [0.023572400212287903, -0.0681888535618782]\n",
      "2300 steps | score: [0.02295304462313652, -0.04928985983133316]\n",
      "2400 steps | score: [0.008629235439002514, -0.04436173290014267]\n",
      "2500 steps | score: [0.012940948829054832, -0.049419838935136795]\n",
      "2600 steps | score: [0.01120432186871767, -0.049825966358184814]\n",
      "0 steps | score: [0.09527638554573059, 0.061200760304927826]\n",
      "100 steps | score: [0.1270042508840561, -0.04451451078057289]\n",
      "200 steps | score: [-0.012975717894732952, 0.03674275055527687]\n",
      "300 steps | score: [-0.0023590801283717155, -0.00854581966996193]\n",
      "0 steps | score: [0.08211842179298401, 0.13581900298595428]\n",
      "100 steps | score: [0.09857106953859329, 0.017834443598985672]\n",
      "200 steps | score: [-0.01687888614833355, 0.10533407330513]\n",
      "300 steps | score: [-0.021309515461325645, 0.055364884436130524]\n",
      "400 steps | score: [0.10906730592250824, -0.05998757481575012]\n",
      "500 steps | score: [0.001711187302134931, 0.031593576073646545]\n",
      "600 steps | score: [0.006621267180889845, 0.02681063674390316]\n",
      "700 steps | score: [0.0409373976290226, -0.005926153622567654]\n",
      "800 steps | score: [0.00687189819291234, 0.057228341698646545]\n",
      "900 steps | score: [-0.05247170478105545, 0.0602155439555645]\n",
      "1000 steps | score: [0.02620598115026951, 0.006667139939963818]\n",
      "1100 steps | score: [-0.008762117475271225, 0.03447536379098892]\n",
      "1200 steps | score: [0.03712848946452141, 0.021848436444997787]\n",
      "1300 steps | score: [-0.03584209084510803, 0.06678371876478195]\n",
      "1400 steps | score: [0.012220630422234535, 0.025107471272349358]\n",
      "1500 steps | score: [-0.0038496581837534904, 0.020050112158060074]\n",
      "1600 steps | score: [0.04697563871741295, 0.01592005416750908]\n",
      "1700 steps | score: [-0.02605404146015644, 0.06298805773258209]\n",
      "1800 steps | score: [-0.008677788078784943, 0.042826320976018906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [0.027884332463145256, 0.001443503424525261]\n",
      "2000 steps | score: [0.012149295769631863, 0.02351580560207367]\n",
      "2100 steps | score: [-0.003052172949537635, 0.04246023669838905]\n",
      "2200 steps | score: [0.011508692055940628, 0.019070494920015335]\n",
      "2300 steps | score: [0.010734640061855316, 0.03312411904335022]\n",
      "2400 steps | score: [-0.007784366607666016, 0.03879360482096672]\n",
      "2500 steps | score: [-0.00489111477509141, 0.030677806586027145]\n",
      "2600 steps | score: [-0.006222685799002647, 0.033553820103406906]\n",
      "unknown params:  tensor([-0.4109, -0.5357])\n",
      "unknown variance:  tensor([[0.8782]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4366, -0.5961])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.17676515877246857]\n",
      "100 steps | score: [0.10760239511728287]\n",
      "200 steps | score: [0.04717165231704712]\n",
      "300 steps | score: [0.07278133928775787]\n",
      "400 steps | score: [-0.012238516472280025]\n",
      "500 steps | score: [-0.006155752576887608]\n",
      "0 steps | score: [0.06922014057636261, 0.11152024567127228]\n",
      "100 steps | score: [0.08042743057012558, -0.0162048302590847]\n",
      "200 steps | score: [-0.0035624676384031773, 0.001139674335718155]\n",
      "0 steps | score: [0.11345727741718292, 0.09971381723880768]\n",
      "100 steps | score: [0.09766021370887756, -0.010081342421472073]\n",
      "200 steps | score: [0.023531759157776833, -0.008693596348166466]\n",
      "300 steps | score: [0.08234740793704987, -0.07036943733692169]\n",
      "400 steps | score: [-0.045329008251428604, 0.06766015291213989]\n",
      "500 steps | score: [-0.019851597025990486, 0.03642174229025841]\n",
      "600 steps | score: [0.017540929839015007, -0.012255067005753517]\n",
      "700 steps | score: [-0.008761151693761349, -0.006794710643589497]\n",
      "0 steps | score: [0.06752171367406845, 0.10233886539936066]\n",
      "100 steps | score: [0.0803002417087555, -0.0380265899002552]\n",
      "200 steps | score: [-0.00898575410246849, -0.012564086355268955]\n",
      "300 steps | score: [0.04323889687657356, -0.07236675173044205]\n",
      "400 steps | score: [-0.06526115536689758, 0.05833987891674042]\n",
      "500 steps | score: [-0.051123760640621185, 0.024480383843183517]\n",
      "600 steps | score: [-0.016293175518512726, -0.015175092965364456]\n",
      "700 steps | score: [-0.034892987459897995, -0.015593412332236767]\n",
      "800 steps | score: [-0.029949059709906578, 0.022857947275042534]\n",
      "900 steps | score: [-0.0018582271877676249, -0.019483061507344246]\n",
      "1000 steps | score: [0.02848375216126442, -0.05572911724448204]\n",
      "1100 steps | score: [-0.006808395031839609, -0.018135227262973785]\n",
      "1200 steps | score: [-0.05202378332614899, 0.030133632943034172]\n",
      "1300 steps | score: [-0.002713584341108799, -0.03621034324169159]\n",
      "1400 steps | score: [-0.004063545260578394, -0.04465100169181824]\n",
      "1500 steps | score: [-0.0022757877595722675, -0.013432628475129604]\n",
      "1600 steps | score: [0.0006302439142018557, -0.02377207949757576]\n",
      "1700 steps | score: [-0.016423270106315613, -0.0013020278420299292]\n",
      "1800 steps | score: [0.0060625504702329636, -0.03830299526453018]\n",
      "1900 steps | score: [-0.054062675684690475, 0.024329468607902527]\n",
      "2000 steps | score: [-0.012820222415030003, -0.01296020857989788]\n",
      "2100 steps | score: [-0.000720183365046978, -0.033259861171245575]\n",
      "2200 steps | score: [-0.014055409468710423, -0.015354476869106293]\n",
      "2300 steps | score: [-0.028830189257860184, -0.0017261076718568802]\n",
      "2400 steps | score: [-0.02779592201113701, -0.002202776726335287]\n",
      "2500 steps | score: [-0.002761467359960079, -0.026440801098942757]\n",
      "2600 steps | score: [-0.04012494906783104, 0.014320717193186283]\n",
      "2700 steps | score: [-0.016448654234409332, -0.0022254432551562786]\n",
      "unknown params:  tensor([-0.4507, -0.6417])\n",
      "unknown variance:  tensor([[0.9755]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4366, -0.5961])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.26564812660217285]\n",
      "100 steps | score: [0.13363267481327057]\n",
      "200 steps | score: [0.23184260725975037]\n",
      "300 steps | score: [0.04824334383010864]\n",
      "400 steps | score: [0.21787302196025848]\n",
      "500 steps | score: [0.04477274417877197]\n",
      "600 steps | score: [0.140636146068573]\n",
      "700 steps | score: [0.13679489493370056]\n",
      "800 steps | score: [0.03616314381361008]\n",
      "900 steps | score: [0.13150173425674438]\n",
      "1000 steps | score: [0.11682263761758804]\n",
      "1100 steps | score: [0.06294234842061996]\n",
      "1200 steps | score: [0.09913524985313416]\n",
      "1300 steps | score: [0.10231789946556091]\n",
      "1400 steps | score: [0.1329496055841446]\n",
      "1500 steps | score: [0.13130605220794678]\n",
      "1600 steps | score: [0.07996929436922073]\n",
      "1700 steps | score: [0.15824076533317566]\n",
      "1800 steps | score: [0.12887224555015564]\n",
      "1900 steps | score: [0.07861565053462982]\n",
      "2000 steps | score: [0.12890852987766266]\n",
      "2100 steps | score: [0.09241726994514465]\n",
      "2200 steps | score: [0.12108403444290161]\n",
      "2300 steps | score: [0.09641914069652557]\n",
      "2400 steps | score: [0.10869082808494568]\n",
      "2500 steps | score: [0.11953181773424149]\n",
      "0 steps | score: [0.11250405013561249, 0.095487080514431]\n",
      "100 steps | score: [-0.044817306101322174, 0.11265002191066742]\n",
      "200 steps | score: [0.1242627277970314, -0.1220504641532898]\n",
      "300 steps | score: [-0.09649592638015747, 0.06635680049657822]\n",
      "400 steps | score: [0.06756296008825302, -0.060685742646455765]\n",
      "500 steps | score: [-0.059997618198394775, 0.06370554864406586]\n",
      "600 steps | score: [0.05605379492044449, -0.06776653230190277]\n",
      "700 steps | score: [-0.012020757421851158, -0.0028244024142622948]\n",
      "800 steps | score: [-0.07499278336763382, 0.09147761762142181]\n",
      "900 steps | score: [-0.02482346072793007, 0.030744047835469246]\n",
      "1000 steps | score: [-0.007425263524055481, -0.035749297589063644]\n",
      "1100 steps | score: [-0.08359353989362717, 0.09008514136075974]\n",
      "1200 steps | score: [-0.003361023962497711, 0.003976763226091862]\n",
      "0 steps | score: [0.126456156373024, 0.12611675262451172]\n",
      "100 steps | score: [-0.02593870274722576, 0.13842548429965973]\n",
      "200 steps | score: [0.15707139670848846, -0.11490488797426224]\n",
      "300 steps | score: [-0.0716475397348404, 0.0884384736418724]\n",
      "400 steps | score: [0.08113867044448853, -0.03349067270755768]\n",
      "500 steps | score: [-0.04091145843267441, 0.09915531426668167]\n",
      "600 steps | score: [0.07492151111364365, -0.04672883450984955]\n",
      "700 steps | score: [0.016263967379927635, 0.019506331533193588]\n",
      "800 steps | score: [-0.04996514320373535, 0.10445627570152283]\n",
      "900 steps | score: [-0.0177355594933033, 0.06683029979467392]\n",
      "1000 steps | score: [0.011861797422170639, -0.0009609553962945938]\n",
      "1100 steps | score: [-0.07177606970071793, 0.12048379331827164]\n",
      "1200 steps | score: [0.017641648650169373, 0.031134605407714844]\n",
      "1300 steps | score: [0.04038988798856735, -0.018103603273630142]\n",
      "1400 steps | score: [0.003530921647325158, 0.04525788873434067]\n",
      "1500 steps | score: [0.033515654504299164, 0.00711873359978199]\n",
      "1600 steps | score: [-0.0068289740011096, 0.040105585008859634]\n",
      "1700 steps | score: [0.050228897482156754, -0.012050924822688103]\n",
      "1800 steps | score: [-0.004656297620385885, 0.05198059231042862]\n",
      "1900 steps | score: [0.0009547064546495676, 0.04288344085216522]\n",
      "2000 steps | score: [0.03328219801187515, -0.007152844220399857]\n",
      "2100 steps | score: [-0.026233654469251633, 0.07056377083063126]\n",
      "2200 steps | score: [0.009568007662892342, 0.03435005620121956]\n",
      "2300 steps | score: [-0.007332474458962679, 0.04412173479795456]\n",
      "2400 steps | score: [-0.016879986971616745, 0.05234624445438385]\n",
      "2500 steps | score: [0.014180186204612255, 0.026139553636312485]\n",
      "unknown params:  tensor([-0.4590, -0.6593])\n",
      "unknown variance:  tensor([[0.9665]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4366, -0.5961])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.13650554418563843]\n",
      "100 steps | score: [-0.019202392548322678]\n",
      "200 steps | score: [-0.010875333100557327]\n",
      "300 steps | score: [-0.026082627475261688]\n",
      "400 steps | score: [-0.05075942724943161]\n",
      "500 steps | score: [-0.04065262898802757]\n",
      "600 steps | score: [-0.005068045109510422]\n",
      "0 steps | score: [0.08141276240348816, 0.17568577826023102]\n",
      "100 steps | score: [0.03869063779711723, 0.05909107252955437]\n",
      "200 steps | score: [-0.050460170954465866, 0.12998288869857788]\n",
      "300 steps | score: [-0.048290230333805084, 0.0664612203836441]\n",
      "400 steps | score: [-0.07405545562505722, 0.14236976206302643]\n",
      "500 steps | score: [-0.0033020637929439545, 0.04188785329461098]\n",
      "600 steps | score: [0.05698142945766449, -0.06709112972021103]\n",
      "700 steps | score: [-0.07045381516218185, 0.11971732974052429]\n",
      "800 steps | score: [-0.014466948807239532, 0.042025864124298096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 steps | score: [0.07985144108533859, -0.10676176100969315]\n",
      "1000 steps | score: [-0.11454945057630539, 0.18358372151851654]\n",
      "1100 steps | score: [-0.03637810796499252, 0.07811419665813446]\n",
      "1200 steps | score: [0.017335867509245872, -0.003023136407136917]\n",
      "1300 steps | score: [-0.09005215018987656, 0.1522548347711563]\n",
      "1400 steps | score: [-0.016256706789135933, 0.053678546100854874]\n",
      "1500 steps | score: [-0.004655699245631695, 0.03734694421291351]\n",
      "1600 steps | score: [-0.07170532643795013, 0.12699562311172485]\n",
      "1700 steps | score: [-0.025567427277565002, 0.07323238253593445]\n",
      "1800 steps | score: [-0.03648703545331955, 0.08029690384864807]\n",
      "1900 steps | score: [-0.0723244771361351, 0.1312071979045868]\n",
      "2000 steps | score: [-0.052638158202171326, 0.10557898879051208]\n",
      "2100 steps | score: [-0.06047944352030754, 0.1027190238237381]\n",
      "2200 steps | score: [-0.07810341566801071, 0.14222948253154755]\n",
      "2300 steps | score: [-0.023175908252596855, 0.060649048537015915]\n",
      "2400 steps | score: [-0.037282105535268784, 0.0762421190738678]\n",
      "2500 steps | score: [-0.07462405413389206, 0.13433468341827393]\n",
      "2600 steps | score: [-0.025861890986561775, 0.06832830607891083]\n",
      "0 steps | score: [0.12236350029706955, 0.0628238394856453]\n",
      "100 steps | score: [0.09334361553192139, -0.07509230822324753]\n",
      "200 steps | score: [-0.021590854972600937, 0.02831440046429634]\n",
      "300 steps | score: [-0.03493143990635872, 0.001385049894452095]\n",
      "400 steps | score: [-0.04448464885354042, 0.0496925488114357]\n",
      "500 steps | score: [0.01187005452811718, -0.04599764198064804]\n",
      "600 steps | score: [0.08460339158773422, -0.16862742602825165]\n",
      "700 steps | score: [-0.011402971111238003, 0.007624415680766106]\n",
      "800 steps | score: [0.02752016671001911, -0.06034598872065544]\n",
      "900 steps | score: [0.12307875603437424, -0.20930957794189453]\n",
      "1000 steps | score: [-0.08217679709196091, 0.07985705137252808]\n",
      "1100 steps | score: [-0.0026023760437965393, -0.015170926228165627]\n",
      "1200 steps | score: [0.06978627294301987, -0.1421300172805786]\n",
      "1300 steps | score: [-0.05226951837539673, 0.05478846654295921]\n",
      "1400 steps | score: [0.022960344329476357, -0.0497521236538887]\n",
      "1500 steps | score: [0.005944350268691778, -0.044033151119947433]\n",
      "1600 steps | score: [-0.053264521062374115, 0.050667792558670044]\n",
      "1700 steps | score: [-0.003363434225320816, -0.011547503992915154]\n",
      "1800 steps | score: [-0.006620097905397415, -0.016521019861102104]\n",
      "1900 steps | score: [-0.04065927118062973, 0.039125584065914154]\n",
      "2000 steps | score: [-0.017693260684609413, 0.002171189058572054]\n",
      "2100 steps | score: [-0.014490913599729538, -0.0005935970693826675]\n",
      "2200 steps | score: [-0.05588207021355629, 0.047996290028095245]\n",
      "2300 steps | score: [0.0040312702767550945, -0.02651277557015419]\n",
      "2400 steps | score: [0.00693388981744647, -0.03183937072753906]\n",
      "2500 steps | score: [-0.03858084976673126, 0.03056769073009491]\n",
      "2600 steps | score: [0.013469352386891842, -0.03717624023556709]\n",
      "0 steps | score: [0.09087932854890823, 0.07684046775102615]\n",
      "100 steps | score: [0.04881691560149193, -0.032852232456207275]\n",
      "200 steps | score: [-0.038186319172382355, 0.04553530737757683]\n",
      "300 steps | score: [-0.03543883562088013, -0.030541401356458664]\n",
      "400 steps | score: [-0.060074981302022934, 0.055975526571273804]\n",
      "500 steps | score: [-0.002158199902623892, -0.04876506328582764]\n",
      "600 steps | score: [0.052135027945041656, -0.14823977649211884]\n",
      "700 steps | score: [-0.05338747799396515, 0.03144025802612305]\n",
      "800 steps | score: [-0.012709567323327065, -0.020195040851831436]\n",
      "900 steps | score: [0.09881746768951416, -0.19309669733047485]\n",
      "1000 steps | score: [-0.1034787967801094, 0.09235009551048279]\n",
      "1100 steps | score: [-0.028385445475578308, 0.00492984801530838]\n",
      "1200 steps | score: [0.03151511400938034, -0.09856247156858444]\n",
      "1300 steps | score: [-0.0939098447561264, 0.07469995319843292]\n",
      "1400 steps | score: [-0.008175157941877842, -0.02714979276061058]\n",
      "1500 steps | score: [-0.007628731429576874, -0.04238560423254967]\n",
      "1600 steps | score: [-0.06959742307662964, 0.054617565125226974]\n",
      "1700 steps | score: [-0.03550880774855614, 0.013074174523353577]\n",
      "1800 steps | score: [-0.037791669368743896, 0.0071751512587070465]\n",
      "1900 steps | score: [-0.07919561117887497, 0.0584602877497673]\n",
      "2000 steps | score: [-0.031172888353466988, 0.013520404696464539]\n",
      "2100 steps | score: [-0.051812928169965744, 0.02297353371977806]\n",
      "2200 steps | score: [-0.07327424734830856, 0.05169183760881424]\n",
      "2300 steps | score: [-0.018890103325247765, -0.016514932736754417]\n",
      "2400 steps | score: [-0.027113845571875572, -0.013195253908634186]\n",
      "2500 steps | score: [-0.05872095376253128, 0.03785232454538345]\n",
      "2600 steps | score: [-0.014331578277051449, -0.023689014837145805]\n",
      "unknown params:  tensor([-0.4922, -0.8113])\n",
      "unknown variance:  tensor([[1.0481]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4366, -0.5961])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.14323720335960388]\n",
      "100 steps | score: [-0.008512113243341446]\n",
      "0 steps | score: [0.10346035659313202, 0.07197370380163193]\n",
      "100 steps | score: [0.1001715138554573, -0.09621433168649673]\n",
      "200 steps | score: [-0.014479798264801502, 0.014546492137014866]\n",
      "300 steps | score: [-0.16065093874931335, 0.18739378452301025]\n",
      "400 steps | score: [-0.17604023218154907, 0.21411657333374023]\n",
      "500 steps | score: [0.02162756957113743, -0.07924150675535202]\n",
      "600 steps | score: [-0.10413408279418945, 0.13017916679382324]\n",
      "700 steps | score: [0.038706690073013306, -0.08730664849281311]\n",
      "800 steps | score: [-0.02880576066672802, -0.013189656659960747]\n",
      "900 steps | score: [-0.0476473867893219, 0.03438767045736313]\n",
      "1000 steps | score: [0.0011203460162505507, -0.04007357358932495]\n",
      "1100 steps | score: [-0.09880383312702179, 0.09986834973096848]\n",
      "1200 steps | score: [-0.14515259861946106, 0.1645704060792923]\n",
      "1300 steps | score: [0.04906424507498741, -0.11330565810203552]\n",
      "1400 steps | score: [-0.07376915216445923, 0.0748610869050026]\n",
      "1500 steps | score: [-0.012948332354426384, -0.01407652162015438]\n",
      "1600 steps | score: [-0.016187291592359543, -0.0076948609203100204]\n",
      "1700 steps | score: [-0.06132587790489197, 0.04731966555118561]\n",
      "1800 steps | score: [-0.03942321240901947, 0.013920792378485203]\n",
      "1900 steps | score: [-0.06001518294215202, 0.04986623302102089]\n",
      "2000 steps | score: [-0.1235399916768074, 0.13972550630569458]\n",
      "2100 steps | score: [0.0009169018012471497, -0.045336008071899414]\n",
      "2200 steps | score: [-0.017010439187288284, -0.008140629157423973]\n",
      "2300 steps | score: [-0.046652741730213165, 0.03372817486524582]\n",
      "2400 steps | score: [-0.03339175507426262, 0.0212326031178236]\n",
      "2500 steps | score: [-0.04654044657945633, 0.03165528178215027]\n",
      "2600 steps | score: [-0.04278845712542534, 0.01791394129395485]\n",
      "0 steps | score: [0.14074589312076569, 0.10440849512815475]\n",
      "100 steps | score: [0.1254381537437439, -0.04639427363872528]\n",
      "200 steps | score: [0.023927245289087296, 0.03922063112258911]\n",
      "300 steps | score: [-0.12220288813114166, 0.21595431864261627]\n",
      "400 steps | score: [-0.10594764351844788, 0.204301655292511]\n",
      "500 steps | score: [0.0703727975487709, -0.0627099946141243]\n",
      "600 steps | score: [-0.07659929990768433, 0.17015036940574646]\n",
      "700 steps | score: [0.10190873593091965, -0.08773350715637207]\n",
      "800 steps | score: [0.0015947585925459862, 0.029205691069364548]\n",
      "900 steps | score: [-0.00772347254678607, 0.05326112359762192]\n",
      "1000 steps | score: [0.05589985102415085, -0.02796306274831295]\n",
      "1100 steps | score: [-0.05818743258714676, 0.1279762089252472]\n",
      "1200 steps | score: [-0.09723106026649475, 0.18448534607887268]\n",
      "1300 steps | score: [0.09193608164787292, -0.08902676403522491]\n",
      "1400 steps | score: [-0.03973250836133957, 0.11686093360185623]\n",
      "1500 steps | score: [0.02698388881981373, -3.852322697639465e-05]\n",
      "1600 steps | score: [0.023416848853230476, 0.011573808267712593]\n",
      "1700 steps | score: [-0.013124936260282993, 0.06421080231666565]\n",
      "1800 steps | score: [0.010404523462057114, 0.029775481671094894]\n",
      "1900 steps | score: [0.0005834962939843535, 0.05060945078730583]\n",
      "2000 steps | score: [-0.09653712064027786, 0.17697395384311676]\n",
      "2100 steps | score: [0.035803668200969696, -0.012665465474128723]\n",
      "2200 steps | score: [0.00558390561491251, 0.03309399634599686]\n",
      "2300 steps | score: [0.001417456311173737, 0.060146331787109375]\n",
      "2400 steps | score: [-0.006156867370009422, 0.04446455091238022]\n",
      "2500 steps | score: [-0.01822568103671074, 0.07807506620883942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600 steps | score: [0.0001240700512425974, 0.04681994765996933]\n",
      "0 steps | score: [0.1050134226679802, 0.1260707676410675]\n",
      "100 steps | score: [0.12257955223321915, -0.07741345465183258]\n",
      "200 steps | score: [-0.005941728595644236, 0.05026073008775711]\n",
      "300 steps | score: [-0.1499268263578415, 0.23442822694778442]\n",
      "400 steps | score: [-0.14453889429569244, 0.22835013270378113]\n",
      "500 steps | score: [0.03915076330304146, -0.05432339757680893]\n",
      "600 steps | score: [-0.10899271816015244, 0.18344545364379883]\n",
      "700 steps | score: [0.08010919392108917, -0.08211401104927063]\n",
      "800 steps | score: [-0.034770410507917404, 0.04860936850309372]\n",
      "900 steps | score: [-0.03434997797012329, 0.06612060964107513]\n",
      "1000 steps | score: [0.016360310837626457, -0.01855623908340931]\n",
      "1100 steps | score: [-0.1009233370423317, 0.15727265179157257]\n",
      "1200 steps | score: [-0.12708590924739838, 0.20009243488311768]\n",
      "1300 steps | score: [0.06734103709459305, -0.09722606092691422]\n",
      "1400 steps | score: [-0.056637778878211975, 0.1104680597782135]\n",
      "1500 steps | score: [0.007233582902699709, 0.010905357077717781]\n",
      "1600 steps | score: [-0.004456296097487211, 0.012618551030755043]\n",
      "1700 steps | score: [-0.05325033515691757, 0.0924411416053772]\n",
      "1800 steps | score: [-0.023863116279244423, 0.04293159767985344]\n",
      "1900 steps | score: [-0.05438612401485443, 0.09160584211349487]\n",
      "2000 steps | score: [-0.10274095088243484, 0.17223434150218964]\n",
      "2100 steps | score: [0.01694307290017605, -0.010214120149612427]\n",
      "2200 steps | score: [-0.01126514095813036, 0.03524298593401909]\n",
      "2300 steps | score: [-0.018896590918302536, 0.04268477484583855]\n",
      "2400 steps | score: [-0.035541195422410965, 0.05974689871072769]\n",
      "2500 steps | score: [-0.036509253084659576, 0.07629009336233139]\n",
      "2600 steps | score: [-0.02226424217224121, 0.04686058685183525]\n",
      "unknown params:  tensor([-0.5294, -0.9908])\n",
      "unknown variance:  tensor([[1.1287]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4366, -0.5961])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.0010670050978660583]\n",
      "100 steps | score: [-0.2904278039932251]\n",
      "200 steps | score: [-0.27952414751052856]\n",
      "300 steps | score: [-0.1813298463821411]\n",
      "400 steps | score: [-0.16979578137397766]\n",
      "500 steps | score: [-0.1902909278869629]\n",
      "600 steps | score: [-0.32050955295562744]\n",
      "700 steps | score: [-0.21317090094089508]\n",
      "800 steps | score: [-0.15911173820495605]\n",
      "900 steps | score: [-0.19765543937683105]\n",
      "1000 steps | score: [-0.22611825168132782]\n",
      "1100 steps | score: [-0.23645074665546417]\n",
      "1200 steps | score: [-0.23184356093406677]\n",
      "1300 steps | score: [-0.22883589565753937]\n",
      "1400 steps | score: [-0.22106653451919556]\n",
      "1500 steps | score: [-0.18076924979686737]\n",
      "1600 steps | score: [-0.20927731692790985]\n",
      "1700 steps | score: [-0.20311234891414642]\n",
      "1800 steps | score: [-0.2383832484483719]\n",
      "1900 steps | score: [-0.21528352797031403]\n",
      "2000 steps | score: [-0.21939517557621002]\n",
      "2100 steps | score: [-0.20558136701583862]\n",
      "2200 steps | score: [-0.1942543089389801]\n",
      "2300 steps | score: [-0.23913949728012085]\n",
      "2400 steps | score: [-0.20839717984199524]\n",
      "2500 steps | score: [-0.2264482080936432]\n",
      "2600 steps | score: [-0.23392459750175476]\n",
      "0 steps | score: [0.2120257019996643, -0.09490485489368439]\n",
      "100 steps | score: [-0.06991537660360336, 0.17560622096061707]\n",
      "200 steps | score: [-0.08887601643800735, 0.1432112753391266]\n",
      "300 steps | score: [-0.08503049612045288, 0.13608747720718384]\n",
      "400 steps | score: [0.1447535902261734, -0.23768889904022217]\n",
      "500 steps | score: [0.16244569420814514, -0.3184104561805725]\n",
      "600 steps | score: [-0.07600238919258118, 0.09994441270828247]\n",
      "700 steps | score: [0.013156428001821041, -0.06046226620674133]\n",
      "800 steps | score: [0.035638753324747086, -0.07095904648303986]\n",
      "900 steps | score: [0.04730401188135147, -0.1039038822054863]\n",
      "1000 steps | score: [-0.003096416126936674, -0.02523634396493435]\n",
      "1100 steps | score: [0.065171018242836, -0.12870341539382935]\n",
      "1200 steps | score: [0.020293351262807846, -0.06281162053346634]\n",
      "1300 steps | score: [-0.04091470688581467, 0.047119174152612686]\n",
      "1400 steps | score: [0.048776280134916306, -0.1180834025144577]\n",
      "1500 steps | score: [0.08486615121364594, -0.15266530215740204]\n",
      "1600 steps | score: [0.030825039371848106, -0.07299312949180603]\n",
      "1700 steps | score: [0.07290253788232803, -0.148380845785141]\n",
      "1800 steps | score: [-0.058183543384075165, 0.07120425999164581]\n",
      "1900 steps | score: [0.02367568574845791, -0.06756746768951416]\n",
      "2000 steps | score: [0.04517305642366409, -0.09971370548009872]\n",
      "2100 steps | score: [0.048789896070957184, -0.11027082055807114]\n",
      "2200 steps | score: [0.06169171258807182, -0.13371817767620087]\n",
      "2300 steps | score: [0.027921011671423912, -0.08316291868686676]\n",
      "2400 steps | score: [0.03205267712473869, -0.08306196331977844]\n",
      "2500 steps | score: [-0.009024123661220074, -0.009842620231211185]\n",
      "unknown params:  tensor([-0.5096, -1.0754])\n",
      "unknown variance:  tensor([[1.1704]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4366, -0.5961])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2561357617378235]\n",
      "100 steps | score: [-0.024473628029227257]\n",
      "200 steps | score: [-0.02545882947742939]\n",
      "300 steps | score: [-0.03981578350067139]\n",
      "400 steps | score: [0.0354471355676651]\n",
      "500 steps | score: [-0.01762644574046135]\n",
      "600 steps | score: [-0.046272777020931244]\n",
      "700 steps | score: [-0.05393480136990547]\n",
      "800 steps | score: [0.019038643687963486]\n",
      "900 steps | score: [-0.036731280386447906]\n",
      "1000 steps | score: [-0.0032964609563350677]\n",
      "0 steps | score: [0.16943174600601196, -0.12185921519994736]\n",
      "100 steps | score: [-0.01260637678205967, 0.08066143840551376]\n",
      "200 steps | score: [-0.1306806206703186, 0.20076672732830048]\n",
      "300 steps | score: [-0.15355490148067474, 0.22970300912857056]\n",
      "400 steps | score: [0.10197869688272476, -0.25204557180404663]\n",
      "500 steps | score: [0.046917252242565155, -0.11574935913085938]\n",
      "600 steps | score: [-0.007901433855295181, -0.042619459331035614]\n",
      "700 steps | score: [-0.10585273802280426, 0.12478618323802948]\n",
      "800 steps | score: [0.08370911329984665, -0.2204170823097229]\n",
      "900 steps | score: [-0.10759198665618896, 0.12965017557144165]\n",
      "1000 steps | score: [-0.019544489681720734, -0.027733247727155685]\n",
      "1100 steps | score: [0.03432225063443184, -0.13917095959186554]\n",
      "1200 steps | score: [-0.017397550866007805, -0.03457006439566612]\n",
      "1300 steps | score: [-0.11251556873321533, 0.12136249244213104]\n",
      "1400 steps | score: [0.09320194274187088, -0.24224069714546204]\n",
      "1500 steps | score: [0.03158794716000557, -0.14333908259868622]\n",
      "1600 steps | score: [-0.06506509333848953, 0.03890545666217804]\n",
      "1700 steps | score: [0.045132141560316086, -0.16008882224559784]\n",
      "1800 steps | score: [-0.14398419857025146, 0.18987375497817993]\n",
      "1900 steps | score: [0.0020779562182724476, -0.07715623080730438]\n",
      "2000 steps | score: [-0.08468993753194809, 0.08204152435064316]\n",
      "2100 steps | score: [-0.036669306457042694, -0.009927891194820404]\n",
      "2200 steps | score: [-0.08127328008413315, 0.0813903659582138]\n",
      "2300 steps | score: [0.04724008962512016, -0.15780265629291534]\n",
      "2400 steps | score: [-0.0047422172501683235, -0.06456821411848068]\n",
      "2500 steps | score: [-0.0018323977710679173, -0.06727824360132217]\n",
      "0 steps | score: [0.0868014320731163, 0.06015978008508682]\n",
      "100 steps | score: [-0.0534333810210228, 0.1889042854309082]\n",
      "200 steps | score: [-0.21684448421001434, 0.38204458355903625]\n",
      "300 steps | score: [-0.19393549859523773, 0.3379688858985901]\n",
      "400 steps | score: [0.05453585088253021, -0.14076358079910278]\n",
      "500 steps | score: [-0.0009657373302616179, -0.020265258848667145]\n",
      "600 steps | score: [-0.07304029911756516, 0.08533646911382675]\n",
      "700 steps | score: [-0.1706649363040924, 0.27438169717788696]\n",
      "800 steps | score: [0.061144132167100906, -0.15893779695034027]\n",
      "900 steps | score: [-0.16819268465042114, 0.2765652537345886]\n",
      "1000 steps | score: [-0.060912396758794785, 0.07613182067871094]\n",
      "1100 steps | score: [-0.019628845155239105, -0.01666991226375103]\n",
      "1200 steps | score: [-0.04671149328351021, 0.03613360971212387]\n",
      "1300 steps | score: [-0.15414299070835114, 0.24672582745552063]\n",
      "1400 steps | score: [0.040167905390262604, -0.12280728667974472]\n",
      "1500 steps | score: [-0.027401404455304146, -0.006266247481107712]\n",
      "1600 steps | score: [-0.12655478715896606, 0.18457289040088654]\n",
      "1700 steps | score: [-0.01270962692797184, -0.030207814648747444]\n",
      "1800 steps | score: [-0.19728393852710724, 0.30182960629463196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [-0.05538731440901756, 0.04949861019849777]\n",
      "2000 steps | score: [-0.14332035183906555, 0.20876950025558472]\n",
      "2100 steps | score: [-0.07280434668064117, 0.0882178246974945]\n",
      "2200 steps | score: [-0.1374627649784088, 0.2081357091665268]\n",
      "2300 steps | score: [-0.014441343955695629, -0.03549235314130783]\n",
      "2400 steps | score: [-0.057027142494916916, 0.06128118559718132]\n",
      "2500 steps | score: [-0.05069093406200409, 0.0431208573281765]\n",
      "0 steps | score: [0.17762379348278046, -0.07295552641153336]\n",
      "100 steps | score: [0.02614550106227398, 0.07678281515836716]\n",
      "200 steps | score: [-0.1268525868654251, 0.24997064471244812]\n",
      "300 steps | score: [-0.13074339926242828, 0.26246365904808044]\n",
      "400 steps | score: [0.089821457862854, -0.1790822446346283]\n",
      "500 steps | score: [0.06251450628042221, -0.09232774376869202]\n",
      "600 steps | score: [0.009786629118025303, -0.029449742287397385]\n",
      "700 steps | score: [-0.08615531027317047, 0.15113890171051025]\n",
      "800 steps | score: [0.12668325006961823, -0.23893749713897705]\n",
      "900 steps | score: [-0.0866645947098732, 0.15440985560417175]\n",
      "1000 steps | score: [-0.011056163348257542, 0.016475286334753036]\n",
      "1100 steps | score: [0.048475008457899094, -0.09746793657541275]\n",
      "1200 steps | score: [0.020773453637957573, -0.03834269940853119]\n",
      "1300 steps | score: [-0.11233406513929367, 0.17556285858154297]\n",
      "1400 steps | score: [0.09932415187358856, -0.2097175419330597]\n",
      "1500 steps | score: [0.02325942926108837, -0.06414764374494553]\n",
      "1600 steps | score: [-0.053164564073085785, 0.084426149725914]\n",
      "1700 steps | score: [0.07230005413293839, -0.16464176774024963]\n",
      "1800 steps | score: [-0.11795932054519653, 0.19511498510837555]\n",
      "1900 steps | score: [0.025168607011437416, -0.06544816493988037]\n",
      "2000 steps | score: [-0.06175517290830612, 0.0998460203409195]\n",
      "2100 steps | score: [-0.008823655545711517, -0.0018059052526950836]\n",
      "unknown params:  tensor([-0.4996, -1.0915])\n",
      "unknown variance:  tensor([[1.2743]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4366, -0.5961])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.25075557827949524]\n",
      "100 steps | score: [-0.13638675212860107]\n",
      "200 steps | score: [0.0958261787891388]\n",
      "300 steps | score: [0.030192222446203232]\n",
      "400 steps | score: [-0.03174867480993271]\n",
      "500 steps | score: [0.05220348760485649]\n",
      "600 steps | score: [-0.00935775600373745]\n",
      "0 steps | score: [0.2522827386856079, -0.2160186916589737]\n",
      "100 steps | score: [0.002321014180779457, 0.14556777477264404]\n",
      "200 steps | score: [0.06676923483610153, -0.01738486811518669]\n",
      "300 steps | score: [0.22179283201694489, -0.3654056787490845]\n",
      "400 steps | score: [-0.0882595032453537, 0.22623708844184875]\n",
      "500 steps | score: [0.19175343215465546, -0.3440331220626831]\n",
      "600 steps | score: [-0.046707652509212494, 0.14231574535369873]\n",
      "700 steps | score: [0.006254049949347973, 0.038718510419130325]\n",
      "800 steps | score: [0.09001835435628891, -0.1312767118215561]\n",
      "900 steps | score: [0.2433813214302063, -0.4917508065700531]\n",
      "1000 steps | score: [-0.14303037524223328, 0.3068222999572754]\n",
      "1100 steps | score: [0.07107570022344589, -0.10276108235120773]\n",
      "1200 steps | score: [-0.12155211716890335, 0.2643336057662964]\n",
      "1300 steps | score: [0.16871275007724762, -0.315674364566803]\n",
      "1400 steps | score: [0.09716707468032837, -0.15579915046691895]\n",
      "1500 steps | score: [-0.04671526700258255, 0.1382015198469162]\n",
      "1600 steps | score: [0.0601920448243618, -0.0886181890964508]\n",
      "1700 steps | score: [0.0988570898771286, -0.15556244552135468]\n",
      "1800 steps | score: [0.09505510330200195, -0.16034528613090515]\n",
      "1900 steps | score: [0.02872302196919918, -0.021034754812717438]\n",
      "2000 steps | score: [0.14676328003406525, -0.26762154698371887]\n",
      "2100 steps | score: [-0.0019651674665510654, 0.049128226935863495]\n",
      "2200 steps | score: [0.07238129526376724, -0.11524220556020737]\n",
      "2300 steps | score: [-0.02076183445751667, 0.07280880212783813]\n",
      "2400 steps | score: [0.15461426973342896, -0.2818554937839508]\n",
      "2500 steps | score: [0.007673201151192188, 0.02527659572660923]\n",
      "unknown params:  tensor([-0.4932, -0.9459])\n",
      "unknown variance:  tensor([[1.3768]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/98273ae1-9c65-4371-94c6-5a25c5a44608\n",
      "gt params:  tensor([-0.4215, -0.6020])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.05079019069671631]\n",
      "100 steps | score: [-0.10497073084115982]\n",
      "200 steps | score: [-0.082522451877594]\n",
      "300 steps | score: [-0.14829674363136292]\n",
      "400 steps | score: [-0.12732365727424622]\n",
      "500 steps | score: [-0.1652577817440033]\n",
      "600 steps | score: [-0.1189253032207489]\n",
      "700 steps | score: [-0.06591078639030457]\n",
      "800 steps | score: [-0.09336148202419281]\n",
      "900 steps | score: [-0.05958428233861923]\n",
      "1000 steps | score: [-0.16423703730106354]\n",
      "1100 steps | score: [-0.11857637017965317]\n",
      "1200 steps | score: [-0.12180938571691513]\n",
      "1300 steps | score: [-0.10347776114940643]\n",
      "1400 steps | score: [-0.11897151917219162]\n",
      "1500 steps | score: [-0.10038955509662628]\n",
      "1600 steps | score: [-0.07497937977313995]\n",
      "1700 steps | score: [-0.10882629454135895]\n",
      "1800 steps | score: [-0.06637115031480789]\n",
      "1900 steps | score: [-0.13295599818229675]\n",
      "2000 steps | score: [-0.13116702437400818]\n",
      "2100 steps | score: [-0.08387807011604309]\n",
      "2200 steps | score: [-0.09159782528877258]\n",
      "2300 steps | score: [-0.11313629150390625]\n",
      "2400 steps | score: [-0.10742756724357605]\n",
      "2500 steps | score: [-0.09503911435604095]\n",
      "2600 steps | score: [-0.09609681367874146]\n",
      "0 steps | score: [0.017485927790403366, 0.04761352017521858]\n",
      "100 steps | score: [-0.03520827367901802, 0.01464877836406231]\n",
      "200 steps | score: [0.006711716763675213, -0.02762550860643387]\n",
      "300 steps | score: [-0.036200713366270065, 0.004834502935409546]\n",
      "400 steps | score: [-0.03285856917500496, -0.02757483720779419]\n",
      "500 steps | score: [-0.03135238587856293, 0.028271842747926712]\n",
      "600 steps | score: [-0.022392408922314644, -0.0023699733428657055]\n",
      "700 steps | score: [0.015962278470396996, -0.06930086761713028]\n",
      "800 steps | score: [0.0019125929102301598, -0.009581032209098339]\n",
      "0 steps | score: [0.10636436939239502, -0.016582069918513298]\n",
      "100 steps | score: [0.021312477067112923, -0.03798268735408783]\n",
      "200 steps | score: [0.07944778352975845, -0.08005021512508392]\n",
      "300 steps | score: [0.04442174360156059, -0.041416674852371216]\n",
      "400 steps | score: [0.024534787982702255, -0.08297208696603775]\n",
      "500 steps | score: [0.03659789636731148, -0.020310379564762115]\n",
      "600 steps | score: [0.047110967338085175, -0.05762164294719696]\n",
      "700 steps | score: [0.08193010091781616, -0.11613170057535172]\n",
      "800 steps | score: [0.07277373224496841, -0.06036246195435524]\n",
      "900 steps | score: [0.07789793610572815, -0.0844254195690155]\n",
      "1000 steps | score: [0.005865828134119511, -0.03887437283992767]\n",
      "1100 steps | score: [0.05661759525537491, -0.05829313024878502]\n",
      "1200 steps | score: [0.05392987281084061, -0.05003730580210686]\n",
      "1300 steps | score: [0.048419561237096786, -0.06337373703718185]\n",
      "1400 steps | score: [0.050097815692424774, -0.04384550824761391]\n",
      "1500 steps | score: [0.04898717626929283, -0.04601959511637688]\n",
      "1600 steps | score: [0.07788363844156265, -0.08489136397838593]\n",
      "1700 steps | score: [0.0725691020488739, -0.061055250465869904]\n",
      "1800 steps | score: [0.07580962777137756, -0.07292722910642624]\n",
      "1900 steps | score: [0.038279373198747635, -0.054974544793367386]\n",
      "2000 steps | score: [0.04976215213537216, -0.0743677169084549]\n",
      "2100 steps | score: [0.06297759711742401, -0.059510521590709686]\n",
      "2200 steps | score: [0.061060670763254166, -0.0622757263481617]\n",
      "2300 steps | score: [0.0540868416428566, -0.06520597636699677]\n",
      "2400 steps | score: [0.05421397462487221, -0.05519980937242508]\n",
      "2500 steps | score: [0.06002434715628624, -0.07513760775327682]\n",
      "2600 steps | score: [0.06100672483444214, -0.056348785758018494]\n",
      "0 steps | score: [0.04062101989984512, 0.019404686987400055]\n",
      "100 steps | score: [-0.03196965903043747, -0.008251836523413658]\n",
      "200 steps | score: [0.035987529903650284, -0.0474654957652092]\n",
      "300 steps | score: [-0.01770070381462574, -0.012121088802814484]\n",
      "400 steps | score: [-0.023098930716514587, -0.056909702718257904]\n",
      "500 steps | score: [-0.021892882883548737, 0.006902010180056095]\n",
      "600 steps | score: [-0.014093993231654167, -0.024776455014944077]\n",
      "700 steps | score: [0.028728201985359192, -0.09399320185184479]\n",
      "800 steps | score: [0.016566850244998932, -0.029908034950494766]\n",
      "900 steps | score: [0.02266586385667324, -0.042640600353479385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 steps | score: [-0.05016476288437843, -0.011560231447219849]\n",
      "1100 steps | score: [-0.0006617208709940314, -0.027990024536848068]\n",
      "1200 steps | score: [0.002132836962118745, -0.014503407292068005]\n",
      "1300 steps | score: [-0.008356953971087933, -0.03831075131893158]\n",
      "1400 steps | score: [-0.008739221841096878, -0.022694258019328117]\n",
      "1500 steps | score: [-0.009555770084261894, -0.015692971646785736]\n",
      "1600 steps | score: [0.015608824789524078, -0.05385180562734604]\n",
      "1700 steps | score: [0.011087176389992237, -0.029283540323376656]\n",
      "1800 steps | score: [0.01744765043258667, -0.04047428071498871]\n",
      "1900 steps | score: [-0.019453879445791245, -0.018550554290413857]\n",
      "2000 steps | score: [-0.004199082963168621, -0.03418755531311035]\n",
      "2100 steps | score: [0.0004223271971568465, -0.029430698603391647]\n",
      "2200 steps | score: [0.0062621161341667175, -0.03455735370516777]\n",
      "2300 steps | score: [-0.0024482684675604105, -0.03382205590605736]\n",
      "2400 steps | score: [-0.0041128285229206085, -0.025574106723070145]\n",
      "2500 steps | score: [0.007746713235974312, -0.044766031205654144]\n",
      "2600 steps | score: [0.008666408248245716, -0.027901262044906616]\n",
      "unknown params:  tensor([-0.3898, -0.4788])\n",
      "unknown variance:  tensor([[0.8035]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4215, -0.6020])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.25471261143684387]\n",
      "100 steps | score: [0.012183811515569687]\n",
      "200 steps | score: [0.04396621137857437]\n",
      "300 steps | score: [0.13716024160385132]\n",
      "400 steps | score: [0.15922263264656067]\n",
      "500 steps | score: [-0.017756648361682892]\n",
      "600 steps | score: [0.07354151457548141]\n",
      "700 steps | score: [0.1454116702079773]\n",
      "800 steps | score: [0.15895694494247437]\n",
      "900 steps | score: [0.024420276284217834]\n",
      "1000 steps | score: [0.1122119128704071]\n",
      "1100 steps | score: [0.12028774619102478]\n",
      "1200 steps | score: [0.1387651264667511]\n",
      "1300 steps | score: [0.06653675436973572]\n",
      "1400 steps | score: [0.11392521858215332]\n",
      "1500 steps | score: [0.09670624136924744]\n",
      "1600 steps | score: [0.11786940693855286]\n",
      "1700 steps | score: [0.09456194192171097]\n",
      "1800 steps | score: [0.08360759913921356]\n",
      "1900 steps | score: [0.10375086963176727]\n",
      "2000 steps | score: [0.1328803300857544]\n",
      "2100 steps | score: [0.10265551507472992]\n",
      "2200 steps | score: [0.10130221396684647]\n",
      "2300 steps | score: [0.11438140273094177]\n",
      "2400 steps | score: [0.12809942662715912]\n",
      "2500 steps | score: [0.11987464129924774]\n",
      "2600 steps | score: [0.08832043409347534]\n",
      "2700 steps | score: [0.10479583591222763]\n",
      "2800 steps | score: [0.10779092460870743]\n",
      "0 steps | score: [0.023843182250857353, 0.08030467480421066]\n",
      "100 steps | score: [-0.1386210173368454, 0.04587658494710922]\n",
      "200 steps | score: [-0.06766974180936813, -0.052072323858737946]\n",
      "300 steps | score: [-0.02680240198969841, 0.025024360045790672]\n",
      "400 steps | score: [0.019297311082482338, -0.034321386367082596]\n",
      "500 steps | score: [-0.12597119808197021, 0.030207155272364616]\n",
      "600 steps | score: [-0.047109317034482956, -0.03275054693222046]\n",
      "700 steps | score: [-0.042211830615997314, 0.018161308020353317]\n",
      "800 steps | score: [0.01357431523501873, -0.033395618200302124]\n",
      "900 steps | score: [-0.09223664551973343, 0.03047606348991394]\n",
      "1000 steps | score: [-0.02796117775142193, -0.04489362984895706]\n",
      "1100 steps | score: [-0.041706595569849014, 0.0043792156502604485]\n",
      "1200 steps | score: [0.006059747189283371, -0.0390610545873642]\n",
      "1300 steps | score: [-0.07883118838071823, 0.015912961214780807]\n",
      "1400 steps | score: [-0.0309778843075037, -0.03435375541448593]\n",
      "1500 steps | score: [-0.04467817023396492, 0.00291196396574378]\n",
      "1600 steps | score: [8.223379700211808e-05, -0.029617398977279663]\n",
      "1700 steps | score: [-0.05279023200273514, -0.0016994308680295944]\n",
      "1800 steps | score: [-0.04527205601334572, -0.011741027235984802]\n",
      "1900 steps | score: [-0.03612605109810829, -0.007852465845644474]\n",
      "2000 steps | score: [-0.01313289999961853, -0.02203252539038658]\n",
      "2100 steps | score: [-0.04223884269595146, -0.008384550921618938]\n",
      "2200 steps | score: [-0.03834996372461319, -0.009705090895295143]\n",
      "2300 steps | score: [-0.03313813731074333, -0.014344165101647377]\n",
      "2400 steps | score: [-0.024864155799150467, -0.017567481845617294]\n",
      "2500 steps | score: [-0.0351894348859787, -0.013906175270676613]\n",
      "2600 steps | score: [-0.039156317710876465, -0.01047342550009489]\n",
      "2700 steps | score: [-0.033089909702539444, -0.013070139102637768]\n",
      "2800 steps | score: [-0.0283968523144722, -0.017456909641623497]\n",
      "0 steps | score: [0.014673416502773762, 0.09808118641376495]\n",
      "100 steps | score: [-0.1610635370016098, 0.05572321265935898]\n",
      "200 steps | score: [-0.09565210342407227, -0.026830365881323814]\n",
      "300 steps | score: [-0.03578135743737221, 0.03599933907389641]\n",
      "400 steps | score: [-0.0015561114996671677, -0.022328324615955353]\n",
      "500 steps | score: [-0.14646166563034058, 0.04558112844824791]\n",
      "600 steps | score: [-0.0670088529586792, -0.024883203208446503]\n",
      "700 steps | score: [-0.05892457813024521, 0.029063524678349495]\n",
      "800 steps | score: [-0.008596488274633884, -0.02046501263976097]\n",
      "900 steps | score: [-0.10967148840427399, 0.03564340993762016]\n",
      "1000 steps | score: [-0.03714191913604736, -0.028935136273503304]\n",
      "1100 steps | score: [-0.04669374227523804, 0.014616452157497406]\n",
      "1200 steps | score: [-0.01545360404998064, -0.02063865028321743]\n",
      "1300 steps | score: [-0.08039897680282593, 0.01748468168079853]\n",
      "1400 steps | score: [-0.039180293679237366, -0.023208823055028915]\n",
      "1500 steps | score: [-0.055306073278188705, 0.018275128677487373]\n",
      "1600 steps | score: [-0.02136882394552231, -0.009846331551671028]\n",
      "1700 steps | score: [-0.06806810200214386, 0.013903288170695305]\n",
      "1800 steps | score: [-0.05525687336921692, 0.004353387281298637]\n",
      "1900 steps | score: [-0.04831321910023689, 0.00467608030885458]\n",
      "2000 steps | score: [-0.03284859657287598, -0.005139678716659546]\n",
      "2100 steps | score: [-0.060253385454416275, 0.007980624213814735]\n",
      "2200 steps | score: [-0.059416357427835464, 0.009118223562836647]\n",
      "2300 steps | score: [-0.04668021574616432, -0.0019289236515760422]\n",
      "2400 steps | score: [-0.03394420072436333, -0.00600005965679884]\n",
      "2500 steps | score: [-0.05334043502807617, 0.0047042956575751305]\n",
      "2600 steps | score: [-0.04767217859625816, 0.002697024494409561]\n",
      "2700 steps | score: [-0.052238162606954575, 0.0009443769231438637]\n",
      "2800 steps | score: [-0.038670770823955536, -0.004685511812567711]\n",
      "0 steps | score: [0.04517870396375656, 0.1302535980939865]\n",
      "100 steps | score: [-0.1219538003206253, 0.08938482403755188]\n",
      "200 steps | score: [-0.060707200318574905, -0.0010666679590940475]\n",
      "300 steps | score: [-0.005876580253243446, 0.07084044814109802]\n",
      "400 steps | score: [0.030067220330238342, 0.006584071554243565]\n",
      "500 steps | score: [-0.10531429946422577, 0.07978721708059311]\n",
      "600 steps | score: [-0.034692589193582535, 0.0018711313605308533]\n",
      "700 steps | score: [-0.03259744495153427, 0.059528715908527374]\n",
      "800 steps | score: [0.024850448593497276, 0.0023507801815867424]\n",
      "900 steps | score: [-0.08283732831478119, 0.07161323726177216]\n",
      "1000 steps | score: [-0.017801428213715553, 0.004138965159654617]\n",
      "1100 steps | score: [-0.0210916418582201, 0.047754090279340744]\n",
      "1200 steps | score: [0.016056248918175697, 0.014640919864177704]\n",
      "1300 steps | score: [-0.06164812296628952, 0.057711582630872726]\n",
      "1400 steps | score: [-0.01545361801981926, 0.015999402850866318]\n",
      "1500 steps | score: [-0.02907000109553337, 0.04488426074385643]\n",
      "1600 steps | score: [0.009644306264817715, 0.020659297704696655]\n",
      "1700 steps | score: [-0.04216456785798073, 0.05428368225693703]\n",
      "1800 steps | score: [-0.030733507126569748, 0.036802493035793304]\n",
      "1900 steps | score: [-0.02184002287685871, 0.04064147546887398]\n",
      "2000 steps | score: [-0.0007683612639084458, 0.023874184116721153]\n",
      "2100 steps | score: [-0.026923006400465965, 0.03636076673865318]\n",
      "2200 steps | score: [-0.02843622863292694, 0.04126041382551193]\n",
      "2300 steps | score: [-0.016868405044078827, 0.03471391648054123]\n",
      "2400 steps | score: [-0.011830426752567291, 0.026880133897066116]\n",
      "2500 steps | score: [-0.015485038049519062, 0.0323178805410862]\n",
      "2600 steps | score: [-0.01875080168247223, 0.034569114446640015]\n",
      "2700 steps | score: [-0.009444387629628181, 0.02955668978393078]\n",
      "2800 steps | score: [-0.012572393752634525, 0.026124514639377594]\n",
      "unknown params:  tensor([-0.4030, -0.5048])\n",
      "unknown variance:  tensor([[0.8461]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4215, -0.6020])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.16510933637619019]\n",
      "100 steps | score: [-0.02626900002360344]\n",
      "200 steps | score: [0.0037484881468117237]\n",
      "0 steps | score: [0.10290206968784332, 0.07999341934919357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [-0.00881959218531847, 0.06604238599538803]\n",
      "200 steps | score: [0.03284769132733345, -0.08588039129972458]\n",
      "300 steps | score: [0.023135768249630928, -0.007349040359258652]\n",
      "400 steps | score: [0.017289582639932632, -0.007870513945817947]\n",
      "500 steps | score: [0.007683760952204466, -0.0015702913515269756]\n",
      "unknown params:  tensor([-0.3992, -0.5276])\n",
      "unknown variance:  tensor([[0.8419]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4215, -0.6020])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.1687626838684082]\n",
      "100 steps | score: [0.020811455324292183]\n",
      "200 steps | score: [0.08529302477836609]\n",
      "300 steps | score: [-0.008695576339960098]\n",
      "0 steps | score: [0.12034556269645691, 0.12762534618377686]\n",
      "100 steps | score: [0.04875187948346138, 0.06617050617933273]\n",
      "200 steps | score: [0.10700459778308868, -0.078235924243927]\n",
      "300 steps | score: [-0.017056167125701904, 0.04129953682422638]\n",
      "400 steps | score: [-0.028004810214042664, 0.0635436475276947]\n",
      "500 steps | score: [0.06975702941417694, -0.024375498294830322]\n",
      "600 steps | score: [-0.054491542279720306, 0.07551443576812744]\n",
      "700 steps | score: [0.05858704820275307, -0.0033866986632347107]\n",
      "800 steps | score: [0.022130189463496208, 0.06005486473441124]\n",
      "900 steps | score: [0.06597135215997696, -0.037534672766923904]\n",
      "1000 steps | score: [0.024817682802677155, -0.012993261218070984]\n",
      "1100 steps | score: [0.017214983701705933, 0.028816772624850273]\n",
      "1200 steps | score: [0.03661171719431877, 0.015568835660815239]\n",
      "1300 steps | score: [-0.015478396788239479, 0.052169665694236755]\n",
      "1400 steps | score: [0.05068995803594589, -0.00603310763835907]\n",
      "1500 steps | score: [-0.00956904236227274, 0.06191509589552879]\n",
      "1600 steps | score: [0.03869515657424927, -0.008266817778348923]\n",
      "1700 steps | score: [0.005193566903471947, 0.02064889296889305]\n",
      "1800 steps | score: [-0.009802142158150673, 0.04775163158774376]\n",
      "1900 steps | score: [0.008330946788191795, 0.03913992643356323]\n",
      "2000 steps | score: [0.023883547633886337, 0.008985742926597595]\n",
      "2100 steps | score: [0.050992101430892944, -0.01237758994102478]\n",
      "2200 steps | score: [-0.0005712623242288828, 0.04758154973387718]\n",
      "2300 steps | score: [0.0271348524838686, 0.01144593209028244]\n",
      "2400 steps | score: [0.0014917829539626837, 0.02550126053392887]\n",
      "2500 steps | score: [0.010227837599813938, 0.03438366949558258]\n",
      "2600 steps | score: [0.007943782955408096, 0.02289487048983574]\n",
      "2700 steps | score: [0.012290522456169128, 0.017538273707032204]\n",
      "0 steps | score: [0.1122865080833435, 0.1118302196264267]\n",
      "100 steps | score: [0.04180426523089409, 0.05944058299064636]\n",
      "200 steps | score: [0.11516983807086945, -0.09639541804790497]\n",
      "300 steps | score: [0.001195074524730444, 0.01380462571978569]\n",
      "400 steps | score: [-0.029020534828305244, 0.051859576255083084]\n",
      "500 steps | score: [0.07461680471897125, -0.04874790459871292]\n",
      "600 steps | score: [-0.06553756445646286, 0.058670565485954285]\n",
      "700 steps | score: [0.07915204763412476, -0.03853350877761841]\n",
      "800 steps | score: [0.0166839100420475, 0.039311181753873825]\n",
      "900 steps | score: [0.07279085367918015, -0.07140334695577621]\n",
      "1000 steps | score: [0.03240656480193138, -0.02621414326131344]\n",
      "1100 steps | score: [0.010628764517605305, 0.01812639832496643]\n",
      "1200 steps | score: [0.03189067915081978, 0.002774401567876339]\n",
      "1300 steps | score: [-0.010162200778722763, 0.03155248239636421]\n",
      "1400 steps | score: [0.05593939125537872, -0.028195861726999283]\n",
      "1500 steps | score: [0.0027826298028230667, 0.041328903287649155]\n",
      "1600 steps | score: [0.04035837948322296, -0.0247818510979414]\n",
      "1700 steps | score: [0.013503332622349262, -0.003672848455607891]\n",
      "1800 steps | score: [-0.006766495294868946, 0.024656245484948158]\n",
      "1900 steps | score: [0.015536123886704445, 0.010581212118268013]\n",
      "2000 steps | score: [0.029050692915916443, -0.013203307054936886]\n",
      "2100 steps | score: [0.05366765335202217, -0.038681820034980774]\n",
      "2200 steps | score: [0.003967263735830784, 0.029801098629832268]\n",
      "2300 steps | score: [0.03478899970650673, -0.010270589962601662]\n",
      "2400 steps | score: [0.014558165334165096, 0.0022132541052997112]\n",
      "2500 steps | score: [0.011880178935825825, 0.01474205031991005]\n",
      "2600 steps | score: [0.013835789635777473, 0.003244738094508648]\n",
      "2700 steps | score: [0.023567132651805878, -0.0025719814002513885]\n",
      "0 steps | score: [0.13617533445358276, 0.07089722901582718]\n",
      "100 steps | score: [0.06084746867418289, 0.021713195368647575]\n",
      "200 steps | score: [0.1152203306555748, -0.11296515166759491]\n",
      "300 steps | score: [0.014688428491353989, -0.022914215922355652]\n",
      "400 steps | score: [-0.006651456002146006, 0.018817050382494926]\n",
      "500 steps | score: [0.08965591341257095, -0.09146517515182495]\n",
      "600 steps | score: [-0.042076144367456436, 0.01506669633090496]\n",
      "700 steps | score: [0.0918547734618187, -0.07692380249500275]\n",
      "800 steps | score: [0.06383634358644485, -0.008505764417350292]\n",
      "900 steps | score: [0.10371952503919601, -0.1116470992565155]\n",
      "1000 steps | score: [0.04760509729385376, -0.058467090129852295]\n",
      "1100 steps | score: [0.037728872150182724, -0.027242453768849373]\n",
      "1200 steps | score: [0.047017164528369904, -0.029596172273159027]\n",
      "1300 steps | score: [0.010895158164203167, -0.0028866324573755264]\n",
      "1400 steps | score: [0.0878891721367836, -0.07266876101493835]\n",
      "1500 steps | score: [0.024917010217905045, 0.004694685339927673]\n",
      "1600 steps | score: [0.06616773456335068, -0.0624280609190464]\n",
      "1700 steps | score: [0.03399134427309036, -0.03284153714776039]\n",
      "1800 steps | score: [0.018225783482193947, -0.007650473155081272]\n",
      "1900 steps | score: [0.03323248773813248, -0.023959826678037643]\n",
      "2000 steps | score: [0.0510501004755497, -0.05373035743832588]\n",
      "2100 steps | score: [0.08800667524337769, -0.0793004035949707]\n",
      "2200 steps | score: [0.028636900708079338, -0.00987775344401598]\n",
      "2300 steps | score: [0.05070861801505089, -0.0430702269077301]\n",
      "2400 steps | score: [0.030614599585533142, -0.030803123489022255]\n",
      "2500 steps | score: [0.03220595419406891, -0.025936484336853027]\n",
      "2600 steps | score: [0.0369403213262558, -0.026905063539743423]\n",
      "2700 steps | score: [0.0459781289100647, -0.0439312681555748]\n",
      "unknown params:  tensor([-0.4284, -0.5901])\n",
      "unknown variance:  tensor([[0.9020]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4215, -0.6020])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.18147653341293335]\n",
      "100 steps | score: [0.039997465908527374]\n",
      "200 steps | score: [-0.007131228223443031]\n",
      "0 steps | score: [0.12999512255191803, 0.09335437417030334]\n",
      "100 steps | score: [0.058830376714468, 0.00887551624327898]\n",
      "200 steps | score: [-0.04346730560064316, 0.053733501583337784]\n",
      "300 steps | score: [0.09424419701099396, -0.11217768490314484]\n",
      "400 steps | score: [-0.10570111870765686, 0.1407538652420044]\n",
      "500 steps | score: [0.1207924634218216, -0.1650950014591217]\n",
      "600 steps | score: [-0.029978834092617035, 0.0077488599345088005]\n",
      "700 steps | score: [-0.02874181605875492, 0.07345928996801376]\n",
      "800 steps | score: [-0.010431085713207722, -0.0031895991414785385]\n",
      "900 steps | score: [-0.007946646772325039, 0.004509343765676022]\n",
      "0 steps | score: [0.13398008048534393, 0.05813423544168472]\n",
      "100 steps | score: [0.05986254662275314, -0.022319721058011055]\n",
      "200 steps | score: [-0.03659405559301376, 0.014924241229891777]\n",
      "300 steps | score: [0.1048823818564415, -0.15531446039676666]\n",
      "400 steps | score: [-0.10629349201917648, 0.10398686677217484]\n",
      "500 steps | score: [0.1101931780576706, -0.16275790333747864]\n",
      "600 steps | score: [-0.021191909909248352, -0.025816969573497772]\n",
      "700 steps | score: [-0.016146665439009666, 0.03028023988008499]\n",
      "800 steps | score: [-0.007770863827317953, -0.03433077409863472]\n",
      "900 steps | score: [-0.010162964463233948, -0.02764124795794487]\n",
      "1000 steps | score: [-0.032199591398239136, 0.03559563308954239]\n",
      "1100 steps | score: [0.035243164747953415, -0.05443334951996803]\n",
      "1200 steps | score: [-0.03144541382789612, 0.0036629540845751762]\n",
      "1300 steps | score: [0.09322153031826019, -0.11771918833255768]\n",
      "1400 steps | score: [-0.010119400918483734, 0.003670159727334976]\n",
      "1500 steps | score: [-0.018437843769788742, -0.0023177999537438154]\n",
      "1600 steps | score: [0.032976701855659485, -0.048276353627443314]\n",
      "1700 steps | score: [-0.0032865621615201235, 0.00049817212857306]\n",
      "unknown params:  tensor([-0.4497, -0.7120])\n",
      "unknown variance:  tensor([[0.9487]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4215, -0.6020])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.23822908103466034]\n",
      "100 steps | score: [0.007602685131132603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 steps | score: [0.16578319668769836, 0.0966654121875763]\n",
      "100 steps | score: [0.007583831436932087, 0.0780768021941185]\n",
      "200 steps | score: [-0.050366733223199844, 0.1092405915260315]\n",
      "300 steps | score: [0.022855184972286224, 0.04690764099359512]\n",
      "400 steps | score: [-0.01954706385731697, 0.08369100093841553]\n",
      "500 steps | score: [-0.07131633907556534, 0.11952900886535645]\n",
      "600 steps | score: [0.12794744968414307, -0.11027568578720093]\n",
      "700 steps | score: [0.002939315512776375, 0.04947412759065628]\n",
      "800 steps | score: [0.0025940362829715014, 0.03102927654981613]\n",
      "900 steps | score: [0.03598109260201454, 0.00845343992114067]\n",
      "1000 steps | score: [0.023709295317530632, 0.029123947024345398]\n",
      "1100 steps | score: [0.0022204311098903418, 0.03164888173341751]\n",
      "1200 steps | score: [0.07670649141073227, -0.04532996192574501]\n",
      "1300 steps | score: [0.029194938018918037, 0.013775115832686424]\n",
      "1400 steps | score: [0.003523959079757333, 0.04453510418534279]\n",
      "1500 steps | score: [0.0475928820669651, -0.01089063473045826]\n",
      "1600 steps | score: [0.036119405180215836, 0.0010153558105230331]\n",
      "1700 steps | score: [0.0026466622948646545, 0.0435929112136364]\n",
      "1800 steps | score: [0.050133075565099716, -0.032097235321998596]\n",
      "1900 steps | score: [0.021593168377876282, 0.022024549543857574]\n",
      "2000 steps | score: [0.023174472153186798, 0.0135908592492342]\n",
      "2100 steps | score: [0.028992805629968643, 0.0135140810161829]\n",
      "2200 steps | score: [0.027870146557688713, 0.0067806970328092575]\n",
      "2300 steps | score: [0.0382327064871788, -0.011131763458251953]\n",
      "2400 steps | score: [0.02864629589021206, 0.012433469295501709]\n",
      "2500 steps | score: [0.025307653471827507, 0.01561342179775238]\n",
      "2600 steps | score: [0.025186244398355484, 0.004986215382814407]\n",
      "0 steps | score: [0.11484586447477341, 0.1579943746328354]\n",
      "100 steps | score: [-0.019952889531850815, 0.1301974207162857]\n",
      "200 steps | score: [-0.07572794705629349, 0.16089217364788055]\n",
      "300 steps | score: [-0.019774125888943672, 0.10061081498861313]\n",
      "400 steps | score: [-0.06900717318058014, 0.15285296738147736]\n",
      "500 steps | score: [-0.09531985968351364, 0.1657063066959381]\n",
      "600 steps | score: [0.07309231907129288, -0.03342149034142494]\n",
      "700 steps | score: [-0.014192732982337475, 0.0913594588637352]\n",
      "800 steps | score: [-0.02593586966395378, 0.07130376249551773]\n",
      "900 steps | score: [0.040375735610723495, 0.026351898908615112]\n",
      "1000 steps | score: [-0.005286766681820154, 0.07504849135875702]\n",
      "1100 steps | score: [-0.03448513150215149, 0.08990612626075745]\n",
      "1200 steps | score: [0.05792225897312164, -0.011241177096962929]\n",
      "1300 steps | score: [0.007468590047210455, 0.05220948904752731]\n",
      "1400 steps | score: [-0.03093528561294079, 0.08657822012901306]\n",
      "1500 steps | score: [0.022645041346549988, 0.02525683119893074]\n",
      "1600 steps | score: [0.012805802747607231, 0.03887387365102768]\n",
      "1700 steps | score: [-0.03514351695775986, 0.09681791067123413]\n",
      "1800 steps | score: [0.032289259135723114, 0.016365977004170418]\n",
      "1900 steps | score: [-0.008766787126660347, 0.06846348941326141]\n",
      "2000 steps | score: [-0.0053524416871368885, 0.06266733258962631]\n",
      "2100 steps | score: [-0.005298198200762272, 0.06071449816226959]\n",
      "2200 steps | score: [-0.0052239494398236275, 0.05912306532263756]\n",
      "2300 steps | score: [0.018875859677791595, 0.03385075554251671]\n",
      "2400 steps | score: [0.0008112628711387515, 0.059397220611572266]\n",
      "2500 steps | score: [-0.009780611842870712, 0.06801684200763702]\n",
      "2600 steps | score: [0.0061315083876252174, 0.04169879108667374]\n",
      "0 steps | score: [0.09324648231267929, 0.11187583953142166]\n",
      "100 steps | score: [-0.05092167109251022, 0.09933184087276459]\n",
      "200 steps | score: [-0.10527832806110382, 0.13008762896060944]\n",
      "300 steps | score: [-0.03897644206881523, 0.05704227089881897]\n",
      "400 steps | score: [-0.08816947788000107, 0.1106019988656044]\n",
      "500 steps | score: [-0.1251770257949829, 0.1279471516609192]\n",
      "600 steps | score: [0.05939233675599098, -0.07414522767066956]\n",
      "700 steps | score: [-0.04199231415987015, 0.05318547412753105]\n",
      "800 steps | score: [-0.04418192431330681, 0.03362399712204933]\n",
      "900 steps | score: [0.012850561179220676, -0.015892693772912025]\n",
      "1000 steps | score: [-0.040065109729766846, 0.04029108211398125]\n",
      "1100 steps | score: [-0.06072735786437988, 0.05743493139743805]\n",
      "1200 steps | score: [0.03799796104431152, -0.05371735244989395]\n",
      "1300 steps | score: [-0.027226384729146957, 0.026276221498847008]\n",
      "1400 steps | score: [-0.052989110350608826, 0.04744643718004227]\n",
      "1500 steps | score: [0.017542444169521332, -0.027072284370660782]\n",
      "1600 steps | score: [-0.01630144566297531, 0.003986332565546036]\n",
      "1700 steps | score: [-0.04596854746341705, 0.04303206875920296]\n",
      "1800 steps | score: [0.013362301513552666, -0.02312837354838848]\n",
      "1900 steps | score: [-0.027058251202106476, 0.022454634308815002]\n",
      "2000 steps | score: [-0.029908401891589165, 0.029179485514760017]\n",
      "2100 steps | score: [-0.020399341359734535, 0.021480398252606392]\n",
      "2200 steps | score: [-0.03088858351111412, 0.028777262195944786]\n",
      "2300 steps | score: [0.00035963626578450203, -0.020163271576166153]\n",
      "2400 steps | score: [-0.019885055720806122, 0.02004019357264042]\n",
      "2500 steps | score: [-0.018743440508842468, 0.018772557377815247]\n",
      "2600 steps | score: [-0.012667627073824406, 0.0018944274634122849]\n",
      "unknown params:  tensor([-0.4763, -0.8077])\n",
      "unknown variance:  tensor([[0.9943]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4215, -0.6020])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2127108871936798]\n",
      "100 steps | score: [0.05033212527632713]\n",
      "200 steps | score: [0.05347445607185364]\n",
      "300 steps | score: [-0.04377395659685135]\n",
      "400 steps | score: [-0.009080581367015839]\n",
      "0 steps | score: [0.10213283449411392, 0.07900586724281311]\n",
      "100 steps | score: [0.06867793947458267, -0.026393480598926544]\n",
      "200 steps | score: [0.18378384411334991, -0.300383597612381]\n",
      "300 steps | score: [-0.21324531733989716, 0.2654430866241455]\n",
      "400 steps | score: [-0.04281895235180855, 0.02898171916604042]\n",
      "500 steps | score: [-0.050625260919332504, 0.030617935582995415]\n",
      "600 steps | score: [-0.11298738420009613, 0.13774651288986206]\n",
      "700 steps | score: [-0.08126591891050339, 0.08237798511981964]\n",
      "800 steps | score: [-0.042971737682819366, 0.00843336433172226]\n",
      "900 steps | score: [-0.076106958091259, 0.08637110143899918]\n",
      "1000 steps | score: [-0.09682649374008179, 0.11160887777805328]\n",
      "1100 steps | score: [-0.056503258645534515, 0.05254988372325897]\n",
      "1200 steps | score: [-0.031706150621175766, 0.03885893523693085]\n",
      "1300 steps | score: [-0.0214004535228014, -0.0014582499861717224]\n",
      "1400 steps | score: [-0.11937134712934494, 0.1308479756116867]\n",
      "1500 steps | score: [0.07055408507585526, -0.15797559916973114]\n",
      "1600 steps | score: [-0.0016878581373021007, -0.047588050365448]\n",
      "1700 steps | score: [-0.07105906307697296, 0.06867851316928864]\n",
      "1800 steps | score: [-0.025053607299923897, 0.011015918105840683]\n",
      "1900 steps | score: [0.007675328757613897, -0.06296289712190628]\n",
      "2000 steps | score: [-0.014457625336945057, -0.011387303471565247]\n",
      "2100 steps | score: [-0.0415474958717823, 0.017466265708208084]\n",
      "2200 steps | score: [-0.05709172412753105, 0.043493203818798065]\n",
      "2300 steps | score: [0.00022561934019904584, -0.040230706334114075]\n",
      "2400 steps | score: [-0.0486440546810627, 0.037044115364551544]\n",
      "2500 steps | score: [-0.06461524218320847, 0.06214828044176102]\n",
      "2600 steps | score: [-0.029250532388687134, 0.010821469128131866]\n",
      "unknown params:  tensor([-0.5038, -0.9772])\n",
      "unknown variance:  tensor([[1.0688]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4215, -0.6020])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.15337195992469788]\n",
      "100 steps | score: [-0.037527985870838165]\n",
      "200 steps | score: [-0.138412743806839]\n",
      "300 steps | score: [-0.12324296683073044]\n",
      "400 steps | score: [-0.08916996419429779]\n",
      "500 steps | score: [0.0052958205342292786]\n",
      "0 steps | score: [0.2044234424829483, -0.018502799794077873]\n",
      "100 steps | score: [0.15198078751564026, -0.10122475773096085]\n",
      "200 steps | score: [-0.1153566762804985, 0.24446329474449158]\n",
      "300 steps | score: [-0.08434659987688065, 0.18326155841350555]\n",
      "400 steps | score: [-0.052344195544719696, 0.12730741500854492]\n",
      "500 steps | score: [0.11773531138896942, -0.13653208315372467]\n",
      "600 steps | score: [0.19670315086841583, -0.29969966411590576]\n",
      "700 steps | score: [0.04105377569794655, -0.0456644706428051]\n",
      "800 steps | score: [0.06652984023094177, -0.057711221277713776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 steps | score: [-0.051958899945020676, 0.12140967696905136]\n",
      "1000 steps | score: [-0.04430239647626877, 0.11793255060911179]\n",
      "1100 steps | score: [0.09869559109210968, -0.13673466444015503]\n",
      "1200 steps | score: [0.11914359778165817, -0.16879208385944366]\n",
      "1300 steps | score: [0.05259706825017929, -0.03474852070212364]\n",
      "1400 steps | score: [0.03714527189731598, -0.026482854038476944]\n",
      "1500 steps | score: [-0.052077848464250565, 0.11382053047418594]\n",
      "1600 steps | score: [0.08140195161104202, -0.09839442372322083]\n",
      "1700 steps | score: [0.03238483518362045, -0.015295642428100109]\n",
      "1800 steps | score: [0.07120494544506073, -0.09146884828805923]\n",
      "1900 steps | score: [0.024467501789331436, 0.0006157699972391129]\n",
      "2000 steps | score: [-0.03402215614914894, 0.0916321724653244]\n",
      "2100 steps | score: [0.009104189462959766, 0.019205501303076744]\n",
      "2200 steps | score: [0.050881341099739075, -0.056637197732925415]\n",
      "2300 steps | score: [0.04467592015862465, -0.03742583841085434]\n",
      "2400 steps | score: [0.02479851245880127, -0.014785829000175]\n",
      "2500 steps | score: [0.022521302103996277, 0.010615771636366844]\n",
      "2600 steps | score: [0.031284697353839874, -0.016125008463859558]\n",
      "0 steps | score: [0.1843884140253067, -0.03465461730957031]\n",
      "100 steps | score: [0.07938553392887115, -0.02253674902021885]\n",
      "200 steps | score: [-0.1626802533864975, 0.25895288586616516]\n",
      "300 steps | score: [-0.12786456942558289, 0.20647409558296204]\n",
      "400 steps | score: [-0.0625956580042839, 0.10062991827726364]\n",
      "500 steps | score: [0.07275700569152832, -0.11264433711767197]\n",
      "600 steps | score: [0.134389728307724, -0.23906344175338745]\n",
      "700 steps | score: [-0.011032091453671455, 0.014875361695885658]\n",
      "800 steps | score: [0.04576483741402626, -0.05915550887584686]\n",
      "900 steps | score: [-0.07659754157066345, 0.11983805149793625]\n",
      "1000 steps | score: [-0.0879950225353241, 0.14375977218151093]\n",
      "1100 steps | score: [0.04930422082543373, -0.10632293671369553]\n",
      "1200 steps | score: [0.06383562833070755, -0.13088767230510712]\n",
      "1300 steps | score: [0.010530339553952217, -0.017125697806477547]\n",
      "1400 steps | score: [0.012072558514773846, -0.025286458432674408]\n",
      "1500 steps | score: [-0.08199791610240936, 0.1304357498884201]\n",
      "1600 steps | score: [0.055005818605422974, -0.09414748102426529]\n",
      "1700 steps | score: [0.016243018209934235, -0.032779257744550705]\n",
      "1800 steps | score: [0.043883003294467926, -0.07888351380825043]\n",
      "1900 steps | score: [-0.003016826929524541, 0.0026335320435464382]\n",
      "0 steps | score: [0.13385887444019318, 0.12360887229442596]\n",
      "100 steps | score: [0.051700517535209656, 0.09875009953975677]\n",
      "200 steps | score: [-0.19329047203063965, 0.3890649080276489]\n",
      "300 steps | score: [-0.13741762936115265, 0.30379822850227356]\n",
      "400 steps | score: [-0.10173380374908447, 0.232533797621727]\n",
      "500 steps | score: [0.035993944853544235, 0.01279386505484581]\n",
      "600 steps | score: [0.12999555468559265, -0.16994108259677887]\n",
      "700 steps | score: [-0.013643098063766956, 0.09066998958587646]\n",
      "800 steps | score: [-0.0031736937817186117, 0.0799078568816185]\n",
      "900 steps | score: [-0.09784193336963654, 0.23558951914310455]\n",
      "1000 steps | score: [-0.11800061166286469, 0.2685515582561493]\n",
      "1100 steps | score: [0.03789055719971657, -0.00017659366130828857]\n",
      "1200 steps | score: [0.05078329145908356, -0.017924802377820015]\n",
      "1300 steps | score: [-0.014014428481459618, 0.10198304057121277]\n",
      "1400 steps | score: [-0.012345774099230766, 0.08963333815336227]\n",
      "1500 steps | score: [-0.10242585837841034, 0.2281770408153534]\n",
      "1600 steps | score: [-0.0036496950779110193, 0.04745367169380188]\n",
      "1700 steps | score: [-0.02869175560772419, 0.10637199133634567]\n",
      "1800 steps | score: [0.017569147050380707, 0.02892106957733631]\n",
      "1900 steps | score: [-0.03670715168118477, 0.12047404050827026]\n",
      "2000 steps | score: [-0.08945919573307037, 0.2164945900440216]\n",
      "2100 steps | score: [-0.053142815828323364, 0.14056608080863953]\n",
      "2200 steps | score: [-0.01793723739683628, 0.09627215564250946]\n",
      "2300 steps | score: [-0.014754089526832104, 0.08562528342008591]\n",
      "2400 steps | score: [-0.041346851736307144, 0.12181271612644196]\n",
      "2500 steps | score: [-0.049455076456069946, 0.14286018908023834]\n",
      "2600 steps | score: [-0.01970040798187256, 0.10061031579971313]\n",
      "unknown params:  tensor([-0.5235, -1.1304])\n",
      "unknown variance:  tensor([[1.1631]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4215, -0.6020])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.28665852546691895]\n",
      "100 steps | score: [0.04138434678316116]\n",
      "200 steps | score: [0.10200132429599762]\n",
      "300 steps | score: [0.06730140000581741]\n",
      "400 steps | score: [0.011085502803325653]\n",
      "500 steps | score: [0.01656380295753479]\n",
      "600 steps | score: [0.03662516176700592]\n",
      "700 steps | score: [-0.005349889397621155]\n",
      "0 steps | score: [0.10245794802904129, 0.0904776081442833]\n",
      "100 steps | score: [-0.0858740508556366, 0.28463780879974365]\n",
      "200 steps | score: [0.3228810131549835, -0.6267186403274536]\n",
      "300 steps | score: [0.025557659566402435, 0.008597470819950104]\n",
      "400 steps | score: [-0.05516671761870384, 0.11762101948261261]\n",
      "500 steps | score: [0.05881534516811371, -0.09363819658756256]\n",
      "600 steps | score: [-0.18158064782619476, 0.3236585557460785]\n",
      "700 steps | score: [-0.19901826977729797, 0.3728371262550354]\n",
      "800 steps | score: [-0.17036515474319458, 0.3035861551761627]\n",
      "900 steps | score: [-0.1997152864933014, 0.3622775971889496]\n",
      "1000 steps | score: [-0.17523474991321564, 0.3101591467857361]\n",
      "1100 steps | score: [-0.19715741276741028, 0.3641374111175537]\n",
      "1200 steps | score: [0.09724090248346329, -0.22409534454345703]\n",
      "1300 steps | score: [0.05789990350604057, -0.12473437190055847]\n",
      "1400 steps | score: [0.06929250061511993, -0.15824683010578156]\n",
      "1500 steps | score: [-0.045852478593587875, 0.07243486493825912]\n",
      "1600 steps | score: [-0.03305720537900925, 0.07370007783174515]\n",
      "1700 steps | score: [-0.07933317124843597, 0.14867395162582397]\n",
      "1800 steps | score: [-0.06646820157766342, 0.12665662169456482]\n",
      "1900 steps | score: [-0.0735786184668541, 0.12315749377012253]\n",
      "2000 steps | score: [-0.10333006829023361, 0.2026492953300476]\n",
      "2100 steps | score: [0.020320530980825424, -0.052721425890922546]\n",
      "2200 steps | score: [-0.12081407010555267, 0.2157408744096756]\n",
      "2300 steps | score: [-0.06687260419130325, 0.12066452205181122]\n",
      "2400 steps | score: [-0.07099240273237228, 0.11944589763879776]\n",
      "2500 steps | score: [-0.048376984894275665, 0.0768408551812172]\n",
      "0 steps | score: [0.14379073679447174, 0.076080322265625]\n",
      "100 steps | score: [-0.03424211964011192, 0.2511919438838959]\n",
      "200 steps | score: [0.3587966859340668, -0.6413362622261047]\n",
      "300 steps | score: [0.09607170522212982, -0.06557909399271011]\n",
      "400 steps | score: [-0.013507342897355556, 0.08581764996051788]\n",
      "500 steps | score: [0.10497426241636276, -0.11888810992240906]\n",
      "600 steps | score: [-0.15010614693164825, 0.31778275966644287]\n",
      "700 steps | score: [-0.16387473046779633, 0.3557347059249878]\n",
      "800 steps | score: [-0.11053431779146194, 0.25502416491508484]\n",
      "900 steps | score: [-0.16888022422790527, 0.36423784494400024]\n",
      "1000 steps | score: [-0.12194198369979858, 0.28335440158843994]\n",
      "1100 steps | score: [-0.15858222544193268, 0.35204845666885376]\n",
      "1200 steps | score: [0.11063162982463837, -0.1603744477033615]\n",
      "1300 steps | score: [0.11743076145648956, -0.16697821021080017]\n",
      "1400 steps | score: [0.11496736109256744, -0.17364443838596344]\n",
      "1500 steps | score: [0.008395073004066944, 0.049061160534620285]\n",
      "1600 steps | score: [0.0014532797504216433, 0.059528373181819916]\n",
      "1700 steps | score: [-0.03648500517010689, 0.12056192010641098]\n",
      "1800 steps | score: [-0.04418202489614487, 0.12591633200645447]\n",
      "1900 steps | score: [-0.0036204818170517683, 0.058842360973358154]\n",
      "2000 steps | score: [-0.06317310780286789, 0.17057403922080994]\n",
      "2100 steps | score: [0.045710645616054535, -0.03760923445224762]\n",
      "2200 steps | score: [-0.09186689555644989, 0.21970321238040924]\n",
      "2300 steps | score: [-0.03481770306825638, 0.11080551147460938]\n",
      "2400 steps | score: [-0.03562504053115845, 0.11416193097829819]\n",
      "2500 steps | score: [-0.004449863918125629, 0.06408224254846573]\n",
      "0 steps | score: [0.16168808937072754, 0.008028455078601837]\n",
      "100 steps | score: [-0.04309011623263359, 0.23402181267738342]\n",
      "200 steps | score: [0.3954301178455353, -0.7403962016105652]\n",
      "300 steps | score: [0.08541405200958252, -0.09908710420131683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 steps | score: [0.005395180080085993, 0.018381774425506592]\n",
      "500 steps | score: [0.14161646366119385, -0.2120083123445511]\n",
      "600 steps | score: [-0.11905352771282196, 0.25307318568229675]\n",
      "700 steps | score: [-0.16461890935897827, 0.32106539607048035]\n",
      "800 steps | score: [-0.11610463261604309, 0.23074470460414886]\n",
      "900 steps | score: [-0.14180852472782135, 0.2878701388835907]\n",
      "1000 steps | score: [-0.12769213318824768, 0.25015363097190857]\n",
      "1100 steps | score: [-0.16093996167182922, 0.32343024015426636]\n",
      "1200 steps | score: [0.12651404738426208, -0.21665936708450317]\n",
      "1300 steps | score: [0.13328233361244202, -0.2304362803697586]\n",
      "1400 steps | score: [0.11598857492208481, -0.22273103892803192]\n",
      "1500 steps | score: [0.0008595088729634881, 0.011010538786649704]\n",
      "1600 steps | score: [0.007579599507153034, 0.01823548972606659]\n",
      "1700 steps | score: [-0.03683508560061455, 0.08419710397720337]\n",
      "1800 steps | score: [-0.024532608687877655, 0.07955101132392883]\n",
      "1900 steps | score: [-0.00952267274260521, 0.03387061506509781]\n",
      "2000 steps | score: [-0.05189922824501991, 0.11873701214790344]\n",
      "2100 steps | score: [0.059256624430418015, -0.07976509630680084]\n",
      "2200 steps | score: [-0.07704512774944305, 0.16447339951992035]\n",
      "2300 steps | score: [-0.00472891004756093, 0.03932419791817665]\n",
      "2400 steps | score: [-0.008945148438215256, 0.044008463621139526]\n",
      "2500 steps | score: [0.012042928487062454, 3.337860107421875e-06]\n",
      "unknown params:  tensor([-0.5179, -1.2042])\n",
      "unknown variance:  tensor([[1.2574]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4215, -0.6020])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.355890691280365]\n",
      "100 steps | score: [0.06483818590641022]\n",
      "200 steps | score: [0.12139402329921722]\n",
      "300 steps | score: [0.042830049991607666]\n",
      "400 steps | score: [0.035684965550899506]\n",
      "500 steps | score: [0.0014458522200584412]\n",
      "0 steps | score: [0.17431224882602692, 0.06639048457145691]\n",
      "100 steps | score: [-0.035392411053180695, 0.3432765007019043]\n",
      "200 steps | score: [-0.03744973614811897, 0.2983664572238922]\n",
      "300 steps | score: [-0.06728918105363846, 0.30403947830200195]\n",
      "400 steps | score: [-0.12038789689540863, 0.4159371256828308]\n",
      "500 steps | score: [-0.10457204282283783, 0.36012768745422363]\n",
      "600 steps | score: [-0.0782303735613823, 0.32542845606803894]\n",
      "700 steps | score: [-0.02955879084765911, 0.2112579047679901]\n",
      "800 steps | score: [-0.17884747684001923, 0.5056928992271423]\n",
      "900 steps | score: [-0.14029240608215332, 0.4234011471271515]\n",
      "1000 steps | score: [-0.08761455863714218, 0.33296316862106323]\n",
      "1100 steps | score: [0.04163142293691635, 0.05374568700790405]\n",
      "1200 steps | score: [0.12129988521337509, -0.09568162262439728]\n",
      "1300 steps | score: [0.11836764961481094, -0.11034884303808212]\n",
      "1400 steps | score: [0.058990396559238434, 0.026734985411167145]\n",
      "1500 steps | score: [0.023127520456910133, 0.10234438627958298]\n",
      "1600 steps | score: [0.10929631441831589, -0.0934264063835144]\n",
      "1700 steps | score: [0.006699563004076481, 0.140757218003273]\n",
      "1800 steps | score: [0.025648895651102066, 0.09147776663303375]\n",
      "1900 steps | score: [-0.033862125128507614, 0.21498343348503113]\n",
      "2000 steps | score: [-0.02596365474164486, 0.20866422355175018]\n",
      "2100 steps | score: [-0.049107275903224945, 0.2579953968524933]\n",
      "2200 steps | score: [0.06029435247182846, 0.011777698993682861]\n",
      "2300 steps | score: [-0.04073766991496086, 0.22492295503616333]\n",
      "2400 steps | score: [0.02686482109129429, 0.09744071960449219]\n",
      "2500 steps | score: [-0.023607870563864708, 0.19389647245407104]\n",
      "2600 steps | score: [0.0003464909386821091, 0.14085647463798523]\n",
      "0 steps | score: [0.19436512887477875, -0.21866166591644287]\n",
      "100 steps | score: [-0.03518855944275856, 0.09822724014520645]\n",
      "200 steps | score: [-0.009910322725772858, 0.01898092031478882]\n",
      "300 steps | score: [-0.04343339055776596, 0.03825618699193001]\n",
      "400 steps | score: [-0.12106680870056152, 0.1847027838230133]\n",
      "500 steps | score: [-0.09077655524015427, 0.10479790717363358]\n",
      "600 steps | score: [-0.08783037215471268, 0.11156259477138519]\n",
      "700 steps | score: [-0.025175675749778748, -0.023229271173477173]\n",
      "800 steps | score: [-0.19787204265594482, 0.302410364151001]\n",
      "900 steps | score: [-0.14572358131408691, 0.203885018825531]\n",
      "1000 steps | score: [-0.0402597151696682, 0.004103607498109341]\n",
      "1100 steps | score: [0.06488554924726486, -0.23333024978637695]\n",
      "1200 steps | score: [0.12471257895231247, -0.33044329285621643]\n",
      "1300 steps | score: [0.12046709656715393, -0.3375422954559326]\n",
      "1400 steps | score: [0.06738178431987762, -0.22467392683029175]\n",
      "1500 steps | score: [0.018717454746365547, -0.12318625301122665]\n",
      "1600 steps | score: [0.10830514878034592, -0.31433388590812683]\n",
      "1700 steps | score: [0.0012215243186801672, -0.08937322348356247]\n",
      "1800 steps | score: [0.028291519731283188, -0.14230671525001526]\n",
      "1900 steps | score: [-0.03141724318265915, -0.0200571957975626]\n",
      "2000 steps | score: [-0.04806453734636307, 0.021712880581617355]\n",
      "2100 steps | score: [-0.05860906466841698, 0.02710893005132675]\n",
      "2200 steps | score: [0.06675665825605392, -0.2394312173128128]\n",
      "2300 steps | score: [-0.0325000025331974, -0.0162656269967556]\n",
      "2400 steps | score: [0.028576837852597237, -0.15909352898597717]\n",
      "2500 steps | score: [-0.0024120688904076815, -0.06464333832263947]\n",
      "2600 steps | score: [0.021545302122831345, -0.12463036179542542]\n",
      "0 steps | score: [0.1285252571105957, -0.015225347131490707]\n",
      "100 steps | score: [-0.08054317533969879, 0.26724374294281006]\n",
      "200 steps | score: [-0.06661668419837952, 0.2007032036781311]\n",
      "300 steps | score: [-0.09839989989995956, 0.2135152518749237]\n",
      "400 steps | score: [-0.16693323850631714, 0.35801124572753906]\n",
      "500 steps | score: [-0.14907041192054749, 0.28783488273620605]\n",
      "600 steps | score: [-0.13552811741828918, 0.2795548439025879]\n",
      "700 steps | score: [-0.085866779088974, 0.15937039256095886]\n",
      "800 steps | score: [-0.22399938106536865, 0.43842706084251404]\n",
      "900 steps | score: [-0.18129374086856842, 0.3434121906757355]\n",
      "1000 steps | score: [-0.11580296605825424, 0.23328876495361328]\n",
      "1100 steps | score: [-0.009138349443674088, -0.005856003612279892]\n",
      "unknown params:  tensor([-0.4672, -1.0501])\n",
      "unknown variance:  tensor([[1.2950]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/bb57a1c9-1b52-449c-87c9-0f0f3df2dda4\n",
      "gt params:  tensor([-0.4319, -0.5835])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.16823814809322357]\n",
      "100 steps | score: [-0.017158422619104385]\n",
      "200 steps | score: [0.09228770434856415]\n",
      "300 steps | score: [0.09576777368783951]\n",
      "400 steps | score: [0.05546675622463226]\n",
      "500 steps | score: [-0.021303296089172363]\n",
      "600 steps | score: [0.052989568561315536]\n",
      "700 steps | score: [0.06335341930389404]\n",
      "800 steps | score: [0.05103612691164017]\n",
      "900 steps | score: [0.03226977586746216]\n",
      "1000 steps | score: [-0.01811477541923523]\n",
      "1100 steps | score: [0.07261742651462555]\n",
      "1200 steps | score: [0.05613604933023453]\n",
      "1300 steps | score: [0.041676148772239685]\n",
      "1400 steps | score: [0.004123866558074951]\n",
      "0 steps | score: [-0.0004365190980024636, 0.03931029513478279]\n",
      "100 steps | score: [-0.06397192180156708, -0.025818869471549988]\n",
      "200 steps | score: [0.008143694140017033, -0.0030500306747853756]\n",
      "0 steps | score: [-0.005126370582729578, 0.0796552523970604]\n",
      "100 steps | score: [-0.06819748133420944, 0.007187132257968187]\n",
      "200 steps | score: [0.014110327698290348, 0.027648920193314552]\n",
      "300 steps | score: [0.00579486507922411, -0.03135690093040466]\n",
      "400 steps | score: [0.004632475320249796, -0.027119647711515427]\n",
      "500 steps | score: [-0.04692722484469414, 0.06159192696213722]\n",
      "600 steps | score: [-0.035592690110206604, 0.03916920721530914]\n",
      "700 steps | score: [-0.0181070938706398, 0.009751900099217892]\n",
      "800 steps | score: [-0.017961535602808, -0.014073820784687996]\n",
      "900 steps | score: [-0.026042666286230087, 0.0289646964520216]\n",
      "1000 steps | score: [-0.05732903629541397, 0.02690828964114189]\n",
      "1100 steps | score: [-0.013645687140524387, 0.04147810861468315]\n",
      "1200 steps | score: [-0.0056501394137740135, -0.017552591860294342]\n",
      "1300 steps | score: [-0.022915758192539215, 0.003674655221402645]\n",
      "1400 steps | score: [-0.03254013508558273, 0.02137126214802265]\n",
      "1500 steps | score: [-0.034199051558971405, 0.0371282584965229]\n",
      "1600 steps | score: [-0.013368599116802216, -0.0010465019149705768]\n",
      "1700 steps | score: [-0.02387813664972782, -0.007479181978851557]\n",
      "1800 steps | score: [-0.02584998495876789, 0.013846123591065407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [-0.03715256229043007, 0.034041181206703186]\n",
      "2000 steps | score: [-0.026958005502820015, 0.03800405189394951]\n",
      "2100 steps | score: [-0.004741930868476629, 0.010797487571835518]\n",
      "2200 steps | score: [-0.024657465517520905, 0.0028387221973389387]\n",
      "2300 steps | score: [-0.02076558768749237, 0.020030131563544273]\n",
      "2400 steps | score: [-0.03018934465944767, 0.027123473584651947]\n",
      "2500 steps | score: [-0.023313358426094055, 0.012778856791555882]\n",
      "2600 steps | score: [-0.02610792964696884, 0.014669486321508884]\n",
      "0 steps | score: [0.08762393146753311, 0.030915187671780586]\n",
      "100 steps | score: [0.011193154379725456, -0.026199547573924065]\n",
      "200 steps | score: [0.08233436197042465, -0.004013156518340111]\n",
      "300 steps | score: [0.08928339928388596, -0.05892711132764816]\n",
      "400 steps | score: [0.0697660744190216, -0.07491926848888397]\n",
      "500 steps | score: [0.02491196244955063, 0.02454330213367939]\n",
      "600 steps | score: [0.03979276493191719, 0.008703447878360748]\n",
      "700 steps | score: [0.05176059529185295, -0.02401934191584587]\n",
      "800 steps | score: [0.05810607224702835, -0.050005849450826645]\n",
      "900 steps | score: [0.04998749867081642, -0.0038843518123030663]\n",
      "1000 steps | score: [0.02153097279369831, 0.009413459338247776]\n",
      "1100 steps | score: [0.06251246482133865, 0.009469413198530674]\n",
      "1200 steps | score: [0.07256733626127243, -0.05731291323900223]\n",
      "1300 steps | score: [0.05833831802010536, -0.03514406085014343]\n",
      "1400 steps | score: [0.038029320538043976, -0.01204974390566349]\n",
      "1500 steps | score: [0.044969309121370316, 0.008124658837914467]\n",
      "1600 steps | score: [0.07128752022981644, -0.030433280393481255]\n",
      "1700 steps | score: [0.05357378348708153, -0.03498399630188942]\n",
      "1800 steps | score: [0.04785025864839554, -0.02087177336215973]\n",
      "1900 steps | score: [0.04173390194773674, 0.0014572269283235073]\n",
      "2000 steps | score: [0.04658820107579231, 0.005758719518780708]\n",
      "2100 steps | score: [0.06340565532445908, -0.021700523793697357]\n",
      "2200 steps | score: [0.04983443394303322, -0.025395262986421585]\n",
      "2300 steps | score: [0.05050589144229889, -0.007823387160897255]\n",
      "2400 steps | score: [0.04096708074212074, -0.002981877187266946]\n",
      "2500 steps | score: [0.05553198605775833, -0.020278658717870712]\n",
      "2600 steps | score: [0.04923120141029358, -0.020267607644200325]\n",
      "unknown params:  tensor([-0.3990, -0.4200])\n",
      "unknown variance:  tensor([[0.8046]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4319, -0.5835])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2376246452331543]\n",
      "100 steps | score: [0.07635386288166046]\n",
      "200 steps | score: [0.2414853721857071]\n",
      "300 steps | score: [0.10738714784383774]\n",
      "400 steps | score: [0.15128669142723083]\n",
      "500 steps | score: [0.06101994961500168]\n",
      "600 steps | score: [0.19182004034519196]\n",
      "700 steps | score: [0.1575387418270111]\n",
      "800 steps | score: [0.11608633399009705]\n",
      "900 steps | score: [0.12224748730659485]\n",
      "1000 steps | score: [0.19174063205718994]\n",
      "1100 steps | score: [0.14072895050048828]\n",
      "1200 steps | score: [0.11500908434391022]\n",
      "1300 steps | score: [0.10013321042060852]\n",
      "1400 steps | score: [0.14974403381347656]\n",
      "1500 steps | score: [0.1417647749185562]\n",
      "1600 steps | score: [0.1289585530757904]\n",
      "1700 steps | score: [0.11003340780735016]\n",
      "1800 steps | score: [0.11793122440576553]\n",
      "1900 steps | score: [0.11765623837709427]\n",
      "2000 steps | score: [0.13032937049865723]\n",
      "2100 steps | score: [0.11923138052225113]\n",
      "2200 steps | score: [0.1302519142627716]\n",
      "2300 steps | score: [0.1422652006149292]\n",
      "2400 steps | score: [0.12276890873908997]\n",
      "2500 steps | score: [0.11344172805547714]\n",
      "2600 steps | score: [0.11730054020881653]\n",
      "2700 steps | score: [0.11301793158054352]\n",
      "0 steps | score: [0.06493950635194778, 0.07657741010189056]\n",
      "100 steps | score: [-0.01764754019677639, 0.028437966480851173]\n",
      "200 steps | score: [0.07029645144939423, -0.0633612796664238]\n",
      "300 steps | score: [-0.009630204178392887, -0.005477888509631157]\n",
      "0 steps | score: [0.019884182140231133, 0.11927221715450287]\n",
      "100 steps | score: [-0.05895087867975235, 0.06384815275669098]\n",
      "200 steps | score: [0.04560001194477081, -0.03581678867340088]\n",
      "300 steps | score: [-0.04761615768074989, 0.02513369545340538]\n",
      "400 steps | score: [-0.006621784530580044, 0.020400499925017357]\n",
      "500 steps | score: [-0.053662821650505066, 0.046541422605514526]\n",
      "600 steps | score: [0.019849151372909546, -0.008205235004425049]\n",
      "700 steps | score: [-0.01943870447576046, -0.008173462003469467]\n",
      "800 steps | score: [-0.022059403359889984, 0.030422307550907135]\n",
      "900 steps | score: [-0.04641927406191826, 0.052627358585596085]\n",
      "1000 steps | score: [-0.007229201961308718, 0.003517787903547287]\n",
      "0 steps | score: [0.031977757811546326, 0.1048479825258255]\n",
      "100 steps | score: [-0.053393274545669556, 0.052046265453100204]\n",
      "200 steps | score: [0.05312679708003998, -0.039841264486312866]\n",
      "300 steps | score: [-0.0428958497941494, 0.026235466822981834]\n",
      "400 steps | score: [0.0011602023150771856, 0.018212441354990005]\n",
      "500 steps | score: [-0.04545743390917778, 0.03790447115898132]\n",
      "600 steps | score: [0.02901696413755417, -0.0183660127222538]\n",
      "700 steps | score: [-0.0003636385372374207, -0.021158233284950256]\n",
      "800 steps | score: [-0.007395163644105196, 0.020742297172546387]\n",
      "900 steps | score: [-0.030056139454245567, 0.04551669955253601]\n",
      "1000 steps | score: [0.019379841163754463, -0.007221026346087456]\n",
      "1100 steps | score: [-0.007508367765694857, -0.015498032793402672]\n",
      "1200 steps | score: [-0.016781125217676163, 0.017651179805397987]\n",
      "1300 steps | score: [-0.03627065569162369, 0.044429175555706024]\n",
      "1400 steps | score: [-0.0018762428080663085, 0.009831646457314491]\n",
      "unknown params:  tensor([-0.4089, -0.4537])\n",
      "unknown variance:  tensor([[0.8576]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4319, -0.5835])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2605111002922058]\n",
      "100 steps | score: [0.08859109878540039]\n",
      "200 steps | score: [0.05825484171509743]\n",
      "300 steps | score: [0.13527905941009521]\n",
      "400 steps | score: [0.12724725902080536]\n",
      "500 steps | score: [0.0750657469034195]\n",
      "600 steps | score: [0.15208584070205688]\n",
      "700 steps | score: [0.10615703463554382]\n",
      "800 steps | score: [0.12998288869857788]\n",
      "900 steps | score: [0.1052781194448471]\n",
      "1000 steps | score: [0.13611944019794464]\n",
      "1100 steps | score: [0.13547199964523315]\n",
      "1200 steps | score: [0.11431006342172623]\n",
      "1300 steps | score: [0.11497689038515091]\n",
      "1400 steps | score: [0.14567279815673828]\n",
      "1500 steps | score: [0.1498272866010666]\n",
      "1600 steps | score: [0.12016202509403229]\n",
      "1700 steps | score: [0.15138264000415802]\n",
      "1800 steps | score: [0.13085955381393433]\n",
      "1900 steps | score: [0.1242535263299942]\n",
      "2000 steps | score: [0.10813793540000916]\n",
      "2100 steps | score: [0.15665389597415924]\n",
      "2200 steps | score: [0.11044496297836304]\n",
      "2300 steps | score: [0.12490379810333252]\n",
      "2400 steps | score: [0.10450248420238495]\n",
      "2500 steps | score: [0.15383529663085938]\n",
      "2600 steps | score: [0.11959117650985718]\n",
      "0 steps | score: [0.07474973052740097, 0.09590199589729309]\n",
      "100 steps | score: [-0.026776786893606186, 0.06743864715099335]\n",
      "200 steps | score: [-0.033019475638866425, 0.028512192890048027]\n",
      "300 steps | score: [-0.0009893564274534583, -0.0317995585501194]\n",
      "400 steps | score: [0.0002604863839223981, 0.015183603391051292]\n",
      "500 steps | score: [-0.03456803038716316, 0.046951618045568466]\n",
      "600 steps | score: [0.04322921484708786, -0.08604468405246735]\n",
      "700 steps | score: [-0.005657179281115532, -0.007606653496623039]\n",
      "0 steps | score: [0.08178152143955231, 0.15051977336406708]\n",
      "100 steps | score: [-0.02808559127151966, 0.11532343924045563]\n",
      "200 steps | score: [-0.03585149720311165, 0.07957134395837784]\n",
      "300 steps | score: [0.007876218296587467, 0.009544344618916512]\n",
      "0 steps | score: [0.09446361660957336, 0.0793321505188942]\n",
      "100 steps | score: [-0.03608931601047516, 0.058776360005140305]\n",
      "200 steps | score: [-0.01606746017932892, 0.013452837243676186]\n",
      "300 steps | score: [0.017581867054104805, -0.04743609577417374]\n",
      "400 steps | score: [0.003145565977320075, 0.011117292568087578]\n",
      "500 steps | score: [-0.020926453173160553, 0.04121684283018112]\n",
      "600 steps | score: [0.056920502334833145, -0.1004994809627533]\n",
      "700 steps | score: [0.0026705290656536818, -0.022189557552337646]\n",
      "800 steps | score: [-0.0031260447576642036, 0.020661085844039917]\n",
      "900 steps | score: [-0.010998736135661602, 0.01717398874461651]\n",
      "1000 steps | score: [0.05156112462282181, -0.07425469905138016]\n",
      "1100 steps | score: [0.019570421427488327, -0.04937673360109329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 steps | score: [0.004416991490870714, 0.006525006145238876]\n",
      "unknown params:  tensor([-0.4405, -0.5504])\n",
      "unknown variance:  tensor([[0.9435]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4319, -0.5835])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3946269452571869]\n",
      "100 steps | score: [0.29662466049194336]\n",
      "200 steps | score: [0.34105104207992554]\n",
      "300 steps | score: [0.32095444202423096]\n",
      "400 steps | score: [0.298074334859848]\n",
      "500 steps | score: [0.24700216948986053]\n",
      "600 steps | score: [0.3304295837879181]\n",
      "700 steps | score: [0.2706986367702484]\n",
      "800 steps | score: [0.22773821651935577]\n",
      "900 steps | score: [0.29586949944496155]\n",
      "1000 steps | score: [0.27484744787216187]\n",
      "1100 steps | score: [0.2657497823238373]\n",
      "1200 steps | score: [0.25726261734962463]\n",
      "1300 steps | score: [0.25668269395828247]\n",
      "1400 steps | score: [0.24921981990337372]\n",
      "1500 steps | score: [0.2360110580921173]\n",
      "1600 steps | score: [0.30249908566474915]\n",
      "1700 steps | score: [0.26341429352760315]\n",
      "1800 steps | score: [0.27096831798553467]\n",
      "1900 steps | score: [0.25587621331214905]\n",
      "2000 steps | score: [0.28664061427116394]\n",
      "2100 steps | score: [0.27146288752555847]\n",
      "2200 steps | score: [0.24574579298496246]\n",
      "2300 steps | score: [0.272877037525177]\n",
      "2400 steps | score: [0.2861745357513428]\n",
      "2500 steps | score: [0.2651684582233429]\n",
      "2600 steps | score: [0.2480667531490326]\n",
      "2700 steps | score: [0.2795027494430542]\n",
      "0 steps | score: [0.0909261405467987, 0.08832497149705887]\n",
      "100 steps | score: [0.024202635511755943, 0.01677721180021763]\n",
      "200 steps | score: [0.12361492961645126, -0.16073888540267944]\n",
      "300 steps | score: [0.07081020623445511, -0.11988335102796555]\n",
      "400 steps | score: [0.025288889184594154, 0.010531650856137276]\n",
      "500 steps | score: [-0.014608506113290787, 0.018886473029851913]\n",
      "600 steps | score: [0.03411442041397095, -0.039085932075977325]\n",
      "700 steps | score: [-0.01062710303813219, -0.007862402126193047]\n",
      "800 steps | score: [-0.03499441593885422, 0.044908106327056885]\n",
      "900 steps | score: [0.11851292103528976, -0.15656375885009766]\n",
      "1000 steps | score: [0.0003467362548690289, -0.027389291673898697]\n",
      "1100 steps | score: [0.008519526571035385, 0.005537760443985462]\n",
      "0 steps | score: [0.1301851123571396, 0.10607221722602844]\n",
      "100 steps | score: [0.054729901254177094, 0.02955922670662403]\n",
      "200 steps | score: [0.1308494359254837, -0.11251185834407806]\n",
      "300 steps | score: [0.09476510435342789, -0.09510225802659988]\n",
      "400 steps | score: [0.06304991245269775, 0.02713790349662304]\n",
      "500 steps | score: [0.006268576718866825, 0.04042372480034828]\n",
      "600 steps | score: [0.05000028759241104, -0.01641399785876274]\n",
      "700 steps | score: [0.00829804316163063, 0.033844366669654846]\n",
      "800 steps | score: [-0.013087187893688679, 0.07188904285430908]\n",
      "900 steps | score: [0.12421859055757523, -0.10128749161958694]\n",
      "1000 steps | score: [0.02196223847568035, -0.0025569461286067963]\n",
      "1100 steps | score: [0.04275321215391159, 0.0216024462133646]\n",
      "1200 steps | score: [0.037328679114580154, 0.021662943065166473]\n",
      "1300 steps | score: [0.02531450055539608, 0.006589654367417097]\n",
      "1400 steps | score: [0.006033147685229778, 0.028945770114660263]\n",
      "1500 steps | score: [0.010798906907439232, 0.027430357411503792]\n",
      "1600 steps | score: [0.07937426120042801, -0.052459850907325745]\n",
      "1700 steps | score: [0.024489812552928925, 0.007475187070667744]\n",
      "1800 steps | score: [0.014229186810553074, 0.03249598294496536]\n",
      "1900 steps | score: [0.024151163175702095, 0.028470417484641075]\n",
      "2000 steps | score: [0.030794871971011162, 6.832042708992958e-05]\n",
      "2100 steps | score: [0.024127233773469925, 0.017567694187164307]\n",
      "2200 steps | score: [-0.0005629393272101879, 0.0385800264775753]\n",
      "2300 steps | score: [0.04680377244949341, -0.006800008937716484]\n",
      "2400 steps | score: [0.03698744624853134, -0.0057416618801653385]\n",
      "2500 steps | score: [0.021257301792502403, 0.023990770801901817]\n",
      "2600 steps | score: [0.020560206845402718, 0.026222895830869675]\n",
      "2700 steps | score: [0.03584865853190422, -0.000684735830873251]\n",
      "0 steps | score: [0.13609807193279266, 0.06007648631930351]\n",
      "100 steps | score: [0.054699577391147614, 0.001881076954305172]\n",
      "200 steps | score: [0.15850473940372467, -0.18246226012706757]\n",
      "300 steps | score: [0.11325707286596298, -0.16168212890625]\n",
      "400 steps | score: [0.05891421064734459, -0.013192370533943176]\n",
      "500 steps | score: [0.011855864897370338, -0.0026936528738588095]\n",
      "600 steps | score: [0.05866973102092743, -0.0591987743973732]\n",
      "700 steps | score: [0.027857739478349686, -0.028153104707598686]\n",
      "800 steps | score: [-0.007477818056941032, 0.029566148295998573]\n",
      "900 steps | score: [0.14186681807041168, -0.1671150177717209]\n",
      "1000 steps | score: [0.025154029950499535, -0.043216776102781296]\n",
      "1100 steps | score: [0.045877400785684586, -0.02276596426963806]\n",
      "1200 steps | score: [0.04408276826143265, -0.02412666752934456]\n",
      "1300 steps | score: [0.03971968963742256, -0.04433652386069298]\n",
      "1400 steps | score: [0.019009340554475784, -0.018382126465439796]\n",
      "1500 steps | score: [0.016184255480766296, -0.011613089591264725]\n",
      "1600 steps | score: [0.08277387917041779, -0.08971410989761353]\n",
      "1700 steps | score: [0.03622262924909592, -0.04670301079750061]\n",
      "1800 steps | score: [0.02503095380961895, -0.008564785122871399]\n",
      "1900 steps | score: [0.036086004227399826, -0.023917822167277336]\n",
      "2000 steps | score: [0.033344198018312454, -0.03858973830938339]\n",
      "2100 steps | score: [0.0312734991312027, -0.031176675111055374]\n",
      "2200 steps | score: [0.01314605213701725, -0.010132815688848495]\n",
      "2300 steps | score: [0.056581273674964905, -0.05820585787296295]\n",
      "2400 steps | score: [0.045125480741262436, -0.04919707030057907]\n",
      "2500 steps | score: [0.027271181344985962, -0.020244868472218513]\n",
      "2600 steps | score: [0.021607136353850365, -0.016612954437732697]\n",
      "2700 steps | score: [0.04228852689266205, -0.04501687362790108]\n",
      "unknown params:  tensor([-0.4348, -0.5552])\n",
      "unknown variance:  tensor([[0.9481]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4319, -0.5835])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3872950077056885]\n",
      "100 steps | score: [0.16352340579032898]\n",
      "200 steps | score: [0.1891280561685562]\n",
      "300 steps | score: [0.20898249745368958]\n",
      "400 steps | score: [0.14553679525852203]\n",
      "500 steps | score: [0.1743333488702774]\n",
      "600 steps | score: [0.1579485386610031]\n",
      "700 steps | score: [0.15011297166347504]\n",
      "800 steps | score: [0.18189097940921783]\n",
      "900 steps | score: [0.13939620554447174]\n",
      "1000 steps | score: [0.1692781299352646]\n",
      "1100 steps | score: [0.12457532435655594]\n",
      "1200 steps | score: [0.1727607548236847]\n",
      "1300 steps | score: [0.18097437918186188]\n",
      "1400 steps | score: [0.16147062182426453]\n",
      "1500 steps | score: [0.1926020234823227]\n",
      "1600 steps | score: [0.1678999364376068]\n",
      "1700 steps | score: [0.16060835123062134]\n",
      "1800 steps | score: [0.18298585712909698]\n",
      "1900 steps | score: [0.17205224931240082]\n",
      "2000 steps | score: [0.14976075291633606]\n",
      "2100 steps | score: [0.15729600191116333]\n",
      "2200 steps | score: [0.17275598645210266]\n",
      "2300 steps | score: [0.16477389633655548]\n",
      "2400 steps | score: [0.15427817404270172]\n",
      "2500 steps | score: [0.16350482404232025]\n",
      "0 steps | score: [0.16053685545921326, 0.05765952169895172]\n",
      "100 steps | score: [0.05135824531316757, -0.005854077637195587]\n",
      "200 steps | score: [0.0251154825091362, -0.05444761738181114]\n",
      "300 steps | score: [0.09698569774627686, -0.0900922641158104]\n",
      "400 steps | score: [0.05266455188393593, -0.04266897588968277]\n",
      "500 steps | score: [0.018281426280736923, -0.007845095358788967]\n",
      "600 steps | score: [0.01910686120390892, -0.008684119209647179]\n",
      "700 steps | score: [0.048395052552223206, -0.018855929374694824]\n",
      "800 steps | score: [0.07665397226810455, -0.05301932990550995]\n",
      "900 steps | score: [0.02961629256606102, -0.0402202308177948]\n",
      "1000 steps | score: [0.03439023718237877, -0.026148585602641106]\n",
      "1100 steps | score: [0.01480015553534031, -0.007821982726454735]\n",
      "1200 steps | score: [0.06872301548719406, -0.08422955870628357]\n",
      "1300 steps | score: [0.03376903012394905, -0.0343434177339077]\n",
      "1400 steps | score: [0.0034374718088656664, 0.010404936969280243]\n",
      "1500 steps | score: [0.10685653984546661, -0.12454801797866821]\n",
      "1600 steps | score: [0.08012522757053375, -0.08386195451021194]\n",
      "1700 steps | score: [-0.0016629992751404643, 0.01934807002544403]\n",
      "1800 steps | score: [0.047380659729242325, -0.03599585220217705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [0.04742085933685303, -0.047868020832538605]\n",
      "2000 steps | score: [0.029574183747172356, -0.01855643279850483]\n",
      "2100 steps | score: [0.029533086344599724, -0.018605098128318787]\n",
      "2200 steps | score: [0.06505218148231506, -0.0725456029176712]\n",
      "2300 steps | score: [0.04088667035102844, -0.02968638204038143]\n",
      "2400 steps | score: [0.028286265209317207, -0.013826195150613785]\n",
      "2500 steps | score: [0.06995115429162979, -0.06256338208913803]\n",
      "0 steps | score: [0.11036107689142227, 0.09303370118141174]\n",
      "100 steps | score: [0.01418701559305191, 0.003675815649330616]\n",
      "200 steps | score: [-0.026940496638417244, -0.011324782855808735]\n",
      "300 steps | score: [0.04648392274975777, -0.04623020067811012]\n",
      "400 steps | score: [-0.007065889425575733, -0.0032057813368737698]\n",
      "0 steps | score: [0.13276568055152893, 0.05142392963171005]\n",
      "100 steps | score: [0.05532994121313095, -0.04805789142847061]\n",
      "200 steps | score: [-0.00530073931440711, -0.038050390779972076]\n",
      "300 steps | score: [0.09517855197191238, -0.11034184694290161]\n",
      "400 steps | score: [0.02809910476207733, -0.05184425041079521]\n",
      "500 steps | score: [-0.0005662609473802149, -0.01809716410934925]\n",
      "600 steps | score: [0.0025153569877147675, -0.022939687594771385]\n",
      "700 steps | score: [0.021354634314775467, -0.02718687802553177]\n",
      "800 steps | score: [0.0590442419052124, -0.06411386281251907]\n",
      "900 steps | score: [0.012957314029335976, -0.044423285871744156]\n",
      "1000 steps | score: [0.013025615364313126, -0.03895766660571098]\n",
      "1100 steps | score: [0.0012374402722343802, -0.024404000490903854]\n",
      "1200 steps | score: [0.05230330675840378, -0.09155944734811783]\n",
      "1300 steps | score: [0.015418273396790028, -0.029571130871772766]\n",
      "1400 steps | score: [-0.005064896307885647, -0.0029683243483304977]\n",
      "unknown params:  tensor([-0.4379, -0.6534])\n",
      "unknown variance:  tensor([[0.9602]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4319, -0.5835])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.24081650376319885]\n",
      "100 steps | score: [-0.013674989342689514]\n",
      "200 steps | score: [0.018990006297826767]\n",
      "300 steps | score: [0.07124646008014679]\n",
      "400 steps | score: [-0.020536787807941437]\n",
      "500 steps | score: [0.05960982292890549]\n",
      "600 steps | score: [-0.003836698830127716]\n",
      "0 steps | score: [0.13382211327552795, 0.09276324510574341]\n",
      "100 steps | score: [-0.10773475468158722, 0.19177013635635376]\n",
      "200 steps | score: [-0.05754324421286583, 0.048706576228141785]\n",
      "300 steps | score: [-0.007925578393042088, 0.030680127441883087]\n",
      "400 steps | score: [-0.11454511433839798, 0.1592269092798233]\n",
      "500 steps | score: [0.020171187818050385, -0.04778308793902397]\n",
      "600 steps | score: [-0.04798758402466774, 0.07376258075237274]\n",
      "700 steps | score: [-0.062381915748119354, 0.1029348149895668]\n",
      "800 steps | score: [0.017223868519067764, -0.018979297950863838]\n",
      "900 steps | score: [-0.03488355129957199, 0.05932876095175743]\n",
      "1000 steps | score: [-0.0433000810444355, 0.07925796508789062]\n",
      "1100 steps | score: [0.05631222948431969, -0.07932412624359131]\n",
      "1200 steps | score: [-0.019551346078515053, 0.043618567287921906]\n",
      "1300 steps | score: [-0.01811174675822258, 0.044941388070583344]\n",
      "1400 steps | score: [0.05119229853153229, -0.06764401495456696]\n",
      "1500 steps | score: [-0.025549575686454773, 0.04814058542251587]\n",
      "1600 steps | score: [-0.029433991760015488, 0.050037190318107605]\n",
      "1700 steps | score: [0.04232434928417206, -0.06471462547779083]\n",
      "1800 steps | score: [-0.025124629959464073, 0.0451066754758358]\n",
      "1900 steps | score: [-0.0304690171033144, 0.05535564944148064]\n",
      "2000 steps | score: [0.03700604662299156, -0.048123594373464584]\n",
      "2100 steps | score: [-0.011495915241539478, 0.029945015907287598]\n",
      "2200 steps | score: [-0.026706717908382416, 0.05151153355836868]\n",
      "2300 steps | score: [0.030110226944088936, -0.03340243175625801]\n",
      "2400 steps | score: [-0.006028057541698217, 0.021075692027807236]\n",
      "2500 steps | score: [-0.027786411345005035, 0.04675384610891342]\n",
      "2600 steps | score: [0.023495323956012726, -0.01461145281791687]\n",
      "0 steps | score: [0.17540359497070312, 0.05902867019176483]\n",
      "100 steps | score: [-0.06494434177875519, 0.1477130651473999]\n",
      "200 steps | score: [-0.02226063795387745, 0.0329427570104599]\n",
      "300 steps | score: [0.017873065546154976, 0.011907059699296951]\n",
      "400 steps | score: [-0.07874245941638947, 0.12740449607372284]\n",
      "500 steps | score: [0.060000788420438766, -0.0711391419172287]\n",
      "600 steps | score: [-0.006739536300301552, 0.02923418954014778]\n",
      "700 steps | score: [-0.031017707660794258, 0.07226848602294922]\n",
      "800 steps | score: [0.025704773142933846, -0.026321420446038246]\n",
      "900 steps | score: [-0.017081737518310547, 0.04136771708726883]\n",
      "1000 steps | score: [-0.01334072183817625, 0.04731481522321701]\n",
      "1100 steps | score: [0.07679726183414459, -0.08789723366498947]\n",
      "1200 steps | score: [0.012458156794309616, 0.014635879546403885]\n",
      "1300 steps | score: [0.0010142747778445482, 0.026904039084911346]\n",
      "1400 steps | score: [0.06037569418549538, -0.06668233126401901]\n",
      "1500 steps | score: [0.004712971858680248, 0.015722136944532394]\n",
      "1600 steps | score: [0.007275837007910013, 0.01890305057168007]\n",
      "1700 steps | score: [0.06298007071018219, -0.07318250089883804]\n",
      "1800 steps | score: [0.00911220908164978, 0.009325027465820312]\n",
      "0 steps | score: [0.14408279955387115, 0.06042761728167534]\n",
      "100 steps | score: [-0.09740535914897919, 0.16528891026973724]\n",
      "200 steps | score: [-0.059831082820892334, 0.038042955100536346]\n",
      "300 steps | score: [-0.0016180395614355803, 0.005034048575907946]\n",
      "unknown params:  tensor([-0.4977, -0.8370])\n",
      "unknown variance:  tensor([[1.0947]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4319, -0.5835])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.27161169052124023]\n",
      "100 steps | score: [0.057492852210998535]\n",
      "200 steps | score: [0.06583775579929352]\n",
      "300 steps | score: [0.051243141293525696]\n",
      "400 steps | score: [0.04617663100361824]\n",
      "500 steps | score: [-0.005183197557926178]\n",
      "0 steps | score: [0.06023333594202995, 0.206455260515213]\n",
      "100 steps | score: [-0.026610001921653748, 0.16561885178089142]\n",
      "200 steps | score: [-0.1110343411564827, 0.21918165683746338]\n",
      "300 steps | score: [-0.14189651608467102, 0.25153329968452454]\n",
      "400 steps | score: [-0.12309631705284119, 0.23655979335308075]\n",
      "500 steps | score: [-0.18029209971427917, 0.2923913896083832]\n",
      "600 steps | score: [-0.0748516395688057, 0.17052315175533295]\n",
      "700 steps | score: [0.22635507583618164, -0.36015236377716064]\n",
      "800 steps | score: [-0.06060943379998207, 0.11458735167980194]\n",
      "900 steps | score: [-0.1133250743150711, 0.20622265338897705]\n",
      "1000 steps | score: [-0.036545511335134506, 0.08159220218658447]\n",
      "1100 steps | score: [-0.1265241950750351, 0.22272273898124695]\n",
      "1200 steps | score: [-0.10902615636587143, 0.20639371871948242]\n",
      "1300 steps | score: [-0.06067659705877304, 0.11909155547618866]\n",
      "1400 steps | score: [-0.0801108255982399, 0.16391496360301971]\n",
      "1500 steps | score: [-0.07348638772964478, 0.15359371900558472]\n",
      "1600 steps | score: [-0.0547364167869091, 0.11967970430850983]\n",
      "1700 steps | score: [-0.10887710005044937, 0.1970326155424118]\n",
      "1800 steps | score: [-0.037254638969898224, 0.09163457155227661]\n",
      "1900 steps | score: [-0.08007857203483582, 0.14743000268936157]\n",
      "2000 steps | score: [-0.0931842103600502, 0.185358464717865]\n",
      "2100 steps | score: [-0.048568110913038254, 0.09764885902404785]\n",
      "2200 steps | score: [-0.10965469479560852, 0.19282297790050507]\n",
      "2300 steps | score: [-0.07373867183923721, 0.14565640687942505]\n",
      "2400 steps | score: [-0.058071624487638474, 0.12067995965480804]\n",
      "2500 steps | score: [-0.09539990872144699, 0.1719260960817337]\n",
      "2600 steps | score: [-0.047861166298389435, 0.09952171891927719]\n",
      "2700 steps | score: [-0.051259513944387436, 0.11688448488712311]\n",
      "0 steps | score: [0.12324662506580353, 0.0491013266146183]\n",
      "100 steps | score: [0.004281811881810427, 0.056229621171951294]\n",
      "200 steps | score: [-0.057155586779117584, 0.06522384285926819]\n",
      "300 steps | score: [-0.09746378660202026, 0.12444300949573517]\n",
      "400 steps | score: [-0.0725289136171341, 0.08894982933998108]\n",
      "500 steps | score: [-0.15985941886901855, 0.17918811738491058]\n",
      "600 steps | score: [-0.00445278687402606, 0.0041219755075871944]\n",
      "0 steps | score: [0.1702503114938736, 0.0077931880950927734]\n",
      "100 steps | score: [0.06176389008760452, -0.01870114728808403]\n",
      "200 steps | score: [-0.01200941577553749, 0.021242396906018257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 steps | score: [-0.06639350205659866, 0.09904571622610092]\n",
      "400 steps | score: [-0.025038819760084152, 0.04927723482251167]\n",
      "500 steps | score: [-0.09764853119850159, 0.11833970248699188]\n",
      "600 steps | score: [0.03224571794271469, -0.03876370191574097]\n",
      "700 steps | score: [0.34592828154563904, -0.6241486072540283]\n",
      "800 steps | score: [0.02003379724919796, -0.05067029595375061]\n",
      "900 steps | score: [-0.01884455606341362, 0.022021666169166565]\n",
      "1000 steps | score: [0.05120355263352394, -0.08766764402389526]\n",
      "1100 steps | score: [-0.041974931955337524, 0.04762786999344826]\n",
      "1200 steps | score: [-0.015346847474575043, 0.014051975682377815]\n",
      "1300 steps | score: [0.04474949091672897, -0.08669570088386536]\n",
      "1400 steps | score: [0.005391543265432119, -0.007071522530168295]\n",
      "unknown params:  tensor([-0.4940, -0.8855])\n",
      "unknown variance:  tensor([[1.1012]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4319, -0.5835])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.32654687762260437]\n",
      "100 steps | score: [0.05166657641530037]\n",
      "200 steps | score: [0.10401657968759537]\n",
      "300 steps | score: [0.09444382041692734]\n",
      "400 steps | score: [0.16176585853099823]\n",
      "500 steps | score: [0.09072712808847427]\n",
      "600 steps | score: [0.1075693666934967]\n",
      "700 steps | score: [0.16886836290359497]\n",
      "800 steps | score: [0.13414449989795685]\n",
      "900 steps | score: [0.17695052921772003]\n",
      "1000 steps | score: [0.13424032926559448]\n",
      "1100 steps | score: [0.11427822709083557]\n",
      "1200 steps | score: [0.1355515718460083]\n",
      "1300 steps | score: [0.12394951283931732]\n",
      "1400 steps | score: [0.1540623903274536]\n",
      "1500 steps | score: [0.11407455056905746]\n",
      "1600 steps | score: [0.1569967120885849]\n",
      "1700 steps | score: [0.13073715567588806]\n",
      "1800 steps | score: [0.09283390641212463]\n",
      "1900 steps | score: [0.1567949503660202]\n",
      "2000 steps | score: [0.1285630464553833]\n",
      "2100 steps | score: [0.14382100105285645]\n",
      "2200 steps | score: [0.1531684398651123]\n",
      "2300 steps | score: [0.1354731321334839]\n",
      "2400 steps | score: [0.14008471369743347]\n",
      "2500 steps | score: [0.11456378549337387]\n",
      "2600 steps | score: [0.15081951022148132]\n",
      "0 steps | score: [0.22440160810947418, -0.048913128674030304]\n",
      "100 steps | score: [-0.02607077732682228, 0.1630413681268692]\n",
      "200 steps | score: [-0.07397367060184479, 0.17988333106040955]\n",
      "300 steps | score: [-0.0063247038051486015, 0.08985825628042221]\n",
      "400 steps | score: [0.08313038945198059, -0.11300899088382721]\n",
      "500 steps | score: [0.0464719794690609, -0.028753211721777916]\n",
      "600 steps | score: [0.013694770634174347, 0.02882855385541916]\n",
      "700 steps | score: [0.19233255088329315, -0.2948875427246094]\n",
      "800 steps | score: [0.058633457869291306, -0.047908104956150055]\n",
      "900 steps | score: [0.02731918916106224, -0.003300219774246216]\n",
      "1000 steps | score: [0.09418679028749466, -0.1013694629073143]\n",
      "1100 steps | score: [0.028871621936559677, 0.0026566796004772186]\n",
      "1200 steps | score: [0.04259469360113144, -0.03542410954833031]\n",
      "1300 steps | score: [0.021476173773407936, 0.020932938903570175]\n",
      "1400 steps | score: [0.10433126986026764, -0.13372619450092316]\n",
      "1500 steps | score: [-0.007100687827914953, 0.06629166007041931]\n",
      "1600 steps | score: [0.1572742611169815, -0.22662557661533356]\n",
      "1700 steps | score: [-0.014414149336516857, 0.0624605193734169]\n",
      "1800 steps | score: [0.02529919147491455, 0.010350272059440613]\n",
      "1900 steps | score: [0.053817056119441986, -0.03981743007898331]\n",
      "2000 steps | score: [0.013355259783565998, 0.027224592864513397]\n",
      "2100 steps | score: [0.11196133494377136, -0.14128278195858002]\n",
      "2200 steps | score: [0.04529610276222229, -0.031123409047722816]\n",
      "2300 steps | score: [0.07169920206069946, -0.0777210220694542]\n",
      "2400 steps | score: [0.08234131336212158, -0.10177087783813477]\n",
      "2500 steps | score: [0.011008913628757, 0.028073377907276154]\n",
      "2600 steps | score: [0.06440108269453049, -0.07194468379020691]\n",
      "0 steps | score: [0.14331750571727753, 0.0585118904709816]\n",
      "100 steps | score: [-0.09868025034666061, 0.2567294239997864]\n",
      "200 steps | score: [-0.13202479481697083, 0.2514975666999817]\n",
      "300 steps | score: [-0.08856614679098129, 0.19552549719810486]\n",
      "400 steps | score: [0.04614504799246788, -0.06913226842880249]\n",
      "500 steps | score: [-0.02083345130085945, 0.0645599365234375]\n",
      "600 steps | score: [-0.05863861367106438, 0.123544842004776]\n",
      "700 steps | score: [0.09035608172416687, -0.14301368594169617]\n",
      "800 steps | score: [0.010768529027700424, 0.031016509979963303]\n",
      "900 steps | score: [-0.023232800886034966, 0.0659453347325325]\n",
      "1000 steps | score: [0.03489262983202934, -0.03442579507827759]\n",
      "1100 steps | score: [-0.057379983365535736, 0.11524146050214767]\n",
      "1200 steps | score: [-0.02600138448178768, 0.05980265140533447]\n",
      "1300 steps | score: [-0.058103807270526886, 0.12177455425262451]\n",
      "1400 steps | score: [0.020667629316449165, -0.023434385657310486]\n",
      "1500 steps | score: [-0.08101484924554825, 0.1551336944103241]\n",
      "1600 steps | score: [0.07088902592658997, -0.10187619924545288]\n",
      "1700 steps | score: [-0.06897776573896408, 0.1276746690273285]\n",
      "1800 steps | score: [-0.04677267000079155, 0.09860455989837646]\n",
      "1900 steps | score: [-0.026140302419662476, 0.061437688767910004]\n",
      "2000 steps | score: [-0.04925196245312691, 0.10152848064899445]\n",
      "2100 steps | score: [0.033103059977293015, -0.045700911432504654]\n",
      "2200 steps | score: [-0.01252215076237917, 0.04023236036300659]\n",
      "2300 steps | score: [0.01929471455514431, -0.006557811051607132]\n",
      "2400 steps | score: [0.016772128641605377, 0.0003247261047363281]\n",
      "2500 steps | score: [-0.05710311979055405, 0.1192234605550766]\n",
      "2600 steps | score: [-0.0021255547180771828, 0.028136957436800003]\n",
      "0 steps | score: [0.1562298983335495, 0.0935131087899208]\n",
      "100 steps | score: [-0.06835854053497314, 0.2678864896297455]\n",
      "200 steps | score: [-0.12527146935462952, 0.2943342626094818]\n",
      "300 steps | score: [-0.0571569949388504, 0.19349688291549683]\n",
      "400 steps | score: [0.07710946351289749, -0.0757608413696289]\n",
      "500 steps | score: [-0.01943986490368843, 0.1073748990893364]\n",
      "600 steps | score: [-0.05309911072254181, 0.17001177370548248]\n",
      "700 steps | score: [0.11570503562688828, -0.13045795261859894]\n",
      "800 steps | score: [0.02464008331298828, 0.05630309134721756]\n",
      "900 steps | score: [-0.03586016595363617, 0.12157446146011353]\n",
      "1000 steps | score: [0.021629998460412025, 0.036042794585227966]\n",
      "1100 steps | score: [-0.05129317194223404, 0.1508011519908905]\n",
      "1200 steps | score: [-0.015631258487701416, 0.09190784394741058]\n",
      "1300 steps | score: [-0.05369042232632637, 0.16012530028820038]\n",
      "1400 steps | score: [0.023954564705491066, 0.013442776165902615]\n",
      "1500 steps | score: [-0.05964117497205734, 0.17207731306552887]\n",
      "1600 steps | score: [0.08061492443084717, -0.05685648322105408]\n",
      "1700 steps | score: [-0.06791193783283234, 0.17305730283260345]\n",
      "1800 steps | score: [-0.045425672084093094, 0.14626890420913696]\n",
      "1900 steps | score: [-0.01648818887770176, 0.09386499226093292]\n",
      "2000 steps | score: [-0.043894339352846146, 0.14585836231708527]\n",
      "2100 steps | score: [0.04755677282810211, -0.016683146357536316]\n",
      "2200 steps | score: [-0.007523490581661463, 0.08173327893018723]\n",
      "2300 steps | score: [-0.002976977964863181, 0.05537695065140724]\n",
      "2400 steps | score: [0.01233644224703312, 0.0437629371881485]\n",
      "2500 steps | score: [-0.046966828405857086, 0.1423777937889099]\n",
      "2600 steps | score: [-0.0015730896266177297, 0.06450486928224564]\n",
      "unknown params:  tensor([-0.5437, -1.1482])\n",
      "unknown variance:  tensor([[1.3069]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4319, -0.5835])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2972241938114166]\n",
      "100 steps | score: [0.07110211998224258]\n",
      "200 steps | score: [0.11310918629169464]\n",
      "300 steps | score: [0.011443044058978558]\n",
      "400 steps | score: [0.0731218010187149]\n",
      "500 steps | score: [0.006496112793684006]\n",
      "0 steps | score: [0.2532999813556671, -0.21281352639198303]\n",
      "100 steps | score: [0.18939703702926636, -0.22612163424491882]\n",
      "200 steps | score: [0.15410968661308289, -0.24272984266281128]\n",
      "300 steps | score: [0.0030544328037649393, -0.0028154123574495316]\n",
      "0 steps | score: [0.14226235449314117, 0.04753338545560837]\n",
      "100 steps | score: [0.13344517350196838, -0.06909511238336563]\n",
      "200 steps | score: [0.10569379478693008, -0.09456229209899902]\n",
      "300 steps | score: [-0.08309432119131088, 0.21136072278022766]\n",
      "400 steps | score: [0.018531695008277893, 0.029609454795718193]\n",
      "500 steps | score: [-0.07850310951471329, 0.19238783419132233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 steps | score: [-0.027581248432397842, 0.09084033966064453]\n",
      "700 steps | score: [-0.06867330521345139, 0.17799462378025055]\n",
      "800 steps | score: [0.11393044143915176, -0.18075068295001984]\n",
      "900 steps | score: [-0.06409747153520584, 0.1658330112695694]\n",
      "1000 steps | score: [0.02096722088754177, -0.009151659905910492]\n",
      "1100 steps | score: [-0.07759113609790802, 0.19039388000965118]\n",
      "1200 steps | score: [0.11011718958616257, -0.1732873022556305]\n",
      "1300 steps | score: [-0.048616088926792145, 0.1372506320476532]\n",
      "1400 steps | score: [-0.010956046171486378, 0.05989310145378113]\n",
      "1500 steps | score: [-0.1110031008720398, 0.23565717041492462]\n",
      "1600 steps | score: [0.047031376510858536, -0.05011942982673645]\n",
      "1700 steps | score: [-0.0517609529197216, 0.129909485578537]\n",
      "1800 steps | score: [-0.05608860403299332, 0.1445281207561493]\n",
      "1900 steps | score: [0.011232905089855194, 0.012630976736545563]\n",
      "2000 steps | score: [-0.09348977357149124, 0.2024742215871811]\n",
      "2100 steps | score: [-0.050458360463380814, 0.12511520087718964]\n",
      "2200 steps | score: [-0.07754366844892502, 0.17314787209033966]\n",
      "2300 steps | score: [0.023369550704956055, -0.009569594636559486]\n",
      "2400 steps | score: [-0.07255933433771133, 0.16942133009433746]\n",
      "2500 steps | score: [-0.005542318802326918, 0.05651894211769104]\n",
      "0 steps | score: [0.09088966995477676, 0.12073840200901031]\n",
      "100 steps | score: [0.09725861251354218, -0.01779746264219284]\n",
      "200 steps | score: [0.08057547360658646, -0.07445290684700012]\n",
      "300 steps | score: [-0.10801137238740921, 0.24199731647968292]\n",
      "400 steps | score: [-0.03476732224225998, 0.09811174869537354]\n",
      "500 steps | score: [-0.12682116031646729, 0.27047795057296753]\n",
      "600 steps | score: [-0.02870970591902733, 0.07620323449373245]\n",
      "700 steps | score: [-0.10723955184221268, 0.23153597116470337]\n",
      "800 steps | score: [0.08528417348861694, -0.15930971503257751]\n",
      "900 steps | score: [-0.11387608200311661, 0.24589413404464722]\n",
      "1000 steps | score: [-0.010636634193360806, 0.03454005718231201]\n",
      "1100 steps | score: [-0.10591591894626617, 0.2261112779378891]\n",
      "1200 steps | score: [0.07145092636346817, -0.1385565847158432]\n",
      "1300 steps | score: [-0.0816911906003952, 0.17927443981170654]\n",
      "1400 steps | score: [-0.04153208062052727, 0.09517136216163635]\n",
      "1500 steps | score: [-0.15080808103084564, 0.30088216066360474]\n",
      "1600 steps | score: [0.02550218626856804, -0.023635268211364746]\n",
      "1700 steps | score: [-0.035171691328287125, 0.08714142441749573]\n",
      "1800 steps | score: [-0.08355864882469177, 0.18219876289367676]\n",
      "1900 steps | score: [-0.0038585683796554804, 0.035911817103624344]\n",
      "2000 steps | score: [-0.11380810290575027, 0.2289731502532959]\n",
      "2100 steps | score: [-0.06822854280471802, 0.14144115149974823]\n",
      "2200 steps | score: [-0.11140719056129456, 0.22340553998947144]\n",
      "2300 steps | score: [-0.013879982754588127, 0.04190228879451752]\n",
      "2400 steps | score: [-0.09425967931747437, 0.19377025961875916]\n",
      "2500 steps | score: [-0.026422059163451195, 0.07395647466182709]\n",
      "unknown params:  tensor([-0.4062, -0.8621])\n",
      "unknown variance:  tensor([[1.2353]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4319, -0.5835])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3210887908935547]\n",
      "100 steps | score: [0.06710808724164963]\n",
      "200 steps | score: [0.05713595449924469]\n",
      "300 steps | score: [0.08694402873516083]\n",
      "400 steps | score: [0.03895898908376694]\n",
      "500 steps | score: [0.034773923456668854]\n",
      "600 steps | score: [0.011548787355422974]\n",
      "700 steps | score: [0.0440678596496582]\n",
      "800 steps | score: [-0.017365526407957077]\n",
      "900 steps | score: [0.04394230246543884]\n",
      "1000 steps | score: [-0.006711006164550781]\n",
      "0 steps | score: [0.17283231019973755, -0.11913683265447617]\n",
      "100 steps | score: [0.18715548515319824, -0.2437654286623001]\n",
      "200 steps | score: [0.03548157215118408, 0.0020949579775333405]\n",
      "300 steps | score: [0.06558484584093094, -0.11571943759918213]\n",
      "400 steps | score: [0.041186943650245667, -0.059153962880373]\n",
      "500 steps | score: [-0.06379329413175583, 0.11407685279846191]\n",
      "600 steps | score: [-0.14567720890045166, 0.28541022539138794]\n",
      "700 steps | score: [0.10932998359203339, -0.23326769471168518]\n",
      "800 steps | score: [-0.14933595061302185, 0.2957051992416382]\n",
      "900 steps | score: [0.08594480156898499, -0.19858203828334808]\n",
      "1000 steps | score: [-0.030433766543865204, 0.052863799035549164]\n",
      "1100 steps | score: [0.13687686622142792, -0.29216670989990234]\n",
      "1200 steps | score: [0.12811432778835297, -0.2800115644931793]\n",
      "1300 steps | score: [-0.06072394177317619, 0.11694774776697159]\n",
      "1400 steps | score: [0.06597737967967987, -0.15422594547271729]\n",
      "1500 steps | score: [-0.05811353400349617, 0.10518686473369598]\n",
      "1600 steps | score: [0.08748871088027954, -0.2072868049144745]\n",
      "1700 steps | score: [-0.10985606163740158, 0.20276577770709991]\n",
      "1800 steps | score: [0.008164769969880581, -0.04010646417737007]\n",
      "1900 steps | score: [-0.05928480625152588, 0.10747852921485901]\n",
      "2000 steps | score: [0.007633029017597437, -0.040695928037166595]\n",
      "2100 steps | score: [-0.05525859072804451, 0.09725373983383179]\n",
      "2200 steps | score: [0.04079343006014824, -0.09845075011253357]\n",
      "2300 steps | score: [-0.015907378867268562, 0.01963520050048828]\n",
      "2400 steps | score: [0.003024450968950987, -0.020491179078817368]\n",
      "2500 steps | score: [0.008108873851597309, -0.036374788731336594]\n",
      "unknown params:  tensor([-0.4121, -0.8460])\n",
      "unknown variance:  tensor([[1.4047]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/60802f43-4eda-42cc-9d5f-7461b8e05c29\n",
      "gt params:  tensor([-0.4302, -0.5904])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.09623292088508606]\n",
      "100 steps | score: [-0.11772039532661438]\n",
      "200 steps | score: [0.09597305208444595]\n",
      "300 steps | score: [-0.0361945778131485]\n",
      "400 steps | score: [-0.05114582180976868]\n",
      "500 steps | score: [-0.06953446567058563]\n",
      "600 steps | score: [-0.007533274590969086]\n",
      "0 steps | score: [0.06860090047121048, -0.006050121039152145]\n",
      "100 steps | score: [-0.02053752914071083, -0.025782467797398567]\n",
      "200 steps | score: [0.08564106374979019, -0.05854668840765953]\n",
      "300 steps | score: [-0.004245026968419552, -0.017209215089678764]\n",
      "400 steps | score: [0.014283510856330395, -0.06569141894578934]\n",
      "500 steps | score: [0.007840657606720924, -0.12835314869880676]\n",
      "600 steps | score: [0.059581078588962555, -0.01155816949903965]\n",
      "700 steps | score: [0.047835275530815125, -0.04735496640205383]\n",
      "800 steps | score: [0.015225822106003761, -0.022540424019098282]\n",
      "900 steps | score: [0.05476734787225723, -0.0937960296869278]\n",
      "1000 steps | score: [0.012080775573849678, -0.033708177506923676]\n",
      "1100 steps | score: [0.05723337084054947, -0.037885669618844986]\n",
      "1200 steps | score: [0.021055152639746666, -0.03573543578386307]\n",
      "1300 steps | score: [-0.014549920335412025, -0.045644279569387436]\n",
      "1400 steps | score: [0.018363697454333305, -0.09493362903594971]\n",
      "1500 steps | score: [0.061222609132528305, -0.04213165119290352]\n",
      "1600 steps | score: [0.03349524736404419, -0.04523436725139618]\n",
      "1700 steps | score: [0.021962257102131844, -0.020831353962421417]\n",
      "1800 steps | score: [0.03066379763185978, -0.06312207877635956]\n",
      "1900 steps | score: [0.019395822659134865, -0.05254404991865158]\n",
      "2000 steps | score: [0.04235129430890083, -0.045673519372940063]\n",
      "2100 steps | score: [0.03258999437093735, -0.037016138434410095]\n",
      "2200 steps | score: [0.007427835837006569, -0.03806782513856888]\n",
      "2300 steps | score: [0.02738768979907036, -0.06034550815820694]\n",
      "2400 steps | score: [0.04400665685534477, -0.061923664063215256]\n",
      "2500 steps | score: [0.028416581451892853, -0.051943711936473846]\n",
      "2600 steps | score: [0.02346782013773918, -0.038975950330495834]\n",
      "unknown params:  tensor([-0.3907, -0.4797])\n",
      "unknown variance:  tensor([[0.8808]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4302, -0.5904])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.35245001316070557]\n",
      "100 steps | score: [0.18720212578773499]\n",
      "200 steps | score: [0.22507330775260925]\n",
      "300 steps | score: [0.25343936681747437]\n",
      "400 steps | score: [0.25972089171409607]\n",
      "500 steps | score: [0.16152648627758026]\n",
      "600 steps | score: [0.2462388128042221]\n",
      "700 steps | score: [0.22730892896652222]\n",
      "800 steps | score: [0.25455793738365173]\n",
      "900 steps | score: [0.1772558093070984]\n",
      "1000 steps | score: [0.28408461809158325]\n",
      "1100 steps | score: [0.24965398013591766]\n",
      "1200 steps | score: [0.21612362563610077]\n",
      "1300 steps | score: [0.2586190700531006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 steps | score: [0.3277546763420105]\n",
      "1500 steps | score: [0.2553238868713379]\n",
      "1600 steps | score: [0.19675084948539734]\n",
      "1700 steps | score: [0.25681790709495544]\n",
      "1800 steps | score: [0.2976582944393158]\n",
      "1900 steps | score: [0.24463418126106262]\n",
      "2000 steps | score: [0.19993223249912262]\n",
      "2100 steps | score: [0.25072771310806274]\n",
      "2200 steps | score: [0.282072514295578]\n",
      "2300 steps | score: [0.25290611386299133]\n",
      "2400 steps | score: [0.23537373542785645]\n",
      "2500 steps | score: [0.2795352637767792]\n",
      "2600 steps | score: [0.28804999589920044]\n",
      "2700 steps | score: [0.27304351329803467]\n",
      "2800 steps | score: [0.22393128275871277]\n",
      "0 steps | score: [0.04148073121905327, 0.11340247839689255]\n",
      "100 steps | score: [-0.06905005127191544, 0.08057348430156708]\n",
      "200 steps | score: [-0.009155676700174809, 0.039906665682792664]\n",
      "300 steps | score: [-0.02492695488035679, 0.06588893383741379]\n",
      "400 steps | score: [-0.019971096888184547, 0.012091415002942085]\n",
      "500 steps | score: [-0.048880573362112045, 0.04072634503245354]\n",
      "600 steps | score: [-0.00812674593180418, 0.05153911933302879]\n",
      "700 steps | score: [-0.028673555701971054, 0.045865900814533234]\n",
      "800 steps | score: [-0.006390641909092665, -0.012441728264093399]\n",
      "900 steps | score: [-0.05709009990096092, 0.038268834352493286]\n",
      "1000 steps | score: [0.017882218584418297, 0.0300971120595932]\n",
      "1100 steps | score: [-0.025828346610069275, 0.052669085562229156]\n",
      "1200 steps | score: [-0.03905873745679855, 0.02378796599805355]\n",
      "1300 steps | score: [-0.023467404767870903, 0.01203968282788992]\n",
      "1400 steps | score: [0.023461278527975082, 0.018102338537573814]\n",
      "1500 steps | score: [-0.014110680669546127, 0.04421757534146309]\n",
      "1600 steps | score: [-0.05042966827750206, 0.03794243559241295]\n",
      "1700 steps | score: [-0.01244740653783083, 0.0003918199799954891]\n",
      "1800 steps | score: [0.017658904194831848, 0.0033396133221685886]\n",
      "1900 steps | score: [-0.018437979742884636, 0.038101810961961746]\n",
      "2000 steps | score: [-0.03800618276000023, 0.03237422555685043]\n",
      "2100 steps | score: [-0.006765767931938171, 0.004371304530650377]\n",
      "0 steps | score: [0.0882435142993927, 0.047313060611486435]\n",
      "100 steps | score: [-0.03140808641910553, 0.025399070233106613]\n",
      "200 steps | score: [0.02925204485654831, -0.013472246006131172]\n",
      "300 steps | score: [0.004837850574404001, 0.01756182312965393]\n",
      "400 steps | score: [0.017898106947541237, -0.04023116081953049]\n",
      "500 steps | score: [-0.015740256756544113, -0.004141716752201319]\n",
      "600 steps | score: [0.0276162251830101, 0.010966277681291103]\n",
      "700 steps | score: [0.0018990437965840101, 0.0008177394047379494]\n",
      "0 steps | score: [0.05821123346686363, 0.13590218126773834]\n",
      "100 steps | score: [-0.05847099795937538, 0.09696824103593826]\n",
      "200 steps | score: [0.008260298520326614, 0.0581531748175621]\n",
      "300 steps | score: [-0.007611478213220835, 0.08817421644926071]\n",
      "400 steps | score: [-0.007903922349214554, 0.03309471160173416]\n",
      "500 steps | score: [-0.05019449442625046, 0.0708446130156517]\n",
      "600 steps | score: [0.008192268200218678, 0.07379092276096344]\n",
      "700 steps | score: [-0.01728755235671997, 0.06479854136705399]\n",
      "800 steps | score: [0.0026873562019318342, 0.012007058598101139]\n",
      "900 steps | score: [-0.04314422607421875, 0.06112294644117355]\n",
      "1000 steps | score: [0.03505929559469223, 0.061707377433776855]\n",
      "1100 steps | score: [-0.004497047979384661, 0.07213003933429718]\n",
      "1200 steps | score: [-0.02239605225622654, 0.03761538490653038]\n",
      "1300 steps | score: [-0.003954635467380285, 0.03249872475862503]\n",
      "1400 steps | score: [0.0437178760766983, 0.03791826590895653]\n",
      "1500 steps | score: [-0.008176479488611221, 0.06435254216194153]\n",
      "1600 steps | score: [-0.03501598536968231, 0.05661477893590927]\n",
      "1700 steps | score: [0.005404504016041756, 0.02535068616271019]\n",
      "1800 steps | score: [0.031847141683101654, 0.029598385095596313]\n",
      "1900 steps | score: [-0.005346544552594423, 0.06217823177576065]\n",
      "2000 steps | score: [-0.01753988303244114, 0.05006173253059387]\n",
      "2100 steps | score: [0.0028509912081062794, 0.02966216392815113]\n",
      "2200 steps | score: [0.022124694660305977, 0.0358615480363369]\n",
      "2300 steps | score: [0.006531755905598402, 0.04982823505997658]\n",
      "2400 steps | score: [-0.015863772481679916, 0.05116771534085274]\n",
      "2500 steps | score: [0.002902788342908025, 0.030025281012058258]\n",
      "2600 steps | score: [0.021627886220812798, 0.036186352372169495]\n",
      "2700 steps | score: [0.006944458466023207, 0.04722191393375397]\n",
      "2800 steps | score: [-0.005029939580708742, 0.045080721378326416]\n",
      "unknown params:  tensor([-0.4143, -0.4995])\n",
      "unknown variance:  tensor([[0.9670]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4302, -0.5904])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [-0.26205530762672424]\n",
      "100 steps | score: [-0.4189828932285309]\n",
      "200 steps | score: [-0.42245379090309143]\n",
      "300 steps | score: [-0.3865746259689331]\n",
      "400 steps | score: [-0.34138864278793335]\n",
      "500 steps | score: [-0.3491363823413849]\n",
      "600 steps | score: [-0.4055755138397217]\n",
      "700 steps | score: [-0.41846784949302673]\n",
      "800 steps | score: [-0.4119417667388916]\n",
      "900 steps | score: [-0.3568876087665558]\n",
      "1000 steps | score: [-0.4455872178077698]\n",
      "1100 steps | score: [-0.4391275942325592]\n",
      "1200 steps | score: [-0.3771650493144989]\n",
      "1300 steps | score: [-0.36564868688583374]\n",
      "1400 steps | score: [-0.4434714913368225]\n",
      "1500 steps | score: [-0.44221848249435425]\n",
      "1600 steps | score: [-0.450169175863266]\n",
      "1700 steps | score: [-0.4178483486175537]\n",
      "1800 steps | score: [-0.43171530961990356]\n",
      "1900 steps | score: [-0.38972264528274536]\n",
      "2000 steps | score: [-0.4089425802230835]\n",
      "2100 steps | score: [-0.37828007340431213]\n",
      "2200 steps | score: [-0.4159882962703705]\n",
      "2300 steps | score: [-0.4332214593887329]\n",
      "2400 steps | score: [-0.3865847885608673]\n",
      "2500 steps | score: [-0.43270042538642883]\n",
      "2600 steps | score: [-0.4419545531272888]\n",
      "0 steps | score: [0.09325718134641647, 0.04632687568664551]\n",
      "100 steps | score: [-0.025702904909849167, 0.022415176033973694]\n",
      "200 steps | score: [-0.034733016043901443, 5.2094459533691406e-05]\n",
      "300 steps | score: [0.018506811931729317, -0.021716158837080002]\n",
      "400 steps | score: [0.059375014156103134, -0.11100184917449951]\n",
      "500 steps | score: [0.056143730878829956, -0.05840349942445755]\n",
      "600 steps | score: [-0.004064637701958418, -0.018258854746818542]\n",
      "700 steps | score: [0.012956498190760612, -0.03806351125240326]\n",
      "800 steps | score: [0.021155336871743202, -0.09509165585041046]\n",
      "900 steps | score: [0.08052877336740494, -0.08851083368062973]\n",
      "1000 steps | score: [-0.028309153392910957, -0.00021048728376626968]\n",
      "1100 steps | score: [-0.014180863276124, -0.023225562646985054]\n",
      "1200 steps | score: [0.03596300631761551, -0.08443772792816162]\n",
      "1300 steps | score: [0.059372998774051666, -0.06566988676786423]\n",
      "1400 steps | score: [-0.012266497127711773, -0.01308787427842617]\n",
      "1500 steps | score: [-0.023526253178715706, -0.014784082770347595]\n",
      "1600 steps | score: [0.004880296066403389, -0.049794819205999374]\n",
      "1700 steps | score: [0.025043612346053123, -0.050820525735616684]\n",
      "1800 steps | score: [-0.00421060249209404, -0.017533261328935623]\n",
      "1900 steps | score: [0.025508658960461617, -0.059209343045949936]\n",
      "2000 steps | score: [0.012735368683934212, -0.04525664076209068]\n",
      "2100 steps | score: [0.03353384882211685, -0.05814553424715996]\n",
      "2200 steps | score: [-0.007384513504803181, -0.01682799495756626]\n",
      "2300 steps | score: [0.03126050904393196, -0.056786905974149704]\n",
      "2400 steps | score: [0.018108747899532318, -0.04802330955862999]\n",
      "2500 steps | score: [0.01831064000725746, -0.04264708235859871]\n",
      "2600 steps | score: [0.0068946159444749355, -0.03205140680074692]\n",
      "0 steps | score: [0.05219143256545067, 0.0661604180932045]\n",
      "100 steps | score: [-0.05552029609680176, 0.037500057369470596]\n",
      "200 steps | score: [-0.05919291824102402, 0.017860863357782364]\n",
      "300 steps | score: [-0.0095807034522295, -0.002323383465409279]\n",
      "0 steps | score: [0.03756879270076752, 0.10264475643634796]\n",
      "100 steps | score: [-0.06383160501718521, 0.07269155234098434]\n",
      "200 steps | score: [-0.07858861982822418, 0.05143396928906441]\n",
      "300 steps | score: [-0.009527679532766342, 0.02011580392718315]\n",
      "400 steps | score: [0.028863200917840004, -0.06724207103252411]\n",
      "500 steps | score: [0.023119166493415833, -0.022237339988350868]\n",
      "600 steps | score: [-0.026730824261903763, 0.022477339953184128]\n",
      "700 steps | score: [-0.024881521239876747, 0.002890386153012514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 steps | score: [-0.019369708374142647, -0.047810669988393784]\n",
      "900 steps | score: [0.03749963268637657, -0.03169121593236923]\n",
      "1000 steps | score: [-0.07409954816102982, 0.05115345120429993]\n",
      "1100 steps | score: [-0.057488735765218735, 0.028043895959854126]\n",
      "1200 steps | score: [0.0039079682901501656, -0.03881886973977089]\n",
      "1300 steps | score: [0.016580253839492798, -0.019841859117150307]\n",
      "1400 steps | score: [-0.05454538017511368, 0.038903817534446716]\n",
      "1500 steps | score: [-0.06419108808040619, 0.031590983271598816]\n",
      "1600 steps | score: [-0.049379751086235046, 0.009258550591766834]\n",
      "1700 steps | score: [-0.01212642714381218, -0.002508364850655198]\n",
      "1800 steps | score: [-0.03867862746119499, 0.025120848789811134]\n",
      "1900 steps | score: [-0.007390779908746481, -0.021146509796380997]\n",
      "2000 steps | score: [-0.03685417026281357, 0.007734963670372963]\n",
      "2100 steps | score: [-0.006523124407976866, -0.013866808265447617]\n",
      "2200 steps | score: [-0.04629260301589966, 0.029734227806329727]\n",
      "2300 steps | score: [-0.012478345073759556, -0.010309280827641487]\n",
      "2400 steps | score: [-0.022614609450101852, 0.00044155679643154144]\n",
      "2500 steps | score: [-0.02767178602516651, 0.0023511145263910294]\n",
      "2600 steps | score: [-0.046202316880226135, 0.01560928300023079]\n",
      "unknown params:  tensor([-0.4061, -0.5224])\n",
      "unknown variance:  tensor([[0.9607]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4302, -0.5904])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3207261860370636]\n",
      "100 steps | score: [0.20204530656337738]\n",
      "200 steps | score: [0.11930829286575317]\n",
      "300 steps | score: [0.10120614618062973]\n",
      "400 steps | score: [0.09664061665534973]\n",
      "500 steps | score: [0.14194457232952118]\n",
      "600 steps | score: [0.05801873281598091]\n",
      "700 steps | score: [0.13975459337234497]\n",
      "800 steps | score: [0.060485921800136566]\n",
      "900 steps | score: [0.09116321057081223]\n",
      "1000 steps | score: [0.10573310405015945]\n",
      "1100 steps | score: [0.1075340211391449]\n",
      "1200 steps | score: [0.15091902017593384]\n",
      "1300 steps | score: [0.12214823067188263]\n",
      "1400 steps | score: [0.08868280053138733]\n",
      "1500 steps | score: [0.07698174566030502]\n",
      "1600 steps | score: [0.11039605736732483]\n",
      "1700 steps | score: [0.0884646326303482]\n",
      "1800 steps | score: [0.10707007348537445]\n",
      "1900 steps | score: [0.13566744327545166]\n",
      "2000 steps | score: [0.06747852265834808]\n",
      "2100 steps | score: [0.1005023792386055]\n",
      "2200 steps | score: [0.08875810354948044]\n",
      "2300 steps | score: [0.11993512511253357]\n",
      "2400 steps | score: [0.12353601306676865]\n",
      "2500 steps | score: [0.123109832406044]\n",
      "2600 steps | score: [0.08859983086585999]\n",
      "2700 steps | score: [0.10341975092887878]\n",
      "2800 steps | score: [0.10220396518707275]\n",
      "0 steps | score: [0.09991014748811722, 0.06884751468896866]\n",
      "100 steps | score: [0.08267486095428467, -0.07653927803039551]\n",
      "200 steps | score: [0.012397754937410355, -0.05232024937868118]\n",
      "300 steps | score: [0.0032744535710662603, -0.04331814497709274]\n",
      "400 steps | score: [-0.014985489659011364, -0.04294193908572197]\n",
      "500 steps | score: [0.02748190052807331, -0.03963221609592438]\n",
      "600 steps | score: [-0.024611638858914375, -0.008988483808934689]\n",
      "700 steps | score: [0.05955134332180023, -0.06597360968589783]\n",
      "800 steps | score: [-0.051873061805963516, 0.029220104217529297]\n",
      "900 steps | score: [0.005028884392231703, -0.02201865240931511]\n",
      "1000 steps | score: [-0.023242009803652763, 0.005202556028962135]\n",
      "1100 steps | score: [0.029874777421355247, -0.07773487269878387]\n",
      "1200 steps | score: [0.047832269221544266, -0.062643863260746]\n",
      "1300 steps | score: [0.0004116264753974974, -0.02857145294547081]\n",
      "1400 steps | score: [-0.03361176699399948, 0.017439674586057663]\n",
      "1500 steps | score: [-0.0296578761190176, 0.004996167495846748]\n",
      "1600 steps | score: [-0.006581184454262257, -0.011149002239108086]\n",
      "1700 steps | score: [-0.028542984277009964, 0.012453196570277214]\n",
      "1800 steps | score: [0.03977423906326294, -0.07063467800617218]\n",
      "1900 steps | score: [0.016763119027018547, -0.04331851750612259]\n",
      "2000 steps | score: [-0.01575176604092121, -0.006368462927639484]\n",
      "2100 steps | score: [-0.019692469388246536, 0.002850353717803955]\n",
      "2200 steps | score: [0.004584659356623888, -0.029225632548332214]\n",
      "2300 steps | score: [0.01718992181122303, -0.03503035753965378]\n",
      "2400 steps | score: [-0.007259760517627001, -0.015911730006337166]\n",
      "2500 steps | score: [0.018409721553325653, -0.03342578560113907]\n",
      "2600 steps | score: [0.01233584899455309, -0.030542640015482903]\n",
      "2700 steps | score: [-0.005998747888952494, -0.016089152544736862]\n",
      "2800 steps | score: [-0.00817462895065546, -0.009945450350642204]\n",
      "0 steps | score: [0.11157483607530594, 0.0618976429104805]\n",
      "100 steps | score: [0.07549735903739929, -0.06263822317123413]\n",
      "200 steps | score: [0.0237117987126112, -0.06423240900039673]\n",
      "300 steps | score: [-0.007321707438677549, -0.05037657544016838]\n",
      "400 steps | score: [-0.012861013412475586, -0.0638924092054367]\n",
      "500 steps | score: [0.027685102075338364, -0.03814233839511871]\n",
      "600 steps | score: [-0.009913930669426918, -0.022724207490682602]\n",
      "700 steps | score: [0.061916783452034, -0.07211865484714508]\n",
      "800 steps | score: [-0.058512113988399506, 0.026310313493013382]\n",
      "900 steps | score: [0.015992889180779457, -0.039638545364141464]\n",
      "1000 steps | score: [-0.016601132228970528, -0.0012763217091560364]\n",
      "1100 steps | score: [0.03044603206217289, -0.083780437707901]\n",
      "1200 steps | score: [0.04823119938373566, -0.0652097836136818]\n",
      "1300 steps | score: [0.01205026637762785, -0.05057133361697197]\n",
      "1400 steps | score: [-0.03012758307158947, 0.010390004143118858]\n",
      "1500 steps | score: [-0.03084801323711872, -0.005637749098241329]\n",
      "1600 steps | score: [-0.005581018514931202, -0.01846330799162388]\n",
      "1700 steps | score: [-0.029639145359396935, 0.011546989902853966]\n",
      "1800 steps | score: [0.0450596883893013, -0.08222939819097519]\n",
      "1900 steps | score: [0.025850854814052582, -0.05198059231042862]\n",
      "2000 steps | score: [-0.01749134436249733, -0.010923991911113262]\n",
      "2100 steps | score: [-0.020031780004501343, -0.002765873447060585]\n",
      "2200 steps | score: [0.0038814155850559473, -0.03420526534318924]\n",
      "2300 steps | score: [0.01884797215461731, -0.047670040279626846]\n",
      "2400 steps | score: [0.0001808392844395712, -0.0307872723788023]\n",
      "2500 steps | score: [0.021336747333407402, -0.04843670874834061]\n",
      "2600 steps | score: [0.016472121700644493, -0.04329255223274231]\n",
      "2700 steps | score: [-0.0018891855143010616, -0.026894308626651764]\n",
      "2800 steps | score: [-0.00530348252505064, -0.023947015404701233]\n",
      "0 steps | score: [0.1386684775352478, 0.09013616293668747]\n",
      "100 steps | score: [0.09262827783823013, -0.036093659698963165]\n",
      "200 steps | score: [0.04113461822271347, -0.03346977382898331]\n",
      "300 steps | score: [0.047371141612529755, -0.0414181649684906]\n",
      "400 steps | score: [0.009988234378397465, -0.030155852437019348]\n",
      "500 steps | score: [0.0536419115960598, -0.012710139155387878]\n",
      "600 steps | score: [0.02060466632246971, 0.004754244349896908]\n",
      "700 steps | score: [0.08533535897731781, -0.04346531257033348]\n",
      "800 steps | score: [-0.025167271494865417, 0.05050460994243622]\n",
      "900 steps | score: [0.03157753869891167, -0.0042554717510938644]\n",
      "1000 steps | score: [0.017043154686689377, 0.015383756719529629]\n",
      "1100 steps | score: [0.05600886419415474, -0.04727733135223389]\n",
      "1200 steps | score: [0.06261122971773148, -0.028857965022325516]\n",
      "1300 steps | score: [0.029348602518439293, -0.022057820111513138]\n",
      "1400 steps | score: [-0.007838960736989975, 0.03893531858921051]\n",
      "1500 steps | score: [-0.005291163921356201, 0.021490376442670822]\n",
      "1600 steps | score: [0.028802216053009033, 0.009199502877891064]\n",
      "1700 steps | score: [-0.0021650786511600018, 0.03776866942644119]\n",
      "1800 steps | score: [0.07018091529607773, -0.05646997690200806]\n",
      "1900 steps | score: [0.05271834507584572, -0.021880794316530228]\n",
      "2000 steps | score: [0.011639414355158806, 0.01669718325138092]\n",
      "2100 steps | score: [0.0024941277224570513, 0.022533193230628967]\n",
      "2200 steps | score: [0.0242227204144001, -0.00710606575012207]\n",
      "2300 steps | score: [0.046609047800302505, -0.014673927798867226]\n",
      "2400 steps | score: [0.027312904596328735, 0.008098824881017208]\n",
      "2500 steps | score: [0.040835652500391006, -0.013089124113321304]\n",
      "2600 steps | score: [0.040514979511499405, -0.011608191765844822]\n",
      "2700 steps | score: [0.02296786569058895, 0.0004928279668092728]\n",
      "2800 steps | score: [0.017146926373243332, 0.00803859531879425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown params:  tensor([-0.4241, -0.5772])\n",
      "unknown variance:  tensor([[1.0031]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4302, -0.5904])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.1209200918674469]\n",
      "100 steps | score: [0.016733959317207336]\n",
      "200 steps | score: [-0.09585549682378769]\n",
      "300 steps | score: [-0.025605978444218636]\n",
      "400 steps | score: [-0.06555002927780151]\n",
      "500 steps | score: [-0.037929680198431015]\n",
      "600 steps | score: [-0.043779924511909485]\n",
      "700 steps | score: [0.002136274240911007]\n",
      "0 steps | score: [0.01149249728769064, 0.23845326900482178]\n",
      "100 steps | score: [0.001198005280457437, 0.08516206592321396]\n",
      "200 steps | score: [-0.18454767763614655, 0.22301289439201355]\n",
      "300 steps | score: [-0.1291874200105667, 0.20471617579460144]\n",
      "400 steps | score: [-0.17115408182144165, 0.21925869584083557]\n",
      "500 steps | score: [-0.1166742593050003, 0.18074776232242584]\n",
      "600 steps | score: [-0.10274876654148102, 0.15862363576889038]\n",
      "700 steps | score: [-0.007677855435758829, 0.016629831865429878]\n",
      "800 steps | score: [-0.003250684356316924, 0.04363805800676346]\n",
      "900 steps | score: [-0.11339255422353745, 0.16625186800956726]\n",
      "1000 steps | score: [-0.03333207964897156, 0.0724053680896759]\n",
      "1100 steps | score: [-0.05899515748023987, 0.1019754558801651]\n",
      "1200 steps | score: [-0.09077820926904678, 0.11834169179201126]\n",
      "1300 steps | score: [-0.07603397220373154, 0.13437440991401672]\n",
      "1400 steps | score: [-0.11265519261360168, 0.15654321014881134]\n",
      "1500 steps | score: [-0.083180733025074, 0.1256251484155655]\n",
      "1600 steps | score: [-0.09588944166898727, 0.15578173100948334]\n",
      "1700 steps | score: [-0.08222413063049316, 0.11814700067043304]\n",
      "1800 steps | score: [-0.051049843430519104, 0.0953010767698288]\n",
      "1900 steps | score: [-0.10912720113992691, 0.16502656042575836]\n",
      "2000 steps | score: [-0.06708502769470215, 0.10217635333538055]\n",
      "2100 steps | score: [-0.04372149333357811, 0.08549060672521591]\n",
      "2200 steps | score: [-0.09064023941755295, 0.13498106598854065]\n",
      "2300 steps | score: [-0.054272767156362534, 0.0969114601612091]\n",
      "2400 steps | score: [-0.07567813992500305, 0.12049540132284164]\n",
      "2500 steps | score: [-0.08390287309885025, 0.13095396757125854]\n",
      "2600 steps | score: [-0.08673787117004395, 0.14056263864040375]\n",
      "0 steps | score: [0.1682419627904892, 0.06216073036193848]\n",
      "100 steps | score: [0.08327091485261917, -0.027883220463991165]\n",
      "200 steps | score: [-0.04968119040131569, 0.06740723550319672]\n",
      "300 steps | score: [-0.010473661124706268, 0.06097175553441048]\n",
      "400 steps | score: [-0.050901103764772415, 0.07439359277486801]\n",
      "500 steps | score: [0.008989197202026844, 0.044213712215423584]\n",
      "600 steps | score: [0.009093389846384525, 0.030702177435159683]\n",
      "700 steps | score: [0.10430695861577988, -0.10932499915361404]\n",
      "800 steps | score: [0.1193811222910881, -0.0833725780248642]\n",
      "900 steps | score: [-0.006662805564701557, 0.040394484996795654]\n",
      "1000 steps | score: [0.08923427760601044, -0.06446178257465363]\n",
      "1100 steps | score: [0.06556795537471771, -0.0433768592774868]\n",
      "1200 steps | score: [0.03274456411600113, -0.02264833077788353]\n",
      "1300 steps | score: [0.04098377749323845, -0.004618258215487003]\n",
      "1400 steps | score: [0.014423043467104435, 0.016050029546022415]\n",
      "1500 steps | score: [0.033694200217723846, -0.007657545618712902]\n",
      "1600 steps | score: [0.019210396334528923, 0.00808365736156702]\n",
      "1700 steps | score: [0.03283720463514328, -0.015969732776284218]\n",
      "1800 steps | score: [0.06994742155075073, -0.035755693912506104]\n",
      "1900 steps | score: [0.006577326916158199, 0.016675826162099838]\n",
      "2000 steps | score: [0.056437138468027115, -0.037960492074489594]\n",
      "2100 steps | score: [0.06691005825996399, -0.047132670879364014]\n",
      "2200 steps | score: [0.02559272013604641, -0.0053186677396297455]\n",
      "2300 steps | score: [0.06856013834476471, -0.0482744537293911]\n",
      "2400 steps | score: [0.041220564395189285, -0.0289057157933712]\n",
      "2500 steps | score: [0.03100818209350109, -0.004035463556647301]\n",
      "2600 steps | score: [0.017779463902115822, 0.006481952965259552]\n",
      "0 steps | score: [0.09616655111312866, 0.1453346461057663]\n",
      "100 steps | score: [0.06587549299001694, 0.005554035305976868]\n",
      "200 steps | score: [-0.10389629006385803, 0.13304726779460907]\n",
      "300 steps | score: [-0.06591009348630905, 0.13176552951335907]\n",
      "400 steps | score: [-0.09922594577074051, 0.13040857017040253]\n",
      "500 steps | score: [-0.04629359021782875, 0.1112317442893982]\n",
      "600 steps | score: [-0.03251955285668373, 0.08767949789762497]\n",
      "700 steps | score: [0.0562850721180439, -0.05991189181804657]\n",
      "800 steps | score: [0.06493499130010605, -0.017126072198152542]\n",
      "900 steps | score: [-0.0541861392557621, 0.0957375019788742]\n",
      "1000 steps | score: [0.041254498064517975, -0.008189472369849682]\n",
      "1100 steps | score: [0.02297416515648365, 0.004197326488792896]\n",
      "1200 steps | score: [-0.006703839637339115, 0.03755622357130051]\n",
      "1300 steps | score: [-0.008956048637628555, 0.05321214348077774]\n",
      "1400 steps | score: [-0.04481804743409157, 0.08596174418926239]\n",
      "1500 steps | score: [-0.008187217637896538, 0.0486675500869751]\n",
      "1600 steps | score: [-0.0390036515891552, 0.0840202048420906]\n",
      "1700 steps | score: [-0.009583053179085255, 0.039602719247341156]\n",
      "1800 steps | score: [0.0188842061907053, 0.026283137500286102]\n",
      "1900 steps | score: [-0.040759872645139694, 0.0796286091208458]\n",
      "2000 steps | score: [-0.0001945822441484779, 0.03505033627152443]\n",
      "2100 steps | score: [0.03299849107861519, 0.0033792899921536446]\n",
      "2200 steps | score: [-0.020510489121079445, 0.06146528571844101]\n",
      "2300 steps | score: [0.010661945678293705, 0.024450402706861496]\n",
      "2400 steps | score: [-0.007875033654272556, 0.04749947413802147]\n",
      "2500 steps | score: [-0.02315741404891014, 0.05759507417678833]\n",
      "2600 steps | score: [-0.020848814398050308, 0.06765296310186386]\n",
      "unknown params:  tensor([-0.4425, -0.6662])\n",
      "unknown variance:  tensor([[1.0455]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4302, -0.5904])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.09784405678510666]\n",
      "100 steps | score: [0.02503684163093567]\n",
      "200 steps | score: [-0.15946537256240845]\n",
      "300 steps | score: [-0.06401665508747101]\n",
      "400 steps | score: [-0.0873924195766449]\n",
      "500 steps | score: [-0.10334277153015137]\n",
      "600 steps | score: [-0.10882081091403961]\n",
      "700 steps | score: [-0.0936974585056305]\n",
      "800 steps | score: [-0.08221954107284546]\n",
      "900 steps | score: [-0.07995958626270294]\n",
      "1000 steps | score: [-0.06169396638870239]\n",
      "1100 steps | score: [-0.1140265166759491]\n",
      "1200 steps | score: [-0.09026187658309937]\n",
      "1300 steps | score: [-0.03203622251749039]\n",
      "1400 steps | score: [-0.08973954617977142]\n",
      "1500 steps | score: [-0.05798158049583435]\n",
      "1600 steps | score: [-0.06110990792512894]\n",
      "1700 steps | score: [-0.09551059454679489]\n",
      "1800 steps | score: [-0.09822969138622284]\n",
      "1900 steps | score: [-0.08785442262887955]\n",
      "2000 steps | score: [-0.06703527271747589]\n",
      "2100 steps | score: [-0.09159301221370697]\n",
      "2200 steps | score: [-0.09098061174154282]\n",
      "2300 steps | score: [-0.06560277193784714]\n",
      "2400 steps | score: [-0.09991349279880524]\n",
      "2500 steps | score: [-0.06763970851898193]\n",
      "2600 steps | score: [-0.07552438974380493]\n",
      "2700 steps | score: [-0.08963456749916077]\n",
      "0 steps | score: [0.13323955237865448, 0.029813075438141823]\n",
      "100 steps | score: [0.2258104681968689, -0.3583522439002991]\n",
      "200 steps | score: [-0.09331655502319336, 0.08448059111833572]\n",
      "300 steps | score: [-0.01280934363603592, 0.0027536433190107346]\n",
      "400 steps | score: [0.03011259436607361, -0.10042873024940491]\n",
      "500 steps | score: [-0.06081084534525871, 0.03635130822658539]\n",
      "600 steps | score: [-0.03006843663752079, 0.021935103461146355]\n",
      "700 steps | score: [0.0418454185128212, -0.10500595718622208]\n",
      "800 steps | score: [-0.036299802362918854, 0.017126446589827538]\n",
      "900 steps | score: [-0.004817316774278879, -0.019087061285972595]\n",
      "1000 steps | score: [0.021326931193470955, -0.07279735803604126]\n",
      "1100 steps | score: [-0.0485798716545105, 0.023970745503902435]\n",
      "1200 steps | score: [0.0034992373548448086, -0.04079815000295639]\n",
      "1300 steps | score: [0.022875644266605377, -0.07718215137720108]\n",
      "1400 steps | score: [-0.024676386266946793, -0.010002100840210915]\n",
      "1500 steps | score: [0.010792500339448452, -0.04045601561665535]\n",
      "1600 steps | score: [0.015021088533103466, -0.05225217714905739]\n",
      "1700 steps | score: [-0.03456050902605057, 0.0033233799040317535]\n",
      "1800 steps | score: [-0.002118227304890752, -0.02972220629453659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [-0.0008506796439178288, -0.03141068294644356]\n",
      "2000 steps | score: [-0.013142641633749008, -0.02629166655242443]\n",
      "2100 steps | score: [-0.02778870239853859, -0.006219089031219482]\n",
      "2200 steps | score: [-0.0024815304204821587, -0.048700492829084396]\n",
      "2300 steps | score: [-0.011072426103055477, -0.0333016999065876]\n",
      "2400 steps | score: [-0.027048837393522263, -0.01477230153977871]\n",
      "2500 steps | score: [-0.00571246724575758, -0.03805665671825409]\n",
      "2600 steps | score: [0.003639577655121684, -0.04948326200246811]\n",
      "2700 steps | score: [-0.019447317346930504, -0.014874681830406189]\n",
      "0 steps | score: [0.14094385504722595, 0.12572790682315826]\n",
      "100 steps | score: [0.23828403651714325, -0.2712630033493042]\n",
      "200 steps | score: [-0.0865500196814537, 0.17746245861053467]\n",
      "300 steps | score: [0.001513441908173263, 0.08650805056095123]\n",
      "400 steps | score: [0.047210607677698135, -0.01301121711730957]\n",
      "500 steps | score: [-0.05044793710112572, 0.13344977796077728]\n",
      "600 steps | score: [-0.019997423514723778, 0.10297957807779312]\n",
      "700 steps | score: [0.041339900344610214, -0.007236439734697342]\n",
      "800 steps | score: [-0.047067634761333466, 0.1153656616806984]\n",
      "900 steps | score: [-0.013718901202082634, 0.08378270268440247]\n",
      "1000 steps | score: [0.02123941294848919, 0.017608195543289185]\n",
      "1100 steps | score: [-0.03981182351708412, 0.10736008733510971]\n",
      "1200 steps | score: [0.007259946316480637, 0.0602521151304245]\n",
      "1300 steps | score: [0.029585279524326324, 0.012702933512628078]\n",
      "1400 steps | score: [-0.03023398667573929, 0.09469516575336456]\n",
      "1500 steps | score: [0.013584486208856106, 0.045815639197826385]\n",
      "1600 steps | score: [-0.00127021421212703, 0.0492706298828125]\n",
      "1700 steps | score: [-0.028130030259490013, 0.09777482599020004]\n",
      "1800 steps | score: [-0.0015286424895748496, 0.05888551101088524]\n",
      "1900 steps | score: [-0.014616068452596664, 0.0672910287976265]\n",
      "2000 steps | score: [-0.0014718308812007308, 0.0651121735572815]\n",
      "2100 steps | score: [-0.02224847860634327, 0.08054978400468826]\n",
      "2200 steps | score: [-0.006535313557833433, 0.06045111268758774]\n",
      "2300 steps | score: [-0.007425743620842695, 0.06719278544187546]\n",
      "2400 steps | score: [-0.016738398000597954, 0.08305995166301727]\n",
      "2500 steps | score: [0.0012152539566159248, 0.05486534908413887]\n",
      "2600 steps | score: [-0.005981233436614275, 0.05855919420719147]\n",
      "2700 steps | score: [-0.0242641419172287, 0.09061791747808456]\n",
      "0 steps | score: [0.07191048562526703, 0.19594751298427582]\n",
      "100 steps | score: [0.17381848394870758, -0.20156961679458618]\n",
      "200 steps | score: [-0.12073223292827606, 0.21233242750167847]\n",
      "300 steps | score: [-0.04146267846226692, 0.12568871676921844]\n",
      "400 steps | score: [-0.00990965310484171, 0.034438859671354294]\n",
      "500 steps | score: [-0.11091819405555725, 0.1833684742450714]\n",
      "600 steps | score: [-0.06217274069786072, 0.1422155648469925]\n",
      "700 steps | score: [-0.02052680030465126, 0.051611751317977905]\n",
      "800 steps | score: [-0.08373158425092697, 0.1545964628458023]\n",
      "900 steps | score: [-0.06091916188597679, 0.14011920988559723]\n",
      "1000 steps | score: [-0.025435753166675568, 0.06339598447084427]\n",
      "1100 steps | score: [-0.08494170010089874, 0.15076670050621033]\n",
      "1200 steps | score: [-0.039450570940971375, 0.10197868198156357]\n",
      "1300 steps | score: [-0.019346026703715324, 0.05565114691853523]\n",
      "1400 steps | score: [-0.09092022478580475, 0.1620597243309021]\n",
      "1500 steps | score: [-0.03615943342447281, 0.09507016092538834]\n",
      "1600 steps | score: [-0.055166661739349365, 0.10879243910312653]\n",
      "1700 steps | score: [-0.0711434930562973, 0.1344595104455948]\n",
      "1800 steps | score: [-0.05487431585788727, 0.11985139548778534]\n",
      "1900 steps | score: [-0.05395374819636345, 0.11251775920391083]\n",
      "2000 steps | score: [-0.0647667869925499, 0.12104503810405731]\n",
      "2100 steps | score: [-0.06991025805473328, 0.1360471546649933]\n",
      "2200 steps | score: [-0.055868420749902725, 0.11096503585577011]\n",
      "2300 steps | score: [-0.05274885520339012, 0.11295482516288757]\n",
      "2400 steps | score: [-0.07441740483045578, 0.13252030313014984]\n",
      "2500 steps | score: [-0.06258285790681839, 0.11145992577075958]\n",
      "2600 steps | score: [-0.05368382856249809, 0.10640396177768707]\n",
      "2700 steps | score: [-0.07793550938367844, 0.14056138694286346]\n",
      "unknown params:  tensor([-0.4771, -0.8253])\n",
      "unknown variance:  tensor([[1.1288]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4302, -0.5904])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.23667758703231812]\n",
      "100 steps | score: [0.10126609355211258]\n",
      "200 steps | score: [-0.008940093219280243]\n",
      "0 steps | score: [0.11821267753839493, 0.07695825397968292]\n",
      "100 steps | score: [0.014216226525604725, 0.05097576230764389]\n",
      "200 steps | score: [-0.06057438254356384, 0.061045099049806595]\n",
      "300 steps | score: [-0.038812290877103806, 0.05005423724651337]\n",
      "400 steps | score: [-0.059938155114650726, 0.11208968609571457]\n",
      "500 steps | score: [-0.023070575669407845, -0.0009405575692653656]\n",
      "600 steps | score: [-0.09862570464611053, 0.13122567534446716]\n",
      "700 steps | score: [-0.027318451553583145, 0.04245331138372421]\n",
      "800 steps | score: [-0.11961913853883743, 0.15896445512771606]\n",
      "900 steps | score: [-0.009419749490916729, 0.004921358078718185]\n",
      "0 steps | score: [0.05618969351053238, 0.232564315199852]\n",
      "100 steps | score: [-0.03664727136492729, 0.18533432483673096]\n",
      "200 steps | score: [-0.09767314791679382, 0.1875326931476593]\n",
      "300 steps | score: [-0.09378563612699509, 0.18467676639556885]\n",
      "400 steps | score: [-0.12137173116207123, 0.2624129354953766]\n",
      "500 steps | score: [-0.06063444912433624, 0.11768941581249237]\n",
      "600 steps | score: [-0.14826202392578125, 0.273074746131897]\n",
      "700 steps | score: [-0.08811445534229279, 0.1876174807548523]\n",
      "800 steps | score: [-0.16646263003349304, 0.28849464654922485]\n",
      "900 steps | score: [-0.04814910516142845, 0.1253124475479126]\n",
      "1000 steps | score: [-0.09478428214788437, 0.17275670170783997]\n",
      "1100 steps | score: [0.006830190774053335, 0.040395092219114304]\n",
      "1200 steps | score: [-0.05598011985421181, 0.13800235092639923]\n",
      "1300 steps | score: [-0.11136404424905777, 0.2089170217514038]\n",
      "1400 steps | score: [-0.019646011292934418, 0.0812310203909874]\n",
      "1500 steps | score: [-0.010245263576507568, 0.0599188357591629]\n",
      "1600 steps | score: [-0.10726392269134521, 0.20313940942287445]\n",
      "1700 steps | score: [-0.1344183385372162, 0.2360108196735382]\n",
      "1800 steps | score: [-0.1120000034570694, 0.21786585450172424]\n",
      "1900 steps | score: [-0.05247523635625839, 0.12127508968114853]\n",
      "2000 steps | score: [-0.04465348273515701, 0.11184434592723846]\n",
      "2100 steps | score: [-0.12407750636339188, 0.21216046810150146]\n",
      "2200 steps | score: [-0.03322536125779152, 0.0887540653347969]\n",
      "2300 steps | score: [-0.08422429859638214, 0.16547811031341553]\n",
      "2400 steps | score: [-0.10308147221803665, 0.18856149911880493]\n",
      "2500 steps | score: [-0.0886436253786087, 0.16869038343429565]\n",
      "2600 steps | score: [-0.07405482977628708, 0.14256680011749268]\n",
      "2700 steps | score: [-0.12171217054128647, 0.2220923751592636]\n",
      "0 steps | score: [0.056391533464193344, 0.217706561088562]\n",
      "100 steps | score: [-0.02419620379805565, 0.15031541883945465]\n",
      "200 steps | score: [-0.09228276461362839, 0.16002777218818665]\n",
      "300 steps | score: [-0.07315563410520554, 0.14003150165081024]\n",
      "400 steps | score: [-0.09998854994773865, 0.20840267837047577]\n",
      "500 steps | score: [-0.048181191086769104, 0.08496294915676117]\n",
      "600 steps | score: [-0.1372765153646469, 0.2456342577934265]\n",
      "700 steps | score: [-0.06330837309360504, 0.13039791584014893]\n",
      "800 steps | score: [-0.16024285554885864, 0.26663851737976074]\n",
      "900 steps | score: [-0.01315722893923521, 0.05747672915458679]\n",
      "1000 steps | score: [-0.05811060592532158, 0.11346450448036194]\n",
      "1100 steps | score: [0.043543096631765366, -0.03587999939918518]\n",
      "1200 steps | score: [-0.03536123409867287, 0.0906105637550354]\n",
      "1300 steps | score: [-0.09409263730049133, 0.1741471141576767]\n",
      "1400 steps | score: [0.01592840999364853, -0.0007182275876402855]\n",
      "1500 steps | score: [0.01221708208322525, 0.016496019437909126]\n",
      "1600 steps | score: [-0.07487966120243073, 0.14283926784992218]\n",
      "1700 steps | score: [-0.11758787930011749, 0.20519223809242249]\n",
      "1800 steps | score: [-0.09995764493942261, 0.1827842742204666]\n",
      "1900 steps | score: [-0.02090672217309475, 0.06305964291095734]\n",
      "2000 steps | score: [-0.019735069945454597, 0.06376081705093384]\n",
      "2100 steps | score: [-0.09707169234752655, 0.1686471849679947]\n",
      "2200 steps | score: [-0.005806112661957741, 0.03919035568833351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300 steps | score: [-0.05536043271422386, 0.12455269694328308]\n",
      "2400 steps | score: [-0.0733160525560379, 0.1415165662765503]\n",
      "2500 steps | score: [-0.061875395476818085, 0.1289292573928833]\n",
      "2600 steps | score: [-0.05286424979567528, 0.11480656266212463]\n",
      "2700 steps | score: [-0.09970320761203766, 0.18034584820270538]\n",
      "unknown params:  tensor([-0.5029, -1.0021])\n",
      "unknown variance:  tensor([[1.2214]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4302, -0.5904])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.19556006789207458]\n",
      "100 steps | score: [-4.3272972106933594e-05]\n",
      "0 steps | score: [0.20744360983371735, -0.12997765839099884]\n",
      "100 steps | score: [-0.03967355564236641, 0.08312530070543289]\n",
      "200 steps | score: [-0.012098317965865135, -0.0013575442135334015]\n",
      "300 steps | score: [-0.05798264965415001, 0.05863949656486511]\n",
      "400 steps | score: [-0.04374595731496811, 0.0166203361004591]\n",
      "500 steps | score: [0.06295780092477798, -0.14894847571849823]\n",
      "600 steps | score: [-0.055539436638355255, 0.03355803340673447]\n",
      "700 steps | score: [0.00518686743453145, -0.07025028765201569]\n",
      "800 steps | score: [-0.024445651099085808, -0.00977187417447567]\n",
      "900 steps | score: [-0.01838078908622265, -0.05116158351302147]\n",
      "1000 steps | score: [0.12976782023906708, -0.27858418226242065]\n",
      "1100 steps | score: [0.058620352298021317, -0.13872206211090088]\n",
      "1200 steps | score: [-0.057781971991062164, 0.03129729628562927]\n",
      "1300 steps | score: [0.025913270190358162, -0.10145267099142075]\n",
      "1400 steps | score: [-0.03572893142700195, -0.0027507860213518143]\n",
      "1500 steps | score: [0.06674689799547195, -0.1677560955286026]\n",
      "1600 steps | score: [0.03502602502703667, -0.13004042208194733]\n",
      "1700 steps | score: [-0.019845016300678253, -0.027251925319433212]\n",
      "1800 steps | score: [0.05815383419394493, -0.1710057258605957]\n",
      "1900 steps | score: [-0.037174247205257416, -0.0008600708097219467]\n",
      "2000 steps | score: [-0.0006778121460229158, -0.05900411680340767]\n",
      "2100 steps | score: [0.007352467160671949, -0.07751673460006714]\n",
      "2200 steps | score: [0.08456184715032578, -0.20564356446266174]\n",
      "2300 steps | score: [0.033381782472133636, -0.10925468057394028]\n",
      "2400 steps | score: [0.004456935916095972, -0.07469074428081512]\n",
      "2500 steps | score: [0.007524078246206045, -0.06712297350168228]\n",
      "2600 steps | score: [0.0010094566969200969, -0.07124291360378265]\n",
      "0 steps | score: [0.11823178827762604, 0.06092799827456474]\n",
      "100 steps | score: [-0.09070317447185516, 0.21635660529136658]\n",
      "200 steps | score: [-0.03764759749174118, 0.09389445185661316]\n",
      "300 steps | score: [-0.1255626231431961, 0.2118794173002243]\n",
      "400 steps | score: [-0.09491398185491562, 0.152110755443573]\n",
      "500 steps | score: [-0.010484776459634304, 0.021625392138957977]\n",
      "600 steps | score: [-0.0932607650756836, 0.15693455934524536]\n",
      "700 steps | score: [-0.035814329981803894, 0.046395041048526764]\n",
      "800 steps | score: [-0.07829523831605911, 0.11569072306156158]\n",
      "900 steps | score: [-0.09873607754707336, 0.14455248415470123]\n",
      "1000 steps | score: [0.05081111937761307, -0.09777040779590607]\n",
      "1100 steps | score: [-0.034099023789167404, 0.05392146110534668]\n",
      "1200 steps | score: [-0.1343889683485031, 0.2081116884946823]\n",
      "1300 steps | score: [-0.026020918041467667, 0.03484918922185898]\n",
      "1400 steps | score: [-0.0947328582406044, 0.13978828489780426]\n",
      "1500 steps | score: [0.008180302567780018, -0.027589885517954826]\n",
      "1600 steps | score: [0.003365263342857361, -0.011761728674173355]\n",
      "1700 steps | score: [-0.0624704547226429, 0.08798881620168686]\n",
      "1800 steps | score: [0.006929540075361729, -0.017965417355298996]\n",
      "1900 steps | score: [-0.09447364509105682, 0.14053790271282196]\n",
      "2000 steps | score: [-0.060786377638578415, 0.09602208435535431]\n",
      "2100 steps | score: [-0.05655532330274582, 0.08138327300548553]\n",
      "2200 steps | score: [0.051111530512571335, -0.10203029215335846]\n",
      "2300 steps | score: [-0.017925886437296867, 0.01924927532672882]\n",
      "2400 steps | score: [-0.04239114001393318, 0.05520869046449661]\n",
      "2500 steps | score: [-0.045354560017585754, 0.06628680974245071]\n",
      "2600 steps | score: [-0.05286145955324173, 0.0655749961733818]\n",
      "0 steps | score: [0.16863952577114105, 0.018045183271169662]\n",
      "100 steps | score: [-0.04670103266835213, 0.1790553480386734]\n",
      "200 steps | score: [-0.011283368803560734, 0.08025576174259186]\n",
      "300 steps | score: [-0.07231669127941132, 0.1644698679447174]\n",
      "400 steps | score: [-0.03299078345298767, 0.09102395921945572]\n",
      "500 steps | score: [0.047736722975969315, -0.04541003704071045]\n",
      "600 steps | score: [-0.051701683551073074, 0.11872711032629013]\n",
      "700 steps | score: [0.01148409117013216, 0.010374022647738457]\n",
      "800 steps | score: [-0.04835664853453636, 0.10491364449262619]\n",
      "900 steps | score: [-0.03567921742796898, 0.08480703830718994]\n",
      "1000 steps | score: [0.08803556114435196, -0.1271895468235016]\n",
      "1100 steps | score: [0.007312915287911892, 0.011677201837301254]\n",
      "1200 steps | score: [-0.09492415189743042, 0.1707494854927063]\n",
      "1300 steps | score: [-0.0019092881120741367, 0.022531963884830475]\n",
      "1400 steps | score: [-0.040018822997808456, 0.0900338813662529]\n",
      "1500 steps | score: [0.0613352470099926, -0.0805773213505745]\n",
      "1600 steps | score: [0.015626540407538414, 0.0014635603874921799]\n",
      "1700 steps | score: [-0.023509416729211807, 0.07191543281078339]\n",
      "1800 steps | score: [0.04569981247186661, -0.04239903762936592]\n",
      "1900 steps | score: [-0.07382386922836304, 0.12326186895370483]\n",
      "2000 steps | score: [-0.01622121036052704, 0.04587692767381668]\n",
      "2100 steps | score: [0.0030265673995018005, 0.018703076988458633]\n",
      "2200 steps | score: [0.06971656531095505, -0.11048370599746704]\n",
      "2300 steps | score: [0.015210450626909733, -0.003983331844210625]\n",
      "2400 steps | score: [-0.022277604788541794, 0.05216754972934723]\n",
      "2500 steps | score: [0.004276231396943331, 0.02535061538219452]\n",
      "2600 steps | score: [-0.0056443349458277225, 0.02847939543426037]\n",
      "unknown params:  tensor([-0.5044, -1.1140])\n",
      "unknown variance:  tensor([[1.3264]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4302, -0.5904])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.06821174174547195]\n",
      "100 steps | score: [-0.14264917373657227]\n",
      "200 steps | score: [-0.19737040996551514]\n",
      "300 steps | score: [-0.07607272267341614]\n",
      "400 steps | score: [-0.181275874376297]\n",
      "500 steps | score: [-0.15257138013839722]\n",
      "600 steps | score: [-0.17489305138587952]\n",
      "700 steps | score: [-0.20999236404895782]\n",
      "800 steps | score: [-0.19898803532123566]\n",
      "900 steps | score: [-0.15460555255413055]\n",
      "1000 steps | score: [-0.165642648935318]\n",
      "1100 steps | score: [-0.15414735674858093]\n",
      "1200 steps | score: [-0.15391311049461365]\n",
      "1300 steps | score: [-0.15971818566322327]\n",
      "1400 steps | score: [-0.14726752042770386]\n",
      "1500 steps | score: [-0.17892523109912872]\n",
      "1600 steps | score: [-0.16665467619895935]\n",
      "1700 steps | score: [-0.19212009012699127]\n",
      "1800 steps | score: [-0.15947528183460236]\n",
      "1900 steps | score: [-0.1828731894493103]\n",
      "2000 steps | score: [-0.18434301018714905]\n",
      "2100 steps | score: [-0.1792815923690796]\n",
      "2200 steps | score: [-0.17388370633125305]\n",
      "2300 steps | score: [-0.1870080977678299]\n",
      "2400 steps | score: [-0.16923290491104126]\n",
      "2500 steps | score: [-0.1524503231048584]\n",
      "0 steps | score: [0.21003678441047668, -0.07582059502601624]\n",
      "100 steps | score: [-0.012940795160830021, 0.15477591753005981]\n",
      "200 steps | score: [-0.04992913454771042, 0.17999856173992157]\n",
      "300 steps | score: [0.15890288352966309, -0.23629111051559448]\n",
      "400 steps | score: [0.038022805005311966, -0.023970726877450943]\n",
      "500 steps | score: [0.11627814173698425, -0.1791032999753952]\n",
      "600 steps | score: [-0.0077103362418711185, 0.052983082830905914]\n",
      "700 steps | score: [-0.09192374348640442, 0.18277007341384888]\n",
      "800 steps | score: [-0.11180432140827179, 0.22046725451946259]\n",
      "900 steps | score: [0.06861082464456558, -0.1044253408908844]\n",
      "1000 steps | score: [-0.05046234652400017, 0.12451601028442383]\n",
      "1100 steps | score: [0.11143413931131363, -0.19262319803237915]\n",
      "1200 steps | score: [0.14652062952518463, -0.24351178109645844]\n",
      "1300 steps | score: [0.24447296559810638, -0.4548095464706421]\n",
      "1400 steps | score: [0.016633672639727592, 0.0038357768207788467]\n",
      "1500 steps | score: [-0.08930687606334686, 0.18826226890087128]\n",
      "1600 steps | score: [0.08239811658859253, -0.10767185688018799]\n",
      "1700 steps | score: [0.0022297000978142023, 0.024940241128206253]\n",
      "1800 steps | score: [0.0724484920501709, -0.11498043686151505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [-0.033901821821928024, 0.09201765805482864]\n",
      "2000 steps | score: [-0.05032367259263992, 0.12003811448812485]\n",
      "2100 steps | score: [0.0010867208475247025, 0.026789270341396332]\n",
      "2200 steps | score: [0.03530283272266388, -0.0489460825920105]\n",
      "2300 steps | score: [-0.00692999642342329, 0.0424712710082531]\n",
      "2400 steps | score: [0.06340533494949341, -0.09106263518333435]\n",
      "2500 steps | score: [0.06926058232784271, -0.09836713969707489]\n",
      "0 steps | score: [0.05827239900827408, 0.2484871745109558]\n",
      "100 steps | score: [-0.1294844001531601, 0.40963393449783325]\n",
      "200 steps | score: [-0.15761101245880127, 0.4314092993736267]\n",
      "300 steps | score: [0.08822090923786163, -0.06349287927150726]\n",
      "400 steps | score: [-0.011131820268929005, 0.11692758649587631]\n",
      "500 steps | score: [0.05733602121472359, -0.03811027482151985]\n",
      "600 steps | score: [-0.10157132148742676, 0.29108744859695435]\n",
      "700 steps | score: [-0.17913417518138885, 0.4045270085334778]\n",
      "800 steps | score: [-0.20987209677696228, 0.44904860854148865]\n",
      "900 steps | score: [-0.04716108739376068, 0.15433089435100555]\n",
      "1000 steps | score: [-0.15935729444026947, 0.36837077140808105]\n",
      "1100 steps | score: [0.03991999104619026, -0.01744687929749489]\n",
      "1200 steps | score: [0.06338593363761902, -0.05553358048200607]\n",
      "1300 steps | score: [0.1916392594575882, -0.34434786438941956]\n",
      "1400 steps | score: [-0.0815420001745224, 0.22654610872268677]\n",
      "1500 steps | score: [-0.17706041038036346, 0.39575299620628357]\n",
      "1600 steps | score: [-0.03059694916009903, 0.1245286762714386]\n",
      "1700 steps | score: [-0.10829931497573853, 0.27941209077835083]\n",
      "1800 steps | score: [-0.006808886304497719, 0.09593578428030014]\n",
      "1900 steps | score: [-0.1341853141784668, 0.33907002210617065]\n",
      "2000 steps | score: [-0.14295007288455963, 0.3428778052330017]\n",
      "2100 steps | score: [-0.08672147244215012, 0.23739254474639893]\n",
      "2200 steps | score: [-0.03444693610072136, 0.1305844485759735]\n",
      "2300 steps | score: [-0.10730713605880737, 0.2786765694618225]\n",
      "2400 steps | score: [-0.0439249649643898, 0.1543065458536148]\n",
      "2500 steps | score: [-0.020213423296809196, 0.11281657963991165]\n",
      "0 steps | score: [0.20218156278133392, -0.14608213305473328]\n",
      "100 steps | score: [-0.012991353869438171, 0.08287857472896576]\n",
      "200 steps | score: [-0.089111328125, 0.16891434788703918]\n",
      "300 steps | score: [0.1660975217819214, -0.3221950829029083]\n",
      "400 steps | score: [0.050459183752536774, -0.12218067049980164]\n",
      "500 steps | score: [0.14253956079483032, -0.30476808547973633]\n",
      "600 steps | score: [-0.017117710784077644, 0.002263534814119339]\n",
      "700 steps | score: [-0.10720952600240707, 0.14380672574043274]\n",
      "800 steps | score: [-0.11862906813621521, 0.1610165536403656]\n",
      "900 steps | score: [0.05910327658057213, -0.1443488895893097]\n",
      "1000 steps | score: [-0.029472606256604195, 0.010466232895851135]\n",
      "1100 steps | score: [0.12588177621364594, -0.2840079665184021]\n",
      "1200 steps | score: [0.13412681221961975, -0.3191559910774231]\n",
      "1300 steps | score: [0.270373672246933, -0.6016145348548889]\n",
      "1400 steps | score: [0.015385384671390057, -0.06330805271863937]\n",
      "1500 steps | score: [-0.07994686812162399, 0.10207488387823105]\n",
      "1600 steps | score: [0.06901691854000092, -0.1650167852640152]\n",
      "1700 steps | score: [0.00787452794611454, -0.05833244323730469]\n",
      "1800 steps | score: [0.06884502619504929, -0.1711086928844452]\n",
      "1900 steps | score: [-0.04985158517956734, 0.05191675201058388]\n",
      "2000 steps | score: [-0.059407029300928116, 0.06007716804742813]\n",
      "2100 steps | score: [0.007377933710813522, -0.060614097863435745]\n",
      "2200 steps | score: [0.0500030480325222, -0.14407934248447418]\n",
      "2300 steps | score: [-0.011480608023703098, -0.034295424818992615]\n",
      "2400 steps | score: [0.04478875920176506, -0.13205723464488983]\n",
      "2500 steps | score: [0.05950689688324928, -0.1587245613336563]\n",
      "unknown params:  tensor([-0.4925, -1.1809])\n",
      "unknown variance:  tensor([[1.4295]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4302, -0.5904])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.20657257735729218]\n",
      "100 steps | score: [-0.0519280731678009]\n",
      "200 steps | score: [-0.035010240972042084]\n",
      "300 steps | score: [-0.03699568286538124]\n",
      "400 steps | score: [-0.06195765733718872]\n",
      "500 steps | score: [-0.09710846841335297]\n",
      "600 steps | score: [-0.0191672220826149]\n",
      "700 steps | score: [-0.08496412634849548]\n",
      "800 steps | score: [-0.051219791173934937]\n",
      "900 steps | score: [-0.0942685678601265]\n",
      "1000 steps | score: [-0.08514808118343353]\n",
      "1100 steps | score: [-0.12740039825439453]\n",
      "1200 steps | score: [-0.04998437687754631]\n",
      "1300 steps | score: [-0.08735386282205582]\n",
      "1400 steps | score: [-0.02587287127971649]\n",
      "1500 steps | score: [-0.09646409749984741]\n",
      "1600 steps | score: [-0.06255759298801422]\n",
      "1700 steps | score: [-0.11698359251022339]\n",
      "1800 steps | score: [-0.05058402568101883]\n",
      "1900 steps | score: [-0.09300923347473145]\n",
      "2000 steps | score: [-0.04827761650085449]\n",
      "2100 steps | score: [-0.07554581761360168]\n",
      "2200 steps | score: [-0.08823875337839127]\n",
      "2300 steps | score: [-0.07455176115036011]\n",
      "2400 steps | score: [-0.05968708172440529]\n",
      "2500 steps | score: [-0.07170520722866058]\n",
      "2600 steps | score: [-0.07381562888622284]\n",
      "0 steps | score: [0.08251731097698212, 0.14825162291526794]\n",
      "100 steps | score: [-0.021411584690213203, 0.2318858653306961]\n",
      "200 steps | score: [-0.05584028735756874, 0.21910570561885834]\n",
      "300 steps | score: [-0.04992028325796127, 0.1920846700668335]\n",
      "400 steps | score: [0.018124600872397423, -0.0019105169922113419]\n",
      "500 steps | score: [-0.2352200150489807, 0.5130491852760315]\n",
      "600 steps | score: [-0.01271106582134962, 0.053086746484041214]\n",
      "700 steps | score: [-0.1337212324142456, 0.31725549697875977]\n",
      "800 steps | score: [-0.2060772180557251, 0.44181007146835327]\n",
      "900 steps | score: [-0.16086159646511078, 0.3702583312988281]\n",
      "1000 steps | score: [-0.16921599209308624, 0.3850241005420685]\n",
      "1100 steps | score: [-0.1979798674583435, 0.4411085546016693]\n",
      "1200 steps | score: [0.09026169031858444, -0.15763390064239502]\n",
      "1300 steps | score: [-0.05141425505280495, 0.1602562516927719]\n",
      "1400 steps | score: [-0.035723138600587845, 0.09790371358394623]\n",
      "1500 steps | score: [-0.12766191363334656, 0.30687010288238525]\n",
      "1600 steps | score: [-0.07418574392795563, 0.18734051287174225]\n",
      "1700 steps | score: [-0.1995246559381485, 0.42934203147888184]\n",
      "1800 steps | score: [-0.09106238931417465, 0.22390274703502655]\n",
      "1900 steps | score: [-0.15287712216377258, 0.35920262336730957]\n",
      "2000 steps | score: [-0.07827721536159515, 0.20133982598781586]\n",
      "2100 steps | score: [-0.04757251590490341, 0.12911063432693481]\n",
      "2200 steps | score: [-0.03393822908401489, 0.1104823425412178]\n",
      "2300 steps | score: [-0.05933384597301483, 0.13565915822982788]\n",
      "2400 steps | score: [-0.10471843183040619, 0.25141435861587524]\n",
      "2500 steps | score: [-0.027582233771681786, 0.08544863015413284]\n",
      "2600 steps | score: [-0.09500862658023834, 0.2165108025074005]\n",
      "0 steps | score: [0.20497755706310272, -0.15683607757091522]\n",
      "100 steps | score: [0.05451776459813118, 0.01983901485800743]\n",
      "200 steps | score: [0.016532300040125847, 0.02813740447163582]\n",
      "300 steps | score: [0.03378753736615181, -0.03718828782439232]\n",
      "400 steps | score: [0.09760655462741852, -0.20590773224830627]\n",
      "500 steps | score: [-0.12239877134561539, 0.24801050126552582]\n",
      "600 steps | score: [0.0728483721613884, -0.1632327437400818]\n",
      "700 steps | score: [-0.039586104452610016, 0.07637551426887512]\n",
      "800 steps | score: [-0.09980137646198273, 0.19160987436771393]\n",
      "900 steps | score: [-0.04875544458627701, 0.0951051265001297]\n",
      "1000 steps | score: [-0.08395611494779587, 0.14936235547065735]\n",
      "1100 steps | score: [-0.1373881846666336, 0.2577438950538635]\n",
      "1200 steps | score: [0.1564532220363617, -0.36302047967910767]\n",
      "1300 steps | score: [0.013851607218384743, -0.045857734978199005]\n",
      "1400 steps | score: [0.049619678407907486, -0.10573238879442215]\n",
      "1500 steps | score: [-0.07267121225595474, 0.127400204539299]\n",
      "1600 steps | score: [0.014594081789255142, -0.03069469705224037]\n",
      "1700 steps | score: [-0.11479075998067856, 0.21974164247512817]\n",
      "1800 steps | score: [-0.007778806611895561, 0.001866709440946579]\n",
      "0 steps | score: [0.2048926204442978, -0.17074313759803772]\n",
      "100 steps | score: [0.11521841585636139, -0.10271531343460083]\n",
      "200 steps | score: [0.005845228675752878, 0.025603540241718292]\n",
      "300 steps | score: [0.03655311092734337, -0.06897249817848206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 steps | score: [0.10656099766492844, -0.23586086928844452]\n",
      "500 steps | score: [-0.11716463416814804, 0.21206922829151154]\n",
      "600 steps | score: [0.09219564497470856, -0.22219347953796387]\n",
      "700 steps | score: [-0.050650704652071, 0.0871032178401947]\n",
      "800 steps | score: [-0.1041773185133934, 0.16557471454143524]\n",
      "900 steps | score: [-0.047475192695856094, 0.07323847711086273]\n",
      "1000 steps | score: [-0.07867605239152908, 0.13072830438613892]\n",
      "1100 steps | score: [-0.108047716319561, 0.18801763653755188]\n",
      "1200 steps | score: [0.18912723660469055, -0.4356316924095154]\n",
      "1300 steps | score: [0.04157276079058647, -0.10879816114902496]\n",
      "1400 steps | score: [0.08308514952659607, -0.21319960057735443]\n",
      "1500 steps | score: [-0.03847751393914223, 0.05175589770078659]\n",
      "1600 steps | score: [0.007360618561506271, -0.03943733125925064]\n",
      "1700 steps | score: [-0.12142698466777802, 0.20479217171669006]\n",
      "1800 steps | score: [-0.01597553677856922, -0.0051561202853918076]\n",
      "1900 steps | score: [-0.04339558258652687, 0.049843929708004]\n",
      "2000 steps | score: [0.040877558290958405, -0.10668410360813141]\n",
      "2100 steps | score: [0.0491211973130703, -0.14458100497722626]\n",
      "2200 steps | score: [0.04293036833405495, -0.12449207901954651]\n",
      "2300 steps | score: [0.061719246208667755, -0.17717109620571136]\n",
      "2400 steps | score: [-0.009536124765872955, -0.021811814978718758]\n",
      "2500 steps | score: [0.08180975168943405, -0.19408094882965088]\n",
      "2600 steps | score: [0.01734822988510132, -0.07511740922927856]\n",
      "unknown params:  tensor([-0.4528, -1.2160])\n",
      "unknown variance:  tensor([[1.5341]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/4d669da3-bbd0-4346-9ea3-b2f5a4566dd5\n",
      "gt params:  tensor([-0.4312, -0.5844])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.22177572548389435]\n",
      "100 steps | score: [-0.03273727744817734]\n",
      "200 steps | score: [0.11952042579650879]\n",
      "300 steps | score: [0.09211032092571259]\n",
      "400 steps | score: [-0.008162513375282288]\n",
      "0 steps | score: [0.02850193716585636, 0.09047200530767441]\n",
      "100 steps | score: [-0.06295578181743622, 0.09185508638620377]\n",
      "200 steps | score: [0.05222461372613907, 0.08410222828388214]\n",
      "300 steps | score: [0.03741730749607086, 0.049504105001688004]\n",
      "400 steps | score: [-0.035508401691913605, 0.038574058562517166]\n",
      "500 steps | score: [-0.05255763605237007, 0.018802348524332047]\n",
      "600 steps | score: [0.042154960334300995, 0.03051736205816269]\n",
      "700 steps | score: [0.06875722855329514, 0.00795060209929943]\n",
      "800 steps | score: [0.008160998113453388, -0.007637784816324711]\n",
      "0 steps | score: [0.032217659056186676, 0.0986892506480217]\n",
      "100 steps | score: [-0.068922258913517, 0.0930807888507843]\n",
      "200 steps | score: [0.05782479792833328, 0.08429664373397827]\n",
      "300 steps | score: [0.037384528666734695, 0.04968845099210739]\n",
      "400 steps | score: [-0.03304898738861084, 0.056171171367168427]\n",
      "500 steps | score: [-0.04451540857553482, 0.028425026684999466]\n",
      "600 steps | score: [0.05521192401647568, 0.03424062207341194]\n",
      "700 steps | score: [0.07790487259626389, 0.01583525538444519]\n",
      "800 steps | score: [0.019429132342338562, -0.002855200320482254]\n",
      "900 steps | score: [-0.05163925141096115, 0.0669165775179863]\n",
      "1000 steps | score: [-0.019479647278785706, 0.0184087622910738]\n",
      "1100 steps | score: [0.022529236972332, 0.05206006020307541]\n",
      "1200 steps | score: [0.0362040139734745, 0.03410089388489723]\n",
      "1300 steps | score: [-0.023093903437256813, 0.029450125992298126]\n",
      "1400 steps | score: [-0.04493073374032974, 0.0443313866853714]\n",
      "1500 steps | score: [0.007453376892954111, 0.055484239012002945]\n",
      "1600 steps | score: [0.03670019283890724, 0.013092687353491783]\n",
      "1700 steps | score: [0.024547012522816658, 0.022263864055275917]\n",
      "1800 steps | score: [-0.00812735315412283, 0.03710310906171799]\n",
      "1900 steps | score: [-0.01465519517660141, 0.03298095241189003]\n",
      "2000 steps | score: [0.003417618339881301, 0.03636995702981949]\n",
      "2100 steps | score: [0.02865716628730297, 0.026334114372730255]\n",
      "2200 steps | score: [-0.0036876783706247807, 0.026112083345651627]\n",
      "2300 steps | score: [-0.015621399506926537, 0.03910759836435318]\n",
      "2400 steps | score: [0.002886832458898425, 0.039687156677246094]\n",
      "2500 steps | score: [0.021635504439473152, 0.02703925035893917]\n",
      "2600 steps | score: [0.019356343895196915, 0.02590247616171837]\n",
      "0 steps | score: [-0.002358807483687997, 0.03240237012505531]\n",
      "100 steps | score: [-0.09300723671913147, 0.04409480839967728]\n",
      "200 steps | score: [0.022383926436305046, 0.03221382573246956]\n",
      "300 steps | score: [0.00441651651635766, -0.004433486610651016]\n",
      "unknown params:  tensor([-0.4018, -0.4828])\n",
      "unknown variance:  tensor([[0.8515]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4312, -0.5844])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.032502226531505585]\n",
      "100 steps | score: [-0.014464527368545532]\n",
      "200 steps | score: [-0.02939184010028839]\n",
      "300 steps | score: [0.0052560195326805115]\n",
      "0 steps | score: [0.029014257714152336, 0.11384817957878113]\n",
      "100 steps | score: [0.03945842757821083, -0.08734076470136642]\n",
      "200 steps | score: [-0.0014251932734623551, -0.007792774122208357]\n",
      "0 steps | score: [0.07567068189382553, 0.10763231664896011]\n",
      "100 steps | score: [0.07800135761499405, -0.09235487878322601]\n",
      "200 steps | score: [0.03202972561120987, -0.013294760137796402]\n",
      "300 steps | score: [0.08703232556581497, -0.04437818005681038]\n",
      "400 steps | score: [-0.05475996434688568, 0.10175681859254837]\n",
      "500 steps | score: [0.02128085307776928, -0.03246580436825752]\n",
      "600 steps | score: [0.026334157213568687, 0.0063841030932962894]\n",
      "700 steps | score: [0.04495522007346153, -0.01766311191022396]\n",
      "800 steps | score: [-0.0637730062007904, 0.08070941269397736]\n",
      "900 steps | score: [-0.0048657250590622425, -0.0041297422721982]\n",
      "0 steps | score: [0.10651742666959763, 0.057522907853126526]\n",
      "100 steps | score: [0.10102559626102448, -0.12213384360074997]\n",
      "200 steps | score: [0.05964721366763115, -0.04902765899896622]\n",
      "300 steps | score: [0.11797758936882019, -0.0787271112203598]\n",
      "400 steps | score: [-0.04036547243595123, 0.05479373037815094]\n",
      "500 steps | score: [0.03983956202864647, -0.06953604519367218]\n",
      "600 steps | score: [0.04525693878531456, -0.030751993879675865]\n",
      "700 steps | score: [0.07265835255384445, -0.057088300585746765]\n",
      "800 steps | score: [-0.033527035266160965, 0.03731489181518555]\n",
      "900 steps | score: [0.033626191318035126, -0.0544482059776783]\n",
      "1000 steps | score: [0.044582150876522064, -0.03718116134405136]\n",
      "1100 steps | score: [0.07555606961250305, -0.06378990411758423]\n",
      "1200 steps | score: [-0.01622672565281391, 0.0229075588285923]\n",
      "1300 steps | score: [0.027389291673898697, -0.030096502974629402]\n",
      "1400 steps | score: [0.050669312477111816, -0.043909840285778046]\n",
      "1500 steps | score: [0.062352970242500305, -0.052846819162368774]\n",
      "1600 steps | score: [0.00982759427279234, -0.002087655244395137]\n",
      "unknown params:  tensor([-0.4299, -0.5350])\n",
      "unknown variance:  tensor([[0.9068]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4312, -0.5844])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.22948066890239716]\n",
      "100 steps | score: [0.14848479628562927]\n",
      "200 steps | score: [0.1571679562330246]\n",
      "300 steps | score: [0.13385345041751862]\n",
      "400 steps | score: [0.06226062774658203]\n",
      "500 steps | score: [0.13911888003349304]\n",
      "600 steps | score: [0.15223270654678345]\n",
      "700 steps | score: [0.1206684410572052]\n",
      "800 steps | score: [0.011307694017887115]\n",
      "900 steps | score: [0.13818798959255219]\n",
      "1000 steps | score: [0.09598053991794586]\n",
      "1100 steps | score: [0.05459001660346985]\n",
      "1200 steps | score: [0.024732835590839386]\n",
      "1300 steps | score: [0.0870337188243866]\n",
      "1400 steps | score: [0.12379094213247299]\n",
      "1500 steps | score: [0.06578053534030914]\n",
      "1600 steps | score: [0.06005868315696716]\n",
      "1700 steps | score: [0.1149081364274025]\n",
      "1800 steps | score: [0.10797710716724396]\n",
      "1900 steps | score: [0.05191153287887573]\n",
      "2000 steps | score: [0.08584214746952057]\n",
      "2100 steps | score: [0.120207779109478]\n",
      "2200 steps | score: [0.07461030781269073]\n",
      "2300 steps | score: [0.0471726730465889]\n",
      "2400 steps | score: [0.09674343466758728]\n",
      "2500 steps | score: [0.10082730650901794]\n",
      "0 steps | score: [0.11981741338968277, 0.1198265552520752]\n",
      "100 steps | score: [0.0885520949959755, -0.04937900975346565]\n",
      "200 steps | score: [0.12955690920352936, -0.08756744116544724]\n",
      "300 steps | score: [0.0675661638379097, -0.008295235224068165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 steps | score: [-0.005493675358593464, 0.04471958428621292]\n",
      "500 steps | score: [0.08021383732557297, -0.004627529997378588]\n",
      "600 steps | score: [0.10699779540300369, -0.0710727870464325]\n",
      "700 steps | score: [0.06192683055996895, 0.020039068534970284]\n",
      "800 steps | score: [-0.027906125411391258, 0.051513321697711945]\n",
      "900 steps | score: [0.06955388188362122, 0.0172369834035635]\n",
      "1000 steps | score: [0.05020299181342125, 0.010461610741913319]\n",
      "1100 steps | score: [0.00019086820248048753, 0.0501110777258873]\n",
      "1200 steps | score: [-0.0015394937945529819, 0.04432709142565727]\n",
      "1300 steps | score: [0.04597316309809685, 0.027271097525954247]\n",
      "1400 steps | score: [0.06226978823542595, -0.012899143621325493]\n",
      "1500 steps | score: [0.013489437289536, 0.03327884152531624]\n",
      "1600 steps | score: [0.029181448742747307, 0.013585109263658524]\n",
      "1700 steps | score: [0.08083260804414749, -0.018507178872823715]\n",
      "1800 steps | score: [0.04797247797250748, 0.008024927228689194]\n",
      "1900 steps | score: [0.009723853319883347, 0.04267202690243721]\n",
      "2000 steps | score: [0.03718657046556473, 0.018539685755968094]\n",
      "2100 steps | score: [0.059324417263269424, -0.009176073595881462]\n",
      "2200 steps | score: [0.0358198918402195, 0.021363478153944016]\n",
      "2300 steps | score: [0.0063352882862091064, 0.03813259303569794]\n",
      "2400 steps | score: [0.033469028770923615, 0.027560705319046974]\n",
      "2500 steps | score: [0.0491069070994854, 0.002060751896351576]\n",
      "0 steps | score: [0.08715671300888062, 0.04797711968421936]\n",
      "100 steps | score: [0.04828959330916405, -0.10266567766666412]\n",
      "200 steps | score: [0.08183740079402924, -0.1434575617313385]\n",
      "300 steps | score: [0.045144595205783844, -0.08255260437726974]\n",
      "400 steps | score: [-0.02828332781791687, -0.01985979452729225]\n",
      "500 steps | score: [0.05123616009950638, -0.07149779051542282]\n",
      "600 steps | score: [0.06544718146324158, -0.12387983500957489]\n",
      "700 steps | score: [0.021262846887111664, -0.045498088002204895]\n",
      "800 steps | score: [-0.059159260243177414, -0.01915084943175316]\n",
      "900 steps | score: [0.033560123294591904, -0.04673823341727257]\n",
      "1000 steps | score: [0.010949993506073952, -0.05099067836999893]\n",
      "1100 steps | score: [-0.02350512519478798, -0.01831435039639473]\n",
      "1200 steps | score: [-0.03172749653458595, -0.027977850288152695]\n",
      "1300 steps | score: [0.016926800832152367, -0.04769454523921013]\n",
      "1400 steps | score: [0.029593871906399727, -0.07662037014961243]\n",
      "1500 steps | score: [-0.01799977757036686, -0.029065074399113655]\n",
      "1600 steps | score: [-0.006228071171790361, -0.047474417835474014]\n",
      "1700 steps | score: [0.03921984136104584, -0.08224378526210785]\n",
      "1800 steps | score: [0.00627862336114049, -0.057917747646570206]\n",
      "1900 steps | score: [-0.02729584462940693, -0.02940545231103897]\n",
      "2000 steps | score: [-0.0005842173704877496, -0.04456188529729843]\n",
      "2100 steps | score: [0.023079928010702133, -0.07050815969705582]\n",
      "2200 steps | score: [0.008334091864526272, -0.046757813543081284]\n",
      "2300 steps | score: [-0.02346503734588623, -0.03015133924782276]\n",
      "2400 steps | score: [-0.0007815264398232102, -0.03902497515082359]\n",
      "2500 steps | score: [0.013920577242970467, -0.05536920949816704]\n",
      "0 steps | score: [0.047002311795949936, 0.12437005341053009]\n",
      "100 steps | score: [0.03258342295885086, -0.05291127413511276]\n",
      "200 steps | score: [0.06032470241189003, -0.08446098864078522]\n",
      "300 steps | score: [0.02749677561223507, -0.023312559351325035]\n",
      "400 steps | score: [-0.0646214410662651, 0.0536823645234108]\n",
      "500 steps | score: [0.02374742180109024, -0.007979854010045528]\n",
      "600 steps | score: [0.04874316230416298, -0.06280715018510818]\n",
      "700 steps | score: [-0.0015300217783078551, 0.019630420953035355]\n",
      "800 steps | score: [-0.08643122762441635, 0.04784787818789482]\n",
      "900 steps | score: [0.008533635176718235, 0.01257760263979435]\n",
      "1000 steps | score: [-0.006964703090488911, 0.012399571016430855]\n",
      "1100 steps | score: [-0.05450185760855675, 0.04572632908821106]\n",
      "1200 steps | score: [-0.06843556463718414, 0.03769791126251221]\n",
      "1300 steps | score: [-0.006192737724632025, 0.013081883080303669]\n",
      "1400 steps | score: [0.004300014581531286, -0.012596288695931435]\n",
      "1500 steps | score: [-0.04204824939370155, 0.03179085627198219]\n",
      "1600 steps | score: [-0.03671548143029213, 0.016399767249822617]\n",
      "1700 steps | score: [0.015212827362120152, -0.013089563697576523]\n",
      "1800 steps | score: [-0.015203773975372314, 0.00572153739631176]\n",
      "1900 steps | score: [-0.04742704704403877, 0.03471577167510986]\n",
      "2000 steps | score: [-0.021723710000514984, 0.016451187431812286]\n",
      "2100 steps | score: [-0.002333841286599636, -0.005350632593035698]\n",
      "unknown params:  tensor([-0.4189, -0.5324])\n",
      "unknown variance:  tensor([[0.9321]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4312, -0.5844])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.12957808375358582]\n",
      "100 steps | score: [-0.003863663412630558]\n",
      "0 steps | score: [0.15093621611595154, 0.11705071479082108]\n",
      "100 steps | score: [0.0598754808306694, -0.04192639887332916]\n",
      "200 steps | score: [0.1681458204984665, -0.10092195123434067]\n",
      "300 steps | score: [0.05033889412879944, -0.007617871277034283]\n",
      "400 steps | score: [-0.053561627864837646, 0.06555794179439545]\n",
      "500 steps | score: [0.058742720633745193, 0.05296335369348526]\n",
      "600 steps | score: [0.10100588202476501, -0.04386519268155098]\n",
      "700 steps | score: [-0.05432603508234024, 0.08986968547105789]\n",
      "800 steps | score: [0.05740956589579582, -0.020659932866692543]\n",
      "900 steps | score: [0.14621204137802124, -0.08179968595504761]\n",
      "1000 steps | score: [0.022383717820048332, 0.03551880270242691]\n",
      "1100 steps | score: [-0.02658594213426113, 0.05165637284517288]\n",
      "1200 steps | score: [0.05867502838373184, 0.0191586222499609]\n",
      "1300 steps | score: [0.08609174937009811, -0.026998674497008324]\n",
      "1400 steps | score: [0.013490842655301094, 0.032608672976493835]\n",
      "1500 steps | score: [0.059556230902671814, -0.007674866355955601]\n",
      "1600 steps | score: [0.09775771200656891, -0.03448395058512688]\n",
      "1700 steps | score: [0.03337135910987854, 0.01878993958234787]\n",
      "1800 steps | score: [-0.02001403644680977, 0.06334272027015686]\n",
      "1900 steps | score: [0.05304338410496712, 0.005381062626838684]\n",
      "2000 steps | score: [0.059062398970127106, -0.006407118868082762]\n",
      "2100 steps | score: [0.012069535441696644, 0.03464102745056152]\n",
      "2200 steps | score: [0.02528522163629532, 0.020837977528572083]\n",
      "2300 steps | score: [0.07513099163770676, -0.018702290952205658]\n",
      "2400 steps | score: [0.03497397154569626, 0.012996561825275421]\n",
      "2500 steps | score: [0.01984657160937786, 0.03318732976913452]\n",
      "2600 steps | score: [0.049223072826862335, 0.004060855135321617]\n",
      "2700 steps | score: [0.06046481430530548, -0.011055881157517433]\n",
      "0 steps | score: [0.0449349470436573, 0.14197909832000732]\n",
      "100 steps | score: [-0.024962862953543663, -0.027210703119635582]\n",
      "200 steps | score: [0.07878364622592926, -0.06948266178369522]\n",
      "300 steps | score: [-0.025489725172519684, 0.008027604781091213]\n",
      "400 steps | score: [-0.14852234721183777, 0.09877601265907288]\n",
      "500 steps | score: [-0.0309118814766407, 0.07868414372205734]\n",
      "600 steps | score: [0.033045291900634766, -0.03402252122759819]\n",
      "700 steps | score: [-0.13553094863891602, 0.11276186257600784]\n",
      "800 steps | score: [-0.027955258265137672, 0.004227062221616507]\n",
      "900 steps | score: [0.06200653687119484, -0.06572003662586212]\n",
      "1000 steps | score: [-0.05772460624575615, 0.0501694418489933]\n",
      "1100 steps | score: [-0.10333405435085297, 0.0749000608921051]\n",
      "1200 steps | score: [-0.037762902677059174, 0.03941798582673073]\n",
      "1300 steps | score: [-0.0024319132789969444, -0.005791069008409977]\n",
      "0 steps | score: [0.12972474098205566, 0.049505434930324554]\n",
      "100 steps | score: [0.03720767796039581, -0.10050327330827713]\n",
      "200 steps | score: [0.12976181507110596, -0.1478852778673172]\n",
      "300 steps | score: [0.022942213341593742, -0.060620181262493134]\n",
      "400 steps | score: [-0.0769045352935791, 0.01691073179244995]\n",
      "500 steps | score: [0.03571488708257675, -0.007387241348624229]\n",
      "600 steps | score: [0.0963776633143425, -0.11082319915294647]\n",
      "700 steps | score: [-0.06584059447050095, 0.033044859766960144]\n",
      "800 steps | score: [0.045329224318265915, -0.08576616644859314]\n",
      "900 steps | score: [0.10259691625833511, -0.129604309797287]\n",
      "1000 steps | score: [-0.0025299875997006893, -0.020769216120243073]\n",
      "1100 steps | score: [-0.04873640090227127, -0.012405735440552235]\n",
      "1200 steps | score: [0.030481811612844467, -0.03499738126993179]\n",
      "1300 steps | score: [0.05128054320812225, -0.07836513966321945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 steps | score: [-0.0027889132034033537, -0.029580971226096153]\n",
      "1500 steps | score: [0.041203636676073074, -0.06995604932308197]\n",
      "1600 steps | score: [0.07638047635555267, -0.08976175636053085]\n",
      "1700 steps | score: [0.0009308754233643413, -0.029172345995903015]\n",
      "1800 steps | score: [-0.04980885237455368, 0.010235863737761974]\n",
      "1900 steps | score: [0.026100320741534233, -0.051777709275484085]\n",
      "2000 steps | score: [0.04791140556335449, -0.07420911639928818]\n",
      "2100 steps | score: [-0.0013617300428450108, -0.02842187136411667]\n",
      "2200 steps | score: [0.014497010968625546, -0.045176561921834946]\n",
      "2300 steps | score: [0.04990355670452118, -0.07509636133909225]\n",
      "2400 steps | score: [0.010329466313123703, -0.03618965297937393]\n",
      "2500 steps | score: [-0.0019157167989760637, -0.0268089659512043]\n",
      "2600 steps | score: [0.026788754388689995, -0.05455896258354187]\n",
      "2700 steps | score: [0.04996301978826523, -0.07115014642477036]\n",
      "unknown params:  tensor([-0.4590, -0.5926])\n",
      "unknown variance:  tensor([[1.0133]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4312, -0.5844])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.09675880521535873]\n",
      "100 steps | score: [0.033400408923625946]\n",
      "200 steps | score: [0.04080528765916824]\n",
      "300 steps | score: [-0.14091208577156067]\n",
      "400 steps | score: [-0.0007249750196933746]\n",
      "0 steps | score: [0.06638733297586441, 0.1720571219921112]\n",
      "100 steps | score: [0.07568380981683731, -0.01499249879270792]\n",
      "200 steps | score: [0.003924376796931028, 0.0504356250166893]\n",
      "300 steps | score: [-0.1344284564256668, 0.17769986391067505]\n",
      "400 steps | score: [0.023551393300294876, 0.005181537941098213]\n",
      "500 steps | score: [0.06119493395090103, -0.04485771059989929]\n",
      "600 steps | score: [-0.10163083672523499, 0.13654538989067078]\n",
      "700 steps | score: [-0.15833556652069092, 0.18938224017620087]\n",
      "800 steps | score: [0.05197693780064583, -0.03143550455570221]\n",
      "900 steps | score: [-0.05928850919008255, 0.08171159029006958]\n",
      "1000 steps | score: [-0.0931263118982315, 0.10934927314519882]\n",
      "1100 steps | score: [-0.020197514444589615, 0.05861338973045349]\n",
      "1200 steps | score: [-0.022328035905957222, 0.04407539218664169]\n",
      "1300 steps | score: [-0.072967030107975, 0.09285973012447357]\n",
      "1400 steps | score: [-0.015829401090741158, 0.05689515918493271]\n",
      "1500 steps | score: [0.0329023078083992, -0.011424383148550987]\n",
      "1600 steps | score: [-0.08210683614015579, 0.10305416584014893]\n",
      "1700 steps | score: [-0.02988344430923462, 0.05917241424322128]\n",
      "1800 steps | score: [-0.004367262590676546, 0.034019194543361664]\n",
      "1900 steps | score: [-0.09919611364603043, 0.1286115050315857]\n",
      "2000 steps | score: [-0.03166528791189194, 0.0647440105676651]\n",
      "2100 steps | score: [0.004691823851317167, 0.021649450063705444]\n",
      "2200 steps | score: [-0.05080901086330414, 0.07998229563236237]\n",
      "2300 steps | score: [-0.04805386811494827, 0.0749468132853508]\n",
      "2400 steps | score: [-0.007959764450788498, 0.03430499508976936]\n",
      "2500 steps | score: [-0.037551768124103546, 0.06408447027206421]\n",
      "0 steps | score: [0.1723872423171997, 0.06368889659643173]\n",
      "100 steps | score: [0.1784173846244812, -0.12533879280090332]\n",
      "200 steps | score: [0.06568380445241928, -0.02299749106168747]\n",
      "300 steps | score: [-0.05806119367480278, 0.09694807231426239]\n",
      "400 steps | score: [0.08147744834423065, -0.07428115606307983]\n",
      "500 steps | score: [0.13614587485790253, -0.12303756922483444]\n",
      "600 steps | score: [-0.015822088345885277, 0.05610602721571922]\n",
      "700 steps | score: [-0.08833055198192596, 0.10917873680591583]\n",
      "800 steps | score: [0.1353921741247177, -0.1260434091091156]\n",
      "900 steps | score: [0.03113623894751072, -0.012204743921756744]\n",
      "1000 steps | score: [-0.016621895134449005, 0.02412243001163006]\n",
      "1100 steps | score: [0.06201986223459244, -0.03231663256883621]\n",
      "1200 steps | score: [0.0551462396979332, -0.041647620499134064]\n",
      "1300 steps | score: [0.00048805217375047505, 0.007148383650928736]\n",
      "0 steps | score: [0.08267568796873093, 0.1336493194103241]\n",
      "100 steps | score: [0.08620136231184006, -0.04606468230485916]\n",
      "200 steps | score: [0.03633207455277443, -0.01244262233376503]\n",
      "300 steps | score: [-0.14480365812778473, 0.16091684997081757]\n",
      "400 steps | score: [0.018640441820025444, -0.012522947043180466]\n",
      "500 steps | score: [0.06601998209953308, -0.07402752339839935]\n",
      "600 steps | score: [-0.08108341693878174, 0.10050123184919357]\n",
      "700 steps | score: [-0.15028400719165802, 0.16226458549499512]\n",
      "800 steps | score: [0.05517866089940071, -0.05303819105029106]\n",
      "900 steps | score: [-0.05495346710085869, 0.06301034986972809]\n",
      "1000 steps | score: [-0.08089971542358398, 0.0825502946972847]\n",
      "1100 steps | score: [0.0020190058276057243, 0.013129223138093948]\n",
      "1200 steps | score: [-0.014694386161863804, 0.015179932117462158]\n",
      "1300 steps | score: [-0.06068449094891548, 0.06047843024134636]\n",
      "1400 steps | score: [-0.006644127890467644, 0.024995211511850357]\n",
      "1500 steps | score: [0.039115168154239655, -0.04196330904960632]\n",
      "1600 steps | score: [-0.07391021400690079, 0.07120606303215027]\n",
      "1700 steps | score: [-0.016896886751055717, 0.02677737921476364]\n",
      "1800 steps | score: [0.005554484203457832, 0.0030241310596466064]\n",
      "unknown params:  tensor([-0.4745, -0.6483])\n",
      "unknown variance:  tensor([[1.0356]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4312, -0.5844])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.22364003956317902]\n",
      "100 steps | score: [0.12159140408039093]\n",
      "200 steps | score: [0.009801261126995087]\n",
      "0 steps | score: [0.08251728117465973, 0.17499610781669617]\n",
      "100 steps | score: [0.11559542268514633, -0.060401417315006256]\n",
      "200 steps | score: [-0.08913706988096237, 0.17785432934761047]\n",
      "300 steps | score: [-0.04866388812661171, 0.10014915466308594]\n",
      "400 steps | score: [0.00805332325398922, 0.04333362728357315]\n",
      "500 steps | score: [0.001823010970838368, 0.036096055060625076]\n",
      "600 steps | score: [-0.06738860160112381, 0.0952301025390625]\n",
      "700 steps | score: [-0.01228670496493578, 0.06291287392377853]\n",
      "800 steps | score: [0.02224484272301197, 0.007034958805888891]\n",
      "900 steps | score: [-0.04404084011912346, 0.0850740373134613]\n",
      "1000 steps | score: [-0.06329965591430664, 0.12558037042617798]\n",
      "1100 steps | score: [-0.01019794400781393, 0.04979370906949043]\n",
      "1200 steps | score: [-0.047186627984046936, 0.09199420362710953]\n",
      "1300 steps | score: [-0.052055589854717255, 0.1055489033460617]\n",
      "1400 steps | score: [-0.01671375334262848, 0.055931221693754196]\n",
      "1500 steps | score: [-0.09170453995466232, 0.14455458521842957]\n",
      "1600 steps | score: [-0.037451013922691345, 0.09261118620634079]\n",
      "1700 steps | score: [-0.02470368891954422, 0.07396451383829117]\n",
      "1800 steps | score: [-0.11165756732225418, 0.17171712219715118]\n",
      "1900 steps | score: [-0.00046534230932593346, 0.03427361324429512]\n",
      "2000 steps | score: [-0.043799594044685364, 0.08989569544792175]\n",
      "2100 steps | score: [-0.084937185049057, 0.13554765284061432]\n",
      "2200 steps | score: [0.00331316702067852, 0.03312699869275093]\n",
      "2300 steps | score: [-0.050130151212215424, 0.09338343888521194]\n",
      "2400 steps | score: [-0.04742823913693428, 0.08904552459716797]\n",
      "2500 steps | score: [0.0012956507271155715, 0.027731407433748245]\n",
      "2600 steps | score: [-0.05444764718413353, 0.0980401560664177]\n",
      "0 steps | score: [0.15676455199718475, -0.0030890358611941338]\n",
      "100 steps | score: [0.1726713478565216, -0.23589074611663818]\n",
      "200 steps | score: [-0.020377639681100845, 0.008847956545650959]\n",
      "300 steps | score: [0.012170160189270973, -0.06700413674116135]\n",
      "400 steps | score: [0.0594949871301651, -0.11057420074939728]\n",
      "500 steps | score: [0.08012097328901291, -0.14516304433345795]\n",
      "600 steps | score: [0.005194550380110741, -0.07409290969371796]\n",
      "700 steps | score: [0.048195190727710724, -0.1033702939748764]\n",
      "800 steps | score: [0.10238583385944366, -0.1771172732114792]\n",
      "900 steps | score: [0.02675555646419525, -0.09158049523830414]\n",
      "1000 steps | score: [-0.002214689739048481, -0.036144547164440155]\n",
      "1100 steps | score: [0.048284389078617096, -0.11733755469322205]\n",
      "1200 steps | score: [0.01957841031253338, -0.07590807229280472]\n",
      "1300 steps | score: [0.010108741000294685, -0.0578264445066452]\n",
      "1400 steps | score: [0.04829308018088341, -0.11982966959476471]\n",
      "1500 steps | score: [-0.023175733163952827, -0.021629881113767624]\n",
      "1600 steps | score: [0.018278485164046288, -0.0799010694026947]\n",
      "1700 steps | score: [0.04622766003012657, -0.10528184473514557]\n",
      "1800 steps | score: [-0.04462231695652008, 0.0067797331139445305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [0.061698783189058304, -0.13956816494464874]\n",
      "2000 steps | score: [0.02608499303460121, -0.07554639875888824]\n",
      "2100 steps | score: [-0.01589251682162285, -0.034098803997039795]\n",
      "2200 steps | score: [0.0677918866276741, -0.1395699679851532]\n",
      "2300 steps | score: [0.013668463565409184, -0.05937642604112625]\n",
      "2400 steps | score: [0.010473527945578098, -0.06293032318353653]\n",
      "2500 steps | score: [0.0749683827161789, -0.14728513360023499]\n",
      "2600 steps | score: [0.006799515802413225, -0.06198612228035927]\n",
      "0 steps | score: [0.10599812865257263, 0.15792815387248993]\n",
      "100 steps | score: [0.14168229699134827, -0.08122211694717407]\n",
      "200 steps | score: [-0.07657024264335632, 0.1730850636959076]\n",
      "300 steps | score: [-0.02993081323802471, 0.07598117738962173]\n",
      "400 steps | score: [0.009791618213057518, 0.057005204260349274]\n",
      "500 steps | score: [0.0320066474378109, 0.013961654156446457]\n",
      "600 steps | score: [-0.04270004481077194, 0.081133171916008]\n",
      "700 steps | score: [0.01281248964369297, 0.0343872606754303]\n",
      "800 steps | score: [0.03792853280901909, 0.005369063466787338]\n",
      "900 steps | score: [-0.03446846827864647, 0.07792702317237854]\n",
      "1000 steps | score: [-0.03987477347254753, 0.11962535977363586]\n",
      "1100 steps | score: [0.012925232760608196, 0.030876247212290764]\n",
      "1200 steps | score: [-0.03452316299080849, 0.07873069494962692]\n",
      "1300 steps | score: [-0.04553204029798508, 0.10454477369785309]\n",
      "1400 steps | score: [0.015571730211377144, 0.024411305785179138]\n",
      "1500 steps | score: [-0.06015994772315025, 0.11842309683561325]\n",
      "1600 steps | score: [-0.022956423461437225, 0.07449133694171906]\n",
      "1700 steps | score: [-0.00514434976503253, 0.054916862398386]\n",
      "1800 steps | score: [-0.09209845960140228, 0.15715087950229645]\n",
      "1900 steps | score: [0.011635887436568737, 0.030554749071598053]\n",
      "2000 steps | score: [-0.028402205556631088, 0.08465489745140076]\n",
      "2100 steps | score: [-0.05211186036467552, 0.11470752954483032]\n",
      "2200 steps | score: [0.01849059946835041, 0.017366038635373116]\n",
      "2300 steps | score: [-0.04296453297138214, 0.0943218395113945]\n",
      "2400 steps | score: [-0.03360636159777641, 0.08900198340415955]\n",
      "2500 steps | score: [0.014476078562438488, 0.025955015793442726]\n",
      "2600 steps | score: [-0.04130392521619797, 0.08812463283538818]\n",
      "unknown params:  tensor([-0.4882, -0.8356])\n",
      "unknown variance:  tensor([[1.0792]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4312, -0.5844])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.05086134001612663]\n",
      "100 steps | score: [-0.09152217954397202]\n",
      "200 steps | score: [-0.0479082427918911]\n",
      "300 steps | score: [-0.13888710737228394]\n",
      "400 steps | score: [-0.14471735060214996]\n",
      "500 steps | score: [-0.1139085441827774]\n",
      "600 steps | score: [-0.10249924659729004]\n",
      "700 steps | score: [-0.053544238209724426]\n",
      "800 steps | score: [-0.16064618527889252]\n",
      "900 steps | score: [-0.09223496168851852]\n",
      "1000 steps | score: [-0.07557366788387299]\n",
      "1100 steps | score: [-0.17787671089172363]\n",
      "1200 steps | score: [-0.12721987068653107]\n",
      "1300 steps | score: [-0.14759933948516846]\n",
      "1400 steps | score: [-0.16238445043563843]\n",
      "1500 steps | score: [-0.10720042884349823]\n",
      "1600 steps | score: [-0.15986864268779755]\n",
      "1700 steps | score: [-0.1074715182185173]\n",
      "1800 steps | score: [-0.0962250828742981]\n",
      "1900 steps | score: [-0.16576553881168365]\n",
      "2000 steps | score: [-0.12015030533075333]\n",
      "2100 steps | score: [-0.1143127903342247]\n",
      "2200 steps | score: [-0.11850503832101822]\n",
      "2300 steps | score: [-0.12048982083797455]\n",
      "2400 steps | score: [-0.13712939620018005]\n",
      "2500 steps | score: [-0.11591188609600067]\n",
      "2600 steps | score: [-0.12688586115837097]\n",
      "0 steps | score: [0.11938824504613876, 0.16814889013767242]\n",
      "100 steps | score: [0.003382454626262188, 0.1412629783153534]\n",
      "200 steps | score: [0.1574147790670395, -0.15683749318122864]\n",
      "300 steps | score: [-0.023290015757083893, 0.08943921327590942]\n",
      "400 steps | score: [0.06320078670978546, -0.032007280737161636]\n",
      "500 steps | score: [-0.03957822546362877, 0.14683866500854492]\n",
      "600 steps | score: [0.006117453332990408, 0.06188587844371796]\n",
      "700 steps | score: [0.007687124889343977, 0.05848453566431999]\n",
      "800 steps | score: [-0.06114853546023369, 0.15953172743320465]\n",
      "900 steps | score: [0.07443377375602722, -0.041477516293525696]\n",
      "1000 steps | score: [0.05070580914616585, -0.014965862967073917]\n",
      "1100 steps | score: [-0.09314680844545364, 0.20155069231987]\n",
      "1200 steps | score: [0.024216894060373306, 0.021294955164194107]\n",
      "1300 steps | score: [-0.09577144682407379, 0.20677323639392853]\n",
      "1400 steps | score: [-0.015181557275354862, 0.09458839893341064]\n",
      "1500 steps | score: [-0.01777421124279499, 0.09500660002231598]\n",
      "1600 steps | score: [-0.05033203586935997, 0.13188618421554565]\n",
      "1700 steps | score: [-0.01597234606742859, 0.1010412648320198]\n",
      "1800 steps | score: [0.024088576436042786, 0.03516358882188797]\n",
      "1900 steps | score: [-0.07837250083684921, 0.17999514937400818]\n",
      "2000 steps | score: [0.026643482968211174, 0.027698205783963203]\n",
      "2100 steps | score: [-0.07460594922304153, 0.17093655467033386]\n",
      "2200 steps | score: [-0.01713549718260765, 0.07716682553291321]\n",
      "2300 steps | score: [-0.0011495077051222324, 0.07460248470306396]\n",
      "2400 steps | score: [-0.07053432613611221, 0.17104263603687286]\n",
      "2500 steps | score: [-0.03438851982355118, 0.10871065407991409]\n",
      "2600 steps | score: [-0.010419394820928574, 0.08187942951917648]\n",
      "0 steps | score: [0.18526138365268707, -0.010849019512534142]\n",
      "100 steps | score: [0.050650205463171005, -0.011869747191667557]\n",
      "200 steps | score: [0.22315175831317902, -0.3406407833099365]\n",
      "300 steps | score: [0.02958431839942932, -0.060391660779714584]\n",
      "400 steps | score: [0.10910751670598984, -0.19589906930923462]\n",
      "500 steps | score: [-0.008664186112582684, 0.011112464591860771]\n",
      "600 steps | score: [0.04877033829689026, -0.07613860070705414]\n",
      "700 steps | score: [0.06751690804958344, -0.10428366810083389]\n",
      "800 steps | score: [-0.016631215810775757, 0.01757112145423889]\n",
      "900 steps | score: [0.11666896939277649, -0.18887284398078918]\n",
      "1000 steps | score: [0.08930078893899918, -0.1462392508983612]\n",
      "1100 steps | score: [-0.020456993952393532, 0.015900924801826477]\n",
      "1200 steps | score: [0.08093207329511642, -0.13853728771209717]\n",
      "1300 steps | score: [-0.045984625816345215, 0.05834370106458664]\n",
      "1400 steps | score: [0.028272662311792374, -0.06407023966312408]\n",
      "1500 steps | score: [0.03795359283685684, -0.06133858859539032]\n",
      "1600 steps | score: [0.007777937687933445, -0.01980942115187645]\n",
      "1700 steps | score: [0.02819187194108963, -0.05668805539608002]\n",
      "1800 steps | score: [0.07320334017276764, -0.10768663138151169]\n",
      "1900 steps | score: [-0.03475799039006233, 0.029409309849143028]\n",
      "2000 steps | score: [0.0759991928935051, -0.13119569420814514]\n",
      "2100 steps | score: [-0.03494712710380554, 0.02506834827363491]\n",
      "2200 steps | score: [0.026005418971180916, -0.0627717524766922]\n",
      "2300 steps | score: [0.05001207813620567, -0.09017407894134521]\n",
      "2400 steps | score: [-0.011975552886724472, 0.004815427586436272]\n",
      "2500 steps | score: [0.010099436156451702, -0.029111677780747414]\n",
      "2600 steps | score: [0.03597649186849594, -0.057968202978372574]\n",
      "0 steps | score: [0.21217036247253418, -0.08248516172170639]\n",
      "100 steps | score: [0.06258139759302139, -0.06395617872476578]\n",
      "200 steps | score: [0.22988246381282806, -0.3786718547344208]\n",
      "300 steps | score: [0.042525459080934525, -0.11588650941848755]\n",
      "400 steps | score: [0.11578420549631119, -0.232786625623703]\n",
      "500 steps | score: [0.010520522482693195, -0.041268616914749146]\n",
      "600 steps | score: [0.06467053294181824, -0.13787689805030823]\n",
      "700 steps | score: [0.09614527970552444, -0.18769198656082153]\n",
      "800 steps | score: [0.01044982485473156, -0.050346702337265015]\n",
      "900 steps | score: [0.15647226572036743, -0.28196343779563904]\n",
      "1000 steps | score: [0.115753173828125, -0.22529266774654388]\n",
      "1100 steps | score: [-0.014149359427392483, -0.02548956498503685]\n",
      "1200 steps | score: [0.10317788273096085, -0.20158495008945465]\n",
      "1300 steps | score: [-0.020687324926257133, -0.005994429811835289]\n",
      "1400 steps | score: [0.04167981445789337, -0.11366008222103119]\n",
      "1500 steps | score: [0.056052710860967636, -0.12775591015815735]\n",
      "1600 steps | score: [0.026528125628829002, -0.089934341609478]\n",
      "1700 steps | score: [0.05517690256237984, -0.11931782215833664]\n",
      "1800 steps | score: [0.09749223291873932, -0.19269613921642303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 steps | score: [-0.014829736202955246, -0.028346125036478043]\n",
      "2000 steps | score: [0.11014866828918457, -0.21546120941638947]\n",
      "2100 steps | score: [0.0011269694659858942, -0.050476886332035065]\n",
      "2200 steps | score: [0.039516184478998184, -0.10289289802312851]\n",
      "2300 steps | score: [0.07523518055677414, -0.15502601861953735]\n",
      "2400 steps | score: [0.0070980144664645195, -0.06336748600006104]\n",
      "2500 steps | score: [0.029584290459752083, -0.0887821838259697]\n",
      "2600 steps | score: [0.05362448841333389, -0.1294746994972229]\n",
      "unknown params:  tensor([-0.5368, -1.0691])\n",
      "unknown variance:  tensor([[1.1775]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4312, -0.5844])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3174848258495331]\n",
      "100 steps | score: [0.1279090791940689]\n",
      "200 steps | score: [0.037781037390232086]\n",
      "300 steps | score: [0.08811208605766296]\n",
      "400 steps | score: [0.05664955824613571]\n",
      "500 steps | score: [0.0028999876230955124]\n",
      "0 steps | score: [0.17382501065731049, 0.011505957692861557]\n",
      "100 steps | score: [0.053727760910987854, 0.036253828555345535]\n",
      "200 steps | score: [-0.1060292050242424, 0.20992746949195862]\n",
      "300 steps | score: [-0.02223675325512886, 0.06300210952758789]\n",
      "400 steps | score: [0.0350949652493, -0.02603357844054699]\n",
      "500 steps | score: [-0.060416847467422485, 0.10830680280923843]\n",
      "600 steps | score: [0.1377277374267578, -0.23724499344825745]\n",
      "700 steps | score: [-0.10809898376464844, 0.19291403889656067]\n",
      "800 steps | score: [0.05821913480758667, -0.09588231891393661]\n",
      "900 steps | score: [0.046178773045539856, -0.06695124506950378]\n",
      "1000 steps | score: [0.10588964074850082, -0.1865350306034088]\n",
      "1100 steps | score: [-0.01251293160021305, 0.04074495658278465]\n",
      "1200 steps | score: [0.03459968790411949, -0.043975841253995895]\n",
      "1300 steps | score: [0.0830172672867775, -0.12117481231689453]\n",
      "1400 steps | score: [-0.09450093656778336, 0.17047971487045288]\n",
      "1500 steps | score: [0.022479690611362457, -0.02380995824933052]\n",
      "1600 steps | score: [0.024691903963685036, -0.030015574768185616]\n",
      "1700 steps | score: [-0.05423480644822121, 0.09334158897399902]\n",
      "1800 steps | score: [0.03050430305302143, -0.0407739132642746]\n",
      "1900 steps | score: [-0.03714775666594505, 0.07519733905792236]\n",
      "2000 steps | score: [0.01138023380190134, -0.0008877571672201157]\n",
      "2100 steps | score: [-0.02712065912783146, 0.05077764391899109]\n",
      "2200 steps | score: [0.02353222481906414, -0.02323426865041256]\n",
      "2300 steps | score: [0.08600553125143051, -0.1293838918209076]\n",
      "2400 steps | score: [-0.07526424527168274, 0.1372942477464676]\n",
      "2500 steps | score: [0.05067067965865135, -0.06174230948090553]\n",
      "0 steps | score: [0.07833497226238251, 0.142833411693573]\n",
      "100 steps | score: [-0.05123775824904442, 0.17064504325389862]\n",
      "200 steps | score: [-0.1860024482011795, 0.3158802092075348]\n",
      "300 steps | score: [-0.11718029528856277, 0.19863007962703705]\n",
      "400 steps | score: [-0.08514610677957535, 0.16085155308246613]\n",
      "500 steps | score: [-0.14626401662826538, 0.23658785223960876]\n",
      "600 steps | score: [0.05755177140235901, -0.12650658190250397]\n",
      "700 steps | score: [-0.20107720792293549, 0.31607142090797424]\n",
      "800 steps | score: [-0.031391892582178116, 0.035309046506881714]\n",
      "900 steps | score: [-0.03961764648556709, 0.05756961554288864]\n",
      "1000 steps | score: [0.051589235663414, -0.10560041666030884]\n",
      "1100 steps | score: [-0.08072708547115326, 0.13634943962097168]\n",
      "1200 steps | score: [-0.05763937905430794, 0.08655718713998795]\n",
      "1300 steps | score: [-0.020105881616473198, 0.01356431096792221]\n",
      "1400 steps | score: [-0.1772317737340927, 0.29044482111930847]\n",
      "1500 steps | score: [-0.04394618421792984, 0.06697863340377808]\n",
      "1600 steps | score: [-0.03958847001194954, 0.05638778582215309]\n",
      "1700 steps | score: [-0.12864309549331665, 0.20054423809051514]\n",
      "1800 steps | score: [-0.04589442163705826, 0.06983165442943573]\n",
      "1900 steps | score: [-0.12412837147712708, 0.19221735000610352]\n",
      "2000 steps | score: [-0.07452455908060074, 0.1220274567604065]\n",
      "2100 steps | score: [-0.1106293722987175, 0.16632740199565887]\n",
      "2200 steps | score: [-0.06344142556190491, 0.09202900528907776]\n",
      "2300 steps | score: [-0.015084744431078434, 0.012977182865142822]\n",
      "2400 steps | score: [-0.1542225331068039, 0.2397564947605133]\n",
      "2500 steps | score: [-0.03513161465525627, 0.04824589937925339]\n",
      "0 steps | score: [0.09609480947256088, 0.13972267508506775]\n",
      "100 steps | score: [-0.025983937084674835, 0.16425484418869019]\n",
      "200 steps | score: [-0.1567613184452057, 0.30442726612091064]\n",
      "300 steps | score: [-0.08339516818523407, 0.17590424418449402]\n",
      "400 steps | score: [-0.05627657473087311, 0.13939158618450165]\n",
      "500 steps | score: [-0.14310525357723236, 0.24386684596538544]\n",
      "600 steps | score: [0.09520567208528519, -0.16000355780124664]\n",
      "700 steps | score: [-0.1618136763572693, 0.2916976809501648]\n",
      "800 steps | score: [0.0014929362805560231, 0.003135768696665764]\n",
      "unknown params:  tensor([-0.5452, -1.2383])\n",
      "unknown variance:  tensor([[1.2914]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4312, -0.5844])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2632061541080475]\n",
      "100 steps | score: [0.05711125582456589]\n",
      "200 steps | score: [-0.015709087252616882]\n",
      "300 steps | score: [0.07259067893028259]\n",
      "400 steps | score: [-0.007967028766870499]\n",
      "0 steps | score: [0.18892480432987213, -0.014102291315793991]\n",
      "100 steps | score: [0.08058830350637436, 0.02703181840479374]\n",
      "200 steps | score: [-0.05645396187901497, 0.21378494799137115]\n",
      "300 steps | score: [-0.09372471272945404, 0.2417590320110321]\n",
      "400 steps | score: [-0.07940642535686493, 0.22139814496040344]\n",
      "500 steps | score: [-0.02879413776099682, 0.11851175129413605]\n",
      "600 steps | score: [-0.07507417351007462, 0.2167237102985382]\n",
      "700 steps | score: [-0.034410636872053146, 0.12318503856658936]\n",
      "800 steps | score: [0.046250615268945694, -0.0032808594405651093]\n",
      "900 steps | score: [0.019207043573260307, 0.007409527897834778]\n",
      "1000 steps | score: [-0.030795300379395485, 0.11303139477968216]\n",
      "1100 steps | score: [0.03472768887877464, -0.011927682906389236]\n",
      "1200 steps | score: [0.052587926387786865, -0.02127102017402649]\n",
      "1300 steps | score: [0.025399839505553246, -0.008226495236158371]\n",
      "1400 steps | score: [0.051903434097766876, -0.034811198711395264]\n",
      "1500 steps | score: [-0.013311208225786686, 0.06871629506349564]\n",
      "1600 steps | score: [0.06269160658121109, -0.06665418297052383]\n",
      "1700 steps | score: [0.047169093042612076, -0.04941001906991005]\n",
      "1800 steps | score: [0.06060164049267769, -0.055146388709545135]\n",
      "1900 steps | score: [-0.11447041481733322, 0.25033068656921387]\n",
      "2000 steps | score: [0.03368678689002991, -0.01114455983042717]\n",
      "2100 steps | score: [-0.06995342671871185, 0.16840693354606628]\n",
      "2200 steps | score: [0.04144100472331047, -0.02470242977142334]\n",
      "2300 steps | score: [-0.03762652724981308, 0.12301985919475555]\n",
      "2400 steps | score: [0.06700197607278824, -0.07932324707508087]\n",
      "2500 steps | score: [-0.03559325635433197, 0.1106967180967331]\n",
      "2600 steps | score: [0.07541338354349136, -0.08562874794006348]\n",
      "unknown params:  tensor([-0.5002, -1.2259])\n",
      "unknown variance:  tensor([[1.3948]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4312, -0.5844])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.010918227024376392]\n",
      "100 steps | score: [-0.16678914427757263]\n",
      "200 steps | score: [-0.2510030269622803]\n",
      "300 steps | score: [-0.2146613746881485]\n",
      "400 steps | score: [-0.2393895536661148]\n",
      "500 steps | score: [-0.19115498661994934]\n",
      "600 steps | score: [-0.20632359385490417]\n",
      "700 steps | score: [-0.24616239964962006]\n",
      "800 steps | score: [-0.20649826526641846]\n",
      "900 steps | score: [-0.25441691279411316]\n",
      "1000 steps | score: [-0.16897237300872803]\n",
      "1100 steps | score: [-0.2591165006160736]\n",
      "1200 steps | score: [-0.19072654843330383]\n",
      "1300 steps | score: [-0.25359711050987244]\n",
      "1400 steps | score: [-0.21777908504009247]\n",
      "1500 steps | score: [-0.213070347905159]\n",
      "1600 steps | score: [-0.2328915148973465]\n",
      "1700 steps | score: [-0.20836208760738373]\n",
      "1800 steps | score: [-0.21933025121688843]\n",
      "1900 steps | score: [-0.20923572778701782]\n",
      "2000 steps | score: [-0.24143195152282715]\n",
      "2100 steps | score: [-0.21756845712661743]\n",
      "2200 steps | score: [-0.24777227640151978]\n",
      "2300 steps | score: [-0.19103866815567017]\n",
      "2400 steps | score: [-0.23187170922756195]\n",
      "2500 steps | score: [-0.2041507065296173]\n",
      "2600 steps | score: [-0.21451422572135925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 steps | score: [0.18941040337085724, -0.17098046839237213]\n",
      "100 steps | score: [0.061472732573747635, -0.03513403981924057]\n",
      "200 steps | score: [-0.06900030374526978, 0.16466642916202545]\n",
      "300 steps | score: [-0.047075726091861725, 0.0934457927942276]\n",
      "400 steps | score: [0.28773459792137146, -0.6677588224411011]\n",
      "500 steps | score: [0.022058963775634766, -0.06557952612638474]\n",
      "600 steps | score: [-0.050570957362651825, 0.06373459100723267]\n",
      "700 steps | score: [-0.09704393148422241, 0.16390004754066467]\n",
      "800 steps | score: [0.12289449572563171, -0.3121345043182373]\n",
      "900 steps | score: [0.04286418855190277, -0.12373919785022736]\n",
      "1000 steps | score: [0.08309044688940048, -0.21662476658821106]\n",
      "1100 steps | score: [-0.0470861941576004, 0.048568740487098694]\n",
      "1200 steps | score: [0.08706911653280258, -0.2244776487350464]\n",
      "1300 steps | score: [-0.020188916474580765, -0.012869012542068958]\n",
      "1400 steps | score: [0.04177771881222725, -0.12309107184410095]\n",
      "1500 steps | score: [0.035913143306970596, -0.11858917027711868]\n",
      "1600 steps | score: [-0.1119891032576561, 0.1738264113664627]\n",
      "1700 steps | score: [0.10983429104089737, -0.2927272915840149]\n",
      "1800 steps | score: [0.0011775086168199778, -0.05077436566352844]\n",
      "1900 steps | score: [-0.015425666235387325, -0.010239994153380394]\n",
      "2000 steps | score: [-0.03326218202710152, 0.014460249803960323]\n",
      "2100 steps | score: [0.05416946858167648, -0.1692097932100296]\n",
      "2200 steps | score: [0.0329420380294323, -0.12495693564414978]\n",
      "2300 steps | score: [-0.033682309091091156, 0.023549512028694153]\n",
      "2400 steps | score: [-0.011347061954438686, -0.02004694566130638]\n",
      "2500 steps | score: [-0.021522294729948044, -0.014167968183755875]\n",
      "2600 steps | score: [0.05472034960985184, -0.17663061618804932]\n",
      "0 steps | score: [0.2585955262184143, -0.28307002782821655]\n",
      "100 steps | score: [0.09419416636228561, -0.07684650272130966]\n",
      "200 steps | score: [-0.014950752258300781, 0.06725895404815674]\n",
      "300 steps | score: [0.02226637303829193, -0.014500301331281662]\n",
      "400 steps | score: [0.29685020446777344, -0.6402056813240051]\n",
      "500 steps | score: [0.11532146483659744, -0.2162259817123413]\n",
      "600 steps | score: [0.02440173178911209, -0.05628717690706253]\n",
      "700 steps | score: [-0.021793970838189125, 0.05447959527373314]\n",
      "800 steps | score: [0.21536435186862946, -0.4582783579826355]\n",
      "900 steps | score: [0.106183260679245, -0.23166359961032867]\n",
      "1000 steps | score: [0.12735393643379211, -0.2775314450263977]\n",
      "1100 steps | score: [0.0011994943488389254, -0.010266445577144623]\n",
      "1200 steps | score: [0.12959805130958557, -0.28213125467300415]\n",
      "1300 steps | score: [0.04982149228453636, -0.12428136169910431]\n",
      "1400 steps | score: [0.07259511947631836, -0.16438710689544678]\n",
      "1500 steps | score: [0.07286013662815094, -0.17448946833610535]\n",
      "1600 steps | score: [-0.05890079587697983, 0.10502348840236664]\n",
      "1700 steps | score: [0.1661749631166458, -0.3637075424194336]\n",
      "1800 steps | score: [0.0789363831281662, -0.1824524700641632]\n",
      "1900 steps | score: [0.03670358657836914, -0.09498715400695801]\n",
      "2000 steps | score: [0.015627825632691383, -0.051353685557842255]\n",
      "2100 steps | score: [0.11340228468179703, -0.259147584438324]\n",
      "2200 steps | score: [0.08838395029306412, -0.19790704548358917]\n",
      "2300 steps | score: [0.04813762009143829, -0.10774977505207062]\n",
      "2400 steps | score: [0.041932832449674606, -0.1016320288181305]\n",
      "2500 steps | score: [0.025511780753731728, -0.07739542424678802]\n",
      "2600 steps | score: [0.13828696310520172, -0.3000987470149994]\n",
      "0 steps | score: [0.14580075442790985, 0.0033795181661844254]\n",
      "100 steps | score: [0.05698187276721001, 0.06044866889715195]\n",
      "200 steps | score: [-0.0732356384396553, 0.2512720227241516]\n",
      "300 steps | score: [-0.07297113537788391, 0.23032745718955994]\n",
      "400 steps | score: [0.3297801911830902, -0.6770008206367493]\n",
      "500 steps | score: [-0.0053667910397052765, 0.0796511247754097]\n",
      "600 steps | score: [-0.07773589342832565, 0.19874051213264465]\n",
      "700 steps | score: [-0.12383295595645905, 0.3022291660308838]\n",
      "800 steps | score: [0.13173876702785492, -0.24332788586616516]\n",
      "900 steps | score: [0.004605963360518217, 0.040115103125572205]\n",
      "1000 steps | score: [0.0659690797328949, -0.09748102724552155]\n",
      "1100 steps | score: [-0.08268660306930542, 0.2182619571685791]\n",
      "1200 steps | score: [0.039387915283441544, -0.03765399008989334]\n",
      "1300 steps | score: [-0.017858272418379784, 0.07434536516666412]\n",
      "1400 steps | score: [0.021713240072131157, -0.003110145218670368]\n",
      "1500 steps | score: [0.019318729639053345, -0.00034935586154460907]\n",
      "1600 steps | score: [-0.15606887638568878, 0.34663790464401245]\n",
      "1700 steps | score: [0.07992561161518097, -0.1224394142627716]\n",
      "1800 steps | score: [-0.030080338940024376, 0.10100673139095306]\n",
      "1900 steps | score: [-0.01712048612535, 0.06990844011306763]\n",
      "2000 steps | score: [-0.06177312508225441, 0.15929904580116272]\n",
      "2100 steps | score: [0.044534195214509964, -0.05389542132616043]\n",
      "2200 steps | score: [0.016261102631688118, 0.00285332091152668]\n",
      "2300 steps | score: [-0.036964766681194305, 0.10709650814533234]\n",
      "2400 steps | score: [-0.053158219903707504, 0.13510102033615112]\n",
      "2500 steps | score: [-0.04471461847424507, 0.1254849135875702]\n",
      "2600 steps | score: [0.056879922747612, -0.08664371073246002]\n",
      "unknown params:  tensor([-0.4207, -1.0277])\n",
      "unknown variance:  tensor([[1.4685]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/bac3f30f-33a0-4376-a2b4-3f9b3264429e\n",
      "gt params:  tensor([-0.4230, -0.5987])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.08724048733711243]\n",
      "100 steps | score: [0.007277658209204674]\n",
      "0 steps | score: [0.013277188874781132, 0.07204493135213852]\n",
      "100 steps | score: [-0.025827884674072266, 0.0664423480629921]\n",
      "200 steps | score: [-0.014520521275699139, 0.004119344986975193]\n",
      "300 steps | score: [-0.05263296514749527, -0.004637430422008038]\n",
      "400 steps | score: [-0.007037214934825897, 0.044003408402204514]\n",
      "500 steps | score: [-0.04851822182536125, -0.03620946407318115]\n",
      "600 steps | score: [-0.003484591143205762, 0.022737544029951096]\n",
      "700 steps | score: [0.002807601820677519, 0.03516300767660141]\n",
      "800 steps | score: [-0.025000840425491333, -0.00804041512310505]\n",
      "900 steps | score: [0.00616034958511591, 0.016561290249228477]\n",
      "1000 steps | score: [-0.022231195122003555, 0.03118731826543808]\n",
      "1100 steps | score: [0.005941018927842379, 0.013730974867939949]\n",
      "1200 steps | score: [-0.03549697622656822, 0.01313550304621458]\n",
      "1300 steps | score: [-0.015406554564833641, 0.024914896115660667]\n",
      "1400 steps | score: [-0.024586807936429977, 0.004208898171782494]\n",
      "1500 steps | score: [-0.003058738075196743, 0.023962819948792458]\n",
      "1600 steps | score: [-0.01348117459565401, 0.018724072724580765]\n",
      "1700 steps | score: [-0.02120118774473667, -0.012463046237826347]\n",
      "1800 steps | score: [0.0035821401979774237, 0.015184767544269562]\n",
      "1900 steps | score: [-0.014741179533302784, 0.02359401248395443]\n",
      "2000 steps | score: [-0.006840355694293976, 0.010400982573628426]\n",
      "2100 steps | score: [-0.021217232570052147, 0.008781326934695244]\n",
      "2200 steps | score: [-0.01402579341083765, 0.015924368053674698]\n",
      "2300 steps | score: [-0.01831616833806038, 0.0035871027503162622]\n",
      "2400 steps | score: [-0.006637305486947298, 0.016965020447969437]\n",
      "2500 steps | score: [-0.0162570308893919, 0.016695020720362663]\n",
      "2600 steps | score: [-0.015328284353017807, 0.002811416983604431]\n",
      "0 steps | score: [0.0022169649600982666, 0.06504134088754654]\n",
      "100 steps | score: [-0.01637965813279152, 0.05692493915557861]\n",
      "200 steps | score: [-0.02223040536046028, -0.006383763160556555]\n",
      "300 steps | score: [-0.06818953156471252, -0.005295944400131702]\n",
      "400 steps | score: [-0.010271596722304821, 0.042721811681985855]\n",
      "500 steps | score: [-0.06433422863483429, -0.03320532292127609]\n",
      "600 steps | score: [-0.009755519218742847, 0.01426572073251009]\n",
      "700 steps | score: [-0.009083633311092854, 0.03408501297235489]\n",
      "800 steps | score: [-0.03691332787275314, -0.017358552664518356]\n",
      "900 steps | score: [0.0010535656474530697, 0.014867737889289856]\n",
      "1000 steps | score: [-0.026890620589256287, 0.02069857344031334]\n",
      "1100 steps | score: [-0.001124726957641542, 0.003917202353477478]\n",
      "unknown params:  tensor([-0.3947, -0.4872])\n",
      "unknown variance:  tensor([[0.8346]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4230, -0.5987])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.2640669345855713]\n",
      "100 steps | score: [0.16516362130641937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 steps | score: [0.12455396354198456]\n",
      "300 steps | score: [0.19844654202461243]\n",
      "400 steps | score: [0.1732204556465149]\n",
      "500 steps | score: [0.11874493956565857]\n",
      "600 steps | score: [0.1032070443034172]\n",
      "700 steps | score: [0.17910261452198029]\n",
      "800 steps | score: [0.130013570189476]\n",
      "900 steps | score: [0.09213535487651825]\n",
      "1000 steps | score: [0.11881295591592789]\n",
      "1100 steps | score: [0.12347805500030518]\n",
      "1200 steps | score: [0.14973920583724976]\n",
      "1300 steps | score: [0.08802514523267746]\n",
      "1400 steps | score: [0.15064865350723267]\n",
      "1500 steps | score: [0.11606702208518982]\n",
      "1600 steps | score: [0.1443784534931183]\n",
      "1700 steps | score: [0.1430850476026535]\n",
      "1800 steps | score: [0.14600670337677002]\n",
      "1900 steps | score: [0.11682528257369995]\n",
      "2000 steps | score: [0.15032319724559784]\n",
      "2100 steps | score: [0.1153910905122757]\n",
      "2200 steps | score: [0.15531019866466522]\n",
      "2300 steps | score: [0.14154604077339172]\n",
      "2400 steps | score: [0.15897858142852783]\n",
      "2500 steps | score: [0.14426428079605103]\n",
      "2600 steps | score: [0.15333367884159088]\n",
      "2700 steps | score: [0.13503314554691315]\n",
      "2800 steps | score: [0.1316598355770111]\n",
      "0 steps | score: [0.08017431944608688, 0.10919418931007385]\n",
      "100 steps | score: [0.017402013763785362, 0.09262043237686157]\n",
      "200 steps | score: [0.006945818196982145, 0.04879467934370041]\n",
      "300 steps | score: [0.06424176692962646, -0.055980194360017776]\n",
      "400 steps | score: [0.04623480886220932, 0.013371892273426056]\n",
      "500 steps | score: [0.0010070923017337918, 0.04279636591672897]\n",
      "600 steps | score: [-0.003320480464026332, 0.020274532958865166]\n",
      "700 steps | score: [0.05595313385128975, -0.04545234143733978]\n",
      "800 steps | score: [0.017882220447063446, 0.031515613198280334]\n",
      "900 steps | score: [-0.013550831936299801, 0.020850500091910362]\n",
      "1000 steps | score: [0.013870268128812313, 0.01952582411468029]\n",
      "1100 steps | score: [0.01852141134440899, 6.241817027330399e-05]\n",
      "1200 steps | score: [0.03250154107809067, 0.043123066425323486]\n",
      "1300 steps | score: [-0.021270520985126495, 0.021250372752547264]\n",
      "1400 steps | score: [0.036240894347429276, 0.009494859725236893]\n",
      "1500 steps | score: [0.020439213141798973, 0.0009849690832197666]\n",
      "1600 steps | score: [0.03791666775941849, 0.021764229983091354]\n",
      "1700 steps | score: [0.015859080478549004, 0.005272038280963898]\n",
      "1800 steps | score: [0.04047882556915283, -0.00022048060782253742]\n",
      "1900 steps | score: [0.009865706786513329, 0.019512582570314407]\n",
      "2000 steps | score: [0.028792332857847214, 0.021628331393003464]\n",
      "2100 steps | score: [0.017582103610038757, 0.009267694316804409]\n",
      "2200 steps | score: [0.04284712299704552, 0.009070638567209244]\n",
      "2300 steps | score: [0.02463962696492672, 0.014976860024034977]\n",
      "2400 steps | score: [0.028110388666391373, 0.017122521996498108]\n",
      "2500 steps | score: [0.027069341391324997, 0.008526451885700226]\n",
      "2600 steps | score: [0.04123247042298317, 0.011510838754475117]\n",
      "2700 steps | score: [0.02845243364572525, 0.014235734939575195]\n",
      "2800 steps | score: [0.025542758405208588, 0.01916254311800003]\n",
      "0 steps | score: [0.04715491086244583, 0.09076903760433197]\n",
      "100 steps | score: [-0.005727719981223345, 0.07579557597637177]\n",
      "200 steps | score: [-0.028214972466230392, 0.027027320116758347]\n",
      "300 steps | score: [0.02894705906510353, -0.0871608629822731]\n",
      "400 steps | score: [0.018084848299622536, -0.010850267484784126]\n",
      "500 steps | score: [-0.05021388828754425, 0.024115897715091705]\n",
      "600 steps | score: [-0.04180413484573364, 0.006700853817164898]\n",
      "700 steps | score: [0.02443232759833336, -0.06345336139202118]\n",
      "800 steps | score: [-0.012163043022155762, 0.014836499467492104]\n",
      "900 steps | score: [-0.04909132793545723, 0.003601287491619587]\n",
      "1000 steps | score: [-0.017509199678897858, 0.0010485555976629257]\n",
      "1100 steps | score: [-0.0204983688890934, -0.02463492378592491]\n",
      "1200 steps | score: [-0.0022452587727457285, 0.01786205731332302]\n",
      "1300 steps | score: [-0.05445156991481781, 0.0048102629370987415]\n",
      "1400 steps | score: [0.0068010734394192696, -0.01758827641606331]\n",
      "1500 steps | score: [-0.020608998835086823, -0.013663101010024548]\n",
      "1600 steps | score: [-0.0032689410727471113, -0.0012969020754098892]\n",
      "0 steps | score: [0.12288427352905273, 0.012086072936654091]\n",
      "100 steps | score: [0.03769252449274063, 0.00576912984251976]\n",
      "200 steps | score: [0.024628696963191032, -0.03849180042743683]\n",
      "300 steps | score: [0.09728739410638809, -0.1552087515592575]\n",
      "400 steps | score: [0.07294436544179916, -0.07667198032140732]\n",
      "500 steps | score: [0.013473836705088615, -0.04191501811146736]\n",
      "600 steps | score: [0.011302393861114979, -0.057166170328855515]\n",
      "700 steps | score: [0.08009170740842819, -0.1342054307460785]\n",
      "800 steps | score: [0.04666743054986, -0.04619526118040085]\n",
      "900 steps | score: [0.0024532200768589973, -0.056717801839113235]\n",
      "1000 steps | score: [0.038110483437776566, -0.06609735637903214]\n",
      "1100 steps | score: [0.03890642151236534, -0.08891366422176361]\n",
      "1200 steps | score: [0.05748160555958748, -0.050066862255334854]\n",
      "1300 steps | score: [0.004749017767608166, -0.06793874502182007]\n",
      "1400 steps | score: [0.05160222575068474, -0.08358656615018845]\n",
      "1500 steps | score: [0.04298514872789383, -0.0851292684674263]\n",
      "1600 steps | score: [0.05068035423755646, -0.06176360324025154]\n",
      "1700 steps | score: [0.04152967780828476, -0.07353058457374573]\n",
      "1800 steps | score: [0.06788571178913116, -0.08313161134719849]\n",
      "1900 steps | score: [0.03279632702469826, -0.06354856491088867]\n",
      "2000 steps | score: [0.054693564772605896, -0.06300920248031616]\n",
      "2100 steps | score: [0.04248267412185669, -0.0785258561372757]\n",
      "2200 steps | score: [0.06058361753821373, -0.08243116736412048]\n",
      "2300 steps | score: [0.05074368417263031, -0.06839383393526077]\n",
      "2400 steps | score: [0.049386464059352875, -0.06585988402366638]\n",
      "2500 steps | score: [0.05007646977901459, -0.08005756884813309]\n",
      "2600 steps | score: [0.06009574234485626, -0.07611900568008423]\n",
      "2700 steps | score: [0.0524652898311615, -0.069569893181324]\n",
      "2800 steps | score: [0.049415625631809235, -0.07154199481010437]\n",
      "unknown params:  tensor([-0.4037, -0.4954])\n",
      "unknown variance:  tensor([[0.8654]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4230, -0.5987])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.01885359175503254]\n",
      "100 steps | score: [-0.1281318962574005]\n",
      "200 steps | score: [-0.09603379666805267]\n",
      "300 steps | score: [-0.09915022552013397]\n",
      "400 steps | score: [-0.1229977160692215]\n",
      "500 steps | score: [-0.15404736995697021]\n",
      "600 steps | score: [-0.13727477192878723]\n",
      "700 steps | score: [-0.14721383154392242]\n",
      "800 steps | score: [-0.1770433783531189]\n",
      "900 steps | score: [-0.06677232682704926]\n",
      "1000 steps | score: [-0.15212248265743256]\n",
      "1100 steps | score: [-0.10490109026432037]\n",
      "1200 steps | score: [-0.10100399702787399]\n",
      "1300 steps | score: [-0.09675461053848267]\n",
      "1400 steps | score: [-0.11826059222221375]\n",
      "1500 steps | score: [-0.12241003662347794]\n",
      "1600 steps | score: [-0.1568223387002945]\n",
      "1700 steps | score: [-0.1253412365913391]\n",
      "1800 steps | score: [-0.12795250117778778]\n",
      "1900 steps | score: [-0.12473246455192566]\n",
      "2000 steps | score: [-0.12280479818582535]\n",
      "2100 steps | score: [-0.10749003291130066]\n",
      "2200 steps | score: [-0.11152416467666626]\n",
      "2300 steps | score: [-0.11736460775136948]\n",
      "2400 steps | score: [-0.13219356536865234]\n",
      "2500 steps | score: [-0.12366873025894165]\n",
      "2600 steps | score: [-0.12649381160736084]\n",
      "0 steps | score: [0.044859711080789566, 0.10905912518501282]\n",
      "100 steps | score: [-0.009893722832202911, 0.04447047412395477]\n",
      "200 steps | score: [-0.019392680376768112, 0.0011076750233769417]\n",
      "300 steps | score: [-0.027871301397681236, 0.003995702601969242]\n",
      "400 steps | score: [-0.030258890241384506, -0.0011198953725397587]\n",
      "500 steps | score: [-0.04608139395713806, 0.03566783666610718]\n",
      "600 steps | score: [-0.04686138406395912, 0.02798048034310341]\n",
      "700 steps | score: [-0.06018422171473503, 0.06298789381980896]\n",
      "800 steps | score: [-0.042103111743927, 0.0012982673943042755]\n",
      "900 steps | score: [0.011196199804544449, -0.009556308388710022]\n",
      "1000 steps | score: [-0.046076271682977676, 0.009965701028704643]\n",
      "1100 steps | score: [-0.026068061590194702, 0.011743498966097832]\n",
      "1200 steps | score: [-0.02452366054058075, -0.009241477586328983]\n",
      "1300 steps | score: [-0.0007429582183249295, -0.025476979091763496]\n",
      "1400 steps | score: [-0.015642689540982246, -0.02616911195218563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 steps | score: [-0.0373244509100914, 0.021827956661581993]\n",
      "1600 steps | score: [-0.05202694609761238, 0.015988050028681755]\n",
      "1700 steps | score: [-0.03184875100851059, 0.013407876715064049]\n",
      "1800 steps | score: [-0.015157397836446762, -0.017877189442515373]\n",
      "1900 steps | score: [-0.01631270721554756, -0.001555421855300665]\n",
      "2000 steps | score: [-0.02816920541226864, 0.012632614001631737]\n",
      "2100 steps | score: [-0.0435728095471859, 0.017446748912334442]\n",
      "2200 steps | score: [-0.021760091185569763, -0.0001237606629729271]\n",
      "2300 steps | score: [-0.029011936858296394, 0.0014074239879846573]\n",
      "2400 steps | score: [-0.031769175082445145, 0.00862530805170536]\n",
      "2500 steps | score: [-0.02977941371500492, 0.0035589933395385742]\n",
      "2600 steps | score: [-0.034934304654598236, 0.012179111130535603]\n",
      "0 steps | score: [0.0545063354074955, 0.0825912356376648]\n",
      "100 steps | score: [-0.0015540106687694788, 0.02784174308180809]\n",
      "200 steps | score: [-0.014043356291949749, -0.008346537128090858]\n",
      "300 steps | score: [-0.010327173396945, -0.021189657971262932]\n",
      "400 steps | score: [-0.011388944461941719, -0.033786315470933914]\n",
      "500 steps | score: [-0.029518285766243935, 0.008798281662166119]\n",
      "600 steps | score: [-0.030632738023996353, 0.002251286059617996]\n",
      "700 steps | score: [-0.04222071170806885, 0.049904536455869675]\n",
      "800 steps | score: [-0.02497900277376175, -0.019995782524347305]\n",
      "900 steps | score: [0.016513846814632416, -0.027608154341578484]\n",
      "1000 steps | score: [-0.027567997574806213, -0.010564608499407768]\n",
      "1100 steps | score: [-0.013508240692317486, -0.012101029977202415]\n",
      "1200 steps | score: [-0.0020771194249391556, -0.03356168419122696]\n",
      "1300 steps | score: [0.011036079376935959, -0.051509056240320206]\n",
      "1400 steps | score: [-0.00500397989526391, -0.05779782682657242]\n",
      "1500 steps | score: [-0.023713810369372368, -0.005392920225858688]\n",
      "1600 steps | score: [-0.021157817915081978, -0.009658546186983585]\n",
      "1700 steps | score: [-0.016207585111260414, -0.014592064544558525]\n",
      "1800 steps | score: [-0.003095122752711177, -0.038495682179927826]\n",
      "1900 steps | score: [-0.009861860424280167, -0.013538173399865627]\n",
      "2000 steps | score: [-0.013378547504544258, -0.007816808298230171]\n",
      "2100 steps | score: [-0.023545999079942703, -0.009385711513459682]\n",
      "2200 steps | score: [-0.011219874955713749, -0.02272597700357437]\n",
      "2300 steps | score: [-0.011113759130239487, -0.0183287151157856]\n",
      "2400 steps | score: [-0.018929706886410713, -0.010932612232863903]\n",
      "2500 steps | score: [-0.015833133831620216, -0.016339626163244247]\n",
      "2600 steps | score: [-0.019262440502643585, -0.010545976459980011]\n",
      "0 steps | score: [0.1095447912812233, 0.08263634145259857]\n",
      "100 steps | score: [0.040976013988256454, 0.026900913566350937]\n",
      "200 steps | score: [0.03210663050413132, -0.00616434495896101]\n",
      "300 steps | score: [0.02766493335366249, -0.02474186196923256]\n",
      "400 steps | score: [0.03173654526472092, -0.02385077252984047]\n",
      "500 steps | score: [0.01314658671617508, 0.016521954908967018]\n",
      "600 steps | score: [0.004880597349256277, 0.007042689248919487]\n",
      "unknown params:  tensor([-0.4059, -0.5444])\n",
      "unknown variance:  tensor([[0.8874]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4230, -0.5987])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.12311764061450958]\n",
      "100 steps | score: [-0.03264245390892029]\n",
      "200 steps | score: [-0.039435263723134995]\n",
      "300 steps | score: [-0.04922477900981903]\n",
      "400 steps | score: [-0.03976564481854439]\n",
      "500 steps | score: [0.09497099369764328]\n",
      "600 steps | score: [-0.0001850728876888752]\n",
      "0 steps | score: [0.15076465904712677, 0.0720779299736023]\n",
      "100 steps | score: [0.03237900882959366, 0.01810283213853836]\n",
      "200 steps | score: [0.031715501099824905, 0.0010520711075514555]\n",
      "300 steps | score: [-0.020874351263046265, 0.05466773360967636]\n",
      "400 steps | score: [0.004947085399180651, -0.02155781164765358]\n",
      "500 steps | score: [0.13631683588027954, -0.11376168578863144]\n",
      "600 steps | score: [0.03390960022807121, -0.05511172115802765]\n",
      "700 steps | score: [0.05769704282283783, -0.037316955626010895]\n",
      "800 steps | score: [0.06420064717531204, -0.042987849563360214]\n",
      "900 steps | score: [0.010528162121772766, 0.005681403446942568]\n",
      "1000 steps | score: [0.002803271170705557, 0.014389614574611187]\n",
      "1100 steps | score: [0.02334556169807911, -0.02398792840540409]\n",
      "1200 steps | score: [0.1153649389743805, -0.09441017359495163]\n",
      "1300 steps | score: [0.01832331158220768, -0.02041599340736866]\n",
      "1400 steps | score: [0.036493148654699326, -0.0217168889939785]\n",
      "1500 steps | score: [0.010073857381939888, 0.005345928482711315]\n",
      "1600 steps | score: [0.017377346754074097, 0.001991600263863802]\n",
      "1700 steps | score: [0.03562556952238083, -0.021008193492889404]\n",
      "1800 steps | score: [0.020113630220294, -0.016936808824539185]\n",
      "1900 steps | score: [0.04935671389102936, -0.025371059775352478]\n",
      "2000 steps | score: [0.02378937043249607, -0.020585056394338608]\n",
      "2100 steps | score: [0.029922017827630043, -0.020355302840471268]\n",
      "2200 steps | score: [0.025447966530919075, -0.014932760037481785]\n",
      "2300 steps | score: [0.03355462849140167, -0.017156247049570084]\n",
      "2400 steps | score: [0.04069826751947403, -0.03479103371500969]\n",
      "2500 steps | score: [0.04045620188117027, -0.02790047787129879]\n",
      "2600 steps | score: [0.03463991731405258, -0.024513255804777145]\n",
      "2700 steps | score: [0.04205287620425224, -0.03271384537220001]\n",
      "2800 steps | score: [0.03521605208516121, -0.025360137224197388]\n",
      "0 steps | score: [0.06979051232337952, 0.10404758155345917]\n",
      "100 steps | score: [-0.03690311685204506, 0.03208010271191597]\n",
      "200 steps | score: [-0.043279796838760376, 0.029529444873332977]\n",
      "300 steps | score: [-0.08710797876119614, 0.07957613468170166]\n",
      "400 steps | score: [-0.06722963601350784, 0.013533331453800201]\n",
      "500 steps | score: [0.06746887415647507, -0.08302249014377594]\n",
      "600 steps | score: [-0.027683954685926437, -0.030529774725437164]\n",
      "700 steps | score: [0.0035613817162811756, -0.02554108016192913]\n",
      "800 steps | score: [-0.0033498303964734077, -0.02675977163016796]\n",
      "900 steps | score: [-0.054304249584674835, 0.03179697319865227]\n",
      "1000 steps | score: [-0.0630369707942009, 0.04117368906736374]\n",
      "1100 steps | score: [-0.03742147982120514, 0.001193745993077755]\n",
      "1200 steps | score: [0.05349978804588318, -0.07565632462501526]\n",
      "1300 steps | score: [-0.04426231607794762, -0.003451569937169552]\n",
      "1400 steps | score: [-0.02425352856516838, -0.0024745925329625607]\n",
      "1500 steps | score: [-0.060388095676898956, 0.03231917694211006]\n",
      "1600 steps | score: [-0.045646555721759796, 0.016413383185863495]\n",
      "1700 steps | score: [-0.034793492406606674, 0.0020049745216965675]\n",
      "1800 steps | score: [-0.04147552698850632, 0.007267573848366737]\n",
      "1900 steps | score: [-0.018069276586174965, -0.003168659284710884]\n",
      "2000 steps | score: [-0.03279564902186394, 0.002086285501718521]\n",
      "2100 steps | score: [-0.03876412659883499, 0.013964025303721428]\n",
      "2200 steps | score: [-0.0392477884888649, 0.008815372362732887]\n",
      "2300 steps | score: [-0.04220791906118393, 0.014030123129487038]\n",
      "2400 steps | score: [-0.02658625692129135, -0.0033415285870432854]\n",
      "2500 steps | score: [-0.023636918514966965, -0.006570644676685333]\n",
      "2600 steps | score: [-0.03133663535118103, 0.004933787509799004]\n",
      "2700 steps | score: [-0.02956552989780903, -0.0012432979419827461]\n",
      "2800 steps | score: [-0.025600414723157883, -0.00339807802811265]\n",
      "0 steps | score: [0.10997658967971802, 0.10295989364385605]\n",
      "100 steps | score: [0.0068684848956763744, 0.03661178797483444]\n",
      "200 steps | score: [-0.0021377485245466232, 0.032803475856781006]\n",
      "300 steps | score: [-0.03985481709241867, 0.07826325297355652]\n",
      "400 steps | score: [-0.022580811753869057, 0.0065015023574233055]\n",
      "500 steps | score: [0.11159022152423859, -0.09095420688390732]\n",
      "600 steps | score: [0.026099998503923416, -0.037267111241817474]\n",
      "700 steps | score: [0.04646404832601547, -0.018894976004958153]\n",
      "800 steps | score: [0.04361242800951004, -0.02114790491759777]\n",
      "900 steps | score: [-0.015197993256151676, 0.036378033459186554]\n",
      "1000 steps | score: [-0.027684617787599564, 0.04522925615310669]\n",
      "1100 steps | score: [-0.004721964243799448, 0.006125304847955704]\n",
      "unknown params:  tensor([-0.4351, -0.6076])\n",
      "unknown variance:  tensor([[0.9587]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4230, -0.5987])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3273870646953583]\n",
      "100 steps | score: [0.0945199728012085]\n",
      "200 steps | score: [0.12400446087121964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 steps | score: [0.17574264109134674]\n",
      "400 steps | score: [0.10585053265094757]\n",
      "500 steps | score: [0.11820800602436066]\n",
      "600 steps | score: [0.12911885976791382]\n",
      "700 steps | score: [0.1333043873310089]\n",
      "800 steps | score: [0.1590869426727295]\n",
      "900 steps | score: [0.15019379556179047]\n",
      "1000 steps | score: [0.17064547538757324]\n",
      "1100 steps | score: [0.1310061812400818]\n",
      "1200 steps | score: [0.10906260460615158]\n",
      "1300 steps | score: [0.14865438640117645]\n",
      "1400 steps | score: [0.12964491546154022]\n",
      "1500 steps | score: [0.14687469601631165]\n",
      "1600 steps | score: [0.1452561914920807]\n",
      "1700 steps | score: [0.14217764139175415]\n",
      "1800 steps | score: [0.12109585106372833]\n",
      "1900 steps | score: [0.14912185072898865]\n",
      "2000 steps | score: [0.156448632478714]\n",
      "2100 steps | score: [0.1712518036365509]\n",
      "2200 steps | score: [0.16302624344825745]\n",
      "2300 steps | score: [0.18392544984817505]\n",
      "2400 steps | score: [0.15915407240390778]\n",
      "2500 steps | score: [0.12375256419181824]\n",
      "2600 steps | score: [0.16546572744846344]\n",
      "0 steps | score: [0.13819245994091034, 0.032623447477817535]\n",
      "100 steps | score: [-0.009869390167295933, 0.007165374234318733]\n",
      "0 steps | score: [0.10170143097639084, 0.1142682358622551]\n",
      "100 steps | score: [-0.04598663002252579, 0.08365703374147415]\n",
      "200 steps | score: [-0.029235072433948517, 0.016446325927972794]\n",
      "300 steps | score: [0.019451921805739403, -0.005213297437876463]\n",
      "400 steps | score: [-0.05477149412035942, 0.07357851415872574]\n",
      "500 steps | score: [-0.007206639740616083, 0.008749406784772873]\n",
      "0 steps | score: [0.12603648006916046, 0.11359092593193054]\n",
      "100 steps | score: [-0.026104535907506943, 0.08395475894212723]\n",
      "200 steps | score: [-0.00843170378357172, 0.008808009326457977]\n",
      "unknown params:  tensor([-0.4032, -0.6075])\n",
      "unknown variance:  tensor([[0.9469]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4230, -0.5987])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3763892352581024]\n",
      "100 steps | score: [0.1939004808664322]\n",
      "200 steps | score: [0.15666824579238892]\n",
      "300 steps | score: [0.21153677999973297]\n",
      "400 steps | score: [0.18079110980033875]\n",
      "500 steps | score: [0.12266343832015991]\n",
      "600 steps | score: [0.20502632856369019]\n",
      "700 steps | score: [0.15106795728206635]\n",
      "800 steps | score: [0.16435661911964417]\n",
      "900 steps | score: [0.17184610664844513]\n",
      "1000 steps | score: [0.1749868392944336]\n",
      "1100 steps | score: [0.13903838396072388]\n",
      "1200 steps | score: [0.18397539854049683]\n",
      "1300 steps | score: [0.15734046697616577]\n",
      "1400 steps | score: [0.1887688785791397]\n",
      "1500 steps | score: [0.17028777301311493]\n",
      "1600 steps | score: [0.14996963739395142]\n",
      "1700 steps | score: [0.1505531370639801]\n",
      "1800 steps | score: [0.16582642495632172]\n",
      "1900 steps | score: [0.17058131098747253]\n",
      "2000 steps | score: [0.15796557068824768]\n",
      "2100 steps | score: [0.18972283601760864]\n",
      "2200 steps | score: [0.15713874995708466]\n",
      "2300 steps | score: [0.1568852812051773]\n",
      "2400 steps | score: [0.18537667393684387]\n",
      "2500 steps | score: [0.16579169034957886]\n",
      "2600 steps | score: [0.16056373715400696]\n",
      "0 steps | score: [0.1853324919939041, 0.005968869663774967]\n",
      "100 steps | score: [0.10511666536331177, -0.11026401817798615]\n",
      "200 steps | score: [-0.0067765056155622005, -0.019288823008537292]\n",
      "300 steps | score: [0.07700128108263016, -0.08360017836093903]\n",
      "400 steps | score: [0.07297078520059586, -0.10151856392621994]\n",
      "500 steps | score: [-0.022146429866552353, -0.005245568230748177]\n",
      "600 steps | score: [0.06198514997959137, -0.05969271808862686]\n",
      "700 steps | score: [0.0388219952583313, -0.06038461998105049]\n",
      "800 steps | score: [-0.002763583790510893, -0.025749951601028442]\n",
      "900 steps | score: [0.04222584515810013, -0.05130234733223915]\n",
      "1000 steps | score: [0.04673114791512489, -0.06998834758996964]\n",
      "1100 steps | score: [-0.007101897615939379, -0.016917601227760315]\n",
      "1200 steps | score: [0.06282298266887665, -0.06916709989309311]\n",
      "1300 steps | score: [0.029821433126926422, -0.03996991366147995]\n",
      "1400 steps | score: [0.05010209232568741, -0.07941681146621704]\n",
      "1500 steps | score: [0.04907353222370148, -0.0693851113319397]\n",
      "1600 steps | score: [0.03277105093002319, -0.052278339862823486]\n",
      "1700 steps | score: [0.016675293445587158, -0.04567665979266167]\n",
      "1800 steps | score: [0.04933685064315796, -0.06284874677658081]\n",
      "1900 steps | score: [0.02323545143008232, -0.03997353836894035]\n",
      "2000 steps | score: [0.029399577528238297, -0.05354084447026253]\n",
      "2100 steps | score: [0.05605900660157204, -0.0714515894651413]\n",
      "2200 steps | score: [0.020385369658470154, -0.04372674226760864]\n",
      "2300 steps | score: [0.03758803755044937, -0.06706658005714417]\n",
      "2400 steps | score: [0.04768427088856697, -0.053055960685014725]\n",
      "2500 steps | score: [0.034387458115816116, -0.04973609745502472]\n",
      "2600 steps | score: [0.03833983093500137, -0.06733934581279755]\n",
      "0 steps | score: [0.10708855837583542, 0.03582260012626648]\n",
      "100 steps | score: [0.06755612045526505, -0.14250323176383972]\n",
      "200 steps | score: [-0.06160690635442734, -0.015488519333302975]\n",
      "300 steps | score: [0.02722620777785778, -0.08029117435216904]\n",
      "400 steps | score: [0.018614009022712708, -0.09167627990245819]\n",
      "500 steps | score: [-0.0854729562997818, 0.008625015616416931]\n",
      "600 steps | score: [-0.0002615999255795032, -0.05416135489940643]\n",
      "700 steps | score: [-0.015022175386548042, -0.05467812344431877]\n",
      "800 steps | score: [-0.06710406392812729, -0.006456402130424976]\n",
      "900 steps | score: [-0.01531419437378645, -0.042642105370759964]\n",
      "1000 steps | score: [-0.006222250405699015, -0.06888557225465775]\n",
      "1100 steps | score: [-0.062726229429245, -0.011230259202420712]\n",
      "1200 steps | score: [-0.0089418338611722, -0.05199751257896423]\n",
      "1300 steps | score: [-0.0280419010668993, -0.034464605152606964]\n",
      "1400 steps | score: [-0.012797673232853413, -0.07498656958341599]\n",
      "1500 steps | score: [-0.029360326007008553, -0.03866636008024216]\n",
      "1600 steps | score: [-0.015056315809488297, -0.045262038707733154]\n",
      "1700 steps | score: [-0.03690008446574211, -0.046923182904720306]\n",
      "1800 steps | score: [-0.017491798847913742, -0.050525471568107605]\n",
      "1900 steps | score: [-0.02838301658630371, -0.027424443513154984]\n",
      "2000 steps | score: [-0.03225582093000412, -0.04449602589011192]\n",
      "2100 steps | score: [-0.016394302248954773, -0.051529403775930405]\n",
      "2200 steps | score: [-0.03702289238572121, -0.022122230380773544]\n",
      "2300 steps | score: [-0.019794253632426262, -0.05795230716466904]\n",
      "2400 steps | score: [-0.01996086724102497, -0.0458807498216629]\n",
      "2500 steps | score: [-0.04152706265449524, -0.023782094940543175]\n",
      "2600 steps | score: [-0.015045602805912495, -0.06990889459848404]\n",
      "0 steps | score: [0.05951428413391113, 0.1697462499141693]\n",
      "100 steps | score: [0.043088290840387344, -0.029716087505221367]\n",
      "200 steps | score: [-0.10065286606550217, 0.10283445566892624]\n",
      "300 steps | score: [-0.018376227468252182, 0.052949804812669754]\n",
      "400 steps | score: [-0.00659056706354022, 0.0009691081941127777]\n",
      "unknown params:  tensor([-0.4891, -0.8679])\n",
      "unknown variance:  tensor([[1.0950]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4230, -0.5987])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.31004083156585693]\n",
      "100 steps | score: [0.0994437038898468]\n",
      "200 steps | score: [0.17063802480697632]\n",
      "300 steps | score: [0.052680399268865585]\n",
      "400 steps | score: [-0.003831966780126095]\n",
      "0 steps | score: [0.17832180857658386, 0.04541486129164696]\n",
      "100 steps | score: [-0.00882139801979065, 0.10206184536218643]\n",
      "200 steps | score: [0.09187434613704681, -0.09798899292945862]\n",
      "300 steps | score: [0.008111422881484032, 0.05984266847372055]\n",
      "400 steps | score: [-0.1495257467031479, 0.2240971028804779]\n",
      "500 steps | score: [-0.12490193545818329, 0.19551795721054077]\n",
      "600 steps | score: [-0.059784673154354095, 0.13181662559509277]\n",
      "700 steps | score: [-0.015420816838741302, 0.042015671730041504]\n",
      "800 steps | score: [0.023035839200019836, -0.009805170819163322]\n",
      "900 steps | score: [-0.041806187480688095, 0.08908113092184067]\n",
      "1000 steps | score: [-0.03633839637041092, 0.06935057789087296]\n",
      "1100 steps | score: [0.04618317633867264, -0.03382483869791031]\n",
      "1200 steps | score: [0.11163686215877533, -0.14736945927143097]\n",
      "1300 steps | score: [0.009487591683864594, 0.01232688408344984]\n",
      "1400 steps | score: [0.01207505539059639, 0.012147166766226292]\n",
      "1500 steps | score: [-0.035806503146886826, 0.07422517240047455]\n",
      "1600 steps | score: [-0.027074359357357025, 0.06929197907447815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 steps | score: [-0.01924421638250351, 0.06740373373031616]\n",
      "1800 steps | score: [0.022235091775655746, -0.008826876059174538]\n",
      "1900 steps | score: [0.007544326595962048, 0.014191575348377228]\n",
      "2000 steps | score: [0.0097836684435606, 0.02495809644460678]\n",
      "2100 steps | score: [0.048886097967624664, -0.05140576511621475]\n",
      "2200 steps | score: [0.03427756205201149, -0.020272407680749893]\n",
      "2300 steps | score: [0.027913009747862816, -0.009952817112207413]\n",
      "2400 steps | score: [0.013566158711910248, 0.006937799043953419]\n",
      "2500 steps | score: [-0.004559253342449665, 0.039532944560050964]\n",
      "2600 steps | score: [0.0019094714662060142, 0.02672114595770836]\n",
      "2700 steps | score: [-0.00019183297990821302, 0.028659414499998093]\n",
      "0 steps | score: [0.15028710663318634, 0.01253489963710308]\n",
      "100 steps | score: [-0.025423459708690643, 0.06375288218259811]\n",
      "200 steps | score: [0.058950770646333694, -0.12367542088031769]\n",
      "300 steps | score: [-0.03314247354865074, 0.026873987168073654]\n",
      "400 steps | score: [-0.19304533302783966, 0.20300418138504028]\n",
      "500 steps | score: [-0.1381734162569046, 0.1538618803024292]\n",
      "600 steps | score: [-0.08935365825891495, 0.09311264008283615]\n",
      "700 steps | score: [-0.04150325804948807, 0.01298459805548191]\n",
      "800 steps | score: [0.00787916500121355, -0.03061383217573166]\n",
      "900 steps | score: [-0.06254162639379501, 0.04358719289302826]\n",
      "1000 steps | score: [-0.05895960330963135, 0.02788241021335125]\n",
      "1100 steps | score: [0.019663674756884575, -0.06704775989055634]\n",
      "1200 steps | score: [0.0822669044137001, -0.1665484756231308]\n",
      "1300 steps | score: [-0.01278709713369608, -0.030024472624063492]\n",
      "1400 steps | score: [-0.019100388512015343, -0.004253304563462734]\n",
      "1500 steps | score: [-0.06207387149333954, 0.0390271432697773]\n",
      "1600 steps | score: [-0.047292664647102356, 0.026367975398898125]\n",
      "1700 steps | score: [-0.051300276070833206, 0.03361456096172333]\n",
      "1800 steps | score: [-0.027542857453227043, -0.008253928273916245]\n",
      "1900 steps | score: [-0.011128190904855728, -0.03271157294511795]\n",
      "2000 steps | score: [-0.0243546012789011, -0.009063070639967918]\n",
      "2100 steps | score: [0.0219880361109972, -0.08210895210504532]\n",
      "2200 steps | score: [0.008304071612656116, -0.04821429401636124]\n",
      "2300 steps | score: [0.01102549396455288, -0.06018364802002907]\n",
      "2400 steps | score: [-0.007420404814183712, -0.03533107414841652]\n",
      "2500 steps | score: [-0.01122475415468216, -0.012847106903791428]\n",
      "2600 steps | score: [-0.026568368077278137, -0.005086056422442198]\n",
      "2700 steps | score: [-0.01962246187031269, -0.010654943063855171]\n",
      "0 steps | score: [0.24195832014083862, -0.010107915848493576]\n",
      "100 steps | score: [0.06826421618461609, 0.03030799701809883]\n",
      "200 steps | score: [0.1475437432527542, -0.16013573110103607]\n",
      "300 steps | score: [0.027901941910386086, 0.03090832196176052]\n",
      "400 steps | score: [-0.11445695161819458, 0.1826452910900116]\n",
      "500 steps | score: [-0.05798277258872986, 0.13316626846790314]\n",
      "600 steps | score: [-0.01703229732811451, 0.08816535770893097]\n",
      "700 steps | score: [0.03365185111761093, -0.0002083396539092064]\n",
      "800 steps | score: [0.059431154280900955, -0.032171688973903656]\n",
      "900 steps | score: [-0.022208675742149353, 0.07300028949975967]\n",
      "1000 steps | score: [0.017364587634801865, 0.014658927917480469]\n",
      "1100 steps | score: [0.10040523111820221, -0.07964367419481277]\n",
      "1200 steps | score: [0.16918709874153137, -0.20137284696102142]\n",
      "1300 steps | score: [0.06277692317962646, -0.04527803510427475]\n",
      "1400 steps | score: [0.06330208480358124, -0.029265977442264557]\n",
      "1500 steps | score: [0.009781629778444767, 0.03345506638288498]\n",
      "1600 steps | score: [0.041949328035116196, -0.0018117455765604973]\n",
      "1700 steps | score: [0.02877654880285263, 0.016444582492113113]\n",
      "1800 steps | score: [0.062099389731884, -0.0381598137319088]\n",
      "1900 steps | score: [0.06508675962686539, -0.038471803069114685]\n",
      "2000 steps | score: [0.0524655245244503, -0.020005952566862106]\n",
      "2100 steps | score: [0.08379348367452621, -0.0726507306098938]\n",
      "2200 steps | score: [0.08393767476081848, -0.060136474668979645]\n",
      "2300 steps | score: [0.08000197261571884, -0.06892646849155426]\n",
      "2400 steps | score: [0.06742250919342041, -0.043676044791936874]\n",
      "2500 steps | score: [0.04888080805540085, -0.013961897231638432]\n",
      "2600 steps | score: [0.060364022850990295, -0.033776331692934036]\n",
      "2700 steps | score: [0.04736759513616562, -0.014088628813624382]\n",
      "unknown params:  tensor([-0.5348, -1.1177])\n",
      "unknown variance:  tensor([[1.2205]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4230, -0.5987])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.040371302515268326]\n",
      "100 steps | score: [-0.07146614044904709]\n",
      "200 steps | score: [-0.2370729148387909]\n",
      "300 steps | score: [-0.2405681163072586]\n",
      "400 steps | score: [-0.14411142468452454]\n",
      "500 steps | score: [-0.15817420184612274]\n",
      "600 steps | score: [-0.17878206074237823]\n",
      "700 steps | score: [-0.16189032793045044]\n",
      "800 steps | score: [-0.2562560737133026]\n",
      "900 steps | score: [-0.14512017369270325]\n",
      "1000 steps | score: [-0.17494262754917145]\n",
      "1100 steps | score: [-0.22278432548046112]\n",
      "1200 steps | score: [-0.20086777210235596]\n",
      "1300 steps | score: [-0.19940686225891113]\n",
      "1400 steps | score: [-0.1679328978061676]\n",
      "1500 steps | score: [-0.19236966967582703]\n",
      "1600 steps | score: [-0.18978451192378998]\n",
      "1700 steps | score: [-0.15543599426746368]\n",
      "1800 steps | score: [-0.17769752442836761]\n",
      "1900 steps | score: [-0.1981363743543625]\n",
      "2000 steps | score: [-0.18984530866146088]\n",
      "2100 steps | score: [-0.210435688495636]\n",
      "2200 steps | score: [-0.16895875334739685]\n",
      "2300 steps | score: [-0.19547368586063385]\n",
      "2400 steps | score: [-0.16999955475330353]\n",
      "2500 steps | score: [-0.20357252657413483]\n",
      "2600 steps | score: [-0.1963815987110138]\n",
      "0 steps | score: [0.1646541953086853, 0.09059330821037292]\n",
      "100 steps | score: [0.32678738236427307, -0.40768852829933167]\n",
      "200 steps | score: [-0.16047631204128265, 0.3466610312461853]\n",
      "300 steps | score: [-0.07534343004226685, 0.22045910358428955]\n",
      "400 steps | score: [0.1443987637758255, -0.18772120773792267]\n",
      "500 steps | score: [0.006374838296324015, 0.09587179869413376]\n",
      "600 steps | score: [-0.026510337367653847, 0.11912377178668976]\n",
      "700 steps | score: [0.04503094404935837, 0.015445844270288944]\n",
      "800 steps | score: [-0.0773596316576004, 0.20320336520671844]\n",
      "900 steps | score: [0.12795566022396088, -0.1565401554107666]\n",
      "1000 steps | score: [0.014694622717797756, 0.06382974982261658]\n",
      "1100 steps | score: [-0.0733877494931221, 0.1950259953737259]\n",
      "1200 steps | score: [-0.050237152725458145, 0.171753391623497]\n",
      "1300 steps | score: [-0.007968964986503124, 0.08941009640693665]\n",
      "1400 steps | score: [0.0031332483049482107, 0.06652811169624329]\n",
      "1500 steps | score: [-0.06857560575008392, 0.19341090321540833]\n",
      "1600 steps | score: [0.02981558069586754, 0.029805772006511688]\n",
      "1700 steps | score: [0.02626311220228672, 0.02538861148059368]\n",
      "1800 steps | score: [0.06335872411727905, -0.032995544373989105]\n",
      "1900 steps | score: [-0.04485461488366127, 0.15569964051246643]\n",
      "2000 steps | score: [-0.024164287373423576, 0.11259409785270691]\n",
      "2100 steps | score: [-0.003117153886705637, 0.07179994136095047]\n",
      "2200 steps | score: [0.013216901570558548, 0.05574096739292145]\n",
      "2300 steps | score: [-0.0013980717631056905, 0.0726596787571907]\n",
      "2400 steps | score: [0.0009004617459140718, 0.06779087334871292]\n",
      "2500 steps | score: [0.006677137687802315, 0.06143404543399811]\n",
      "2600 steps | score: [0.04823973774909973, -0.011594511568546295]\n",
      "0 steps | score: [0.15087874233722687, 0.05676111578941345]\n",
      "100 steps | score: [0.2893947660923004, -0.3967364728450775]\n",
      "200 steps | score: [-0.17911241948604584, 0.3227042257785797]\n",
      "300 steps | score: [-0.09607933461666107, 0.20123223960399628]\n",
      "400 steps | score: [0.10618551820516586, -0.17121167480945587]\n",
      "500 steps | score: [0.0016873495187610388, 0.048741575330495834]\n",
      "600 steps | score: [-0.05749767646193504, 0.10996831953525543]\n",
      "700 steps | score: [0.047771383076906204, -0.03651496022939682]\n",
      "800 steps | score: [-0.10158975422382355, 0.17309972643852234]\n",
      "900 steps | score: [0.09017409384250641, -0.1605806052684784]\n",
      "1000 steps | score: [-0.008774642832577229, 0.04272221401333809]\n",
      "1100 steps | score: [-0.09196455031633377, 0.1679990291595459]\n",
      "1200 steps | score: [-0.04872510954737663, 0.10501305013895035]\n",
      "1300 steps | score: [-0.004840881563723087, 0.024196095764636993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 steps | score: [-0.01925470493733883, 0.05132084712386131]\n",
      "1500 steps | score: [-0.07266805320978165, 0.15491823852062225]\n",
      "1600 steps | score: [0.004016105551272631, 0.0023557189851999283]\n",
      "0 steps | score: [0.22801573574543, -0.08260414004325867]\n",
      "100 steps | score: [0.3316515386104584, -0.4567442238330841]\n",
      "200 steps | score: [-0.11453858762979507, 0.20370522141456604]\n",
      "300 steps | score: [-0.03535376116633415, 0.0790577307343483]\n",
      "400 steps | score: [0.18319685757160187, -0.31577232480049133]\n",
      "500 steps | score: [0.03169877454638481, -0.018837081268429756]\n",
      "600 steps | score: [0.006097376812249422, -0.0059533980675041676]\n",
      "unknown params:  tensor([-0.5552, -1.2623])\n",
      "unknown variance:  tensor([[1.3115]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4230, -0.5987])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.34820085763931274]\n",
      "100 steps | score: [0.12894724309444427]\n",
      "200 steps | score: [0.10874035954475403]\n",
      "300 steps | score: [0.15008993446826935]\n",
      "400 steps | score: [0.08249983936548233]\n",
      "500 steps | score: [0.07938753813505173]\n",
      "600 steps | score: [0.0016660429537296295]\n",
      "0 steps | score: [0.15344120562076569, 0.056949980556964874]\n",
      "100 steps | score: [0.02725941315293312, 0.1298818588256836]\n",
      "200 steps | score: [-0.12678778171539307, 0.3357842266559601]\n",
      "300 steps | score: [0.1446252316236496, -0.21366377174854279]\n",
      "400 steps | score: [0.04178335890173912, 0.007542818784713745]\n",
      "500 steps | score: [0.011221865192055702, 0.04171176254749298]\n",
      "600 steps | score: [-0.22830621898174286, 0.4515044093132019]\n",
      "700 steps | score: [0.013123960234224796, 0.04346292093396187]\n",
      "800 steps | score: [-0.07959658652544022, 0.20555774867534637]\n",
      "900 steps | score: [0.012408517301082611, 0.048994019627571106]\n",
      "1000 steps | score: [0.1685362309217453, -0.26265546679496765]\n",
      "1100 steps | score: [-0.09274353832006454, 0.2285633087158203]\n",
      "1200 steps | score: [0.1726694405078888, -0.2907724976539612]\n",
      "1300 steps | score: [0.04171116650104523, -0.013551600277423859]\n",
      "1400 steps | score: [0.0916595607995987, -0.1094038113951683]\n",
      "1500 steps | score: [-0.003539646975696087, 0.06954897940158844]\n",
      "1600 steps | score: [0.00706030149012804, 0.04503148794174194]\n",
      "1700 steps | score: [0.03390566259622574, 0.005951933562755585]\n",
      "1800 steps | score: [-0.0007482036598958075, 0.07027192413806915]\n",
      "1900 steps | score: [0.0007825731881894171, 0.06019482761621475]\n",
      "2000 steps | score: [0.0498497374355793, -0.02930045686662197]\n",
      "2100 steps | score: [-0.020604686811566353, 0.10777406394481659]\n",
      "2200 steps | score: [0.08229976147413254, -0.0908178836107254]\n",
      "2300 steps | score: [-0.01108027994632721, 0.08520901203155518]\n",
      "2400 steps | score: [-0.014573106542229652, 0.08411755412817001]\n",
      "2500 steps | score: [-0.03686927258968353, 0.1266297996044159]\n",
      "0 steps | score: [0.13381628692150116, 0.019864846020936966]\n",
      "100 steps | score: [-0.00039647630183026195, 0.11801862716674805]\n",
      "200 steps | score: [-0.15347012877464294, 0.3140358030796051]\n",
      "300 steps | score: [0.08050194382667542, -0.1447412520647049]\n",
      "400 steps | score: [0.0114981010556221, -0.011602271348237991]\n",
      "500 steps | score: [-0.028602005913853645, 0.05050162225961685]\n",
      "600 steps | score: [-0.24974584579467773, 0.41200822591781616]\n",
      "700 steps | score: [-0.03372220695018768, 0.04709921404719353]\n",
      "800 steps | score: [-0.1347813606262207, 0.22129866480827332]\n",
      "900 steps | score: [-0.03970532491803169, 0.06146463379263878]\n",
      "1000 steps | score: [0.10844100266695023, -0.2314501851797104]\n",
      "1100 steps | score: [-0.12560054659843445, 0.21966858208179474]\n",
      "1200 steps | score: [0.11303722113370895, -0.2368718832731247]\n",
      "1300 steps | score: [-0.01455566007643938, 0.014900398440659046]\n",
      "1400 steps | score: [0.028573399409651756, -0.06772051751613617]\n",
      "1500 steps | score: [-0.06944917887449265, 0.11254557967185974]\n",
      "1600 steps | score: [-0.03604775667190552, 0.060145653784275055]\n",
      "1700 steps | score: [-0.03852653503417969, 0.06915652006864548]\n",
      "1800 steps | score: [-0.0406438410282135, 0.058602474629879]\n",
      "1900 steps | score: [-0.051478248089551926, 0.07862307131290436]\n",
      "2000 steps | score: [-0.04426861181855202, 0.05631110072135925]\n",
      "2100 steps | score: [-0.07961302250623703, 0.13197298347949982]\n",
      "2200 steps | score: [0.006926168221980333, -0.029200734570622444]\n",
      "2300 steps | score: [-0.06460472196340561, 0.1100388914346695]\n",
      "2400 steps | score: [-0.04386693984270096, 0.06967277824878693]\n",
      "2500 steps | score: [-0.08695763349533081, 0.15806972980499268]\n",
      "0 steps | score: [0.1388407051563263, 0.03795787692070007]\n",
      "100 steps | score: [-0.02263285219669342, 0.18000057339668274]\n",
      "200 steps | score: [-0.15424275398254395, 0.33733227849006653]\n",
      "300 steps | score: [0.06891239434480667, -0.08846911787986755]\n",
      "400 steps | score: [0.0031142649240791798, 0.037197746336460114]\n",
      "500 steps | score: [-0.014417690224945545, 0.054469022899866104]\n",
      "600 steps | score: [-0.22049134969711304, 0.3973256051540375]\n",
      "700 steps | score: [-0.0034518875181674957, 0.02802858129143715]\n",
      "800 steps | score: [-0.10732580721378326, 0.21340249478816986]\n",
      "900 steps | score: [-0.049329474568367004, 0.11523508280515671]\n",
      "1000 steps | score: [0.12326251715421677, -0.21668143570423126]\n",
      "1100 steps | score: [-0.1002865880727768, 0.21262751519680023]\n",
      "1200 steps | score: [0.13689251244068146, -0.2651616334915161]\n",
      "1300 steps | score: [0.008812795393168926, 0.0032792743295431137]\n",
      "unknown params:  tensor([-0.4870, -1.1228])\n",
      "unknown variance:  tensor([[1.3387]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4230, -0.5987])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3070012629032135]\n",
      "100 steps | score: [0.00865224190056324]\n",
      "0 steps | score: [0.18477316200733185, -0.14123636484146118]\n",
      "100 steps | score: [-0.1502142995595932, 0.35869157314300537]\n",
      "200 steps | score: [-0.060344088822603226, 0.1621445119380951]\n",
      "300 steps | score: [-0.12703289091587067, 0.24949926137924194]\n",
      "400 steps | score: [-0.053978271782398224, 0.10078632831573486]\n",
      "500 steps | score: [0.10377974808216095, -0.24838025867938995]\n",
      "600 steps | score: [-0.08836551010608673, 0.16699407994747162]\n",
      "700 steps | score: [-0.000625721993856132, -0.015506482683122158]\n",
      "800 steps | score: [-0.007800760213285685, -0.018246345221996307]\n",
      "900 steps | score: [-0.19786857068538666, 0.35317257046699524]\n",
      "1000 steps | score: [0.11342122405767441, -0.26956915855407715]\n",
      "1100 steps | score: [0.03899228945374489, -0.10157398134469986]\n",
      "1200 steps | score: [-0.04447381943464279, 0.06026593595743179]\n",
      "1300 steps | score: [-0.021168725565075874, 0.020144034177064896]\n",
      "1400 steps | score: [-0.0006237904890440404, -0.0337117537856102]\n",
      "1500 steps | score: [-0.030013805255293846, 0.03017439693212509]\n",
      "1600 steps | score: [0.056258708238601685, -0.14568328857421875]\n",
      "1700 steps | score: [-0.0003300260577816516, -0.018920019268989563]\n",
      "1800 steps | score: [0.08193603903055191, -0.21450701355934143]\n",
      "1900 steps | score: [-0.03260590136051178, 0.03902532905340195]\n",
      "2000 steps | score: [0.09810085594654083, -0.23148630559444427]\n",
      "2100 steps | score: [-0.016329267993569374, 0.0018489547073841095]\n",
      "2200 steps | score: [-0.0683634877204895, 0.10075267404317856]\n",
      "2300 steps | score: [-0.029678167775273323, 0.02631828933954239]\n",
      "2400 steps | score: [-0.03018803894519806, 0.0280851349234581]\n",
      "2500 steps | score: [0.05021963641047478, -0.15310201048851013]\n",
      "2600 steps | score: [0.0021069487556815147, -0.03406961262226105]\n",
      "unknown params:  tensor([-0.4634, -1.1818])\n",
      "unknown variance:  tensor([[1.4790]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/a334fc1f-2f0d-43fb-aeec-60253c209f97\n",
      "gt params:  tensor([-0.4307, -0.5714])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [-0.053923334926366806]\n",
      "100 steps | score: [-0.23278634250164032]\n",
      "200 steps | score: [-0.2378859519958496]\n",
      "300 steps | score: [-0.23815183341503143]\n",
      "400 steps | score: [-0.1885763257741928]\n",
      "500 steps | score: [-0.1775536686182022]\n",
      "600 steps | score: [-0.14286842942237854]\n",
      "700 steps | score: [-0.17637008428573608]\n",
      "800 steps | score: [-0.20717956125736237]\n",
      "900 steps | score: [-0.18867120146751404]\n",
      "1000 steps | score: [-0.20229516923427582]\n",
      "1100 steps | score: [-0.22511325776576996]\n",
      "1200 steps | score: [-0.20947864651679993]\n",
      "1300 steps | score: [-0.16845493018627167]\n",
      "1400 steps | score: [-0.18069908022880554]\n",
      "1500 steps | score: [-0.18160200119018555]\n",
      "1600 steps | score: [-0.15867654979228973]\n",
      "1700 steps | score: [-0.18325075507164001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 steps | score: [-0.2064133733510971]\n",
      "1900 steps | score: [-0.18715739250183105]\n",
      "2000 steps | score: [-0.19767658412456512]\n",
      "2100 steps | score: [-0.17389483749866486]\n",
      "2200 steps | score: [-0.19416290521621704]\n",
      "2300 steps | score: [-0.1721569001674652]\n",
      "2400 steps | score: [-0.1975073665380478]\n",
      "2500 steps | score: [-0.20667731761932373]\n",
      "2600 steps | score: [-0.18039941787719727]\n",
      "0 steps | score: [0.0455109179019928, 0.08096106350421906]\n",
      "100 steps | score: [-0.010702881030738354, 0.01912493258714676]\n",
      "200 steps | score: [-0.03381699323654175, 0.02754034847021103]\n",
      "300 steps | score: [-0.01330244168639183, 0.08769948780536652]\n",
      "400 steps | score: [0.012959197163581848, 0.028547022491693497]\n",
      "500 steps | score: [0.01342618465423584, 0.050478968769311905]\n",
      "600 steps | score: [0.03600987419486046, 0.04091780632734299]\n",
      "700 steps | score: [0.008098405785858631, 0.028839468955993652]\n",
      "800 steps | score: [0.008915894664824009, 0.028967617079615593]\n",
      "900 steps | score: [0.009196926839649677, 0.020288454368710518]\n",
      "1000 steps | score: [0.012888998724520206, 0.0228885430842638]\n",
      "1100 steps | score: [-0.003086615353822708, 0.03049258142709732]\n",
      "1200 steps | score: [0.008374742232263088, 0.020656967535614967]\n",
      "1300 steps | score: [0.014653628692030907, 0.022129597142338753]\n",
      "1400 steps | score: [0.008862128481268883, 0.040337178856134415]\n",
      "1500 steps | score: [0.026001255959272385, 0.021145373582839966]\n",
      "1600 steps | score: [0.021405402570962906, 0.021002229303121567]\n",
      "1700 steps | score: [0.008627981878817081, 0.01222474966198206]\n",
      "1800 steps | score: [0.015326489694416523, 0.02464125119149685]\n",
      "1900 steps | score: [0.010776720009744167, 0.011850758455693722]\n",
      "2000 steps | score: [0.00879350584000349, 0.02144368551671505]\n",
      "2100 steps | score: [0.015484937466681004, 0.02786000445485115]\n",
      "2200 steps | score: [0.013378249481320381, 0.01990857720375061]\n",
      "2300 steps | score: [0.013791227713227272, 0.01620958000421524]\n",
      "2400 steps | score: [0.009656192734837532, 0.012640303000807762]\n",
      "2500 steps | score: [0.015911702066659927, 0.027496615424752235]\n",
      "2600 steps | score: [0.01051163300871849, 0.021514056250452995]\n",
      "0 steps | score: [0.07378044724464417, 0.07485955208539963]\n",
      "100 steps | score: [0.0219531562179327, 0.021870354190468788]\n",
      "200 steps | score: [-0.011594194918870926, 0.020637735724449158]\n",
      "300 steps | score: [0.014469149522483349, 0.08402881026268005]\n",
      "400 steps | score: [0.035914648324251175, 0.02004523202776909]\n",
      "500 steps | score: [0.03985320404171944, 0.051496535539627075]\n",
      "600 steps | score: [0.061155714094638824, 0.03475426137447357]\n",
      "700 steps | score: [0.028914008289575577, 0.02670527808368206]\n",
      "800 steps | score: [0.030480995774269104, 0.030091417953372]\n",
      "900 steps | score: [0.028197962790727615, 0.022197801619768143]\n",
      "1000 steps | score: [0.04022398218512535, 0.02689407393336296]\n",
      "1100 steps | score: [0.019612710922956467, 0.033563096076250076]\n",
      "1200 steps | score: [0.02703576534986496, 0.028404098004102707]\n",
      "1300 steps | score: [0.04352260008454323, 0.025860097259283066]\n",
      "1400 steps | score: [0.03208830952644348, 0.04006640985608101]\n",
      "1500 steps | score: [0.045549891889095306, 0.022069616243243217]\n",
      "1600 steps | score: [0.043336350470781326, 0.016655931249260902]\n",
      "1700 steps | score: [0.03220713138580322, 0.012882577255368233]\n",
      "1800 steps | score: [0.03870147094130516, 0.02967451512813568]\n",
      "1900 steps | score: [0.039785031229257584, 0.011940784752368927]\n",
      "2000 steps | score: [0.029162045568227768, 0.016346663236618042]\n",
      "2100 steps | score: [0.03211459890007973, 0.02777373045682907]\n",
      "2200 steps | score: [0.032420385628938675, 0.018296444788575172]\n",
      "2300 steps | score: [0.03748631477355957, 0.022126246243715286]\n",
      "2400 steps | score: [0.03207678347826004, 0.010818456299602985]\n",
      "2500 steps | score: [0.04056798294186592, 0.023360509425401688]\n",
      "2600 steps | score: [0.03454050049185753, 0.019858431071043015]\n",
      "0 steps | score: [0.04149739816784859, 0.06644367426633835]\n",
      "100 steps | score: [-0.01459586899727583, 0.013610605150461197]\n",
      "200 steps | score: [-0.038385216146707535, 0.01863355189561844]\n",
      "300 steps | score: [-0.013090276159346104, 0.07322265952825546]\n",
      "400 steps | score: [0.010647383518517017, 0.023373911157250404]\n",
      "500 steps | score: [0.007671465631574392, 0.04274183139204979]\n",
      "600 steps | score: [0.026118142530322075, 0.024598825722932816]\n",
      "700 steps | score: [0.003036094130948186, 0.011164406314492226]\n",
      "800 steps | score: [0.013756952248513699, 0.017814526334404945]\n",
      "900 steps | score: [0.0057319761253893375, 0.01321092527359724]\n",
      "1000 steps | score: [0.016451360657811165, 0.0101214200258255]\n",
      "1100 steps | score: [-0.01080242544412613, 0.024006281048059464]\n",
      "1200 steps | score: [-0.002049187431111932, 0.018280941992998123]\n",
      "1300 steps | score: [0.01487007923424244, 0.012535963207483292]\n",
      "1400 steps | score: [0.008663427084684372, 0.041522543877363205]\n",
      "1500 steps | score: [0.0198811125010252, 0.015012997202575207]\n",
      "1600 steps | score: [0.015776515007019043, 0.009693902917206287]\n",
      "1700 steps | score: [0.006855613552033901, -0.001795182004570961]\n",
      "unknown params:  tensor([-0.4044, -0.4774])\n",
      "unknown variance:  tensor([[0.8669]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4307, -0.5714])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.14466804265975952]\n",
      "100 steps | score: [-0.009712889790534973]\n",
      "0 steps | score: [0.045907117426395416, 0.12357552349567413]\n",
      "100 steps | score: [-0.026762813329696655, 0.05032368376851082]\n",
      "200 steps | score: [0.017092125490307808, -0.013763952068984509]\n",
      "300 steps | score: [-0.013728700578212738, -3.7196092307567596e-05]\n",
      "400 steps | score: [0.01746918261051178, 0.04032154753804207]\n",
      "500 steps | score: [-0.03807525709271431, 0.03059513494372368]\n",
      "600 steps | score: [0.021430673077702522, 0.006213419139385223]\n",
      "700 steps | score: [-0.020633447915315628, 0.03065142035484314]\n",
      "800 steps | score: [0.010578778572380543, 0.040955644100904465]\n",
      "900 steps | score: [-0.02094411477446556, 0.02096446417272091]\n",
      "1000 steps | score: [-0.018131401389837265, 0.024143487215042114]\n",
      "1100 steps | score: [-0.01064208708703518, 0.025855641812086105]\n",
      "1200 steps | score: [0.0014685074565932155, 0.0396953821182251]\n",
      "1300 steps | score: [-0.025116316974163055, 0.01992097869515419]\n",
      "1400 steps | score: [-0.01875179447233677, 0.03762368485331535]\n",
      "1500 steps | score: [-0.020928846672177315, 0.03974961116909981]\n",
      "1600 steps | score: [0.004074445925652981, 0.03722146153450012]\n",
      "1700 steps | score: [-0.023044249042868614, 0.02829677239060402]\n",
      "1800 steps | score: [-0.012762424536049366, 0.033760156482458115]\n",
      "1900 steps | score: [-0.018352655693888664, 0.03905949741601944]\n",
      "2000 steps | score: [0.00048133128439076245, 0.02442074939608574]\n",
      "2100 steps | score: [-0.020408155396580696, 0.024519890546798706]\n",
      "2200 steps | score: [-0.01576600782573223, 0.030241219326853752]\n",
      "2300 steps | score: [-0.01966658979654312, 0.032310955226421356]\n",
      "2400 steps | score: [-0.005429450422525406, 0.03304606303572655]\n",
      "2500 steps | score: [-0.010385037399828434, 0.023295897990465164]\n",
      "2600 steps | score: [-0.021048912778496742, 0.03234655782580376]\n",
      "2700 steps | score: [-0.013218778185546398, 0.02824629470705986]\n",
      "2800 steps | score: [-0.004758548457175493, 0.028798729181289673]\n",
      "0 steps | score: [0.007682388182729483, 0.17361386120319366]\n",
      "100 steps | score: [-0.05712516978383064, 0.09006089717149734]\n",
      "200 steps | score: [0.004820824600756168, 0.011078959330916405]\n",
      "300 steps | score: [-0.03743471950292587, 0.03198441490530968]\n",
      "400 steps | score: [-0.016520291566848755, 0.07370625436306]\n",
      "500 steps | score: [-0.06802967190742493, 0.06841479241847992]\n",
      "600 steps | score: [0.0041339038871228695, 0.03856569901108742]\n",
      "700 steps | score: [-0.039075322449207306, 0.06021878868341446]\n",
      "800 steps | score: [-0.01206686906516552, 0.07057252526283264]\n",
      "900 steps | score: [-0.0560714527964592, 0.053942352533340454]\n",
      "1000 steps | score: [-0.04771553725004196, 0.0617092028260231]\n",
      "1100 steps | score: [-0.029991351068019867, 0.06610807776451111]\n",
      "1200 steps | score: [-0.015029795467853546, 0.06641998887062073]\n",
      "1300 steps | score: [-0.05392586812376976, 0.05755850300192833]\n",
      "1400 steps | score: [-0.048107534646987915, 0.07242346554994583]\n",
      "1500 steps | score: [-0.051645081490278244, 0.07910070568323135]\n",
      "1600 steps | score: [-0.03271898999810219, 0.07127366214990616]\n",
      "1700 steps | score: [-0.054572489112615585, 0.057184092700481415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 steps | score: [-0.047753747552633286, 0.06773488223552704]\n",
      "1900 steps | score: [-0.043993398547172546, 0.06512290239334106]\n",
      "2000 steps | score: [-0.030652739107608795, 0.06524752825498581]\n",
      "2100 steps | score: [-0.043836504220962524, 0.05616527795791626]\n",
      "2200 steps | score: [-0.04229550436139107, 0.06284964084625244]\n",
      "2300 steps | score: [-0.048019539564847946, 0.07234230637550354]\n",
      "2400 steps | score: [-0.03196524828672409, 0.06728886067867279]\n",
      "2500 steps | score: [-0.04118421673774719, 0.06158771365880966]\n",
      "2600 steps | score: [-0.04146634042263031, 0.06881057471036911]\n",
      "2700 steps | score: [-0.03420671820640564, 0.07220019400119781]\n",
      "2800 steps | score: [-0.0336124561727047, 0.06987488269805908]\n",
      "0 steps | score: [0.05635620653629303, 0.10544279217720032]\n",
      "100 steps | score: [-0.013708224520087242, 0.03644236549735069]\n",
      "200 steps | score: [0.030146241188049316, -0.037238288670778275]\n",
      "300 steps | score: [-0.004577928688377142, -0.016662482172250748]\n",
      "400 steps | score: [0.02648705057799816, 0.023739980533719063]\n",
      "500 steps | score: [-0.02086741104722023, 0.011330251581966877]\n",
      "600 steps | score: [0.032329149544239044, -0.012920787557959557]\n",
      "700 steps | score: [0.0008112453506328166, -4.421453922986984e-06]\n",
      "unknown params:  tensor([-0.4136, -0.4878])\n",
      "unknown variance:  tensor([[0.9093]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4307, -0.5714])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [-0.002891410142183304]\n",
      "100 steps | score: [-0.11807063966989517]\n",
      "200 steps | score: [-0.2255016565322876]\n",
      "300 steps | score: [-0.09151464700698853]\n",
      "400 steps | score: [-0.18884287774562836]\n",
      "500 steps | score: [-0.15255767107009888]\n",
      "600 steps | score: [-0.16988229751586914]\n",
      "700 steps | score: [-0.1396770030260086]\n",
      "800 steps | score: [-0.1605035662651062]\n",
      "900 steps | score: [-0.17180748283863068]\n",
      "1000 steps | score: [-0.18400317430496216]\n",
      "1100 steps | score: [-0.11747866868972778]\n",
      "1200 steps | score: [-0.144797682762146]\n",
      "1300 steps | score: [-0.16937029361724854]\n",
      "1400 steps | score: [-0.1672430783510208]\n",
      "1500 steps | score: [-0.12713047862052917]\n",
      "1600 steps | score: [-0.1625124216079712]\n",
      "1700 steps | score: [-0.17464005947113037]\n",
      "1800 steps | score: [-0.13808298110961914]\n",
      "1900 steps | score: [-0.18743911385536194]\n",
      "2000 steps | score: [-0.15254637598991394]\n",
      "2100 steps | score: [-0.15153351426124573]\n",
      "2200 steps | score: [-0.13280965387821198]\n",
      "2300 steps | score: [-0.1575278490781784]\n",
      "2400 steps | score: [-0.1646430790424347]\n",
      "2500 steps | score: [-0.15820729732513428]\n",
      "2600 steps | score: [-0.12543044984340668]\n",
      "0 steps | score: [0.09229335933923721, 0.10543009638786316]\n",
      "100 steps | score: [-0.013893919996917248, -0.005923837423324585]\n",
      "200 steps | score: [-0.03677905723452568, 0.05367478355765343]\n",
      "300 steps | score: [0.047158099710941315, -0.008212280459702015]\n",
      "400 steps | score: [-0.011494392529129982, 0.027473166584968567]\n",
      "500 steps | score: [-0.006635760888457298, 0.013187054544687271]\n",
      "600 steps | score: [-0.013687166385352612, 0.04382885619997978]\n",
      "700 steps | score: [0.025381451472640038, 0.004381746053695679]\n",
      "800 steps | score: [-0.014099839143455029, 0.034603338688611984]\n",
      "900 steps | score: [-0.018488189205527306, 0.029975006356835365]\n",
      "1000 steps | score: [-0.03415388613939285, 0.051158320158720016]\n",
      "1100 steps | score: [0.013314293697476387, 0.028218086808919907]\n",
      "1200 steps | score: [0.047461580485105515, -0.06256917119026184]\n",
      "1300 steps | score: [-0.015002366155385971, 0.02732275426387787]\n",
      "1400 steps | score: [0.010580440983176231, 0.01495349034667015]\n",
      "1500 steps | score: [0.012222426012158394, 0.018845312297344208]\n",
      "1600 steps | score: [0.007653152570128441, -0.011482124216854572]\n",
      "1700 steps | score: [-0.004137633368372917, 0.014750968664884567]\n",
      "1800 steps | score: [0.017281614243984222, 0.003422889858484268]\n",
      "1900 steps | score: [0.000634486903436482, 0.019491244107484818]\n",
      "2000 steps | score: [0.014023584313690662, -0.009399035014212132]\n",
      "2100 steps | score: [0.004486450459808111, 0.012207293882966042]\n",
      "2200 steps | score: [0.013651557266712189, 0.004178440198302269]\n",
      "2300 steps | score: [-0.007004339247941971, 0.015188378281891346]\n",
      "2400 steps | score: [0.00021916946570854634, 0.004841625690460205]\n",
      "0 steps | score: [0.058877766132354736, 0.11208386719226837]\n",
      "100 steps | score: [-0.020280128344893456, -0.017117826268076897]\n",
      "200 steps | score: [-0.06022175773978233, 0.06269574165344238]\n",
      "300 steps | score: [0.032122060656547546, -0.0055684661492705345]\n",
      "400 steps | score: [-0.027094492688775063, 0.01923861727118492]\n",
      "500 steps | score: [-0.01899426244199276, 0.013014830648899078]\n",
      "600 steps | score: [-0.022032655775547028, 0.041562601923942566]\n",
      "700 steps | score: [0.009254727512598038, 0.0017013102769851685]\n",
      "0 steps | score: [0.05658256262540817, 0.1165008470416069]\n",
      "100 steps | score: [-0.030802559107542038, -0.012339510954916477]\n",
      "200 steps | score: [-0.057734400033950806, 0.060337040573358536]\n",
      "300 steps | score: [0.03489144518971443, -0.011785296723246574]\n",
      "400 steps | score: [-0.03215567395091057, 0.032124970108270645]\n",
      "500 steps | score: [-0.009723469614982605, 0.011820811778306961]\n",
      "600 steps | score: [-0.03699617460370064, 0.04936738312244415]\n",
      "700 steps | score: [0.0030483475420624018, 0.005242230370640755]\n",
      "unknown params:  tensor([-0.4190, -0.4806])\n",
      "unknown variance:  tensor([[0.9341]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4307, -0.5714])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.38576740026474]\n",
      "100 steps | score: [0.29195037484169006]\n",
      "200 steps | score: [0.30627232789993286]\n",
      "300 steps | score: [0.25787782669067383]\n",
      "400 steps | score: [0.19020159542560577]\n",
      "500 steps | score: [0.18233036994934082]\n",
      "600 steps | score: [0.24712665379047394]\n",
      "700 steps | score: [0.2644502520561218]\n",
      "800 steps | score: [0.2995088994503021]\n",
      "900 steps | score: [0.2591589093208313]\n",
      "1000 steps | score: [0.25882688164711]\n",
      "1100 steps | score: [0.20155301690101624]\n",
      "1200 steps | score: [0.23260942101478577]\n",
      "1300 steps | score: [0.24743062257766724]\n",
      "1400 steps | score: [0.27694424986839294]\n",
      "1500 steps | score: [0.2724149227142334]\n",
      "1600 steps | score: [0.28726741671562195]\n",
      "1700 steps | score: [0.2669355869293213]\n",
      "1800 steps | score: [0.2649100422859192]\n",
      "1900 steps | score: [0.2231307476758957]\n",
      "2000 steps | score: [0.23662030696868896]\n",
      "2100 steps | score: [0.2599380910396576]\n",
      "2200 steps | score: [0.2400510013103485]\n",
      "2300 steps | score: [0.25650936365127563]\n",
      "2400 steps | score: [0.2801401615142822]\n",
      "2500 steps | score: [0.22943812608718872]\n",
      "2600 steps | score: [0.24408309161663055]\n",
      "2700 steps | score: [0.25929635763168335]\n",
      "2800 steps | score: [0.2466309368610382]\n",
      "0 steps | score: [0.10118074715137482, 0.0799807459115982]\n",
      "100 steps | score: [0.04421987757086754, -0.11640462279319763]\n",
      "200 steps | score: [0.07024336606264114, -0.0640406385064125]\n",
      "300 steps | score: [0.007703162729740143, -0.03430264815688133]\n",
      "400 steps | score: [-0.02837918885052204, 0.02034550905227661]\n",
      "500 steps | score: [-0.06254296749830246, 0.04608122259378433]\n",
      "600 steps | score: [0.03636619448661804, -0.03836040198802948]\n",
      "700 steps | score: [0.00981973297894001, -0.010154232382774353]\n",
      "800 steps | score: [0.038496505469083786, -0.08427058905363083]\n",
      "900 steps | score: [0.021504003554582596, -0.018568359315395355]\n",
      "1000 steps | score: [0.033075712621212006, -0.05156112462282181]\n",
      "1100 steps | score: [-0.02014346793293953, 0.013231859542429447]\n",
      "1200 steps | score: [-0.05180740728974342, 0.026440560817718506]\n",
      "1300 steps | score: [-0.00040254404302686453, -0.003805681597441435]\n",
      "0 steps | score: [0.05304540693759918, 0.11662531644105911]\n",
      "100 steps | score: [0.005737713538110256, -0.07900696247816086]\n",
      "200 steps | score: [0.015028662048280239, -0.008083810098469257]\n",
      "300 steps | score: [-0.03533805534243584, 0.011227213777601719]\n",
      "400 steps | score: [-0.07375083863735199, 0.05537339672446251]\n",
      "500 steps | score: [-0.11386862397193909, 0.07920099794864655]\n",
      "600 steps | score: [-0.012749592773616314, 0.008809835650026798]\n",
      "700 steps | score: [-0.024333084002137184, 0.021396182477474213]\n",
      "800 steps | score: [-0.006144730374217033, -0.046517785638570786]\n",
      "900 steps | score: [-0.020578453317284584, 0.01739838346838951]\n",
      "1000 steps | score: [-0.008992698974907398, -0.011574321426451206]\n",
      "1100 steps | score: [-0.06498579680919647, 0.043372742831707]\n",
      "1200 steps | score: [-0.10153692215681076, 0.059476565569639206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 steps | score: [-0.04200202599167824, 0.02394765615463257]\n",
      "1400 steps | score: [-0.03892127051949501, 0.02095244824886322]\n",
      "1500 steps | score: [-0.01262633316218853, -0.025178227573633194]\n",
      "1600 steps | score: [-0.027348175644874573, 0.008560271933674812]\n",
      "1700 steps | score: [-0.027679385617375374, 0.006162411533296108]\n",
      "1800 steps | score: [-0.06392275542020798, 0.03454507514834404]\n",
      "1900 steps | score: [-0.058538373559713364, 0.027313612401485443]\n",
      "2000 steps | score: [-0.04945197328925133, 0.018499795347452164]\n",
      "2100 steps | score: [-0.03485316038131714, 0.011603286489844322]\n",
      "2200 steps | score: [-0.04141039401292801, 0.0037899482995271683]\n",
      "2300 steps | score: [-0.047587644308805466, 0.017383098602294922]\n",
      "2400 steps | score: [-0.031376950442790985, 0.006428585387766361]\n",
      "2500 steps | score: [-0.04959838464856148, 0.027176465839147568]\n",
      "2600 steps | score: [-0.0382036492228508, 0.007732630707323551]\n",
      "2700 steps | score: [-0.04503326863050461, 0.019442450255155563]\n",
      "2800 steps | score: [-0.0454997792840004, 0.021096626296639442]\n",
      "0 steps | score: [0.16721448302268982, 0.006008420139551163]\n",
      "100 steps | score: [0.10502805560827255, -0.1768253892660141]\n",
      "200 steps | score: [0.13075610995292664, -0.12458179146051407]\n",
      "300 steps | score: [0.06583744287490845, -0.09459361433982849]\n",
      "400 steps | score: [0.008337548933923244, -0.034949228167533875]\n",
      "500 steps | score: [-0.02416710928082466, -0.01332168746739626]\n",
      "600 steps | score: [0.0914803296327591, -0.10844831168651581]\n",
      "700 steps | score: [0.059895921498537064, -0.06448563933372498]\n",
      "800 steps | score: [0.08783755451440811, -0.13973817229270935]\n",
      "900 steps | score: [0.06740453094244003, -0.07801750302314758]\n",
      "1000 steps | score: [0.07569647580385208, -0.09449329227209091]\n",
      "1100 steps | score: [0.033296938985586166, -0.05208587273955345]\n",
      "1200 steps | score: [-0.002763010561466217, -0.03705614060163498]\n",
      "1300 steps | score: [0.06024022400379181, -0.076325424015522]\n",
      "1400 steps | score: [0.06230343505740166, -0.07428757101297379]\n",
      "1500 steps | score: [0.07677485048770905, -0.12475243955850601]\n",
      "1600 steps | score: [0.07180189341306686, -0.09287940710783005]\n",
      "1700 steps | score: [0.07455666363239288, -0.09483559429645538]\n",
      "1800 steps | score: [0.03952891752123833, -0.05755513533949852]\n",
      "1900 steps | score: [0.0296318382024765, -0.06575088202953339]\n",
      "2000 steps | score: [0.046193499118089676, -0.0739545077085495]\n",
      "2100 steps | score: [0.05809837207198143, -0.07788003981113434]\n",
      "2200 steps | score: [0.05708833411335945, -0.09586255252361298]\n",
      "2300 steps | score: [0.054042454808950424, -0.07921787351369858]\n",
      "2400 steps | score: [0.0573665052652359, -0.08275432139635086]\n",
      "2500 steps | score: [0.04895313084125519, -0.06855228543281555]\n",
      "2600 steps | score: [0.04596618562936783, -0.08353857696056366]\n",
      "2700 steps | score: [0.05204056575894356, -0.07243305444717407]\n",
      "2800 steps | score: [0.05252915620803833, -0.07723213732242584]\n",
      "unknown params:  tensor([-0.4268, -0.5576])\n",
      "unknown variance:  tensor([[0.9653]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4307, -0.5714])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.11629550904035568]\n",
      "100 steps | score: [-0.015283340588212013]\n",
      "200 steps | score: [-0.041909243911504745]\n",
      "300 steps | score: [-0.07236222922801971]\n",
      "400 steps | score: [-0.13294552266597748]\n",
      "500 steps | score: [-0.04416074976325035]\n",
      "600 steps | score: [-0.054695792496204376]\n",
      "700 steps | score: [-0.11404414474964142]\n",
      "800 steps | score: [-0.12070859223604202]\n",
      "900 steps | score: [-0.07202532887458801]\n",
      "1000 steps | score: [-0.10432683676481247]\n",
      "1100 steps | score: [-0.09144511818885803]\n",
      "1200 steps | score: [-0.09100918471813202]\n",
      "1300 steps | score: [-0.09892871975898743]\n",
      "1400 steps | score: [-0.10885757207870483]\n",
      "1500 steps | score: [-0.06939397007226944]\n",
      "1600 steps | score: [-0.09844143688678741]\n",
      "1700 steps | score: [-0.07928650081157684]\n",
      "1800 steps | score: [-0.07646097242832184]\n",
      "1900 steps | score: [-0.06785812973976135]\n",
      "2000 steps | score: [-0.061226312071084976]\n",
      "2100 steps | score: [-0.08590832352638245]\n",
      "2200 steps | score: [-0.08743270486593246]\n",
      "2300 steps | score: [-0.09475500136613846]\n",
      "2400 steps | score: [-0.10170040279626846]\n",
      "2500 steps | score: [-0.07148069143295288]\n",
      "0 steps | score: [0.08972305804491043, 0.09529508650302887]\n",
      "100 steps | score: [-0.01186733040958643, -0.027379076927900314]\n",
      "200 steps | score: [0.022692397236824036, 0.0047597866505384445]\n",
      "300 steps | score: [-0.03114822320640087, 0.03105659782886505]\n",
      "400 steps | score: [-0.09618540108203888, 0.01642586663365364]\n",
      "500 steps | score: [0.04182865098118782, -0.06747011095285416]\n",
      "600 steps | score: [0.025210220366716385, -0.049168821424245834]\n",
      "700 steps | score: [0.02307116985321045, -0.0944456234574318]\n",
      "800 steps | score: [-0.02925434336066246, -3.4302473068237305e-05]\n",
      "900 steps | score: [-0.028218956664204597, 0.025091221556067467]\n",
      "1000 steps | score: [-0.034663401544094086, 0.01711687073111534]\n",
      "1100 steps | score: [-0.06475122272968292, 0.013827591203153133]\n",
      "1200 steps | score: [0.003327776212245226, -0.014323227107524872]\n",
      "1300 steps | score: [-0.04946479573845863, 0.038310933858156204]\n",
      "1400 steps | score: [-0.019421564415097237, -0.0199142973870039]\n",
      "1500 steps | score: [-0.01615353301167488, 0.0039902664721012115]\n",
      "1600 steps | score: [-0.0149966636672616, -0.005370881408452988]\n",
      "1700 steps | score: [-0.01143032405525446, -0.027011625468730927]\n",
      "1800 steps | score: [-0.010177696123719215, -0.01843363232910633]\n",
      "1900 steps | score: [0.0006168948602862656, -0.021504005417227745]\n",
      "2000 steps | score: [0.01939939521253109, -0.06363128125667572]\n",
      "2100 steps | score: [-0.02867957018315792, -0.008389418944716454]\n",
      "2200 steps | score: [-0.012056341394782066, -0.01739630103111267]\n",
      "2300 steps | score: [-0.03390755131840706, 0.010418541729450226]\n",
      "2400 steps | score: [-0.03534416854381561, 0.010554938577115536]\n",
      "2500 steps | score: [-0.023761607706546783, 0.00034446269273757935]\n",
      "unknown params:  tensor([-0.4550, -0.6752])\n",
      "unknown variance:  tensor([[1.0423]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4307, -0.5714])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.09986156225204468]\n",
      "100 steps | score: [-0.03459121286869049]\n",
      "200 steps | score: [-0.1274007260799408]\n",
      "300 steps | score: [-0.08399058878421783]\n",
      "400 steps | score: [-0.07867716997861862]\n",
      "500 steps | score: [-0.08164261281490326]\n",
      "600 steps | score: [-0.08738161623477936]\n",
      "700 steps | score: [-0.07262024283409119]\n",
      "800 steps | score: [-0.057013288140296936]\n",
      "900 steps | score: [-0.05305159091949463]\n",
      "1000 steps | score: [-0.0756206065416336]\n",
      "1100 steps | score: [-0.08308938145637512]\n",
      "1200 steps | score: [-0.0730607882142067]\n",
      "1300 steps | score: [-0.07568700611591339]\n",
      "1400 steps | score: [-0.07623410224914551]\n",
      "1500 steps | score: [-0.058097872883081436]\n",
      "1600 steps | score: [-0.0752408355474472]\n",
      "1700 steps | score: [-0.030607126653194427]\n",
      "1800 steps | score: [-0.07088148593902588]\n",
      "1900 steps | score: [-0.08859145641326904]\n",
      "2000 steps | score: [-0.06552638113498688]\n",
      "2100 steps | score: [-0.08531957119703293]\n",
      "2200 steps | score: [-0.05730028077960014]\n",
      "2300 steps | score: [-0.0526922233402729]\n",
      "2400 steps | score: [-0.08317425847053528]\n",
      "2500 steps | score: [-0.06592714786529541]\n",
      "2600 steps | score: [-0.03390410542488098]\n",
      "0 steps | score: [0.08536309748888016, 0.11951044946908951]\n",
      "100 steps | score: [0.0037769440095871687, 0.02651183307170868]\n",
      "200 steps | score: [-0.06045403331518173, 0.07471071928739548]\n",
      "300 steps | score: [-0.10512293875217438, 0.11731524765491486]\n",
      "400 steps | score: [-0.08927305787801743, 0.09235715121030807]\n",
      "500 steps | score: [0.015786603093147278, -0.03808365762233734]\n",
      "600 steps | score: [-0.08378886431455612, 0.0951201394200325]\n",
      "700 steps | score: [-0.07315654307603836, 0.04712534695863724]\n",
      "800 steps | score: [-0.01319496612995863, 0.00035000313073396683]\n",
      "900 steps | score: [-0.056969042867422104, 0.06494037806987762]\n",
      "1000 steps | score: [-0.06722167134284973, 0.06055234745144844]\n",
      "1100 steps | score: [-0.03458660468459129, 0.03771964833140373]\n",
      "1200 steps | score: [-0.0577659010887146, 0.06635433435440063]\n",
      "1300 steps | score: [-0.09524262696504593, 0.09180977940559387]\n",
      "1400 steps | score: [-0.018126945942640305, 0.009432894177734852]\n",
      "1500 steps | score: [-0.043138884007930756, 0.0483684316277504]\n",
      "1600 steps | score: [-0.09846753627061844, 0.10512395203113556]\n",
      "1700 steps | score: [-0.042162805795669556, 0.040067970752716064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 steps | score: [-0.049968793988227844, 0.05939924716949463]\n",
      "1900 steps | score: [-0.06720522046089172, 0.06831873953342438]\n",
      "2000 steps | score: [-0.05570615082979202, 0.053999386727809906]\n",
      "2100 steps | score: [-0.04127576947212219, 0.04471953213214874]\n",
      "2200 steps | score: [-0.062024012207984924, 0.056519027799367905]\n",
      "2300 steps | score: [-0.03949455916881561, 0.039406195282936096]\n",
      "2400 steps | score: [-0.06551780551671982, 0.06478986889123917]\n",
      "2500 steps | score: [-0.04375826194882393, 0.0394473522901535]\n",
      "2600 steps | score: [-0.025246188044548035, 0.020482998341321945]\n",
      "unknown params:  tensor([-0.4901, -0.8317])\n",
      "unknown variance:  tensor([[1.1273]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4307, -0.5714])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.13994404673576355]\n",
      "100 steps | score: [-0.0797058641910553]\n",
      "200 steps | score: [-0.05991246923804283]\n",
      "300 steps | score: [-0.11604470014572144]\n",
      "400 steps | score: [-0.10990485548973083]\n",
      "500 steps | score: [-0.13862565159797668]\n",
      "600 steps | score: [-0.09185761213302612]\n",
      "700 steps | score: [-0.12285294383764267]\n",
      "800 steps | score: [-0.1384499967098236]\n",
      "900 steps | score: [-0.09870844334363937]\n",
      "1000 steps | score: [-0.10250907391309738]\n",
      "1100 steps | score: [-0.11459740996360779]\n",
      "1200 steps | score: [-0.08252564817667007]\n",
      "1300 steps | score: [-0.11337905377149582]\n",
      "1400 steps | score: [-0.13338248431682587]\n",
      "1500 steps | score: [-0.13013891875743866]\n",
      "1600 steps | score: [-0.11595764011144638]\n",
      "1700 steps | score: [-0.09511663019657135]\n",
      "1800 steps | score: [-0.1037428006529808]\n",
      "1900 steps | score: [-0.12394435703754425]\n",
      "2000 steps | score: [-0.1169719249010086]\n",
      "2100 steps | score: [-0.11636152863502502]\n",
      "2200 steps | score: [-0.1000119000673294]\n",
      "2300 steps | score: [-0.15964865684509277]\n",
      "2400 steps | score: [-0.11660362035036087]\n",
      "2500 steps | score: [-0.11425140500068665]\n",
      "2600 steps | score: [-0.12143019586801529]\n",
      "0 steps | score: [0.13205859065055847, 0.12676629424095154]\n",
      "100 steps | score: [-0.04085236415266991, 0.17221282422542572]\n",
      "200 steps | score: [0.0784582570195198, -0.024499336257576942]\n",
      "300 steps | score: [-0.03003055416047573, 0.12726210057735443]\n",
      "400 steps | score: [-0.05234352499246597, 0.1330665647983551]\n",
      "500 steps | score: [-0.04298293963074684, 0.13429315388202667]\n",
      "600 steps | score: [0.047227777540683746, -0.040612831711769104]\n",
      "700 steps | score: [0.010603900998830795, 0.06723692268133163]\n",
      "800 steps | score: [-0.03736233338713646, 0.12482345104217529]\n",
      "900 steps | score: [0.009928829036653042, 0.038880109786987305]\n",
      "1000 steps | score: [0.04154384508728981, 0.004533411934971809]\n",
      "1100 steps | score: [-0.012807282619178295, 0.08701659739017487]\n",
      "1200 steps | score: [0.005965612828731537, 0.05448540672659874]\n",
      "1300 steps | score: [0.03664979711174965, 0.01265300065279007]\n",
      "1400 steps | score: [0.05687795206904411, -0.040375880897045135]\n",
      "1500 steps | score: [-0.024285638704895973, 0.09857277572154999]\n",
      "1600 steps | score: [-0.004055894911289215, 0.06985104084014893]\n",
      "1700 steps | score: [0.004266345873475075, 0.049256838858127594]\n",
      "1800 steps | score: [0.008495685644447803, 0.0529065877199173]\n",
      "1900 steps | score: [-0.013928909786045551, 0.08608697354793549]\n",
      "2000 steps | score: [0.0003733520279638469, 0.048729728907346725]\n",
      "2100 steps | score: [0.008510819636285305, 0.0492713525891304]\n",
      "2200 steps | score: [0.02520792745053768, 0.015994500368833542]\n",
      "2300 steps | score: [-0.0188670102506876, 0.08507905155420303]\n",
      "2400 steps | score: [-0.0052935173735022545, 0.07134866714477539]\n",
      "2500 steps | score: [0.03410037234425545, 0.016752813011407852]\n",
      "2600 steps | score: [-0.011432153172791004, 0.06411492824554443]\n",
      "unknown params:  tensor([-0.5153, -1.0023])\n",
      "unknown variance:  tensor([[1.2361]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4307, -0.5714])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3205487132072449]\n",
      "100 steps | score: [-0.032774418592453]\n",
      "200 steps | score: [0.14151175320148468]\n",
      "300 steps | score: [0.11846952885389328]\n",
      "400 steps | score: [0.02767249196767807]\n",
      "500 steps | score: [0.106234610080719]\n",
      "600 steps | score: [0.07808792591094971]\n",
      "700 steps | score: [0.09252751618623734]\n",
      "800 steps | score: [0.1419476866722107]\n",
      "900 steps | score: [0.08493782579898834]\n",
      "1000 steps | score: [0.15574440360069275]\n",
      "1100 steps | score: [0.0800216794013977]\n",
      "1200 steps | score: [0.099525585770607]\n",
      "1300 steps | score: [0.057041995227336884]\n",
      "1400 steps | score: [0.13183742761611938]\n",
      "1500 steps | score: [0.140520378947258]\n",
      "1600 steps | score: [0.10329992324113846]\n",
      "1700 steps | score: [0.09901691973209381]\n",
      "1800 steps | score: [0.08203861117362976]\n",
      "1900 steps | score: [0.0901804119348526]\n",
      "2000 steps | score: [0.12659189105033875]\n",
      "2100 steps | score: [0.10961919277906418]\n",
      "2200 steps | score: [0.11889155209064484]\n",
      "2300 steps | score: [0.09239500761032104]\n",
      "2400 steps | score: [0.10354762524366379]\n",
      "2500 steps | score: [0.08646859973669052]\n",
      "2600 steps | score: [0.116907998919487]\n",
      "0 steps | score: [0.22026249766349792, -0.06796273589134216]\n",
      "100 steps | score: [-0.1415538340806961, 0.2711465358734131]\n",
      "200 steps | score: [0.06212027743458748, -0.03918240964412689]\n",
      "300 steps | score: [0.008471358567476273, 0.008804325014352798]\n",
      "unknown params:  tensor([-0.4953, -1.0852])\n",
      "unknown variance:  tensor([[1.3479]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4307, -0.5714])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.33614662289619446]\n",
      "100 steps | score: [0.09497319161891937]\n",
      "200 steps | score: [0.10630697757005692]\n",
      "300 steps | score: [0.03944995254278183]\n",
      "400 steps | score: [0.08597058802843094]\n",
      "500 steps | score: [0.09177187830209732]\n",
      "600 steps | score: [0.102284274995327]\n",
      "700 steps | score: [0.09028106927871704]\n",
      "800 steps | score: [0.05599011853337288]\n",
      "900 steps | score: [0.09767112880945206]\n",
      "1000 steps | score: [0.06015293672680855]\n",
      "1100 steps | score: [0.09021474421024323]\n",
      "1200 steps | score: [0.02767510712146759]\n",
      "1300 steps | score: [0.074808269739151]\n",
      "1400 steps | score: [0.06524965167045593]\n",
      "1500 steps | score: [0.08131131529808044]\n",
      "1600 steps | score: [0.04830751568078995]\n",
      "1700 steps | score: [0.0760117694735527]\n",
      "1800 steps | score: [0.05340607836842537]\n",
      "1900 steps | score: [0.08732737600803375]\n",
      "2000 steps | score: [0.06060517951846123]\n",
      "2100 steps | score: [0.06463752686977386]\n",
      "2200 steps | score: [0.07696161419153214]\n",
      "2300 steps | score: [0.04822031036019325]\n",
      "2400 steps | score: [0.11434613168239594]\n",
      "2500 steps | score: [0.04474407434463501]\n",
      "0 steps | score: [0.16560587286949158, -0.019082404673099518]\n",
      "100 steps | score: [0.07847860455513, -0.008162923157215118]\n",
      "200 steps | score: [-0.02025010995566845, 0.10061413049697876]\n",
      "300 steps | score: [-0.17760564386844635, 0.3282243609428406]\n",
      "400 steps | score: [0.04097238555550575, -0.05161195993423462]\n",
      "500 steps | score: [-0.04179031029343605, 0.07972604036331177]\n",
      "600 steps | score: [0.08118816465139389, -0.1385881006717682]\n",
      "700 steps | score: [-0.04921877384185791, 0.08997243642807007]\n",
      "800 steps | score: [-0.13622280955314636, 0.2508406937122345]\n",
      "900 steps | score: [0.006020629778504372, -0.026309609413146973]\n",
      "1000 steps | score: [-0.02252320386469364, 0.038898687809705734]\n",
      "1100 steps | score: [0.17284102737903595, -0.3588513135910034]\n",
      "1200 steps | score: [-0.1329016089439392, 0.23685072362422943]\n",
      "1300 steps | score: [-0.0692436546087265, 0.14399731159210205]\n",
      "1400 steps | score: [-0.0838976725935936, 0.15694208443164825]\n",
      "1500 steps | score: [-0.0628829374909401, 0.11698221415281296]\n",
      "1600 steps | score: [0.00867812056094408, -0.017543654888868332]\n",
      "1700 steps | score: [-0.051079701632261276, 0.09088711440563202]\n",
      "1800 steps | score: [0.013321379199624062, -0.023928018286824226]\n",
      "1900 steps | score: [0.0030426527373492718, -0.001127384603023529]\n",
      "0 steps | score: [0.18947462737560272, -0.13855327665805817]\n",
      "100 steps | score: [0.08436713367700577, -0.10400225967168808]\n",
      "200 steps | score: [-0.008891047909855843, 0.002014201134443283]\n",
      "unknown params:  tensor([-0.5455, -1.3136])\n",
      "unknown variance:  tensor([[1.5034]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4307, -0.5714])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.17309701442718506]\n",
      "100 steps | score: [-0.08943904936313629]\n",
      "200 steps | score: [-0.1300041675567627]\n",
      "300 steps | score: [-0.09549456089735031]\n",
      "400 steps | score: [0.00291251577436924]\n",
      "0 steps | score: [0.13211515545845032, -0.04943586885929108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [0.014621329493820667, 0.06546080112457275]\n",
      "200 steps | score: [-0.12901288270950317, 0.27852708101272583]\n",
      "300 steps | score: [-0.09134463965892792, 0.18005581200122833]\n",
      "400 steps | score: [0.9551714658737183, -2.654348611831665]\n",
      "500 steps | score: [-0.06220834702253342, 0.09351756423711777]\n",
      "600 steps | score: [0.10178631544113159, -0.24349945783615112]\n",
      "700 steps | score: [0.15198184549808502, -0.3868623971939087]\n",
      "800 steps | score: [-0.10053814947605133, 0.15715493261814117]\n",
      "900 steps | score: [-0.14588813483715057, 0.24656108021736145]\n",
      "1000 steps | score: [-0.16668899357318878, 0.2797020673751831]\n",
      "1100 steps | score: [-0.028706584125757217, 0.00686870701611042]\n",
      "1200 steps | score: [-0.1495646983385086, 0.25343504548072815]\n",
      "1300 steps | score: [-0.12494685500860214, 0.20350143313407898]\n",
      "1400 steps | score: [-0.1490013152360916, 0.24311017990112305]\n",
      "1500 steps | score: [0.10733844339847565, -0.2965468168258667]\n",
      "1600 steps | score: [-0.07768065482378006, 0.10972122848033905]\n",
      "1700 steps | score: [0.027412207797169685, -0.11084084212779999]\n",
      "1800 steps | score: [-0.09226884692907333, 0.12955988943576813]\n",
      "1900 steps | score: [-0.06332922726869583, 0.0710810199379921]\n",
      "2000 steps | score: [-0.05234721675515175, 0.04261940345168114]\n",
      "2100 steps | score: [-0.11688099801540375, 0.17797406017780304]\n",
      "2200 steps | score: [-0.06981708109378815, 0.0785706639289856]\n",
      "2300 steps | score: [-0.06797373294830322, 0.08041175454854965]\n",
      "2400 steps | score: [-0.07932005822658539, 0.10846903920173645]\n",
      "2500 steps | score: [-0.08313863724470139, 0.10350149124860764]\n",
      "unknown params:  tensor([-0.4790, -1.2050])\n",
      "unknown variance:  tensor([[1.5340]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/a0de8e7b-87b3-4002-a8e1-76eec081c023\n",
      "gt params:  tensor([-0.4339, -0.5924])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.23147132992744446]\n",
      "100 steps | score: [0.08486445993185043]\n",
      "200 steps | score: [0.09093175083398819]\n",
      "300 steps | score: [0.16971297562122345]\n",
      "400 steps | score: [0.0902068018913269]\n",
      "500 steps | score: [0.11754319071769714]\n",
      "600 steps | score: [0.07199278473854065]\n",
      "700 steps | score: [0.1279071718454361]\n",
      "800 steps | score: [0.10588312149047852]\n",
      "900 steps | score: [0.13272780179977417]\n",
      "1000 steps | score: [0.09189864248037338]\n",
      "1100 steps | score: [0.042119596153497696]\n",
      "1200 steps | score: [0.11820535361766815]\n",
      "1300 steps | score: [0.06965936720371246]\n",
      "1400 steps | score: [0.09433028846979141]\n",
      "1500 steps | score: [0.06567415595054626]\n",
      "1600 steps | score: [0.1384885311126709]\n",
      "1700 steps | score: [0.11917193979024887]\n",
      "1800 steps | score: [0.15950605273246765]\n",
      "1900 steps | score: [0.09751591831445694]\n",
      "2000 steps | score: [0.08493289351463318]\n",
      "2100 steps | score: [0.13095785677433014]\n",
      "2200 steps | score: [0.10469487309455872]\n",
      "2300 steps | score: [0.10763517767190933]\n",
      "2400 steps | score: [0.09543420374393463]\n",
      "2500 steps | score: [0.1347954422235489]\n",
      "2600 steps | score: [0.1477862298488617]\n",
      "0 steps | score: [0.0020125850569456816, 0.07202214747667313]\n",
      "100 steps | score: [-0.02679768018424511, 0.05028075724840164]\n",
      "200 steps | score: [-0.022008545696735382, 0.059723854064941406]\n",
      "300 steps | score: [0.04842176288366318, -0.012546803802251816]\n",
      "400 steps | score: [-0.012362583540380001, -0.025495532900094986]\n",
      "500 steps | score: [-0.007184731308370829, 0.002618839032948017]\n",
      "0 steps | score: [0.023837774991989136, 0.07311833649873734]\n",
      "100 steps | score: [-0.0045400517992675304, 0.051098719239234924]\n",
      "200 steps | score: [-0.005331452935934067, 0.060944631695747375]\n",
      "300 steps | score: [0.059955719858407974, -0.016208359971642494]\n",
      "400 steps | score: [-0.00484900688752532, -0.036382753401994705]\n",
      "500 steps | score: [0.012266158126294613, -0.007540838792920113]\n",
      "600 steps | score: [-0.02037160098552704, 0.01791389100253582]\n",
      "700 steps | score: [-0.010508565232157707, 0.029232103377580643]\n",
      "800 steps | score: [0.009662432596087456, 0.02157810889184475]\n",
      "900 steps | score: [-0.0023762451019138098, -0.07512681186199188]\n",
      "1000 steps | score: [-0.010251670144498348, 0.018764156848192215]\n",
      "1100 steps | score: [-0.04115021601319313, 0.05413230136036873]\n",
      "1200 steps | score: [-0.0032402961514890194, 0.008506148122251034]\n",
      "0 steps | score: [0.06628381460905075, 0.049120016396045685]\n",
      "100 steps | score: [0.028745004907250404, 0.025519076734781265]\n",
      "200 steps | score: [0.02342277765274048, 0.028768353164196014]\n",
      "300 steps | score: [0.10137373208999634, -0.02378224767744541]\n",
      "400 steps | score: [0.03345070034265518, -0.05532851070165634]\n",
      "500 steps | score: [0.0434403195977211, -0.021829282864928246]\n",
      "600 steps | score: [0.015692560002207756, 0.0018925960175693035]\n",
      "700 steps | score: [0.019397465512156487, 0.01919860951602459]\n",
      "800 steps | score: [0.03917494788765907, -0.0030558668076992035]\n",
      "900 steps | score: [0.04021284729242325, -0.0851798951625824]\n",
      "1000 steps | score: [0.029677389189600945, -0.002328600501641631]\n",
      "1100 steps | score: [-0.007031528744846582, 0.033970337361097336]\n",
      "1200 steps | score: [0.035512182861566544, -0.01377035491168499]\n",
      "1300 steps | score: [0.011883634142577648, -0.010222082957625389]\n",
      "1400 steps | score: [0.021447528153657913, -0.014630723744630814]\n",
      "1500 steps | score: [0.02350553870201111, -0.0008725516963750124]\n",
      "1600 steps | score: [0.04349846765398979, -0.0029359813779592514]\n",
      "1700 steps | score: [0.05423728749155998, -0.009789282456040382]\n",
      "1800 steps | score: [0.04393770173192024, -0.03534384444355965]\n",
      "1900 steps | score: [0.03092309460043907, 0.0030094145331531763]\n",
      "2000 steps | score: [0.018751300871372223, 0.0050079054199159145]\n",
      "2100 steps | score: [0.039971090853214264, -0.00038953544571995735]\n",
      "2200 steps | score: [0.036101020872592926, -0.013163086026906967]\n",
      "2300 steps | score: [0.03228386491537094, -0.005547447130084038]\n",
      "2400 steps | score: [0.02578185498714447, -0.000500447116792202]\n",
      "2500 steps | score: [0.0387958288192749, -0.00232084677554667]\n",
      "2600 steps | score: [0.0408126562833786, -0.006982309278100729]\n",
      "unknown params:  tensor([-0.3978, -0.4698])\n",
      "unknown variance:  tensor([[0.8183]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4339, -0.5924])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [-0.0036560632288455963]\n",
      "100 steps | score: [-0.10928583890199661]\n",
      "200 steps | score: [-0.25305235385894775]\n",
      "300 steps | score: [-0.05139753222465515]\n",
      "400 steps | score: [-0.061786431819200516]\n",
      "500 steps | score: [-0.10988450050354004]\n",
      "600 steps | score: [-0.23340240120887756]\n",
      "700 steps | score: [-0.04619152098894119]\n",
      "800 steps | score: [-0.10269910097122192]\n",
      "900 steps | score: [-0.10038025677204132]\n",
      "1000 steps | score: [-0.22742748260498047]\n",
      "1100 steps | score: [-0.08358332514762878]\n",
      "1200 steps | score: [-0.11041028797626495]\n",
      "1300 steps | score: [-0.151242196559906]\n",
      "1400 steps | score: [-0.16505488753318787]\n",
      "1500 steps | score: [-0.10557247698307037]\n",
      "1600 steps | score: [-0.1268560290336609]\n",
      "1700 steps | score: [-0.1300007402896881]\n",
      "1800 steps | score: [-0.17146244645118713]\n",
      "1900 steps | score: [-0.11081860959529877]\n",
      "2000 steps | score: [-0.12141429632902145]\n",
      "2100 steps | score: [-0.1347312033176422]\n",
      "2200 steps | score: [-0.1654951572418213]\n",
      "2300 steps | score: [-0.11575347185134888]\n",
      "2400 steps | score: [-0.14317789673805237]\n",
      "2500 steps | score: [-0.09680788218975067]\n",
      "2600 steps | score: [-0.15642331540584564]\n",
      "2700 steps | score: [-0.12892568111419678]\n",
      "0 steps | score: [0.030276870355010033, 0.12607823312282562]\n",
      "100 steps | score: [-0.021799379959702492, 0.06323763728141785]\n",
      "200 steps | score: [-0.12244261801242828, 0.09836176782846451]\n",
      "300 steps | score: [0.029348628595471382, 0.000645143911242485]\n",
      "400 steps | score: [-0.003474840661510825, -0.0074968114495277405]\n",
      "0 steps | score: [0.06193385273218155, 0.10510428994894028]\n",
      "100 steps | score: [0.012883057817816734, 0.030676813796162605]\n",
      "200 steps | score: [-0.09037032723426819, 0.0924777239561081]\n",
      "300 steps | score: [0.046630844473838806, -0.008511757478117943]\n",
      "400 steps | score: [0.03494531288743019, -0.031619369983673096]\n",
      "500 steps | score: [0.020861616358160973, 0.00046266475692391396]\n",
      "600 steps | score: [-0.06503953039646149, 0.08113240450620651]\n",
      "700 steps | score: [0.0505170002579689, 0.004649393260478973]\n",
      "800 steps | score: [0.04191403463482857, -0.04337343946099281]\n",
      "900 steps | score: [0.013776922598481178, 0.002337622456252575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 steps | score: [-0.050929222255945206, 0.07286150753498077]\n",
      "1100 steps | score: [0.03835439309477806, -0.001199476420879364]\n",
      "1200 steps | score: [0.025858547538518906, -0.023578664287924767]\n",
      "1300 steps | score: [0.01051195990294218, -3.4683384001255035e-05]\n",
      "1400 steps | score: [-0.02808968350291252, 0.051944833248853683]\n",
      "1500 steps | score: [0.02842423878610134, 0.007130998186767101]\n",
      "1600 steps | score: [0.018936827778816223, -0.010159365832805634]\n",
      "1700 steps | score: [0.0038577246014028788, 0.013955624774098396]\n",
      "1800 steps | score: [-0.028551414608955383, 0.04690885916352272]\n",
      "1900 steps | score: [0.022895047441124916, 0.012221019715070724]\n",
      "2000 steps | score: [0.014225671999156475, -0.003119207452982664]\n",
      "2100 steps | score: [0.008759877644479275, 0.0038776304572820663]\n",
      "0 steps | score: [0.04615144804120064, 0.09849582612514496]\n",
      "100 steps | score: [-0.001414218102581799, 0.025661801919341087]\n",
      "200 steps | score: [-0.10447809845209122, 0.07673634588718414]\n",
      "300 steps | score: [0.03680626302957535, -0.023970454931259155]\n",
      "400 steps | score: [0.01577904261648655, -0.043473370373249054]\n",
      "500 steps | score: [-0.004727263003587723, 0.0033158771693706512]\n",
      "unknown params:  tensor([-0.4101, -0.4916])\n",
      "unknown variance:  tensor([[0.8694]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4339, -0.5924])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.21477320790290833]\n",
      "100 steps | score: [0.08574225008487701]\n",
      "200 steps | score: [0.09986366331577301]\n",
      "300 steps | score: [0.10416904091835022]\n",
      "400 steps | score: [0.16082367300987244]\n",
      "500 steps | score: [0.04168878495693207]\n",
      "600 steps | score: [0.0816023126244545]\n",
      "700 steps | score: [0.11520445346832275]\n",
      "800 steps | score: [0.14074355363845825]\n",
      "900 steps | score: [0.05386914312839508]\n",
      "1000 steps | score: [0.1493918001651764]\n",
      "1100 steps | score: [0.07779795676469803]\n",
      "1200 steps | score: [0.08041082322597504]\n",
      "1300 steps | score: [0.0816618874669075]\n",
      "1400 steps | score: [0.10191342234611511]\n",
      "1500 steps | score: [0.09096098691225052]\n",
      "1600 steps | score: [0.09738513827323914]\n",
      "1700 steps | score: [0.04752999544143677]\n",
      "1800 steps | score: [0.11092235147953033]\n",
      "1900 steps | score: [0.1145666316151619]\n",
      "2000 steps | score: [0.09003950655460358]\n",
      "2100 steps | score: [0.084286168217659]\n",
      "2200 steps | score: [0.11772134900093079]\n",
      "2300 steps | score: [0.11019778996706009]\n",
      "2400 steps | score: [0.08902788162231445]\n",
      "2500 steps | score: [0.08890211582183838]\n",
      "2600 steps | score: [0.11886836588382721]\n",
      "0 steps | score: [0.07992434501647949, 0.16627243161201477]\n",
      "100 steps | score: [0.025173505768179893, 0.044132448732852936]\n",
      "200 steps | score: [-0.006151880603283644, 0.07342192530632019]\n",
      "300 steps | score: [0.012069928459823132, 0.06992147117853165]\n",
      "400 steps | score: [0.05493077263236046, -0.029377929866313934]\n",
      "500 steps | score: [-0.0366826206445694, 0.08241386711597443]\n",
      "600 steps | score: [-0.018183903768658638, 0.0726621225476265]\n",
      "700 steps | score: [0.015156923793256283, 0.08054781705141068]\n",
      "800 steps | score: [0.024766940623521805, 0.04562294855713844]\n",
      "900 steps | score: [-0.01690051704645157, 0.08590620756149292]\n",
      "1000 steps | score: [0.03272361680865288, 0.034551817923784256]\n",
      "1100 steps | score: [0.005231819115579128, 0.04968108981847763]\n",
      "1200 steps | score: [-0.02329898439347744, 0.07020711153745651]\n",
      "1300 steps | score: [-0.018894420936703682, 0.06477667391300201]\n",
      "1400 steps | score: [0.008877991698682308, 0.05575357377529144]\n",
      "1500 steps | score: [-0.01418974157422781, 0.07008892297744751]\n",
      "1600 steps | score: [-0.008085270412266254, 0.063900887966156]\n",
      "1700 steps | score: [-0.0457160584628582, 0.09095961600542068]\n",
      "1800 steps | score: [0.012829682789742947, 0.05097223073244095]\n",
      "1900 steps | score: [0.022880524396896362, 0.02374783530831337]\n",
      "2000 steps | score: [-0.016662489622831345, 0.06483986228704453]\n",
      "2100 steps | score: [-0.018700629472732544, 0.07602275162935257]\n",
      "2200 steps | score: [-0.007513964548707008, 0.06541372090578079]\n",
      "2300 steps | score: [0.019888589158654213, 0.03276246041059494]\n",
      "2400 steps | score: [-0.007918795570731163, 0.0633787214756012]\n",
      "2500 steps | score: [-0.004314417485147715, 0.06249377131462097]\n",
      "2600 steps | score: [0.012563634663820267, 0.05017684027552605]\n",
      "0 steps | score: [0.06890124082565308, 0.06626509875059128]\n",
      "100 steps | score: [0.019818777218461037, -0.05114613473415375]\n",
      "200 steps | score: [-0.029416963458061218, -0.009966987185180187]\n",
      "300 steps | score: [0.0037899573799222708, -0.014229479245841503]\n",
      "400 steps | score: [0.03948625549674034, -0.12614911794662476]\n",
      "500 steps | score: [-0.04611627385020256, -0.011186709627509117]\n",
      "600 steps | score: [-0.0253773033618927, -0.021630721166729927]\n",
      "700 steps | score: [-0.0012530410895124078, -0.0037918142043054104]\n",
      "unknown params:  tensor([-0.4228, -0.5343])\n",
      "unknown variance:  tensor([[0.9028]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4339, -0.5924])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.17763133347034454]\n",
      "100 steps | score: [0.012112729251384735]\n",
      "200 steps | score: [-0.022187180817127228]\n",
      "300 steps | score: [0.013254283927381039]\n",
      "400 steps | score: [-0.015645330771803856]\n",
      "500 steps | score: [-0.02852715738117695]\n",
      "600 steps | score: [0.00937797874212265]\n",
      "0 steps | score: [0.03249796852469444, 0.19903112947940826]\n",
      "100 steps | score: [-0.08125758171081543, 0.1263272762298584]\n",
      "200 steps | score: [-0.0744427740573883, 0.10104168951511383]\n",
      "300 steps | score: [-0.008331438526511192, 0.0690179169178009]\n",
      "400 steps | score: [-0.08339673280715942, 0.11257943511009216]\n",
      "500 steps | score: [-0.0643419399857521, 0.10740213096141815]\n",
      "600 steps | score: [-0.03467216342687607, 0.08928223699331284]\n",
      "700 steps | score: [0.011722302995622158, -0.005516744218766689]\n",
      "800 steps | score: [-0.0810890793800354, 0.12196092307567596]\n",
      "900 steps | score: [-0.06764938682317734, 0.10862737149000168]\n",
      "1000 steps | score: [-0.017892034724354744, 0.06521452218294144]\n",
      "1100 steps | score: [-0.06183585897088051, 0.0920710489153862]\n",
      "1200 steps | score: [-0.05305633321404457, 0.09358616173267365]\n",
      "1300 steps | score: [-0.020131489261984825, 0.06267483532428741]\n",
      "1400 steps | score: [-0.0002742655051406473, 0.011138875037431717]\n",
      "1500 steps | score: [-0.07931416481733322, 0.11190933734178543]\n",
      "1600 steps | score: [-0.05939804017543793, 0.09048303961753845]\n",
      "1700 steps | score: [-0.031011642888188362, 0.08114922046661377]\n",
      "1800 steps | score: [-0.05022173747420311, 0.07995426654815674]\n",
      "1900 steps | score: [-0.06999991834163666, 0.10054896771907806]\n",
      "2000 steps | score: [-0.021582407876849174, 0.06260336190462112]\n",
      "2100 steps | score: [-0.019391844049096107, 0.0400976724922657]\n",
      "2200 steps | score: [-0.04999848082661629, 0.08672799170017242]\n",
      "2300 steps | score: [-0.06153995543718338, 0.08714834600687027]\n",
      "2400 steps | score: [-0.025661766529083252, 0.05541199445724487]\n",
      "2500 steps | score: [-0.0397132933139801, 0.07033497095108032]\n",
      "2600 steps | score: [-0.0580122172832489, 0.08499572426080704]\n",
      "2700 steps | score: [-0.042690835893154144, 0.07467418164014816]\n",
      "0 steps | score: [0.01694599725306034, 0.15500180423259735]\n",
      "100 steps | score: [-0.08575814217329025, 0.09484095871448517]\n",
      "200 steps | score: [-0.09004493057727814, 0.07043489813804626]\n",
      "300 steps | score: [-0.025390226393938065, 0.043538905680179596]\n",
      "400 steps | score: [-0.09382811933755875, 0.08160340785980225]\n",
      "500 steps | score: [-0.07651345431804657, 0.06782829016447067]\n",
      "600 steps | score: [-0.04246833920478821, 0.05066694691777229]\n",
      "700 steps | score: [-0.009741383604705334, -0.01725079119205475]\n",
      "800 steps | score: [-0.09271679818630219, 0.07918444275856018]\n",
      "900 steps | score: [-0.08845911920070648, 0.07417505979537964]\n",
      "1000 steps | score: [-0.014199894852936268, 0.024592522531747818]\n",
      "1100 steps | score: [-0.08008861541748047, 0.0615522563457489]\n",
      "1200 steps | score: [-0.06263506412506104, 0.056125033646821976]\n",
      "1300 steps | score: [-0.026669926941394806, 0.029994705691933632]\n",
      "1400 steps | score: [0.002220894442871213, -0.027872446924448013]\n",
      "1500 steps | score: [-0.09059546142816544, 0.08118247985839844]\n",
      "1600 steps | score: [-0.07013805210590363, 0.0530812069773674]\n",
      "1700 steps | score: [-0.039195023477077484, 0.0357632115483284]\n",
      "1800 steps | score: [-0.07156239449977875, 0.05062783509492874]\n",
      "1900 steps | score: [-0.09217346459627151, 0.07177247107028961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 steps | score: [-0.03786991909146309, 0.03130166232585907]\n",
      "2100 steps | score: [-0.03642016276717186, 0.008821580559015274]\n",
      "2200 steps | score: [-0.0785994604229927, 0.0604025237262249]\n",
      "2300 steps | score: [-0.07412472367286682, 0.05467092618346214]\n",
      "2400 steps | score: [-0.03498861566185951, 0.024641981348395348]\n",
      "2500 steps | score: [-0.052914950996637344, 0.038447506725788116]\n",
      "2600 steps | score: [-0.07514860481023788, 0.0681985542178154]\n",
      "2700 steps | score: [-0.053966224193573, 0.0399298220872879]\n",
      "0 steps | score: [0.11167319118976593, 0.11757552623748779]\n",
      "100 steps | score: [-0.009283983148634434, 0.06834602355957031]\n",
      "200 steps | score: [-0.011323303915560246, 0.04546445980668068]\n",
      "300 steps | score: [0.03776492550969124, 0.015764504671096802]\n",
      "400 steps | score: [-0.025528613477945328, 0.06064819172024727]\n",
      "500 steps | score: [0.00037167948903515935, 0.048113130033016205]\n",
      "600 steps | score: [0.03326379507780075, 0.01797783374786377]\n",
      "700 steps | score: [0.061405278742313385, -0.048986442387104034]\n",
      "800 steps | score: [-0.024277083575725555, 0.06023653969168663]\n",
      "900 steps | score: [-0.02069670520722866, 0.055203549563884735]\n",
      "1000 steps | score: [0.05347416549921036, -0.0011606216430664062]\n",
      "1100 steps | score: [0.003214441239833832, 0.023459799587726593]\n",
      "1200 steps | score: [0.012582115828990936, 0.024031538516283035]\n",
      "1300 steps | score: [0.03972243890166283, 0.005176162347197533]\n",
      "1400 steps | score: [0.0617988184094429, -0.05270732194185257]\n",
      "1500 steps | score: [-0.015066854655742645, 0.04401462897658348]\n",
      "1600 steps | score: [0.003726376686245203, 0.025784794241189957]\n",
      "1700 steps | score: [0.031591255217790604, 0.014246129430830479]\n",
      "1800 steps | score: [0.0024125983472913504, 0.02189275249838829]\n",
      "1900 steps | score: [-0.007588950451463461, 0.03409545123577118]\n",
      "2000 steps | score: [0.0421917550265789, -0.004308539442718029]\n",
      "2100 steps | score: [0.04659062623977661, -0.013531831093132496]\n",
      "2200 steps | score: [0.0033623536583036184, 0.02885540947318077]\n",
      "2300 steps | score: [0.0014554151566699147, 0.03337816148996353]\n",
      "2400 steps | score: [0.031048893928527832, 0.0014958204701542854]\n",
      "2500 steps | score: [0.020709602162241936, 0.00616306159645319]\n",
      "2600 steps | score: [0.0036258241161704063, 0.031365685164928436]\n",
      "2700 steps | score: [0.022338371723890305, 0.020617596805095673]\n",
      "unknown params:  tensor([-0.4338, -0.5773])\n",
      "unknown variance:  tensor([[0.9413]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4339, -0.5924])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.024571415036916733]\n",
      "100 steps | score: [-0.15105271339416504]\n",
      "200 steps | score: [-0.04358697682619095]\n",
      "300 steps | score: [-0.21366922557353973]\n",
      "400 steps | score: [-0.17338506877422333]\n",
      "500 steps | score: [-0.12655334174633026]\n",
      "600 steps | score: [-0.1083143800497055]\n",
      "700 steps | score: [-0.16356401145458221]\n",
      "800 steps | score: [-0.17302781343460083]\n",
      "900 steps | score: [-0.11874423921108246]\n",
      "1000 steps | score: [-0.07984557747840881]\n",
      "1100 steps | score: [-0.17122791707515717]\n",
      "1200 steps | score: [-0.14270411431789398]\n",
      "1300 steps | score: [-0.11208260804414749]\n",
      "1400 steps | score: [-0.16253915429115295]\n",
      "1500 steps | score: [-0.12200851738452911]\n",
      "1600 steps | score: [-0.1360575556755066]\n",
      "1700 steps | score: [-0.13655059039592743]\n",
      "1800 steps | score: [-0.15384624898433685]\n",
      "1900 steps | score: [-0.13011899590492249]\n",
      "2000 steps | score: [-0.16538920998573303]\n",
      "2100 steps | score: [-0.1517907828092575]\n",
      "2200 steps | score: [-0.13231556117534637]\n",
      "2300 steps | score: [-0.11506631225347519]\n",
      "2400 steps | score: [-0.15222525596618652]\n",
      "2500 steps | score: [-0.10849347710609436]\n",
      "0 steps | score: [0.12287247180938721, 0.0833980068564415]\n",
      "100 steps | score: [-0.015772219747304916, 0.05746183544397354]\n",
      "200 steps | score: [0.1524174064397812, -0.1629280149936676]\n",
      "300 steps | score: [-0.0985250249505043, 0.08523707091808319]\n",
      "400 steps | score: [-0.04955485090613365, 0.02998475544154644]\n",
      "500 steps | score: [0.038619641214609146, -0.04483133554458618]\n",
      "600 steps | score: [0.13658006489276886, -0.16225719451904297]\n",
      "700 steps | score: [-0.07722849398851395, 0.08866073936223984]\n",
      "800 steps | score: [-0.054644472897052765, 0.07017683237791061]\n",
      "900 steps | score: [0.012276887893676758, 0.01658020354807377]\n",
      "1000 steps | score: [0.0752309039235115, -0.0944928228855133]\n",
      "1100 steps | score: [-0.0072213467210531235, 0.012513363733887672]\n",
      "1200 steps | score: [0.006573696620762348, -0.0006318662781268358]\n",
      "0 steps | score: [0.12056930363178253, 0.08290422707796097]\n",
      "100 steps | score: [-0.030496858060359955, 0.07327837496995926]\n",
      "200 steps | score: [0.1503429114818573, -0.16882604360580444]\n",
      "300 steps | score: [-0.09364735335111618, 0.0726843774318695]\n",
      "400 steps | score: [-0.03912961110472679, 0.02177826315164566]\n",
      "500 steps | score: [0.03630571812391281, -0.042903508991003036]\n",
      "600 steps | score: [0.11803877353668213, -0.14403030276298523]\n",
      "700 steps | score: [-0.09662951529026031, 0.09299211204051971]\n",
      "800 steps | score: [-0.0718720406293869, 0.07205776125192642]\n",
      "900 steps | score: [0.0023550144396722317, 0.017693504691123962]\n",
      "1000 steps | score: [0.08010771870613098, -0.10859061777591705]\n",
      "1100 steps | score: [-0.009031261317431927, 0.005447543691843748]\n",
      "0 steps | score: [0.12168644368648529, 0.02558307722210884]\n",
      "100 steps | score: [-0.043656125664711, 0.023521827533841133]\n",
      "200 steps | score: [0.1295607089996338, -0.19161564111709595]\n",
      "300 steps | score: [-0.10588078200817108, 0.028091471642255783]\n",
      "400 steps | score: [-0.058620352298021317, 0.002208251506090164]\n",
      "500 steps | score: [0.018183475360274315, -0.08362740278244019]\n",
      "600 steps | score: [0.07849735021591187, -0.1545776128768921]\n",
      "700 steps | score: [-0.08927597850561142, 0.03415626287460327]\n",
      "800 steps | score: [-0.08189595490694046, 0.027133842930197716]\n",
      "900 steps | score: [-0.008182760328054428, -0.0273615550249815]\n",
      "1000 steps | score: [0.07810648530721664, -0.1564958542585373]\n",
      "1100 steps | score: [-0.025134453549981117, -0.02699168585240841]\n",
      "1200 steps | score: [-0.007885193452239037, -0.038452647626399994]\n",
      "1300 steps | score: [0.05563436448574066, -0.1428527981042862]\n",
      "1400 steps | score: [-0.02401338890194893, -0.037914954125881195]\n",
      "1500 steps | score: [0.016276733949780464, -0.0776325911283493]\n",
      "1600 steps | score: [-0.024192489683628082, -0.0400293692946434]\n",
      "1700 steps | score: [-0.023562230169773102, -0.036066778004169464]\n",
      "1800 steps | score: [-0.0313020683825016, -0.01591862551867962]\n",
      "1900 steps | score: [0.027323121204972267, -0.08892570436000824]\n",
      "2000 steps | score: [-0.0320267453789711, -0.035775262862443924]\n",
      "2100 steps | score: [-0.050288546830415726, -0.005586008541285992]\n",
      "2200 steps | score: [-0.012246891856193542, -0.04435725137591362]\n",
      "2300 steps | score: [0.0257484819740057, -0.08900178968906403]\n",
      "2400 steps | score: [-0.021201010793447495, -0.035398226231336594]\n",
      "2500 steps | score: [0.0013633827911689878, -0.055459968745708466]\n",
      "unknown params:  tensor([-0.4608, -0.6798])\n",
      "unknown variance:  tensor([[1.0066]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4339, -0.5924])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.23681816458702087]\n",
      "100 steps | score: [0.023117460310459137]\n",
      "200 steps | score: [0.08213276416063309]\n",
      "300 steps | score: [0.03606225177645683]\n",
      "400 steps | score: [-0.07661379128694534]\n",
      "500 steps | score: [0.033095791935920715]\n",
      "600 steps | score: [0.037717875093221664]\n",
      "700 steps | score: [-0.03884778916835785]\n",
      "800 steps | score: [0.02394215762615204]\n",
      "900 steps | score: [0.051655180752277374]\n",
      "1000 steps | score: [-0.03504863753914833]\n",
      "1100 steps | score: [-0.015706242993474007]\n",
      "1200 steps | score: [0.0075143687427043915]\n",
      "0 steps | score: [0.22718545794487, -0.000660216435790062]\n",
      "100 steps | score: [0.12548111379146576, -0.0859282985329628]\n",
      "200 steps | score: [0.14133432507514954, -0.09435275197029114]\n",
      "300 steps | score: [0.20420607924461365, -0.2842957377433777]\n",
      "400 steps | score: [0.007207345217466354, 0.01966341957449913]\n",
      "500 steps | score: [0.12250732630491257, -0.07965811342000961]\n",
      "600 steps | score: [0.1696224957704544, -0.21029061079025269]\n",
      "700 steps | score: [0.008814528584480286, 0.019389957189559937]\n",
      "800 steps | score: [0.10563559085130692, -0.07616535574197769]\n",
      "900 steps | score: [0.19910307228565216, -0.2571757435798645]\n",
      "1000 steps | score: [0.030323458835482597, 0.003780897706747055]\n",
      "1100 steps | score: [0.050459470599889755, -0.008250527083873749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 steps | score: [0.13849563896656036, -0.15270012617111206]\n",
      "1300 steps | score: [0.03258125111460686, -0.006521319970488548]\n",
      "1400 steps | score: [0.13376006484031677, -0.11412237584590912]\n",
      "1500 steps | score: [0.13945171236991882, -0.14862610399723053]\n",
      "1600 steps | score: [0.07354249805212021, -0.05091523751616478]\n",
      "1700 steps | score: [0.08975154906511307, -0.06168157234787941]\n",
      "1800 steps | score: [0.13399110734462738, -0.13765981793403625]\n",
      "1900 steps | score: [0.04025975242257118, -0.013450331054627895]\n",
      "2000 steps | score: [0.06938596814870834, -0.041775625199079514]\n",
      "2100 steps | score: [0.12959451973438263, -0.11551850289106369]\n",
      "2200 steps | score: [0.03604581207036972, -0.01022966206073761]\n",
      "2300 steps | score: [0.07562390714883804, -0.0600714236497879]\n",
      "2400 steps | score: [0.10553011298179626, -0.09969310462474823]\n",
      "2500 steps | score: [0.0562419518828392, -0.02880033478140831]\n",
      "2600 steps | score: [0.07050050050020218, -0.04604923725128174]\n",
      "0 steps | score: [0.1657823771238327, 0.07109465450048447]\n",
      "100 steps | score: [0.09332059323787689, -0.03948652744293213]\n",
      "200 steps | score: [0.0915624350309372, -0.05073065310716629]\n",
      "300 steps | score: [0.13243214786052704, -0.20267939567565918]\n",
      "400 steps | score: [-0.04705948755145073, 0.07257045060396194]\n",
      "500 steps | score: [0.05666692554950714, -0.013525180518627167]\n",
      "600 steps | score: [0.1099543645977974, -0.14360415935516357]\n",
      "700 steps | score: [-0.03351443260908127, 0.07096640020608902]\n",
      "800 steps | score: [0.03877396136522293, 0.006119116209447384]\n",
      "900 steps | score: [0.1480054259300232, -0.19191521406173706]\n",
      "1000 steps | score: [-0.020713578909635544, 0.05538128316402435]\n",
      "1100 steps | score: [0.013066358864307404, 0.027802351862192154]\n",
      "1200 steps | score: [0.0892542228102684, -0.10144776105880737]\n",
      "1300 steps | score: [-0.008493956178426743, 0.0320461168885231]\n",
      "1400 steps | score: [0.07516530156135559, -0.04688570648431778]\n",
      "1500 steps | score: [0.09061990678310394, -0.0858452245593071]\n",
      "1600 steps | score: [0.016660863533616066, 0.005278017371892929]\n",
      "1700 steps | score: [0.04440280422568321, -0.00930052250623703]\n",
      "1800 steps | score: [0.08420207351446152, -0.08582594245672226]\n",
      "1900 steps | score: [-0.002206244505941868, 0.02415648102760315]\n",
      "2000 steps | score: [0.023832209408283234, 0.006179829128086567]\n",
      "2100 steps | score: [0.07119296491146088, -0.05635315179824829]\n",
      "2200 steps | score: [-0.007576807867735624, 0.036167316138744354]\n",
      "2300 steps | score: [0.024051370099186897, 0.0025641974061727524]\n",
      "2400 steps | score: [0.05934260040521622, -0.05729922279715538]\n",
      "2500 steps | score: [-0.0013526672264561057, 0.03128568455576897]\n",
      "2600 steps | score: [0.025476954877376556, 0.006868031807243824]\n",
      "0 steps | score: [0.11357593536376953, 0.09950868040323257]\n",
      "100 steps | score: [0.04392680525779724, -0.0067342836409807205]\n",
      "200 steps | score: [0.05763586238026619, -0.031905341893434525]\n",
      "300 steps | score: [0.08878451585769653, -0.15571127831935883]\n",
      "400 steps | score: [-0.07500693947076797, 0.09304806590080261]\n",
      "500 steps | score: [0.016454380005598068, 0.014325359836220741]\n",
      "600 steps | score: [0.07123073935508728, -0.12610769271850586]\n",
      "700 steps | score: [-0.0780830904841423, 0.09555038809776306]\n",
      "800 steps | score: [0.001577991060912609, 0.017242321744561195]\n",
      "900 steps | score: [0.10555873066186905, -0.15721344947814941]\n",
      "1000 steps | score: [-0.06239581108093262, 0.08649241179227829]\n",
      "1100 steps | score: [-0.03227495774626732, 0.059754811227321625]\n",
      "1200 steps | score: [0.03188180923461914, -0.05866636335849762]\n",
      "1300 steps | score: [-0.04742466285824776, 0.05585635453462601]\n",
      "1400 steps | score: [0.03790958598256111, -0.02537367306649685]\n",
      "1500 steps | score: [0.04064005985856056, -0.05307384580373764]\n",
      "1600 steps | score: [-0.022986283525824547, 0.02793670818209648]\n",
      "1700 steps | score: [0.0016939216293394566, 0.009549316018819809]\n",
      "unknown params:  tensor([-0.4763, -0.7693])\n",
      "unknown variance:  tensor([[1.0689]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4339, -0.5924])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [-0.08407488465309143]\n",
      "100 steps | score: [-0.27716878056526184]\n",
      "200 steps | score: [-0.20456433296203613]\n",
      "300 steps | score: [-0.14245112240314484]\n",
      "400 steps | score: [-0.3341303765773773]\n",
      "500 steps | score: [-0.2236182689666748]\n",
      "600 steps | score: [-0.272962749004364]\n",
      "700 steps | score: [-0.22107058763504028]\n",
      "800 steps | score: [-0.22391262650489807]\n",
      "900 steps | score: [-0.3084048628807068]\n",
      "1000 steps | score: [-0.21214604377746582]\n",
      "1100 steps | score: [-0.16363711655139923]\n",
      "1200 steps | score: [-0.2704083025455475]\n",
      "1300 steps | score: [-0.26554304361343384]\n",
      "1400 steps | score: [-0.2291119396686554]\n",
      "1500 steps | score: [-0.2644169330596924]\n",
      "1600 steps | score: [-0.27616560459136963]\n",
      "1700 steps | score: [-0.26914548873901367]\n",
      "1800 steps | score: [-0.23983174562454224]\n",
      "1900 steps | score: [-0.2290397733449936]\n",
      "2000 steps | score: [-0.2965049147605896]\n",
      "2100 steps | score: [-0.2883675992488861]\n",
      "2200 steps | score: [-0.2664295434951782]\n",
      "2300 steps | score: [-0.2525008022785187]\n",
      "2400 steps | score: [-0.26449084281921387]\n",
      "2500 steps | score: [-0.2398402988910675]\n",
      "2600 steps | score: [-0.2250664234161377]\n",
      "0 steps | score: [0.10040035843849182, 0.15300744771957397]\n",
      "100 steps | score: [-0.08479031920433044, 0.21882109344005585]\n",
      "200 steps | score: [0.09581074118614197, -0.0395573228597641]\n",
      "300 steps | score: [-0.059427835047245026, 0.13272228837013245]\n",
      "400 steps | score: [-0.1618138998746872, 0.2629709243774414]\n",
      "500 steps | score: [0.09116185456514359, -0.0886046290397644]\n",
      "600 steps | score: [-0.09142740070819855, 0.16741760075092316]\n",
      "700 steps | score: [0.034602805972099304, -0.00889001227915287]\n",
      "800 steps | score: [0.024317298084497452, -0.004761969670653343]\n",
      "900 steps | score: [-0.102047860622406, 0.1734565645456314]\n",
      "1000 steps | score: [-0.006842189934104681, 0.0731993019580841]\n",
      "1100 steps | score: [0.05517314374446869, -0.0551508367061615]\n",
      "1200 steps | score: [-0.10114887356758118, 0.18478655815124512]\n",
      "1300 steps | score: [-0.08735549449920654, 0.17901022732257843]\n",
      "1400 steps | score: [-0.04316352307796478, 0.10492601245641708]\n",
      "1500 steps | score: [-0.00992706511169672, 0.057437725365161896]\n",
      "1600 steps | score: [-0.0789293423295021, 0.14027367532253265]\n",
      "1700 steps | score: [-0.057092346251010895, 0.11965281516313553]\n",
      "1800 steps | score: [-0.04374214634299278, 0.09966901689767838]\n",
      "1900 steps | score: [-0.006188053172081709, 0.039050325751304626]\n",
      "2000 steps | score: [-0.08960531651973724, 0.15984128415584564]\n",
      "2100 steps | score: [-0.06478728353977203, 0.14339189231395721]\n",
      "2200 steps | score: [-0.05936894938349724, 0.11714626848697662]\n",
      "2300 steps | score: [-0.08033466339111328, 0.14592911303043365]\n",
      "2400 steps | score: [-0.070866659283638, 0.14316248893737793]\n",
      "2500 steps | score: [-0.05452873930335045, 0.12266615033149719]\n",
      "2600 steps | score: [-0.0400250218808651, 0.10424967855215073]\n",
      "0 steps | score: [0.1223306804895401, 0.16042618453502655]\n",
      "100 steps | score: [-0.04893149062991142, 0.20413346588611603]\n",
      "200 steps | score: [0.10935395210981369, -0.03152085468173027]\n",
      "300 steps | score: [-0.0015051153022795916, 0.08157345652580261]\n",
      "400 steps | score: [-0.1549384891986847, 0.28773900866508484]\n",
      "500 steps | score: [0.12221245467662811, -0.10237662494182587]\n",
      "600 steps | score: [-0.040434110909700394, 0.1364668309688568]\n",
      "700 steps | score: [0.0673850029706955, -0.006189342588186264]\n",
      "800 steps | score: [0.0419100783765316, 0.008234284818172455]\n",
      "900 steps | score: [-0.06184987723827362, 0.16812041401863098]\n",
      "1000 steps | score: [0.008116234093904495, 0.0739034041762352]\n",
      "1100 steps | score: [0.06328530609607697, -0.030507871881127357]\n",
      "1200 steps | score: [-0.08344102650880814, 0.20223098993301392]\n",
      "1300 steps | score: [-0.05474119260907173, 0.17034363746643066]\n",
      "1400 steps | score: [-0.00989646278321743, 0.08937454223632812]\n",
      "1500 steps | score: [0.020874345675110817, 0.04581587761640549]\n",
      "1600 steps | score: [-0.028385130688548088, 0.11452069878578186]\n",
      "1700 steps | score: [-0.028289858251810074, 0.122275710105896]\n",
      "1800 steps | score: [0.0010881641646847129, 0.0891379714012146]\n",
      "1900 steps | score: [0.03454158827662468, 0.0254402756690979]\n",
      "2000 steps | score: [-0.05765007436275482, 0.155260369181633]\n",
      "2100 steps | score: [-0.026883071288466454, 0.12733063101768494]\n",
      "2200 steps | score: [-0.03160819783806801, 0.11909343302249908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300 steps | score: [-0.04812043532729149, 0.1490856409072876]\n",
      "2400 steps | score: [-0.03756489232182503, 0.134933203458786]\n",
      "2500 steps | score: [-0.02668658457696438, 0.11153685301542282]\n",
      "2600 steps | score: [-0.00827078241854906, 0.09638002514839172]\n",
      "0 steps | score: [0.08263695985078812, 0.1500709354877472]\n",
      "100 steps | score: [-0.0876910462975502, 0.19920413196086884]\n",
      "200 steps | score: [0.11103830486536026, -0.09938065707683563]\n",
      "300 steps | score: [-0.03322061523795128, 0.07799078524112701]\n",
      "400 steps | score: [-0.18022483587265015, 0.25946253538131714]\n",
      "500 steps | score: [0.06953373551368713, -0.08938948810100555]\n",
      "600 steps | score: [-0.07765820622444153, 0.12272480130195618]\n",
      "700 steps | score: [0.036552976816892624, -0.038580574095249176]\n",
      "800 steps | score: [0.017026808112859726, -0.027003610506653786]\n",
      "900 steps | score: [-0.09352485090494156, 0.1388951689004898]\n",
      "1000 steps | score: [-0.018020642921328545, 0.053177494555711746]\n",
      "1100 steps | score: [0.03783203661441803, -0.05456269904971123]\n",
      "1200 steps | score: [-0.12053494155406952, 0.1770356148481369]\n",
      "1300 steps | score: [-0.10126152634620667, 0.1625566929578781]\n",
      "1400 steps | score: [-0.05649036169052124, 0.08478432148694992]\n",
      "1500 steps | score: [-0.008579251356422901, 0.026740148663520813]\n",
      "1600 steps | score: [-0.05701840668916702, 0.0963490754365921]\n",
      "1700 steps | score: [-0.052785973995923996, 0.08936285972595215]\n",
      "1800 steps | score: [-0.02353772707283497, 0.051820605993270874]\n",
      "1900 steps | score: [0.0028562748339027166, 0.005351467989385128]\n",
      "unknown params:  tensor([-0.5093, -0.9852])\n",
      "unknown variance:  tensor([[1.1949]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4339, -0.5924])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.35263606905937195]\n",
      "100 steps | score: [0.16298164427280426]\n",
      "200 steps | score: [0.09995350986719131]\n",
      "300 steps | score: [0.12912657856941223]\n",
      "400 steps | score: [0.18309138715267181]\n",
      "500 steps | score: [0.15691637992858887]\n",
      "600 steps | score: [0.0950666069984436]\n",
      "700 steps | score: [0.11035193502902985]\n",
      "800 steps | score: [0.10945916175842285]\n",
      "900 steps | score: [0.14712893962860107]\n",
      "1000 steps | score: [0.13901206851005554]\n",
      "1100 steps | score: [0.10840083658695221]\n",
      "1200 steps | score: [0.09663635492324829]\n",
      "1300 steps | score: [0.11242187023162842]\n",
      "1400 steps | score: [0.119844451546669]\n",
      "1500 steps | score: [0.11614254117012024]\n",
      "1600 steps | score: [0.10878735780715942]\n",
      "1700 steps | score: [0.11304322630167007]\n",
      "1800 steps | score: [0.11705929785966873]\n",
      "1900 steps | score: [0.12719324231147766]\n",
      "2000 steps | score: [0.10767130553722382]\n",
      "2100 steps | score: [0.1412673443555832]\n",
      "2200 steps | score: [0.13329890370368958]\n",
      "2300 steps | score: [0.10563628375530243]\n",
      "2400 steps | score: [0.1261289119720459]\n",
      "2500 steps | score: [0.1232101172208786]\n",
      "2600 steps | score: [0.13445094227790833]\n",
      "0 steps | score: [0.14885374903678894, 0.043037936091423035]\n",
      "100 steps | score: [0.07441437244415283, -0.003908529877662659]\n",
      "200 steps | score: [-0.08676675707101822, 0.205223947763443]\n",
      "300 steps | score: [-0.07852587848901749, 0.14750322699546814]\n",
      "400 steps | score: [-0.004541977308690548, 0.049161896109580994]\n",
      "500 steps | score: [-0.032480012625455856, 0.0394420325756073]\n",
      "600 steps | score: [-0.0547865629196167, 0.10184723138809204]\n",
      "700 steps | score: [0.4155576229095459, -0.880454421043396]\n",
      "800 steps | score: [-0.08536461740732193, 0.14303937554359436]\n",
      "900 steps | score: [-0.021034708246588707, 0.05827346444129944]\n",
      "1000 steps | score: [-0.05498872697353363, 0.08443311601877213]\n",
      "1100 steps | score: [-0.015915557742118835, 0.025520315393805504]\n",
      "1200 steps | score: [-0.11500896513462067, 0.18765467405319214]\n",
      "1300 steps | score: [-0.026679906994104385, 0.047257356345653534]\n",
      "1400 steps | score: [-0.036037370562553406, 0.08861295878887177]\n",
      "1500 steps | score: [-0.04364711791276932, 0.0769907534122467]\n",
      "1600 steps | score: [0.024237528443336487, -0.03463972359895706]\n",
      "1700 steps | score: [0.11223037540912628, -0.2124754786491394]\n",
      "1800 steps | score: [-0.03400092571973801, 0.05261246860027313]\n",
      "1900 steps | score: [-0.03373226523399353, 0.06429737061262131]\n",
      "2000 steps | score: [0.0021348493173718452, -0.004987718537449837]\n",
      "0 steps | score: [0.18547935783863068, -0.09179165959358215]\n",
      "100 steps | score: [0.07578179240226746, -0.0761079341173172]\n",
      "200 steps | score: [-0.0705365240573883, 0.10555586963891983]\n",
      "300 steps | score: [-0.07398378849029541, 0.05852065607905388]\n",
      "400 steps | score: [-0.014652971178293228, -0.020592831075191498]\n",
      "500 steps | score: [-0.019068222492933273, -0.04797053337097168]\n",
      "600 steps | score: [-0.03737840801477432, 0.0018557719886302948]\n",
      "700 steps | score: [0.3908642530441284, -0.8769059777259827]\n",
      "800 steps | score: [-0.06819722056388855, 0.04248468205332756]\n",
      "900 steps | score: [-0.031038537621498108, 0.0035486146807670593]\n",
      "1000 steps | score: [-0.03793294355273247, -0.004859182983636856]\n",
      "1100 steps | score: [-0.005868508480489254, -0.052677541971206665]\n",
      "1200 steps | score: [-0.11116304248571396, 0.09494121372699738]\n",
      "1300 steps | score: [-0.031651969999074936, -0.011476435698568821]\n",
      "1400 steps | score: [-0.045127034187316895, 0.017227135598659515]\n",
      "1500 steps | score: [-0.04559972137212753, -0.0014106547459959984]\n",
      "1600 steps | score: [0.03680078312754631, -0.12243374437093735]\n",
      "1700 steps | score: [0.11914098262786865, -0.29176077246665955]\n",
      "1800 steps | score: [-0.029261188581585884, -0.027982812374830246]\n",
      "1900 steps | score: [-0.022802142426371574, -0.03365013748407364]\n",
      "2000 steps | score: [-0.008537646383047104, -0.05571398138999939]\n",
      "2100 steps | score: [0.034496698528528214, -0.1171884685754776]\n",
      "2200 steps | score: [0.05369546264410019, -0.16880232095718384]\n",
      "2300 steps | score: [-0.06722631305456161, 0.03641057386994362]\n",
      "2400 steps | score: [-0.009890439920127392, -0.05395779758691788]\n",
      "2500 steps | score: [-0.020698681473731995, -0.030515801161527634]\n",
      "2600 steps | score: [0.00036454302608035505, -0.07867597788572311]\n",
      "0 steps | score: [0.10809212177991867, 0.13222096860408783]\n",
      "100 steps | score: [0.04714177921414375, 0.07717298716306686]\n",
      "200 steps | score: [-0.11426707357168198, 0.27740442752838135]\n",
      "300 steps | score: [-0.11367988586425781, 0.22802181541919708]\n",
      "400 steps | score: [-0.04301862418651581, 0.12410883605480194]\n",
      "500 steps | score: [-0.06727513670921326, 0.1333169788122177]\n",
      "600 steps | score: [-0.08758992701768875, 0.18312008678913116]\n",
      "700 steps | score: [0.33518704771995544, -0.6678184270858765]\n",
      "800 steps | score: [-0.10291534662246704, 0.19386719167232513]\n",
      "900 steps | score: [-0.06845711916685104, 0.1672157496213913]\n",
      "1000 steps | score: [-0.09183480590581894, 0.18333837389945984]\n",
      "1100 steps | score: [-0.05485331639647484, 0.11983846127986908]\n",
      "1200 steps | score: [-0.150089293718338, 0.2629767060279846]\n",
      "1300 steps | score: [-0.06468096375465393, 0.13679781556129456]\n",
      "1400 steps | score: [-0.0810294896364212, 0.17020699381828308]\n",
      "1500 steps | score: [-0.11009471118450165, 0.19852301478385925]\n",
      "1600 steps | score: [-0.03229834884405136, 0.08108308166265488]\n",
      "1700 steps | score: [0.054353293031454086, -0.07789112627506256]\n",
      "1800 steps | score: [-0.07193737477064133, 0.14310358464717865]\n",
      "1900 steps | score: [-0.07549531012773514, 0.15692205727100372]\n",
      "2000 steps | score: [-0.044509727507829666, 0.10693225264549255]\n",
      "2100 steps | score: [-0.0019655863288789988, 0.035056497901678085]\n",
      "2200 steps | score: [0.023878326639533043, -0.018738215789198875]\n",
      "2300 steps | score: [-0.1020490750670433, 0.20240293443202972]\n",
      "2400 steps | score: [-0.037953801453113556, 0.09820128977298737]\n",
      "2500 steps | score: [-0.06807295978069305, 0.14685502648353577]\n",
      "2600 steps | score: [-0.03188082203269005, 0.09417401999235153]\n",
      "unknown params:  tensor([-0.5594, -1.2409])\n",
      "unknown variance:  tensor([[1.3123]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4339, -0.5924])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3083747625350952]\n",
      "100 steps | score: [0.034006863832473755]\n",
      "200 steps | score: [-0.009804635308682919]\n",
      "0 steps | score: [0.11534059047698975, 0.03657858446240425]\n",
      "100 steps | score: [-0.13865774869918823, 0.3271700143814087]\n",
      "200 steps | score: [-0.3773915469646454, 0.6275480389595032]\n",
      "300 steps | score: [0.13999418914318085, -0.2493577003479004]\n",
      "400 steps | score: [0.5118659734725952, -1.153557538986206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 steps | score: [-0.1090722307562828, 0.18288427591323853]\n",
      "600 steps | score: [-0.13197825849056244, 0.2376643717288971]\n",
      "700 steps | score: [0.020432863384485245, -0.08174039423465729]\n",
      "800 steps | score: [-0.07434261590242386, 0.1288832128047943]\n",
      "900 steps | score: [-0.029110748320817947, 0.012715764343738556]\n",
      "1000 steps | score: [-0.07070109993219376, 0.1088927686214447]\n",
      "1100 steps | score: [0.011488872580230236, -0.057948194444179535]\n",
      "1200 steps | score: [-0.004786159377545118, -0.035335294902324677]\n",
      "1300 steps | score: [0.16941021382808685, -0.40055254101753235]\n",
      "1400 steps | score: [-0.15143373608589172, 0.23451510071754456]\n",
      "1500 steps | score: [-0.0808742493391037, 0.10994385182857513]\n",
      "1600 steps | score: [-0.07492321729660034, 0.10269320011138916]\n",
      "1700 steps | score: [0.02066311053931713, -0.0897645577788353]\n",
      "1800 steps | score: [-0.07186336070299149, 0.10864084959030151]\n",
      "1900 steps | score: [-0.08498525619506836, 0.12701721489429474]\n",
      "2000 steps | score: [-0.07057419419288635, 0.10111727565526962]\n",
      "2100 steps | score: [-0.05678976699709892, 0.07489712536334991]\n",
      "2200 steps | score: [-0.04366207495331764, 0.056023355573415756]\n",
      "2300 steps | score: [-0.01361189316958189, -0.005286399275064468]\n",
      "2400 steps | score: [-0.053850702941417694, 0.056812942028045654]\n",
      "2500 steps | score: [-0.032771434634923935, 0.019101280719041824]\n",
      "0 steps | score: [0.2749878466129303, -0.23010241985321045]\n",
      "100 steps | score: [-0.03289514780044556, 0.13776929676532745]\n",
      "200 steps | score: [-0.2231045961380005, 0.3781687021255493]\n",
      "300 steps | score: [0.29105377197265625, -0.526364803314209]\n",
      "400 steps | score: [0.5828967690467834, -1.2534154653549194]\n",
      "500 steps | score: [-0.00017855533224064857, -0.006505267694592476]\n",
      "0 steps | score: [0.18659915030002594, -0.07640054076910019]\n",
      "100 steps | score: [-0.10971827059984207, 0.27760690450668335]\n",
      "200 steps | score: [-0.28747716546058655, 0.48900923132896423]\n",
      "300 steps | score: [0.1886671483516693, -0.33248671889305115]\n",
      "400 steps | score: [0.5382575392723083, -1.1800239086151123]\n",
      "500 steps | score: [-0.054627735167741776, 0.09239060431718826]\n",
      "600 steps | score: [-0.07456279546022415, 0.14724047482013702]\n",
      "700 steps | score: [0.10747326910495758, -0.20845414698123932]\n",
      "800 steps | score: [-0.0192439965903759, 0.03148886561393738]\n",
      "900 steps | score: [0.00503026507794857, -0.023589015007019043]\n",
      "1000 steps | score: [-0.007658009417355061, 0.0076723177917301655]\n",
      "unknown params:  tensor([-0.5729, -1.4630])\n",
      "unknown variance:  tensor([[1.5157]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4339, -0.5924])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.22094574570655823]\n",
      "100 steps | score: [-0.07710019499063492]\n",
      "200 steps | score: [-0.006731219589710236]\n",
      "0 steps | score: [0.21899765729904175, -0.21261537075042725]\n",
      "100 steps | score: [0.2723740041255951, -0.40909379720687866]\n",
      "200 steps | score: [-0.05210864916443825, 0.1329517364501953]\n",
      "300 steps | score: [0.2535289525985718, -0.48845136165618896]\n",
      "400 steps | score: [-0.10551571846008301, 0.19709762930870056]\n",
      "500 steps | score: [-0.024600574746727943, 0.060150664299726486]\n",
      "600 steps | score: [0.03570700064301491, -0.09635204821825027]\n",
      "700 steps | score: [-0.06943640112876892, 0.13094528019428253]\n",
      "800 steps | score: [-0.0413186140358448, 0.05694010481238365]\n",
      "900 steps | score: [-0.08524610102176666, 0.15027204155921936]\n",
      "1000 steps | score: [-0.0006966596702113748, -0.015829311683773994]\n",
      "1100 steps | score: [-0.010734135285019875, -0.017641285434365273]\n",
      "1200 steps | score: [-0.03130076080560684, 0.033230796456336975]\n",
      "1300 steps | score: [0.06564797461032867, -0.1811133623123169]\n",
      "1400 steps | score: [-0.020206209272146225, 0.015724681317806244]\n",
      "1500 steps | score: [0.12362970411777496, -0.3055908679962158]\n",
      "1600 steps | score: [0.06092735007405281, -0.14445945620536804]\n",
      "1700 steps | score: [-0.012639188207685947, -0.015283757820725441]\n",
      "1800 steps | score: [0.036691248416900635, -0.10060562938451767]\n",
      "1900 steps | score: [0.01668386720120907, -0.07864698767662048]\n",
      "2000 steps | score: [0.024380220100283623, -0.07796750962734222]\n",
      "2100 steps | score: [-0.042692117393016815, 0.04818444326519966]\n",
      "2200 steps | score: [-0.018826723098754883, 0.003255411982536316]\n",
      "2300 steps | score: [-0.005419230554252863, -0.0348542258143425]\n",
      "2400 steps | score: [0.07230500876903534, -0.1890888810157776]\n",
      "2500 steps | score: [0.024832213297486305, -0.08419463783502579]\n",
      "2600 steps | score: [-0.018300728872418404, -0.00452069565653801]\n",
      "0 steps | score: [0.21259410679340363, -0.1879328340291977]\n",
      "100 steps | score: [0.2955048680305481, -0.4477790594100952]\n",
      "200 steps | score: [-0.04666585475206375, 0.1275649070739746]\n",
      "300 steps | score: [0.31683415174484253, -0.6398870348930359]\n",
      "400 steps | score: [-0.09277454763650894, 0.18351319432258606]\n",
      "500 steps | score: [-0.039057131856679916, 0.08290943503379822]\n",
      "600 steps | score: [0.018188530579209328, -0.05627952143549919]\n",
      "700 steps | score: [-0.0716376081109047, 0.14380791783332825]\n",
      "800 steps | score: [-0.030136657878756523, 0.04646237939596176]\n",
      "900 steps | score: [-0.07063767313957214, 0.13057464361190796]\n",
      "1000 steps | score: [-0.010237930342555046, -0.005743272602558136]\n",
      "1100 steps | score: [0.0073371888138353825, -0.040520697832107544]\n",
      "1200 steps | score: [-0.032350942492485046, 0.04597938433289528]\n",
      "1300 steps | score: [0.06762085109949112, -0.1681232750415802]\n",
      "1400 steps | score: [-0.04728604480624199, 0.06380302459001541]\n",
      "1500 steps | score: [0.12790143489837646, -0.30214908719062805]\n",
      "1600 steps | score: [0.06779643148183823, -0.17424210906028748]\n",
      "1700 steps | score: [-0.007178172469139099, -0.022715987637639046]\n",
      "1800 steps | score: [0.03187030926346779, -0.07838127762079239]\n",
      "1900 steps | score: [-0.013100381940603256, -0.02137446030974388]\n",
      "2000 steps | score: [0.006559567991644144, -0.035912785679101944]\n",
      "2100 steps | score: [-0.04736782982945442, 0.062399864196777344]\n",
      "2200 steps | score: [-0.024953659623861313, 0.01731215789914131]\n",
      "2300 steps | score: [-0.005881001707166433, -0.013294749893248081]\n",
      "2400 steps | score: [0.061858490109443665, -0.16636495292186737]\n",
      "2500 steps | score: [0.002380432328209281, -0.040124088525772095]\n",
      "2600 steps | score: [-0.006021259818226099, -0.02196980081498623]\n",
      "0 steps | score: [0.1989230513572693, -0.15679346024990082]\n",
      "100 steps | score: [0.2848813235759735, -0.42667001485824585]\n",
      "200 steps | score: [-0.0702030211687088, 0.17459160089492798]\n",
      "300 steps | score: [0.24332599341869354, -0.44535505771636963]\n",
      "400 steps | score: [-0.09474188089370728, 0.19887959957122803]\n",
      "500 steps | score: [-0.01087486557662487, 0.043048959225416183]\n",
      "600 steps | score: [0.018363092094659805, -0.050593286752700806]\n",
      "700 steps | score: [-0.080010324716568, 0.16137172281742096]\n",
      "800 steps | score: [-0.048549022525548935, 0.0835408940911293]\n",
      "900 steps | score: [-0.13303212821483612, 0.24301552772521973]\n",
      "1000 steps | score: [-0.025016820058226585, 0.037386972457170486]\n",
      "1100 steps | score: [-0.037556424736976624, 0.05123273655772209]\n",
      "1200 steps | score: [-0.04508408159017563, 0.07263296842575073]\n",
      "1300 steps | score: [0.02839973196387291, -0.08761174976825714]\n",
      "1400 steps | score: [-0.044719159603118896, 0.07556112110614777]\n",
      "1500 steps | score: [0.09070983529090881, -0.21608801186084747]\n",
      "1600 steps | score: [0.05083441361784935, -0.1309305876493454]\n",
      "1700 steps | score: [-0.008180171251296997, -0.010477831587195396]\n",
      "1800 steps | score: [0.007638354320079088, -0.04252737760543823]\n",
      "1900 steps | score: [-0.032589517533779144, 0.03760687634348869]\n",
      "2000 steps | score: [0.01416789647191763, -0.04092975705862045]\n",
      "2100 steps | score: [-0.05029405653476715, 0.07060956209897995]\n",
      "2200 steps | score: [-0.05620608106255531, 0.07966545224189758]\n",
      "2300 steps | score: [-0.03259249031543732, 0.028313521295785904]\n",
      "2400 steps | score: [0.04083617031574249, -0.11522670090198517]\n",
      "2500 steps | score: [-0.002632259391248226, -0.013830860145390034]\n",
      "2600 steps | score: [-0.02746681682765484, 0.03040517121553421]\n",
      "unknown params:  tensor([-0.5031, -1.3201])\n",
      "unknown variance:  tensor([[1.5840]], grad_fn=<MulBackward0>)\n",
      "Logging in: /home/gridsan/stefanou/Regression/5KLaplace/1a507c89-f701-4084-a156-d41094b8697f\n",
      "gt params:  tensor([-0.4236, -0.5715])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.16186638176441193]\n",
      "100 steps | score: [0.001931123435497284]\n",
      "0 steps | score: [0.031454358249902725, 0.04769640043377876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps | score: [-0.022577496245503426, -0.032265856862068176]\n",
      "200 steps | score: [-0.00855707935988903, 0.05322328954935074]\n",
      "300 steps | score: [-0.03591948002576828, -0.03776385635137558]\n",
      "400 steps | score: [0.01046462170779705, 0.00883454829454422]\n",
      "500 steps | score: [-0.012806707061827183, -0.04057367146015167]\n",
      "600 steps | score: [0.026849443092942238, 0.013032641261816025]\n",
      "700 steps | score: [-0.020010123029351234, -0.04012969136238098]\n",
      "800 steps | score: [0.030522530898451805, 0.0019378256984055042]\n",
      "900 steps | score: [-0.017943643033504486, -0.012775290757417679]\n",
      "1000 steps | score: [-0.021458949893712997, -0.01622685045003891]\n",
      "1100 steps | score: [-0.0024664506781846285, 0.03829117491841316]\n",
      "1200 steps | score: [-0.02374112606048584, -0.02393573522567749]\n",
      "1300 steps | score: [0.008044847287237644, -0.016474012285470963]\n",
      "1400 steps | score: [-0.0052639939822256565, -0.03410657122731209]\n",
      "1500 steps | score: [0.014682063832879066, 0.0010911626741290092]\n",
      "1600 steps | score: [0.002194552682340145, -0.006455572787672281]\n",
      "0 steps | score: [0.039828069508075714, 0.006918573286384344]\n",
      "100 steps | score: [-0.022232266142964363, -0.07759584486484528]\n",
      "200 steps | score: [0.0014518932439386845, 0.014293299987912178]\n",
      "300 steps | score: [-0.03151322528719902, -0.08020951598882675]\n",
      "400 steps | score: [0.005550552159547806, -0.021648811176419258]\n",
      "500 steps | score: [-0.008536245673894882, -0.06975111365318298]\n",
      "600 steps | score: [0.03667069226503372, -0.02083548530936241]\n",
      "700 steps | score: [-0.010047519579529762, -0.06195778399705887]\n",
      "800 steps | score: [0.02085944637656212, -0.031027231365442276]\n",
      "900 steps | score: [-0.009993183426558971, -0.04166439548134804]\n",
      "1000 steps | score: [-0.013928291387856007, -0.040381915867328644]\n",
      "1100 steps | score: [0.0047843316569924355, 0.009364008903503418]\n",
      "0 steps | score: [0.06602533906698227, 0.07050640881061554]\n",
      "100 steps | score: [-0.0004952499293722212, -0.014606383629143238]\n",
      "200 steps | score: [0.03202790394425392, 0.07271648943424225]\n",
      "300 steps | score: [-0.01143945474177599, -0.028125731274485588]\n",
      "400 steps | score: [0.03512733802199364, 0.025822024792432785]\n",
      "500 steps | score: [0.016982192173600197, -0.011876949109137058]\n",
      "600 steps | score: [0.058689557015895844, 0.04038417711853981]\n",
      "700 steps | score: [0.006630531512200832, -0.010636746883392334]\n",
      "800 steps | score: [0.05289420858025551, 0.023888112977147102]\n",
      "900 steps | score: [0.01094045676290989, 0.014571215957403183]\n",
      "1000 steps | score: [0.011207325384020805, 0.004630882292985916]\n",
      "1100 steps | score: [0.033488012850284576, 0.06479238718748093]\n",
      "1200 steps | score: [0.00826271902769804, -0.00705276895314455]\n",
      "unknown params:  tensor([-0.3666, -0.4450])\n",
      "unknown variance:  tensor([[0.7928]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4236, -0.5715])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [-0.07630560547113419]\n",
      "100 steps | score: [-0.1790560483932495]\n",
      "200 steps | score: [-0.10438910126686096]\n",
      "300 steps | score: [-0.18290114402770996]\n",
      "400 steps | score: [-0.16634300351142883]\n",
      "500 steps | score: [-0.18637654185295105]\n",
      "600 steps | score: [-0.18265298008918762]\n",
      "700 steps | score: [-0.1350303441286087]\n",
      "800 steps | score: [-0.1291918307542801]\n",
      "900 steps | score: [-0.19367651641368866]\n",
      "1000 steps | score: [-0.2049223780632019]\n",
      "1100 steps | score: [-0.11218982934951782]\n",
      "1200 steps | score: [-0.145975723862648]\n",
      "1300 steps | score: [-0.17053888738155365]\n",
      "1400 steps | score: [-0.17676010727882385]\n",
      "1500 steps | score: [-0.1739107221364975]\n",
      "1600 steps | score: [-0.1327853798866272]\n",
      "1700 steps | score: [-0.13900582492351532]\n",
      "1800 steps | score: [-0.14385159313678741]\n",
      "1900 steps | score: [-0.14429274201393127]\n",
      "2000 steps | score: [-0.14228087663650513]\n",
      "2100 steps | score: [-0.14628276228904724]\n",
      "2200 steps | score: [-0.16170406341552734]\n",
      "2300 steps | score: [-0.1508341133594513]\n",
      "2400 steps | score: [-0.15020006895065308]\n",
      "2500 steps | score: [-0.16482087969779968]\n",
      "2600 steps | score: [-0.1707647144794464]\n",
      "2700 steps | score: [-0.14616070687770844]\n",
      "2800 steps | score: [-0.15639910101890564]\n",
      "0 steps | score: [0.03320959582924843, 0.06669574975967407]\n",
      "100 steps | score: [-0.06537382304668427, 0.0029797821771353483]\n",
      "200 steps | score: [0.005338835529983044, -0.03382979705929756]\n",
      "300 steps | score: [-0.0415504090487957, 0.0027521923184394836]\n",
      "400 steps | score: [-0.03165270388126373, -0.00992228277027607]\n",
      "500 steps | score: [-0.054294317960739136, -0.0218272153288126]\n",
      "600 steps | score: [-0.04919147491455078, 0.02398652210831642]\n",
      "700 steps | score: [-0.016826694831252098, -0.00841591041535139]\n",
      "800 steps | score: [-0.008618408814072609, -0.048197243362665176]\n",
      "900 steps | score: [-0.06294458359479904, -0.03315725550055504]\n",
      "1000 steps | score: [-0.04331020265817642, 0.024043697863817215]\n",
      "1100 steps | score: [-0.004736978095024824, -0.019411833956837654]\n",
      "1200 steps | score: [-0.01766403578221798, -0.029672082513570786]\n",
      "1300 steps | score: [-0.021828217431902885, -0.04954379424452782]\n",
      "1400 steps | score: [-0.039719108492136, 0.011142400093376637]\n",
      "1500 steps | score: [-0.02857261151075363, -0.011900429613888264]\n",
      "1600 steps | score: [-0.01568487472832203, -0.03842109441757202]\n",
      "1700 steps | score: [-0.011785958893597126, -0.041679881513118744]\n",
      "1800 steps | score: [-0.02873821370303631, -0.004862505942583084]\n",
      "1900 steps | score: [-0.026191692799329758, -0.015696773305535316]\n",
      "2000 steps | score: [-0.011337592266499996, -0.02805592678487301]\n",
      "2100 steps | score: [-0.022331681102514267, -0.032674770802259445]\n",
      "2200 steps | score: [-0.03091198392212391, -0.008133048191666603]\n",
      "2300 steps | score: [-0.02612013928592205, -0.01524958573281765]\n",
      "2400 steps | score: [-0.020735470578074455, -0.02120211534202099]\n",
      "2500 steps | score: [-0.011085279285907745, -0.03869820013642311]\n",
      "2600 steps | score: [-0.02245359495282173, -0.01678319089114666]\n",
      "2700 steps | score: [-0.017548145726323128, -0.02401058003306389]\n",
      "2800 steps | score: [-0.02084621973335743, -0.01782369427382946]\n",
      "unknown params:  tensor([-0.4058, -0.4909])\n",
      "unknown variance:  tensor([[0.9046]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4236, -0.5715])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.14993366599082947]\n",
      "100 steps | score: [0.04871106520295143]\n",
      "200 steps | score: [0.03574452921748161]\n",
      "300 steps | score: [0.03252563625574112]\n",
      "400 steps | score: [0.04102282226085663]\n",
      "500 steps | score: [0.02812301553785801]\n",
      "600 steps | score: [0.031253959983587265]\n",
      "700 steps | score: [0.0644221305847168]\n",
      "800 steps | score: [0.01380736380815506]\n",
      "900 steps | score: [0.05809682607650757]\n",
      "1000 steps | score: [0.01618998311460018]\n",
      "1100 steps | score: [0.03499260172247887]\n",
      "1200 steps | score: [0.05145501345396042]\n",
      "1300 steps | score: [0.0004875361919403076]\n",
      "0 steps | score: [0.12052711844444275, 0.06171918660402298]\n",
      "100 steps | score: [0.04839078336954117, -0.01394219696521759]\n",
      "200 steps | score: [0.019152551889419556, -0.00948726199567318]\n",
      "300 steps | score: [0.042849790304899216, -0.033010657876729965]\n",
      "400 steps | score: [0.04131137207150459, -0.0685265064239502]\n",
      "500 steps | score: [0.04712574928998947, -0.02194066159427166]\n",
      "600 steps | score: [0.043056193739175797, -0.04128916934132576]\n",
      "700 steps | score: [0.06003689020872116, -0.04598093405365944]\n",
      "800 steps | score: [0.023153774440288544, -0.05767428129911423]\n",
      "900 steps | score: [0.07691692560911179, -0.05300447717308998]\n",
      "1000 steps | score: [0.028154941275715828, -0.01460876315832138]\n",
      "1100 steps | score: [0.0334538035094738, -0.012149976566433907]\n",
      "1200 steps | score: [0.06684312224388123, -0.07428275793790817]\n",
      "1300 steps | score: [0.008253373205661774, 0.013157501816749573]\n",
      "1400 steps | score: [0.046409204602241516, -0.03829510509967804]\n",
      "1500 steps | score: [0.036244310438632965, -0.0519644170999527]\n",
      "1600 steps | score: [0.0380866602063179, -0.051839135587215424]\n",
      "1700 steps | score: [0.009827883914113045, -0.002391977934166789]\n",
      "0 steps | score: [0.10832439363002777, 0.11754512786865234]\n",
      "100 steps | score: [0.03271029517054558, 0.02632834203541279]\n",
      "200 steps | score: [0.0144736897200346, 0.03305358067154884]\n",
      "300 steps | score: [0.027297722175717354, 0.021020740270614624]\n",
      "400 steps | score: [0.029011886566877365, -0.012498393654823303]\n",
      "500 steps | score: [0.03012182004749775, 0.027980487793684006]\n",
      "600 steps | score: [0.03015614114701748, 0.011862297542393208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 steps | score: [0.03999755159020424, 0.005260355770587921]\n",
      "800 steps | score: [0.021084096282720566, -0.013365920633077621]\n",
      "900 steps | score: [0.053029488772153854, 0.0044622402638196945]\n",
      "1000 steps | score: [0.018312884494662285, 0.039787061512470245]\n",
      "1100 steps | score: [0.023174980655312538, 0.03322453424334526]\n",
      "1200 steps | score: [0.04983660951256752, -0.024631865322589874]\n",
      "1300 steps | score: [0.004083320964127779, 0.06158936023712158]\n",
      "1400 steps | score: [0.0347212590277195, 0.015233101323246956]\n",
      "1500 steps | score: [0.0405534952878952, -0.008847583085298538]\n",
      "1600 steps | score: [0.02251930721104145, -0.0007701721042394638]\n",
      "1700 steps | score: [-0.007127275224775076, 0.053243592381477356]\n",
      "1800 steps | score: [0.014987402595579624, 0.022459354251623154]\n",
      "1900 steps | score: [0.027352241799235344, 0.00497979111969471]\n",
      "2000 steps | score: [0.0185728520154953, 0.010819205082952976]\n",
      "2100 steps | score: [0.01026113610714674, 0.030368853360414505]\n",
      "2200 steps | score: [0.020100221037864685, 0.018818022683262825]\n",
      "2300 steps | score: [0.021904826164245605, 0.011785199865698814]\n",
      "2400 steps | score: [0.024291716516017914, 0.013117261230945587]\n",
      "2500 steps | score: [0.014880986884236336, 0.027049174532294273]\n",
      "2600 steps | score: [0.021289171651005745, 0.018128549680113792]\n",
      "unknown params:  tensor([-0.3979, -0.5290])\n",
      "unknown variance:  tensor([[0.8990]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4236, -0.5715])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.07517015933990479]\n",
      "100 steps | score: [-0.009069794788956642]\n",
      "0 steps | score: [0.10465821623802185, 0.11957550793886185]\n",
      "100 steps | score: [0.03859937936067581, 0.01807272993028164]\n",
      "200 steps | score: [-0.020719613879919052, 0.022071216255426407]\n",
      "300 steps | score: [-0.053033437579870224, 0.08136477321386337]\n",
      "400 steps | score: [0.021091919392347336, -0.026815103366971016]\n",
      "500 steps | score: [-0.06893368065357208, 0.1289300173521042]\n",
      "600 steps | score: [-0.02605568803846836, 0.05587558448314667]\n",
      "700 steps | score: [-0.020853191614151, 0.03224499523639679]\n",
      "800 steps | score: [0.004796215798705816, 0.014383267611265182]\n",
      "900 steps | score: [0.003190374933183193, 0.0241421889513731]\n",
      "1000 steps | score: [0.014966011047363281, 0.011428751051425934]\n",
      "1100 steps | score: [0.0494060143828392, -0.056550830602645874]\n",
      "1200 steps | score: [0.007510024588555098, 0.03471957892179489]\n",
      "1300 steps | score: [0.004922676365822554, 0.018227502703666687]\n",
      "1400 steps | score: [0.026762859895825386, -0.00770211685448885]\n",
      "1500 steps | score: [0.0028167953714728355, 0.011975176632404327]\n",
      "1600 steps | score: [0.013812686316668987, 0.014623185619711876]\n",
      "1700 steps | score: [0.005522578954696655, 0.014246165752410889]\n",
      "1800 steps | score: [0.019985277205705643, -0.017986223101615906]\n",
      "1900 steps | score: [0.0022724897135049105, 0.025573736056685448]\n",
      "2000 steps | score: [-0.001848106156103313, 0.022072266787290573]\n",
      "2100 steps | score: [0.014870461076498032, 0.005455087870359421]\n",
      "2200 steps | score: [-0.002447316190227866, 0.015315171331167221]\n",
      "2300 steps | score: [0.0025462929625064135, 0.025693733245134354]\n",
      "2400 steps | score: [0.007761440239846706, 0.0211627334356308]\n",
      "2500 steps | score: [0.015232040546834469, 0.0028145648539066315]\n",
      "2600 steps | score: [0.011161062866449356, 0.00877426192164421]\n",
      "2700 steps | score: [0.0033530842047184706, 0.016461443156003952]\n",
      "2800 steps | score: [0.008116851560771465, 0.011932307854294777]\n",
      "unknown params:  tensor([-0.4367, -0.5935])\n",
      "unknown variance:  tensor([[0.9915]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4236, -0.5715])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.04485996812582016]\n",
      "100 steps | score: [-0.06794105470180511]\n",
      "200 steps | score: [-0.1438976526260376]\n",
      "300 steps | score: [-0.05773382633924484]\n",
      "400 steps | score: [-0.09317473322153091]\n",
      "500 steps | score: [-0.05358121171593666]\n",
      "600 steps | score: [-0.1496308147907257]\n",
      "700 steps | score: [-0.10074953734874725]\n",
      "800 steps | score: [-0.13429316878318787]\n",
      "900 steps | score: [-0.10637260973453522]\n",
      "1000 steps | score: [-0.08914808183908463]\n",
      "1100 steps | score: [-0.08964630216360092]\n",
      "1200 steps | score: [-0.08653602004051208]\n",
      "1300 steps | score: [-0.0551728829741478]\n",
      "1400 steps | score: [-0.051546860486269]\n",
      "1500 steps | score: [-0.06273031234741211]\n",
      "1600 steps | score: [-0.07739199697971344]\n",
      "1700 steps | score: [-0.07655562460422516]\n",
      "1800 steps | score: [-0.09945254027843475]\n",
      "1900 steps | score: [-0.10402396321296692]\n",
      "2000 steps | score: [-0.08183230459690094]\n",
      "2100 steps | score: [-0.09114549309015274]\n",
      "2200 steps | score: [-0.060677751898765564]\n",
      "2300 steps | score: [-0.08144647628068924]\n",
      "2400 steps | score: [-0.0839901715517044]\n",
      "2500 steps | score: [-0.06872372329235077]\n",
      "0 steps | score: [0.014490602537989616, 0.09955580532550812]\n",
      "100 steps | score: [-0.06698652356863022, 0.061310771852731705]\n",
      "200 steps | score: [-0.1360112428665161, 0.06238659471273422]\n",
      "300 steps | score: [-0.025783231481909752, -0.10034509748220444]\n",
      "400 steps | score: [-0.13019587099552155, 0.039536524564027786]\n",
      "500 steps | score: [-0.03407123312354088, -0.042590800672769547]\n",
      "600 steps | score: [-0.14370742440223694, 0.05784359201788902]\n",
      "700 steps | score: [-0.08078139275312424, -0.028805937618017197]\n",
      "800 steps | score: [-0.1646100878715515, 0.0950465127825737]\n",
      "900 steps | score: [-0.08781763166189194, 0.000403563492000103]\n",
      "1000 steps | score: [-0.07642652839422226, -0.03489084169268608]\n",
      "1100 steps | score: [-0.11334112286567688, 0.05182138457894325]\n",
      "1200 steps | score: [-0.08410752564668655, 0.01212330162525177]\n",
      "1300 steps | score: [-0.0116789061576128, -0.10037969052791595]\n",
      "1400 steps | score: [-0.07034903764724731, -0.004816161468625069]\n",
      "1500 steps | score: [-0.03632098436355591, -0.05608455836772919]\n",
      "1600 steps | score: [-0.06678281724452972, -0.023291349411010742]\n",
      "1700 steps | score: [-0.08361127227544785, 0.00011377502232789993]\n",
      "1800 steps | score: [-0.0960933193564415, 0.009122643619775772]\n",
      "1900 steps | score: [-0.093365378677845, 0.010902082547545433]\n",
      "2000 steps | score: [-0.052765682339668274, -0.04610701650381088]\n",
      "2100 steps | score: [-0.10727164149284363, 0.027040962129831314]\n",
      "2200 steps | score: [-0.0744406133890152, -0.011739135719835758]\n",
      "2300 steps | score: [-0.03665667399764061, -0.059759851545095444]\n",
      "2400 steps | score: [-0.10235923528671265, 0.019202442839741707]\n",
      "2500 steps | score: [-0.08910238742828369, 0.005018437281250954]\n",
      "unknown params:  tensor([-0.4618, -0.6620])\n",
      "unknown variance:  tensor([[1.1052]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4236, -0.5715])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.21804282069206238]\n",
      "100 steps | score: [0.1189703419804573]\n",
      "200 steps | score: [0.06528601050376892]\n",
      "300 steps | score: [0.058623142540454865]\n",
      "400 steps | score: [0.09592591971158981]\n",
      "500 steps | score: [0.07283218204975128]\n",
      "600 steps | score: [0.0544927716255188]\n",
      "700 steps | score: [0.10412921756505966]\n",
      "800 steps | score: [0.09171326458454132]\n",
      "900 steps | score: [0.06698372960090637]\n",
      "1000 steps | score: [0.10777775943279266]\n",
      "1100 steps | score: [0.04825639724731445]\n",
      "1200 steps | score: [0.07211442291736603]\n",
      "1300 steps | score: [0.12967079877853394]\n",
      "1400 steps | score: [0.0863439217209816]\n",
      "1500 steps | score: [0.0938144326210022]\n",
      "1600 steps | score: [0.11600136756896973]\n",
      "1700 steps | score: [0.07631503790616989]\n",
      "1800 steps | score: [0.08958347141742706]\n",
      "1900 steps | score: [0.09020225703716278]\n",
      "2000 steps | score: [0.08190318942070007]\n",
      "2100 steps | score: [0.0691155344247818]\n",
      "2200 steps | score: [0.10478959232568741]\n",
      "2300 steps | score: [0.10079552233219147]\n",
      "2400 steps | score: [0.07677200436592102]\n",
      "2500 steps | score: [0.1169801652431488]\n",
      "2600 steps | score: [0.0947674959897995]\n",
      "0 steps | score: [0.14712829887866974, -0.004300135653465986]\n",
      "100 steps | score: [0.04853079095482826, -0.04117446020245552]\n",
      "200 steps | score: [-0.079598568379879, 0.045648518949747086]\n",
      "300 steps | score: [0.02941640093922615, -0.12763336300849915]\n",
      "400 steps | score: [-0.025000344961881638, -0.004839247092604637]\n",
      "500 steps | score: [-0.025846945121884346, -0.01708841696381569]\n",
      "600 steps | score: [-0.04220247641205788, -0.02374810352921486]\n",
      "700 steps | score: [0.032499659806489944, -0.0789283961057663]\n",
      "800 steps | score: [-0.018851090222597122, -0.03699002414941788]\n",
      "900 steps | score: [0.04428902640938759, -0.1275312602519989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 steps | score: [0.06183705851435661, -0.12542355060577393]\n",
      "1100 steps | score: [-0.021206995472311974, -0.03144180774688721]\n",
      "1200 steps | score: [-0.006731553003191948, -0.05897390842437744]\n",
      "1300 steps | score: [0.04622960463166237, -0.11145417392253876]\n",
      "1400 steps | score: [-0.004418069496750832, -0.05020543932914734]\n",
      "1500 steps | score: [0.028693102300167084, -0.08954525738954544]\n",
      "1600 steps | score: [0.04346675053238869, -0.103547602891922]\n",
      "1700 steps | score: [-0.011596753261983395, -0.03595799580216408]\n",
      "1800 steps | score: [0.02589219994843006, -0.0911029502749443]\n",
      "1900 steps | score: [0.033843062818050385, -0.08880699425935745]\n",
      "2000 steps | score: [0.008571373298764229, -0.06046660989522934]\n",
      "2100 steps | score: [0.030285978689789772, -0.08992649614810944]\n",
      "2200 steps | score: [0.01774490438401699, -0.07342755794525146]\n",
      "2300 steps | score: [-0.0013254930963739753, -0.045207295566797256]\n",
      "2400 steps | score: [0.006942817009985447, -0.07069909572601318]\n",
      "2500 steps | score: [0.008626630529761314, -0.07347739487886429]\n",
      "2600 steps | score: [-0.0056776609271764755, -0.0465448796749115]\n",
      "unknown params:  tensor([-0.4814, -0.8124])\n",
      "unknown variance:  tensor([[1.1364]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4236, -0.5715])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.03301054984331131]\n",
      "100 steps | score: [-0.06705125421285629]\n",
      "200 steps | score: [-0.19956476986408234]\n",
      "300 steps | score: [-0.13774198293685913]\n",
      "400 steps | score: [-0.22834888100624084]\n",
      "500 steps | score: [-0.19044345617294312]\n",
      "600 steps | score: [-0.18263167142868042]\n",
      "700 steps | score: [-0.16163820028305054]\n",
      "800 steps | score: [-0.1981344372034073]\n",
      "900 steps | score: [-0.1768501251935959]\n",
      "1000 steps | score: [-0.22908712923526764]\n",
      "1100 steps | score: [-0.16004855930805206]\n",
      "1200 steps | score: [-0.2339107096195221]\n",
      "1300 steps | score: [-0.16918759047985077]\n",
      "1400 steps | score: [-0.1887395679950714]\n",
      "1500 steps | score: [-0.20149049162864685]\n",
      "1600 steps | score: [-0.17835862934589386]\n",
      "1700 steps | score: [-0.19191208481788635]\n",
      "1800 steps | score: [-0.21712110936641693]\n",
      "1900 steps | score: [-0.2310875654220581]\n",
      "2000 steps | score: [-0.19525399804115295]\n",
      "2100 steps | score: [-0.22949139773845673]\n",
      "2200 steps | score: [-0.17970076203346252]\n",
      "2300 steps | score: [-0.21578839421272278]\n",
      "2400 steps | score: [-0.20518001914024353]\n",
      "2500 steps | score: [-0.17348642647266388]\n",
      "2600 steps | score: [-0.20799671113491058]\n",
      "2700 steps | score: [-0.16238974034786224]\n",
      "0 steps | score: [0.08511722832918167, 0.10669387131929398]\n",
      "100 steps | score: [0.12843528389930725, -0.1304687261581421]\n",
      "200 steps | score: [-0.0643656998872757, 0.10635905712842941]\n",
      "300 steps | score: [0.11238212138414383, -0.20142459869384766]\n",
      "400 steps | score: [-0.14482004940509796, 0.19493389129638672]\n",
      "500 steps | score: [-0.13036024570465088, 0.1651298552751541]\n",
      "600 steps | score: [-0.08647816628217697, 0.08856461197137833]\n",
      "700 steps | score: [0.004223506432026625, -0.03850974515080452]\n",
      "800 steps | score: [-0.05291576310992241, 0.04758182168006897]\n",
      "900 steps | score: [-0.057436130940914154, 0.06560038030147552]\n",
      "1000 steps | score: [-0.09470129013061523, 0.10360491275787354]\n",
      "1100 steps | score: [0.018494512885808945, -0.06629741191864014]\n",
      "1200 steps | score: [-0.1041811853647232, 0.133490189909935]\n",
      "1300 steps | score: [0.00903694611042738, -0.04590010643005371]\n",
      "1400 steps | score: [-0.044329993426799774, 0.027766812592744827]\n",
      "1500 steps | score: [-0.030712725594639778, 0.03269340097904205]\n",
      "1600 steps | score: [-0.01383253000676632, -0.005836199969053268]\n",
      "1700 steps | score: [-0.06854510307312012, 0.08112454414367676]\n",
      "1800 steps | score: [-0.014481548219919205, -0.013463318347930908]\n",
      "1900 steps | score: [-0.0536162331700325, 0.04894460737705231]\n",
      "2000 steps | score: [-0.05841619521379471, 0.06847137212753296]\n",
      "2100 steps | score: [-0.048931997269392014, 0.04240751266479492]\n",
      "2200 steps | score: [0.0005414815386757255, -0.032787956297397614]\n",
      "2300 steps | score: [-0.07335773855447769, 0.07686562091112137]\n",
      "2400 steps | score: [-0.06099370867013931, 0.0646171122789383]\n",
      "2500 steps | score: [-0.04997701942920685, 0.04363001510500908]\n",
      "2600 steps | score: [-0.06910748779773712, 0.07136635482311249]\n",
      "2700 steps | score: [-0.029415825381875038, 0.01879516988992691]\n",
      "unknown params:  tensor([-0.5019, -0.9451])\n",
      "unknown variance:  tensor([[1.2102]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4236, -0.5715])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.3084993362426758]\n",
      "100 steps | score: [0.05907055735588074]\n",
      "200 steps | score: [0.06241166591644287]\n",
      "300 steps | score: [0.05746164545416832]\n",
      "400 steps | score: [0.1068984866142273]\n",
      "500 steps | score: [0.04442809149622917]\n",
      "600 steps | score: [0.024753205478191376]\n",
      "700 steps | score: [0.04848221689462662]\n",
      "800 steps | score: [0.053527384996414185]\n",
      "900 steps | score: [0.03659217059612274]\n",
      "1000 steps | score: [0.05788394808769226]\n",
      "1100 steps | score: [0.012423735111951828]\n",
      "1200 steps | score: [0.036628060042858124]\n",
      "1300 steps | score: [0.07074577361345291]\n",
      "1400 steps | score: [-0.0025201747193932533]\n",
      "0 steps | score: [0.2151421308517456, -0.10488183796405792]\n",
      "100 steps | score: [0.022155866026878357, 0.04528506472706795]\n",
      "200 steps | score: [-0.00226631760597229, 0.014226691797375679]\n",
      "300 steps | score: [-0.06506731361150742, 0.08320359885692596]\n",
      "400 steps | score: [0.08051445335149765, -0.14323194324970245]\n",
      "500 steps | score: [0.024576282128691673, -0.055999066680669785]\n",
      "600 steps | score: [-0.04896348714828491, 0.06900180876255035]\n",
      "700 steps | score: [0.007548787165433168, -0.024465249851346016]\n",
      "800 steps | score: [-0.01279064267873764, -0.0022919599432498217]\n",
      "900 steps | score: [-0.003766345325857401, -0.0061486875638365746]\n",
      "0 steps | score: [0.10574031621217728, 0.09149177372455597]\n",
      "100 steps | score: [-0.09214362502098083, 0.2502523362636566]\n",
      "200 steps | score: [-0.05712017044425011, 0.12366770952939987]\n",
      "300 steps | score: [-0.13589023053646088, 0.23302242159843445]\n",
      "400 steps | score: [-0.003498741192743182, 0.008604444563388824]\n",
      "unknown params:  tensor([-0.4642, -0.9735])\n",
      "unknown variance:  tensor([[1.2245]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4236, -0.5715])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [-0.02405184507369995]\n",
      "100 steps | score: [-0.2970804274082184]\n",
      "200 steps | score: [-0.273060142993927]\n",
      "300 steps | score: [-0.2715038061141968]\n",
      "400 steps | score: [-0.28224122524261475]\n",
      "500 steps | score: [-0.25559768080711365]\n",
      "600 steps | score: [-0.25432220101356506]\n",
      "700 steps | score: [-0.2324395626783371]\n",
      "800 steps | score: [-0.29833483695983887]\n",
      "900 steps | score: [-0.242555633187294]\n",
      "1000 steps | score: [-0.28140026330947876]\n",
      "1100 steps | score: [-0.2503689229488373]\n",
      "1200 steps | score: [-0.28352779150009155]\n",
      "1300 steps | score: [-0.2577303647994995]\n",
      "1400 steps | score: [-0.27864959836006165]\n",
      "1500 steps | score: [-0.26508787274360657]\n",
      "1600 steps | score: [-0.2746858298778534]\n",
      "1700 steps | score: [-0.28193408250808716]\n",
      "1800 steps | score: [-0.24744528532028198]\n",
      "1900 steps | score: [-0.24201661348342896]\n",
      "2000 steps | score: [-0.26181846857070923]\n",
      "2100 steps | score: [-0.27687573432922363]\n",
      "2200 steps | score: [-0.27450400590896606]\n",
      "2300 steps | score: [-0.28690898418426514]\n",
      "2400 steps | score: [-0.25273042917251587]\n",
      "2500 steps | score: [-0.2615223526954651]\n",
      "0 steps | score: [0.2129761278629303, -0.19142086803913116]\n",
      "100 steps | score: [0.07701615244150162, -0.07351541519165039]\n",
      "200 steps | score: [0.3071684241294861, -0.6129280924797058]\n",
      "300 steps | score: [-0.06930109113454819, 0.09494520723819733]\n",
      "400 steps | score: [-0.10958186537027359, 0.14563825726509094]\n",
      "500 steps | score: [-0.10365729033946991, 0.13615764677524567]\n",
      "600 steps | score: [0.07425590604543686, -0.18406793475151062]\n",
      "700 steps | score: [-0.008757773786783218, -0.039688840508461]\n",
      "800 steps | score: [-0.04549969360232353, 0.009916560724377632]\n",
      "900 steps | score: [-0.012617803178727627, -0.04448924958705902]\n",
      "1000 steps | score: [0.22902561724185944, -0.5238885879516602]\n",
      "1100 steps | score: [0.12537643313407898, -0.29828375577926636]\n",
      "1200 steps | score: [0.05736307054758072, -0.1624477207660675]\n",
      "1300 steps | score: [0.056259892880916595, -0.1639048159122467]\n",
      "1400 steps | score: [0.03445463255047798, -0.11799650639295578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 steps | score: [0.05556770786643028, -0.17105989158153534]\n",
      "1600 steps | score: [-0.005234833806753159, -0.05035741254687309]\n",
      "1700 steps | score: [-0.042639996856451035, 0.016476351767778397]\n",
      "1800 steps | score: [0.07441823929548264, -0.19643977284431458]\n",
      "1900 steps | score: [0.05669385567307472, -0.1665402352809906]\n",
      "2000 steps | score: [0.010942336171865463, -0.08495704084634781]\n",
      "2100 steps | score: [0.02417384460568428, -0.10387389361858368]\n",
      "2200 steps | score: [0.028892740607261658, -0.11473742127418518]\n",
      "2300 steps | score: [0.027438737452030182, -0.11353190243244171]\n",
      "2400 steps | score: [0.07591857016086578, -0.212323859333992]\n",
      "2500 steps | score: [0.006426394917070866, -0.0851084515452385]\n",
      "unknown params:  tensor([-0.4761, -1.0892])\n",
      "unknown variance:  tensor([[1.4042]], grad_fn=<MulBackward0>)\n",
      "gt params:  tensor([-0.4236, -0.5715])\n",
      "gt var:  tensor([1.])\n",
      "0 steps | score: [0.1601281464099884]\n",
      "100 steps | score: [-0.1549828201532364]\n",
      "200 steps | score: [-0.08940902352333069]\n",
      "300 steps | score: [-0.10488258302211761]\n",
      "400 steps | score: [-0.08383293449878693]\n",
      "500 steps | score: [-0.0860404521226883]\n",
      "600 steps | score: [-0.10361398756504059]\n",
      "700 steps | score: [-0.14383156597614288]\n",
      "800 steps | score: [-0.11727961152791977]\n",
      "900 steps | score: [-0.1480157971382141]\n",
      "1000 steps | score: [-0.1202506273984909]\n",
      "1100 steps | score: [-0.11596246808767319]\n",
      "1200 steps | score: [-0.11768713593482971]\n",
      "1300 steps | score: [-0.13678181171417236]\n",
      "1400 steps | score: [-0.132182314991951]\n",
      "1500 steps | score: [-0.14157041907310486]\n",
      "1600 steps | score: [-0.1389358639717102]\n",
      "1700 steps | score: [-0.14181286096572876]\n",
      "1800 steps | score: [-0.12184640765190125]\n",
      "1900 steps | score: [-0.11166457086801529]\n",
      "2000 steps | score: [-0.10783593356609344]\n",
      "2100 steps | score: [-0.12928587198257446]\n",
      "2200 steps | score: [-0.09230099618434906]\n",
      "2300 steps | score: [-0.12051200866699219]\n",
      "2400 steps | score: [-0.13474608957767487]\n",
      "2500 steps | score: [-0.10330790281295776]\n",
      "2600 steps | score: [-0.11114321649074554]\n",
      "0 steps | score: [0.19265130162239075, -0.09889153391122818]\n",
      "100 steps | score: [0.008518245071172714, 0.14561773836612701]\n",
      "200 steps | score: [0.05110448598861694, 0.003873135894536972]\n",
      "300 steps | score: [0.035473957657814026, 0.015003200620412827]\n",
      "400 steps | score: [0.0984199047088623, -0.1453145295381546]\n",
      "500 steps | score: [0.2515270709991455, -0.5099266171455383]\n",
      "600 steps | score: [0.031038975343108177, -0.02975691296160221]\n",
      "700 steps | score: [-0.09847577661275864, 0.22068464756011963]\n",
      "800 steps | score: [-0.11768417805433273, 0.26782670617103577]\n",
      "900 steps | score: [0.06003613397479057, -0.09341024607419968]\n",
      "1000 steps | score: [-0.019474901258945465, 0.07806272804737091]\n",
      "1100 steps | score: [0.014744139276444912, 0.0035122763365507126]\n"
     ]
    }
   ],
   "source": [
    " # expriment parameters\n",
    "w_lower, w_upper = -1, 1\n",
    "d, k = 1, 1\n",
    "\n",
    "# distribution for generating feature vectors\n",
    "W = Uniform(w_lower, w_upper)\n",
    "dist = Uniform(-5, 5)\n",
    "noise_var = ch.ones(1)\n",
    "noise_scale = ch.sqrt(noise_var/2)\n",
    "laplace = Laplace(ch.zeros(1), noise_scale)\n",
    "\n",
    "C = [-2.5, -2, -1.75, -1.5, -1.25, -1.0, -.75, -.5, -.25, 0.0]\n",
    "\n",
    "# generate ground truth\n",
    "gt = ch.nn.Linear(in_features=d, out_features=k)\n",
    "gt.weight = ch.nn.Parameter(W.sample(ch.Size([k, d])))\n",
    "gt.bias = ch.nn.Parameter(W.sample(ch.Size([1, 1]))) if args.bias else None\n",
    "\n",
    "for i in range(args.trials):\n",
    "    # create store and add table\n",
    "    store = Store(OUT_DIR + EXP)\n",
    "    store.add_table(TABLE_NAME, { \n",
    "        'ols_r2': float,\n",
    "        'ols_param_mse': float,\n",
    "        'ols_var_l1': float,\n",
    "        'known_r2': float,\n",
    "        'known_param_mse': float,\n",
    "        'known_time': int,\n",
    "        'unknown_r2': float, \n",
    "        'unknown_param_mse': float,\n",
    "        'unknown_var_l1': float,\n",
    "        'unknown_time': int,\n",
    "        'alpha': float, \n",
    "        'c': float,\n",
    "        'num_samples': int,\n",
    "        'noise_scale': float, \n",
    "    })\n",
    "    \n",
    "    # create base classifier\n",
    "    with ch.no_grad():\n",
    "        # generate data\n",
    "        X = dist.sample(ch.Size([args.samples, d])) if isinstance(dist, Uniform) else dist.sample(ch.Size([args.samples]))\n",
    "        noised = gt(X) + laplace.sample(ch.Size([X.size(0)]))\n",
    "        \n",
    "    for c in C: \n",
    "        phi = oracle.Left(c)\n",
    "        # add noise to ground-truth pedictions\n",
    "        # truncate based off of the standardized data\n",
    "        indices = phi(noised).flatten().nonzero(as_tuple=False).flatten()\n",
    "        y_trunc, x_trunc = noised[indices], X[indices]\n",
    "        alpha = Tensor([y_trunc.size(0) / args.samples])\n",
    "        \n",
    "        val = int(.2*x_trunc.size(0))\n",
    "        \n",
    "        # normalize x features so that ||x_{i}||_{2}^{2} <= 1\n",
    "        l_inf = LA.norm(x_trunc, dim=-1, ord=float('inf')).max() # find max l_inf\n",
    "        # calculate normalizing constant\n",
    "        beta = l_inf*math.sqrt(d)\n",
    "        \"\"\"\n",
    "        Divide input features by normalizing constant. By doing so, \n",
    "        the weights will be increased by a magnitude of beta.\n",
    "        \"\"\"\n",
    "        x_trunc_norm = x_trunc / beta\n",
    "         # normalize entire dataset by beta\n",
    "        x_norm = X / beta\n",
    "        \n",
    "        # ground-truth ols\n",
    "        gt_ols = LinearRegression()\n",
    "        gt_ols.fit(X, noised)\n",
    "        gt_params = ch.cat([Tensor(gt_ols.coef_).T, Tensor(gt_ols.intercept_)[..., None]]).flatten()\n",
    "        print(\"gt params: \", gt_params)\n",
    "        print(\"gt var: \", noise_var)\n",
    "        \n",
    "        # empirical linear regression\n",
    "        ols = LinearRegression() \n",
    "        ols.fit(x_trunc, y_trunc)\n",
    "        ols_var = ch.var(Tensor(ols.predict(x_trunc)) - y_trunc, dim=0)[..., None]\n",
    "        ols_params = ch.cat([Tensor(ols.coef_).T, Tensor(ols.intercept_)[..., None]]).flatten()\n",
    "        # check r2 for entire dataset\n",
    "        ols_pred = ols.predict(X)\n",
    "\n",
    "        # ols results\n",
    "        store[TABLE_NAME].update_row({\n",
    "            'ols_r2': r2_score(noised.flatten(), ols_pred.flatten()), \n",
    "            'ols_var_l1': ch.abs(ols_var - noise_var),\n",
    "            'ols_param_mse': mse_loss(ols_params, gt_params),\n",
    "        })\n",
    "        \n",
    "        \"\"\"\n",
    "        Run dataset on truncated regression with known variance, while \n",
    "        assuming that the empirical noise variance is the underlying noise \n",
    "        variance of our linear regression. This means that we want to standardize \n",
    "        our dependent variable by the empirical noise variance. \n",
    "        \"\"\"\n",
    "        # variance of the residuals\n",
    "        emp_noise_var = (y_trunc - ols.predict(x_trunc_norm)).var(0)\n",
    "        # standardize y trunc by the empirical noise variance\n",
    "        emp_noise_scale = ch.sqrt(emp_noise_var/2) \n",
    "        emp_stand_y_trunc = y_trunc / ch.sqrt(emp_noise_var)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Run dataset on truncated regression with known variance. This means that we want to standardize \n",
    "        our dependent variable by the true noise variance. \n",
    "        \"\"\"\n",
    "        # standardize y trunc by the empirical noise variance\n",
    "        stand_y_trunc = y_trunc / ch.sqrt(noise_var)\n",
    "        # standardize noised by the empirical noise variance\n",
    "        stand_noised = noised / ch.sqrt(noise_var)\n",
    "        trunc_reg = trunc_reg = TruncatedRegression(phi=phi, alpha=alpha, bias=args.bias, unknown=False, bs=args.bs, n=100, tol=args.tol, steps=args.steps)\n",
    "        st = datetime.datetime.now()\n",
    "        known_results = trunc_reg.fit(x_trunc_norm, stand_y_trunc)\n",
    "        w, w0 = (known_results.weight.detach().cpu() * ch.sqrt(noise_var)) / beta, known_results.bias.detach().cpu()[..., None] * ch.sqrt(noise_var)\n",
    "        known_params = ch.cat([w, w0], dim=1).flatten()\n",
    "        # known results\n",
    "        store[TABLE_NAME].update_row({\n",
    "            'known_r2': r2_score(noised.flatten(), X@w.T + w0), \n",
    "            'known_param_mse': mse_loss(known_params, gt_params),\n",
    "            'known_time': int((datetime.datetime.now() - st).total_seconds()), \n",
    "        })\n",
    "        \n",
    "        \n",
    "        # truncated regression with unknown variance\n",
    "        # run procedure until get reasonable gradient value\n",
    "        st = datetime.datetime.now()\n",
    "        attempt, grad = 0, None\n",
    "        best, unknown_results = None, None\n",
    "        while (grad is None or grad < 3e-1) and attempt < 3:\n",
    "            trunc_reg = TruncatedRegression(phi=phi, alpha=alpha, bias=args.bias, unknown=True, bs=args.bs, n=100, tol=args.tol, steps=args.steps, val=val)\n",
    "            res = trunc_reg.fit(x_trunc_norm, emp_stand_y_trunc)\n",
    "            grad = ch.abs(ch.cat([res.weight.grad.flatten(), res.bias.grad.flatten(), res.lambda_.grad.flatten()])).mean(0)\n",
    "            if best is None or grad < best: \n",
    "                best, unknown_results = grad, res\n",
    "            attempt += 1\n",
    "    \n",
    "\n",
    "        var_ = unknown_results.lambda_.inverse()\n",
    "        unknown_var = var_ * emp_noise_var\n",
    "        w, w0 = (((unknown_results.weight * var_) * ch.sqrt(emp_noise_var)) / beta).detach(), ((unknown_results.bias * var_ * ch.sqrt(emp_noise_var))).detach()\n",
    "        unknown_params = ch.cat([w, w0], dim=1).flatten()\n",
    "        print(\"unknown params: \", unknown_params)\n",
    "        print(\"unknown variance: \", unknown_var)\n",
    "\n",
    "        # known emp results\n",
    "        store[TABLE_NAME].update_row({\n",
    "            'unknown_r2': r2_score(noised.flatten(), X@w.T + w0), \n",
    "            'unknown_param_mse': mse_loss(unknown_params, gt_params),\n",
    "            'unknown_var_l1': float(ch.abs(unknown_var - noise_var)),\n",
    "            'unknown_time': int((datetime.datetime.now() - st).total_seconds()), \n",
    "        })\n",
    "        \n",
    "        \n",
    "        # add additional exp data to store\n",
    "        store[TABLE_NAME].update_row({ \n",
    "            'alpha': float(alpha.flatten()),\n",
    "            'num_samples': x_trunc.size(0),\n",
    "            'noise_scale': ch.ones(1), \n",
    "            'c': c,\n",
    "        })\n",
    "\n",
    "        # append row to table\n",
    "        store[TABLE_NAME].flush_row()\n",
    "    store.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:00<00:00, 178.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ols_r2</th>\n",
       "      <th>ols_param_mse</th>\n",
       "      <th>ols_var_l1</th>\n",
       "      <th>known_r2</th>\n",
       "      <th>known_param_mse</th>\n",
       "      <th>known_time</th>\n",
       "      <th>unknown_r2</th>\n",
       "      <th>unknown_param_mse</th>\n",
       "      <th>unknown_var_l1</th>\n",
       "      <th>unknown_time</th>\n",
       "      <th>alpha</th>\n",
       "      <th>c</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>noise_scale</th>\n",
       "      <th>exp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.152779</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.102018</td>\n",
       "      <td>0.153504</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>2</td>\n",
       "      <td>0.153291</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.104234</td>\n",
       "      <td>12</td>\n",
       "      <td>0.9904</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>9904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49a9b744-70d9-427c-89b3-0be8bdd153c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.150526</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.150979</td>\n",
       "      <td>0.153170</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>4</td>\n",
       "      <td>0.152084</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.130812</td>\n",
       "      <td>13</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>9816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49a9b744-70d9-427c-89b3-0be8bdd153c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.148389</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>0.180705</td>\n",
       "      <td>0.152915</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0</td>\n",
       "      <td>0.152856</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.142953</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>9746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49a9b744-70d9-427c-89b3-0be8bdd153c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.144894</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.215329</td>\n",
       "      <td>0.153446</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>4</td>\n",
       "      <td>0.152959</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.161318</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>9645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49a9b744-70d9-427c-89b3-0be8bdd153c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.138841</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>0.254207</td>\n",
       "      <td>0.153691</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>4</td>\n",
       "      <td>0.153354</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.184326</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9495</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>9495</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49a9b744-70d9-427c-89b3-0be8bdd153c4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ols_r2  ols_param_mse  ols_var_l1  known_r2  known_param_mse  known_time  \\\n",
       "0  0.152779       0.000608    0.102018  0.153504         0.000336           2   \n",
       "1  0.150526       0.001678    0.150979  0.153170         0.000513           4   \n",
       "2  0.148389       0.002744    0.180705  0.152915         0.000647           0   \n",
       "3  0.144894       0.004546    0.215329  0.153446         0.000382           4   \n",
       "4  0.138841       0.007658    0.254207  0.153691         0.000133           4   \n",
       "\n",
       "   unknown_r2  unknown_param_mse  unknown_var_l1  unknown_time   alpha     c  \\\n",
       "0    0.153291           0.000463        0.104234            12  0.9904 -2.50   \n",
       "1    0.152084           0.001111        0.130812            13  0.9816 -2.00   \n",
       "2    0.152856           0.000729        0.142953             5  0.9746 -1.75   \n",
       "3    0.152959           0.000648        0.161318             4  0.9645 -1.50   \n",
       "4    0.153354           0.000237        0.184326            15  0.9495 -1.25   \n",
       "\n",
       "   num_samples  noise_scale                                exp_id  \n",
       "0         9904          1.0  49a9b744-70d9-427c-89b3-0be8bdd153c4  \n",
       "1         9816          1.0  49a9b744-70d9-427c-89b3-0be8bdd153c4  \n",
       "2         9746          1.0  49a9b744-70d9-427c-89b3-0be8bdd153c4  \n",
       "3         9645          1.0  49a9b744-70d9-427c-89b3-0be8bdd153c4  \n",
       "4         9495          1.0  49a9b744-70d9-427c-89b3-0be8bdd153c4  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store.close()\n",
    "reader = CollectionReader(OUT_DIR + EXP)\n",
    "logs = reader.df(TABLE_NAME)\n",
    "reader.close()\n",
    "logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ols_r2</th>\n",
       "      <th>ols_param_mse</th>\n",
       "      <th>ols_var_l1</th>\n",
       "      <th>known_r2</th>\n",
       "      <th>known_param_mse</th>\n",
       "      <th>known_time</th>\n",
       "      <th>unknown_r2</th>\n",
       "      <th>unknown_param_mse</th>\n",
       "      <th>unknown_var_l1</th>\n",
       "      <th>unknown_time</th>\n",
       "      <th>alpha</th>\n",
       "      <th>c</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>noise_scale</th>\n",
       "      <th>exp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.142504</td>\n",
       "      <td>0.309806</td>\n",
       "      <td>0.438713</td>\n",
       "      <td>0.353813</td>\n",
       "      <td>0.006480</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.969051</td>\n",
       "      <td>0.941152</td>\n",
       "      <td>0.894512</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>5140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c169b767-7006-4795-86f0-f7229d15c579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.155564</td>\n",
       "      <td>0.325148</td>\n",
       "      <td>0.416177</td>\n",
       "      <td>0.367973</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.761265</td>\n",
       "      <td>0.863839</td>\n",
       "      <td>0.954204</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5139</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>5139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89706473-a9ac-4be7-a4c8-c9b1dbe67eae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.139493</td>\n",
       "      <td>0.322603</td>\n",
       "      <td>0.473248</td>\n",
       "      <td>0.381122</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.183067</td>\n",
       "      <td>0.426758</td>\n",
       "      <td>0.575063</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5186</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>5186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7b825bda-6a1e-4c28-9e18-3ec006655bd7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.167381</td>\n",
       "      <td>0.319581</td>\n",
       "      <td>0.429336</td>\n",
       "      <td>0.356595</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.660523</td>\n",
       "      <td>0.756506</td>\n",
       "      <td>0.908247</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>5140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dd05cd94-70dd-4065-9893-e85964f995e8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.156538</td>\n",
       "      <td>0.317880</td>\n",
       "      <td>0.400103</td>\n",
       "      <td>0.367498</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.839491</td>\n",
       "      <td>1.581126</td>\n",
       "      <td>1.190123</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5171</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>5171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a2497808-aaf8-4284-a207-e785ac0c6a80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.161602</td>\n",
       "      <td>0.315198</td>\n",
       "      <td>0.433497</td>\n",
       "      <td>0.371696</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.095694</td>\n",
       "      <td>1.061920</td>\n",
       "      <td>1.029433</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>5074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3dfed078-bc77-4654-9742-527f15ad0823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.147236</td>\n",
       "      <td>0.312506</td>\n",
       "      <td>0.441578</td>\n",
       "      <td>0.371326</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.083176</td>\n",
       "      <td>1.066921</td>\n",
       "      <td>0.980096</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5164</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>5164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>459051fa-6386-4e92-b22d-f5dee6a9cc07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.173533</td>\n",
       "      <td>0.323975</td>\n",
       "      <td>0.386644</td>\n",
       "      <td>0.360457</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.560591</td>\n",
       "      <td>2.645218</td>\n",
       "      <td>1.254862</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5211</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>5211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42fac9b8-f73c-4155-b0bf-7a8ababe2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.170751</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.406722</td>\n",
       "      <td>0.353943</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.251262</td>\n",
       "      <td>1.214983</td>\n",
       "      <td>1.162685</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5129</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>5129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>f1daecd5-f242-441b-8524-90f87d780bd7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.164684</td>\n",
       "      <td>0.318776</td>\n",
       "      <td>0.438449</td>\n",
       "      <td>0.363485</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.766003</td>\n",
       "      <td>0.841145</td>\n",
       "      <td>0.899521</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5104</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>5104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>796a9179-c6b5-4670-9430-63ee622f100c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ols_r2  ols_param_mse  ols_var_l1  known_r2  known_param_mse  known_time  \\\n",
       "8 -0.142504       0.309806    0.438713  0.353813         0.006480           3   \n",
       "8 -0.155564       0.325148    0.416177  0.367973         0.000784           4   \n",
       "8 -0.139493       0.322603    0.473248  0.381122         0.002245           4   \n",
       "8 -0.167381       0.319581    0.429336  0.356595         0.000628           3   \n",
       "8 -0.156538       0.317880    0.400103  0.367498         0.001150           4   \n",
       "8 -0.161602       0.315198    0.433497  0.371696         0.002578           4   \n",
       "8 -0.147236       0.312506    0.441578  0.371326         0.003964           4   \n",
       "8 -0.173533       0.323975    0.386644  0.360457         0.001051           4   \n",
       "8 -0.170751       0.336300    0.406722  0.353943         0.000514           4   \n",
       "8 -0.164684       0.318776    0.438449  0.363485         0.001853           3   \n",
       "\n",
       "   unknown_r2  unknown_param_mse  unknown_var_l1  unknown_time   alpha     c  \\\n",
       "8   -0.969051           0.941152        0.894512             4  0.5140 -0.25   \n",
       "8   -0.761265           0.863839        0.954204             4  0.5139 -0.25   \n",
       "8   -0.183067           0.426758        0.575063             4  0.5186 -0.25   \n",
       "8   -0.660523           0.756506        0.908247             4  0.5140 -0.25   \n",
       "8   -1.839491           1.581126        1.190123             5  0.5171 -0.25   \n",
       "8   -1.095694           1.061920        1.029433             5  0.5074 -0.25   \n",
       "8   -1.083176           1.066921        0.980096             5  0.5164 -0.25   \n",
       "8   -3.560591           2.645218        1.254862             5  0.5211 -0.25   \n",
       "8   -1.251262           1.214983        1.162685             4  0.5129 -0.25   \n",
       "8   -0.766003           0.841145        0.899521             4  0.5104 -0.25   \n",
       "\n",
       "   num_samples  noise_scale                                exp_id  \n",
       "8         5140          1.0  c169b767-7006-4795-86f0-f7229d15c579  \n",
       "8         5139          1.0  89706473-a9ac-4be7-a4c8-c9b1dbe67eae  \n",
       "8         5186          1.0  7b825bda-6a1e-4c28-9e18-3ec006655bd7  \n",
       "8         5140          1.0  dd05cd94-70dd-4065-9893-e85964f995e8  \n",
       "8         5171          1.0  a2497808-aaf8-4284-a207-e785ac0c6a80  \n",
       "8         5074          1.0  3dfed078-bc77-4654-9742-527f15ad0823  \n",
       "8         5164          1.0  459051fa-6386-4e92-b22d-f5dee6a9cc07  \n",
       "8         5211          1.0  42fac9b8-f73c-4155-b0bf-7a8ababe2960  \n",
       "8         5129          1.0  f1daecd5-f242-441b-8524-90f87d780bd7  \n",
       "8         5104          1.0  796a9179-c6b5-4670-9430-63ee622f100c  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs[logs['c'] == -.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.1066]], grad_fn=<MulBackward0>),\n",
       " tensor([[-1.9161]], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_results.weight * unknown_results.lambda_.inverse(), unknown_results.bias * unknown_results.lambda_.inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1110]]), tensor([-0.1995]), tensor([[0.2293]]))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_results.weight.grad, unknown_results.bias.grad, unknown_results.lambda_.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.6244]], grad_fn=<InverseBackward>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_results.lambda_.inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = LinearRegression()\n",
    "test.fit(x_norm, noised / ch.sqrt(emp_noise_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.75042]], dtype=float32), array([-0.25078043], dtype=float32))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.coef_, test.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_test = LinearRegression().fit(x_trunc_norm, emp_stand_y_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.49994558]], dtype=float32), array([1.021418], dtype=float32))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_test.coef_, ols_test.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = logs[logs['c'] <= -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Truncation Parameter C'),\n",
       " Text(0, 0.5, 'L1 Distance to Ground-Truth')]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=logs, x='c', y='ols_param_mse', label='ols')\n",
    "ax = sns.lineplot(data=logs, x='c', y='known_param_mse', label='known')\n",
    "ax = sns.lineplot(data=logs, x='c', y='unknown_param_mse', label='unknown')\n",
    "ax.set(xlabel='Truncation Parameter C', ylabel='L2 Distance to Ground-Truth')\n",
    "plt.show()\n",
    "\n",
    "sns.lineplot(data=logs, x='c', y='ols_var_l1', label='ols')\n",
    "ax = sns.lineplot(data=logs, x='c', y='unknown_var_l1', label='unknown')\n",
    "ax.set(xlabel='Truncation Parameter C', ylabel='L1 Distance to Ground-Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4925])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_ols = LinearRegression().fit(x_trunc, y_trunc)\n",
    "emp_noise_var = (y_trunc - trunc_ols.predict(x_trunc)).var(0)\n",
    "emp_noise_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4962])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_noise_scale = ch.sqrt(emp_noise_var / 2)\n",
    "emp_noise_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4962])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emp_noise_var / 2).pow(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_noised = noised / ch.sqrt(emp_noise_var)\n",
    "new_y_trunc = y_trunc / ch.sqrt(emp_noise_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = LinearRegression().fit(x_trunc_norm, new_y_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new_y_trunc - ols.predict(x_trunc_norm)).var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_ols = LinearRegression()\n",
    "another_ols.fit(X, noised / noise_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0035])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(noised - another_ols.predict(X)).var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.gca(projection='3d')\n",
    "# data = ch.from_numpy(np.linspace(-3.0, 3.0, 100)).unsqueeze(1).float()\n",
    "\n",
    "ax.scatter3D(X[indices][:,0], X[indices][:,1], noised[indices], color=\"green\", alpha=.1)\n",
    "ax.scatter3D(x_trunc[:,0], x_trunc[:,1], y_trunc, color=\"red\", alpha=.75)\n",
    "\n",
    "ax.view_init(10, -150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_logs = pd.DataFrame(columns=logs.columns)\n",
    "for var in range(1, 21):\n",
    "    noise_scale = logs[logs['noise_scale'] == var].reset_index()\n",
    "    noise_scale.drop(index=noise_scale[['unknown_param_mse', 'unknown_var_mse']].sum(1).idxmax(), inplace=True)\n",
    "    cleaned_logs = pd.concat([cleaned_logs, noise_scale])\n",
    "cleaned_logs = cleaned_logs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6702)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.sample(ch.Size([10000])).norm(dim=-1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = Uniform(-1/d, 1/d)\n",
    "\n",
    "s = u.sample(ch.Size([10000, d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.0481],\n",
       "        [-4.1819],\n",
       "        [-3.8256],\n",
       "        ...,\n",
       "        [ 0.5905],\n",
       "        [-2.1130],\n",
       "        [-1.7292]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_trunc@w+w0 - y_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.3957]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.5118]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.5949]], requires_grad=True))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.weight, gt.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1744, 2.7350])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5809])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch.abs((x_trunc@w + w0) - y_trunc).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.8567])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((X@w + w0) - noised).var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.2200])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_trunc@w + w0 - y_trunc).var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd30c687dc0>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, noised)\n",
    "plt.scatter(x_trunc, y_trunc)\n",
    "plt.plot(x_trunc, x_trunc@w + w0, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Tensor(np.expand_dims(np.linspace(-3, 3), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_half, y_half = X[:5000], noised[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.1086])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_half@w + w0 - y_half).var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.2200])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_trunc@w - y_trunc).var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1702]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = ch.randn(100, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False],\n",
       "         [False],\n",
       "         [False],\n",
       "         ...,\n",
       "         [False],\n",
       "         [False],\n",
       "         [ True]],\n",
       "\n",
       "        [[ True],\n",
       "         [False],\n",
       "         [False],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False]],\n",
       "\n",
       "        [[ True],\n",
       "         [False],\n",
       "         [ True],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[False],\n",
       "         [ True],\n",
       "         [False],\n",
       "         ...,\n",
       "         [False],\n",
       "         [ True],\n",
       "         [ True]],\n",
       "\n",
       "        [[False],\n",
       "         [False],\n",
       "         [False],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False]],\n",
       "\n",
       "        [[ True],\n",
       "         [False],\n",
       "         [ True],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [False]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand > 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
